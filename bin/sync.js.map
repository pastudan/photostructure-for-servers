{
  "version": 3,
  "sources": ["../../../../core/node_modules/paseto/lib/errors.js", "../../../../core/node_modules/paseto/lib/help/is_object.js", "../../../../core/node_modules/paseto/lib/help/check_footer.js", "../../../../core/node_modules/paseto/lib/help/ms.js", "../../../../core/node_modules/paseto/lib/help/apply_options.js", "../../../../core/node_modules/paseto/lib/help/check_payload.js", "../../../../core/node_modules/paseto/lib/help/le64.js", "../../../../core/node_modules/paseto/lib/help/pae.js", "../../../../core/node_modules/paseto/lib/help/base64url.js", "../../../../core/node_modules/paseto/lib/help/pack.js", "../../../../core/node_modules/paseto/lib/help/timing_safe_equal.js", "../../../../core/node_modules/paseto/lib/help/crypto_worker.js", "../../../../core/node_modules/paseto/lib/help/sign.js", "../../../../core/node_modules/paseto/lib/v1/sign.js", "../../../../core/node_modules/paseto/lib/help/assert_payload.js", "../../../../core/node_modules/paseto/lib/help/parse_paseto_payload.js", "../../../../core/node_modules/paseto/lib/help/verify.js", "../../../../core/node_modules/paseto/lib/v1/verify.js", "../../../../core/node_modules/paseto/lib/help/symmetric_key_check.js", "../../../../core/node_modules/paseto/lib/help/random_bytes.js", "../../../../core/node_modules/paseto/lib/v1/encrypt.js", "../../../../core/node_modules/paseto/lib/v1/decrypt.js", "../../../../core/node_modules/paseto/lib/v1/key.js", "../../../../core/node_modules/paseto/lib/v1/index.js", "../../../../core/node_modules/paseto/lib/v2/sign.js", "../../../../core/node_modules/paseto/lib/v2/verify.js", "../../../../core/node_modules/paseto/lib/v2/key.js", "../../../../core/node_modules/paseto/lib/v2/index.js", "../../../../core/node_modules/paseto/lib/general/decode.js", "../../../../core/node_modules/paseto/lib/general/index.js", "../../../../core/node_modules/paseto/lib/index.js", "../../../node_modules/@sentry/types/src/loglevel.ts", "../../../node_modules/@sentry/types/src/session.ts", "../../../node_modules/@sentry/types/src/severity.ts", "../../../node_modules/@sentry/types/src/status.ts", "../../../node_modules/@sentry/types/src/transaction.ts", "../../../node_modules/@sentry/types/src/index.ts", "../../../node_modules/source-map/lib/base64.js", "../../../node_modules/source-map/lib/base64-vlq.js", "../../../node_modules/source-map/lib/util.js", "../../../node_modules/source-map/lib/array-set.js", "../../../node_modules/source-map/lib/mapping-list.js", "../../../node_modules/source-map/lib/source-map-generator.js", "../../../node_modules/source-map/lib/binary-search.js", "../../../node_modules/source-map/lib/quick-sort.js", "../../../node_modules/source-map/lib/source-map-consumer.js", "../../../node_modules/source-map/lib/source-node.js", "../../../node_modules/source-map/source-map.js", "../../../node_modules/buffer-from/index.js", "../../../node_modules/source-map-support/source-map-support.js", "../../../../core/cli/CLI.ts", "../../../../core/ServiceNames.ts", "../../../../fe/Iterable.ts", "../../../../fe/toS.ts", "../../../../fe/Primitive.ts", "../../../../fe/ObjectType.ts", "../../../../fe/Thunk.ts", "../../../../fe/Maybe.ts", "../../../../fe/Blank.ts", "../../../../fe/JSON.ts", "../../../../fe/Eql.ts", "../../../../fe/List.ts", "../../../../fe/Map.ts", "../../../../fe/Opt.ts", "../../../../fe/Number.ts", "../../../../fe/Random.ts", "../../../../fe/String.ts", "../../../../fe/toA.ts", "../../../../fe/Array.ts", "../../../../fe/Lazy.ts", "../../../../fe/Date.ts", "../../../../fe/StrEnum.ts", "../../../../core/NodeEnv.ts", "../../../../fe/Boolean.ts", "../../../../core/AppName.ts", "../../../../core/Chalk.ts", "../../../../core/Env.ts", "../../../../fe/Object.ts", "../../../../core/Array.ts", "../../../../core/Eql.ts", "../../../../core/math/Average.ts", "../../../../core/BoundedList.ts", "../../../../core/String.ts", "../../../../core/Number.ts", "../../../../core/CountingSet.ts", "../../../../core/Set.ts", "../../../../core/math/Vector.ts", "../../../../core/MultiMap.ts", "../../../../core/Object.ts", "../../../../fe/AsPromise.ts", "../../../../fe/Delay.ts", "../../../../core/async/thenOrTimeout.ts", "../../../../core/async/Timers.ts", "../../../../core/async/Endable.ts", "../../../../core/settings/Settings.ts", "../../../../fe/ImageSizes.ts", "../../../../fe/Units.ts", "../../../../core/fs/Path.ts", "../../../../fe/Promise.ts", "../../../../fe/Latch.ts", "../../../../core/work/MaxCpus.ts", "../../../../core/event/EventEmitter.ts", "../../../../core/event/TestEventEmitter.ts", "../../../../core/async/Deferred.ts", "../../../../fe/Error.ts", "../../../../fe/PromiseState.ts", "../../../../core/error/ErrorTypes.ts", "../../../../core/async/Promises.ts", "../../../../core/async/Promise.ts", "../../../../core/Platform.ts", "../../../../core/volumes/VolumeTtls.ts", "../../../../core/fs/StatTimeout.ts", "../../../../core/fs/Streams.ts", "../../../../core/HomeDir.ts", "../../../../core/DefaultCacheDir.ts", "../../../../core/LogDir.ts", "../../../../core/AppData.ts", "../../../../core/Version.ts", "../../../../core/PhotoStructureVersion.ts", "../../../../core/PicturesDir.ts", "../../../../core/pwsh/PowerShell.ts", "../../../../core/async/until.ts", "../../../../core/BatchClusterObserver.ts", "../../../../core/async/EndableWrapper.ts", "../../../../core/child/ChildProcess.ts", "../../../../fe/AsyncRetry.ts", "../../../../core/math/Rate.ts", "../../../../core/TTLArray.ts", "../../../../core/error/ErrorCodes.ts", "../../../../core/error/Error.ts", "../../../../core/Pids.ts", "../../../../core/FifoCache.ts", "../../../../core/fs/BaseFile.ts", "../../../../core/async/Predicate.ts", "../../../../core/Elapsed.ts", "../../../../core/async/PromiseTimer.ts", "../../../../core/math/Radix.ts", "../../../../core/math/b64.ts", "../../../../core/CussWords.ts", "../../../../core/Leet.ts", "../../../../core/Cuss.ts", "../../../../core/StringSimilarity.ts", "../../../../core/fs/CRLF.ts", "../../../../core/fs/DirectoryEntry.ts", "../../../../core/fs/Readdir.ts", "../../../../core/fs/Hash.ts", "../../../../core/fs/zcat.ts", "../../../../core/error/WrappedError.ts", "../../../../core/fs/WritableToBuffer.ts", "../../../../core/fs/FileCache.ts", "../../../../core/fs/LineReader.ts", "../../../../core/fs/ProgressObservers.ts", "../../../../core/event/ProgressEvt.ts", "../../../../fe/Throttle.ts", "../../../../core/fs/ProjectPath.ts", "../../../../core/fs/Ancestors.ts", "../../../../core/fs/StreamChunker.ts", "../../../../core/Map.ts", "../../../../core/Ps.ts", "../../../../core/RegExp.ts", "../../../../core/Fixed.ts", "../../../../core/fs/PathTo.ts", "../../../../core/WinDate.ts", "../../../../core/UserData.ts", "../../../../core/PriorityClass.ts", "../../../../core/TTLSet.ts", "../../../../core/Renice.ts", "../../../../core/child/ChildEnv.ts", "../../../../core/Locale.ts", "../../../../fe/OptAsync.ts", "../../../../core/async/Later.ts", "../../../../core/log/LogMeta.ts", "../../../../core/log/LogLevel.ts", "../../../../core/log/RecentLogs.ts", "../../../../core/log/Logger.ts", "../../../../core/tags/DefaultLensMakes.ts", "../../../../core/tags/SidecarExts.ts", "../../../../core/settings/Setting.ts", "../../../../core/StringCase.ts", "../../../../core/log/LogFilter.ts", "../../../../core/SortedArray.ts", "../../../../core/log/DefaultLogFormatter.ts", "../../../../core/log/ColoredLogFormatter.ts", "../../../../core/log/LogCommon.ts", "../../../../core/log/PlaintextLogFormatter.ts", "../../../../core/log/LogEntry.ts", "../../../../core/log/LogTailEntries.ts", "../../../../core/log/ConsoleLogger.ts", "../../../../core/log/LogWriter.ts", "../../../../core/JSON.ts", "../../../../core/Logger.ts", "../../../../core/cli/CliConstants.ts", "../../../../core/cli/IsDaemon.ts", "../../../../core/cli/LogArgs.ts", "../../../cli/CommonArgs.ts", "../../../cli/ExitWhenDone.ts", "../../../cli/ExitWhenDoneArg.ts", "../../../StatsDbDir.ts", "../../../../core/fs/PosixFile.ts", "../../../../core/tags/FileExts.ts", "../../../../fe/URI.ts", "../../../../core/net/nslookup.ts", "../../../../core/async/MemoizedAsyncFunc.ts", "../../../../core/net/ping.ts", "../../../../core/volumes/Mount.ts", "../../../../core/volumes/DfPosixRaw.ts", "../../../../core/volumes/Gio.ts", "../../../../core/date/Date.ts", "../../../../core/child/WatchedChild.ts", "../../../../core/Debounce.ts", "../../../../core/volumes/MountpointsPosix.ts", "../../../../core/volumes/MountpointsWin.ts", "../../../../core/volumes/Mountpoints.ts", "../../../../core/volumes/LazyFsAsync.ts", "../../../../core/volumes/DfPosix.ts", "../../../../core/volumes/RemoteVolumesWin.ts", "../../../../core/volumes/DfWin.ts", "../../../../core/volumes/LocalVolumesMac.ts", "../../../../core/EnvTokens.ts", "../../../../core/volumes/LocalVolumesPosix.ts", "../../../../core/volumes/RemoteVolumesPosix.ts", "../../../../core/async/TryWithErrorHandling.ts", "../../../../core/math/UUID.ts", "../../../../core/volumes/VolumeUUID.ts", "../../../../core/volumes/Volumes.ts", "../../../../core/uri/psfile.ts", "../../../../core/MemoizedFunc.ts", "../../../../core/uri/URI.ts", "../../../../core/CharCode.ts", "../../../../core/uri/pslib.ts", "../../../../core/uri/psnet.ts", "../../../../core/uri/UriNormalization.ts", "../../../../core/uri/FileURI.ts", "../../../../core/fs/Hidden.ts", "../../../../core/LoggedThunks.ts", "../../../../core/SetSet.ts", "../../../../core/fs/NeverIgnoredPaths.ts", "../../../../core/fs/NoMedia.ts", "../../../../core/fs/SeemsRecursive.ts", "../../../../core/async/AsyncFilter.ts", "../../../../core/fs/Snap.ts", "../../../../core/fs/Ignorable.ts", "../../../../core/CacheDir.ts", "../../../../core/PhotoStructureVersions.ts", "../../../cli/ForceArg.ts", "../../../cli/NoFilterArg.ts", "../../../cli/RebuildArg.ts", "../../../cli/SkipUpdateArg.ts", "../../../sync/SyncService.ts", "../../../../core/child/ChildService.ts", "../../../../core/child/HealthChecks.ts", "../../../../core/async/EndableInterval.ts", "../../../../core/fs/TmpfileCleanup.ts", "../../../../core/fs/FileType.ts", "../../../../core/tags/ExifTags.ts", "../../../../core/fs/Tools.ts", "../../../../core/img/RawInfo.ts", "../../../../core/img/Video.ts", "../../../../core/math/Lerp.ts", "../../../../core/img/VideoFilter.ts", "../../../../core/tags/Duration.ts", "../../../../fe/Rotation.ts", "../../../../core/tags/Orientation.ts", "../../../../fe/Dimensions.ts", "../../../../core/tags/SizeInfo.ts", "../../../../core/img/SyncFileTimeout.ts", "../../../../core/fs/SameFiles.ts", "../../../../fe/api/Subscriptions.ts", "../../../../core/settings/LibraryDirs.ts", "../../../../core/net/Request.ts", "../../../../core/licensing/BrotliDecode.ts", "../../../../core/licensing/SystemIds.ts", "../../../../core/fs/ReadFile.ts", "../../../../core/fs/JsonFileStore.ts", "../../../../core/fs/UIDStore.ts", "../../../../core/net/mac.ts", "../../../../core/licensing/SystemIdSchemes.ts", "../../../../core/licensing/L.ts", "../../../../core/licensing/WriteLicense.ts", "../../../../core/licensing/AutoRefreshLicense.ts", "../../../../core/licensing/Paseto.ts", "../../../../core/licensing/Licensing.ts", "../../../../core/img/jpegtran.ts", "../../../../core/tags/BinaryTag.ts", "../../../../core/tags/Mimetypes.ts", "../../../../core/img/Dimensions.ts", "../../../../core/img/FileDimensions.ts", "../../../../core/img/HeifConvert.ts", "../../../../core/img/sips.ts", "../../../../core/img/Heif.ts", "../../../../core/img/HeifFilter.ts", "../../../../core/event/EmitSafely.ts", "../../../../core/img/ImageSize.ts", "../../../../fe/Fit.ts", "../../../../fe/ImageReducers.ts", "../../../../core/img/Reducers.ts", "../../../../core/img/libraw.ts", "../../../../core/img/SharpReadable.ts", "../../../../core/img/ValidFile.ts", "../../../../core/img/ffmpeg.ts", "../../../../core/img/vlc.ts", "../../../../core/tags/CapturedAt.ts", "../../../../core/date/FuzzyDate.ts", "../../../../core/Timezone.ts", "../../../../core/date/DateInterval.ts", "../../../../core/Filter.ts", "../../../../core/fs/BaseFileFilters.ts", "../../../../core/tags/TagInference.ts", "../../../../core/tags/ExposureSettings.ts", "../../../../core/math/Bits.ts", "../../../../core/GeoHash.ts", "../../../../core/tags/JsonSidecar.ts", "../../../../core/tags/MakeModel.ts", "../../../../core/tags/LensMakeModel.ts", "../../../../core/tags/TitleDescription.ts", "../../../../core/fs/ReadFilePart.ts", "../../../../core/img/ImgCache.ts", "../../../db/DbRetries.ts", "../../../../core/rpc/NoOpBroadcaster.ts", "../../../../core/rpc/Broadcaster.ts", "../../../OpenedBy.ts", "../../../rpc/RpcClient.ts", "../../../../core/rpc/Client.ts", "../../../../core/UID.ts", "../../../../core/rpc/RequestResponse.ts", "../../../db/Vacuum.ts", "../../../db/Transactions.ts", "../../../../core/date/ExtendedDate.ts", "../../../../fe/api/ID.ts", "../../../../fe/AssetUrls.ts", "../../../../fe/api/Tag.ts", "../../../curators/DateTagger.ts", "../../../../core/tags/Names.ts", "../../../curators/WhoTagger.ts", "../../../curators/Taggers.ts", "../../../../core/img/AssetPreviewBuilder.ts", "../../../../core/img/AssetFileSorter.ts", "../../../../core/img/FitSizes.ts", "../../../../core/img/Sharp.ts", "../../../../core/img/SharpColorspace.ts", "../../../../core/img/PreviewInfo.ts", "../../../../core/img/AssetPreviews.ts", "../../../../core/img/Previews.ts", "../../../../core/settings/SettingsIO.ts", "../../../../core/rpc/Server.ts", "../../../../core/work/WorkPlanner.ts", "../../../LibraryHealthChecks.ts", "../../../../core/Memory.ts", "../../../HealthChecks.ts", "../../../model/Model.ts", "../../../db/Knex.ts", "../../../db/DbPath.ts", "../../../model/ModelDb.ts", "../../../model/ModelJson.ts", "../../../db/DbValued.ts", "../../../db/SqlQuery.ts", "../../../db/DbRequest.ts", "../../../model/ModelOps.ts", "../../../model/TimestampedModel.ts", "../../../model/Heartbeat.ts", "../../../PauseHealthChecks.ts", "../../../rpc/RpcServiceHandlers.ts", "../../../rpc/RpcServer.ts", "../../../BroadcasterImpl.ts", "../../../model/AdvisoryLock.ts", "../../../../core/math/Matrix.ts", "../../../../core/img/Colorspace.ts", "../../../../core/img/ImageHash.ts", "../../../db/Migrations.ts", "../../../db/Migration.ts", "../../../db/MkDb.ts", "../../../../core/fs/Stat.ts", "../../../db/SqliteSuffixes.ts", "../../../db/SQLiteFiles.ts", "../../../db/WithDb.ts", "../../../db/SQLite.ts", "../../../db/Db.ts", "../../../../core/fs/Hanoi.ts", "../../../../core/Stdout.ts", "../../../db/DbBackup.ts", "../../../LocalDbDir.ts", "../../../../fe/PRNG.ts", "../../../../core/math/PRNG.ts", "../../../../fe/TagUrls.ts", "../../../model/AssetTag.ts", "../../../model/TaggedAssetStream.ts", "../../../model/Tag.ts", "../../../model/DateTagNormalizer.ts", "../../../model/Progress.ts", "../../../model/Operation.ts", "../../../model/ProgressMeta.ts", "../../../model/AssetFile.ts", "../../../../core/fs/PosixFileFilters.ts", "../../../../core/tags/ExifUid.ts", "../../../../fe/fmtDuration.ts", "../../../curators/FilePathTagger.ts", "../../../model/TagSql.ts", "../../../model/ModelDbJanitor.ts", "../../../rpc/RpcSetup.ts", "../../../stats/StatsDb.ts", "../../../stats/StatsDbJanitor.ts", "../../../sync-file/AssetFileRepository.ts", "../../../Library.ts", "../../../model/Asset.ts", "../../../ForceRebuildLibrary.ts", "../../../Service.ts", "../../../../core/log/LogTail.ts", "../../../../core/RoundRobin.ts", "../../../../core/work/Idle.ts", "../../../SendRecentLogs.ts", "../../../../core/event/EventStore.ts", "../../../SentryEnabled.ts", "../../../SentrySetup.ts", "../../../../core/BoundedGreatestList.ts", "../../../../core/log/LogReader.ts", "../../../../core/log/AllRecentLogEntries.ts", "../../../../core/os.ts", "../../../StdoutWrite.ts", "../../../sync-file/NativePathImportTask.ts", "../../../sync-file/ImportResult.ts", "../../../sync-file/UpdateTask.ts", "../../../sync-file/UpdateResult.ts", "../../../../core/math/ETA.ts", "../../../../fe/api/ProgressState.ts", "../../../sync/DirectoryTaggerOperation.ts", "../../../WorkQueue.ts", "../../../stats/StatsModel.ts", "../../../stats/QueueItem.ts", "../../../stats/Queue.ts", "../../../sync/UpdateQueue.ts", "../../../sync/AssetFileUpdateQueue.ts", "../../../sync/AssetPreviewQueue.ts", "../../../sync/AssetUpdateQueue.ts", "../../../sync/ModelDbUpdater.ts", "../../../sync/ProgressUpdater.ts", "../../../../core/async/Done.ts", "../../../../core/fs/PosixFileSorters.ts", "../../../../core/fs/DirectoryIterator.ts", "../../../../core/fs/DirectoryWalker.ts", "../../../sync/AssetFileQueue.ts", "../../../sync/PrecheckFiles.ts", "../../../sync/DirectorySync.ts", "../../../sync/SyncPaths.ts", "../../../sync/SyncRunner.ts", "../../../sync/FileSync.ts", "../../../sync/Syncs.ts", "../../../sync.ts"],
  "sourcesContent": ["const CODES = {\n  PasetoNotSupported: 'ERR_PASETO_NOT_SUPPORTED',\n  PasetoDecryptionFailed: 'ERR_PASETO_DECRYPTION_FAILED',\n  PasetoInvalid: 'ERR_PASETO_INVALID',\n  PasetoVerificationFailed: 'ERR_PASETO_VERIFICATION_FAILED',\n  PasetoClaimInvalid: 'ERR_PASETO_CLAIM_INVALID',\n  PasetoWorkerFailure: 'ERR_PASETO_WORKER_FAILURE'\n}\n\nclass PasetoError extends Error {\n  constructor (message) {\n    super(message)\n    this.name = this.constructor.name\n    this.code = CODES[this.constructor.name]\n    Error.captureStackTrace(this, this.constructor)\n  }\n}\n\nmodule.exports.PasetoError = PasetoError\n\nmodule.exports.PasetoNotSupported = class PasetoNotSupported extends PasetoError {}\nmodule.exports.PasetoDecryptionFailed = class PasetoDecryptionFailed extends PasetoError {}\nmodule.exports.PasetoInvalid = class PasetoInvalid extends PasetoError {}\nmodule.exports.PasetoVerificationFailed = class PasetoVerificationFailed extends PasetoError {}\nmodule.exports.PasetoClaimInvalid = class PasetoClaimInvalid extends PasetoError {}\nmodule.exports.PasetoWorkerFailure = class PasetoWorkerFailure extends PasetoError {}\n", "module.exports = input => !!input && input.constructor === Object\n", "const isObject = require('./is_object')\n\nmodule.exports = function checkFooter (footer) {\n  if (typeof footer === 'undefined') {\n    return Buffer.from('')\n  }\n\n  if (Buffer.isBuffer(footer)) {\n    return footer\n  }\n\n  if (isObject(footer)) {\n    return Buffer.from(JSON.stringify(footer), 'utf8')\n  }\n\n  if (typeof footer !== 'string') {\n    throw new TypeError('options.footer must be a string, Buffer, or a plain object')\n  }\n\n  return Buffer.from(footer, 'utf8')\n}\n", "const second = 1000\nconst minute = second * 60\nconst hour = minute * 60\nconst day = hour * 24\nconst week = day * 7\nconst year = day * 365.25\n\nconst REGEX = /^(\\d+|\\d+\\.\\d+) ?(seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)$/i\n\nmodule.exports = (str) => {\n  const matched = REGEX.exec(str)\n\n  if (!matched) {\n    throw new TypeError(`invalid time period format (\"${str}\")`)\n  }\n\n  const value = parseFloat(matched[1])\n  const unit = matched[2].toLowerCase()\n\n  switch (unit) {\n    case 'sec':\n    case 'secs':\n    case 'second':\n    case 'seconds':\n    case 's':\n      return Math.round(value * second)\n    case 'minute':\n    case 'minutes':\n    case 'min':\n    case 'mins':\n    case 'm':\n      return Math.round(value * minute)\n    case 'hour':\n    case 'hours':\n    case 'hr':\n    case 'hrs':\n    case 'h':\n      return Math.round(value * hour)\n    case 'day':\n    case 'days':\n    case 'd':\n      return Math.round(value * day)\n    case 'week':\n    case 'weeks':\n    case 'w':\n      return Math.round(value * week)\n    case 'year':\n    case 'years':\n    case 'yr':\n    case 'yrs':\n    case 'y':\n      return Math.round(value * year)\n  }\n}\n", "const ms = require('../help/ms')\n\nmodule.exports = ({\n  audience, expiresIn, iat = true, issuer, jti, kid, notBefore, now = new Date(), subject\n}, payload) => {\n  if (!(now instanceof Date) || !now.getTime()) {\n    throw new TypeError('options.now must be a valid Date object')\n  }\n\n  const unix = now.getTime()\n\n  if (iat !== undefined) {\n    if (typeof iat !== 'boolean') {\n      throw new TypeError('options.iat must be a boolean')\n    }\n\n    if (iat) {\n      payload.iat = new Date(unix)\n    }\n  }\n\n  if (expiresIn !== undefined) {\n    if (typeof expiresIn !== 'string') {\n      throw new TypeError('options.expiresIn must be a string')\n    }\n\n    payload.exp = new Date(unix + ms(expiresIn))\n  }\n\n  if (notBefore !== undefined) {\n    if (typeof notBefore !== 'string') {\n      throw new TypeError('options.notBefore must be a string')\n    }\n\n    payload.nbf = new Date(unix + ms(notBefore))\n  }\n\n  if (audience !== undefined) {\n    if (typeof audience !== 'string') {\n      throw new TypeError('options.audience must be a string')\n    }\n\n    payload.aud = audience\n  }\n\n  if (issuer !== undefined) {\n    if (typeof issuer !== 'string') {\n      throw new TypeError('options.issuer must be a string')\n    }\n\n    payload.iss = issuer\n  }\n\n  if (subject !== undefined) {\n    if (typeof subject !== 'string') {\n      throw new TypeError('options.subject must be a string')\n    }\n\n    payload.sub = subject\n  }\n\n  if (kid !== undefined) {\n    if (typeof kid !== 'string') {\n      throw new TypeError('options.kid must be a string')\n    }\n\n    payload.kid = kid\n  }\n\n  if (jti !== undefined) {\n    if (typeof jti !== 'string') {\n      throw new TypeError('options.jti must be a string')\n    }\n\n    payload.jti = jti\n  }\n\n  return payload\n}\n", "const applyOptions = require('./apply_options')\nconst isObject = require('./is_object')\nconst deepClone = payload => JSON.parse(JSON.stringify(payload))\n\nmodule.exports = (payload, options) => {\n  if (Buffer.isBuffer(payload)) {\n    if (Object.keys(options).length !== 0) {\n      throw new TypeError('options cannot contain claims when payload is a Buffer')\n    }\n\n    return payload\n  }\n  if (!isObject(payload)) {\n    throw new TypeError('payload must be a Buffer or a plain object')\n  }\n\n  payload = deepClone(payload)\n  payload = applyOptions(options, payload)\n  return Buffer.from(JSON.stringify(payload), 'utf-8')\n}\n", "const { PasetoNotSupported } = require('../errors')\n\nmodule.exports = (n) => {\n  if (!Number.isSafeInteger(n)) {\n    throw new PasetoNotSupported('message is too long for Node.js to safely process')\n  }\n\n  const up = ~~(n / 0xFFFFFFFF)\n  const dn = (n % 0xFFFFFFFF) - up\n\n  const buf = Buffer.allocUnsafe(8)\n\n  buf.writeUInt32LE(up, 4)\n  buf.writeUInt32LE(dn, 0)\n\n  return buf\n}\n", "const le64 = require('./le64')\n\nmodule.exports = (...pieces) => {\n  let accumulator = le64(pieces.length)\n  for (let piece of pieces) {\n    piece = Buffer.from(piece, 'utf8')\n    const len = le64(Buffer.byteLength(piece))\n    accumulator = Buffer.concat([accumulator, len, piece])\n  }\n  return accumulator\n}\n", "const fromBase64 = (base64) => {\n  return base64.replace(/=/g, '').replace(/\\+/g, '-').replace(/\\//g, '_')\n}\n\nconst toBase64 = (base64url) => {\n  return base64url.replace(/-/g, '+').replace(/_/g, '/')\n}\n\nconst encode = (buf) => {\n  return fromBase64(buf.toString('base64'))\n}\n\nconst decode = (input) => {\n  return Buffer.from(toBase64(input), 'base64')\n}\n\nmodule.exports.decode = decode\nmodule.exports.encode = encode\n", "const { encode } = require('./base64url')\n\nmodule.exports = function pack (header, payload, footer) {\n  if (footer.length !== 0) {\n    return `${header}${encode(Buffer.concat(payload))}.${encode(footer)}`\n  }\n\n  return `${header}${encode(Buffer.concat(payload))}`\n}\n", "const { timingSafeEqual: TSE } = require('crypto')\n\nconst paddedBuffer = (input, length) => {\n  if (input.length === length) {\n    return input\n  }\n\n  const buffer = Buffer.alloc(length)\n  input.copy(buffer)\n  return buffer\n}\n\nconst timingSafeEqual = (a, b) => {\n  const length = Math.max(a.length, b.length)\n  return TSE(paddedBuffer(a, length), paddedBuffer(b, length))\n}\n\nmodule.exports = timingSafeEqual\n", "const crypto = require('crypto')\nconst util = require('util')\nconst { PasetoWorkerFailure } = require('../errors')\n\nconst pae = require('./pae')\nlet hkdf\nif (crypto.hkdf) {\n  const pHkdf = util.promisify(crypto.hkdf)\n  hkdf = (key, length, salt, info) => pHkdf('sha384', key, salt, info, length)\n} else {\n  hkdf = (key, length, salt, info) => {\n    const prk = methods.hmac('sha384', key, salt)\n\n    const u = Buffer.from(info)\n\n    let t = Buffer.from('')\n    let lb = Buffer.from('')\n    let i\n\n    for (let bi = 1; Buffer.byteLength(t) < length; ++i) {\n      i = Buffer.from(String.fromCharCode(bi))\n      const inp = Buffer.concat([lb, u, i])\n\n      lb = methods.hmac('sha384', inp, prk)\n      t = Buffer.concat([t, lb])\n    }\n\n    const orm = Buffer.from(t).slice(0, length)\n    return orm\n  }\n}\n\nconst pack = require('./pack')\nconst timingSafeEqual = require('./timing_safe_equal')\n\nconst methods = {\n  async 'aes-256-ctr-hmac-sha-384-encrypt' (m, f, k, nonce) {\n    let n = methods.hmac('sha384', m, nonce)\n    n = n.slice(0, 32)\n    f = Buffer.from(f)\n\n    const salt = n.slice(0, 16)\n    const [ek, ak] = await Promise.all([\n      hkdf(k, 32, salt, 'paseto-encryption-key'),\n      hkdf(k, 32, salt, 'paseto-auth-key-for-aead')\n    ])\n\n    const c = methods.encrypt('aes-256-ctr', m, ek, n.slice(16))\n    const preAuth = pae('v1.local.', n, c, f)\n    const t = methods.hmac('sha384', preAuth, ak)\n\n    return pack('v1.local.', [n, c, t], f)\n  },\n  async 'aes-256-ctr-hmac-sha-384-decrypt' (raw, f, k) {\n    const n = raw.slice(0, 32)\n    const t = raw.slice(-48)\n    const c = raw.slice(32, -48)\n\n    const salt = n.slice(0, 16)\n    const [ek, ak] = await Promise.all([\n      hkdf(k, 32, salt, 'paseto-encryption-key'),\n      hkdf(k, 32, salt, 'paseto-auth-key-for-aead')\n    ])\n\n    const preAuth = pae('v1.local.', n, c, f)\n\n    const t2 = methods.hmac('sha384', preAuth, ak)\n    const payload = methods.decrypt('aes-256-ctr', c, ek, n.slice(16))\n\n    if (!timingSafeEqual(t, t2) || !payload) {\n      return false\n    }\n\n    return payload\n  },\n  hmac (alg, payload, key) {\n    const hmac = crypto.createHmac(alg, key)\n    hmac.update(payload)\n    return hmac.digest()\n  },\n  verify (alg, payload, key, signature) {\n    return crypto.verify(alg, payload, key, signature)\n  },\n  sign (alg, payload, key) {\n    return crypto.sign(alg, payload, key)\n  },\n  encrypt (cipher, cleartext, key, iv) {\n    const encryptor = crypto.createCipheriv(cipher, key, iv)\n    return Buffer.concat([encryptor.update(cleartext), encryptor.final()])\n  },\n  decrypt (cipher, ciphertext, key, iv) {\n    const decryptor = crypto.createDecipheriv(cipher, key, iv)\n    return Buffer.concat([decryptor.update(ciphertext), decryptor.final()])\n  }\n}\n\nmodule.exports = methods", "const { sign } = require('./crypto_worker')\n\nconst pae = require('./pae')\nconst pack = require('./pack')\n\nmodule.exports = async function signPaseto (h, m, f, alg, key, expectedSigLength) {\n  const m2 = pae(h, m, f)\n  const sig = await sign(alg, m2, key)\n\n  if (sig.length !== expectedSigLength) {\n    throw new TypeError(`invalid ${h.slice(0, -1)} signing key bit length`)\n  }\n\n  return pack(h, [m, sig], f)\n}\n", "const {\n  constants: {\n    RSA_PKCS1_PSS_PADDING: padding,\n    RSA_PSS_SALTLEN_DIGEST: saltLength\n  },\n  createPrivateKey,\n  KeyObject\n} = require('crypto')\n\nconst checkFooter = require('../help/check_footer')\nconst checkPayload = require('../help/check_payload')\nconst sign = require('../help/sign')\n\nfunction checkKey (key) {\n  if (!(key instanceof KeyObject)) {\n    key = createPrivateKey(key)\n  }\n\n  if (key.type !== 'private' || key.asymmetricKeyType !== 'rsa') {\n    throw new TypeError('v1.public signing key must be a private RSA key')\n  }\n\n  return key\n}\n\nmodule.exports = async function v1Sign (payload, key, { footer, ...options } = {}) {\n  const m = checkPayload(payload, options)\n  const f = checkFooter(footer)\n  key = checkKey(key)\n  return sign('v1.public.', m, f, 'sha384', { key, padding, saltLength }, 256)\n}\n", "const { PasetoClaimInvalid } = require('../errors')\nconst ms = require('./ms')\n\nmodule.exports = ({\n  ignoreExp, ignoreNbf, ignoreIat, maxTokenAge, subject, issuer, clockTolerance, audience, now = new Date()\n}, payload) => {\n  if (!(now instanceof Date) || !now.getTime()) {\n    throw new TypeError('options.now must be a valid Date object')\n  }\n\n  const unix = now.getTime()\n\n  // iss\n  if ('iss' in payload && typeof payload.iss !== 'string') {\n    throw new PasetoClaimInvalid('payload.iss must be a string')\n  }\n\n  if (issuer !== undefined) {\n    if (typeof issuer !== 'string') {\n      throw new TypeError('options.issuer must be a string')\n    }\n\n    if (payload.iss !== issuer) {\n      throw new PasetoClaimInvalid('issuer mismatch')\n    }\n  }\n\n  // sub\n  if ('sub' in payload && typeof payload.sub !== 'string') {\n    throw new PasetoClaimInvalid('payload.sub must be a string')\n  }\n\n  if (subject !== undefined) {\n    if (typeof subject !== 'string') {\n      throw new TypeError('options.subject must be a string')\n    }\n\n    if (payload.sub !== subject) {\n      throw new PasetoClaimInvalid('subject mismatch')\n    }\n  }\n\n  // aud\n  if ('aud' in payload && typeof payload.aud !== 'string') {\n    throw new PasetoClaimInvalid('payload.aud must be a string')\n  }\n\n  if (audience !== undefined) {\n    if (typeof audience !== 'string') {\n      throw new TypeError('options.audience must be a string')\n    }\n\n    if (payload.aud !== audience) {\n      throw new PasetoClaimInvalid('audience mismatch')\n    }\n  }\n\n  if (clockTolerance !== undefined && typeof clockTolerance !== 'string') {\n    throw new TypeError('options.clockTolerance must be a string')\n  }\n\n  const tolerance = clockTolerance ? ms(clockTolerance) : 0\n\n  // iat\n  let iat\n  if ('iat' in payload) {\n    if (typeof payload.iat !== 'string') {\n      throw new PasetoClaimInvalid('payload.iat must be a string')\n    }\n    iat = new Date(payload.iat).getTime()\n    if (!iat) {\n      throw new PasetoClaimInvalid('payload.iat must be a valid ISO8601 string')\n    }\n    if (!ignoreIat) {\n      if (iat > unix + tolerance) {\n        throw new PasetoClaimInvalid('token issued in the future')\n      }\n    }\n  }\n\n  // nbf\n  if ('nbf' in payload) {\n    if (typeof payload.nbf !== 'string') {\n      throw new PasetoClaimInvalid('payload.nbf must be a string')\n    }\n    const nbf = new Date(payload.nbf).getTime()\n    if (!nbf) {\n      throw new PasetoClaimInvalid('payload.nbf must be a valid ISO8601 string')\n    }\n    if (!ignoreNbf) {\n      if (nbf > unix + tolerance) {\n        throw new PasetoClaimInvalid('token is not active yet')\n      }\n    }\n  }\n\n  // exp\n  if ('exp' in payload) {\n    if (typeof payload.exp !== 'string') {\n      throw new PasetoClaimInvalid('payload.exp must be a string')\n    }\n    const exp = new Date(payload.exp).getTime()\n    if (!exp) {\n      throw new PasetoClaimInvalid('payload.exp must be a valid ISO8601 string')\n    }\n    if (!ignoreExp) {\n      if (exp <= unix - tolerance) {\n        throw new PasetoClaimInvalid('token is expired')\n      }\n    }\n  }\n\n  // maxTokenAge\n  if (maxTokenAge !== undefined) {\n    if (typeof maxTokenAge !== 'string') {\n      throw new TypeError('options.maxTokenAge must be a string')\n    }\n\n    if (!('iat' in payload)) {\n      throw new PasetoClaimInvalid('missing iat claim')\n    }\n\n    if (iat + ms(maxTokenAge) < unix + tolerance) {\n      throw new PasetoClaimInvalid('maxTokenAge exceeded')\n    }\n  }\n}\n", "const { PasetoInvalid } = require('../errors')\n\nconst { strict: assert } = require('assert')\nconst isObject = require('./is_object')\n\nmodule.exports = (payload) => {\n  try {\n    const parsed = JSON.parse(payload)\n    assert(isObject(parsed))\n    return parsed\n  } catch (err) {\n    throw new PasetoInvalid('All PASETO payloads MUST be a JSON object')\n  }\n}\n", "const { PasetoInvalid, PasetoVerificationFailed } = require('../errors')\n\nconst { decode } = require('./base64url')\nconst { verify } = require('./crypto_worker')\nconst pae = require('./pae')\n\nmodule.exports = async function verifyPaseto (h, token, alg, sigLength, key) {\n  if (typeof token !== 'string') {\n    throw new TypeError('token must be a string')\n  }\n\n  if (token.substr(0, h.length) !== h) {\n    throw new PasetoInvalid(`token is not a ${h.slice(0, -1)} token`)\n  }\n\n  const { 0: b64ms, 1: b64f, length } = token.substr(h.length).split('.')\n  if (length !== 1 && length !== 2) {\n    throw new PasetoInvalid('token value is not a PASETO formatted value')\n  }\n\n  let f\n  let ms\n\n  try {\n    ms = decode(b64ms)\n    f = decode(b64f || '')\n  } catch (err) {\n    throw new PasetoInvalid('token value is not a PASETO formatted value')\n  }\n\n  const m = ms.slice(0, -sigLength)\n  const s = ms.slice(-sigLength)\n  const m2 = pae(h, m, f)\n\n  const valid = await verify(alg, m2, key, s)\n\n  if (!valid) {\n    throw new PasetoVerificationFailed('invalid signature')\n  }\n\n  return {\n    m,\n    footer: f.length ? f : undefined\n  }\n}\n", "const {\n  constants: {\n    RSA_PKCS1_PSS_PADDING: padding,\n    RSA_PSS_SALTLEN_DIGEST: saltLength\n  },\n  createPublicKey,\n  KeyObject\n} = require('crypto')\n\nconst assertPayload = require('../help/assert_payload')\nconst parse = require('../help/parse_paseto_payload')\nconst verify = require('../help/verify')\n\nfunction checkKey (key) {\n  if (!(key instanceof KeyObject) || key.type === 'private') {\n    key = createPublicKey(key)\n  }\n\n  if (key.type !== 'public' || key.asymmetricKeyType !== 'rsa') {\n    throw new TypeError('v1.public verify key must be a public RSA key')\n  }\n\n  return key\n}\n\nmodule.exports = async function v1Verify (token, key, { complete = false, buffer = false, ...options } = {}) {\n  key = checkKey(key)\n\n  const { m, footer } = await verify('v1.public.', token, 'sha384', 256, { key, padding, saltLength })\n\n  if (buffer) {\n    if (complete) {\n      return { payload: m, footer, version: 'v2', purpose: 'public' }\n    }\n\n    return m\n  }\n\n  const payload = parse(m)\n  assertPayload(options, payload)\n\n  if (complete) {\n    return { payload, footer, version: 'v1', purpose: 'public' }\n  }\n\n  return payload\n}\n", "const { createSecretKey, KeyObject } = require('crypto')\n\nmodule.exports = function checkKey (header, key) {\n  if (!(key instanceof KeyObject)) {\n    key = createSecretKey(key)\n  }\n\n  if (key.type !== 'secret' || key.symmetricKeySize !== 32) {\n    throw new TypeError(`${header} secret key must be 32 bytes long symmetric key`)\n  }\n\n  return key\n}\n", "const crypto = require('crypto')\nconst { promisify } = require('util')\n\nconst randomFill = promisify(crypto.randomFill)\n\nmodule.exports = async function randomBytes (bytes) {\n  const buf = Buffer.allocUnsafe(bytes)\n  return randomFill(buf)\n}\n", "const checkFooter = require('../help/check_footer')\nconst checkKey = require('../help/symmetric_key_check').bind(undefined, 'v1.local')\nconst checkPayload = require('../help/check_payload')\nconst randomBytes = require('../help/random_bytes')\nconst { 'aes-256-ctr-hmac-sha-384-encrypt': encrypt } = require('../help/crypto_worker')\n\nmodule.exports = async function v1Encrypt (payload, key, { footer, nonce, ...options } = {}) {\n  const m = checkPayload(payload, options)\n  key = checkKey(key)\n  const f = checkFooter(footer)\n\n  const k = key.export()\n\n  if ((nonce && process.env.NODE_ENV !== 'test') || !nonce) {\n    nonce = await randomBytes(32)\n  }\n\n  return encrypt(m, f, k, nonce)\n}\n", "const { decode } = require('../help/base64url')\nconst { 'aes-256-ctr-hmac-sha-384-decrypt': decrypt } = require('../help/crypto_worker')\nconst { PasetoDecryptionFailed, PasetoInvalid } = require('../errors')\nconst assertPayload = require('../help/assert_payload')\nconst checkKey = require('../help/symmetric_key_check').bind(undefined, 'v1.local')\nconst parse = require('../help/parse_paseto_payload')\n\nconst h = 'v1.local.'\n\nmodule.exports = async function v1Decrypt (token, key, { complete = false, buffer = false, ...options } = {}) {\n  if (typeof token !== 'string') {\n    throw new TypeError(`token must be a string, got: ${typeof token}`)\n  }\n\n  key = checkKey(key)\n\n  if (token.substr(0, h.length) !== h) {\n    throw new PasetoInvalid('token is not a v1.local PASETO')\n  }\n\n  const { 0: b64, 1: b64f = '', length } = token.substr(h.length).split('.')\n  if (length > 2) {\n    throw new PasetoInvalid('token value is not a PASETO formatted value')\n  }\n\n  const f = decode(b64f)\n  const raw = decode(b64)\n  const k = key.export()\n\n  const m = await decrypt(raw, f, k)\n  if (!m) {\n    throw new PasetoDecryptionFailed('decryption failed')\n  }\n\n  if (buffer) {\n    if (Object.keys(options).length !== 0) {\n      throw new TypeError('options cannot contain claims when options.buffer is true')\n    }\n    if (complete) {\n      return { payload: m, footer: f.length ? f : undefined, version: 'v2', purpose: 'local' }\n    }\n\n    return m\n  }\n\n  const payload = parse(m)\n\n  assertPayload(options, payload)\n\n  if (complete) {\n    return { payload, footer: f.length ? f : undefined, version: 'v1', purpose: 'local' }\n  }\n\n  return payload\n}\n", "const crypto = require('crypto')\nconst { promisify } = require('util')\n\nconst { PasetoNotSupported } = require('../errors')\nconst randomBytes = require('../help/random_bytes')\n\nconst generateKeyPair = promisify(crypto.generateKeyPair)\n\nconst LOCAL_KEY_LENGTH = 32\nconst PUBLIC_KEY_ARGS = ['rsa', { modulusLength: 2048 }]\n\nasync function generateKey (purpose) {\n  switch (purpose) {\n    case 'local':\n      return crypto.createSecretKey(await randomBytes(LOCAL_KEY_LENGTH))\n    case 'public': {\n      const { privateKey } = await generateKeyPair(...PUBLIC_KEY_ARGS)\n      return privateKey\n    }\n    default:\n      throw new PasetoNotSupported('unsupported v1 purpose')\n  }\n}\n\nmodule.exports = generateKey\n", "const sign = require('./sign')\nconst verify = require('./verify')\nconst encrypt = require('./encrypt')\nconst decrypt = require('./decrypt')\nconst generateKey = require('./key')\n\nmodule.exports = { sign, verify, encrypt, decrypt, generateKey }\n", "const {\n  createPrivateKey,\n  KeyObject\n} = require('crypto')\n\nconst checkFooter = require('../help/check_footer')\nconst checkPayload = require('../help/check_payload')\nconst sign = require('../help/sign')\n\nfunction checkKey (key) {\n  if (!(key instanceof KeyObject)) {\n    key = createPrivateKey(key)\n  }\n\n  if (key.type !== 'private' || key.asymmetricKeyType !== 'ed25519') {\n    throw new TypeError('v2.public signing key must be a private ed25519 key')\n  }\n\n  return key\n}\n\nmodule.exports = async function v2Sign (payload, key, { footer, ...options } = {}) {\n  const m = checkPayload(payload, options)\n  key = checkKey(key)\n  const f = checkFooter(footer)\n  return sign('v2.public.', m, f, undefined, key, 64)\n}\n", "const {\n  createPublicKey,\n  KeyObject\n} = require('crypto')\n\nconst assertPayload = require('../help/assert_payload')\nconst parse = require('../help/parse_paseto_payload')\nconst verify = require('../help/verify')\n\nfunction checkKey (key) {\n  if (!(key instanceof KeyObject) || key.type === 'private') {\n    key = createPublicKey(key)\n  }\n\n  if (key.type !== 'public' || key.asymmetricKeyType !== 'ed25519') {\n    throw new TypeError('v2.public verify key must be a public ed25519 key')\n  }\n\n  return key\n}\n\nmodule.exports = async function v2Verify (token, key, { complete = false, buffer = false, ...options } = {}) {\n  key = checkKey(key)\n\n  const { m, footer } = await verify('v2.public.', token, undefined, 64, key)\n\n  if (buffer) {\n    if (complete) {\n      return { payload: m, footer, version: 'v2', purpose: 'public' }\n    }\n\n    return m\n  }\n\n  const payload = parse(m)\n  assertPayload(options, payload)\n\n  if (complete) {\n    return { payload, footer, version: 'v2', purpose: 'public' }\n  }\n\n  return payload\n}\n", "const crypto = require('crypto')\nconst { promisify } = require('util')\n\nconst { PasetoNotSupported } = require('../errors')\n\nconst generateKeyPair = promisify(crypto.generateKeyPair)\n\nasync function generateKey (purpose) {\n  switch (purpose) {\n    case 'public': {\n      const { privateKey } = await generateKeyPair('ed25519')\n      return privateKey\n    }\n    default:\n      throw new PasetoNotSupported('unsupported v2 purpose')\n  }\n}\n\nmodule.exports = generateKey\n", "const sign = require('./sign')\nconst verify = require('./verify')\nconst generateKey = require('./key')\n\nmodule.exports = { sign, verify, generateKey }\n", "const { PasetoInvalid, PasetoNotSupported } = require('../errors')\nconst { decode } = require('../help/base64url')\nconst parsePayload = require('../help/parse_paseto_payload')\n\nmodule.exports = (token, /* second arg is private API */{ parse = true } = {}) => {\n  if (typeof token !== 'string') {\n    throw new TypeError('token must be a string')\n  }\n\n  const {\n    0: version,\n    1: purpose,\n    2: payload,\n    3: footer,\n    length\n  } = token.split('.')\n\n  if (length !== 3 && length !== 4) {\n    throw new PasetoInvalid('token value is not a PASETO formatted value')\n  }\n\n  if (version !== 'v1' && version !== 'v2') {\n    throw new PasetoNotSupported('unsupported PASETO version')\n  }\n\n  if (purpose !== 'local' && purpose !== 'public') {\n    throw new PasetoNotSupported('unsupported PASETO purpose')\n  }\n\n  const result = { footer: footer ? decode(footer) : undefined, payload: undefined, version, purpose }\n\n  if (purpose === 'local') {\n    return result\n  }\n\n  const sigLength = version === 'v1' ? 256 : 64\n\n  let raw\n  try {\n    raw = decode(payload).slice(0, -sigLength)\n  } catch (err) {\n    throw new PasetoInvalid('token value is not a PASETO formatted value')\n  }\n\n  if (!parse) {\n    result.payload = raw\n  } else {\n    result.payload = parsePayload(raw)\n  }\n\n  return result\n}\n", "const decode = require('./decode')\n\nmodule.exports = { decode }\n", "const errors = require('./errors')\nconst V1 = require('./v1')\nconst V2 = require('./v2')\n\nconst { decode } = require('./general')\n\nmodule.exports = { decode, V1, V2, errors }\n", "/** Console logging verbosity for the SDK. */\nexport enum LogLevel {\n  /** No logs will be generated. */\n  None = 0,\n  /** Only SDK internal errors will be logged. */\n  Error = 1,\n  /** Information useful for debugging the SDK will be logged. */\n  Debug = 2,\n  /** All SDK actions will be logged. */\n  Verbose = 3,\n}\n", "import { User } from './user';\n\n/**\n * @inheritdoc\n */\nexport interface Session extends SessionContext {\n  /** JSDoc */\n  update(context?: SessionContext): void;\n\n  /** JSDoc */\n  close(status?: SessionStatus): void;\n\n  /** JSDoc */\n  toJSON(): {\n    init: boolean;\n    sid: string;\n    did?: string;\n    timestamp: string;\n    started: string;\n    duration: number;\n    status: SessionStatus;\n    errors: number;\n    attrs?: {\n      release?: string;\n      environment?: string;\n      user_agent?: string;\n      ip_address?: string;\n    };\n  };\n}\n\n/**\n * Session Context\n */\nexport interface SessionContext {\n  sid?: string;\n  did?: string;\n  init?: boolean;\n  timestamp?: number;\n  started?: number;\n  duration?: number;\n  status?: SessionStatus;\n  release?: string;\n  environment?: string;\n  userAgent?: string;\n  ipAddress?: string;\n  errors?: number;\n  user?: User | null;\n}\n\n/**\n * Session Status\n */\nexport enum SessionStatus {\n  /** JSDoc */\n  Ok = 'ok',\n  /** JSDoc */\n  Exited = 'exited',\n  /** JSDoc */\n  Crashed = 'crashed',\n  /** JSDoc */\n  Abnormal = 'abnormal',\n}\n", "/** JSDoc */\n// eslint-disable-next-line import/export\nexport enum Severity {\n  /** JSDoc */\n  Fatal = 'fatal',\n  /** JSDoc */\n  Error = 'error',\n  /** JSDoc */\n  Warning = 'warning',\n  /** JSDoc */\n  Log = 'log',\n  /** JSDoc */\n  Info = 'info',\n  /** JSDoc */\n  Debug = 'debug',\n  /** JSDoc */\n  Critical = 'critical',\n}\n\n// eslint-disable-next-line @typescript-eslint/no-namespace, import/export\nexport namespace Severity {\n  /**\n   * Converts a string-based level into a {@link Severity}.\n   *\n   * @param level string representation of Severity\n   * @returns Severity\n   */\n  export function fromString(level: string): Severity {\n    switch (level) {\n      case 'debug':\n        return Severity.Debug;\n      case 'info':\n        return Severity.Info;\n      case 'warn':\n      case 'warning':\n        return Severity.Warning;\n      case 'error':\n        return Severity.Error;\n      case 'fatal':\n        return Severity.Fatal;\n      case 'critical':\n        return Severity.Critical;\n      case 'log':\n      default:\n        return Severity.Log;\n    }\n  }\n}\n", "/** The status of an event. */\n// eslint-disable-next-line import/export\nexport enum Status {\n  /** The status could not be determined. */\n  Unknown = 'unknown',\n  /** The event was skipped due to configuration or callbacks. */\n  Skipped = 'skipped',\n  /** The event was sent to Sentry successfully. */\n  Success = 'success',\n  /** The client is currently rate limited and will try again later. */\n  RateLimit = 'rate_limit',\n  /** The event could not be processed. */\n  Invalid = 'invalid',\n  /** A server-side error ocurred during submission. */\n  Failed = 'failed',\n}\n\n// eslint-disable-next-line @typescript-eslint/no-namespace, import/export\nexport namespace Status {\n  /**\n   * Converts a HTTP status code into a {@link Status}.\n   *\n   * @param code The HTTP response status code.\n   * @returns The send status or {@link Status.Unknown}.\n   */\n  export function fromHttpCode(code: number): Status {\n    if (code >= 200 && code < 300) {\n      return Status.Success;\n    }\n\n    if (code === 429) {\n      return Status.RateLimit;\n    }\n\n    if (code >= 400 && code < 500) {\n      return Status.Invalid;\n    }\n\n    if (code >= 500) {\n      return Status.Failed;\n    }\n\n    return Status.Unknown;\n  }\n}\n", "import { ExtractedNodeRequestData, Primitive, WorkerLocation } from './misc';\nimport { Span, SpanContext } from './span';\n\n/**\n * Interface holding Transaction-specific properties\n */\nexport interface TransactionContext extends SpanContext {\n  /**\n   * Human-readable identifier for the transaction\n   */\n  name: string;\n\n  /**\n   * If true, sets the end timestamp of the transaction to the highest timestamp of child spans, trimming\n   * the duration of the transaction. This is useful to discard extra time in the transaction that is not\n   * accounted for in child spans, like what happens in the idle transaction Tracing integration, where we finish the\n   * transaction after a given \"idle time\" and we don't want this \"idle time\" to be part of the transaction.\n   */\n  trimEnd?: boolean;\n\n  /**\n   * If this transaction has a parent, the parent's sampling decision\n   */\n  parentSampled?: boolean;\n}\n\n/**\n * Data pulled from a `sentry-trace` header\n */\nexport type TraceparentData = Pick<TransactionContext, 'traceId' | 'parentSpanId' | 'parentSampled'>;\n\n/**\n * Transaction \"Class\", inherits Span only has `setName`\n */\nexport interface Transaction extends TransactionContext, Span {\n  /**\n   * @inheritDoc\n   */\n  spanId: string;\n\n  /**\n   * @inheritDoc\n   */\n  traceId: string;\n\n  /**\n   * @inheritDoc\n   */\n  startTimestamp: number;\n\n  /**\n   * @inheritDoc\n   */\n  tags: { [key: string]: Primitive };\n\n  /**\n   * @inheritDoc\n   */\n  data: { [key: string]: any };\n\n  /**\n   * Set the name of the transaction\n   */\n  setName(name: string): void;\n\n  /** Returns the current transaction properties as a `TransactionContext` */\n  toContext(): TransactionContext;\n\n  /** Updates the current transaction with a new `TransactionContext` */\n  updateWithContext(transactionContext: TransactionContext): this;\n}\n\n/**\n * Context data passed by the user when starting a transaction, to be used by the tracesSampler method.\n */\nexport interface CustomSamplingContext {\n  [key: string]: any;\n}\n\n/**\n * Data passed to the `tracesSampler` function, which forms the basis for whatever decisions it might make.\n *\n * Adds default data to data provided by the user. See {@link Hub.startTransaction}\n */\nexport interface SamplingContext extends CustomSamplingContext {\n  /**\n   * Context data with which transaction being sampled was created\n   */\n  transactionContext: TransactionContext;\n\n  /**\n   * Sampling decision from the parent transaction, if any.\n   */\n  parentSampled?: boolean;\n\n  /**\n   * Object representing the URL of the current page or worker script. Passed by default when using the `BrowserTracing`\n   * integration.\n   */\n  location?: WorkerLocation;\n\n  /**\n   * Object representing the incoming request to a node server. Passed by default when using the TracingHandler.\n   */\n  request?: ExtractedNodeRequestData;\n}\n\nexport type Measurements = Record<string, { value: number }>;\n\nexport enum TransactionSamplingMethod {\n  Explicit = 'explicitly_set',\n  Sampler = 'client_sampler',\n  Rate = 'client_rate',\n  Inheritance = 'inheritance',\n}\n", "export { Breadcrumb, BreadcrumbHint } from './breadcrumb';\nexport { Client } from './client';\nexport { Context, Contexts } from './context';\nexport { Dsn, DsnComponents, DsnLike, DsnProtocol } from './dsn';\nexport { DebugImage, DebugImageType, DebugMeta } from './debugMeta';\nexport { ExtendedError } from './error';\nexport { Event, EventHint } from './event';\nexport { EventProcessor } from './eventprocessor';\nexport { Exception } from './exception';\nexport { Extra, Extras } from './extra';\nexport { Hub } from './hub';\nexport { Integration, IntegrationClass } from './integration';\nexport { LogLevel } from './loglevel';\nexport { Mechanism } from './mechanism';\nexport { ExtractedNodeRequestData, Primitive, WorkerLocation } from './misc';\nexport { Options } from './options';\nexport { Package } from './package';\nexport { Request, SentryRequest, SentryRequestType } from './request';\nexport { Response } from './response';\nexport { Runtime } from './runtime';\nexport { CaptureContext, Scope, ScopeContext } from './scope';\nexport { SdkInfo } from './sdkinfo';\nexport { SdkMetadata } from './sdkmetadata';\nexport { Session, SessionContext, SessionStatus } from './session';\nexport { Severity } from './severity';\nexport { Span, SpanContext } from './span';\nexport { StackFrame } from './stackframe';\nexport { Stacktrace } from './stacktrace';\nexport { Status } from './status';\nexport {\n  CustomSamplingContext,\n  Measurements,\n  SamplingContext,\n  TraceparentData,\n  Transaction,\n  TransactionContext,\n  TransactionSamplingMethod,\n} from './transaction';\nexport { Thread } from './thread';\nexport { Transport, TransportOptions, TransportClass } from './transport';\nexport { User } from './user';\nexport { WrappedFunction } from './wrappedfunction';\n", "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar intToCharMap = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'.split('');\n\n/**\n * Encode an integer in the range of 0 to 63 to a single base 64 digit.\n */\nexports.encode = function (number) {\n  if (0 <= number && number < intToCharMap.length) {\n    return intToCharMap[number];\n  }\n  throw new TypeError(\"Must be between 0 and 63: \" + number);\n};\n\n/**\n * Decode a single base 64 character code digit to an integer. Returns -1 on\n * failure.\n */\nexports.decode = function (charCode) {\n  var bigA = 65;     // 'A'\n  var bigZ = 90;     // 'Z'\n\n  var littleA = 97;  // 'a'\n  var littleZ = 122; // 'z'\n\n  var zero = 48;     // '0'\n  var nine = 57;     // '9'\n\n  var plus = 43;     // '+'\n  var slash = 47;    // '/'\n\n  var littleOffset = 26;\n  var numberOffset = 52;\n\n  // 0 - 25: ABCDEFGHIJKLMNOPQRSTUVWXYZ\n  if (bigA <= charCode && charCode <= bigZ) {\n    return (charCode - bigA);\n  }\n\n  // 26 - 51: abcdefghijklmnopqrstuvwxyz\n  if (littleA <= charCode && charCode <= littleZ) {\n    return (charCode - littleA + littleOffset);\n  }\n\n  // 52 - 61: 0123456789\n  if (zero <= charCode && charCode <= nine) {\n    return (charCode - zero + numberOffset);\n  }\n\n  // 62: +\n  if (charCode == plus) {\n    return 62;\n  }\n\n  // 63: /\n  if (charCode == slash) {\n    return 63;\n  }\n\n  // Invalid base64 digit.\n  return -1;\n};\n", "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n *\n * Based on the Base 64 VLQ implementation in Closure Compiler:\n * https://code.google.com/p/closure-compiler/source/browse/trunk/src/com/google/debugging/sourcemap/Base64VLQ.java\n *\n * Copyright 2011 The Closure Compiler Authors. All rights reserved.\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are\n * met:\n *\n *  * Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n *  * Redistributions in binary form must reproduce the above\n *    copyright notice, this list of conditions and the following\n *    disclaimer in the documentation and/or other materials provided\n *    with the distribution.\n *  * Neither the name of Google Inc. nor the names of its\n *    contributors may be used to endorse or promote products derived\n *    from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\nvar base64 = require('./base64');\n\n// A single base 64 digit can contain 6 bits of data. For the base 64 variable\n// length quantities we use in the source map spec, the first bit is the sign,\n// the next four bits are the actual value, and the 6th bit is the\n// continuation bit. The continuation bit tells us whether there are more\n// digits in this value following this digit.\n//\n//   Continuation\n//   |    Sign\n//   |    |\n//   V    V\n//   101011\n\nvar VLQ_BASE_SHIFT = 5;\n\n// binary: 100000\nvar VLQ_BASE = 1 << VLQ_BASE_SHIFT;\n\n// binary: 011111\nvar VLQ_BASE_MASK = VLQ_BASE - 1;\n\n// binary: 100000\nvar VLQ_CONTINUATION_BIT = VLQ_BASE;\n\n/**\n * Converts from a two-complement value to a value where the sign bit is\n * placed in the least significant bit.  For example, as decimals:\n *   1 becomes 2 (10 binary), -1 becomes 3 (11 binary)\n *   2 becomes 4 (100 binary), -2 becomes 5 (101 binary)\n */\nfunction toVLQSigned(aValue) {\n  return aValue < 0\n    ? ((-aValue) << 1) + 1\n    : (aValue << 1) + 0;\n}\n\n/**\n * Converts to a two-complement value from a value where the sign bit is\n * placed in the least significant bit.  For example, as decimals:\n *   2 (10 binary) becomes 1, 3 (11 binary) becomes -1\n *   4 (100 binary) becomes 2, 5 (101 binary) becomes -2\n */\nfunction fromVLQSigned(aValue) {\n  var isNegative = (aValue & 1) === 1;\n  var shifted = aValue >> 1;\n  return isNegative\n    ? -shifted\n    : shifted;\n}\n\n/**\n * Returns the base 64 VLQ encoded value.\n */\nexports.encode = function base64VLQ_encode(aValue) {\n  var encoded = \"\";\n  var digit;\n\n  var vlq = toVLQSigned(aValue);\n\n  do {\n    digit = vlq & VLQ_BASE_MASK;\n    vlq >>>= VLQ_BASE_SHIFT;\n    if (vlq > 0) {\n      // There are still more digits in this value, so we must make sure the\n      // continuation bit is marked.\n      digit |= VLQ_CONTINUATION_BIT;\n    }\n    encoded += base64.encode(digit);\n  } while (vlq > 0);\n\n  return encoded;\n};\n\n/**\n * Decodes the next base 64 VLQ value from the given string and returns the\n * value and the rest of the string via the out parameter.\n */\nexports.decode = function base64VLQ_decode(aStr, aIndex, aOutParam) {\n  var strLen = aStr.length;\n  var result = 0;\n  var shift = 0;\n  var continuation, digit;\n\n  do {\n    if (aIndex >= strLen) {\n      throw new Error(\"Expected more digits in base 64 VLQ value.\");\n    }\n\n    digit = base64.decode(aStr.charCodeAt(aIndex++));\n    if (digit === -1) {\n      throw new Error(\"Invalid base64 digit: \" + aStr.charAt(aIndex - 1));\n    }\n\n    continuation = !!(digit & VLQ_CONTINUATION_BIT);\n    digit &= VLQ_BASE_MASK;\n    result = result + (digit << shift);\n    shift += VLQ_BASE_SHIFT;\n  } while (continuation);\n\n  aOutParam.value = fromVLQSigned(result);\n  aOutParam.rest = aIndex;\n};\n", "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\n/**\n * This is a helper function for getting values from parameter/options\n * objects.\n *\n * @param args The object we are extracting values from\n * @param name The name of the property we are getting.\n * @param defaultValue An optional value to return if the property is missing\n * from the object. If this is not specified and the property is missing, an\n * error will be thrown.\n */\nfunction getArg(aArgs, aName, aDefaultValue) {\n  if (aName in aArgs) {\n    return aArgs[aName];\n  } else if (arguments.length === 3) {\n    return aDefaultValue;\n  } else {\n    throw new Error('\"' + aName + '\" is a required argument.');\n  }\n}\nexports.getArg = getArg;\n\nvar urlRegexp = /^(?:([\\w+\\-.]+):)?\\/\\/(?:(\\w+:\\w+)@)?([\\w.-]*)(?::(\\d+))?(.*)$/;\nvar dataUrlRegexp = /^data:.+\\,.+$/;\n\nfunction urlParse(aUrl) {\n  var match = aUrl.match(urlRegexp);\n  if (!match) {\n    return null;\n  }\n  return {\n    scheme: match[1],\n    auth: match[2],\n    host: match[3],\n    port: match[4],\n    path: match[5]\n  };\n}\nexports.urlParse = urlParse;\n\nfunction urlGenerate(aParsedUrl) {\n  var url = '';\n  if (aParsedUrl.scheme) {\n    url += aParsedUrl.scheme + ':';\n  }\n  url += '//';\n  if (aParsedUrl.auth) {\n    url += aParsedUrl.auth + '@';\n  }\n  if (aParsedUrl.host) {\n    url += aParsedUrl.host;\n  }\n  if (aParsedUrl.port) {\n    url += \":\" + aParsedUrl.port\n  }\n  if (aParsedUrl.path) {\n    url += aParsedUrl.path;\n  }\n  return url;\n}\nexports.urlGenerate = urlGenerate;\n\n/**\n * Normalizes a path, or the path portion of a URL:\n *\n * - Replaces consecutive slashes with one slash.\n * - Removes unnecessary '.' parts.\n * - Removes unnecessary '<dir>/..' parts.\n *\n * Based on code in the Node.js 'path' core module.\n *\n * @param aPath The path or url to normalize.\n */\nfunction normalize(aPath) {\n  var path = aPath;\n  var url = urlParse(aPath);\n  if (url) {\n    if (!url.path) {\n      return aPath;\n    }\n    path = url.path;\n  }\n  var isAbsolute = exports.isAbsolute(path);\n\n  var parts = path.split(/\\/+/);\n  for (var part, up = 0, i = parts.length - 1; i >= 0; i--) {\n    part = parts[i];\n    if (part === '.') {\n      parts.splice(i, 1);\n    } else if (part === '..') {\n      up++;\n    } else if (up > 0) {\n      if (part === '') {\n        // The first part is blank if the path is absolute. Trying to go\n        // above the root is a no-op. Therefore we can remove all '..' parts\n        // directly after the root.\n        parts.splice(i + 1, up);\n        up = 0;\n      } else {\n        parts.splice(i, 2);\n        up--;\n      }\n    }\n  }\n  path = parts.join('/');\n\n  if (path === '') {\n    path = isAbsolute ? '/' : '.';\n  }\n\n  if (url) {\n    url.path = path;\n    return urlGenerate(url);\n  }\n  return path;\n}\nexports.normalize = normalize;\n\n/**\n * Joins two paths/URLs.\n *\n * @param aRoot The root path or URL.\n * @param aPath The path or URL to be joined with the root.\n *\n * - If aPath is a URL or a data URI, aPath is returned, unless aPath is a\n *   scheme-relative URL: Then the scheme of aRoot, if any, is prepended\n *   first.\n * - Otherwise aPath is a path. If aRoot is a URL, then its path portion\n *   is updated with the result and aRoot is returned. Otherwise the result\n *   is returned.\n *   - If aPath is absolute, the result is aPath.\n *   - Otherwise the two paths are joined with a slash.\n * - Joining for example 'http://' and 'www.example.com' is also supported.\n */\nfunction join(aRoot, aPath) {\n  if (aRoot === \"\") {\n    aRoot = \".\";\n  }\n  if (aPath === \"\") {\n    aPath = \".\";\n  }\n  var aPathUrl = urlParse(aPath);\n  var aRootUrl = urlParse(aRoot);\n  if (aRootUrl) {\n    aRoot = aRootUrl.path || '/';\n  }\n\n  // `join(foo, '//www.example.org')`\n  if (aPathUrl && !aPathUrl.scheme) {\n    if (aRootUrl) {\n      aPathUrl.scheme = aRootUrl.scheme;\n    }\n    return urlGenerate(aPathUrl);\n  }\n\n  if (aPathUrl || aPath.match(dataUrlRegexp)) {\n    return aPath;\n  }\n\n  // `join('http://', 'www.example.com')`\n  if (aRootUrl && !aRootUrl.host && !aRootUrl.path) {\n    aRootUrl.host = aPath;\n    return urlGenerate(aRootUrl);\n  }\n\n  var joined = aPath.charAt(0) === '/'\n    ? aPath\n    : normalize(aRoot.replace(/\\/+$/, '') + '/' + aPath);\n\n  if (aRootUrl) {\n    aRootUrl.path = joined;\n    return urlGenerate(aRootUrl);\n  }\n  return joined;\n}\nexports.join = join;\n\nexports.isAbsolute = function (aPath) {\n  return aPath.charAt(0) === '/' || urlRegexp.test(aPath);\n};\n\n/**\n * Make a path relative to a URL or another path.\n *\n * @param aRoot The root path or URL.\n * @param aPath The path or URL to be made relative to aRoot.\n */\nfunction relative(aRoot, aPath) {\n  if (aRoot === \"\") {\n    aRoot = \".\";\n  }\n\n  aRoot = aRoot.replace(/\\/$/, '');\n\n  // It is possible for the path to be above the root. In this case, simply\n  // checking whether the root is a prefix of the path won't work. Instead, we\n  // need to remove components from the root one by one, until either we find\n  // a prefix that fits, or we run out of components to remove.\n  var level = 0;\n  while (aPath.indexOf(aRoot + '/') !== 0) {\n    var index = aRoot.lastIndexOf(\"/\");\n    if (index < 0) {\n      return aPath;\n    }\n\n    // If the only part of the root that is left is the scheme (i.e. http://,\n    // file:///, etc.), one or more slashes (/), or simply nothing at all, we\n    // have exhausted all components, so the path is not relative to the root.\n    aRoot = aRoot.slice(0, index);\n    if (aRoot.match(/^([^\\/]+:\\/)?\\/*$/)) {\n      return aPath;\n    }\n\n    ++level;\n  }\n\n  // Make sure we add a \"../\" for each component we removed from the root.\n  return Array(level + 1).join(\"../\") + aPath.substr(aRoot.length + 1);\n}\nexports.relative = relative;\n\nvar supportsNullProto = (function () {\n  var obj = Object.create(null);\n  return !('__proto__' in obj);\n}());\n\nfunction identity (s) {\n  return s;\n}\n\n/**\n * Because behavior goes wacky when you set `__proto__` on objects, we\n * have to prefix all the strings in our set with an arbitrary character.\n *\n * See https://github.com/mozilla/source-map/pull/31 and\n * https://github.com/mozilla/source-map/issues/30\n *\n * @param String aStr\n */\nfunction toSetString(aStr) {\n  if (isProtoString(aStr)) {\n    return '$' + aStr;\n  }\n\n  return aStr;\n}\nexports.toSetString = supportsNullProto ? identity : toSetString;\n\nfunction fromSetString(aStr) {\n  if (isProtoString(aStr)) {\n    return aStr.slice(1);\n  }\n\n  return aStr;\n}\nexports.fromSetString = supportsNullProto ? identity : fromSetString;\n\nfunction isProtoString(s) {\n  if (!s) {\n    return false;\n  }\n\n  var length = s.length;\n\n  if (length < 9 /* \"__proto__\".length */) {\n    return false;\n  }\n\n  if (s.charCodeAt(length - 1) !== 95  /* '_' */ ||\n      s.charCodeAt(length - 2) !== 95  /* '_' */ ||\n      s.charCodeAt(length - 3) !== 111 /* 'o' */ ||\n      s.charCodeAt(length - 4) !== 116 /* 't' */ ||\n      s.charCodeAt(length - 5) !== 111 /* 'o' */ ||\n      s.charCodeAt(length - 6) !== 114 /* 'r' */ ||\n      s.charCodeAt(length - 7) !== 112 /* 'p' */ ||\n      s.charCodeAt(length - 8) !== 95  /* '_' */ ||\n      s.charCodeAt(length - 9) !== 95  /* '_' */) {\n    return false;\n  }\n\n  for (var i = length - 10; i >= 0; i--) {\n    if (s.charCodeAt(i) !== 36 /* '$' */) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\n/**\n * Comparator between two mappings where the original positions are compared.\n *\n * Optionally pass in `true` as `onlyCompareGenerated` to consider two\n * mappings with the same original source/line/column, but different generated\n * line and column the same. Useful when searching for a mapping with a\n * stubbed out mapping.\n */\nfunction compareByOriginalPositions(mappingA, mappingB, onlyCompareOriginal) {\n  var cmp = strcmp(mappingA.source, mappingB.source);\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalLine - mappingB.originalLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalColumn - mappingB.originalColumn;\n  if (cmp !== 0 || onlyCompareOriginal) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedColumn - mappingB.generatedColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedLine - mappingB.generatedLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  return strcmp(mappingA.name, mappingB.name);\n}\nexports.compareByOriginalPositions = compareByOriginalPositions;\n\n/**\n * Comparator between two mappings with deflated source and name indices where\n * the generated positions are compared.\n *\n * Optionally pass in `true` as `onlyCompareGenerated` to consider two\n * mappings with the same generated line and column, but different\n * source/name/original line and column the same. Useful when searching for a\n * mapping with a stubbed out mapping.\n */\nfunction compareByGeneratedPositionsDeflated(mappingA, mappingB, onlyCompareGenerated) {\n  var cmp = mappingA.generatedLine - mappingB.generatedLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedColumn - mappingB.generatedColumn;\n  if (cmp !== 0 || onlyCompareGenerated) {\n    return cmp;\n  }\n\n  cmp = strcmp(mappingA.source, mappingB.source);\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalLine - mappingB.originalLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalColumn - mappingB.originalColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  return strcmp(mappingA.name, mappingB.name);\n}\nexports.compareByGeneratedPositionsDeflated = compareByGeneratedPositionsDeflated;\n\nfunction strcmp(aStr1, aStr2) {\n  if (aStr1 === aStr2) {\n    return 0;\n  }\n\n  if (aStr1 === null) {\n    return 1; // aStr2 !== null\n  }\n\n  if (aStr2 === null) {\n    return -1; // aStr1 !== null\n  }\n\n  if (aStr1 > aStr2) {\n    return 1;\n  }\n\n  return -1;\n}\n\n/**\n * Comparator between two mappings with inflated source and name strings where\n * the generated positions are compared.\n */\nfunction compareByGeneratedPositionsInflated(mappingA, mappingB) {\n  var cmp = mappingA.generatedLine - mappingB.generatedLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedColumn - mappingB.generatedColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = strcmp(mappingA.source, mappingB.source);\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalLine - mappingB.originalLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalColumn - mappingB.originalColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  return strcmp(mappingA.name, mappingB.name);\n}\nexports.compareByGeneratedPositionsInflated = compareByGeneratedPositionsInflated;\n\n/**\n * Strip any JSON XSSI avoidance prefix from the string (as documented\n * in the source maps specification), and then parse the string as\n * JSON.\n */\nfunction parseSourceMapInput(str) {\n  return JSON.parse(str.replace(/^\\)]}'[^\\n]*\\n/, ''));\n}\nexports.parseSourceMapInput = parseSourceMapInput;\n\n/**\n * Compute the URL of a source given the the source root, the source's\n * URL, and the source map's URL.\n */\nfunction computeSourceURL(sourceRoot, sourceURL, sourceMapURL) {\n  sourceURL = sourceURL || '';\n\n  if (sourceRoot) {\n    // This follows what Chrome does.\n    if (sourceRoot[sourceRoot.length - 1] !== '/' && sourceURL[0] !== '/') {\n      sourceRoot += '/';\n    }\n    // The spec says:\n    //   Line 4: An optional source root, useful for relocating source\n    //   files on a server or removing repeated values in the\n    //   \u201Csources\u201D entry.  This value is prepended to the individual\n    //   entries in the \u201Csource\u201D field.\n    sourceURL = sourceRoot + sourceURL;\n  }\n\n  // Historically, SourceMapConsumer did not take the sourceMapURL as\n  // a parameter.  This mode is still somewhat supported, which is why\n  // this code block is conditional.  However, it's preferable to pass\n  // the source map URL to SourceMapConsumer, so that this function\n  // can implement the source URL resolution algorithm as outlined in\n  // the spec.  This block is basically the equivalent of:\n  //    new URL(sourceURL, sourceMapURL).toString()\n  // ... except it avoids using URL, which wasn't available in the\n  // older releases of node still supported by this library.\n  //\n  // The spec says:\n  //   If the sources are not absolute URLs after prepending of the\n  //   \u201CsourceRoot\u201D, the sources are resolved relative to the\n  //   SourceMap (like resolving script src in a html document).\n  if (sourceMapURL) {\n    var parsed = urlParse(sourceMapURL);\n    if (!parsed) {\n      throw new Error(\"sourceMapURL could not be parsed\");\n    }\n    if (parsed.path) {\n      // Strip the last path component, but keep the \"/\".\n      var index = parsed.path.lastIndexOf('/');\n      if (index >= 0) {\n        parsed.path = parsed.path.substring(0, index + 1);\n      }\n    }\n    sourceURL = join(urlGenerate(parsed), sourceURL);\n  }\n\n  return normalize(sourceURL);\n}\nexports.computeSourceURL = computeSourceURL;\n", "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar util = require('./util');\nvar has = Object.prototype.hasOwnProperty;\nvar hasNativeMap = typeof Map !== \"undefined\";\n\n/**\n * A data structure which is a combination of an array and a set. Adding a new\n * member is O(1), testing for membership is O(1), and finding the index of an\n * element is O(1). Removing elements from the set is not supported. Only\n * strings are supported for membership.\n */\nfunction ArraySet() {\n  this._array = [];\n  this._set = hasNativeMap ? new Map() : Object.create(null);\n}\n\n/**\n * Static method for creating ArraySet instances from an existing array.\n */\nArraySet.fromArray = function ArraySet_fromArray(aArray, aAllowDuplicates) {\n  var set = new ArraySet();\n  for (var i = 0, len = aArray.length; i < len; i++) {\n    set.add(aArray[i], aAllowDuplicates);\n  }\n  return set;\n};\n\n/**\n * Return how many unique items are in this ArraySet. If duplicates have been\n * added, than those do not count towards the size.\n *\n * @returns Number\n */\nArraySet.prototype.size = function ArraySet_size() {\n  return hasNativeMap ? this._set.size : Object.getOwnPropertyNames(this._set).length;\n};\n\n/**\n * Add the given string to this set.\n *\n * @param String aStr\n */\nArraySet.prototype.add = function ArraySet_add(aStr, aAllowDuplicates) {\n  var sStr = hasNativeMap ? aStr : util.toSetString(aStr);\n  var isDuplicate = hasNativeMap ? this.has(aStr) : has.call(this._set, sStr);\n  var idx = this._array.length;\n  if (!isDuplicate || aAllowDuplicates) {\n    this._array.push(aStr);\n  }\n  if (!isDuplicate) {\n    if (hasNativeMap) {\n      this._set.set(aStr, idx);\n    } else {\n      this._set[sStr] = idx;\n    }\n  }\n};\n\n/**\n * Is the given string a member of this set?\n *\n * @param String aStr\n */\nArraySet.prototype.has = function ArraySet_has(aStr) {\n  if (hasNativeMap) {\n    return this._set.has(aStr);\n  } else {\n    var sStr = util.toSetString(aStr);\n    return has.call(this._set, sStr);\n  }\n};\n\n/**\n * What is the index of the given string in the array?\n *\n * @param String aStr\n */\nArraySet.prototype.indexOf = function ArraySet_indexOf(aStr) {\n  if (hasNativeMap) {\n    var idx = this._set.get(aStr);\n    if (idx >= 0) {\n        return idx;\n    }\n  } else {\n    var sStr = util.toSetString(aStr);\n    if (has.call(this._set, sStr)) {\n      return this._set[sStr];\n    }\n  }\n\n  throw new Error('\"' + aStr + '\" is not in the set.');\n};\n\n/**\n * What is the element at the given index?\n *\n * @param Number aIdx\n */\nArraySet.prototype.at = function ArraySet_at(aIdx) {\n  if (aIdx >= 0 && aIdx < this._array.length) {\n    return this._array[aIdx];\n  }\n  throw new Error('No element indexed by ' + aIdx);\n};\n\n/**\n * Returns the array representation of this set (which has the proper indices\n * indicated by indexOf). Note that this is a copy of the internal array used\n * for storing the members so that no one can mess with internal state.\n */\nArraySet.prototype.toArray = function ArraySet_toArray() {\n  return this._array.slice();\n};\n\nexports.ArraySet = ArraySet;\n", "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2014 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar util = require('./util');\n\n/**\n * Determine whether mappingB is after mappingA with respect to generated\n * position.\n */\nfunction generatedPositionAfter(mappingA, mappingB) {\n  // Optimized for most common case\n  var lineA = mappingA.generatedLine;\n  var lineB = mappingB.generatedLine;\n  var columnA = mappingA.generatedColumn;\n  var columnB = mappingB.generatedColumn;\n  return lineB > lineA || lineB == lineA && columnB >= columnA ||\n         util.compareByGeneratedPositionsInflated(mappingA, mappingB) <= 0;\n}\n\n/**\n * A data structure to provide a sorted view of accumulated mappings in a\n * performance conscious manner. It trades a neglibable overhead in general\n * case for a large speedup in case of mappings being added in order.\n */\nfunction MappingList() {\n  this._array = [];\n  this._sorted = true;\n  // Serves as infimum\n  this._last = {generatedLine: -1, generatedColumn: 0};\n}\n\n/**\n * Iterate through internal items. This method takes the same arguments that\n * `Array.prototype.forEach` takes.\n *\n * NOTE: The order of the mappings is NOT guaranteed.\n */\nMappingList.prototype.unsortedForEach =\n  function MappingList_forEach(aCallback, aThisArg) {\n    this._array.forEach(aCallback, aThisArg);\n  };\n\n/**\n * Add the given source mapping.\n *\n * @param Object aMapping\n */\nMappingList.prototype.add = function MappingList_add(aMapping) {\n  if (generatedPositionAfter(this._last, aMapping)) {\n    this._last = aMapping;\n    this._array.push(aMapping);\n  } else {\n    this._sorted = false;\n    this._array.push(aMapping);\n  }\n};\n\n/**\n * Returns the flat, sorted array of mappings. The mappings are sorted by\n * generated position.\n *\n * WARNING: This method returns internal data without copying, for\n * performance. The return value must NOT be mutated, and should be treated as\n * an immutable borrow. If you want to take ownership, you must make your own\n * copy.\n */\nMappingList.prototype.toArray = function MappingList_toArray() {\n  if (!this._sorted) {\n    this._array.sort(util.compareByGeneratedPositionsInflated);\n    this._sorted = true;\n  }\n  return this._array;\n};\n\nexports.MappingList = MappingList;\n", "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar base64VLQ = require('./base64-vlq');\nvar util = require('./util');\nvar ArraySet = require('./array-set').ArraySet;\nvar MappingList = require('./mapping-list').MappingList;\n\n/**\n * An instance of the SourceMapGenerator represents a source map which is\n * being built incrementally. You may pass an object with the following\n * properties:\n *\n *   - file: The filename of the generated source.\n *   - sourceRoot: A root for all relative URLs in this source map.\n */\nfunction SourceMapGenerator(aArgs) {\n  if (!aArgs) {\n    aArgs = {};\n  }\n  this._file = util.getArg(aArgs, 'file', null);\n  this._sourceRoot = util.getArg(aArgs, 'sourceRoot', null);\n  this._skipValidation = util.getArg(aArgs, 'skipValidation', false);\n  this._sources = new ArraySet();\n  this._names = new ArraySet();\n  this._mappings = new MappingList();\n  this._sourcesContents = null;\n}\n\nSourceMapGenerator.prototype._version = 3;\n\n/**\n * Creates a new SourceMapGenerator based on a SourceMapConsumer\n *\n * @param aSourceMapConsumer The SourceMap.\n */\nSourceMapGenerator.fromSourceMap =\n  function SourceMapGenerator_fromSourceMap(aSourceMapConsumer) {\n    var sourceRoot = aSourceMapConsumer.sourceRoot;\n    var generator = new SourceMapGenerator({\n      file: aSourceMapConsumer.file,\n      sourceRoot: sourceRoot\n    });\n    aSourceMapConsumer.eachMapping(function (mapping) {\n      var newMapping = {\n        generated: {\n          line: mapping.generatedLine,\n          column: mapping.generatedColumn\n        }\n      };\n\n      if (mapping.source != null) {\n        newMapping.source = mapping.source;\n        if (sourceRoot != null) {\n          newMapping.source = util.relative(sourceRoot, newMapping.source);\n        }\n\n        newMapping.original = {\n          line: mapping.originalLine,\n          column: mapping.originalColumn\n        };\n\n        if (mapping.name != null) {\n          newMapping.name = mapping.name;\n        }\n      }\n\n      generator.addMapping(newMapping);\n    });\n    aSourceMapConsumer.sources.forEach(function (sourceFile) {\n      var sourceRelative = sourceFile;\n      if (sourceRoot !== null) {\n        sourceRelative = util.relative(sourceRoot, sourceFile);\n      }\n\n      if (!generator._sources.has(sourceRelative)) {\n        generator._sources.add(sourceRelative);\n      }\n\n      var content = aSourceMapConsumer.sourceContentFor(sourceFile);\n      if (content != null) {\n        generator.setSourceContent(sourceFile, content);\n      }\n    });\n    return generator;\n  };\n\n/**\n * Add a single mapping from original source line and column to the generated\n * source's line and column for this source map being created. The mapping\n * object should have the following properties:\n *\n *   - generated: An object with the generated line and column positions.\n *   - original: An object with the original line and column positions.\n *   - source: The original source file (relative to the sourceRoot).\n *   - name: An optional original token name for this mapping.\n */\nSourceMapGenerator.prototype.addMapping =\n  function SourceMapGenerator_addMapping(aArgs) {\n    var generated = util.getArg(aArgs, 'generated');\n    var original = util.getArg(aArgs, 'original', null);\n    var source = util.getArg(aArgs, 'source', null);\n    var name = util.getArg(aArgs, 'name', null);\n\n    if (!this._skipValidation) {\n      this._validateMapping(generated, original, source, name);\n    }\n\n    if (source != null) {\n      source = String(source);\n      if (!this._sources.has(source)) {\n        this._sources.add(source);\n      }\n    }\n\n    if (name != null) {\n      name = String(name);\n      if (!this._names.has(name)) {\n        this._names.add(name);\n      }\n    }\n\n    this._mappings.add({\n      generatedLine: generated.line,\n      generatedColumn: generated.column,\n      originalLine: original != null && original.line,\n      originalColumn: original != null && original.column,\n      source: source,\n      name: name\n    });\n  };\n\n/**\n * Set the source content for a source file.\n */\nSourceMapGenerator.prototype.setSourceContent =\n  function SourceMapGenerator_setSourceContent(aSourceFile, aSourceContent) {\n    var source = aSourceFile;\n    if (this._sourceRoot != null) {\n      source = util.relative(this._sourceRoot, source);\n    }\n\n    if (aSourceContent != null) {\n      // Add the source content to the _sourcesContents map.\n      // Create a new _sourcesContents map if the property is null.\n      if (!this._sourcesContents) {\n        this._sourcesContents = Object.create(null);\n      }\n      this._sourcesContents[util.toSetString(source)] = aSourceContent;\n    } else if (this._sourcesContents) {\n      // Remove the source file from the _sourcesContents map.\n      // If the _sourcesContents map is empty, set the property to null.\n      delete this._sourcesContents[util.toSetString(source)];\n      if (Object.keys(this._sourcesContents).length === 0) {\n        this._sourcesContents = null;\n      }\n    }\n  };\n\n/**\n * Applies the mappings of a sub-source-map for a specific source file to the\n * source map being generated. Each mapping to the supplied source file is\n * rewritten using the supplied source map. Note: The resolution for the\n * resulting mappings is the minimium of this map and the supplied map.\n *\n * @param aSourceMapConsumer The source map to be applied.\n * @param aSourceFile Optional. The filename of the source file.\n *        If omitted, SourceMapConsumer's file property will be used.\n * @param aSourceMapPath Optional. The dirname of the path to the source map\n *        to be applied. If relative, it is relative to the SourceMapConsumer.\n *        This parameter is needed when the two source maps aren't in the same\n *        directory, and the source map to be applied contains relative source\n *        paths. If so, those relative source paths need to be rewritten\n *        relative to the SourceMapGenerator.\n */\nSourceMapGenerator.prototype.applySourceMap =\n  function SourceMapGenerator_applySourceMap(aSourceMapConsumer, aSourceFile, aSourceMapPath) {\n    var sourceFile = aSourceFile;\n    // If aSourceFile is omitted, we will use the file property of the SourceMap\n    if (aSourceFile == null) {\n      if (aSourceMapConsumer.file == null) {\n        throw new Error(\n          'SourceMapGenerator.prototype.applySourceMap requires either an explicit source file, ' +\n          'or the source map\\'s \"file\" property. Both were omitted.'\n        );\n      }\n      sourceFile = aSourceMapConsumer.file;\n    }\n    var sourceRoot = this._sourceRoot;\n    // Make \"sourceFile\" relative if an absolute Url is passed.\n    if (sourceRoot != null) {\n      sourceFile = util.relative(sourceRoot, sourceFile);\n    }\n    // Applying the SourceMap can add and remove items from the sources and\n    // the names array.\n    var newSources = new ArraySet();\n    var newNames = new ArraySet();\n\n    // Find mappings for the \"sourceFile\"\n    this._mappings.unsortedForEach(function (mapping) {\n      if (mapping.source === sourceFile && mapping.originalLine != null) {\n        // Check if it can be mapped by the source map, then update the mapping.\n        var original = aSourceMapConsumer.originalPositionFor({\n          line: mapping.originalLine,\n          column: mapping.originalColumn\n        });\n        if (original.source != null) {\n          // Copy mapping\n          mapping.source = original.source;\n          if (aSourceMapPath != null) {\n            mapping.source = util.join(aSourceMapPath, mapping.source)\n          }\n          if (sourceRoot != null) {\n            mapping.source = util.relative(sourceRoot, mapping.source);\n          }\n          mapping.originalLine = original.line;\n          mapping.originalColumn = original.column;\n          if (original.name != null) {\n            mapping.name = original.name;\n          }\n        }\n      }\n\n      var source = mapping.source;\n      if (source != null && !newSources.has(source)) {\n        newSources.add(source);\n      }\n\n      var name = mapping.name;\n      if (name != null && !newNames.has(name)) {\n        newNames.add(name);\n      }\n\n    }, this);\n    this._sources = newSources;\n    this._names = newNames;\n\n    // Copy sourcesContents of applied map.\n    aSourceMapConsumer.sources.forEach(function (sourceFile) {\n      var content = aSourceMapConsumer.sourceContentFor(sourceFile);\n      if (content != null) {\n        if (aSourceMapPath != null) {\n          sourceFile = util.join(aSourceMapPath, sourceFile);\n        }\n        if (sourceRoot != null) {\n          sourceFile = util.relative(sourceRoot, sourceFile);\n        }\n        this.setSourceContent(sourceFile, content);\n      }\n    }, this);\n  };\n\n/**\n * A mapping can have one of the three levels of data:\n *\n *   1. Just the generated position.\n *   2. The Generated position, original position, and original source.\n *   3. Generated and original position, original source, as well as a name\n *      token.\n *\n * To maintain consistency, we validate that any new mapping being added falls\n * in to one of these categories.\n */\nSourceMapGenerator.prototype._validateMapping =\n  function SourceMapGenerator_validateMapping(aGenerated, aOriginal, aSource,\n                                              aName) {\n    // When aOriginal is truthy but has empty values for .line and .column,\n    // it is most likely a programmer error. In this case we throw a very\n    // specific error message to try to guide them the right way.\n    // For example: https://github.com/Polymer/polymer-bundler/pull/519\n    if (aOriginal && typeof aOriginal.line !== 'number' && typeof aOriginal.column !== 'number') {\n        throw new Error(\n            'original.line and original.column are not numbers -- you probably meant to omit ' +\n            'the original mapping entirely and only map the generated position. If so, pass ' +\n            'null for the original mapping instead of an object with empty or null values.'\n        );\n    }\n\n    if (aGenerated && 'line' in aGenerated && 'column' in aGenerated\n        && aGenerated.line > 0 && aGenerated.column >= 0\n        && !aOriginal && !aSource && !aName) {\n      // Case 1.\n      return;\n    }\n    else if (aGenerated && 'line' in aGenerated && 'column' in aGenerated\n             && aOriginal && 'line' in aOriginal && 'column' in aOriginal\n             && aGenerated.line > 0 && aGenerated.column >= 0\n             && aOriginal.line > 0 && aOriginal.column >= 0\n             && aSource) {\n      // Cases 2 and 3.\n      return;\n    }\n    else {\n      throw new Error('Invalid mapping: ' + JSON.stringify({\n        generated: aGenerated,\n        source: aSource,\n        original: aOriginal,\n        name: aName\n      }));\n    }\n  };\n\n/**\n * Serialize the accumulated mappings in to the stream of base 64 VLQs\n * specified by the source map format.\n */\nSourceMapGenerator.prototype._serializeMappings =\n  function SourceMapGenerator_serializeMappings() {\n    var previousGeneratedColumn = 0;\n    var previousGeneratedLine = 1;\n    var previousOriginalColumn = 0;\n    var previousOriginalLine = 0;\n    var previousName = 0;\n    var previousSource = 0;\n    var result = '';\n    var next;\n    var mapping;\n    var nameIdx;\n    var sourceIdx;\n\n    var mappings = this._mappings.toArray();\n    for (var i = 0, len = mappings.length; i < len; i++) {\n      mapping = mappings[i];\n      next = ''\n\n      if (mapping.generatedLine !== previousGeneratedLine) {\n        previousGeneratedColumn = 0;\n        while (mapping.generatedLine !== previousGeneratedLine) {\n          next += ';';\n          previousGeneratedLine++;\n        }\n      }\n      else {\n        if (i > 0) {\n          if (!util.compareByGeneratedPositionsInflated(mapping, mappings[i - 1])) {\n            continue;\n          }\n          next += ',';\n        }\n      }\n\n      next += base64VLQ.encode(mapping.generatedColumn\n                                 - previousGeneratedColumn);\n      previousGeneratedColumn = mapping.generatedColumn;\n\n      if (mapping.source != null) {\n        sourceIdx = this._sources.indexOf(mapping.source);\n        next += base64VLQ.encode(sourceIdx - previousSource);\n        previousSource = sourceIdx;\n\n        // lines are stored 0-based in SourceMap spec version 3\n        next += base64VLQ.encode(mapping.originalLine - 1\n                                   - previousOriginalLine);\n        previousOriginalLine = mapping.originalLine - 1;\n\n        next += base64VLQ.encode(mapping.originalColumn\n                                   - previousOriginalColumn);\n        previousOriginalColumn = mapping.originalColumn;\n\n        if (mapping.name != null) {\n          nameIdx = this._names.indexOf(mapping.name);\n          next += base64VLQ.encode(nameIdx - previousName);\n          previousName = nameIdx;\n        }\n      }\n\n      result += next;\n    }\n\n    return result;\n  };\n\nSourceMapGenerator.prototype._generateSourcesContent =\n  function SourceMapGenerator_generateSourcesContent(aSources, aSourceRoot) {\n    return aSources.map(function (source) {\n      if (!this._sourcesContents) {\n        return null;\n      }\n      if (aSourceRoot != null) {\n        source = util.relative(aSourceRoot, source);\n      }\n      var key = util.toSetString(source);\n      return Object.prototype.hasOwnProperty.call(this._sourcesContents, key)\n        ? this._sourcesContents[key]\n        : null;\n    }, this);\n  };\n\n/**\n * Externalize the source map.\n */\nSourceMapGenerator.prototype.toJSON =\n  function SourceMapGenerator_toJSON() {\n    var map = {\n      version: this._version,\n      sources: this._sources.toArray(),\n      names: this._names.toArray(),\n      mappings: this._serializeMappings()\n    };\n    if (this._file != null) {\n      map.file = this._file;\n    }\n    if (this._sourceRoot != null) {\n      map.sourceRoot = this._sourceRoot;\n    }\n    if (this._sourcesContents) {\n      map.sourcesContent = this._generateSourcesContent(map.sources, map.sourceRoot);\n    }\n\n    return map;\n  };\n\n/**\n * Render the source map being generated to a string.\n */\nSourceMapGenerator.prototype.toString =\n  function SourceMapGenerator_toString() {\n    return JSON.stringify(this.toJSON());\n  };\n\nexports.SourceMapGenerator = SourceMapGenerator;\n", "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nexports.GREATEST_LOWER_BOUND = 1;\nexports.LEAST_UPPER_BOUND = 2;\n\n/**\n * Recursive implementation of binary search.\n *\n * @param aLow Indices here and lower do not contain the needle.\n * @param aHigh Indices here and higher do not contain the needle.\n * @param aNeedle The element being searched for.\n * @param aHaystack The non-empty array being searched.\n * @param aCompare Function which takes two elements and returns -1, 0, or 1.\n * @param aBias Either 'binarySearch.GREATEST_LOWER_BOUND' or\n *     'binarySearch.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n */\nfunction recursiveSearch(aLow, aHigh, aNeedle, aHaystack, aCompare, aBias) {\n  // This function terminates when one of the following is true:\n  //\n  //   1. We find the exact element we are looking for.\n  //\n  //   2. We did not find the exact element, but we can return the index of\n  //      the next-closest element.\n  //\n  //   3. We did not find the exact element, and there is no next-closest\n  //      element than the one we are searching for, so we return -1.\n  var mid = Math.floor((aHigh - aLow) / 2) + aLow;\n  var cmp = aCompare(aNeedle, aHaystack[mid], true);\n  if (cmp === 0) {\n    // Found the element we are looking for.\n    return mid;\n  }\n  else if (cmp > 0) {\n    // Our needle is greater than aHaystack[mid].\n    if (aHigh - mid > 1) {\n      // The element is in the upper half.\n      return recursiveSearch(mid, aHigh, aNeedle, aHaystack, aCompare, aBias);\n    }\n\n    // The exact needle element was not found in this haystack. Determine if\n    // we are in termination case (3) or (2) and return the appropriate thing.\n    if (aBias == exports.LEAST_UPPER_BOUND) {\n      return aHigh < aHaystack.length ? aHigh : -1;\n    } else {\n      return mid;\n    }\n  }\n  else {\n    // Our needle is less than aHaystack[mid].\n    if (mid - aLow > 1) {\n      // The element is in the lower half.\n      return recursiveSearch(aLow, mid, aNeedle, aHaystack, aCompare, aBias);\n    }\n\n    // we are in termination case (3) or (2) and return the appropriate thing.\n    if (aBias == exports.LEAST_UPPER_BOUND) {\n      return mid;\n    } else {\n      return aLow < 0 ? -1 : aLow;\n    }\n  }\n}\n\n/**\n * This is an implementation of binary search which will always try and return\n * the index of the closest element if there is no exact hit. This is because\n * mappings between original and generated line/col pairs are single points,\n * and there is an implicit region between each of them, so a miss just means\n * that you aren't on the very start of a region.\n *\n * @param aNeedle The element you are looking for.\n * @param aHaystack The array that is being searched.\n * @param aCompare A function which takes the needle and an element in the\n *     array and returns -1, 0, or 1 depending on whether the needle is less\n *     than, equal to, or greater than the element, respectively.\n * @param aBias Either 'binarySearch.GREATEST_LOWER_BOUND' or\n *     'binarySearch.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n *     Defaults to 'binarySearch.GREATEST_LOWER_BOUND'.\n */\nexports.search = function search(aNeedle, aHaystack, aCompare, aBias) {\n  if (aHaystack.length === 0) {\n    return -1;\n  }\n\n  var index = recursiveSearch(-1, aHaystack.length, aNeedle, aHaystack,\n                              aCompare, aBias || exports.GREATEST_LOWER_BOUND);\n  if (index < 0) {\n    return -1;\n  }\n\n  // We have found either the exact element, or the next-closest element than\n  // the one we are searching for. However, there may be more than one such\n  // element. Make sure we always return the smallest of these.\n  while (index - 1 >= 0) {\n    if (aCompare(aHaystack[index], aHaystack[index - 1], true) !== 0) {\n      break;\n    }\n    --index;\n  }\n\n  return index;\n};\n", "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\n// It turns out that some (most?) JavaScript engines don't self-host\n// `Array.prototype.sort`. This makes sense because C++ will likely remain\n// faster than JS when doing raw CPU-intensive sorting. However, when using a\n// custom comparator function, calling back and forth between the VM's C++ and\n// JIT'd JS is rather slow *and* loses JIT type information, resulting in\n// worse generated code for the comparator function than would be optimal. In\n// fact, when sorting with a comparator, these costs outweigh the benefits of\n// sorting in C++. By using our own JS-implemented Quick Sort (below), we get\n// a ~3500ms mean speed-up in `bench/bench.html`.\n\n/**\n * Swap the elements indexed by `x` and `y` in the array `ary`.\n *\n * @param {Array} ary\n *        The array.\n * @param {Number} x\n *        The index of the first item.\n * @param {Number} y\n *        The index of the second item.\n */\nfunction swap(ary, x, y) {\n  var temp = ary[x];\n  ary[x] = ary[y];\n  ary[y] = temp;\n}\n\n/**\n * Returns a random integer within the range `low .. high` inclusive.\n *\n * @param {Number} low\n *        The lower bound on the range.\n * @param {Number} high\n *        The upper bound on the range.\n */\nfunction randomIntInRange(low, high) {\n  return Math.round(low + (Math.random() * (high - low)));\n}\n\n/**\n * The Quick Sort algorithm.\n *\n * @param {Array} ary\n *        An array to sort.\n * @param {function} comparator\n *        Function to use to compare two items.\n * @param {Number} p\n *        Start index of the array\n * @param {Number} r\n *        End index of the array\n */\nfunction doQuickSort(ary, comparator, p, r) {\n  // If our lower bound is less than our upper bound, we (1) partition the\n  // array into two pieces and (2) recurse on each half. If it is not, this is\n  // the empty array and our base case.\n\n  if (p < r) {\n    // (1) Partitioning.\n    //\n    // The partitioning chooses a pivot between `p` and `r` and moves all\n    // elements that are less than or equal to the pivot to the before it, and\n    // all the elements that are greater than it after it. The effect is that\n    // once partition is done, the pivot is in the exact place it will be when\n    // the array is put in sorted order, and it will not need to be moved\n    // again. This runs in O(n) time.\n\n    // Always choose a random pivot so that an input array which is reverse\n    // sorted does not cause O(n^2) running time.\n    var pivotIndex = randomIntInRange(p, r);\n    var i = p - 1;\n\n    swap(ary, pivotIndex, r);\n    var pivot = ary[r];\n\n    // Immediately after `j` is incremented in this loop, the following hold\n    // true:\n    //\n    //   * Every element in `ary[p .. i]` is less than or equal to the pivot.\n    //\n    //   * Every element in `ary[i+1 .. j-1]` is greater than the pivot.\n    for (var j = p; j < r; j++) {\n      if (comparator(ary[j], pivot) <= 0) {\n        i += 1;\n        swap(ary, i, j);\n      }\n    }\n\n    swap(ary, i + 1, j);\n    var q = i + 1;\n\n    // (2) Recurse on each half.\n\n    doQuickSort(ary, comparator, p, q - 1);\n    doQuickSort(ary, comparator, q + 1, r);\n  }\n}\n\n/**\n * Sort the given array in-place with the given comparator function.\n *\n * @param {Array} ary\n *        An array to sort.\n * @param {function} comparator\n *        Function to use to compare two items.\n */\nexports.quickSort = function (ary, comparator) {\n  doQuickSort(ary, comparator, 0, ary.length - 1);\n};\n", "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar util = require('./util');\nvar binarySearch = require('./binary-search');\nvar ArraySet = require('./array-set').ArraySet;\nvar base64VLQ = require('./base64-vlq');\nvar quickSort = require('./quick-sort').quickSort;\n\nfunction SourceMapConsumer(aSourceMap, aSourceMapURL) {\n  var sourceMap = aSourceMap;\n  if (typeof aSourceMap === 'string') {\n    sourceMap = util.parseSourceMapInput(aSourceMap);\n  }\n\n  return sourceMap.sections != null\n    ? new IndexedSourceMapConsumer(sourceMap, aSourceMapURL)\n    : new BasicSourceMapConsumer(sourceMap, aSourceMapURL);\n}\n\nSourceMapConsumer.fromSourceMap = function(aSourceMap, aSourceMapURL) {\n  return BasicSourceMapConsumer.fromSourceMap(aSourceMap, aSourceMapURL);\n}\n\n/**\n * The version of the source mapping spec that we are consuming.\n */\nSourceMapConsumer.prototype._version = 3;\n\n// `__generatedMappings` and `__originalMappings` are arrays that hold the\n// parsed mapping coordinates from the source map's \"mappings\" attribute. They\n// are lazily instantiated, accessed via the `_generatedMappings` and\n// `_originalMappings` getters respectively, and we only parse the mappings\n// and create these arrays once queried for a source location. We jump through\n// these hoops because there can be many thousands of mappings, and parsing\n// them is expensive, so we only want to do it if we must.\n//\n// Each object in the arrays is of the form:\n//\n//     {\n//       generatedLine: The line number in the generated code,\n//       generatedColumn: The column number in the generated code,\n//       source: The path to the original source file that generated this\n//               chunk of code,\n//       originalLine: The line number in the original source that\n//                     corresponds to this chunk of generated code,\n//       originalColumn: The column number in the original source that\n//                       corresponds to this chunk of generated code,\n//       name: The name of the original symbol which generated this chunk of\n//             code.\n//     }\n//\n// All properties except for `generatedLine` and `generatedColumn` can be\n// `null`.\n//\n// `_generatedMappings` is ordered by the generated positions.\n//\n// `_originalMappings` is ordered by the original positions.\n\nSourceMapConsumer.prototype.__generatedMappings = null;\nObject.defineProperty(SourceMapConsumer.prototype, '_generatedMappings', {\n  configurable: true,\n  enumerable: true,\n  get: function () {\n    if (!this.__generatedMappings) {\n      this._parseMappings(this._mappings, this.sourceRoot);\n    }\n\n    return this.__generatedMappings;\n  }\n});\n\nSourceMapConsumer.prototype.__originalMappings = null;\nObject.defineProperty(SourceMapConsumer.prototype, '_originalMappings', {\n  configurable: true,\n  enumerable: true,\n  get: function () {\n    if (!this.__originalMappings) {\n      this._parseMappings(this._mappings, this.sourceRoot);\n    }\n\n    return this.__originalMappings;\n  }\n});\n\nSourceMapConsumer.prototype._charIsMappingSeparator =\n  function SourceMapConsumer_charIsMappingSeparator(aStr, index) {\n    var c = aStr.charAt(index);\n    return c === \";\" || c === \",\";\n  };\n\n/**\n * Parse the mappings in a string in to a data structure which we can easily\n * query (the ordered arrays in the `this.__generatedMappings` and\n * `this.__originalMappings` properties).\n */\nSourceMapConsumer.prototype._parseMappings =\n  function SourceMapConsumer_parseMappings(aStr, aSourceRoot) {\n    throw new Error(\"Subclasses must implement _parseMappings\");\n  };\n\nSourceMapConsumer.GENERATED_ORDER = 1;\nSourceMapConsumer.ORIGINAL_ORDER = 2;\n\nSourceMapConsumer.GREATEST_LOWER_BOUND = 1;\nSourceMapConsumer.LEAST_UPPER_BOUND = 2;\n\n/**\n * Iterate over each mapping between an original source/line/column and a\n * generated line/column in this source map.\n *\n * @param Function aCallback\n *        The function that is called with each mapping.\n * @param Object aContext\n *        Optional. If specified, this object will be the value of `this` every\n *        time that `aCallback` is called.\n * @param aOrder\n *        Either `SourceMapConsumer.GENERATED_ORDER` or\n *        `SourceMapConsumer.ORIGINAL_ORDER`. Specifies whether you want to\n *        iterate over the mappings sorted by the generated file's line/column\n *        order or the original's source/line/column order, respectively. Defaults to\n *        `SourceMapConsumer.GENERATED_ORDER`.\n */\nSourceMapConsumer.prototype.eachMapping =\n  function SourceMapConsumer_eachMapping(aCallback, aContext, aOrder) {\n    var context = aContext || null;\n    var order = aOrder || SourceMapConsumer.GENERATED_ORDER;\n\n    var mappings;\n    switch (order) {\n    case SourceMapConsumer.GENERATED_ORDER:\n      mappings = this._generatedMappings;\n      break;\n    case SourceMapConsumer.ORIGINAL_ORDER:\n      mappings = this._originalMappings;\n      break;\n    default:\n      throw new Error(\"Unknown order of iteration.\");\n    }\n\n    var sourceRoot = this.sourceRoot;\n    mappings.map(function (mapping) {\n      var source = mapping.source === null ? null : this._sources.at(mapping.source);\n      source = util.computeSourceURL(sourceRoot, source, this._sourceMapURL);\n      return {\n        source: source,\n        generatedLine: mapping.generatedLine,\n        generatedColumn: mapping.generatedColumn,\n        originalLine: mapping.originalLine,\n        originalColumn: mapping.originalColumn,\n        name: mapping.name === null ? null : this._names.at(mapping.name)\n      };\n    }, this).forEach(aCallback, context);\n  };\n\n/**\n * Returns all generated line and column information for the original source,\n * line, and column provided. If no column is provided, returns all mappings\n * corresponding to a either the line we are searching for or the next\n * closest line that has any mappings. Otherwise, returns all mappings\n * corresponding to the given line and either the column we are searching for\n * or the next closest column that has any offsets.\n *\n * The only argument is an object with the following properties:\n *\n *   - source: The filename of the original source.\n *   - line: The line number in the original source.  The line number is 1-based.\n *   - column: Optional. the column number in the original source.\n *    The column number is 0-based.\n *\n * and an array of objects is returned, each with the following properties:\n *\n *   - line: The line number in the generated source, or null.  The\n *    line number is 1-based.\n *   - column: The column number in the generated source, or null.\n *    The column number is 0-based.\n */\nSourceMapConsumer.prototype.allGeneratedPositionsFor =\n  function SourceMapConsumer_allGeneratedPositionsFor(aArgs) {\n    var line = util.getArg(aArgs, 'line');\n\n    // When there is no exact match, BasicSourceMapConsumer.prototype._findMapping\n    // returns the index of the closest mapping less than the needle. By\n    // setting needle.originalColumn to 0, we thus find the last mapping for\n    // the given line, provided such a mapping exists.\n    var needle = {\n      source: util.getArg(aArgs, 'source'),\n      originalLine: line,\n      originalColumn: util.getArg(aArgs, 'column', 0)\n    };\n\n    needle.source = this._findSourceIndex(needle.source);\n    if (needle.source < 0) {\n      return [];\n    }\n\n    var mappings = [];\n\n    var index = this._findMapping(needle,\n                                  this._originalMappings,\n                                  \"originalLine\",\n                                  \"originalColumn\",\n                                  util.compareByOriginalPositions,\n                                  binarySearch.LEAST_UPPER_BOUND);\n    if (index >= 0) {\n      var mapping = this._originalMappings[index];\n\n      if (aArgs.column === undefined) {\n        var originalLine = mapping.originalLine;\n\n        // Iterate until either we run out of mappings, or we run into\n        // a mapping for a different line than the one we found. Since\n        // mappings are sorted, this is guaranteed to find all mappings for\n        // the line we found.\n        while (mapping && mapping.originalLine === originalLine) {\n          mappings.push({\n            line: util.getArg(mapping, 'generatedLine', null),\n            column: util.getArg(mapping, 'generatedColumn', null),\n            lastColumn: util.getArg(mapping, 'lastGeneratedColumn', null)\n          });\n\n          mapping = this._originalMappings[++index];\n        }\n      } else {\n        var originalColumn = mapping.originalColumn;\n\n        // Iterate until either we run out of mappings, or we run into\n        // a mapping for a different line than the one we were searching for.\n        // Since mappings are sorted, this is guaranteed to find all mappings for\n        // the line we are searching for.\n        while (mapping &&\n               mapping.originalLine === line &&\n               mapping.originalColumn == originalColumn) {\n          mappings.push({\n            line: util.getArg(mapping, 'generatedLine', null),\n            column: util.getArg(mapping, 'generatedColumn', null),\n            lastColumn: util.getArg(mapping, 'lastGeneratedColumn', null)\n          });\n\n          mapping = this._originalMappings[++index];\n        }\n      }\n    }\n\n    return mappings;\n  };\n\nexports.SourceMapConsumer = SourceMapConsumer;\n\n/**\n * A BasicSourceMapConsumer instance represents a parsed source map which we can\n * query for information about the original file positions by giving it a file\n * position in the generated source.\n *\n * The first parameter is the raw source map (either as a JSON string, or\n * already parsed to an object). According to the spec, source maps have the\n * following attributes:\n *\n *   - version: Which version of the source map spec this map is following.\n *   - sources: An array of URLs to the original source files.\n *   - names: An array of identifiers which can be referrenced by individual mappings.\n *   - sourceRoot: Optional. The URL root from which all sources are relative.\n *   - sourcesContent: Optional. An array of contents of the original source files.\n *   - mappings: A string of base64 VLQs which contain the actual mappings.\n *   - file: Optional. The generated file this source map is associated with.\n *\n * Here is an example source map, taken from the source map spec[0]:\n *\n *     {\n *       version : 3,\n *       file: \"out.js\",\n *       sourceRoot : \"\",\n *       sources: [\"foo.js\", \"bar.js\"],\n *       names: [\"src\", \"maps\", \"are\", \"fun\"],\n *       mappings: \"AA,AB;;ABCDE;\"\n *     }\n *\n * The second parameter, if given, is a string whose value is the URL\n * at which the source map was found.  This URL is used to compute the\n * sources array.\n *\n * [0]: https://docs.google.com/document/d/1U1RGAehQwRypUTovF1KRlpiOFze0b-_2gc6fAH0KY0k/edit?pli=1#\n */\nfunction BasicSourceMapConsumer(aSourceMap, aSourceMapURL) {\n  var sourceMap = aSourceMap;\n  if (typeof aSourceMap === 'string') {\n    sourceMap = util.parseSourceMapInput(aSourceMap);\n  }\n\n  var version = util.getArg(sourceMap, 'version');\n  var sources = util.getArg(sourceMap, 'sources');\n  // Sass 3.3 leaves out the 'names' array, so we deviate from the spec (which\n  // requires the array) to play nice here.\n  var names = util.getArg(sourceMap, 'names', []);\n  var sourceRoot = util.getArg(sourceMap, 'sourceRoot', null);\n  var sourcesContent = util.getArg(sourceMap, 'sourcesContent', null);\n  var mappings = util.getArg(sourceMap, 'mappings');\n  var file = util.getArg(sourceMap, 'file', null);\n\n  // Once again, Sass deviates from the spec and supplies the version as a\n  // string rather than a number, so we use loose equality checking here.\n  if (version != this._version) {\n    throw new Error('Unsupported version: ' + version);\n  }\n\n  if (sourceRoot) {\n    sourceRoot = util.normalize(sourceRoot);\n  }\n\n  sources = sources\n    .map(String)\n    // Some source maps produce relative source paths like \"./foo.js\" instead of\n    // \"foo.js\".  Normalize these first so that future comparisons will succeed.\n    // See bugzil.la/1090768.\n    .map(util.normalize)\n    // Always ensure that absolute sources are internally stored relative to\n    // the source root, if the source root is absolute. Not doing this would\n    // be particularly problematic when the source root is a prefix of the\n    // source (valid, but why??). See github issue #199 and bugzil.la/1188982.\n    .map(function (source) {\n      return sourceRoot && util.isAbsolute(sourceRoot) && util.isAbsolute(source)\n        ? util.relative(sourceRoot, source)\n        : source;\n    });\n\n  // Pass `true` below to allow duplicate names and sources. While source maps\n  // are intended to be compressed and deduplicated, the TypeScript compiler\n  // sometimes generates source maps with duplicates in them. See Github issue\n  // #72 and bugzil.la/889492.\n  this._names = ArraySet.fromArray(names.map(String), true);\n  this._sources = ArraySet.fromArray(sources, true);\n\n  this._absoluteSources = this._sources.toArray().map(function (s) {\n    return util.computeSourceURL(sourceRoot, s, aSourceMapURL);\n  });\n\n  this.sourceRoot = sourceRoot;\n  this.sourcesContent = sourcesContent;\n  this._mappings = mappings;\n  this._sourceMapURL = aSourceMapURL;\n  this.file = file;\n}\n\nBasicSourceMapConsumer.prototype = Object.create(SourceMapConsumer.prototype);\nBasicSourceMapConsumer.prototype.consumer = SourceMapConsumer;\n\n/**\n * Utility function to find the index of a source.  Returns -1 if not\n * found.\n */\nBasicSourceMapConsumer.prototype._findSourceIndex = function(aSource) {\n  var relativeSource = aSource;\n  if (this.sourceRoot != null) {\n    relativeSource = util.relative(this.sourceRoot, relativeSource);\n  }\n\n  if (this._sources.has(relativeSource)) {\n    return this._sources.indexOf(relativeSource);\n  }\n\n  // Maybe aSource is an absolute URL as returned by |sources|.  In\n  // this case we can't simply undo the transform.\n  var i;\n  for (i = 0; i < this._absoluteSources.length; ++i) {\n    if (this._absoluteSources[i] == aSource) {\n      return i;\n    }\n  }\n\n  return -1;\n};\n\n/**\n * Create a BasicSourceMapConsumer from a SourceMapGenerator.\n *\n * @param SourceMapGenerator aSourceMap\n *        The source map that will be consumed.\n * @param String aSourceMapURL\n *        The URL at which the source map can be found (optional)\n * @returns BasicSourceMapConsumer\n */\nBasicSourceMapConsumer.fromSourceMap =\n  function SourceMapConsumer_fromSourceMap(aSourceMap, aSourceMapURL) {\n    var smc = Object.create(BasicSourceMapConsumer.prototype);\n\n    var names = smc._names = ArraySet.fromArray(aSourceMap._names.toArray(), true);\n    var sources = smc._sources = ArraySet.fromArray(aSourceMap._sources.toArray(), true);\n    smc.sourceRoot = aSourceMap._sourceRoot;\n    smc.sourcesContent = aSourceMap._generateSourcesContent(smc._sources.toArray(),\n                                                            smc.sourceRoot);\n    smc.file = aSourceMap._file;\n    smc._sourceMapURL = aSourceMapURL;\n    smc._absoluteSources = smc._sources.toArray().map(function (s) {\n      return util.computeSourceURL(smc.sourceRoot, s, aSourceMapURL);\n    });\n\n    // Because we are modifying the entries (by converting string sources and\n    // names to indices into the sources and names ArraySets), we have to make\n    // a copy of the entry or else bad things happen. Shared mutable state\n    // strikes again! See github issue #191.\n\n    var generatedMappings = aSourceMap._mappings.toArray().slice();\n    var destGeneratedMappings = smc.__generatedMappings = [];\n    var destOriginalMappings = smc.__originalMappings = [];\n\n    for (var i = 0, length = generatedMappings.length; i < length; i++) {\n      var srcMapping = generatedMappings[i];\n      var destMapping = new Mapping;\n      destMapping.generatedLine = srcMapping.generatedLine;\n      destMapping.generatedColumn = srcMapping.generatedColumn;\n\n      if (srcMapping.source) {\n        destMapping.source = sources.indexOf(srcMapping.source);\n        destMapping.originalLine = srcMapping.originalLine;\n        destMapping.originalColumn = srcMapping.originalColumn;\n\n        if (srcMapping.name) {\n          destMapping.name = names.indexOf(srcMapping.name);\n        }\n\n        destOriginalMappings.push(destMapping);\n      }\n\n      destGeneratedMappings.push(destMapping);\n    }\n\n    quickSort(smc.__originalMappings, util.compareByOriginalPositions);\n\n    return smc;\n  };\n\n/**\n * The version of the source mapping spec that we are consuming.\n */\nBasicSourceMapConsumer.prototype._version = 3;\n\n/**\n * The list of original sources.\n */\nObject.defineProperty(BasicSourceMapConsumer.prototype, 'sources', {\n  get: function () {\n    return this._absoluteSources.slice();\n  }\n});\n\n/**\n * Provide the JIT with a nice shape / hidden class.\n */\nfunction Mapping() {\n  this.generatedLine = 0;\n  this.generatedColumn = 0;\n  this.source = null;\n  this.originalLine = null;\n  this.originalColumn = null;\n  this.name = null;\n}\n\n/**\n * Parse the mappings in a string in to a data structure which we can easily\n * query (the ordered arrays in the `this.__generatedMappings` and\n * `this.__originalMappings` properties).\n */\nBasicSourceMapConsumer.prototype._parseMappings =\n  function SourceMapConsumer_parseMappings(aStr, aSourceRoot) {\n    var generatedLine = 1;\n    var previousGeneratedColumn = 0;\n    var previousOriginalLine = 0;\n    var previousOriginalColumn = 0;\n    var previousSource = 0;\n    var previousName = 0;\n    var length = aStr.length;\n    var index = 0;\n    var cachedSegments = {};\n    var temp = {};\n    var originalMappings = [];\n    var generatedMappings = [];\n    var mapping, str, segment, end, value;\n\n    while (index < length) {\n      if (aStr.charAt(index) === ';') {\n        generatedLine++;\n        index++;\n        previousGeneratedColumn = 0;\n      }\n      else if (aStr.charAt(index) === ',') {\n        index++;\n      }\n      else {\n        mapping = new Mapping();\n        mapping.generatedLine = generatedLine;\n\n        // Because each offset is encoded relative to the previous one,\n        // many segments often have the same encoding. We can exploit this\n        // fact by caching the parsed variable length fields of each segment,\n        // allowing us to avoid a second parse if we encounter the same\n        // segment again.\n        for (end = index; end < length; end++) {\n          if (this._charIsMappingSeparator(aStr, end)) {\n            break;\n          }\n        }\n        str = aStr.slice(index, end);\n\n        segment = cachedSegments[str];\n        if (segment) {\n          index += str.length;\n        } else {\n          segment = [];\n          while (index < end) {\n            base64VLQ.decode(aStr, index, temp);\n            value = temp.value;\n            index = temp.rest;\n            segment.push(value);\n          }\n\n          if (segment.length === 2) {\n            throw new Error('Found a source, but no line and column');\n          }\n\n          if (segment.length === 3) {\n            throw new Error('Found a source and line, but no column');\n          }\n\n          cachedSegments[str] = segment;\n        }\n\n        // Generated column.\n        mapping.generatedColumn = previousGeneratedColumn + segment[0];\n        previousGeneratedColumn = mapping.generatedColumn;\n\n        if (segment.length > 1) {\n          // Original source.\n          mapping.source = previousSource + segment[1];\n          previousSource += segment[1];\n\n          // Original line.\n          mapping.originalLine = previousOriginalLine + segment[2];\n          previousOriginalLine = mapping.originalLine;\n          // Lines are stored 0-based\n          mapping.originalLine += 1;\n\n          // Original column.\n          mapping.originalColumn = previousOriginalColumn + segment[3];\n          previousOriginalColumn = mapping.originalColumn;\n\n          if (segment.length > 4) {\n            // Original name.\n            mapping.name = previousName + segment[4];\n            previousName += segment[4];\n          }\n        }\n\n        generatedMappings.push(mapping);\n        if (typeof mapping.originalLine === 'number') {\n          originalMappings.push(mapping);\n        }\n      }\n    }\n\n    quickSort(generatedMappings, util.compareByGeneratedPositionsDeflated);\n    this.__generatedMappings = generatedMappings;\n\n    quickSort(originalMappings, util.compareByOriginalPositions);\n    this.__originalMappings = originalMappings;\n  };\n\n/**\n * Find the mapping that best matches the hypothetical \"needle\" mapping that\n * we are searching for in the given \"haystack\" of mappings.\n */\nBasicSourceMapConsumer.prototype._findMapping =\n  function SourceMapConsumer_findMapping(aNeedle, aMappings, aLineName,\n                                         aColumnName, aComparator, aBias) {\n    // To return the position we are searching for, we must first find the\n    // mapping for the given position and then return the opposite position it\n    // points to. Because the mappings are sorted, we can use binary search to\n    // find the best mapping.\n\n    if (aNeedle[aLineName] <= 0) {\n      throw new TypeError('Line must be greater than or equal to 1, got '\n                          + aNeedle[aLineName]);\n    }\n    if (aNeedle[aColumnName] < 0) {\n      throw new TypeError('Column must be greater than or equal to 0, got '\n                          + aNeedle[aColumnName]);\n    }\n\n    return binarySearch.search(aNeedle, aMappings, aComparator, aBias);\n  };\n\n/**\n * Compute the last column for each generated mapping. The last column is\n * inclusive.\n */\nBasicSourceMapConsumer.prototype.computeColumnSpans =\n  function SourceMapConsumer_computeColumnSpans() {\n    for (var index = 0; index < this._generatedMappings.length; ++index) {\n      var mapping = this._generatedMappings[index];\n\n      // Mappings do not contain a field for the last generated columnt. We\n      // can come up with an optimistic estimate, however, by assuming that\n      // mappings are contiguous (i.e. given two consecutive mappings, the\n      // first mapping ends where the second one starts).\n      if (index + 1 < this._generatedMappings.length) {\n        var nextMapping = this._generatedMappings[index + 1];\n\n        if (mapping.generatedLine === nextMapping.generatedLine) {\n          mapping.lastGeneratedColumn = nextMapping.generatedColumn - 1;\n          continue;\n        }\n      }\n\n      // The last mapping for each line spans the entire line.\n      mapping.lastGeneratedColumn = Infinity;\n    }\n  };\n\n/**\n * Returns the original source, line, and column information for the generated\n * source's line and column positions provided. The only argument is an object\n * with the following properties:\n *\n *   - line: The line number in the generated source.  The line number\n *     is 1-based.\n *   - column: The column number in the generated source.  The column\n *     number is 0-based.\n *   - bias: Either 'SourceMapConsumer.GREATEST_LOWER_BOUND' or\n *     'SourceMapConsumer.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n *     Defaults to 'SourceMapConsumer.GREATEST_LOWER_BOUND'.\n *\n * and an object is returned with the following properties:\n *\n *   - source: The original source file, or null.\n *   - line: The line number in the original source, or null.  The\n *     line number is 1-based.\n *   - column: The column number in the original source, or null.  The\n *     column number is 0-based.\n *   - name: The original identifier, or null.\n */\nBasicSourceMapConsumer.prototype.originalPositionFor =\n  function SourceMapConsumer_originalPositionFor(aArgs) {\n    var needle = {\n      generatedLine: util.getArg(aArgs, 'line'),\n      generatedColumn: util.getArg(aArgs, 'column')\n    };\n\n    var index = this._findMapping(\n      needle,\n      this._generatedMappings,\n      \"generatedLine\",\n      \"generatedColumn\",\n      util.compareByGeneratedPositionsDeflated,\n      util.getArg(aArgs, 'bias', SourceMapConsumer.GREATEST_LOWER_BOUND)\n    );\n\n    if (index >= 0) {\n      var mapping = this._generatedMappings[index];\n\n      if (mapping.generatedLine === needle.generatedLine) {\n        var source = util.getArg(mapping, 'source', null);\n        if (source !== null) {\n          source = this._sources.at(source);\n          source = util.computeSourceURL(this.sourceRoot, source, this._sourceMapURL);\n        }\n        var name = util.getArg(mapping, 'name', null);\n        if (name !== null) {\n          name = this._names.at(name);\n        }\n        return {\n          source: source,\n          line: util.getArg(mapping, 'originalLine', null),\n          column: util.getArg(mapping, 'originalColumn', null),\n          name: name\n        };\n      }\n    }\n\n    return {\n      source: null,\n      line: null,\n      column: null,\n      name: null\n    };\n  };\n\n/**\n * Return true if we have the source content for every source in the source\n * map, false otherwise.\n */\nBasicSourceMapConsumer.prototype.hasContentsOfAllSources =\n  function BasicSourceMapConsumer_hasContentsOfAllSources() {\n    if (!this.sourcesContent) {\n      return false;\n    }\n    return this.sourcesContent.length >= this._sources.size() &&\n      !this.sourcesContent.some(function (sc) { return sc == null; });\n  };\n\n/**\n * Returns the original source content. The only argument is the url of the\n * original source file. Returns null if no original source content is\n * available.\n */\nBasicSourceMapConsumer.prototype.sourceContentFor =\n  function SourceMapConsumer_sourceContentFor(aSource, nullOnMissing) {\n    if (!this.sourcesContent) {\n      return null;\n    }\n\n    var index = this._findSourceIndex(aSource);\n    if (index >= 0) {\n      return this.sourcesContent[index];\n    }\n\n    var relativeSource = aSource;\n    if (this.sourceRoot != null) {\n      relativeSource = util.relative(this.sourceRoot, relativeSource);\n    }\n\n    var url;\n    if (this.sourceRoot != null\n        && (url = util.urlParse(this.sourceRoot))) {\n      // XXX: file:// URIs and absolute paths lead to unexpected behavior for\n      // many users. We can help them out when they expect file:// URIs to\n      // behave like it would if they were running a local HTTP server. See\n      // https://bugzilla.mozilla.org/show_bug.cgi?id=885597.\n      var fileUriAbsPath = relativeSource.replace(/^file:\\/\\//, \"\");\n      if (url.scheme == \"file\"\n          && this._sources.has(fileUriAbsPath)) {\n        return this.sourcesContent[this._sources.indexOf(fileUriAbsPath)]\n      }\n\n      if ((!url.path || url.path == \"/\")\n          && this._sources.has(\"/\" + relativeSource)) {\n        return this.sourcesContent[this._sources.indexOf(\"/\" + relativeSource)];\n      }\n    }\n\n    // This function is used recursively from\n    // IndexedSourceMapConsumer.prototype.sourceContentFor. In that case, we\n    // don't want to throw if we can't find the source - we just want to\n    // return null, so we provide a flag to exit gracefully.\n    if (nullOnMissing) {\n      return null;\n    }\n    else {\n      throw new Error('\"' + relativeSource + '\" is not in the SourceMap.');\n    }\n  };\n\n/**\n * Returns the generated line and column information for the original source,\n * line, and column positions provided. The only argument is an object with\n * the following properties:\n *\n *   - source: The filename of the original source.\n *   - line: The line number in the original source.  The line number\n *     is 1-based.\n *   - column: The column number in the original source.  The column\n *     number is 0-based.\n *   - bias: Either 'SourceMapConsumer.GREATEST_LOWER_BOUND' or\n *     'SourceMapConsumer.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n *     Defaults to 'SourceMapConsumer.GREATEST_LOWER_BOUND'.\n *\n * and an object is returned with the following properties:\n *\n *   - line: The line number in the generated source, or null.  The\n *     line number is 1-based.\n *   - column: The column number in the generated source, or null.\n *     The column number is 0-based.\n */\nBasicSourceMapConsumer.prototype.generatedPositionFor =\n  function SourceMapConsumer_generatedPositionFor(aArgs) {\n    var source = util.getArg(aArgs, 'source');\n    source = this._findSourceIndex(source);\n    if (source < 0) {\n      return {\n        line: null,\n        column: null,\n        lastColumn: null\n      };\n    }\n\n    var needle = {\n      source: source,\n      originalLine: util.getArg(aArgs, 'line'),\n      originalColumn: util.getArg(aArgs, 'column')\n    };\n\n    var index = this._findMapping(\n      needle,\n      this._originalMappings,\n      \"originalLine\",\n      \"originalColumn\",\n      util.compareByOriginalPositions,\n      util.getArg(aArgs, 'bias', SourceMapConsumer.GREATEST_LOWER_BOUND)\n    );\n\n    if (index >= 0) {\n      var mapping = this._originalMappings[index];\n\n      if (mapping.source === needle.source) {\n        return {\n          line: util.getArg(mapping, 'generatedLine', null),\n          column: util.getArg(mapping, 'generatedColumn', null),\n          lastColumn: util.getArg(mapping, 'lastGeneratedColumn', null)\n        };\n      }\n    }\n\n    return {\n      line: null,\n      column: null,\n      lastColumn: null\n    };\n  };\n\nexports.BasicSourceMapConsumer = BasicSourceMapConsumer;\n\n/**\n * An IndexedSourceMapConsumer instance represents a parsed source map which\n * we can query for information. It differs from BasicSourceMapConsumer in\n * that it takes \"indexed\" source maps (i.e. ones with a \"sections\" field) as\n * input.\n *\n * The first parameter is a raw source map (either as a JSON string, or already\n * parsed to an object). According to the spec for indexed source maps, they\n * have the following attributes:\n *\n *   - version: Which version of the source map spec this map is following.\n *   - file: Optional. The generated file this source map is associated with.\n *   - sections: A list of section definitions.\n *\n * Each value under the \"sections\" field has two fields:\n *   - offset: The offset into the original specified at which this section\n *       begins to apply, defined as an object with a \"line\" and \"column\"\n *       field.\n *   - map: A source map definition. This source map could also be indexed,\n *       but doesn't have to be.\n *\n * Instead of the \"map\" field, it's also possible to have a \"url\" field\n * specifying a URL to retrieve a source map from, but that's currently\n * unsupported.\n *\n * Here's an example source map, taken from the source map spec[0], but\n * modified to omit a section which uses the \"url\" field.\n *\n *  {\n *    version : 3,\n *    file: \"app.js\",\n *    sections: [{\n *      offset: {line:100, column:10},\n *      map: {\n *        version : 3,\n *        file: \"section.js\",\n *        sources: [\"foo.js\", \"bar.js\"],\n *        names: [\"src\", \"maps\", \"are\", \"fun\"],\n *        mappings: \"AAAA,E;;ABCDE;\"\n *      }\n *    }],\n *  }\n *\n * The second parameter, if given, is a string whose value is the URL\n * at which the source map was found.  This URL is used to compute the\n * sources array.\n *\n * [0]: https://docs.google.com/document/d/1U1RGAehQwRypUTovF1KRlpiOFze0b-_2gc6fAH0KY0k/edit#heading=h.535es3xeprgt\n */\nfunction IndexedSourceMapConsumer(aSourceMap, aSourceMapURL) {\n  var sourceMap = aSourceMap;\n  if (typeof aSourceMap === 'string') {\n    sourceMap = util.parseSourceMapInput(aSourceMap);\n  }\n\n  var version = util.getArg(sourceMap, 'version');\n  var sections = util.getArg(sourceMap, 'sections');\n\n  if (version != this._version) {\n    throw new Error('Unsupported version: ' + version);\n  }\n\n  this._sources = new ArraySet();\n  this._names = new ArraySet();\n\n  var lastOffset = {\n    line: -1,\n    column: 0\n  };\n  this._sections = sections.map(function (s) {\n    if (s.url) {\n      // The url field will require support for asynchronicity.\n      // See https://github.com/mozilla/source-map/issues/16\n      throw new Error('Support for url field in sections not implemented.');\n    }\n    var offset = util.getArg(s, 'offset');\n    var offsetLine = util.getArg(offset, 'line');\n    var offsetColumn = util.getArg(offset, 'column');\n\n    if (offsetLine < lastOffset.line ||\n        (offsetLine === lastOffset.line && offsetColumn < lastOffset.column)) {\n      throw new Error('Section offsets must be ordered and non-overlapping.');\n    }\n    lastOffset = offset;\n\n    return {\n      generatedOffset: {\n        // The offset fields are 0-based, but we use 1-based indices when\n        // encoding/decoding from VLQ.\n        generatedLine: offsetLine + 1,\n        generatedColumn: offsetColumn + 1\n      },\n      consumer: new SourceMapConsumer(util.getArg(s, 'map'), aSourceMapURL)\n    }\n  });\n}\n\nIndexedSourceMapConsumer.prototype = Object.create(SourceMapConsumer.prototype);\nIndexedSourceMapConsumer.prototype.constructor = SourceMapConsumer;\n\n/**\n * The version of the source mapping spec that we are consuming.\n */\nIndexedSourceMapConsumer.prototype._version = 3;\n\n/**\n * The list of original sources.\n */\nObject.defineProperty(IndexedSourceMapConsumer.prototype, 'sources', {\n  get: function () {\n    var sources = [];\n    for (var i = 0; i < this._sections.length; i++) {\n      for (var j = 0; j < this._sections[i].consumer.sources.length; j++) {\n        sources.push(this._sections[i].consumer.sources[j]);\n      }\n    }\n    return sources;\n  }\n});\n\n/**\n * Returns the original source, line, and column information for the generated\n * source's line and column positions provided. The only argument is an object\n * with the following properties:\n *\n *   - line: The line number in the generated source.  The line number\n *     is 1-based.\n *   - column: The column number in the generated source.  The column\n *     number is 0-based.\n *\n * and an object is returned with the following properties:\n *\n *   - source: The original source file, or null.\n *   - line: The line number in the original source, or null.  The\n *     line number is 1-based.\n *   - column: The column number in the original source, or null.  The\n *     column number is 0-based.\n *   - name: The original identifier, or null.\n */\nIndexedSourceMapConsumer.prototype.originalPositionFor =\n  function IndexedSourceMapConsumer_originalPositionFor(aArgs) {\n    var needle = {\n      generatedLine: util.getArg(aArgs, 'line'),\n      generatedColumn: util.getArg(aArgs, 'column')\n    };\n\n    // Find the section containing the generated position we're trying to map\n    // to an original position.\n    var sectionIndex = binarySearch.search(needle, this._sections,\n      function(needle, section) {\n        var cmp = needle.generatedLine - section.generatedOffset.generatedLine;\n        if (cmp) {\n          return cmp;\n        }\n\n        return (needle.generatedColumn -\n                section.generatedOffset.generatedColumn);\n      });\n    var section = this._sections[sectionIndex];\n\n    if (!section) {\n      return {\n        source: null,\n        line: null,\n        column: null,\n        name: null\n      };\n    }\n\n    return section.consumer.originalPositionFor({\n      line: needle.generatedLine -\n        (section.generatedOffset.generatedLine - 1),\n      column: needle.generatedColumn -\n        (section.generatedOffset.generatedLine === needle.generatedLine\n         ? section.generatedOffset.generatedColumn - 1\n         : 0),\n      bias: aArgs.bias\n    });\n  };\n\n/**\n * Return true if we have the source content for every source in the source\n * map, false otherwise.\n */\nIndexedSourceMapConsumer.prototype.hasContentsOfAllSources =\n  function IndexedSourceMapConsumer_hasContentsOfAllSources() {\n    return this._sections.every(function (s) {\n      return s.consumer.hasContentsOfAllSources();\n    });\n  };\n\n/**\n * Returns the original source content. The only argument is the url of the\n * original source file. Returns null if no original source content is\n * available.\n */\nIndexedSourceMapConsumer.prototype.sourceContentFor =\n  function IndexedSourceMapConsumer_sourceContentFor(aSource, nullOnMissing) {\n    for (var i = 0; i < this._sections.length; i++) {\n      var section = this._sections[i];\n\n      var content = section.consumer.sourceContentFor(aSource, true);\n      if (content) {\n        return content;\n      }\n    }\n    if (nullOnMissing) {\n      return null;\n    }\n    else {\n      throw new Error('\"' + aSource + '\" is not in the SourceMap.');\n    }\n  };\n\n/**\n * Returns the generated line and column information for the original source,\n * line, and column positions provided. The only argument is an object with\n * the following properties:\n *\n *   - source: The filename of the original source.\n *   - line: The line number in the original source.  The line number\n *     is 1-based.\n *   - column: The column number in the original source.  The column\n *     number is 0-based.\n *\n * and an object is returned with the following properties:\n *\n *   - line: The line number in the generated source, or null.  The\n *     line number is 1-based. \n *   - column: The column number in the generated source, or null.\n *     The column number is 0-based.\n */\nIndexedSourceMapConsumer.prototype.generatedPositionFor =\n  function IndexedSourceMapConsumer_generatedPositionFor(aArgs) {\n    for (var i = 0; i < this._sections.length; i++) {\n      var section = this._sections[i];\n\n      // Only consider this section if the requested source is in the list of\n      // sources of the consumer.\n      if (section.consumer._findSourceIndex(util.getArg(aArgs, 'source')) === -1) {\n        continue;\n      }\n      var generatedPosition = section.consumer.generatedPositionFor(aArgs);\n      if (generatedPosition) {\n        var ret = {\n          line: generatedPosition.line +\n            (section.generatedOffset.generatedLine - 1),\n          column: generatedPosition.column +\n            (section.generatedOffset.generatedLine === generatedPosition.line\n             ? section.generatedOffset.generatedColumn - 1\n             : 0)\n        };\n        return ret;\n      }\n    }\n\n    return {\n      line: null,\n      column: null\n    };\n  };\n\n/**\n * Parse the mappings in a string in to a data structure which we can easily\n * query (the ordered arrays in the `this.__generatedMappings` and\n * `this.__originalMappings` properties).\n */\nIndexedSourceMapConsumer.prototype._parseMappings =\n  function IndexedSourceMapConsumer_parseMappings(aStr, aSourceRoot) {\n    this.__generatedMappings = [];\n    this.__originalMappings = [];\n    for (var i = 0; i < this._sections.length; i++) {\n      var section = this._sections[i];\n      var sectionMappings = section.consumer._generatedMappings;\n      for (var j = 0; j < sectionMappings.length; j++) {\n        var mapping = sectionMappings[j];\n\n        var source = section.consumer._sources.at(mapping.source);\n        source = util.computeSourceURL(section.consumer.sourceRoot, source, this._sourceMapURL);\n        this._sources.add(source);\n        source = this._sources.indexOf(source);\n\n        var name = null;\n        if (mapping.name) {\n          name = section.consumer._names.at(mapping.name);\n          this._names.add(name);\n          name = this._names.indexOf(name);\n        }\n\n        // The mappings coming from the consumer for the section have\n        // generated positions relative to the start of the section, so we\n        // need to offset them to be relative to the start of the concatenated\n        // generated file.\n        var adjustedMapping = {\n          source: source,\n          generatedLine: mapping.generatedLine +\n            (section.generatedOffset.generatedLine - 1),\n          generatedColumn: mapping.generatedColumn +\n            (section.generatedOffset.generatedLine === mapping.generatedLine\n            ? section.generatedOffset.generatedColumn - 1\n            : 0),\n          originalLine: mapping.originalLine,\n          originalColumn: mapping.originalColumn,\n          name: name\n        };\n\n        this.__generatedMappings.push(adjustedMapping);\n        if (typeof adjustedMapping.originalLine === 'number') {\n          this.__originalMappings.push(adjustedMapping);\n        }\n      }\n    }\n\n    quickSort(this.__generatedMappings, util.compareByGeneratedPositionsDeflated);\n    quickSort(this.__originalMappings, util.compareByOriginalPositions);\n  };\n\nexports.IndexedSourceMapConsumer = IndexedSourceMapConsumer;\n", "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar SourceMapGenerator = require('./source-map-generator').SourceMapGenerator;\nvar util = require('./util');\n\n// Matches a Windows-style `\\r\\n` newline or a `\\n` newline used by all other\n// operating systems these days (capturing the result).\nvar REGEX_NEWLINE = /(\\r?\\n)/;\n\n// Newline character code for charCodeAt() comparisons\nvar NEWLINE_CODE = 10;\n\n// Private symbol for identifying `SourceNode`s when multiple versions of\n// the source-map library are loaded. This MUST NOT CHANGE across\n// versions!\nvar isSourceNode = \"$$$isSourceNode$$$\";\n\n/**\n * SourceNodes provide a way to abstract over interpolating/concatenating\n * snippets of generated JavaScript source code while maintaining the line and\n * column information associated with the original source code.\n *\n * @param aLine The original line number.\n * @param aColumn The original column number.\n * @param aSource The original source's filename.\n * @param aChunks Optional. An array of strings which are snippets of\n *        generated JS, or other SourceNodes.\n * @param aName The original identifier.\n */\nfunction SourceNode(aLine, aColumn, aSource, aChunks, aName) {\n  this.children = [];\n  this.sourceContents = {};\n  this.line = aLine == null ? null : aLine;\n  this.column = aColumn == null ? null : aColumn;\n  this.source = aSource == null ? null : aSource;\n  this.name = aName == null ? null : aName;\n  this[isSourceNode] = true;\n  if (aChunks != null) this.add(aChunks);\n}\n\n/**\n * Creates a SourceNode from generated code and a SourceMapConsumer.\n *\n * @param aGeneratedCode The generated code\n * @param aSourceMapConsumer The SourceMap for the generated code\n * @param aRelativePath Optional. The path that relative sources in the\n *        SourceMapConsumer should be relative to.\n */\nSourceNode.fromStringWithSourceMap =\n  function SourceNode_fromStringWithSourceMap(aGeneratedCode, aSourceMapConsumer, aRelativePath) {\n    // The SourceNode we want to fill with the generated code\n    // and the SourceMap\n    var node = new SourceNode();\n\n    // All even indices of this array are one line of the generated code,\n    // while all odd indices are the newlines between two adjacent lines\n    // (since `REGEX_NEWLINE` captures its match).\n    // Processed fragments are accessed by calling `shiftNextLine`.\n    var remainingLines = aGeneratedCode.split(REGEX_NEWLINE);\n    var remainingLinesIndex = 0;\n    var shiftNextLine = function() {\n      var lineContents = getNextLine();\n      // The last line of a file might not have a newline.\n      var newLine = getNextLine() || \"\";\n      return lineContents + newLine;\n\n      function getNextLine() {\n        return remainingLinesIndex < remainingLines.length ?\n            remainingLines[remainingLinesIndex++] : undefined;\n      }\n    };\n\n    // We need to remember the position of \"remainingLines\"\n    var lastGeneratedLine = 1, lastGeneratedColumn = 0;\n\n    // The generate SourceNodes we need a code range.\n    // To extract it current and last mapping is used.\n    // Here we store the last mapping.\n    var lastMapping = null;\n\n    aSourceMapConsumer.eachMapping(function (mapping) {\n      if (lastMapping !== null) {\n        // We add the code from \"lastMapping\" to \"mapping\":\n        // First check if there is a new line in between.\n        if (lastGeneratedLine < mapping.generatedLine) {\n          // Associate first line with \"lastMapping\"\n          addMappingWithCode(lastMapping, shiftNextLine());\n          lastGeneratedLine++;\n          lastGeneratedColumn = 0;\n          // The remaining code is added without mapping\n        } else {\n          // There is no new line in between.\n          // Associate the code between \"lastGeneratedColumn\" and\n          // \"mapping.generatedColumn\" with \"lastMapping\"\n          var nextLine = remainingLines[remainingLinesIndex] || '';\n          var code = nextLine.substr(0, mapping.generatedColumn -\n                                        lastGeneratedColumn);\n          remainingLines[remainingLinesIndex] = nextLine.substr(mapping.generatedColumn -\n                                              lastGeneratedColumn);\n          lastGeneratedColumn = mapping.generatedColumn;\n          addMappingWithCode(lastMapping, code);\n          // No more remaining code, continue\n          lastMapping = mapping;\n          return;\n        }\n      }\n      // We add the generated code until the first mapping\n      // to the SourceNode without any mapping.\n      // Each line is added as separate string.\n      while (lastGeneratedLine < mapping.generatedLine) {\n        node.add(shiftNextLine());\n        lastGeneratedLine++;\n      }\n      if (lastGeneratedColumn < mapping.generatedColumn) {\n        var nextLine = remainingLines[remainingLinesIndex] || '';\n        node.add(nextLine.substr(0, mapping.generatedColumn));\n        remainingLines[remainingLinesIndex] = nextLine.substr(mapping.generatedColumn);\n        lastGeneratedColumn = mapping.generatedColumn;\n      }\n      lastMapping = mapping;\n    }, this);\n    // We have processed all mappings.\n    if (remainingLinesIndex < remainingLines.length) {\n      if (lastMapping) {\n        // Associate the remaining code in the current line with \"lastMapping\"\n        addMappingWithCode(lastMapping, shiftNextLine());\n      }\n      // and add the remaining lines without any mapping\n      node.add(remainingLines.splice(remainingLinesIndex).join(\"\"));\n    }\n\n    // Copy sourcesContent into SourceNode\n    aSourceMapConsumer.sources.forEach(function (sourceFile) {\n      var content = aSourceMapConsumer.sourceContentFor(sourceFile);\n      if (content != null) {\n        if (aRelativePath != null) {\n          sourceFile = util.join(aRelativePath, sourceFile);\n        }\n        node.setSourceContent(sourceFile, content);\n      }\n    });\n\n    return node;\n\n    function addMappingWithCode(mapping, code) {\n      if (mapping === null || mapping.source === undefined) {\n        node.add(code);\n      } else {\n        var source = aRelativePath\n          ? util.join(aRelativePath, mapping.source)\n          : mapping.source;\n        node.add(new SourceNode(mapping.originalLine,\n                                mapping.originalColumn,\n                                source,\n                                code,\n                                mapping.name));\n      }\n    }\n  };\n\n/**\n * Add a chunk of generated JS to this source node.\n *\n * @param aChunk A string snippet of generated JS code, another instance of\n *        SourceNode, or an array where each member is one of those things.\n */\nSourceNode.prototype.add = function SourceNode_add(aChunk) {\n  if (Array.isArray(aChunk)) {\n    aChunk.forEach(function (chunk) {\n      this.add(chunk);\n    }, this);\n  }\n  else if (aChunk[isSourceNode] || typeof aChunk === \"string\") {\n    if (aChunk) {\n      this.children.push(aChunk);\n    }\n  }\n  else {\n    throw new TypeError(\n      \"Expected a SourceNode, string, or an array of SourceNodes and strings. Got \" + aChunk\n    );\n  }\n  return this;\n};\n\n/**\n * Add a chunk of generated JS to the beginning of this source node.\n *\n * @param aChunk A string snippet of generated JS code, another instance of\n *        SourceNode, or an array where each member is one of those things.\n */\nSourceNode.prototype.prepend = function SourceNode_prepend(aChunk) {\n  if (Array.isArray(aChunk)) {\n    for (var i = aChunk.length-1; i >= 0; i--) {\n      this.prepend(aChunk[i]);\n    }\n  }\n  else if (aChunk[isSourceNode] || typeof aChunk === \"string\") {\n    this.children.unshift(aChunk);\n  }\n  else {\n    throw new TypeError(\n      \"Expected a SourceNode, string, or an array of SourceNodes and strings. Got \" + aChunk\n    );\n  }\n  return this;\n};\n\n/**\n * Walk over the tree of JS snippets in this node and its children. The\n * walking function is called once for each snippet of JS and is passed that\n * snippet and the its original associated source's line/column location.\n *\n * @param aFn The traversal function.\n */\nSourceNode.prototype.walk = function SourceNode_walk(aFn) {\n  var chunk;\n  for (var i = 0, len = this.children.length; i < len; i++) {\n    chunk = this.children[i];\n    if (chunk[isSourceNode]) {\n      chunk.walk(aFn);\n    }\n    else {\n      if (chunk !== '') {\n        aFn(chunk, { source: this.source,\n                     line: this.line,\n                     column: this.column,\n                     name: this.name });\n      }\n    }\n  }\n};\n\n/**\n * Like `String.prototype.join` except for SourceNodes. Inserts `aStr` between\n * each of `this.children`.\n *\n * @param aSep The separator.\n */\nSourceNode.prototype.join = function SourceNode_join(aSep) {\n  var newChildren;\n  var i;\n  var len = this.children.length;\n  if (len > 0) {\n    newChildren = [];\n    for (i = 0; i < len-1; i++) {\n      newChildren.push(this.children[i]);\n      newChildren.push(aSep);\n    }\n    newChildren.push(this.children[i]);\n    this.children = newChildren;\n  }\n  return this;\n};\n\n/**\n * Call String.prototype.replace on the very right-most source snippet. Useful\n * for trimming whitespace from the end of a source node, etc.\n *\n * @param aPattern The pattern to replace.\n * @param aReplacement The thing to replace the pattern with.\n */\nSourceNode.prototype.replaceRight = function SourceNode_replaceRight(aPattern, aReplacement) {\n  var lastChild = this.children[this.children.length - 1];\n  if (lastChild[isSourceNode]) {\n    lastChild.replaceRight(aPattern, aReplacement);\n  }\n  else if (typeof lastChild === 'string') {\n    this.children[this.children.length - 1] = lastChild.replace(aPattern, aReplacement);\n  }\n  else {\n    this.children.push(''.replace(aPattern, aReplacement));\n  }\n  return this;\n};\n\n/**\n * Set the source content for a source file. This will be added to the SourceMapGenerator\n * in the sourcesContent field.\n *\n * @param aSourceFile The filename of the source file\n * @param aSourceContent The content of the source file\n */\nSourceNode.prototype.setSourceContent =\n  function SourceNode_setSourceContent(aSourceFile, aSourceContent) {\n    this.sourceContents[util.toSetString(aSourceFile)] = aSourceContent;\n  };\n\n/**\n * Walk over the tree of SourceNodes. The walking function is called for each\n * source file content and is passed the filename and source content.\n *\n * @param aFn The traversal function.\n */\nSourceNode.prototype.walkSourceContents =\n  function SourceNode_walkSourceContents(aFn) {\n    for (var i = 0, len = this.children.length; i < len; i++) {\n      if (this.children[i][isSourceNode]) {\n        this.children[i].walkSourceContents(aFn);\n      }\n    }\n\n    var sources = Object.keys(this.sourceContents);\n    for (var i = 0, len = sources.length; i < len; i++) {\n      aFn(util.fromSetString(sources[i]), this.sourceContents[sources[i]]);\n    }\n  };\n\n/**\n * Return the string representation of this source node. Walks over the tree\n * and concatenates all the various snippets together to one string.\n */\nSourceNode.prototype.toString = function SourceNode_toString() {\n  var str = \"\";\n  this.walk(function (chunk) {\n    str += chunk;\n  });\n  return str;\n};\n\n/**\n * Returns the string representation of this source node along with a source\n * map.\n */\nSourceNode.prototype.toStringWithSourceMap = function SourceNode_toStringWithSourceMap(aArgs) {\n  var generated = {\n    code: \"\",\n    line: 1,\n    column: 0\n  };\n  var map = new SourceMapGenerator(aArgs);\n  var sourceMappingActive = false;\n  var lastOriginalSource = null;\n  var lastOriginalLine = null;\n  var lastOriginalColumn = null;\n  var lastOriginalName = null;\n  this.walk(function (chunk, original) {\n    generated.code += chunk;\n    if (original.source !== null\n        && original.line !== null\n        && original.column !== null) {\n      if(lastOriginalSource !== original.source\n         || lastOriginalLine !== original.line\n         || lastOriginalColumn !== original.column\n         || lastOriginalName !== original.name) {\n        map.addMapping({\n          source: original.source,\n          original: {\n            line: original.line,\n            column: original.column\n          },\n          generated: {\n            line: generated.line,\n            column: generated.column\n          },\n          name: original.name\n        });\n      }\n      lastOriginalSource = original.source;\n      lastOriginalLine = original.line;\n      lastOriginalColumn = original.column;\n      lastOriginalName = original.name;\n      sourceMappingActive = true;\n    } else if (sourceMappingActive) {\n      map.addMapping({\n        generated: {\n          line: generated.line,\n          column: generated.column\n        }\n      });\n      lastOriginalSource = null;\n      sourceMappingActive = false;\n    }\n    for (var idx = 0, length = chunk.length; idx < length; idx++) {\n      if (chunk.charCodeAt(idx) === NEWLINE_CODE) {\n        generated.line++;\n        generated.column = 0;\n        // Mappings end at eol\n        if (idx + 1 === length) {\n          lastOriginalSource = null;\n          sourceMappingActive = false;\n        } else if (sourceMappingActive) {\n          map.addMapping({\n            source: original.source,\n            original: {\n              line: original.line,\n              column: original.column\n            },\n            generated: {\n              line: generated.line,\n              column: generated.column\n            },\n            name: original.name\n          });\n        }\n      } else {\n        generated.column++;\n      }\n    }\n  });\n  this.walkSourceContents(function (sourceFile, sourceContent) {\n    map.setSourceContent(sourceFile, sourceContent);\n  });\n\n  return { code: generated.code, map: map };\n};\n\nexports.SourceNode = SourceNode;\n", "/*\n * Copyright 2009-2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE.txt or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\nexports.SourceMapGenerator = require('./lib/source-map-generator').SourceMapGenerator;\nexports.SourceMapConsumer = require('./lib/source-map-consumer').SourceMapConsumer;\nexports.SourceNode = require('./lib/source-node').SourceNode;\n", "var toString = Object.prototype.toString\n\nvar isModern = (\n  typeof Buffer.alloc === 'function' &&\n  typeof Buffer.allocUnsafe === 'function' &&\n  typeof Buffer.from === 'function'\n)\n\nfunction isArrayBuffer (input) {\n  return toString.call(input).slice(8, -1) === 'ArrayBuffer'\n}\n\nfunction fromArrayBuffer (obj, byteOffset, length) {\n  byteOffset >>>= 0\n\n  var maxLength = obj.byteLength - byteOffset\n\n  if (maxLength < 0) {\n    throw new RangeError(\"'offset' is out of bounds\")\n  }\n\n  if (length === undefined) {\n    length = maxLength\n  } else {\n    length >>>= 0\n\n    if (length > maxLength) {\n      throw new RangeError(\"'length' is out of bounds\")\n    }\n  }\n\n  return isModern\n    ? Buffer.from(obj.slice(byteOffset, byteOffset + length))\n    : new Buffer(new Uint8Array(obj.slice(byteOffset, byteOffset + length)))\n}\n\nfunction fromString (string, encoding) {\n  if (typeof encoding !== 'string' || encoding === '') {\n    encoding = 'utf8'\n  }\n\n  if (!Buffer.isEncoding(encoding)) {\n    throw new TypeError('\"encoding\" must be a valid string encoding')\n  }\n\n  return isModern\n    ? Buffer.from(string, encoding)\n    : new Buffer(string, encoding)\n}\n\nfunction bufferFrom (value, encodingOrOffset, length) {\n  if (typeof value === 'number') {\n    throw new TypeError('\"value\" argument must not be a number')\n  }\n\n  if (isArrayBuffer(value)) {\n    return fromArrayBuffer(value, encodingOrOffset, length)\n  }\n\n  if (typeof value === 'string') {\n    return fromString(value, encodingOrOffset)\n  }\n\n  return isModern\n    ? Buffer.from(value)\n    : new Buffer(value)\n}\n\nmodule.exports = bufferFrom\n", "var SourceMapConsumer = require('source-map').SourceMapConsumer;\nvar path = require('path');\n\nvar fs;\ntry {\n  fs = require('fs');\n  if (!fs.existsSync || !fs.readFileSync) {\n    // fs doesn't have all methods we need\n    fs = null;\n  }\n} catch (err) {\n  /* nop */\n}\n\nvar bufferFrom = require('buffer-from');\n\n/**\n * Requires a module which is protected against bundler minification.\n *\n * @param {NodeModule} mod\n * @param {string} request\n */\nfunction dynamicRequire(mod, request) {\n  return mod.require(request);\n}\n\n// Only install once if called multiple times\nvar errorFormatterInstalled = false;\nvar uncaughtShimInstalled = false;\n\n// If true, the caches are reset before a stack trace formatting operation\nvar emptyCacheBetweenOperations = false;\n\n// Supports {browser, node, auto}\nvar environment = \"auto\";\n\n// Maps a file path to a string containing the file contents\nvar fileContentsCache = {};\n\n// Maps a file path to a source map for that file\nvar sourceMapCache = {};\n\n// Regex for detecting source maps\nvar reSourceMap = /^data:application\\/json[^,]+base64,/;\n\n// Priority list of retrieve handlers\nvar retrieveFileHandlers = [];\nvar retrieveMapHandlers = [];\n\nfunction isInBrowser() {\n  if (environment === \"browser\")\n    return true;\n  if (environment === \"node\")\n    return false;\n  return ((typeof window !== 'undefined') && (typeof XMLHttpRequest === 'function') && !(window.require && window.module && window.process && window.process.type === \"renderer\"));\n}\n\nfunction hasGlobalProcessEventEmitter() {\n  return ((typeof process === 'object') && (process !== null) && (typeof process.on === 'function'));\n}\n\nfunction handlerExec(list) {\n  return function(arg) {\n    for (var i = 0; i < list.length; i++) {\n      var ret = list[i](arg);\n      if (ret) {\n        return ret;\n      }\n    }\n    return null;\n  };\n}\n\nvar retrieveFile = handlerExec(retrieveFileHandlers);\n\nretrieveFileHandlers.push(function(path) {\n  // Trim the path to make sure there is no extra whitespace.\n  path = path.trim();\n  if (/^file:/.test(path)) {\n    // existsSync/readFileSync can't handle file protocol, but once stripped, it works\n    path = path.replace(/file:\\/\\/\\/(\\w:)?/, function(protocol, drive) {\n      return drive ?\n        '' : // file:///C:/dir/file -> C:/dir/file\n        '/'; // file:///root-dir/file -> /root-dir/file\n    });\n  }\n  if (path in fileContentsCache) {\n    return fileContentsCache[path];\n  }\n\n  var contents = '';\n  try {\n    if (!fs) {\n      // Use SJAX if we are in the browser\n      var xhr = new XMLHttpRequest();\n      xhr.open('GET', path, /** async */ false);\n      xhr.send(null);\n      if (xhr.readyState === 4 && xhr.status === 200) {\n        contents = xhr.responseText;\n      }\n    } else if (fs.existsSync(path)) {\n      // Otherwise, use the filesystem\n      contents = fs.readFileSync(path, 'utf8');\n    }\n  } catch (er) {\n    /* ignore any errors */\n  }\n\n  return fileContentsCache[path] = contents;\n});\n\n// Support URLs relative to a directory, but be careful about a protocol prefix\n// in case we are in the browser (i.e. directories may start with \"http://\" or \"file:///\")\nfunction supportRelativeURL(file, url) {\n  if (!file) return url;\n  var dir = path.dirname(file);\n  var match = /^\\w+:\\/\\/[^\\/]*/.exec(dir);\n  var protocol = match ? match[0] : '';\n  var startPath = dir.slice(protocol.length);\n  if (protocol && /^\\/\\w\\:/.test(startPath)) {\n    // handle file:///C:/ paths\n    protocol += '/';\n    return protocol + path.resolve(dir.slice(protocol.length), url).replace(/\\\\/g, '/');\n  }\n  return protocol + path.resolve(dir.slice(protocol.length), url);\n}\n\nfunction retrieveSourceMapURL(source) {\n  var fileData;\n\n  if (isInBrowser()) {\n     try {\n       var xhr = new XMLHttpRequest();\n       xhr.open('GET', source, false);\n       xhr.send(null);\n       fileData = xhr.readyState === 4 ? xhr.responseText : null;\n\n       // Support providing a sourceMappingURL via the SourceMap header\n       var sourceMapHeader = xhr.getResponseHeader(\"SourceMap\") ||\n                             xhr.getResponseHeader(\"X-SourceMap\");\n       if (sourceMapHeader) {\n         return sourceMapHeader;\n       }\n     } catch (e) {\n     }\n  }\n\n  // Get the URL of the source map\n  fileData = retrieveFile(source);\n  var re = /(?:\\/\\/[@#][\\s]*sourceMappingURL=([^\\s'\"]+)[\\s]*$)|(?:\\/\\*[@#][\\s]*sourceMappingURL=([^\\s*'\"]+)[\\s]*(?:\\*\\/)[\\s]*$)/mg;\n  // Keep executing the search to find the *last* sourceMappingURL to avoid\n  // picking up sourceMappingURLs from comments, strings, etc.\n  var lastMatch, match;\n  while (match = re.exec(fileData)) lastMatch = match;\n  if (!lastMatch) return null;\n  return lastMatch[1];\n};\n\n// Can be overridden by the retrieveSourceMap option to install. Takes a\n// generated source filename; returns a {map, optional url} object, or null if\n// there is no source map.  The map field may be either a string or the parsed\n// JSON object (ie, it must be a valid argument to the SourceMapConsumer\n// constructor).\nvar retrieveSourceMap = handlerExec(retrieveMapHandlers);\nretrieveMapHandlers.push(function(source) {\n  var sourceMappingURL = retrieveSourceMapURL(source);\n  if (!sourceMappingURL) return null;\n\n  // Read the contents of the source map\n  var sourceMapData;\n  if (reSourceMap.test(sourceMappingURL)) {\n    // Support source map URL as a data url\n    var rawData = sourceMappingURL.slice(sourceMappingURL.indexOf(',') + 1);\n    sourceMapData = bufferFrom(rawData, \"base64\").toString();\n    sourceMappingURL = source;\n  } else {\n    // Support source map URLs relative to the source URL\n    sourceMappingURL = supportRelativeURL(source, sourceMappingURL);\n    sourceMapData = retrieveFile(sourceMappingURL);\n  }\n\n  if (!sourceMapData) {\n    return null;\n  }\n\n  return {\n    url: sourceMappingURL,\n    map: sourceMapData\n  };\n});\n\nfunction mapSourcePosition(position) {\n  var sourceMap = sourceMapCache[position.source];\n  if (!sourceMap) {\n    // Call the (overrideable) retrieveSourceMap function to get the source map.\n    var urlAndMap = retrieveSourceMap(position.source);\n    if (urlAndMap) {\n      sourceMap = sourceMapCache[position.source] = {\n        url: urlAndMap.url,\n        map: new SourceMapConsumer(urlAndMap.map)\n      };\n\n      // Load all sources stored inline with the source map into the file cache\n      // to pretend like they are already loaded. They may not exist on disk.\n      if (sourceMap.map.sourcesContent) {\n        sourceMap.map.sources.forEach(function(source, i) {\n          var contents = sourceMap.map.sourcesContent[i];\n          if (contents) {\n            var url = supportRelativeURL(sourceMap.url, source);\n            fileContentsCache[url] = contents;\n          }\n        });\n      }\n    } else {\n      sourceMap = sourceMapCache[position.source] = {\n        url: null,\n        map: null\n      };\n    }\n  }\n\n  // Resolve the source URL relative to the URL of the source map\n  if (sourceMap && sourceMap.map && typeof sourceMap.map.originalPositionFor === 'function') {\n    var originalPosition = sourceMap.map.originalPositionFor(position);\n\n    // Only return the original position if a matching line was found. If no\n    // matching line is found then we return position instead, which will cause\n    // the stack trace to print the path and line for the compiled file. It is\n    // better to give a precise location in the compiled file than a vague\n    // location in the original file.\n    if (originalPosition.source !== null) {\n      originalPosition.source = supportRelativeURL(\n        sourceMap.url, originalPosition.source);\n      return originalPosition;\n    }\n  }\n\n  return position;\n}\n\n// Parses code generated by FormatEvalOrigin(), a function inside V8:\n// https://code.google.com/p/v8/source/browse/trunk/src/messages.js\nfunction mapEvalOrigin(origin) {\n  // Most eval() calls are in this format\n  var match = /^eval at ([^(]+) \\((.+):(\\d+):(\\d+)\\)$/.exec(origin);\n  if (match) {\n    var position = mapSourcePosition({\n      source: match[2],\n      line: +match[3],\n      column: match[4] - 1\n    });\n    return 'eval at ' + match[1] + ' (' + position.source + ':' +\n      position.line + ':' + (position.column + 1) + ')';\n  }\n\n  // Parse nested eval() calls using recursion\n  match = /^eval at ([^(]+) \\((.+)\\)$/.exec(origin);\n  if (match) {\n    return 'eval at ' + match[1] + ' (' + mapEvalOrigin(match[2]) + ')';\n  }\n\n  // Make sure we still return useful information if we didn't find anything\n  return origin;\n}\n\n// This is copied almost verbatim from the V8 source code at\n// https://code.google.com/p/v8/source/browse/trunk/src/messages.js. The\n// implementation of wrapCallSite() used to just forward to the actual source\n// code of CallSite.prototype.toString but unfortunately a new release of V8\n// did something to the prototype chain and broke the shim. The only fix I\n// could find was copy/paste.\nfunction CallSiteToString() {\n  var fileName;\n  var fileLocation = \"\";\n  if (this.isNative()) {\n    fileLocation = \"native\";\n  } else {\n    fileName = this.getScriptNameOrSourceURL();\n    if (!fileName && this.isEval()) {\n      fileLocation = this.getEvalOrigin();\n      fileLocation += \", \";  // Expecting source position to follow.\n    }\n\n    if (fileName) {\n      fileLocation += fileName;\n    } else {\n      // Source code does not originate from a file and is not native, but we\n      // can still get the source position inside the source string, e.g. in\n      // an eval string.\n      fileLocation += \"<anonymous>\";\n    }\n    var lineNumber = this.getLineNumber();\n    if (lineNumber != null) {\n      fileLocation += \":\" + lineNumber;\n      var columnNumber = this.getColumnNumber();\n      if (columnNumber) {\n        fileLocation += \":\" + columnNumber;\n      }\n    }\n  }\n\n  var line = \"\";\n  var functionName = this.getFunctionName();\n  var addSuffix = true;\n  var isConstructor = this.isConstructor();\n  var isMethodCall = !(this.isToplevel() || isConstructor);\n  if (isMethodCall) {\n    var typeName = this.getTypeName();\n    // Fixes shim to be backward compatable with Node v0 to v4\n    if (typeName === \"[object Object]\") {\n      typeName = \"null\";\n    }\n    var methodName = this.getMethodName();\n    if (functionName) {\n      if (typeName && functionName.indexOf(typeName) != 0) {\n        line += typeName + \".\";\n      }\n      line += functionName;\n      if (methodName && functionName.indexOf(\".\" + methodName) != functionName.length - methodName.length - 1) {\n        line += \" [as \" + methodName + \"]\";\n      }\n    } else {\n      line += typeName + \".\" + (methodName || \"<anonymous>\");\n    }\n  } else if (isConstructor) {\n    line += \"new \" + (functionName || \"<anonymous>\");\n  } else if (functionName) {\n    line += functionName;\n  } else {\n    line += fileLocation;\n    addSuffix = false;\n  }\n  if (addSuffix) {\n    line += \" (\" + fileLocation + \")\";\n  }\n  return line;\n}\n\nfunction cloneCallSite(frame) {\n  var object = {};\n  Object.getOwnPropertyNames(Object.getPrototypeOf(frame)).forEach(function(name) {\n    object[name] = /^(?:is|get)/.test(name) ? function() { return frame[name].call(frame); } : frame[name];\n  });\n  object.toString = CallSiteToString;\n  return object;\n}\n\nfunction wrapCallSite(frame, state) {\n  // provides interface backward compatibility\n  if (state === undefined) {\n    state = { nextPosition: null, curPosition: null }\n  }\n  if(frame.isNative()) {\n    state.curPosition = null;\n    return frame;\n  }\n\n  // Most call sites will return the source file from getFileName(), but code\n  // passed to eval() ending in \"//# sourceURL=...\" will return the source file\n  // from getScriptNameOrSourceURL() instead\n  var source = frame.getFileName() || frame.getScriptNameOrSourceURL();\n  if (source) {\n    var line = frame.getLineNumber();\n    var column = frame.getColumnNumber() - 1;\n\n    // Fix position in Node where some (internal) code is prepended.\n    // See https://github.com/evanw/node-source-map-support/issues/36\n    // Header removed in node at ^10.16 || >=11.11.0\n    // v11 is not an LTS candidate, we can just test the one version with it.\n    // Test node versions for: 10.16-19, 10.20+, 12-19, 20-99, 100+, or 11.11\n    var noHeader = /^v(10\\.1[6-9]|10\\.[2-9][0-9]|10\\.[0-9]{3,}|1[2-9]\\d*|[2-9]\\d|\\d{3,}|11\\.11)/;\n    var headerLength = noHeader.test(process.version) ? 0 : 62;\n    if (line === 1 && column > headerLength && !isInBrowser() && !frame.isEval()) {\n      column -= headerLength;\n    }\n\n    var position = mapSourcePosition({\n      source: source,\n      line: line,\n      column: column\n    });\n    state.curPosition = position;\n    frame = cloneCallSite(frame);\n    var originalFunctionName = frame.getFunctionName;\n    frame.getFunctionName = function() {\n      if (state.nextPosition == null) {\n        return originalFunctionName();\n      }\n      return state.nextPosition.name || originalFunctionName();\n    };\n    frame.getFileName = function() { return position.source; };\n    frame.getLineNumber = function() { return position.line; };\n    frame.getColumnNumber = function() { return position.column + 1; };\n    frame.getScriptNameOrSourceURL = function() { return position.source; };\n    return frame;\n  }\n\n  // Code called using eval() needs special handling\n  var origin = frame.isEval() && frame.getEvalOrigin();\n  if (origin) {\n    origin = mapEvalOrigin(origin);\n    frame = cloneCallSite(frame);\n    frame.getEvalOrigin = function() { return origin; };\n    return frame;\n  }\n\n  // If we get here then we were unable to change the source position\n  return frame;\n}\n\n// This function is part of the V8 stack trace API, for more info see:\n// https://v8.dev/docs/stack-trace-api\nfunction prepareStackTrace(error, stack) {\n  if (emptyCacheBetweenOperations) {\n    fileContentsCache = {};\n    sourceMapCache = {};\n  }\n\n  var name = error.name || 'Error';\n  var message = error.message || '';\n  var errorString = name + \": \" + message;\n\n  var state = { nextPosition: null, curPosition: null };\n  var processedStack = [];\n  for (var i = stack.length - 1; i >= 0; i--) {\n    processedStack.push('\\n    at ' + wrapCallSite(stack[i], state));\n    state.nextPosition = state.curPosition;\n  }\n  state.curPosition = state.nextPosition = null;\n  return errorString + processedStack.reverse().join('');\n}\n\n// Generate position and snippet of original source with pointer\nfunction getErrorSource(error) {\n  var match = /\\n    at [^(]+ \\((.*):(\\d+):(\\d+)\\)/.exec(error.stack);\n  if (match) {\n    var source = match[1];\n    var line = +match[2];\n    var column = +match[3];\n\n    // Support the inline sourceContents inside the source map\n    var contents = fileContentsCache[source];\n\n    // Support files on disk\n    if (!contents && fs && fs.existsSync(source)) {\n      try {\n        contents = fs.readFileSync(source, 'utf8');\n      } catch (er) {\n        contents = '';\n      }\n    }\n\n    // Format the line from the original source code like node does\n    if (contents) {\n      var code = contents.split(/(?:\\r\\n|\\r|\\n)/)[line - 1];\n      if (code) {\n        return source + ':' + line + '\\n' + code + '\\n' +\n          new Array(column).join(' ') + '^';\n      }\n    }\n  }\n  return null;\n}\n\nfunction printErrorAndExit (error) {\n  var source = getErrorSource(error);\n\n  // Ensure error is printed synchronously and not truncated\n  if (process.stderr._handle && process.stderr._handle.setBlocking) {\n    process.stderr._handle.setBlocking(true);\n  }\n\n  if (source) {\n    console.error();\n    console.error(source);\n  }\n\n  console.error(error.stack);\n  process.exit(1);\n}\n\nfunction shimEmitUncaughtException () {\n  var origEmit = process.emit;\n\n  process.emit = function (type) {\n    if (type === 'uncaughtException') {\n      var hasStack = (arguments[1] && arguments[1].stack);\n      var hasListeners = (this.listeners(type).length > 0);\n\n      if (hasStack && !hasListeners) {\n        return printErrorAndExit(arguments[1]);\n      }\n    }\n\n    return origEmit.apply(this, arguments);\n  };\n}\n\nvar originalRetrieveFileHandlers = retrieveFileHandlers.slice(0);\nvar originalRetrieveMapHandlers = retrieveMapHandlers.slice(0);\n\nexports.wrapCallSite = wrapCallSite;\nexports.getErrorSource = getErrorSource;\nexports.mapSourcePosition = mapSourcePosition;\nexports.retrieveSourceMap = retrieveSourceMap;\n\nexports.install = function(options) {\n  options = options || {};\n\n  if (options.environment) {\n    environment = options.environment;\n    if ([\"node\", \"browser\", \"auto\"].indexOf(environment) === -1) {\n      throw new Error(\"environment \" + environment + \" was unknown. Available options are {auto, browser, node}\")\n    }\n  }\n\n  // Allow sources to be found by methods other than reading the files\n  // directly from disk.\n  if (options.retrieveFile) {\n    if (options.overrideRetrieveFile) {\n      retrieveFileHandlers.length = 0;\n    }\n\n    retrieveFileHandlers.unshift(options.retrieveFile);\n  }\n\n  // Allow source maps to be found by methods other than reading the files\n  // directly from disk.\n  if (options.retrieveSourceMap) {\n    if (options.overrideRetrieveSourceMap) {\n      retrieveMapHandlers.length = 0;\n    }\n\n    retrieveMapHandlers.unshift(options.retrieveSourceMap);\n  }\n\n  // Support runtime transpilers that include inline source maps\n  if (options.hookRequire && !isInBrowser()) {\n    // Use dynamicRequire to avoid including in browser bundles\n    var Module = dynamicRequire(module, 'module');\n    var $compile = Module.prototype._compile;\n\n    if (!$compile.__sourceMapSupport) {\n      Module.prototype._compile = function(content, filename) {\n        fileContentsCache[filename] = content;\n        sourceMapCache[filename] = undefined;\n        return $compile.call(this, content, filename);\n      };\n\n      Module.prototype._compile.__sourceMapSupport = true;\n    }\n  }\n\n  // Configure options\n  if (!emptyCacheBetweenOperations) {\n    emptyCacheBetweenOperations = 'emptyCacheBetweenOperations' in options ?\n      options.emptyCacheBetweenOperations : false;\n  }\n\n  // Install the error reformatter\n  if (!errorFormatterInstalled) {\n    errorFormatterInstalled = true;\n    Error.prepareStackTrace = prepareStackTrace;\n  }\n\n  if (!uncaughtShimInstalled) {\n    var installHandler = 'handleUncaughtExceptions' in options ?\n      options.handleUncaughtExceptions : true;\n\n    // Do not override 'uncaughtException' with our own handler in Node.js\n    // Worker threads. Workers pass the error to the main thread as an event,\n    // rather than printing something to stderr and exiting.\n    try {\n      // We need to use `dynamicRequire` because `require` on it's own will be optimized by WebPack/Browserify.\n      var worker_threads = dynamicRequire(module, 'worker_threads');\n      if (worker_threads.isMainThread === false) {\n        installHandler = false;\n      }\n    } catch(e) {}\n\n    // Provide the option to not install the uncaught exception handler. This is\n    // to support other uncaught exception handlers (in test frameworks, for\n    // example). If this handler is not installed and there are no other uncaught\n    // exception handlers, uncaught exceptions will be caught by node's built-in\n    // exception handler and the process will still be terminated. However, the\n    // generated JavaScript code will be shown above the stack trace instead of\n    // the original source code.\n    if (installHandler && hasGlobalProcessEventEmitter()) {\n      uncaughtShimInstalled = true;\n      shimEmitUncaughtException();\n    }\n  }\n};\n\nexports.resetRetrieveHandlers = function() {\n  retrieveFileHandlers.length = 0;\n  retrieveMapHandlers.length = 0;\n\n  retrieveFileHandlers = originalRetrieveFileHandlers.slice(0);\n  retrieveMapHandlers = originalRetrieveMapHandlers.slice(0);\n\n  retrieveSourceMap = handlerExec(retrieveMapHandlers);\n  retrieveFile = handlerExec(retrieveFileHandlers);\n}\n", "import { Command, program } from \"commander\"\nimport p from \"process\"\nimport { Pojo } from \"../../core/Object\"\nimport { ServiceName, setServiceName } from \"../../core/ServiceNames\"\nimport { version } from \"../../core/Version\"\nimport { mapNotBlankOr } from \"../../fe/Blank\"\nimport { map } from \"../../fe/Maybe\"\nimport { addFooter, CliDesc } from \"./CliConstants\"\n\nexport interface CommandPlugin {\n  beforeParse(cmd: Command): Command\n  afterParse(opts: Pojo): void\n}\n\nexport class CLI {\n  private readonly plugins: CommandPlugin[] = []\n\n  /**\n   * @param args if non-empty, passed to `Command.arguments()`\n   */\n  constructor(\n    readonly serviceName: keyof typeof CliDesc & ServiceName,\n    readonly args?: string,\n    readonly additionalDescription?: string\n  ) {\n    setServiceName(serviceName)\n  }\n\n  add(...plugins: CommandPlugin[]) {\n    this.plugins.push(...plugins)\n    return this\n  }\n\n  async parse() {\n    let cmd = addFooter(\n      program.description(\n        CliDesc[this.serviceName] +\n          mapNotBlankOr(\n            this.additionalDescription,\n            ea => \"\\n\\n\" + ea,\n            () => \"\"\n          )\n      ) as Command\n    )\n\n    map(this.args, ea => {\n      cmd = cmd.arguments(ea)\n    })\n\n    for (const ea of this.plugins) {\n      cmd = ea.beforeParse(cmd)\n    }\n\n    cmd.version(\n      version,\n      \"--version\",\n      \"Output the version number (spoiler: it's \" + version + \")\"\n    )\n\n    cmd.parse(p.argv)\n\n    const opts = cmd.opts()\n\n    for (const ea of this.plugins) {\n      await ea.afterParse(opts)\n    }\n\n    return cmd\n  }\n}\n", "import { pid } from \"process\"\nimport { compactBlanks } from \"../fe/Array\"\nimport { blank } from \"../fe/Blank\"\nimport { minuteMs, secondMs } from \"../fe/Date\"\nimport { lazy } from \"../fe/Lazy\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { strEnum, StrEnumKeys } from \"../fe/StrEnum\"\nimport { toS } from \"../fe/toS\"\nimport { AppName } from \"./AppName\"\nimport {\n  bgBlack,\n  blue,\n  blueBright,\n  cyan,\n  green,\n  magenta,\n  red,\n  yellow\n} from \"./Chalk\"\nimport { setupLogger } from \"./Logger\"\nimport { isTest } from \"./NodeEnv\"\n\nexport const ServiceNames = strEnum(\n  \"main\",\n  \"web\",\n  \"sync\",\n  \"sync-file\",\n  \"info\",\n  \"test\",\n  \"logcat\",\n  \"logtail\",\n  \"list\",\n  \"billing\"\n)\n\nexport type ServiceName = StrEnumKeys<typeof ServiceNames>\n\nexport function serviceNameIndex(s: Maybe<ServiceName>): number {\n  const idx = ServiceNames.indexOf(s)\n  return idx < 0 ? ServiceNames.length + 1 : idx\n}\n\nexport const RpcServerServices: ServiceName[] = [\"main\", \"test\"]\n\n/**\n * These are the only services that don't require a library to start up\n */\nexport const WelcomeServices: ServiceName[] = [\"main\", \"web\", \"test\", \"info\"]\nexport const StatsDbServices: ServiceName[] = [\"sync\", \"sync-file\"]\n\nexport function title(service: ServiceName): string {\n  return AppName() + \" \" + service\n}\n\nexport function serviceShutdownTimeoutMs(service: ServiceName): number {\n  switch (service) {\n    case \"main\":\n    case \"web\":\n      return minuteMs // time to vacuum and restore the db to the library\n    case \"sync\":\n    case \"sync-file\":\n    default:\n      return 10 * secondMs // time to finish a given import\n  }\n}\n\nlet _serviceName: ServiceName = \"\" as any\n\nexport function serviceName() {\n  if (blank(_serviceName)) throw Error(\"serviceName() is unset\")\n  return _serviceName\n}\n\nexport function setServiceName(s: ServiceName) {\n  if (!isTest && s !== _serviceName && (_serviceName as any) !== \"\") {\n    throw new Error(\"Cannot set service name twice\")\n  }\n  _serviceName = s\n  processName.unset()\n  setupLogger()\n}\n\nexport function maybeSetServiceName(s: ServiceName) {\n  if (!isTest) throw new Error(\"Only used by tests\")\n  if (blank(_serviceName)) setServiceName(s)\n}\n\nconst procColors = lazy(() => [\n  { re: /sync-file|billing/, f: cyan },\n  { re: /sync/, f: blue },\n  { re: /web/, f: green },\n  { re: /db/, f: magenta },\n  { re: /main/, f: yellow },\n  { re: /info/, f: blueBright },\n  { re: /test/, f: red }\n])\n\nexport const processName = lazy(() =>\n  compactBlanks([_serviceName, toS(pid)]).join(\"-\")\n)\n\nexport function colorProcessName(s: string): string {\n  const pc = procColors().find(ea => s.match(ea.re))\n  return pc != null ? bgBlack(pc.f(s)) : s\n}\n\nexport function isMainService() {\n  // This is called by Library: don't call serviceName(), which throws an error,\n  // because that fails tests. If it's the main service, main service will have\n  // set this properly.\n  return _serviceName === ServiceNames.main\n}\n\nexport function isWebService() {\n  // This is called by Library: don't call serviceName(), which throws an error,\n  // because that fails tests. If it's the main service, main service will have\n  // set this properly.\n  return _serviceName === ServiceNames.web\n}\n\n/**\n * This process should host the RPC event orchestration service and run the\n * Model DB Janitor service.\n */\nexport function isRpcServer(): boolean {\n  return RpcServerServices.includes(serviceName())\n}\n\nexport function isRpcClient(): boolean {\n  return !isRpcServer() && _serviceName !== \"info\"\n}\n\nexport function isSyncService() {\n  // This is called by StdoutWrite: don't call serviceName().\n  return _serviceName === \"sync\"\n}\n\nexport function isSyncFileService() {\n  // This is called by StdoutWrite: don't call serviceName().\n  return _serviceName === \"sync-file\"\n}\n\n/**\n * These are services that can run without a set library.\n */\nexport function isWelcomeService() {\n  return WelcomeServices.includes(serviceName())\n}\n\nexport function isStatsDbClient() {\n  // This is called by StdoutWrite: don't call serviceName().\n  return StatsDbServices.includes(serviceName())\n}\n\n// lazy for tests to .set():\nexport const isStatsDbMigrator = lazy(\n  () => isSyncService() || (isTest && !isSyncFileService())\n)\n", "/**\n * @return true if obj is both Iterable *and not a string* (because srsly wth)\n */\nexport function isIterable(obj: any): obj is Iterable<any> {\n  return (\n    obj != null &&\n    typeof obj !== \"string\" &&\n    typeof obj[Symbol.iterator] === \"function\"\n  )\n}\n\n// export function max<T>(i: Iterable<T>, f: (t: T) => Comparable): Maybe<T> {\n//   let result = undefined\n//   let m = undefined\n//   for (const ea of i) {\n//     const r = f(ea)\n//     if (m == null || m < r) {\n//       m = r\n//       result = ea\n//     }\n//   }\n//   return result\n// }\n", "/**\n * Similar to `String(a)`, but `undefined` and `null` render as \"\", arrays are\n * comma-separated with no square bracket prefix/suffix\n */\nexport function toS(a?: any | any[]): string {\n  // PERF: unrolled\n  return a == null\n    ? \"\"\n    : typeof a === \"string\"\n    ? a\n    : Array.isArray(a)\n    ? a.map(toS).join(\",\")\n    : a.toString()\n}\n", "import { isEmpty } from \"./Array\"\nimport { Maybe, MaybeNull } from \"./MaybeTypes\"\nimport { toS } from \"./toS\"\n\nexport type Primitive = number | string | boolean | Date\nconst primitiveTypes = [\"number\", \"string\", \"boolean\"]\n\nexport interface PrimitiveValued {\n  [key: string]: Primitive\n}\n\nexport interface Primitivable {\n  valueOf(): Primitive\n}\n\nexport interface Primitivables {\n  valueOf(): Primitive[]\n}\n\nexport type Comparable = Primitive | (Primitive | Primitive[])[]\n\nexport function isPrimitive(obj: any): obj is Primitive {\n  return primitiveTypes.indexOf(typeof obj) !== -1 || obj instanceof Date\n}\n\nexport function mapPrimitive<T>(a: any, f: (t: Primitive) => T): Maybe<T> {\n  return isPrimitive(a) ? f(a) : undefined\n}\n\nexport function mapPrimitiveOr<T>(\n  a: any,\n  f: (t: Primitive) => T,\n  defaultValue: () => T\n): Maybe<T> {\n  return isPrimitive(a) ? f(a) : defaultValue()\n}\n\nexport function isPrimitiveArray(obj: any): obj is Primitive[] {\n  return Array.isArray(obj) && (obj as any[]).every(isPrimitive)\n}\n\n// export function cmp<T extends Comparable | Comparable[]>(\n//   a: MaybeNull<T>,\n//   b: MaybeNull<T>\n// ): number {\n//   return tap(_cmp(a, b), result => console.log(\"cmp\", { a, b, result }))\n// }\n\n// See https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/typeof\nconst TypeLevel = [\n  \"boolean\",\n  \"number\",\n  \"bigint\",\n  \"symbol\",\n  \"string\",\n  \"object\",\n  \"function\"\n] // typeof array is \"object\"\n\n/**\n * (null || undefined) < false < true < numbers < strings < arrays\n * @return 1 if a > b, -1 if a < b, 0 if a == b.\n */\nexport function cmp<T extends Comparable | Comparable[]>(\n  a: MaybeNull<T>,\n  b: MaybeNull<T>\n): number {\n  // undefined == undefined:\n  if (a == null && b == null) return 0\n\n  // undefined should be < defined. We can't use typeof here because typeof null\n  // is \"object\" and typeof undefined = \"undefined\".\n  if (a == null) return -1\n  if (b == null) return 1\n\n  const aType = typeof a\n  const bType = typeof b\n\n  if (\n    (aType === \"string\" || aType === \"symbol\") &&\n    (bType === \"string\" || bType === \"symbol\")\n  ) {\n    // in German, \u00E4 sorts before z, in Swedish, \u00E4 sorts after z\n    return toS(a).localeCompare(toS(b))\n  }\n  if (Array.isArray(a) && Array.isArray(b)) {\n    return cmpArr(a as any, b as any) // SITS: TS 4.1 required /as any/\n  }\n  if (aType !== bType) {\n    return TypeLevel.indexOf(aType) - TypeLevel.indexOf(bType)\n  } else {\n    return a > b ? 1 : a < b ? -1 : 0\n  }\n}\n\nexport function lt<T extends Comparable>(\n  a: MaybeNull<T>,\n  b: MaybeNull<T>\n): boolean {\n  return cmp(a, b) < 0\n}\n\nexport function lte<T extends Comparable>(\n  a: MaybeNull<T>,\n  b: MaybeNull<T>\n): boolean {\n  return cmp(a, b) <= 0\n}\n\nexport function gte<T extends Comparable>(\n  a: MaybeNull<T>,\n  b: MaybeNull<T>\n): boolean {\n  return cmp(a, b) >= 0\n}\n\nexport function gt<T extends Comparable>(\n  a: MaybeNull<T>,\n  b: MaybeNull<T>\n): boolean {\n  return cmp(a, b) > 0\n}\n\nexport function cmpArr<T extends Primitive>(a: T[], b: T[]): number {\n  if (isEmpty(a) && isEmpty(b)) return 0\n  const len = Math.min(a.length, b.length)\n  for (let i = 0; i < len; i++) {\n    const c = cmp(a[i], b[i])\n    if (c !== 0) {\n      return c\n    }\n  }\n  return cmp(a.length, b.length)\n}\n", "import { isIterable } from \"./Iterable\"\nimport { Defined } from \"./Maybe\"\nimport { isPrimitive } from \"./Primitive\"\n\n// eslint-disable-next-line no-shadow\nexport enum ObjectType {\n  Empty,\n  Primitive,\n  Symbol,\n  Object,\n  Array,\n  Iterable,\n  Instance,\n  Function,\n  Unknown\n}\n\nexport function isSymbol(obj: any): obj is symbol {\n  return typeof obj === \"symbol\"\n}\n\n// eslint-disable-next-line @typescript-eslint/ban-types\nexport function isFunction(obj: any): obj is Function {\n  return typeof obj === \"function\"\n}\n\n// eslint-disable-next-line @typescript-eslint/ban-types\nexport function isObject(obj: any): obj is Defined<any> {\n  return objectType(obj) === ObjectType.Object\n}\n\nexport function objectType(t: any): ObjectType {\n  if (t == null) {\n    return ObjectType.Empty\n  } else if (isSymbol(t)) {\n    return ObjectType.Symbol\n  } else if (isPrimitive(t)) {\n    return ObjectType.Primitive\n  } else if (Array.isArray(t)) {\n    return ObjectType.Array\n  } else if (isIterable(t)) {\n    return ObjectType.Iterable\n  } else if (isFunction(t)) {\n    return ObjectType.Function\n  } else if (typeof t === \"object\") {\n    // we're in fe, we can't use ?. TODO FIXME\n    return t.constructor != null && t.constructor.name === \"Object\"\n      ? ObjectType.Object\n      : ObjectType.Instance\n  } else {\n    return ObjectType.Unknown\n  }\n}\n", "import { Maybe } from \"./MaybeTypes\"\nimport { isFunction } from \"./ObjectType\"\n\nexport interface Thunk<T> {\n  (): T\n}\n\nexport type ThunkOrT<T> = T | Thunk<T>\n\n/**\n * Convert a ThunkOrT into a T.\n *\n * Caution: Don't have T be a function type!\n */\nexport function tot<T>(t: ThunkOrT<T>): T {\n  return isFunction(t) ? t() : t\n}\n\nexport interface ThunkMaybe<T> {\n  (): Maybe<T>\n}\n\nexport function firstDefinedThunk<T>(iter: Iterable<ThunkMaybe<T>>): Maybe<T> {\n  for (const f of iter) {\n    const result = f()\n    if (result != null) return result\n  }\n  return\n}\n\nexport const NoOp = () => undefined\n", "import { Maybe, MaybeNull } from \"./MaybeTypes\"\nimport { ThunkOrT, tot } from \"./Thunk\"\nimport { toS } from \"./toS\"\n\nexport function map<T, U>(obj: MaybeNull<T>, f: (t: T) => U): Maybe<U> {\n  return obj == null ? undefined : f(obj)\n}\n\nexport function mapTry<T, U>(f: () => MaybeNull<T>, g: (t: T) => U): Maybe<U> {\n  try {\n    return map(f(), g)\n  } catch {\n    return\n  }\n}\n\nexport function map2<T1, T2, U>(\n  t1: MaybeNull<T1>,\n  t2: MaybeNull<T2>,\n  f: (ea1: T1, ea2: T2) => U\n): Maybe<U> {\n  return t1 == null || t2 == null ? undefined : f(t1, t2)\n}\n\nexport function map3<T1, T2, T3, U>(\n  t1: MaybeNull<T1>,\n  t2: MaybeNull<T2>,\n  t3: MaybeNull<T3>,\n  f: (ea1: T1, ea2: T2, ea3: T3) => U\n): Maybe<U> {\n  return t1 == null || t2 == null || t3 == null ? undefined : f(t1, t2, t3)\n}\n\nexport function orElse<T>(obj: MaybeNull<T>, defaultValue: ThunkOrT<T>): T {\n  return obj != null ? obj : tot(defaultValue)\n}\n\nexport function mapOr<T, U>(\n  obj: MaybeNull<T>,\n  f: (t: T) => U,\n  defaultValue: ThunkOrT<U>\n): U {\n  return obj != null ? f(obj) : tot(defaultValue)\n}\n\nexport function map2Or<T1, T2, U>(\n  t1: MaybeNull<T1>,\n  t2: MaybeNull<T2>,\n  f: (ea1: T1, ea2: T2) => U,\n  defaultValue: () => U\n): U {\n  return orElse(map2(t1, t2, f), defaultValue)\n}\n\n// https://www.typescriptlang.org/docs/handbook/advanced-types.html#predefined-conditional-types\n\nexport type Diff<T, U> = T extends U ? never : T\n\nexport type Unpick<T, U> = { [P in keyof T]: P extends U ? never : T[P] }\n\nexport type Defined<T> = Diff<T, null | undefined | void>\n\n/**\n * @return true iff all `objects` are not `null` or `undefined`\n */\nexport function defined<T>(object: T): object is Defined<T> {\n  return object != null\n}\n\nexport function allDefined<T>(arr: T[]): arr is Defined<T>[] {\n  return arr != null && arr.every(defined)\n}\n\nexport function firstDefined<T>(...objects: MaybeNull<T>[]): Maybe<T> {\n  return objects.find(defined)\n}\n\nexport function denull<T>(t: T | undefined | null): T | undefined {\n  return t == null || toS(t) === \"null\" ? undefined : t\n}\n\nexport function nulled<T>(t: T | undefined | null): T | null {\n  return t == null ? null : t\n}\n", "import { Defined, orElse } from \"./Maybe\"\nimport { Maybe, MaybeNull } from \"./MaybeTypes\"\nimport { ThunkOrT, tot } from \"./Thunk\"\nimport { toS } from \"./toS\"\n\nexport function blank(o: any): o is undefined {\n  // PERF: unrolled from Opt\n  if (o == null) return true\n  const s = toS(o)\n  return s.length === 0 || s.trim().length === 0\n}\n\nconst BlankishRE = /^\\s*(?:null|undefined)?\\s*$/i\n\nexport function blankish(s: Maybe<string>): s is undefined {\n  return s == null || BlankishRE.exec(s) != null\n}\n\nexport function notBlank<T>(s: T): s is Defined<T> {\n  return !blank(s)\n}\n\n// aka \"trimToUndefined\"\nexport function ifNotBlank(o: any): Maybe<string> {\n  if (o == null) return\n  const s = toS(o)\n  return s.length === 0 || s.trim().length === 0 ? undefined : s\n}\n\n/**\n * Equivalent to `Opt(s).flatMap(toS).filter(notBlank).getOrElse(() => orElse)`\n */\nexport function notBlankOr(s: any, ifBlank: ThunkOrT<string>): string {\n  if (s == null) return tot(ifBlank)\n  const str = toS(s).trim()\n  return str.length > 0 ? str : tot(ifBlank)\n}\n\nexport function notBlankAnd(s: any, f: (ea: string) => boolean): boolean {\n  return !blank(s) ? f(s) : false\n}\n\nexport function mapNotBlank<T>(arg: any, f: (s: string) => T): Maybe<T> {\n  if (arg === false || arg == null || arg === \"\") {\n    return undefined\n  }\n  const s = toS(arg)\n  return notBlank(s) ? f(s!) : undefined\n}\n\nexport function mapNotBlankOr<T>(\n  arg: any,\n  f: (s: string) => T,\n  defaultValue: T | (() => T)\n): T {\n  return orElse(mapNotBlank(arg, f), defaultValue)\n}\n\nexport function firstNotBlank<T>(...arr: MaybeNull<T>[]): Maybe<T> {\n  // PERF: unrolled\n  for (const ea of arr) {\n    if (notBlank(ea)) return ea\n  }\n  return\n}\n", "import { denull } from \"./Maybe\"\nimport { MaybeNull } from \"./MaybeTypes\"\n\n/**\n * Work-alike to JSON.stringify, except that circular dependencies are replaced\n * with a string reference.\n */\nexport function stringify(\n  ea: any,\n  replacer?: (this: any, key: string, value: any) => any,\n  space?: string | number,\n  cycleReplacer?: (this: any, key: string, value: any) => any\n): string {\n  return JSON.stringify(ea, serializer(replacer, cycleReplacer), denull(space))\n}\n\nfunction serializer(\n  replacer?: MaybeNull<(this: any, key: string, value: any) => any>,\n  cycleReplacer?: MaybeNull<(this: any, key: string, value: any) => any>\n): (this: any, key: string, value: any) => any {\n  const stack: any[] = []\n  const keys: any[] = []\n\n  const cr =\n    cycleReplacer != null\n      ? cycleReplacer\n      : (_key: string, value: any) =>\n          stack[0] === value\n            ? \"[Circular ~]\"\n            : \"[Circular ~.\" +\n              keys.slice(0, stack.indexOf(value)).join(\".\") +\n              \"]\"\n\n  /**\n   * The object in which the key was found is provided as the replacer's `this`\n   * parameter.\n   */\n  return function (this: any, key: string, value: any) {\n    if (stack.length > 0) {\n      const thisPos = stack.indexOf(this)\n      if (thisPos >= 0) {\n        stack.splice(thisPos + 1)\n        keys.splice(thisPos, Infinity, key)\n      } else {\n        stack.push(this)\n        keys.push(key)\n      }\n      if (stack.indexOf(value) >= 0) {\n        value = cr.call(this, key, value)\n      }\n    } else {\n      stack.push(value)\n    }\n    const result = replacer == null ? value : replacer.call(this, key, value)\n    return result\n  }\n}\n", "import { stringify } from \"./JSON\"\n\nexport function eql(a: any, b: any): boolean {\n  return stringify(a) === stringify(b)\n}\n", "import { isFunction } from \"./ObjectType\"\n\nexport interface List<T> {\n  length: number\n  [Symbol.iterator](): IterableIterator<T>\n\n  // we can't add get(), because then List<T> doesn't match T[]:\n  // get(index: number): T | undefined\n\n  push(...items: T[]): number\n  pop(): T | undefined\n\n  unshift(...items: T[]): number\n  shift(): T | undefined\n\n  every(callbackfn: (value: T, index: number) => boolean): boolean\n  some(callbackfn: (value: T, index: number) => boolean): boolean\n\n  forEach(callbackfn: (value: T, index: number) => void): void\n  map<U>(callbackfn: (value: T, index: number) => U): U[]\n\n  reduce<U>(\n    callbackfn: (previousValue: U, currentValue: T, currentIndex: number) => U,\n    initialValue: U\n  ): U\n\n  reverse(): this\n\n  slice(start?: number | undefined, end?: number | undefined): T[]\n}\n\nexport function isList(l: any): l is List<any> {\n  return (\n    l != null &&\n    (Array.isArray(l) ||\n      (isFinite(l.length) &&\n        isFunction(l[Symbol.iterator]) &&\n        isFunction(l.push) &&\n        isFunction(l.pop) &&\n        isFunction(l.forEach) &&\n        isFunction(l.some))) // TODO: good enough to be listish?\n  )\n}\n", "export function getOrSet<K, V>(\n  m: Map<K, V> | WeakMap<any, V>,\n  k: K,\n  valueThunk: () => V\n): V {\n  if (k == null) throw new Error(\"null key\")\n  if (m.has(k)) {\n    return m.get(k)!\n  } else {\n    const v = valueThunk()\n    if (v != null) m.set(k, v)\n    return v\n  }\n}\n\nexport function deleteIf<K, V>(\n  m: Map<K, V>,\n  predicate: (key: K, value: V) => boolean\n) {\n  for (const [k, v] of m.entries()) {\n    if (predicate(k, v)) {\n      m.delete(k)\n    }\n  }\n}\n", "import { Maybe, MaybeNull } from \"./MaybeTypes\"\n\n// Scala got a Some things right.\n// HUR HUR I AM HILLLARIOUS\n\n// \"Opt\" instead of \"Option\" due to Option being an html entity already\n\nexport type MaybeOpt<T> = Opt<T> | MaybeNull<T>\n\n/**\n * @see http://www.scala-lang.org/api/current/scala/Option.html\n */\nexport interface Opt<A> {\n  /**\n   * @return true if the option is an instance of Some, false otherwise\n   */\n  isDefined: boolean\n  /**\n   * @return true if the option is None, false otherwise\n   */\n  isEmpty: boolean\n  /**\n   * @return the option's value.\n   */\n  get(): Maybe<A>\n  /**\n   * @return true if this option is nonempty and the predicate `p` returns true\n   * when applied to this Option's value.\n   */\n  exists(p: (a: A) => boolean): boolean\n  /**\n   * @return a `Some` containing the result of applying `f` to this `Option`'s value\n   * if this `Option` is nonempty.\n   */\n  map<B>(f: (a: A) => B): Opt<B>\n  /**\n   * @return the result of applying `f` to this `Option`'s value if this\n   * `Option` is nonempty. By supporting `undefined` or `B`, we make caller's\n   * lives a little easier--we'll wrap the result in an `Option` for you.\n   */\n  flatMap<B>(f: (a: A) => MaybeOpt<B>): Opt<B>\n  /**\n   * @return this `Option` if it is both nonempty\n   * and applying the predicate `p` to this `Option`'s value returns true.\n   */\n  filter(p: (a: A) => boolean): Opt<A>\n  /**\n   * Apply the given procedure `f` to the `Option`'s value\n   * if this `Option` is nonempty.\n   * @return this (for fluent or chaining calls)\n   */\n  forEach(f: (a: A) => void): Opt<A>\n  /**\n   * @return this `Option`'s value if this `Option` is nonempty,\n   * otherwise return the result of evaluating `f`.\n   */\n  getOrElse(f: () => A): A\n  /**\n   * @return this `Option`'s value if this `Option` is nonempty,\n   * otherwise return the result of evaluating `f`.\n   */\n  orElse(f: () => MaybeOpt<A>): Opt<A>\n\n  /**\n   * @param f will only be invoked if both `this` and `b` are defined\n   */\n  zip1<B, T>(b: MaybeOpt<B>, f: (a: A, b: B) => MaybeOpt<T>): Opt<T>\n\n  zip2<B, C, T>(\n    b: MaybeOpt<B>,\n    c: MaybeOpt<C>,\n    f: (a: A, b: B, c: C) => MaybeOpt<T>\n  ): Opt<T>\n\n  zip3<B, C, D, T>(\n    b: MaybeOpt<B>,\n    c: MaybeOpt<C>,\n    d: MaybeOpt<D>,\n    f: (a: A, b: B, c: C, d: D) => MaybeOpt<T>\n  ): Opt<T>\n}\n\nnamespace NoneImpl {\n  export const isDefined = false\n  export const isEmpty = true\n  export const get = () => undefined\n  export const exists = () => false\n  const noop = () => NoneImpl\n  export const map = noop\n  export const flatMap = noop\n  export const filter = noop\n  export const forEach = noop\n  export const getOrElse = <A>(f: () => A): A => f()\n  export const orElse = <A>(f: () => MaybeOpt<A>): Opt<A> => opt(f())\n  export const zip1 = noop\n  export const zip2 = noop\n  export const zip3 = noop\n}\n\nexport const None: Opt<any> = NoneImpl\n\nexport class Some<A> implements Opt<A> {\n  readonly isDefined = true\n  readonly isEmpty = false\n\n  constructor(private readonly a: A) {}\n\n  get(): A {\n    return this.a\n  }\n\n  exists(f: (a: A) => boolean): boolean {\n    return f(this.a)\n  }\n\n  map<B>(f: (a: A) => B): Opt<B> {\n    return new Some(f(this.a))\n  }\n\n  flatMap<B>(f: (a: A) => Opt<B> | MaybeNull<B>): Opt<B> {\n    const b = f(this.a)\n    return isOpt(b) ? b : opt(b)\n  }\n\n  filter(f: (a: A) => boolean): Opt<A> {\n    return opt(f(this.a) ? this.a : undefined)\n  }\n\n  forEach(f: (a: A) => void): this {\n    f(this.a)\n    return this\n  }\n\n  getOrElse(): A {\n    return this.a\n  }\n\n  orElse(): Opt<A> {\n    return this\n  }\n\n  zip1<B, T>(b: MaybeOpt<B>, f: (a: A, b: B) => MaybeOpt<T>): Opt<T> {\n    return opt(b).flatMap(eb => f(this.a, eb))\n  }\n\n  zip2<B, C, T>(\n    b: Opt<B>,\n    c: Opt<C>,\n    f: (a: A, b: B, c: C) => MaybeOpt<T>\n  ): Opt<T> {\n    return opt(b).flatMap(eb => opt(c).flatMap(ec => f(this.a, eb, ec)))\n  }\n\n  zip3<B, C, D, T>(\n    b: MaybeOpt<B>,\n    c: MaybeOpt<C>,\n    d: MaybeOpt<D>,\n    f: (a: A, b: B, c: C, d: D) => MaybeOpt<T>\n  ): Opt<T> {\n    return opt(b).flatMap(eb =>\n      opt(c).flatMap(ec => opt(d).flatMap(ed => f(this.a, eb, ec, ed)))\n    )\n  }\n}\n\nexport function isOpt<A>(a: MaybeOpt<A>): a is Opt<A> {\n  return a instanceof Some || a === None\n}\n\n/**\n * @see http://www.scala-lang.org/api/current/scala/Option.html\n */\nexport function opt<A>(a: MaybeOpt<A>): Opt<A> {\n  return isOpt(a) ? a : a != null ? new Some(a) : None\n}\n", "import { blank } from \"./Blank\"\nimport { orElse } from \"./Maybe\"\nimport { Maybe, MaybeNull } from \"./MaybeTypes\"\nimport { isFunction } from \"./ObjectType\"\nimport { opt } from \"./Opt\"\nimport { ThunkOrT, tot } from \"./Thunk\"\nimport { toS } from \"./toS\"\n\nexport function isNumber(o: any): o is number {\n  return typeof o === \"number\" && !isNaN(o) && isFinite(o)\n}\n\nexport function mapFinite<T>(i: Maybe<number>, f: (ea: number) => T): Maybe<T> {\n  return isNumber(i) ? f(i) : undefined\n}\n\nconst mapPredicate = (f: (lhs: number, rhs: number) => boolean) => (\n  lhs: MaybeNull<number>,\n  rhs: MaybeNull<number>\n) => isNumber(lhs) && isNumber(rhs) && f(lhs, rhs)\n\nexport const lt = mapPredicate((i, j) => i < j)\nexport const lte = mapPredicate((i, j) => i <= j)\nexport const gt = mapPredicate((i, j) => i > j)\nexport const gte = mapPredicate((i, j) => i >= j)\n\nexport function finiteOrElse<T>(i: Maybe<number>, defaultValue: T): number | T {\n  return isNumber(i) ? i : defaultValue\n}\n\nexport function diff(i: Maybe<number>, j: Maybe<number>): Maybe<number> {\n  return isNumber(i) && isNumber(j) ? i - j : undefined\n}\n\nexport function absdiff(i: Maybe<number>, j: Maybe<number>): Maybe<number> {\n  return isNumber(i) && isNumber(j) ? Math.abs(i - j) : undefined\n}\n\nexport function safeDivide(numerator: number, denominator: number): number {\n  return numerator / (denominator === 0 ? 1e-8 : denominator)\n}\n\nexport function approximates(\n  a: MaybeNull<number>,\n  b: MaybeNull<number>,\n  ratioGte: number\n): boolean {\n  return a == null || b == null\n    ? false\n    : a === b\n    ? true\n    : gte(a < b ? safeDivide(a, b) : safeDivide(b, a), ratioGte)\n}\n\nexport function closeTo(\n  expected: MaybeNull<number>,\n  actual: MaybeNull<number>,\n  delta: number\n): boolean {\n  return expected == null || actual == null\n    ? false\n    : Math.abs(expected - actual) < delta\n}\n\nexport function trunc(n: Maybe<number>): Maybe<number> {\n  if (!isNumber(n)) return undefined\n  const i = Math.trunc(n)\n  return i === 0 ? Math.abs(i) : i\n}\n\nexport interface ToNumber {\n  toNumber(): number\n}\n\nexport function isToNumber(v: any): v is ToNumber {\n  return isFunction(v[\"toNumber\"])\n}\n\nfunction toNumber(\n  value: MaybeNull<number | string | ToNumber>,\n  opts: {\n    defaultValue: Maybe<number>\n    nton: (n: number) => number\n    ston: (s: string) => Maybe<number>\n  }\n) {\n  if (blank(value)) return opts.defaultValue\n  if (isNumber(value)) return opts.nton(value)\n  if (isToNumber(value)) return opts.nton(value.toNumber())\n  try {\n    const i = opts.ston(toS(value))\n    return isNumber(i) ? opts.nton(i) : opts.defaultValue\n  } catch {\n    return opts.defaultValue\n  }\n}\n\nexport function toInt(\n  value: MaybeNull<number | string | ToNumber>,\n  opts?: { defaultValue?: number }\n): Maybe<number> {\n  return toNumber(value, {\n    defaultValue: undefined,\n    nton: i => trunc(i)!,\n    ston: parseInt,\n    ...opts\n  })\n}\n\nexport function toFloat(\n  value: MaybeNull<number | string>,\n  opts?: { defaultValue?: number }\n): Maybe<number> {\n  return toNumber(value, {\n    defaultValue: undefined,\n    nton: i => i,\n    ston: parseFloat,\n    ...opts\n  })\n}\n\nexport function toGt0(n: any): Maybe<number> {\n  const i = toInt(n)\n  return i != null && i > 0 ? i : undefined\n}\n\nexport function lt0(n: any): n is number {\n  return isNumber(n) && n < 0\n}\n\nexport function gt0(n: any): n is number {\n  return isNumber(n) && n > 0\n}\n\nexport function gtOrElse(\n  n: Maybe<number>,\n  mustBeGreaterThan: number\n): Maybe<number> {\n  return isNumber(n) && isNumber(mustBeGreaterThan) && n > mustBeGreaterThan\n    ? n\n    : undefined\n}\n\nexport function lte0(n: any): n is number {\n  return isNumber(n) && n <= 0\n}\n\nexport function gte0(n: any): n is number {\n  return isNumber(n) && n >= 0\n}\n\nexport function mapInt<T>(o: any, f: (i: number) => T): Maybe<T> {\n  return opt(o)\n    .flatMap(i => toInt(i))\n    .flatMap(f)\n    .get()\n}\n\nexport function mapFloat<T>(o: any, f: (i: number) => T): Maybe<T> {\n  return opt(o)\n    .flatMap(i => toFloat(i))\n    .flatMap(f)\n    .get()\n}\n\n/**\n * @return a stringified `value` iff `value` is a positive integer\n */\nexport function id(value: Maybe<number | string>): Maybe<string> {\n  const i = toInt(value)\n  return gt0(i) ? String(i) : undefined\n}\n\nexport function mapIntOr<T>(o: any, f: (i: number) => T, orElseF: () => T): T {\n  return orElse(mapInt(o, f), orElseF)\n}\n\nexport function mapNumeric<T>(o: any, f: (i: number) => T): Maybe<T> {\n  return isNumber(o) ? f(o) : undefined\n}\n\nexport function map2Numeric<T>(\n  i: any,\n  j: any,\n  f: (ea1: number, ea2: number) => T\n): Maybe<T> {\n  return mapNumeric(i, ea1 => mapNumeric(j, ea2 => f(ea1, ea2)))\n}\n\nexport function mapNumericOr<T>(\n  o: any,\n  f: (i: number) => T,\n  defaultValue: T\n): T {\n  return isNumber(o) ? f(o) : defaultValue\n}\n\nexport function numericOr(o: any, defaultValue: ThunkOrT<number>): number {\n  return isNumber(o) ? o : tot(defaultValue)\n}\n\nexport function round(i: number): number {\n  // Workaround for bug in javascript (Math.round(-1.5) === -1 (!!)):\n  return i < 0 ? -Math.round(-i) : Math.round(i)\n}\n\nexport function toPrecisionMaybe(\n  i: Maybe<number>,\n  decimalPlaces: number\n): Maybe<number> {\n  return mapFinite(i, ea => toPrecision(ea, decimalPlaces))\n}\n\nexport function toFixed(i: Maybe<number>, decimals: number): Maybe<number> {\n  try {\n    return mapNumeric(i, ea => round(ea * 10 ** decimals) / 10 ** decimals)\n  } catch (err) {\n    return\n  }\n}\n\nexport function toPrecision(i: number, decimalPlaces: number): number {\n  if (i == null) return 0\n  // pow should be 1 for decimalPlaces = 0\n  const pow = Math.pow(10, decimalPlaces)\n  return round(i * pow) / pow\n}\n\nexport function sigFigs(i: number, digits: number): number {\n  if (i === 0 || digits === 0) {\n    return 0\n  }\n  const exp = digits - round(Math.ceil(Math.log10(Math.abs(i))))\n  const pow = Math.pow(10, Math.abs(exp))\n  // Prevent 120.000000001:\n  return exp < 0 ? round(i / pow) * pow : round(i * pow) / pow\n}\n\nexport function base2Ceil(i: number): number {\n  return Math.pow(2, Math.ceil(Math.log2(i)))\n}\n\nexport function base10Ceil(i: number): number {\n  return Math.pow(10, Math.ceil(Math.log10(i)))\n}\n\nexport function clamp(min: number, max: number, value: number): number {\n  if (min > max || !isNumber(min) || !isNumber(max))\n    throw new Error(`invalid clamp(${min}, ${max}, ${value})`)\n  if (!isNumber(value)) return round((min + max) / 2)\n  return value < min ? min : value > max ? max : value\n}\n\n/**\n * Accumulate the result of `f`, called `count` times. `f` receives a\n * zero-indexed argument.\n */\nexport function times<T>(count: number, f: (i: number) => T): T[] {\n  if (!gt0(count)) return []\n  const c = Math.round(count)\n  if (c <= 0) return []\n  return [...Array(c)].map((_, i) => f(i))\n}\n", "import { isEmpty, isNotEmpty, mapNotEmpty, range, sum } from \"./Array\"\nimport { Maybe } from \"./MaybeTypes\"\nimport { gt0 } from \"./Number\"\n\n/**\n * @return a random integer between min (included) and max (excluded)\n * Using Math.round() will give you a non-uniform distribution!\n * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/random\n */\nexport function randomInt(\n  min: number,\n  max: number,\n  excluded: number[] = []\n): number {\n  min = Math.ceil(min)\n  max = Math.floor(max)\n  if (max < min) return min\n  if (isNotEmpty(excluded) && excluded.length + 10 > max - min) {\n    const included = range(min, max).filter(ea => !excluded.includes(ea))\n    return mapNotEmpty(included, arr => arr[randomInt(0, included.length)])!\n  }\n\n  const result = Math.floor(Math.random() * (max - min)) + min\n  return excluded.includes(result) ? randomInt(min, max, excluded) : result\n}\n\nexport function randomInts(min: number, max: number, size: number): number[] {\n  const result: number[] = []\n  while (result.length < size) {\n    result.push(randomInt(min, max, result))\n  }\n  return result\n}\n\n/**\n * @return a random float between `min` and `max`\n */\nexport function randomFloat(min: number, max: number) {\n  return Math.random() * (max - min) + min\n}\n\n// No upper case to support case-insensitive filesystems. Exported for tests.\n// We could have used GeoRadix.numerals, but that's a possible circular dep.\nexport const RandomChars = \"0123456789abcdefghijkmnopqrstuvwxyz\"\n\nexport function randomChars(\n  count: number,\n  chars: string = RandomChars\n): string {\n  let result = \"\"\n  for (let i = 0; i < count; i++) {\n    result += randomChar(chars)\n  }\n  return result\n}\n\nexport function randomChar(chars: string = RandomChars): string {\n  return chars[randomInt(0, chars.length)]\n}\n\nexport function pickRandom<T>(arr: T[]): Maybe<T> {\n  return arr[randomInt(0, arr.length)]\n}\n\n// fisher-yates\nexport function shuffle<T>(arr: T[]): T[] {\n  const r = [...arr]\n  for (let i = r.length - 1; i > 0; i--) {\n    const j = Math.floor(Math.random() * (i + 1))\n    if (i !== j) [r[i], r[j]] = [r[j], r[i]]\n  }\n  return r\n}\n\nexport function sample<T>(arr: T[], size: number): T[] {\n  if (size < arr.length / 10) {\n    const result = new Set<number>()\n    while (result.size < size) {\n      result.add(randomInt(0, arr.length))\n    }\n    return [...result.keys()].map(ea => arr[ea])\n  } else {\n    return shuffle([...arr]).slice(0, size)\n  }\n}\n\nexport function pickWeightedRandom<T extends { priority?: number }>(\n  arr: T[]\n): Maybe<T> {\n  if (isEmpty(arr)) return\n  const nonZeroes = arr.filter(ea => gt0(ea.priority))\n  const totalPriority = sum(nonZeroes, ea => ea.priority!)\n  let rand = randomFloat(0, totalPriority)\n  return nonZeroes.find(ea => {\n    rand -= ea.priority!\n    return rand <= 0\n  })\n}\n", "import { flatten } from \"./Array\"\nimport { toS } from \"./toS\"\n\nexport function isString(obj: any): obj is string {\n  return typeof obj === \"string\"\n}\n\nexport function ensurePrefix(s: string, prefix: string): string {\n  s = toS(s)\n  prefix = toS(prefix)\n  return s.startsWith(prefix) ? s : prefix + s\n}\n\nexport function ensureSuffix(s: string, suffix: string): string {\n  s = toS(s)\n  suffix = toS(suffix)\n  return s.endsWith(suffix) ? s : s + suffix\n}\n\nexport function ellipsize(a: any, maxLen: number = 80): string {\n  if (a == null) {\n    return \"\"\n  }\n  const s = toS(a)\n  return s.length <= maxLen ? s : s.slice(0, maxLen - 1) + \"\u2026\"\n}\n\nexport const newlineRe = /\\r?\\n/gm\n\n/**\n * Returns the nearest occurrence of a substring to the left of a given position in the string.\n * @param haystack The string to search against.\n * @param needle The substring to search for.\n * @param position The index at which to begin searching. If omitted, the search begins at the end of the string.\n */\nexport function leftIndexOf(\n  haystack: string,\n  needle: string,\n  position?: number\n) {\n  if (position == null) position = haystack.length\n  for (let i = position; i >= 0; i--) {\n    if (haystack.substr(i).startsWith(needle)) return i\n  }\n  return -1\n}\n\nexport function wrap(\n  s: string,\n  opts = { maxLineLen: 75, prefix: \"\" }\n): string[] {\n  if (s.includes(\"\\n\")) {\n    return flatten(s.split(newlineRe).map(ea => wrap(ea, opts)))\n  }\n  s = ensurePrefix(toS(s), opts.prefix).trim()\n  if (s.length <= opts.maxLineLen) {\n    return [s]\n  }\n  const leftSliceAt = leftIndexOf(s, \" \", opts.maxLineLen)\n\n  if (leftSliceAt > opts.prefix.length) {\n    return [s.slice(0, leftSliceAt), ...wrap(s.slice(leftSliceAt + 1), opts)]\n  } else {\n    const rightSliceAt = s.indexOf(\" \", opts.prefix.length + 1)\n    if (rightSliceAt > 0 && rightSliceAt < s.length - 1) {\n      return [\n        s.slice(0, rightSliceAt),\n        ...wrap(s.slice(rightSliceAt + 1), opts)\n      ]\n    } else {\n      return [s]\n    }\n  }\n\n  // }\n\n  // const index = s\n  //   .slice(0, opts.maxLineLen + 1)\n  //   .replace(/[\\s-]/g, \" \")\n  //   .lastIndexOf(\" \")\n  // const sliceAt =\n  //   index <= 1 ? opts.maxLineLen - (opts.prefix.length + 2) : index\n  // return [s.slice(0, sliceAt + 1).trim(), ...wrap(s.slice(sliceAt + 1), opts)]\n}\n\nexport function eqlStrings(a: string, b: string): boolean {\n  return a == null || b == null ? false : a.normalize() === b.normalize()\n}\n\nexport function replaceAll(\n  s: string,\n  searchValue: string | RegExp,\n  replaceValue: string\n): string {\n  if (searchValue === \"\") return s\n  return s.split(searchValue).join(replaceValue)\n}\n\nexport function compressWhitespace(...s: string[]): string {\n  return s.join(\" \").replace(/\\s+/g, \" \").trim()\n}\n", "import { isIterable } from \"./Iterable\"\nimport { MaybeNull } from \"./MaybeTypes\"\n\nexport type Arrayish<T> = ArrayLike<T> | Iterable<T> | T | Set<T>\n\nexport function toA<T>(arr: MaybeNull<Arrayish<T>>): T[] {\n  return arr == null\n    ? []\n    : Array.isArray(arr)\n    ? (arr as T[])\n    : isIterable(arr)\n    ? Array.from(arr)\n    : [arr as T]\n}\n", "import { blankish } from \"./Blank\"\nimport { eql } from \"./Eql\"\nimport { isIterable } from \"./Iterable\"\nimport { stringify } from \"./JSON\"\nimport { isList, List } from \"./List\"\nimport { getOrSet } from \"./Map\"\nimport { Defined, defined, map } from \"./Maybe\"\nimport { Maybe, MaybeNull } from \"./MaybeTypes\"\nimport {\n  cmp,\n  Comparable,\n  isPrimitive,\n  isPrimitiveArray,\n  lt,\n  Primitivable,\n  Primitivables,\n  Primitive\n} from \"./Primitive\"\nimport { randomInt } from \"./Random\"\nimport { isString } from \"./String\"\nimport { ThunkOrT, tot } from \"./Thunk\"\nimport { toA } from \"./toA\"\nimport { toS } from \"./toS\"\n\n// Added isNotEmpty so I can make the arr is not null assertion:\nexport function isNotEmpty<L extends List<any>>(arr: Maybe<L>): arr is L {\n  return isList(arr) && arr.length > 0 && arr.some(ea => ea != null)\n}\n\nexport function notEmptyOr<L extends List<any>>(\n  arr: Maybe<L>,\n  defaultValue: ThunkOrT<L>\n): L {\n  return isNotEmpty(arr) ? arr : tot(defaultValue)\n}\n\nexport function isEmpty(arr: Maybe<List<any>>): arr is undefined {\n  return !isNotEmpty(arr)\n}\n\nexport function mapArray<T, U>(arr: Maybe<T[]>, f: (t: T[]) => U): Maybe<U> {\n  return Array.isArray(arr) ? f(arr) : undefined\n}\n\nexport function mapNotEmpty<L extends List<any>, R>(\n  arr: Maybe<L>,\n  f: (ea: L) => R\n): Maybe<R> {\n  return isNotEmpty(arr) ? f(arr) : undefined\n}\n\nexport function mapNotEmptyOr<L extends List<any>, R>(\n  arr: Maybe<L>,\n  f: (ea: L) => R,\n  defaultValue: ThunkOrT<R>\n): R {\n  return isNotEmpty(arr) ? f(arr) : tot(defaultValue)\n}\n\nfunction asPrim(\n  a: Primitive | Primitive[] | Primitivable | Primitivables\n): Primitive | Primitive[] {\n  return isPrimitive(a) || isPrimitiveArray(a) ? a : a.valueOf()\n}\n\n/**\n * Compacts and flattens ONE LEVEL\n */\nexport function flatten<T>(\n  arr: (MaybeNull<T> | MaybeNull<T>[])[],\n  result: T[] = []\n): T[] {\n  if (arr == null) return result\n  for (const ea of arr) {\n    if (ea != null) {\n      if (Array.isArray(ea)) {\n        // PERF: UNROLL\n        for (const ea1 of ea) {\n          if (ea1 != null) result.push(ea1)\n        }\n      } else {\n        result.push(ea)\n      }\n    }\n  }\n  return result\n}\n\nexport function sort<\n  T extends Primitive | Primitive[] | Primitivable | Primitivables\n>(arr: Maybe<T>[] | ReadonlyArray<Maybe<T>>): Defined<T>[] {\n  return sortByInPlace(compact(arr), asPrim)\n}\n\nexport function copyArrayTo<T>(source: T[], destination: T[]): T[] {\n  for (let i = 0; i < source.length; i++) {\n    destination[i] = source[i]\n  }\n  destination.length = source.length\n  return destination\n}\n\nexport function sortByInPlace<T>(arr: T[], f: (t: T) => Comparable): T[] {\n  return copyArrayTo(sortBy(arr, f), arr)\n}\n\nexport function sortUniqByInPlace<T>(arr: T[], f: (t: T) => Comparable): T[] {\n  const m = new Map<string, T>()\n  for (const ea of arr) {\n    getOrSet(m, stringify(f(ea)), () => ea)\n  }\n  return copyArrayTo(sortBy(m.values(), f), arr)\n}\n\nexport function sorted(arr: Primitivable[]): boolean {\n  return arr.every((ea, idx) => idx === 0 || ea > arr[idx - 1])\n}\n\nexport function sortedBy<T>(arr: T[], f: (t: T) => Primitive): boolean {\n  return arr.every((ea, idx) => idx === 0 || f(ea) > f(arr[idx - 1]))\n}\n\n/**\n * Returns a copy of arr, stable sorted by the given constraint. Note that false\n * < true, and that `f` may return an array for sort priorities, or undefined if\n * the item should be skipped from the returned result.\n *\n * Note: localeSort() thinks lower case should come before upper case (!!)\n */\nexport function sortBy<T, V extends Comparable>(\n  arr: Iterable<T> | T[],\n  f: (t: T, index: number) => Maybe<V>\n): T[] {\n  return toA(arr)\n    .filter(ea => ea != null)\n    .map((item, idx) => ({\n      item,\n      cmp: map(f(item, idx), ea => [ea, idx])\n    }))\n    .filter(ea => ea.cmp != null)\n    .sort((a, b) => cmp(a.cmp!, b.cmp!))\n    .map(ea => ea.item)\n}\n\nexport function deepSortBy<T, V extends Primitive | Primitive[]>(\n  arr: Iterable<T> | T[],\n  f: (t: T) => Maybe<V>\n): T[] {\n  return sortBy(arr, f).map(ea =>\n    isIterable(ea) ? deepSortBy(ea, f) : ea\n  ) as any // SITS typing\n}\n\nexport function arrayEql<T extends Primitive>(a: T[], b: T[]): boolean {\n  return (\n    a != null &&\n    b != null &&\n    a.length === b.length &&\n    a.every((ea, idx) => ea === b[idx])\n  )\n}\n\n/**\n * @return true if `prefix` == `haystack.slice(0, prefix.length)`.\n */\nexport function startsWith<T extends Primitive>(\n  haystack: T[],\n  prefix: T[]\n): boolean {\n  return arrayEql(haystack.slice(0, prefix.length), prefix)\n}\n\n/**\n * Retain all items from `arr` where the `keepIfTrue` returns `true`.\n * @return true if `arr` was changed.\n */\nexport function filterInPlace<T>(\n  arr: T[],\n  keepIfTrue: (item: T, index: number, ea: T[]) => boolean\n): T[] {\n  for (let i = 0; i < arr.length; ) {\n    if (keepIfTrue(arr[i], i, arr)) {\n      i++\n    } else {\n      arr.splice(i, 1)\n    }\n  }\n  return arr\n}\n\nexport function move<T>(arr: T[], fromIndex: number, toIndex: number): T[] {\n  if (\n    fromIndex === toIndex ||\n    fromIndex < 0 ||\n    toIndex < 0 ||\n    fromIndex >= arr.length ||\n    toIndex >= arr.length\n  ) {\n    return arr\n  }\n  const ea = arr[fromIndex]\n  arr.splice(fromIndex, 1)\n  arr.splice(toIndex, 0, ea)\n  return arr\n}\n\n// ES2016 polyfill that also supports Iterable\nexport function includes(\n  haystack: MaybeNull<any[] | Iterable<any>>,\n  needle: any\n): boolean {\n  if (haystack == null) return false\n  for (const ea of haystack) {\n    if (needle.valueOf() === ea.valueOf()) return true\n  }\n  return false\n}\n\nexport function indexOf<T>(\n  iter: Maybe<Iterable<T>>,\n  f: (t: T, index: number) => boolean\n): Maybe<number> {\n  if (iter == null) return\n  let index = 0\n  for (const ea of iter) {\n    if (f(ea, index)) return index\n    index++\n  }\n  return\n}\n\n/**\n * @returns true iff all `needles` are found in `haystack`\n */\nexport function includesAll(\n  haystack?: Primitive[],\n  needles?: Primitive[]\n): boolean {\n  if (haystack == null || needles == null) return false\n  return needles.every(needle => includes(haystack, needle))\n}\n\nexport function eqlUnordered(a: Primitive[], b: Primitive[]): boolean {\n  if (a == null || b == null || a.length !== b.length) return false\n  const a1 = sortBy(a, asPrim)\n  const b1 = sortBy(b, asPrim)\n  return a1.every((ea, idx) => ea === b1[idx])\n}\n\nexport function pushUniq<T>(arr: T[], ...items: T[]): T[] {\n  for (const item of items) {\n    if (!arr.some(ea => eql(ea, item))) {\n      arr.push(item)\n    }\n  }\n  return arr\n}\n\nexport function pushUniqBy<T>(\n  arr: T[],\n  items: T[],\n  valueOf: (t: T) => Comparable\n): T[] {\n  const vArr = arr.map(valueOf)\n  for (const item of items) {\n    const v = valueOf(item)\n    if (!vArr.includes(v)) {\n      arr.push(item)\n      vArr.push(v)\n    }\n  }\n  return arr\n}\n\nexport function insertAt<T>(arr: T[], index: number, ...items: T[]): T[] {\n  arr.splice(index, 0, ...items)\n  return arr\n}\n\n/**\n * Insert `item` into `arr` only if `item` is not in `arr` (according to `cmp`).\n *\n * Assumes `arr` is ascending-sorted.\n */\nexport function insertUniq<T>(\n  arr: T[],\n  item: T,\n  cmp_: (a: T, b: T) => number\n): T[] {\n  // verify the array is already in proper sort-order\n  for (let i = 0; i < arr.length - 1; i++) {\n    if (cmp_(arr[i], arr[i + 1]) > 0) {\n      throw new Error(\"badly sorted array: \" + arr)\n    }\n  }\n  for (let i = 0; i < arr.length; i++) {\n    const ea = arr[i]\n    const c = cmp_(ea, item)\n    if (c === 0) return arr\n    // if item is greater than ea, insert right before ea\n    if (c > 0) {\n      arr.splice(i, 0, item)\n      return arr\n    }\n  }\n  arr.push(item)\n  return arr\n}\n\nexport function compact<T>(iter: MaybeNull<Iterable<T>>): Defined<T>[] {\n  if (iter == null) return []\n  const arr = toA(iter)\n  return arr.every(defined) ? (arr as Defined<T>[]) : arr.filter(defined)\n}\n\nexport function compactBlankish<T>(iter: MaybeNull<Iterable<T>>): Defined<T>[] {\n  const arr = toA(iter).filter(ea => !blankish(toS(ea)))\n  return (isString(arr[0]) ? arr.map(ea => toS(ea).trim()) : arr) as any\n}\n\nexport function compactBlanks(arr: Maybe<any[]>): string[] {\n  // trim() to fix https://gitlab.com/mceachen/photostructure/issues/58\n  return toA(arr)\n    .map(ea => toS(ea).trim())\n    .filter(ea => ea.length > 0)\n}\n\nexport function uniq<T>(arr: Maybe<Maybe<T>[]>): Defined<T>[] {\n  return uniqBy(compact(arr), ea => stringify(ea))\n}\n\n/**\n * First-one-in-wins\n */\nexport function uniqBy<T, V extends Primitive>(\n  arr: Maybe<T>[],\n  f: (t: T) => Maybe<V> = ea => stringify(ea) as V\n): T[] {\n  if (isEmpty(arr)) return []\n  const m = new Map<V, T>()\n  for (const ea of arr) {\n    if (ea != null) {\n      const v = f(ea)\n      if (v != null) {\n        getOrSet(m, v, () => ea)\n      }\n    }\n  }\n  return [...m.values()]\n}\n\n/**\n * First-one-in-wins\n */\nexport function uniqBy2<T>(\n  arr: Maybe<T>[],\n  equals: (a: T, b: T) => boolean\n): T[] {\n  if (isEmpty(arr)) return []\n  const result: T[] = []\n  for (const a of arr) {\n    if (a != null && result.every(b => !equals(a, b))) {\n      result.push(a)\n    }\n  }\n  return result\n}\n\nexport function clear<T>(arr: T[]): T[] {\n  arr.length = 0\n  return arr\n}\n\n/**\n * Equivalent to filtering all items in an array to a new array and calling\n * length. This method avoids creating the intermediate array.\n *\n * @return the number of elements in `arr` that `predicate` returns `true`.\n */\nexport function count<T>(\n  arr: T[],\n  predicate: (t: T, idx: number) => boolean\n): number {\n  return arr.reduce((acc, ea, idx) => acc + (predicate(ea, idx) ? 1 : 0), 0)\n}\n\n/**\n * Equivalent to mapping all items in an array to a new number array and calling\n * Vector.sum(). This method avoids creating the intermediate array.\n *\n * @return the sum of elements of `f`-transmuted numbers from `arr`.\n */\nexport function sum<T>(\n  arr: T[],\n  f: (t: T, currentIndex: number) => number\n): number {\n  return arr.reduce((acc, ea, idx) => acc + f(ea, idx), 0)\n}\n\nexport function firstMatch(\n  re: RegExp,\n  arr: Maybe<string>[]\n): Maybe<RegExpExecArray> {\n  for (const s of compact(arr)) {\n    const m = re.exec(s)\n    if (m != null) return m\n  }\n  return\n}\n\nexport function commonPrefixLength<T extends Primitive>(\n  a: Maybe<T[] | string>,\n  b: Maybe<T[] | string>\n): number {\n  if (a == null || b == null) return 0\n  if (a === b) return a.length\n  if (typeof a === \"string\") a = (a.split(\"\") as any) as T[]\n  if (typeof b === \"string\") b = (b.split(\"\") as any) as T[]\n  if (arrayEql(a, b)) return a.length\n  let length = 0\n  while (a[length] === b[length]) length++\n  return length\n}\n\n/**\n * Make random perturbations to `array` to minimize the given expense function\n */\nexport function anneal<T>({\n  array,\n  expense,\n  allowedDelta\n}: {\n  array: T[]\n  expense: (arr: T[], fromIndex: number, toIndex: number) => Comparable\n  allowedDelta: number\n}): T[] {\n  const delta = Math.round(allowedDelta)\n  if (delta < 2) return array\n  for (let mid = 0; mid < array.length - 1; mid++) {\n    const newPos = randomInt(\n      Math.max(0, mid - delta),\n      Math.min(array.length, mid + delta),\n      [mid]\n    )\n    if (newPos == null) continue\n    // the range is either [mid - 1, newPos + 1] or [newPos - 1, mid + 1]\n    const i = Math.max(0, Math.min(newPos, mid) - 1)\n    const j = Math.min(array.length, Math.max(newPos, mid) + 1)\n    const currentExpense = expense(array, i, j)\n    move(array, mid, newPos)\n    const newExpense = expense(array, i, j)\n    // undo the move if newExpense isn't better:\n    if (lt(currentExpense, newExpense)) {\n      move(array, newPos, mid)\n    }\n  }\n  return array\n}\n\n/**\n * @param from inclusive\n * @param to exclusive\n * @param f\n */\nexport function range<T = number>(\n  from: number,\n  to: number,\n  f: (i: number) => T = ea => ea as any\n): T[] {\n  return stepRange(from, to, 1, f)\n}\n\n/**\n * @param to return an array up to but not including `to`\n * @see https://docs.python.org/2/library/functions.html#range\n */\nexport function stepRange<T = number>(\n  from: number,\n  to: number,\n  step: number = 1,\n  f: (i: number) => T = ea => ea as any\n): T[] {\n  const r: T[] = []\n  if (from < to) {\n    for (let i = from; i < to; i += step) {\n      r.push(f(i))\n    }\n  } else {\n    for (let i = from; i > to; i -= step) {\n      r.push(f(i))\n    }\n  }\n  return r\n}\n\n/**\n * `minuend - subtrahend`, or the elements in minuend that are not in\n * subtrahend. Only works with Primitives.\n *\n * @param {T[]} minuend (haystack)\n * @param {T[]} subtrahend (needles)\n * @returns {T[]} values in `minuend` that, according to `.valueOf()`, are not\n * in `subtrahend`. Neither arg is mutated.\n */\nexport function diff<T extends Primitive>(minuend: T[], subtrahend: T[]): T[] {\n  const s = new Set(subtrahend)\n  return minuend.filter(ea => !s.has(ea))\n}\n\nexport function last<T>(arr: Maybe<T[]>): Maybe<T> {\n  return arr != null ? arr[arr.length - 1] : undefined\n}\n\nexport function commaList(arr: string[], finalJoin = \"or\"): string {\n  if (arr.length <= 1) return arr.join(\"\")\n  if (arr.length === 2) return arr.join(\" \" + finalJoin + \" \")\n  return (\n    arr.slice(0, -1).join(\", \") + \", \" + finalJoin + \" \" + arr[arr.length - 1]\n  )\n}\n", "import { isEmpty } from \"./Array\"\nimport { eql } from \"./Eql\"\nimport { map } from \"./Maybe\"\nimport { Maybe } from \"./MaybeTypes\"\n\n// USED BY LOG: DON'T DEPEND ON ANYTHING (much)\n\n/**\n * `clear` will only remove any previously-memoized value.\n * `prior` returns the previously-memoized value.\n * `refresh` forces the thunk to be applied\n */\nexport interface MemoizedThunk<T> {\n  (): T\n  set(t: T): T\n  /** @return clear the prior value and return it */\n  clear(): Maybe<T>\n  /**\n   * Clears the prior value but doesn't return it (so we don't have to\n   * explicitly ignore unawaited promises)\n   */\n  unset(): void\n  prior(): Maybe<T>\n  /**\n   * Forces the underlying thunk or later to be applied\n   */\n  refresh(): T\n  ttl(): Maybe<number>\n  setTTL(ttl: number | undefined): void\n  onChange(listener: ChangeListener<T>): void\n  lastSetAgoMs(): number\n}\n\ntype ChangeListener<T> = (newResult: Maybe<T>, priorResult?: Maybe<T>) => any\n\n// HEY, FUTURE ME: yeah, I know you think something here should call\n// onClearCache(), but DON'T DO IT, MAN. lazy is used by lots of instances that\n// we want to be garbage collected, and that would create a huge memory leak.\n\nexport function lazy<T>(thunk: () => T, ttlMs?: number): MemoizedThunk<T> {\n  return new Lazy(thunk, ttlMs).asMemoizedThunk()\n}\n\nexport class Lazy<T> {\n  private lastSet = 0\n  private result: T | undefined\n  private readonly listeners: ChangeListener<T>[] = []\n\n  constructor(readonly thunk: () => T, public ttlMs?: number) {}\n\n  asMemoizedThunk(): MemoizedThunk<T> {\n    // As of 20200624 with node 14, this is better than fat arrows for memory consumption (!!?)\n    const f: any = this.apply.bind(this)\n    f.set = this.set.bind(this)\n    f.clear = this.clear.bind(this)\n    f.unset = this.unset.bind(this)\n    f.prior = this.prior.bind(this)\n    f.refresh = this.refresh.bind(this)\n    f.ttl = this.ttl.bind(this)\n    f.setTTL = this.setTTL.bind(this)\n    f.onChange = this.onChange.bind(this)\n    f.toJSON = this.toJSON.bind(this)\n    f.lastSetAgoMs = this.lastSetAgoMs.bind(this)\n    return f\n  }\n\n  private async onSetResult(priorP: Maybe<T>, currentP: Maybe<T>) {\n    if (isEmpty(this.listeners)) return\n    const prior = await priorP\n    const current = await currentP\n    if (!eql(prior, current)) {\n      for (const ea of this.listeners) ea(current, prior)\n    }\n  }\n\n  setResult(t: T) {\n    this.lastSet = Date.now()\n    void this.onSetResult(this.result, t)\n    return (this.result = t)\n  }\n\n  apply() {\n    if (\n      this.lastSet === 0 ||\n      (this.ttlMs != null && this.lastSet + this.ttlMs <= Date.now())\n    ) {\n      // NO PROMISE AWAITING HERE. Otherwise N calls would go through while we\n      // wait for the promise to resolve.\n      this.setResult(this.thunk())\n    }\n    return this.result!\n  }\n\n  set(t: T) {\n    return this.setResult(t)\n  }\n\n  unset() {\n    this.setResult(undefined as any)\n    this.lastSet = 0\n  }\n\n  clear() {\n    const prior = this.result\n    this.unset()\n    return prior\n  }\n\n  prior() {\n    return this.result\n  }\n\n  refresh() {\n    return this.setResult(this.thunk())\n  }\n\n  ttl() {\n    return this.ttlMs\n  }\n\n  setTTL(ttl: number) {\n    this.ttlMs = ttl\n  }\n\n  onChange(listener: ChangeListener<T>) {\n    this.listeners.push(listener)\n    map(this.result, listener)\n  }\n\n  // We don't support JSON encode/decode:\n  toJSON() {\n    return \"(Lazy)\"\n  }\n\n  lastSetAgoMs() {\n    return Date.now() - this.lastSet\n  }\n}\n", "import { lazy } from \"./Lazy\"\nimport { mapOr, orElse } from \"./Maybe\"\nimport { isNumber } from \"./Number\"\nimport { opt } from \"./Opt\"\n\nexport const secondMs = 1000\nexport const minuteMs = 60 * secondMs\nexport const hourMs = 60 * minuteMs\nexport const dayMs = 24 * hourMs\nexport const weekMs = 7 * dayMs\nexport const yearMs = 365.25 * dayMs\n\nconst dtf = lazy(\n  () =>\n    new Intl.DateTimeFormat(undefined, {\n      weekday: \"short\",\n      year: \"numeric\",\n      month: \"short\",\n      day: \"numeric\",\n      hour: \"numeric\",\n      minute: \"numeric\"\n    })\n)\n\nexport function fmtDateShort(d: Date | number) {\n  return opt(d)\n    .flatMap(ea => (ea instanceof Date ? ea.getTime() : ea))\n    .map(t => dtf().format(t))\n    .get()\n}\n\n/**\n * split an HMS string into a (possibly empty) prefix of zeroes and the remaining suffix.\n */\nexport function splitHMS(hms: string): string[] {\n  return mapOr(\n    /^[0:]{1,4}/.exec(hms),\n    m => [m[0], hms.substr(m[0].length)],\n    () => [\"\", hms]\n  )\n}\n\nexport function isDate(obj: any): obj is Date {\n  return obj instanceof Date\n}\n\n/**\n * @return Date `deltaMs` in the past\n */\nexport function ago(deltaMs: number, from?: Date): Date {\n  return new Date(orElse(from, new Date()).getTime() - deltaMs)\n}\n\n/**\n * @return Date `deltaMs` in the future\n */\nexport function hence(deltaMs: number, from?: Date): Date {\n  return ago(-deltaMs, from)\n}\n\nexport function unixtime(d?: Date | number): number {\n  const ms = isDate(d) ? d.getTime() : isNumber(d) ? d : Date.now()\n  return Math.floor(ms / secondMs)\n}\n\n// NOT FOR GENERAL USE. Only works for positive values.\nfunction pad2(i: number) {\n  const s = String(i)\n  return s.length >= 2 ? s : (\"0\" + s).slice(-2)\n}\n\n/**\n * Appropriate for filenames: yMMddHHmmss\n */\nexport function fmtYMDHMS(arg: Date | number): string {\n  const d = isDate(arg) ? arg : new Date(arg)\n  return (\n    d.getFullYear() +\n    pad2(d.getMonth() + 1) +\n    pad2(d.getDate()) +\n    pad2(d.getHours()) +\n    pad2(d.getMinutes()) +\n    pad2(d.getSeconds())\n  )\n}\n\n/**\n * ISO-formatted datestamp: y-MM-dd\n */\nexport function fmtIsoDate(ts: Date | number): string {\n  const d = isDate(ts) ? ts : new Date(ts)\n  return (\n    d.getFullYear() + \"-\" + pad2(d.getMonth() + 1) + \"-\" + pad2(d.getDate())\n  )\n}\n", "import { Maybe, MaybeNull } from \"./MaybeTypes\"\nimport { ThunkOrT, tot } from \"./Thunk\"\n\n// See https://basarat.gitbooks.io/typescript/content/docs/types/literal-types.html\n\nexport type StrEnumType<T extends string> = {\n  [K in T]: K\n}\n\nexport type StrEnumHelpers<T extends string> = {\n  values: T[]\n  length: number\n  has(s: MaybeNull<string>): s is T\n  indexOf(s: MaybeNull<string>): number\n  validOrElse<R>(s: MaybeNull<string>, defaultValue: ThunkOrT<R>): T | R\n  mapValid<R>(s: MaybeNull<string>, f: (t: T) => R): Maybe<R>\n}\n\nexport type StrEnum<T extends string> = StrEnumType<T> & StrEnumHelpers<T>\n\nexport type StrEnumKeys<Type> = Type extends StrEnum<infer X> ? X : never\n\nexport function strEnum<T extends string>(...o: T[]): StrEnum<T> {\n  const values = Object.freeze(o) as T[]\n\n  const dict: StrEnumType<T> = {} as any\n  for (const ea of values) {\n    dict[ea] = ea\n  }\n\n  const has = (s: MaybeNull<string>): s is T =>\n    s != null && values.includes(s as T)\n\n  const indexOf = (s: MaybeNull<string>) =>\n    s == null ? -1 : values.indexOf(s as T)\n\n  const validOrElse = <R>(s: MaybeNull<string>, defaultValue: ThunkOrT<R>) =>\n    has(s) ? s : tot(defaultValue)\n\n  const mapValid = <R>(s: string, f: (t: T) => R) =>\n    has(s) ? f(s as T) : undefined\n\n  return {\n    ...dict,\n    values,\n    length: values.length,\n    has,\n    indexOf,\n    validOrElse,\n    mapValid\n  }\n}\n\n// export const Directions = strEnum(\"North\", \"South\", \"East\", \"West\")\n// export type Direction = StrEnumKeys<typeof Directions>\n", "import { argv, env } from \"process\"\nimport { toS } from \"../fe/toS\"\nimport { isTrue } from \"../fe/Boolean\"\n\nexport function _nodeEnv() {\n  switch (toS(env.NODE_ENV).toLowerCase()) {\n    case \"test\":\n    case \"testing\":\n      return \"test\"\n    case \"dev\":\n    case \"development\":\n      return \"development\"\n    case \"prod\":\n    case \"production\":\n      return \"production\"\n    default:\n      if (argv.some(ea => ea.endsWith(\"mocha\") || ea.endsWith(\".spec.js\"))) {\n        return \"test\"\n      } else {\n        return \"production\"\n      }\n  }\n}\n\nexport const nodeEnv = (() => {\n  const ne = _nodeEnv()\n  // Make sure NODE_ENV gets the final value. If not, stuff like Pug stays in\n  // dev mode: https://pugjs.org/api/express.html\n  env.NODE_ENV = ne\n  return ne\n})()\n\nexport const isDev = nodeEnv === \"development\"\nexport const isTest = nodeEnv === \"test\"\nexport const isProd = nodeEnv === \"production\"\n\nexport function isSingleSpecTests() {\n  return isTest && isTrue(env.SINGLE_SPEC_TESTS)\n}\n\nexport function setSingleSpecTests(b: boolean) {\n  env.SINGLE_SPEC_TESTS = b ? \"true\" : \"false\"\n}\n\nexport const start = Date.now()\n", "import { Maybe } from \"../fe/MaybeTypes\"\n\nexport function isBoolean(object: any): object is boolean {\n  return typeof object === \"boolean\"\n}\n\n/**\n * (Fairly) strict coercion to true.\n *\n * @return false unless `o` is `true` or `1` (or stringifies to \"true\" or \"1\")\n */\nexport function isTrue(o: any): boolean {\n  if (typeof o === \"boolean\") return o\n  if (o == null) return false\n  if (o === 1) return true\n  const s = String(o).toLowerCase()\n  return [\"true\", \"1\"].includes(s)\n}\n\n/**\n * (Fairly) strict coercion to boolean. If parsing fails, returns undefined.\n */\nexport function toBoolean(o: any): Maybe<boolean> {\n  return isTrue(o) ? true : isFalse(o) ? false : undefined\n}\n\nexport function boolToInt(o: any) {\n  return isTrue(o) ? 1 : 0\n}\n\n/**\n * (Fairly) strict coercion to false.\n *\n * @return false unless `o` is `false` or `0` (or stringifies to \"false\" or\n * \"0\")\n */\nexport function isFalse(o: any): boolean {\n  if (typeof o === \"boolean\") return !o\n  if (o == null) return false\n  if (o === 0) return true\n  const s = String(o).toLowerCase()\n  return [\"false\", \"0\"].includes(s)\n}\n\nexport function or(arr: any[]): boolean {\n  return arr.some(ea => isTrue(ea))\n}\n\nexport function and(arr: any[]): boolean {\n  return arr.every(ea => isTrue(ea))\n}\n\nexport function mapBoolean<T>(obj: any, f: (b: boolean) => T): Maybe<T> {\n  return isTrue(obj) ? f(true) : isFalse(obj) ? f(false) : undefined\n}\n\nexport function mapTrue<T>(b: any, f: () => T): Maybe<T> {\n  return isTrue(b) ? f() : undefined\n}\n", "import { lazy } from \"../fe/Lazy\"\nimport { isProd, nodeEnv } from \"./NodeEnv\"\n\nexport const SimpleAppName = \"PhotoStructure\"\n\nexport const AppName = lazy(() => SimpleAppName + (isProd ? \"\" : `-${nodeEnv}`))\n", "function chalk(on: number, off: number) {\n  return (msg: string) => `\\u001b[${on}m${msg}\\u001b[${off}m`\n}\n\n// https://en.wikipedia.org/wiki/ANSI_escape_code#3/4_bit\n\nexport const black = chalk(30, 39)\nexport const red = chalk(31, 39)\nexport const green = chalk(32, 39)\nexport const yellow = chalk(33, 39)\nexport const blue = chalk(34, 39)\nexport const magenta = chalk(35, 39)\nexport const cyan = chalk(36, 39)\nexport const lightGrey = chalk(37, 39)\nexport const darkGrey = chalk(90, 39)\nexport const redBright = chalk(91, 39)\nexport const greenBright = chalk(92, 39)\nexport const yellowBright = chalk(93, 39)\nexport const blueBright = chalk(94, 39)\nexport const magentaBright = chalk(95, 39)\nexport const cyanBright = chalk(96, 39)\nexport const white = chalk(97, 39)\nexport const bgBlack = chalk(40, 49)\nexport const bgRed = chalk(41, 49)\nexport const bgGreen = chalk(42, 49)\nexport const bgYellow = chalk(43, 49)\nexport const bgBlue = chalk(44, 49)\nexport const bgMagenta = chalk(45, 49)\nexport const bgCyan = chalk(46, 49)\nexport const bgLightGrey = chalk(47, 49)\nexport const bgDarkGrey = chalk(100, 49)\nexport const bgRedBright = chalk(101, 49)\nexport const bgGreenBright = chalk(102, 49)\nexport const bgYellowBright = chalk(103, 49)\nexport const bgBlueBright = chalk(104, 49)\nexport const bgMagentaBright = chalk(105, 49)\nexport const bgCyanBright = chalk(106, 49)\nexport const bgWhite = chalk(107, 49)\n\n// export function ansiColor(msg: string, rgb: Triplet) {\n//   const [r,g,b] = clampRGB(rgb)\n//   return `\\u001b[38;2;${r};${g};${b}m\"`\n// }\n", "import { env } from \"process\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { firstValueCaseInsensitive } from \"../fe/Object\"\nimport { isTrue } from \"../fe/Boolean\"\n\n/**\n * Case-insensitive search for a given ENV key\n */\nexport function getEnv(key: string): Maybe<string> {\n  return firstValueCaseInsensitive(env, key)\n}\n\nexport function isEnvTrue(key: string): boolean {\n  return isTrue(getEnv(key))\n}\n", "import { compact, isEmpty, isNotEmpty, sortBy, uniq } from \"./Array\"\nimport { blank, notBlank } from \"./Blank\"\nimport { stringify } from \"./JSON\"\nimport { defined, Unpick } from \"./Maybe\"\nimport { Maybe, MaybeValued, ReqValued } from \"./MaybeTypes\"\nimport { isFunction } from \"./ObjectType\"\n\nexport interface Valued<T> {\n  [key: string]: T\n}\n\nexport type KeyOf<T> = string & keyof T\n// export type KeyOf<T> = Extract<keyof T, string>\n\nexport type StringValued = Valued<Maybe<string>>\nexport type StrBoolValued = Valued<Maybe<string | boolean>>\nexport type NativeValued = Valued<Maybe<string | boolean | number>>\n\nexport type Obj = Record<string, any>\n\nexport function tap<T>(o: T, block?: (t: T) => void): T {\n  if (block != null) {\n    block(o)\n  } else {\n    if (typeof o === \"string\") {\n      console.log(o)\n    } else {\n      console.dir(o, { depth: 3 })\n    }\n  }\n  return o\n}\n\nexport function keys<T extends Obj>(obj: Maybe<T>): KeyOf<T>[] {\n  // `typeof null == \"Obj\"` because js wants to blow your mind.\n  if (obj == null || typeof obj !== \"object\") return []\n  return Object.keys(obj).filter(\n    k =>\n      typeof k === \"string\" &&\n      (obj[\"propertyIsEnumerable\"] == null ||\n        obj[\"propertyIsEnumerable\"](k) === true)\n  )\n}\n\nexport function emptyObj(o: Maybe<Obj>) {\n  return isEmpty(keys(o))\n}\n\nexport function notEmptyObj(o: Maybe<Obj>): o is Obj {\n  return o != null && isNotEmpty(keys(o))\n}\n\nexport function mapCompactObj<T>(o: Maybe<Obj>, f: (o: Obj) => T): Maybe<T> {\n  const c = compactValues(o)\n  return notEmptyObj(c) ? f(c) : undefined\n}\n\nexport function values<T extends Obj>(o: T): T[KeyOf<T>][] {\n  return keys(o).map(k => o[k]) as any\n}\n\n// polyfill for Object.entries\nexport function entries<T extends Obj>(obj: T): [KeyOf<T>, T[KeyOf<T>]][] {\n  return keys(obj).map(ea => [ea, obj[ea]])\n}\n\nexport function fromEntries(\n  arr: Maybe<[Maybe<string>, any]>[],\n  obj?: any\n): any {\n  if (typeof obj !== \"object\") obj = {} // don't use Object.create(null), json stringify will break!\n  return compact(arr).reduce(\n    (acc, [k, v]) =>\n      tap(acc, () => {\n        if (k != null && v != null) {\n          acc[k] = v\n        }\n      }),\n    obj\n  )\n}\n\nexport function compactValues<T extends Obj>(\n  t: Maybe<T>\n): Maybe<ReqValued<Partial<T>>> {\n  if (t == null) return undefined\n  const pairs = entries(t).filter(([k, v]) => k != null && v != null)\n  return isEmpty(pairs) ? undefined : fromEntries(pairs)\n}\n\nexport function compactBlankValues<T extends Obj>(\n  t: Maybe<T>\n): Maybe<ReqValued<Partial<T>>> {\n  if (t == null) return undefined\n  const pairs = entries(t).filter(([k, v]) => k != null && notBlank(v))\n  return isEmpty(pairs) ? undefined : fromEntries(pairs)\n}\n\nexport function mapFields(\n  o: Obj,\n  f: (key: string, value: any) => Maybe<[string, Maybe<any>]>,\n  obj = {}\n): Obj {\n  const arr = compact(\n    entries(o)\n      // DON'T DELETE THIS SORT! This makes model upserts have the same prepared\n      // statements:\n      .sort(([k1], [k2]) =>\n        k1.localeCompare(k2, undefined, { sensitivity: \"base\" })\n      )\n      .map(([k, v]) => f(k, v))\n  )\n  return fromEntries(\n    arr.filter(([k, v]) => k != null && v != null),\n    obj\n  )\n}\n\nexport function pick<T, K extends keyof T>(\n  obj: T,\n  ...keyNames: K[]\n): Pick<T, K> {\n  if (obj == null) return obj\n  if (!keyNames.every(ea => typeof ea === \"string\"))\n    throw new Error(\"bad keys: \" + stringify(keyNames))\n  if (isEmpty(keyNames)) return {} as any\n  // PERF: unrolled\n  const result: Pick<T, K> = {} as any\n  for (const ea of keyNames) {\n    const v = obj[ea]\n    if (v != null) result[ea] = v\n  }\n  return result\n}\n\n/**\n * @return the first value in `obj` associated to `keyNames` that `predicate` returns true.\n */\nexport function pickFirst<T, K extends keyof T>(\n  obj: T,\n  keyNames: K[],\n  predicate: (v: T[K]) => boolean = defined\n): Maybe<T[K]> {\n  if (obj == null) return\n  for (const key of keyNames) {\n    if (predicate(obj[key])) return obj[key]\n  }\n  return\n}\n\nexport function omit<T extends Obj, S extends string>(\n  t: Maybe<T>,\n  ...keysToOmit: S[]\n): Unpick<T, S> {\n  if (t == null || keysToOmit.every(ea => blank((t as any)[ea] as any))) {\n    return t as any\n  }\n  const pairs = entries(t).filter(([k]) => !keysToOmit.includes(k as any))\n  return isEmpty(pairs) ? undefined : fromEntries(pairs)\n}\n\nexport function isReqValued<T>(t: MaybeValued<T>): t is ReqValued<T> {\n  return values(t as any).every(ea => ea != null)\n}\n\nexport function reqValuedOrElse<T>(t: MaybeValued<T>): Maybe<ReqValued<T>> {\n  return isReqValued(t) ? t : undefined\n}\n\nexport function mapReqValued<T, U>(\n  t: MaybeValued<T>,\n  f: (ea: ReqValued<T>) => U\n): Maybe<U> {\n  return isReqValued(t) ? f(t) : undefined\n}\n\nexport function onlyReqValued<T>(arr: MaybeValued<T>[]): ReqValued<T>[] {\n  return arr.filter(isReqValued)\n}\n\nexport function sortedKeys<T extends Obj>(obj: T): T {\n  return fromEntries(sortBy(entries(obj), ([k]) => k.toLowerCase()))\n}\n\nexport function filter<T extends Obj, K extends string & keyof T>(\n  obj: T,\n  predicate: (k: K, value: T[K]) => boolean\n): Partial<T> {\n  if (obj == null) return obj\n  return fromEntries(\n    entries(obj).filter(([k, v]) => predicate(k as K, v as T[K]))\n  )\n}\n\n/**\n * As opposed to .keys() which only returns fields directly associated to the\n * given Obj, `allKeys` returns all direct *and inherited* properties (if\n * `obj` is a class instance, for example)\n */\nexport function allKeys(obj: any): string[] {\n  const methods: string[] = keys(obj)\n  while (null != (obj = Reflect.getPrototypeOf(obj))) {\n    methods.push(\n      ...(Reflect.ownKeys(obj).filter(\n        key => typeof key === \"string\"\n      ) as string[])\n    )\n  }\n  return uniq(methods)\n}\n\nexport function maybeCall(o: any, method: string, ...args: any[]) {\n  return o != null && isFunction(o[method])\n    ? o[method].bind(o)(...args)\n    : undefined\n}\n\nexport function firstValueCaseInsensitive(o: any, key: string): any {\n  if (blank(key)) return\n  if (o[key] != null) return o[key]\n  const lckey = key.toLocaleLowerCase().normalize()\n  for (const k of keys(o)) {\n    if (lckey === k.toLocaleLowerCase().normalize() && o[k] != null) return o[k]\n  }\n  return\n}\n", "import { inspect } from \"util\"\nimport {\n  compact,\n  copyArrayTo,\n  filterInPlace,\n  isEmpty,\n  isNotEmpty,\n  sort,\n  stepRange,\n  uniqBy\n} from \"../fe/Array\"\nimport { notBlank } from \"../fe/Blank\"\nimport { stringify } from \"../fe/JSON\"\nimport { Defined, defined, map, mapOr } from \"../fe/Maybe\"\nimport { Maybe, MaybeNull, PromiseMaybe } from \"../fe/MaybeTypes\"\nimport { times } from \"../fe/Number\"\nimport { tap } from \"../fe/Object\"\nimport { isFunction } from \"../fe/ObjectType\"\nimport { SyncOrAsync } from \"../fe/OptAsync\"\nimport {\n  Comparable,\n  gt,\n  isPrimitive,\n  lt,\n  Primitivable,\n  Primitive\n} from \"../fe/Primitive\"\nimport { Thunk } from \"../fe/Thunk\"\nimport { toA } from \"../fe/toA\"\nimport { eql } from \"./Eql\"\n\n// Extract the element type of an array:\nexport type ElementType<T extends readonly unknown[]> = T[number]\n// type T = ElementType<SomeArrayType[]>\n\n/**\n * @return true iff all `objects` are neither `undefined` nor `null`. Note\n * that `[]` returns true.\n */\nexport function allDefined<T>(\n  arr: MaybeNull<MaybeNull<T>[]>\n): arr is Defined<T>[] {\n  return defined(arr) && arr.every(defined)\n}\n\nexport function mapAllDefined<T, U>(\n  arr: MaybeNull<MaybeNull<T>[]>,\n  f: (t: T[]) => U\n): Maybe<U> {\n  return allDefined(arr) ? f(arr) : undefined\n}\n\nexport function mapAll<T, V>(\n  arr: MaybeNull<MaybeNull<T>[]>,\n  f: (ea: T[]) => V\n): Maybe<V> {\n  return allDefined(arr) ? f(arr) : undefined\n}\n\n/**\n * @return true iff all `objects` are `undefined` or `null`\n */\nexport function allNotDefined(objects: any[]): boolean {\n  return objects == null || objects.every(ea => ea == null)\n}\n\nexport function allNotBlank(...arr: MaybeNull<any>[]): boolean {\n  return arr != null && arr.every(notBlank)\n}\n\n/**\n * @return true iff any `objects` are `undefined` or `null`. Note that `[]`\n * returns false (as there aren't not-defined instances).\n */\nexport function anyNotDefined(objects: any[]): boolean {\n  return objects == null || objects.some(ea => ea == null)\n}\n\nexport function anyDefined(objects: any[]): boolean {\n  return objects != null && objects.some(ea => ea != null)\n}\n\n/**\n * @return the first non-`null` result of `f`, or if `f` is omitted, the first\n * non-null value in `arr`.\n */\nexport function first<T, R>(\n  arr: Maybe<Maybe<T>[]>,\n  f: (t: T) => MaybeNull<R>\n): Maybe<R> {\n  if (arr != null) {\n    for (const t of compact(arr)) {\n      const r = f(t)\n      if (r != null) {\n        return r\n      }\n    }\n  }\n  return\n}\n\n/**\n * Return the first result from `f` that is defined.\n * @see Array#first\n * @see Later#firstDefinedLater\n */\nexport async function firstAsync<T, R>(\n  arr: Maybe<Maybe<T>[]>,\n  f: (t: T, index: number) => SyncOrAsync<MaybeNull<R>>\n): PromiseMaybe<R> {\n  if (arr != null) {\n    let index = -1\n    for (const t of arr) {\n      index++\n      try {\n        if (t == null) continue\n        const r = await f(t, index)\n        if (r != null) {\n          return r\n        }\n      } catch (err) {\n        //\n      }\n    }\n  }\n  return undefined\n}\n\n/**\n * @see Later#firstDefinedLater\n */\nexport function firstNonEmptyThunk<T>(\n  ...thunks: Thunk<Maybe<T[]>>[]\n): Maybe<T[]> {\n  for (const t of thunks) {\n    const arr = t()\n    if (isNotEmpty(arr)) {\n      return arr\n    }\n  }\n  return\n}\n\n/**\n * @return the last value in the array that satisfies the predicate\n */\nexport function findLast<T>(arr: T[], predicate: (t: T) => boolean): Maybe<T> {\n  for (let i = arr.length - 1; i >= 0; i--) {\n    if (predicate(arr[i])) return arr[i]\n  }\n  return\n}\n\n/**\n * @return the last index in the array that satisfies the predicate\n */\nexport function findLastIndex<T>(\n  arr: T[],\n  predicate: (t: T) => boolean\n): number {\n  for (let i = arr.length - 1; i >= 0; i--) {\n    if (predicate(arr[i])) return i\n  }\n  return -1\n}\n\nexport function concat<T>(...arrs: (MaybeNull<T> | MaybeNull<T>[])[]): T[] {\n  const arr: T[] = []\n  for (const ea of arrs) {\n    if (Array.isArray(ea)) {\n      for (const elem of ea) {\n        if (elem != null) arr.push(elem)\n      }\n    } else if (ea != null) {\n      arr.push(ea)\n    }\n  }\n  return arr\n}\n\n// Can't call this delete, as that's a javascript keyword\nexport function remove<T>(arr: T[], ...element: T[]): boolean {\n  const before = arr.length\n  filterInPlace(arr, ea => element.every(ea2 => !eql(ea, ea2)))\n  return before !== arr.length\n}\n\nexport function moveToEnd<T>(arr: T[], element: T): T[] {\n  remove(arr, element)\n  arr.push(element)\n  return arr\n}\n\nexport function moveIndexToEnd<T>(arr: T[], index: number): T[] {\n  const moved = arr[index]\n  if (moved == null) return arr\n  arr.push(moved)\n  for (let i = index; i < arr.length - 1; i++) {\n    arr[i] = arr[i + 1]\n  }\n  arr.length = arr.length - 1\n  return arr\n}\n\nconst primitiveValueOfOrElse = (a: any) => {\n  if (isPrimitive(a)) {\n    return a\n  }\n  // [].valueOf() is worthless, so use json\n  if (Array.isArray(a)) {\n    return stringify(a)\n  }\n  if (isFunction(a.valueOf)) {\n    return a.valueOf()\n  } else {\n    throw new Error(\"Cannot get primitive value for \" + inspect(a))\n  }\n}\n\n/**\n * `minuend - subtrahend`.\n *\n * @template T must have a .valueOf() implementation\n * @param {T[]} minuend (haystack)\n * @param {T[]} subtrahend (needles)\n * @returns {T[]} values in `minuend` that, according to `.valueOf()`, are\n * not in `subtrahend`. Neither arg is mutated.\n */\nexport function diff<T>(\n  minuend: T[],\n  subtrahend: T[],\n  valueOf: (t: T) => Primitive = primitiveValueOfOrElse\n): T[] {\n  const s = new Set(subtrahend.map(valueOf))\n  return minuend.filter(ea => !s.has(valueOf(ea)))\n}\n\n/**\n * @template T must have a .valueOf() implementation\n * @return the values in both `a` and `b`\n */\nexport function intersection<T>(\n  a: T[],\n  b: T[],\n  valueOf: (t: T) => Primitive = primitiveValueOfOrElse\n): T[] {\n  const s = new Set(b.map(valueOf))\n  return a.filter(ea => s.has(valueOf(ea)))\n}\n\nexport function diceCoeff<T>(\n  a: T[],\n  b: T[],\n  valueOf: (t: T) => Primitive = primitiveValueOfOrElse\n): number {\n  if (isEmpty(a) && isEmpty(b)) return 1\n  return (intersection(a, b, valueOf).length * 2) / (a.length + b.length)\n}\n\n/**\n * @return true iff all elements in `a` are in `b` and all elements in `b` are\n * in `a`. Order is ignored. Elements must be sortable, however.\n */\nexport function eqlContents(a: any[], b: any[]): boolean {\n  return zip(sort(a), sort(b)).every(([x, y]) => x === y)\n}\n\n/**\n * Remove the first item from `arr` where the `predicate` returns `true`.\n * @return the element removed from `arr`\n */\nexport function removeFirst<T>(\n  arr: T[],\n  predicate: (item: T, index: number, sourceArray: T[]) => boolean\n): Maybe<T> {\n  const idx = arr.findIndex(predicate)\n  return idx >= 0 ? arr.splice(idx, 1)[0] : undefined\n}\n\nexport function uniqInPlace<T>(\n  arr: T[],\n  f: (t: T) => Maybe<Primitive> = ea => stringify(ea)\n): void {\n  copyArrayTo(uniqBy(arr, f), arr)\n}\n\nexport function partition<T>(\n  arr: T[],\n  filter: (t: T, index: number) => boolean\n): [T[], T[]] {\n  const accept: T[] = []\n  const reject: T[] = []\n  arr.forEach((ea, i) => (filter(ea, i) ? accept : reject).push(ea))\n  return [accept, reject]\n}\n\n/**\n * `Uniq -c`: return unique strings and their count\n */\nexport function uniqCount<T extends Primitive>(\n  arr: T[]\n): { t: T; count: number }[] {\n  return _uniqCount(arr.sort())\n}\n\nfunction _uniqCount<T extends Primitive>(\n  sortedArr: T[]\n): { t: T; count: number }[] {\n  if (sortedArr == null || sortedArr.length === 0) return []\n  const t = sortedArr[0]\n  const lastElem = sortedArr.lastIndexOf(t)\n  return [\n    { t, count: lastElem + 1 },\n    ..._uniqCount(sortedArr.slice(lastElem + 1))\n  ]\n}\n\nexport function mapCompact<T, R>(\n  arr: MaybeNull<T>[],\n  f: (t: T) => Maybe<R>\n): R[] {\n  return compact(compact(arr).map(f))\n}\n\nexport function toMapEntries<T, K, V>(\n  arr: T[],\n  f: (t: T) => MaybeNull<[K, V]>\n): Map<K, V> {\n  return new Map<K, V>(arr.map(f).filter(defined) as [K, V][])\n}\n\nexport function flatMap<T, U>(arr: T[], f: (t: T) => Maybe<Maybe<U>[]>): U[] {\n  return arr.reduce(\n    (prev: U[], curr: T) => prev.concat(...compact(f(curr))),\n    []\n  )\n}\n\nexport function retainLastN<T>(arr: T[], length: number): T[] {\n  if (arr.length > length) {\n    arr.splice(0, arr.length - length)\n  }\n  return arr\n}\n\nexport function retainFirstN<T>(arr: T[], length: number): T[] {\n  arr.length = Math.min(arr.length, length)\n  return arr\n}\n\nexport interface Surrounding<T> {\n  before: T[]\n  after: T[]\n}\n\nexport function contextAround<T>(\n  arr: T[],\n  limitBefore: number,\n  limitAfter: number,\n  predicate: (t: T) => boolean\n): Maybe<Surrounding<T>> {\n  const idx = arr.findIndex(predicate)\n  if (idx === -1) {\n    return\n  } else {\n    const before =\n      idx === 0 ? [] : arr.slice(Math.max(0, idx - limitBefore), idx)\n    const after =\n      idx === arr.length - 1\n        ? []\n        : arr.slice(idx + 1, Math.min(idx + 1 + limitAfter, arr.length))\n    return { before, after }\n  }\n}\n\nexport function zip<T1, T2>(arr1: T1[], arr2: T2[]): [T1, T2][]\nexport function zip<T1, T2, T3>(\n  arr1: T1[],\n  arr2: T2[],\n  arr3: T3[]\n): [T1, T2, T3][]\nexport function zip<T1, T2, T3, T4>(\n  arr1: T1[],\n  arr2: T2[],\n  arr3: T3[],\n  arr4: T4[]\n): [T1, T2, T3, T4][]\nexport function zip<T1, T2, T3, T4, T5>(\n  arr1: T1[],\n  arr2: T2[],\n  arr3: T3[],\n  arr4: T4[],\n  arr5: T5[]\n): [T1, T2, T3, T4, T5][]\nexport function zip<T1, T2, T3, T4, T5, T6>(\n  arr1: T1[],\n  arr2: T2[],\n  arr3: T3[],\n  arr4: T4[],\n  arr5: T5[],\n  arr6: T6[]\n): [T1, T2, T3, T4, T5, T6][]\nexport function zip<T1, T2, T3, T4, T5, T6, T7>(\n  arr1: T1[],\n  arr2: T2[],\n  arr3: T3[],\n  arr4: T4[],\n  arr5: T5[],\n  arr6: T6[],\n  arr7: T7[]\n): [T1, T2, T3, T4, T5, T6, T7][]\nexport function zip<T1, T2, T3, T4, T5, T6, T7, T8>(\n  arr1: T1[],\n  arr2: T2[],\n  arr3: T3[],\n  arr4: T4[],\n  arr5: T5[],\n  arr6: T6[],\n  arr7: T7[],\n  arr8: T8[]\n): [T1, T2, T3, T4, T5, T6, T7, T8][]\nexport function zip<T>(...arrarr: T[][]): T[][] {\n  const len = Math.max(...arrarr.map(ea => ea.length))\n  return times(len, i => arrarr.map(ea => ea[i]))\n}\n\nexport function flatZip<T>(...arrarr: T[][]): T[] {\n  const len = Math.max(...arrarr.map(ea => ea.length))\n  const r: T[] = []\n  times(len, i => arrarr.map(ea => r.push(ea[i])))\n  return r\n}\n\nexport function unzip<T1, T2>(arr: [T1, T2][]): [T1[], T2[]] {\n  return [arr.map(([t1]) => t1), arr.map(([, t2]) => t2)]\n}\n\n/**\n * Given [A,B,C], return [A], [A,B], [A,B,C]\n */\nexport function ancestry<T>(arr: T[]): T[][] {\n  return times(arr.length, i => arr.slice(0, i + 1))\n}\n\nexport function min<T extends Primitivable>(arr: MaybeNull<T>[]): Maybe<T> {\n  return arr[leastIndex(arr)] as Maybe<T>\n}\n\n/**\n * Return the first index into `arr` holding the least value (using `valueOf`\n * of T)\n */\nexport function leastIndex<T extends Primitivable>(\n  arr: MaybeNull<T>[]\n): number {\n  return leastIndexBy(arr, ea => ea.valueOf())\n}\n\nexport function max<T extends Primitivable>(arr: MaybeNull<T>[]): Maybe<T> {\n  return arr[greatestIndex(arr)] as Maybe<T>\n}\n\n/**\n * Return the first index into `arr` holding the largest value (using `valueOf`\n * of T)\n */\nexport function greatestIndex<T extends Primitivable>(\n  arr: MaybeNull<T>[]\n): number {\n  return greatestIndexBy(arr, ea => ea.valueOf())\n}\n\nexport function leastIndexBy<T>(\n  arr: MaybeNull<T>[],\n  valueOf: (t: T) => Maybe<Comparable>\n): number {\n  return estIndex(arr, valueOf, (a, b) => lt(a, b))\n}\n\nexport function greatestIndexBy<T>(\n  arr: MaybeNull<T>[],\n  valueOf: (t: T) => Maybe<Comparable>\n): number {\n  return estIndex(arr, valueOf, (a, b) => gt(a, b))\n}\n\nexport function leastBy<T>(\n  arr: MaybeNull<T>[],\n  valueOf: (t: T) => Maybe<Comparable>\n): Maybe<T> {\n  return arr[leastIndexBy(arr, valueOf)] as Maybe<T>\n}\n\nexport function greatestBy<T>(\n  arr: MaybeNull<T>[],\n  valueOf: (t: T) => Maybe<Comparable>\n): Maybe<T> {\n  return arr[greatestIndexBy(arr, valueOf)] as Maybe<T>\n}\n\nfunction estIndex<T>(\n  arr: MaybeNull<T>[],\n  valueOf: (t: T) => Maybe<Comparable>,\n  predicate: (a: Comparable, b: Comparable) => boolean\n): number {\n  if (isEmpty(arr)) return -1\n\n  let result = -1\n  let prior: Maybe<Comparable>\n\n  for (let i = 0; i < arr.length; i++) {\n    const ea = arr[i]\n    if (ea != null) {\n      const v = valueOf(ea)\n      if (v != null) {\n        if (prior == null || predicate(v, prior) === true) {\n          result = i\n          prior = v\n        }\n      }\n    }\n  }\n  return result\n}\n\nexport interface ArrayLike<T> {\n  length: number\n  [index: number]: Maybe<T>\n}\n\nexport function reverse<T extends ArrayLike<any>>(arr: T): T {\n  const r = []\n  for (let i = arr.length - 1; i >= 0; i--) {\n    r.push(arr[i])\n  }\n  return r as any\n}\n\nexport function batches<T>(arr: T[], batchsize: number): T[][] {\n  if (batchsize <= 0) batchsize = 1\n  return stepRange(0, arr.length, batchsize, i => arr.slice(i, i + batchsize))\n}\n\nexport function collectBatched<T1, T2>(\n  arr: T1[],\n  batchSize: number,\n  f: (arr: T1[]) => Maybe<Maybe<T2>[]>\n): T2[] {\n  const result: T2[] = []\n  for (const batchArr of batches(toA(arr), batchSize)) {\n    result.push(...compact(f(compact(batchArr))))\n  }\n  return result\n}\n\nexport function contextFilter<T>(\n  arr: T[],\n  predicate: (t: T, idx: number, lastPass: Maybe<T>) => boolean\n): T[] {\n  let lastPass: Maybe<T>\n  return arr.filter((ea, idx) =>\n    tap(predicate(ea, idx, lastPass), result => {\n      if (result) lastPass = ea\n    })\n  )\n}\n\nexport async function clusterStrictAsync<T>(\n  arr: T[],\n  cmp: (a: T, b: T) => SyncOrAsync<boolean>\n): Promise<T[][]> {\n  return clusterAsync(arr, cmp, true)\n}\n\nexport async function clusterAsync<T>(\n  arr: T[],\n  cmp: (a: T, b: T) => SyncOrAsync<boolean>,\n  strict: boolean = false\n): Promise<T[][]> {\n  const result: T[][] = []\n  outer: for (const ea of arr) {\n    for (const resultArr of result) {\n      if (strict) {\n        if (await everyAsync(resultArr, prior => cmp(ea, prior))) {\n          resultArr.push(ea)\n          continue outer\n        }\n      } else {\n        if (await someAsync(resultArr, prior => cmp(ea, prior))) {\n          resultArr.push(ea)\n          continue outer\n        }\n      }\n    }\n    result.push([ea])\n  }\n  return result\n}\n\n/**\n * Return if any `f` returns true.\n * @see Array#some\n */\nexport async function someAsync<T>(\n  arr: T[],\n  f: (t: T, index: number) => SyncOrAsync<boolean>\n): Promise<boolean> {\n  if (arr != null) {\n    for (let i = 0; i < arr.length; i++) {\n      if (await f(arr[i], i)) return true\n    }\n  }\n  return false\n}\n\n/**\n * Return if every `f` returns true.\n * @see Array#every\n */\nexport async function everyAsync<T>(\n  arr: T[],\n  f: (t: T, index: number) => SyncOrAsync<boolean>\n): Promise<boolean> {\n  return isEmpty(arr) || (await Promise.all(arr.map(f))).every(ea => ea)\n}\n\nexport function firstIndexNearest<T>({\n  arr,\n  fromIndex,\n  pred,\n  maxDelta\n}: {\n  arr: T[]\n  fromIndex: number\n  pred: (t: T, index: number) => boolean\n  maxDelta: number\n}): Maybe<number> {\n  for (let i = 1; i < Math.min(maxDelta + 1, arr.length); i++) {\n    {\n      const before = fromIndex - i\n      if (before >= 0 && true === map(arr[before], ea => pred(ea, before))) {\n        return before\n      }\n    }\n    {\n      const after = fromIndex + i\n      if (after < arr.length && pred(arr[after]!, after)) return after\n    }\n  }\n  return\n}\n\nexport function dupes<T extends Primitive>(arr: Maybe<T>[]) {\n  const mm = new Map<T, number>()\n  for (const ea of arr) {\n    if (ea != null)\n      mm.set(\n        ea,\n        mapOr(mm.get(ea), i => i + 1, 1)\n      )\n  }\n  return toA(mm.entries()).filter(([, v]) => v > 1)\n}\n\nexport function leftPadArray<T>(arr: T[], minLength: number, pad: T) {\n  if (arr.length < minLength) {\n    arr.unshift(...times(minLength - arr.length, () => pad))\n  }\n  return arr\n}\n", "import { map2Or } from \"../fe/Maybe\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { pick } from \"../fe/Object\"\nimport { MaybeSyncOrAsync } from \"../fe/OptAsync\"\n\nconst de = require(\"deep-eql\")\n\nexport function eql<T>(a: Maybe<T>, b: Maybe<T>): boolean {\n  return de(a, b)\n}\n\nexport function definedAndEql<T>(a: Maybe<T>, b: Maybe<T>): boolean {\n  return a == null || b == null ? false : eql(a, b)\n}\n\nexport function definedAndNotEql<T>(a: Maybe<T>, b: Maybe<T>): boolean {\n  return a != null && b != null && !eql(a, b)\n}\n\nexport async function eqlAsync<T>(\n  a: MaybeSyncOrAsync<T>,\n  b: MaybeSyncOrAsync<T>\n): Promise<boolean> {\n  return map2Or(await a, await b, eql, () => false)\n}\n\nexport async function eqlAsyncPicked<T, K extends keyof T>(\n  a: MaybeSyncOrAsync<T>,\n  b: MaybeSyncOrAsync<T>,\n  ...keys: K[]\n): Promise<boolean> {\n  return map2Or(\n    await a,\n    await b,\n    (a1, a2) => eql(pick(a1, ...keys), pick(a2, ...keys)),\n    () => false\n  )\n}\n", "import { inspect } from \"util\"\nimport { flatten, mapNotEmpty } from \"../../fe/Array\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { sigFigs } from \"../../fe/Number\"\nimport { tap } from \"../../fe/Object\"\nimport { zip } from \"../Array\"\nimport { BoundedList } from \"../BoundedList\"\nimport { CountingSet } from \"../CountingSet\"\nimport { mapGt0 } from \"../Number\"\nimport { avg, slope, stdDev, weightedAvg } from \"./Vector\"\n\nexport interface AverageStats {\n  k: number\n  mean?: number\n  mode?: number\n  sd?: number\n  max?: number\n  min?: number\n  sum?: number\n}\n\nexport function averageStats(vec: number[]) {\n  return new Average().pushAll(vec).stats()\n}\n\nexport class Average {\n  static merge(a: Average, b: Average): Average {\n    if (a.n === 0 && b.n === 0) {\n      return new Average(Math.max(a.maxSamples, b.maxSamples))\n    } else if (a.n === 0) {\n      return b.clone()\n    } else if (b.n === 0) {\n      return a.clone()\n    } else if (a.n <= a.maxSamples) {\n      const r = b.clone()\n      r.pushAll(a.samples)\n      return r\n    } else if (b.n <= b.maxSamples) {\n      const r = a.clone()\n      r.pushAll(b.samples)\n      return r\n    } else {\n      const r = new Average(Math.max(a.maxSamples, b.maxSamples))\n      r._n = a.n + b.n\n      r._avg = (a._avg! * a.n) / r.n + (b._avg! * b.n) / r.n\n      r._min = Math.min(a._min!, b._min!)\n      r._max = Math.max(a._max!, b._max!)\n      r._m = (a._m! * a.n) / r.n + (b._m! * b.n) / r.n\n      r._s = (a._s! * a.n) / r.n + (b._s! * b.n) / r.n\n      const samples = flatten(zip(a.samples, b.samples))\n      r._samples.push(...samples)\n      r._weightedTotalAvg = weightedAvg([r._avg, ...samples])\n      return r\n    }\n  }\n\n  protected _n: number\n  protected _avg?: number\n  protected _min?: number\n  protected _max?: number\n  protected _m?: number\n  protected _s?: number\n  protected _weightedTotalAvg?: number\n  protected readonly _samples: BoundedList<number>\n\n  constructor(readonly maxSamples: number = 20) {\n    this._n = 0\n    this._samples = new BoundedList(maxSamples)\n  }\n\n  [inspect.custom]() {\n    return this.stats()\n  }\n\n  push(x: number): number {\n    if (!isFinite(x)) throw new Error(\"Average.push(\" + x + \"): not a number\")\n    this._n++\n    this._samples.push(x)\n    this._min = this._min == null ? x : Math.min(x, this._min)\n    this._max = this._max == null ? x : Math.max(x, this._max)\n\n    // https://math.stackexchange.com/a/116344\n    // https://www.johndcook.com/blog/standard_deviation/\n    if (\n      this._n === 1 ||\n      this._m == null ||\n      this._s == null ||\n      this._avg == null ||\n      this._weightedTotalAvg == null\n    ) {\n      this._m = x\n      this._s = 0\n      this._avg = x\n      this._weightedTotalAvg = x\n    } else {\n      const priorM = this._m\n      this._m += (x - this._m) / this._n\n      this._s += (x - priorM) * (x - this._m)\n      this._avg = (this._avg * (this._n - 1)) / this._n + x / this._n\n      this._weightedTotalAvg = (this._weightedTotalAvg + x) / 2\n    }\n    return x\n  }\n\n  clone(): Average {\n    return tap(new Average(this.maxSamples), ea => {\n      ea._n = this._n\n      ea._avg = this._avg\n      ea._min = this._min\n      ea._max = this._max\n      ea._m = this._m\n      ea._s = this._s\n      ea._weightedTotalAvg = this._weightedTotalAvg\n      ea._samples.push(...this._samples)\n    })\n  }\n\n  pushAll(arr: number[]): this {\n    arr.forEach(ea => this.push(ea))\n    return this\n  }\n\n  stats(sigfigs = 2): AverageStats {\n    const sf = (i?: number) => map(i, (ea: number) => sigFigs(ea, sigfigs))\n    const o: AverageStats = {} as any\n    if (!this.empty) {\n      o.sum = sf(this.sum)\n      o.mean = sf(this.avg)\n      // o.mode = sf(this.sampleMode)\n      o.sd = sf(this.stdDev)\n      // o.max = sf(this.max)\n      // o.min = sf(this.min)\n    }\n    o.k = sigFigs(this.n, sigfigs)\n    return o\n  }\n\n  get empty(): boolean {\n    return this._n === 0\n  }\n\n  /**\n   * @return the total number of samples provided to `push()`\n   */\n  get n(): number {\n    return this._n\n  }\n\n  get avg(): Maybe<number> {\n    return this.empty ? undefined : sigFigs(this._avg!, 4)\n  }\n\n  get sum(): number {\n    return this._avg == null || this.empty ? 0 : this._avg! * this._n\n  }\n\n  get max(): Maybe<number> {\n    return this._max\n  }\n\n  get min(): Maybe<number> {\n    return this._min\n  }\n\n  /**\n   * @return mean + 1 SD\n   */\n  get p84(): Maybe<number> {\n    return mapGt0(this.avg, ea => mapGt0(this.stdDev, sd => ea + sd))\n  }\n\n  get variance(): Maybe<number> {\n    return this._n <= 1 ? undefined : this._s! / (this._n - 1)\n  }\n\n  get stdDev(): Maybe<number> {\n    return map(this.variance, Math.sqrt)\n  }\n\n  get sampleMode(): Maybe<number> {\n    return map(this.sampleModes(1), ea => ea[0])\n  }\n\n  sampleModes(n: number): Maybe<number[]> {\n    if (this.empty) return\n    const c = new CountingSet<number>()\n    this._samples.forEach(ea => c.incr(ea))\n    return c.topKeys(n)\n  }\n\n  get sampleStdDev(): Maybe<number> {\n    return mapNotEmpty(this._samples, stdDev)\n  }\n\n  get sampleAvg(): Maybe<number> {\n    return mapNotEmpty(this._samples, avg)\n  }\n\n  get sampleSlope(): number {\n    return orElse(mapNotEmpty(this._samples, slope), 0)\n  }\n\n  get samples(): number[] {\n    return [...this._samples]\n  }\n\n  p(percentile: number): number {\n    if (this._samples.length === 0) return 0 // NaN instead?\n    const arr = [...this._samples].sort((a, b) => a - b)\n    const idx = Math.floor(arr.length * (percentile / 100))\n    return arr[idx]\n  }\n\n  /**\n   * weighted average of the last `sampleCount` values\n   */\n  get weightedSampleAvg(): Maybe<number> {\n    return mapNotEmpty(this._samples, arr => sigFigs(weightedAvg(arr), 4))\n  }\n\n  /**\n   * weighted average of all values\n   */\n  get weightedTotalAvg(): Maybe<number> {\n    return this._weightedTotalAvg\n  }\n\n  clear(): void {\n    this._avg = 0\n    this._n = 0\n    this._weightedTotalAvg = 0\n    this._samples.length = 0\n  }\n}\n", "import { List } from \"../fe/List\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { clamp, times } from \"../fe/Number\"\n\nexport class BoundedList<T> implements Iterable<T>, List<T> {\n  // round-robin implementation:\n  private readonly store: T[]\n  private _length = 0\n  private _firstIndex = 0\n  constructor(readonly maxLength: number) {\n    if (maxLength > 1000)\n      throw new Error(\"BoundedList.maxLength of \" + maxLength)\n    this.store = new Array<T>(...(times(maxLength, () => null) as any))\n  }\n\n  /**\n   * @param index follows https://github.com/tc39/proposal-item-method\n   */\n  private mapIndex<U>(index: number, f: (storeIndex: number) => U): Maybe<U> {\n    index = Math.trunc(index) ?? 0\n    if (index < 0) {\n      index += this._length\n    }\n    return index < 0 || index > this._length - 1\n      ? undefined\n      : f((index + this._firstIndex + this.maxLength) % this.maxLength)\n  }\n\n  // [i: number]: T {\n  //   return this.get(i) as any\n  // }\n\n  /**\n   * @see https://github.com/tc39/proposal-item-method\n   */\n  item(n: number): T {\n    return this.mapIndex(n, idx => this.store[idx]) as T\n  }\n\n  set(n: number, value: T) {\n    return this.mapIndex(n, idx => (this.store[idx] = value))\n  }\n\n  get length(): number {\n    return this._length\n  }\n\n  set length(l: number) {\n    this._length = clamp(0, this._length, l)\n  }\n\n  clear() {\n    this.length = 0\n  }\n\n  [Symbol.iterator](): IterableIterator<T> {\n    // eslint-disable-next-line @typescript-eslint/no-this-alias\n    const self = this\n    function* iter(): IterableIterator<T> {\n      for (let i = 0; i < self.length; i++) {\n        yield self.mapIndex(i, ea => self.store[ea])!\n      }\n    }\n    return iter()\n  }\n\n  push(...items: T[]): number {\n    // Don't bother pushing more than the last maxLength items:\n    for (const item of items.slice(-this.maxLength)) {\n      if (this._length < this.maxLength) {\n        this._length++\n      } else {\n        // push 1 entry off the head:\n        this._firstIndex++\n        this._firstIndex = this._firstIndex % this.maxLength\n      }\n      this.mapIndex(this._length - 1, idx => {\n        this.store[idx] = item\n      })\n    }\n    return this._length\n  }\n\n  pop(): T | undefined {\n    return this.mapIndex(this._length - 1, idx => {\n      this._length--\n      return this.store[idx]\n    })\n  }\n\n  unshift(...items: T[]): number {\n    for (const item of items.reverse()) {\n      if (this._length < this.maxLength) {\n        this._length++\n      }\n      // push 1 entry off the head:\n      this._firstIndex--\n      this.mapIndex(0, idx => {\n        this.store[idx] = item\n        this._firstIndex = idx\n      })\n    }\n    return this._length\n  }\n\n  shift(): T | undefined {\n    return this.mapIndex(0, idx => {\n      this._firstIndex++\n      this._length--\n      return this.store[idx]\n    })\n  }\n\n  shiftOrFirst() {\n    return this.length > 1 ? this.shift() : this.item(0)\n  }\n\n  every(callbackfn: (value: T, index: number) => boolean): boolean {\n    for (let i = 0; i < this._length; i++) {\n      if (!callbackfn(this.item(i), i)) return false\n    }\n    return true\n  }\n\n  some(callbackfn: (value: T, index: number) => boolean): boolean {\n    for (let i = 0; i < this._length; i++) {\n      if (callbackfn(this.item(i), i)) return true\n    }\n    return false\n  }\n\n  forEach(callbackfn: (value: T, index: number) => void): void {\n    for (let i = 0; i < this._length; i++) {\n      callbackfn(this.item(i), i)\n    }\n  }\n\n  map<U>(callbackfn: (value: T, index: number) => U): U[] {\n    const arr = []\n    for (let i = 0; i < this._length; i++) {\n      arr.push(callbackfn(this.item(i), i))\n    }\n    return arr\n  }\n\n  reduce<U>(\n    callbackfn: (previousValue: U, currentValue: T, currentIndex: number) => U,\n    initialValue: U\n  ): U {\n    let acc = initialValue\n    for (let i = 0; i < this._length; i++) {\n      acc = callbackfn(acc, this.item(i), i)\n    }\n    return acc\n  }\n\n  reverse(): this {\n    for (let i = 0; i < Math.floor(this._length / 2); i++) {\n      this.mapIndex(i, from => {\n        this.mapIndex(this._length - 1 - i, to => {\n          const swap = this.store[to]\n          this.store[to] = this.store[from]\n          this.store[from] = swap\n        })\n      })\n    }\n    return this\n  }\n\n  toA(): T[] {\n    return [...this]\n  }\n\n  slice(start?: number | undefined, end?: number | undefined): T[] {\n    return [...this].slice(start, end)\n  }\n\n  // sort(compareFn?: ((a: T, b: T) => number) | undefined): this {\n  //   throw new Error(\"Method not implemented.\")\n  // }\n  // indexOf(searchElement: T, fromIndex?: number | undefined): number {\n  //   throw new Error(\"Method not implemented.\");\n  // }\n  // lastIndexOf(searchElement: T, fromIndex?: number | undefined): number {\n  //   throw new Error(\"Method not implemented.\");\n  // }\n  // filter<S extends T>(callbackfn: (value: T, index: number, array: T[]) => value is S, thisArg?: any): S[];\n  // filter(callbackfn: (value: T, index: number, array: T[]) => , thisArg?: any): T[];\n  // filter(callbackfn: any, thisArg?: any) {\n  //   throw new Error(\"Method not implemented.\");\n  // }\n  // reduce(callbackfn: (previousValue: T, currentValue: T, currentIndex: number, array: T[]) => T): T;\n  // reduce(callbackfn: (previousValue: T, currentValue: T, currentIndex: number, array: T[]) => T, initialValue: T): T;\n  // reduce(callbackfn: any, initialValue?: any) {\n  //   throw new Error(\"Method not implemented.\");\n  // }\n  // reduceRight(callbackfn: (previousValue: T, currentValue: T, currentIndex: number, array: T[]) => T): T;\n  // reduceRight(callbackfn: (previousValue: T, currentValue: T, currentIndex: number, array: T[]) => T, initialValue: T): T;\n  // reduceRight<U>(callbackfn: (previousValue: U, currentValue: T, currentIndex: number, array: T[]) => U, initialValue: U): U;\n  // reduceRight(callbackfn: any, initialValue?: any) {\n  //   throw new Error(\"Method not implemented.\");\n  // }\n  // find<S extends T>(predicate: (this: void, value: T, index: number, obj: T[]) => value is S, thisArg?: any): S | undefined;\n  // find(predicate: (value: T, index: number, obj: T[]) => boolean, thisArg?: any): T | undefined;\n  // find(predicate: any, thisArg?: any) {\n  //   throw new Error(\"Method not implemented.\");\n  // }\n  // findIndex(predicate: (value: T, index: number, obj: T[]) => boolean, thisArg?: any): number {\n  //   throw new Error(\"Method not implemented.\");\n  // }\n  // fill(value: T, start?: number | undefined, end?: number | undefined): this {\n  //   throw new Error(\"Method not implemented.\");\n  // }\n  // copyWithin(target: number, start: number, end?: number | undefined): this {\n  //   throw new Error(\"Method not implemented.\");\n  // }\n  // entries(): IterableIterator<[number, T]> {\n  //   throw new Error(\"Method not implemented.\");\n  // }\n  // keys(): IterableIterator<number> {\n  //   throw new Error(\"Method not implemented.\");\n  // }\n  // values(): IterableIterator<T> {\n  //   throw new Error(\"Method not implemented.\");\n  // }\n  // [Symbol.unscopables](): { copyWithin: boolean; entries: boolean; fill: boolean; find: boolean; findIndex: boolean; keys: boolean; values: boolean; } {\n  //   throw new Error(\"Method not implemented.\");\n  // }\n  // includes(searchElement: T, fromIndex?: number | undefined): boolean {\n  //   throw new Error(\"Method not implemented.\");\n  // }\n}\n", "import { compactBlanks, isEmpty, sortBy, uniqBy2 } from \"../fe/Array\"\nimport { blank, notBlank } from \"../fe/Blank\"\nimport { map, orElse } from \"../fe/Maybe\"\nimport { Maybe, MaybeNull } from \"../fe/MaybeTypes\"\nimport { times, toFloat } from \"../fe/Number\"\nimport { cmp } from \"../fe/Primitive\"\nimport { toA } from \"../fe/toA\"\nimport { toS } from \"../fe/toS\"\nimport { greatestBy } from \"./Array\"\n\nconst he = require(\"he\")\n\n// TODO: inline\nexport {\n  ellipsize,\n  ensurePrefix,\n  ensureSuffix,\n  isString,\n  newlineRe,\n  wrap\n} from \"../fe/String\"\n\nconst pads = {}\n\nexport function padding(char: string, length: number): string {\n  if (length < 1) return \"\"\n  if (pads[char] == null) pads[char] = char\n  while (length > pads[char].length) {\n    pads[char] += char\n  }\n  return pads[char].substring(0, length)\n}\n\n// first added for irony, then used nonironically:\nexport function leftPad(s: any, minLength: number, padChar: string): string {\n  if (padChar.length === 0) throw new Error(\"leftPad() given empty pad\")\n  if (typeof s === \"number\" && s < 0) {\n    return \"-\" + leftPad(String(-s), minLength - 1, padChar)\n  }\n  const str = String(s)\n  return padding(padChar, minLength - str.length) + str\n}\n\nexport function rightPad(s: any, minLength: number, padChar: string): string {\n  if (padChar.length === 0) throw new Error(\"rightPad() given empty pad\")\n  const str = String(s)\n  return str + padding(padChar, minLength - str.length)\n}\n\n/**\n * Left-zero-pad\n */\nexport function pad2(s: any): string {\n  return leftPad(s, 2, \"0\")\n}\n\nexport function padReplace(\n  s: string,\n  fromIdx: number,\n  length: number,\n  padChar: string\n) {\n  return (\n    s.substr(0, fromIdx) + padding(padChar, length) + s.substr(fromIdx + length)\n  )\n}\n\nexport function contains(\n  haystack: string,\n  needle: string,\n  fromPosition?: number\n): boolean {\n  return toS(haystack).indexOf(toS(needle), fromPosition) > -1\n}\n\nexport function count(\n  haystack: string,\n  needle: string,\n  fromPosition = 0\n): number {\n  if (needle == null || needle.length === 0) return 0\n  const idx = haystack.indexOf(needle, fromPosition)\n  return idx === -1 ? 0 : 1 + count(haystack, needle, idx + needle.length)\n}\n\nexport function maybeToS(a?: any): Maybe<string> {\n  return a == null ? undefined : String(a)\n}\n\nexport function trim(arr: any[]): string[] {\n  return arr.map(toS).filter(ea => notBlank(ea))\n}\n\nexport function splitFirst(\n  s: string,\n  pattern: string\n): [string, string] | [string] {\n  const indexOf = s.indexOf(pattern)\n  return indexOf === -1\n    ? [s]\n    : [s.slice(0, indexOf), s.slice(indexOf + pattern.length)]\n}\n\nexport function splitEvery(s: string, n: number, maxSplits?: number): string[] {\n  const sliceTimes =\n    Math.min(\n      Math.ceil(s.length / n),\n      orElse(maxSplits, () => s.length)\n    ) - 1\n  if (sliceTimes <= 0) return [s]\n  return [\n    ...times(sliceTimes, i => s.slice(i * n, (i + 1) * n)),\n    s.slice(sliceTimes * n)\n  ]\n}\n\n/**\n * Removes the first capture group defined by `re` found in `s`.\n */\nexport function spliceCapture(s: string, re: RegExp) {\n  const m = re.exec(s)\n  if (m == null || m[1] == null) return\n  const matchedIndex = m[0].indexOf(m[1]) + m.index\n  return {\n    captured: m[1],\n    uncaptured:\n      s.substring(0, matchedIndex) + s.substring(matchedIndex + m[1].length),\n    unmatched: s.substring(0, m.index) + s.substring(m.index + m[0].length),\n    matchedIndex\n  }\n}\n\nexport function stripPrefix(s: string, prefix: string): string {\n  const str = toS(s)\n  const pfx = toS(prefix)\n  return pfx.length > 0 && str.startsWith(pfx) ? str.slice(pfx.length) : str\n}\n\nexport function stripPrefixIgnoreCase(s: string, prefix: string): string {\n  s = toS(s)\n  prefix = toS(prefix)\n  return startsWithIgnoreCase(s, prefix) ? s.slice(prefix.length) : s\n}\n\nexport function stripSuffix(s: string, suffix: string): string {\n  if (suffix == null) return s\n  const str = toS(s)\n  const sfx = toS(suffix)\n  return sfx.length > 0 && str.endsWith(sfx) ? str.slice(0, -sfx.length) : str\n}\n\n/**\n * Only strip the prefix and suffix if they both exist.\n */\nexport function stripPreSuff(s: string, prefix: string, suffix: string) {\n  if (prefix == null) return stripSuffix(s, suffix)\n  s = toS(s)\n  return s.endsWith(suffix) && s.startsWith(prefix)\n    ? s.slice(prefix.length, -suffix.length)\n    : s\n}\n\nexport function gist(a: string, maxPre = 80, maxPost = 80): string {\n  const s = toS(a)\n  const charsOmitted = s.length - (maxPre + maxPost)\n  return charsOmitted <= 0\n    ? s\n    : s.slice(0, maxPre).trim() +\n        \" \u2026(+\" +\n        charsOmitted +\n        \" chars)\u2026\" +\n        s.slice(-maxPost).trim()\n}\n\nexport function capitalize(s: Maybe<string>): string {\n  s = toS(s)\n  const arr = s.normalize().split(\"\")\n  return blank(s) ? s : arr[0].toLocaleUpperCase() + arr.slice(1).join(\"\")\n}\n\nexport function compareIgnoreCase(a: string, b: string) {\n  return a.localeCompare(b, undefined, { sensitivity: \"base\" })\n}\n\nexport function equalsIgnoreCase(\n  a: MaybeNull<string | Buffer>,\n  b: MaybeNull<string | Buffer>\n): boolean {\n  if (a == null || b == null) return false\n  const as = toS(a)\n  const bs = toS(b)\n  if (as.length !== bs.length) return false\n  if (as === bs) return true\n  // cheap, but false is sometimes wrong (like in Turkish):\n  if (as.toLowerCase() === bs.toLowerCase()) return true\n  return (\n    as.localeCompare(bs, undefined, {\n      sensitivity: \"base\"\n    }) === 0 ||\n    // .normalize is expensive():\n    0 === compareIgnoreCase(as.normalize(), bs.normalize())\n  )\n}\n\nexport function uniqIgnoreCase(arr: string[]): string[] {\n  return uniqBy2(arr, equalsIgnoreCase)\n}\n\nexport function sortIgnoreCase(arr: string[]): string[] {\n  return arr.sort(compareIgnoreCase)\n}\n\nexport function sortByCaseInsensitive<T>(\n  arr: Iterable<T> | T[],\n  f: (t: T, index: number) => Maybe<string>\n): T[] {\n  return toA(arr)\n    .filter(ea => ea != null)\n    .map((item, idx) => ({\n      item,\n      cmp: map(f(item, idx), ea => [ea, idx]) as [string, number]\n    }))\n    .filter(ea => ea.cmp != null)\n    .sort((a, b) => {\n      const ea = compareIgnoreCase(a.cmp[0], b.cmp[0])\n      return ea !== 0 ? ea : cmp(a.cmp[1], b.cmp[1])\n    })\n    .map(ea => ea.item)\n}\n\n/** TODO DELETE IF UNUSED\n * @return true iff `haystack` starts with `needle`\n */\nexport function startsWithIgnoreCase(\n  haystack: string,\n  needle: string\n): boolean {\n  return haystack == null ||\n    needle == null ||\n    needle.length === 0 ||\n    haystack.length === 0\n    ? false\n    : equalsIgnoreCase(haystack.substring(0, needle.length), needle)\n}\n\n/**\n * @return the first item in `haystack` that is a case-insensitive substring of\n * `needle`.\n */\nexport function firstSubstringIgnoreCase(\n  haystack: string[],\n  needle: string\n): Maybe<{ index: number; match: string }> {\n  if (isEmpty(haystack) || blank(needle)) return\n  for (const ea of haystack) {\n    if (equalsIgnoreCase(ea, needle)) return { index: 0, match: ea }\n  }\n  for (const ea of haystack) {\n    const index = needle.indexOf(ea)\n    if (index >= 0) return { index, match: ea }\n  }\n  const nn = needle.normalize()\n  for (const ea of haystack) {\n    {\n      const index = nn.indexOf(ea)\n      if (index >= 0) return { index, match: ea }\n    }\n    const hn = ea.normalize()\n    {\n      const index = nn.indexOf(hn)\n      if (index >= 0) return { index, match: hn }\n    }\n    {\n      const nl = nn.toLocaleLowerCase()\n      const hl = hn.toLocaleLowerCase()\n      const index = nl.indexOf(hl)\n      if (index >= 0) return { index, match: hl }\n    }\n  }\n  return\n}\n\n/**\n * Is any item in `haystack` included in `needle`?\n */\nexport function hasAnyIgnoreCase(haystack: string[], needle: string): boolean {\n  return isEmpty(haystack) || blank(needle)\n    ? false\n    : haystack.some(ea => equalsIgnoreCase(needle, ea))\n}\n\nexport function reverse(s: string): string {\n  return s == null ? s : s.split(\"\").reverse().join(\"\")\n}\n\nexport type Stringable = { valueOf(): string }\n\n/**\n * Return the longest-matching prefix pattern from `patterns` that needle\n * startsWith.\n */\nexport function longestPrefix(\n  needle: string,\n  patterns: string[]\n): Maybe<string> {\n  return greatestBy(\n    patterns.filter(ea => needle.startsWith(ea)),\n    ea => ea.length\n  )\n}\n\n// \\u001b[90m\nexport function stripAnsiEsc(s: string): string {\n  // eslint-disable-next-line no-control-regex\n  return toS(s).replace(/\\u001b\\[[0-9;]+[a-z]/gi, \"\")\n}\n\nconst Smart2Dumb: [RegExp, string][] = [\n  [/[\u2018\u2019]/g, `'`],\n  [/[\u201C\u201D\u201E\u00AB\u00BB\u201D\u3003]/g, `\"`]\n]\n\nexport function dumbquote(s: string): string {\n  return Smart2Dumb.reduce(\n    (acc, [smart, dumb]) => acc.replace(smart, dumb),\n    s\n  ).normalize()\n}\n\nconst quoted = /^(['\"]).+\\1$/\n\nexport function stripQuotes(s: string): string {\n  if (blank(s)) return s\n  // Some Vivitar cameras have numeric models (!!) so we need to toS().\n  s = toS(s).trim()\n  if (quoted.exec(dumbquote(s)) != null) {\n    s = s.slice(1, -1).trim()\n  }\n  return s\n}\n\nexport function wbrPath(s: string): string {\n  return s\n    .split(/(?<=[\\\\/_,:=-]+)/)\n    .map(ea => he.escape(ea.normalize()) as string)\n    .join(\"<wbr>\")\n}\n\nexport function zipStrings(...arr: string[]): string {\n  let s = \"\"\n  const cb = compactBlanks(arr)\n  const maxLen = Math.max(...cb.map(ea => ea.length))\n  for (let j = 0; j < maxLen; j++) {\n    for (let i = 0; i < cb.length; i++) {\n      map(cb[i], str => map(str[j], ea => (s += ea)))\n    }\n  }\n  return s\n}\n\nexport function joinEng(arr: string[]): string {\n  arr = compactBlanks(arr)\n  return arr.length < 2\n    ? arr.join(\"\")\n    : arr.slice(0, -1).join(\", \") + \" or \" + arr[arr.length - 1]\n}\n\nexport function splitKeep(s: string, re: RegExp): string[] {\n  const result: string[] = []\n  let pos = 0\n  let m: RegExpExecArray | null\n  while ((m = re.exec(s)) != null) {\n    // This is necessary to avoid infinite loops with zero-width matches\n    if (m.index === re.lastIndex) {\n      re.lastIndex++\n    } else {\n      re.lastIndex = m[0].length + m.index\n      result.push(s.substring(pos, m.index))\n      result.push(s.substring(m.index, re.lastIndex))\n      pos = re.lastIndex\n    }\n  }\n  if (pos < s.length) {\n    result.push(s.substring(pos))\n  }\n  return result.filter(ea => ea.length > 0)\n}\n\nexport function sortNaturalBy(line: string) {\n  return splitKeep(toS(line), /\\d+(?:\\.\\d*)?/g).map(ea =>\n    orElse<number | string>(toFloat(ea.trim()), ea)\n  )\n}\n\nexport function sortNatural(lines: string[]): string[] {\n  return sortBy(lines, line => sortNaturalBy(line))\n}\n\nexport function stripDiacritics(s: string): string {\n  // see https://stackoverflow.com/a/37511463/1268016\n  return toS(s)\n    .normalize(\"NFD\")\n    .replace(/[\\u0300-\\u036f]/g, \"\")\n}\n\nexport function stripEmoji(s: string): string {\n  // see https://stackoverflow.com/a/38987183/1268016\n  return toS(s).replace(\n    /\\ud83c[\\udf00-\\udfff]|\\ud83d[\\udc00-\\ude4f]|\\ud83d[\\ude80-\\udeff]/g,\n    \"\"\n  )\n}\n\nexport function uniqSubstr(arr: string[]): string[] {\n  const rev = sortIgnoreCase(compactBlanks(arr))\n  const result = rev.filter(\n    (ea, idx) => !startsWithIgnoreCase(rev[idx + 1], ea)\n  )\n  return sortBy(result, ea => arr.indexOf(ea))\n}\n", "import { count, flatten, isEmpty } from \"../fe/Array\"\nimport { blank } from \"../fe/Blank\"\nimport { map, orElse } from \"../fe/Maybe\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport {\n  clamp,\n  gt0,\n  gte,\n  isNumber,\n  lte,\n  map2Numeric,\n  mapInt,\n  mapNumeric,\n  toFloat,\n  toInt\n} from \"../fe/Number\"\nimport { toS } from \"../fe/toS\"\nimport { leftPad } from \"./String\"\n\nexport function firstGt0(...objects: any[]): Maybe<number> {\n  return objects.find(gt0)\n}\n\n/**\n * @return the first element in `objects` that can be parsed into a number and is\n * greater than zero.\n */\nexport function firstNonZero(...objects: any[]): Maybe<number> {\n  for (const ea of flatten(objects)) {\n    const f = toFloat(ea)\n    if (f != null && f !== 0) return f\n  }\n  return undefined\n}\n\nexport function mapGte0<T>(n: any, f: (i: number) => T): Maybe<T> {\n  return mapInt(n, i => (i >= 0 ? f(i) : undefined))\n}\n\nexport function mapGte0Or<T>(\n  n: any,\n  f: (i: number) => T,\n  defaultValue: T | (() => T)\n): T {\n  return orElse(mapGte0(n, f), defaultValue)\n}\n\nexport function mapGte0f<T>(n: any, f: (i: number) => T): Maybe<T> {\n  return mapNumeric(n, i => (i >= 0 ? f(i) : undefined))\n}\n\nexport function mapGt0<T>(n: any, f: (i: number) => T): Maybe<T> {\n  return mapInt(n, i => (i > 0 ? f(i) : undefined))\n}\n\nexport function mapGt0f<T>(n: any, f: (i: number) => T): Maybe<T> {\n  return mapNumeric(n, i => (i > 0 ? f(i) : undefined))\n}\n\nexport function mapGt0Or<T>(\n  n: any,\n  f: (i: number) => T,\n  defaultValue: T | (() => T)\n): T {\n  return orElse(mapGt0(n, f), defaultValue)\n}\n\n/**\n * @param min inclusive\n * @param max inclusive\n */\nexport function within(min: number, max: number, n: any): n is number {\n  if (n == null || !isNumber(n)) return false\n  ;[min, max] = [Math.min(min, max), Math.max(min, max)]\n  return gte(n, min) && lte(n, max)\n}\n\n// WAT WAT WAAAAAT? (this is the simplest regex I could come up with that\n// supported both \"-123\", \"+123.\", \"-123.456\" and \"-.789\") \\\n\n// I could do this:\n// const validFloatRe = /((?:[+-]?[0-9]+(?:\\.[0-9]*)?)|(?:[+-]?[0-9]*(?:\\.[0-9]+)))/\n\n// but that sort of rigor isn't necessary. parseFloat is fine with parsing\n// \"-123.456GUACAMOLE\".\nconst numstartRe = /[+-]?[0-9\\,\\.]+/\n\n/**\n * Pull out the first float from `value`.\n *\n * This method ignores any non-numeric characters that prefix or suffix the\n * first number (as opposed to `toFloat`, which ignores only non-numeric\n * suffixes)\n */\nexport function extractFloat(value: any): Maybe<number> {\n  if (isNumber(value)) return value\n  if (blank(value)) return undefined\n  const s = String(value)\n  return map(numstartRe.exec(s), m => toFloat(s.substr(m.index)))\n}\n\n/**\n * Pull out the first integer from `value`.\n *\n * This method ignores any non-numeric characters that prefix or suffix the\n * first number (as opposed to `toInt`, which ignores only non-numeric suffixes)\n */\nexport function extractInt(value: any): Maybe<number> {\n  return toInt(extractFloat(value))\n}\n\nexport function extractFraction(value: any): Maybe<number> {\n  if (isNumber(value)) return value\n  const s = toS(value)\n  if (s.includes(\"/\")) {\n    const arr = s.split(\"/\", 2)\n    return map2Numeric(extractInt(arr[0]), extractInt(arr[1]), (i, j) => i / j)\n  } else {\n    return extractFloat(s)\n  }\n}\n\nexport function assertPositive(name: string, value?: number) {\n  if (value == null || value <= 0) {\n    throw new Error(name + \" must be positive\")\n  }\n}\n\nexport class Array2D {\n  private readonly store: number[] = []\n  constructor(readonly columns: number) {}\n  get(row: number, col: number): number {\n    return row < 0 || col < 0\n      ? 0\n      : orElse(this.store[row * this.columns + col], () => 0)\n  }\n  set(row: number, col: number, value: number) {\n    this.store[row * this.columns + col] = value\n  }\n}\n\nfunction prepHammBigInts(\n  a: number | BigInt,\n  b: number | BigInt\n): Maybe<[string, string]> {\n  if (a == null || b == null) return\n  const arr = [a, b].map(ea => ea.toString(2))\n  const maxLen = Math.max(...arr.map(ea => ea.length))\n  return arr.map(ea => leftPad(ea, maxLen, \"0\")) as [string, string]\n}\n\n/**\n * @return the number of bits not matching between a and b\n */\nexport function hammingDistanceBigInt(\n  a: number | BigInt,\n  b: number | BigInt\n): Maybe<number> {\n  return map(prepHammBigInts(a, b), ([s1, s2]) =>\n    count(s1.split(\"\"), (ea, idx) => ea !== s2.charAt(idx))\n  )\n}\n\n/**\n * @return `matching bits / total bits`. 1 == complete match.\n */\nexport function hammRatioBigInt(\n  a: Maybe<number | BigInt>,\n  b: Maybe<number | BigInt>\n): Maybe<number> {\n  if (a == null || b == null) return 0\n  return map(prepHammBigInts(a, b), ([i, j]) => hammRatioBinaryString(i, j))\n}\n\nexport function hammRatioBinaryString(a: string, b: string) {\n  if (a === b) return 1\n  if (a.length !== b.length)\n    throw new Error(`hammRatioBinaryString(${a}, ${b}): invalid lengths`)\n  let matching = 0\n  // console.log(\"hammRatioBinaryString a\")\n  // console.log(splitEvery(a, 24).join(\"\\n\"))\n  // console.log(\"hammRatioBinaryString b\")\n  // console.log(splitEvery(b, 24).join(\"\\n\"))\n  for (let i = 0; i < a.length; i++) {\n    if (a[i] === b[i]) matching++\n  }\n  // console.log(\"matching: \" + matching)\n  // 50% match is random. Scale that to 0.\n  return clamp(0, 1, (2 * matching) / a.length - 1)\n}\n\nexport function valuesToBigInt(arr: number[], bitsPerValue: number): BigInt {\n  if (isEmpty(arr)) return BigInt(0)\n  return BigInt(\n    \"0b0\" +\n      arr.map(ea => leftPad(ea.toString(2), bitsPerValue - 1, \"0\")).join(\"\")\n  )\n}\n", "import { sort, sortBy } from \"../fe/Array\"\nimport { orElse } from \"../fe/Maybe\"\nimport { isNumber, mapNumericOr } from \"../fe/Number\"\nimport { tap } from \"../fe/Object\"\nimport { Average } from \"./math/Average\"\n\nexport class CountingSet<K extends number | string> {\n  private readonly m = new Map<K, number>()\n\n  incr(key: K, count: number = 1): this {\n    const v = this.get(key) + count\n    if (v === 0) this.m.delete(key)\n    else this.m.set(key, v)\n    return this\n  }\n\n  get(key: K): number {\n    return orElse(this.m.get(key), () => 0)\n  }\n\n  has(key: K): boolean {\n    return this.m.has(key)\n  }\n\n  /**\n   * Return the number of non-zero `incr`emented keys\n   */\n  get size(): number {\n    return this.m.size\n  }\n\n  keys(): IterableIterator<K> {\n    return this.m.keys()\n  }\n\n  keyAvg() {\n    const avg = new Average(0)\n    for (const k of this.keys()) {\n      if (isNumber(k)) {\n        avg.push(k)\n      } else {\n        return\n      }\n    }\n    return avg.avg\n  }\n\n  entries(): IterableIterator<[K, number]> {\n    return this.m.entries()\n  }\n\n  /** Multimodal ties are solved by proximity to mean */\n  entriesByCountDesc(): [K, number][] {\n    const keyAvg = this.keyAvg()\n    return sortBy([...this.entries()], ([k, v]) => [\n      -v,\n      mapNumericOr(keyAvg, ea => Math.abs((k as number) - ea), 0)\n    ])\n  }\n\n  top(n = 1): [K, number][] {\n    return this.entriesByCountDesc().slice(0, n)\n  }\n\n  topKeys(n = 1): K[] {\n    return this.top(n).map(ea => ea[0])\n  }\n\n  get averageCounts(): Average {\n    return tap(new Average(this.size), a =>\n      [...this.m.values()].forEach(ea => a.push(ea))\n    )\n  }\n\n  forEach(callbackfn: (count: number, key: K) => void): void {\n    this.m.forEach(callbackfn)\n  }\n\n  clear(): void {\n    this.m.clear()\n  }\n\n  get toS() {\n    return sort([...this.keys()])\n      .map(key => key + \" \" + this.get(key))\n      .join(\"\\n\")\n  }\n}\n", "import { Maybe } from \"../fe/MaybeTypes\"\nimport { Primitive } from \"../fe/Primitive\"\nimport { toA } from \"../fe/toA\"\n\nexport function asSet<T>(s: Maybe<Iterable<T>>): Set<T> {\n  return s instanceof Set ? s : new Set(toA(s))\n}\n\nexport function setEql<T>(a: Set<T>, b: Set<T>): boolean {\n  return (\n    toA(a.keys()).every(ea => b.has(ea)) && toA(b.keys()).every(ea => a.has(ea))\n  )\n}\n\nexport function getOrAdd<K, V>(s: Set<K>, k: K, onAdd: () => V): Maybe<V> {\n  if (k == null) throw new Error(\"null key\")\n  if (s.has(k)) {\n    return undefined\n  } else {\n    s.add(k)\n    return onAdd()\n  }\n}\n\n//\n// These only support primitives, as comparison is done with ==\n//\n\n/**\n * @return unique elements in a or b\n */\nexport function union<T extends Primitive>(\n  a: Iterable<T>,\n  b: Iterable<T>\n): Set<T> {\n  return new Set([...a, ...b])\n}\n\n/**\n * @return elements in a that are also in b\n */\nexport function intersection<T extends Primitive>(\n  a: Iterable<T>,\n  b: Iterable<T>\n): Set<T> {\n  const s = asSet(b)\n  return new Set([...a].filter(ea => s.has(ea)))\n}\n\n/**\n * @return elements in `a` that are not in `b`\n */\nexport function diff<T extends Primitive>(\n  a: Iterable<T>,\n  b: Iterable<T>\n): Set<T> {\n  const s = asSet(b)\n  return new Set([...a].filter(ea => !s.has(ea)))\n}\n", "import { compact, isEmpty } from \"../../fe/Array\"\nimport { List } from \"../../fe/List\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { finiteOrElse, isNumber, mapFinite, times } from \"../../fe/Number\"\nimport { Arrayish, toA } from \"../../fe/toA\"\nimport { CountingSet } from \"../CountingSet\"\nimport { mapGt0Or } from \"../Number\"\nimport { intersection, union } from \"../Set\"\n\nexport type NumericList =\n  | List<number>\n  | number[]\n  | Float32Array\n  | Uint32Array\n  | Int32Array\n\nexport type Numberlist = Arrayish<number>\n\nexport function min<T>(vec: List<Maybe<T>>) {\n  let result\n  for (const ea of vec) {\n    if (ea != null) {\n      if (result == null || ea < result) {\n        result = ea\n      }\n    }\n  }\n  return result\n}\n\nexport function max<T>(vec: List<Maybe<T>>) {\n  let result\n  for (const ea of vec) {\n    if (ea != null) {\n      if (result == null || ea > result) {\n        result = ea\n      }\n    }\n  }\n  return result\n}\n\n/**\n * @return `[arr[1] - arr[0], arr[2] - arr[1], ...]`\n */\nexport function deltas(vec: Numberlist): number[] {\n  const l = toA(vec)\n  if (vec == null || l.length <= 1) return []\n  return l.slice(1).map((ea, idx) => ea - vec[idx])\n}\n\nexport function modes(vec: Numberlist, topN: number): number[] {\n  const cs = new CountingSet<number>()\n  toA(vec).forEach(i => mapFinite(i, ea => cs.incr(ea)))\n  return cs.topKeys(topN)\n}\n\nexport function mode(vec: number[]): Maybe<number> {\n  return modes(vec, 1)[0]\n}\n\nexport function sum(vec: Numberlist): number {\n  return toA(vec).reduce((acc, ea) => (isNumber(ea) ? acc + ea : acc), 0)\n}\n\nexport function avg(vec: Arrayish<Maybe<number>>): Maybe<number> {\n  const l = compact(toA(vec))\n  return isEmpty(l)\n    ? undefined\n    : l.reduce(\n        (mean, ea, idx) =>\n          // Prevent overflow:\n          idx === 0 ? ea : (mean * idx) / (idx + 1) + ea / (idx + 1),\n        0\n      )\n}\n\n/**\n * @param strength how strong should the normalization be applied. [0,1]\n */\nexport function normalize({\n  x,\n  strength = 1,\n  normMin,\n  normMax\n}: {\n  x: number[]\n  strength?: number\n  normMin: number\n  normMax: number\n}): number[] {\n  const xMin = min(x)!\n  const xRange = max(x)! - xMin\n  const normRange = normMax - normMin\n  return x.map(\n    ea =>\n      (1 - strength) * ea +\n      strength * (normMin + (normRange * (ea - xMin)) / xRange)\n  )\n}\n\nexport function slope(vec: Numberlist): Maybe<number> {\n  const l = toA(vec)\n  return map(avg(l), x_mean => {\n    const y_mean = (l.length - 1) / 2\n    const num = sum(l.map((x, y) => (x - x_mean) * (y - y_mean)))\n    const denom = sum(l.map(x => (x - x_mean) ** 2))\n    return denom === 0 ? 0 : num / denom\n  })\n}\n\nexport function avgMaybe(...m: Maybe<number>[]): Maybe<number> {\n  const arr = compact(m)\n  return isEmpty(arr) ? undefined : sum(arr) / arr.length\n}\n\nexport function variance(arr: List<number>): Maybe<number> {\n  return map(avg(arr), mean => avg(arr.map(i => Math.pow(i - mean, 2))))\n}\n\nexport function stdDev(arr: List<number>): Maybe<number> {\n  return map(variance(arr), ea => Math.sqrt(ea))\n}\n\nexport function weightedAvg(arr: List<number> | Iterable<number>): number {\n  let acc\n  for (const ea of arr) {\n    acc = acc == null ? ea : (acc + ea) / 2\n  }\n  return acc == null ? NaN : acc\n}\n\nexport function avgWeighted(arr: List<number>, weights: List<number>): number {\n  let wSum = 0\n  return (\n    arr.reduce((agg, ea, idx) => {\n      const w = mapGt0Or(weights[idx], identity => identity, 1)\n      wSum += w\n      return agg + ea * w\n    }, 0) / wSum\n  )\n}\n\nexport function euclidean<T extends NumericList>(x: T, y: T): number {\n  return Math.sqrt(\n    toA(x).reduce((sum_, ea, idx) => sum_ + Math.pow(ea - y[idx], 2), 0)\n  )\n}\n\nexport function centroid(vectors: NumericList[]): Maybe<number>[] {\n  return times(vectors[0].length, dim => avg(vectors.map(arr => arr[dim])))\n}\n\n/**\n * Euclidean norm, or L2 norm, of a given vector\n * @see https://en.wikipedia.org/wiki/Norm_(mathematics)\n */\nexport function l2norm(vec: List<number>): number {\n  return Math.sqrt(vec.reduce((sum_, ea) => sum_ + ea * ea, 0))\n}\n\n/**\n * @see https://en.wikipedia.org/wiki/Euclidean_vector#Dot_product\n */\nexport function dot(x: number[], y: number[]): number {\n  return x.reduce((sum_, ea, i) => sum_ + ea * y[i], 0)\n}\n\n/**\n * Ranges between -1 (anticorrelation) to 1 (correlation)\n * @see https://en.wikipedia.org/wiki/Cosine_similarity\n */\nexport function cosineSimilarity(x: number[], y: number[]): Maybe<number> {\n  return finiteOrElse(dot(x, y) / (l2norm(x) * l2norm(y)), undefined)\n}\n\n/**\n * Ranges between 0 (no overlap) to 1 (complete overlap)\n */\nexport function jaccard(x: number[], y: number[]): Maybe<number> {\n  return isEmpty(x) && isEmpty(y)\n    ? 0\n    : finiteOrElse(intersection(x, y).size / union(x, y).size, undefined)\n}\n", "import { filterInPlace, isNotEmpty, sortBy } from \"../fe/Array\"\nimport { getOrSet } from \"../fe/Map\"\nimport { map } from \"../fe/Maybe\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { Primitive } from \"../fe/Primitive\"\nimport { toA } from \"../fe/toA\"\nimport { remove } from \"./Array\"\nimport { sum } from \"./math/Vector\"\n\n/**\n * Multi-valued Map.\n * @see SetMap\n */\nexport class MultiMap<K, V> {\n  readonly store: Map<K, V[]>\n\n  constructor(store = new Map<K, V[]>()) {\n    this.store = store\n  }\n\n  get(key: K): V[] | undefined {\n    return this.store.get(key)\n  }\n\n  has(key: K): boolean {\n    return this.store.has(key)\n  }\n\n  /**\n   * @return the number of unique keys in this store\n   */\n  get keyCount(): number {\n    return this.store.size\n  }\n\n  /**\n   * @return the number of values in this store\n   */\n  get valueCount(): number {\n    return sum([...this.store.values()].map(ea => ea.length))\n  }\n\n  add(key: K, ...values: V[]): V[] {\n    const store = getOrSet(this.store, key, () => [])\n    store.push(...values)\n    return store\n  }\n\n  set(key: K, values: V[]) {\n    this.store.set(key, values)\n  }\n\n  delete(key: K, value?: V): boolean {\n    if (value == null) {\n      return this.store.delete(key)\n    } else {\n      const arr = this.store.get(key)\n      if (arr == null) {\n        return false\n      } else {\n        const result = remove(arr, value)\n        if (result && arr.length === 0) {\n          this.store.delete(key)\n        }\n        return result\n      }\n    }\n  }\n\n  clear(): this {\n    this.store.clear()\n    return this\n  }\n\n  keys(): IterableIterator<K> {\n    // eslint-disable-next-line @typescript-eslint/no-this-alias\n    const self = this\n    function* iter(): IterableIterator<K> {\n      for (const [k, v] of self.store.entries()) {\n        if (v.length > 0) {\n          yield k\n        }\n      }\n    }\n    return iter()\n  }\n\n  values(): IterableIterator<V[]> {\n    // eslint-disable-next-line @typescript-eslint/no-this-alias\n    const self = this\n    function* iter(): IterableIterator<V[]> {\n      for (const [, v] of self.store.entries()) {\n        if (v.length > 0) {\n          yield v\n        }\n      }\n    }\n    return iter()\n  }\n\n  flatValues(): IterableIterator<V> {\n    // eslint-disable-next-line @typescript-eslint/no-this-alias\n    const self = this\n    function* iter(): IterableIterator<V> {\n      for (const [, arr] of self.store.entries()) {\n        if (arr.length > 0) {\n          for (const ea of arr) {\n            yield ea\n          }\n        }\n      }\n    }\n    return iter()\n  }\n\n  entriesArray(): [K, V[]][] {\n    return [...this.store.entries()].filter(([, v]) => isNotEmpty(v))\n  }\n\n  entries(): IterableIterator<[K, V[]]> {\n    // eslint-disable-next-line @typescript-eslint/no-this-alias\n    const self = this\n    function* iter(): IterableIterator<[K, V[]]> {\n      for (const [k, v] of self.store.entries()) {\n        if (v.length > 0) {\n          yield [k, v]\n        }\n      }\n    }\n    return iter()\n  }\n\n  tuples(): IterableIterator<[K, V]> {\n    // eslint-disable-next-line @typescript-eslint/no-this-alias\n    const self = this\n    function* iter(): IterableIterator<[K, V]> {\n      for (const [k, v] of self.store.entries()) {\n        for (const ea of toA(v)) {\n          if (ea != null) yield [k, ea]\n        }\n      }\n    }\n    return iter()\n  }\n\n  filterInPlace(predicate: (key: K, value: V) => boolean): boolean {\n    let changed = false\n    for (const [k, arr] of this.store.entries()) {\n      const len = arr.length\n      filterInPlace(arr, v => predicate(k, v))\n      changed = changed || len !== arr.length\n    }\n    return changed\n  }\n}\n\n/**\n * Groups the given enumeration\n * @return a copy of arr, sorted by the given constraint\n */\nexport function groupBy<K extends Primitive, V>(\n  arr: V[],\n  f: (t: V) => Maybe<K>\n): MultiMap<K, V> {\n  const m = new MultiMap<K, V>()\n  arr.forEach(ea => map(f(ea), k => m.add(k, ea)))\n  return m\n}\n\nexport function groupByValues<K extends Primitive, V>(\n  arr: V[],\n  f: (t: V) => Maybe<K>\n): V[][] {\n  const g = groupBy(arr, f)\n  return sortBy(toA(g.values()), ea => f(ea[0]))\n}\n", "import { compact } from \"../fe/Array\"\nimport { blank } from \"../fe/Blank\"\nimport { isDate } from \"../fe/Date\"\nimport { defined, map } from \"../fe/Maybe\"\nimport { Maybe, MaybeNull } from \"../fe/MaybeTypes\"\nimport { entries, keys, Obj } from \"../fe/Object\"\nimport { isPrimitive, Primitive } from \"../fe/Primitive\"\nimport { Thunk } from \"../fe/Thunk\"\nimport { first } from \"./Array\"\nimport { eql } from \"./Eql\"\nimport { equalsIgnoreCase } from \"./String\"\n\n// TODO: INLINE\nexport type Pojo = Obj\n\n// \"{ new(): T }\"\n// is from https://www.typescriptlang.org/docs/handbook/generics.html#using-class-types-in-generics\nexport interface Constructor<M> {\n  new (...args: any[]): M\n}\n\nexport function definedThunks(...thunks: Thunk<any>[]): boolean {\n  return thunks.every(ea => defined(ea()))\n}\n\nexport function firstThunk<T>(...thunks: Thunk<Maybe<T>>[]): Maybe<T> {\n  for (const t of thunks) {\n    const r = t()\n    if (r != null) {\n      return r\n    }\n  }\n  return\n}\n\nexport function firstTrueThunk<T>(\n  thunks: Thunk<Maybe<T>>[],\n  predicate?: (t: T) => boolean\n): Maybe<T> {\n  for (const t of thunks) {\n    const r = t()\n    if (r != null && (predicate == null || predicate(r))) {\n      return r\n    }\n  }\n  return\n}\n\nexport function firstDefined<T>(...objects: MaybeNull<T>[]): Maybe<T> {\n  return objects.find(defined)\n}\n\nexport function firstDefinedField<T, K extends keyof T>(\n  obj: T,\n  ...fieldNames: K[]\n): Maybe<T[K]> {\n  return map(\n    fieldNames.find(field => null != obj[field]),\n    fieldName => obj[fieldName]\n  )\n}\n\nexport function firstFieldLike<T extends Pojo, K extends keyof T>(\n  obj: T,\n  predicate: (key: K, value: T[K]) => boolean\n): Maybe<T[K]> {\n  return first(\n    keys(obj) as K[], // SITS: why is this cast needed?\n    key => (predicate(key, obj[key]) ? obj[key] : undefined)\n  )\n}\n\n// knex interprets undefined parameters as runtime mistakes, so use null:\nexport function ornull<T>(a?: T): T | null {\n  return a === undefined ? null : a\n}\n\nexport function mapAnd<T>(obj: MaybeNull<T>, f: (t: T) => boolean): boolean {\n  return obj != null ? f(obj) : false\n}\n\nexport function mapOrThrow<T, R>(\n  obj: MaybeNull<T>,\n  f: (t: T) => R,\n  errIfMissing: string\n): R {\n  if (obj != null) {\n    return f(obj)\n  } else {\n    throw new Error(errIfMissing)\n  }\n}\n\nexport function Try<T>(\n  f: () => T,\n  onError?: (error: Error) => Maybe<T>\n): Maybe<T> {\n  try {\n    return f()\n  } catch (err) {\n    return onError != null ? onError(err) : undefined\n  }\n}\n\nexport function tryEach<T>(iter: Iterable<T>, f: (t: T) => any): void {\n  ;[...iter].forEach(ea => Try(() => f(ea)))\n}\n\nexport function identity<T>(t: T) {\n  return t\n}\n\nexport function ctor(obj: any): Maybe<string> {\n  return map(obj.constructor, ea => ea.name)\n}\n\nexport function hasKeys(obj: any): boolean {\n  return Object.keys(obj).some(\n    // eslint-disable-next-line @typescript-eslint/strict-boolean-expressions, no-prototype-builtins\n    k => typeof k === \"string\" && obj.propertyIsEnumerable(k)\n  )\n}\n\n/**\n * primitive and Dates\n */\nexport function primitiveEntries(o: Pojo): [string, Primitive][] {\n  return keys(o)\n    .filter(k => isPrimitive(o[k]) || isDate(o[k]))\n    .map(k => [k, o[k]] as [string, Primitive])\n}\n\nexport function spread<T extends Pojo>(\n  defaults: T,\n  ...sources: MaybeNull<Partial<T>>[]\n): T {\n  return Object.assign({} as T, defaults, ...compact(sources))\n}\n\nexport function assignMissingPrimitives<T>(dest: T, src: Maybe<Partial<T>>): T {\n  if (src == null) {\n    return dest\n  }\n  for (const [k, v] of primitiveEntries(src)) {\n    if (dest[k] == null) {\n      dest[k] = v\n    }\n  }\n  return dest\n}\n\nexport function assignFields<T>(dest: T, src: Maybe<Pick<T, any>>): T {\n  if (src == null) {\n    return dest\n  }\n  for (const [k, v] of entries(src)) {\n    if (v != null) (dest as any)[k] = v\n  }\n  return dest\n}\n\nexport function pickMap<K extends string, V, U>(\n  obj: Record<K, V>,\n  keysToRetain: K[],\n  f: (key: K, value: V) => U\n): Record<K, U> {\n  const r = {} as Record<K, U>\n  for (const k of keysToRetain) {\n    r[k] = f(k, obj[k])\n  }\n  return r\n}\n\nexport function mapEntries<T extends Pojo, U>(\n  obj: T,\n  f: (key: keyof T & string, value: T[keyof T]) => Maybe<U>\n): Record<keyof T, U> {\n  const r = {} as Record<keyof T, U>\n  for (const k of keys(obj)) {\n    // PERF: UNROLL\n    const v = f(k, obj[k])\n    if (v != null) r[k] = v\n  }\n  return r\n}\n\n/**\n * Do all fields in `a` match `b`?\n */\nexport function eqlSubset<T>(a: Maybe<Pick<T, any>>, b: T): boolean {\n  return a == null ? false : keys(a).every(ea => eql(a[ea], b[ea]))\n}\n\n/**\n * For a given field name, what's o[fieldpath]?\n *\n * If fieldpath includes \".\", those will be used to find sub-objects.\n */\nexport function valpath(o: any, ciFieldPath: string): any {\n  if (ciFieldPath == null || o == null || blank(ciFieldPath)) return o\n  if (Array.isArray(o)) return compact(o.map(ea => valpath(ea, ciFieldPath)))\n  const nextDot = ciFieldPath.indexOf(\".\")\n  const field = nextDot < 0 ? ciFieldPath : ciFieldPath.slice(0, nextDot)\n  const fieldRemains = nextDot < 0 ? undefined : ciFieldPath.slice(nextDot + 1)\n  const k = keys(o)\n  if (k.includes(field)) return valpath(o[field], fieldRemains!)\n  const ciField = k.find(ea => equalsIgnoreCase(ea, field))\n  if (ciField != null) {\n    return valpath(o[ciField], fieldRemains!)\n  }\n  return\n}\n", "import { isFunction } from \"./ObjectType\"\n\nexport type AsPromiseable<T> =\n  | T\n  | Promise<T>\n  | (() => T | Promise<T>)\n  | Promise<() => T | Promise<T>>\n\nexport async function asPromise<T>(o: AsPromiseable<T>): Promise<T> {\n  const a = await o\n  return isFunction(a) ? a() : a\n}\n", "import { gt0 } from \"./Number\"\nimport { isFunction } from \"./ObjectType\"\n\nexport function unrefDelay(millis: number) {\n  return _delay(millis, true)\n}\n\nexport function delay(millis: number) {\n  return _delay(millis, false)\n}\n\nexport function delayUntil(date: Date | number) {\n  const t = gt0(date) ? date : date.getTime()\n  const delayMs = t - Date.now()\n  if (delayMs < 0) {\n    if (delayMs > -500) {\n      // meh close enough\n      return\n    } else {\n      throw new Error(\n        \"Mr. Fusion not found, cannot time travel back \" + -delayMs + \"ms\"\n      )\n    }\n  }\n  return delay(delayMs).then(() => delayMs)\n}\n\nfunction _delay(millis: number, unref: boolean): Promise<void> {\n  // On windows at least, setTimeout() only ensures N-1 millis have passed.\n  return new Promise<void>(resolve => {\n    if (millis <= 0) {\n      resolve()\n    } else {\n      // ceil(+0.5) to make sure we wait enough time:\n\n      // SITS: any casting shenanigans to make this work on the frontend and\n      // backend:\n      const t: any = setTimeout(() => resolve(), Math.ceil(millis + 0.5))\n      // eslint-disable-next-line @typescript-eslint/unbound-method\n      if (unref && t.unref != null && isFunction(t.unref)) t.unref()\n    }\n  })\n}\n\nexport function later(f: () => any, delayMs: number = 1) {\n  return setTimeout(f, Math.max(1, Math.ceil(delayMs)))\n}\n", "import { asPromise } from \"../../fe/AsPromise\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { unrefDelay } from \"../../fe/Delay\"\n\nexport async function thenOrTimeout<T>(\n  p: T | (() => T | Promise<T>),\n  timeoutMs: number,\n  onTimeout: () => any = () => undefined,\n  onSuccess: (t: T) => any | Promise<any> = () => undefined\n): PromiseMaybe<T> {\n  let _resolved = false\n  let timedOut = false\n  let result: Maybe<T>\n  await Promise.race([\n    asPromise(p).then(ea => {\n      if (!timedOut) {\n        result = ea\n        _resolved = true\n        return ea\n      } else {\n        return\n      }\n    }),\n    // This delay must be unref'ed so as to not prevent node from exitting:\n    unrefDelay(timeoutMs).then(() => {\n      if (!_resolved) {\n        timedOut = true\n      }\n    })\n  ])\n  if (_resolved) {\n    await onSuccess(result!)\n  } else {\n    await onTimeout()\n  }\n  return result\n}\n", "import { setInterval, setTimeout } from \"timers\"\nimport { tap } from \"../../fe/Object\"\n\nexport function setUnrefTimeout(\n  callback: (...ea: any[]) => void,\n  ms: number,\n  ...args: any[]\n): NodeJS.Timeout {\n  return tap(setTimeout(callback, Math.round(ms), ...args), t => t.unref())\n}\n\nexport function setUnrefInterval(\n  callback: (...ea: any[]) => void,\n  ms: number,\n  ...args: any[]\n): NodeJS.Timeout {\n  return tap(setInterval(callback, Math.round(ms), ...args), t => t.unref())\n}\n", "import { isNotEmpty } from \"../../fe/Array\"\nimport { minuteMs, secondMs } from \"../../fe/Date\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { MaybeSyncOrAsync } from \"../../fe/OptAsync\"\nimport { strEnum, StrEnumKeys } from \"../../fe/StrEnum\"\nimport { magenta } from \"../Chalk\"\nimport { isEnvTrue } from \"../Env\"\nimport { mkLogger } from \"../Logger\"\nimport { MultiMap } from \"../MultiMap\"\nimport { isSingleSpecTests, isTest } from \"../NodeEnv\"\nimport { firstGt0 } from \"../Number\"\nimport { Try } from \"../Object\"\nimport { thenOrTimeout } from \"./thenOrTimeout\"\nimport { setUnrefInterval } from \"./Timers\"\n\nconst logger = lazy(() => mkLogger(magenta(\"Endable\")))\n\nexport interface Endable {\n  readonly name: string\n  readonly ended: boolean\n  readonly endTimeoutMs?: number\n  end(): Promise<any> | any\n}\n\nconst endablesByRank = new MultiMap<EndableRank, Endable>()\n\nsetUnrefInterval(() => vacuumEndables(), 1 * minuteMs)\n\nconst DefaultTimeoutMs = 5 * secondMs\n\nexport const EndableRanks = strEnum(\n  \"first\",\n  \"service\",\n  \"predb\",\n  \"db\",\n  \"postdb\",\n  \"logger\"\n)\nexport type EndableRank = StrEnumKeys<typeof EndableRanks>\n\n/**\n * \"First\" endables have no dependant services.\n */\nexport function addFirstEndable<T extends Endable>(endable: T): T {\n  return addEndable(EndableRanks.first, endable)\n}\n\n/**\n * These are services that \"first\" endables depend on, but may require other services.\n */\nexport function addServiceEndable<T extends Endable>(endable: T): T {\n  return addEndable(EndableRanks.service, endable)\n}\n\n/**\n * These are final cleanup tasks once the services are shut down, like a db\n * backup.\n */\nexport function addPreDbEndable<T extends Endable>(endable: T): T {\n  return addEndable(EndableRanks.predb, endable)\n}\n\n/**\n * Final services that services depend on, like closing the DB.\n */\nexport function addDbEndable<T extends Endable>(endable: T): T {\n  // closing the db should be instant, use the default timeout:\n  return addEndable(EndableRanks.db, endable)\n}\n\n/**\n * Final services that need to run after the db has closed (like releasing the\n * opened-by lock)\n */\nexport function addPostDbEndable<T extends Endable>(endable: T): T {\n  // closing the db should be instant, use the default timeout:\n  return addEndable(EndableRanks.postdb, endable)\n}\n\n/**\n * Final-final ending-endable, reserved for the logger.\n */\nexport function addLoggerEndable<T extends Endable>(endable: T): T {\n  return addEndable(EndableRanks.logger, endable)\n}\n\n/**\n * Add an endable with an arbitrary end rank\n */\nexport function addEndable<T extends Endable>(\n  rank: EndableRank,\n  endable: T\n): T {\n  EndableRanks.validOrElse(rank, () => {\n    throw new Error(\"internal error: invalid rank \" + rank)\n  })\n  endablesByRank.add(rank, endable)\n  return endable\n}\n\nlet _ending = false\n\nexport function ending(): boolean {\n  return _ending\n}\n\nexport function setEnding(value: boolean) {\n  if (isTest) {\n    _ending = value\n  } else {\n    throw new Error(\"cannot set ending\")\n  }\n}\n\nexport function endAll(...arr: Maybe<Endable>[]) {\n  return Promise.all(arr.map(ea => end(ea)))\n}\n\nexport async function end(e: MaybeSyncOrAsync<Endable>, endTimeoutMs?: number) {\n  const endable = await e\n  if (endable == null || endable.ended) return\n  const timeoutMs =\n    isTest && isEnvTrue(\"SINGLE_SPEC_TESTS\")\n      ? 100\n      : firstGt0(endTimeoutMs, endable.endTimeoutMs, DefaultTimeoutMs)!\n  logger().debug(endable.name + \" ending...\", { timeoutMs })\n  return thenOrTimeout(\n    endable.end(),\n    timeoutMs,\n    () => logger().warn(endable.name + \".end() timed out\"),\n    () => logger().debug(endable.name + \".end() completed\")\n  ).catch(err => {\n    // the logger might throw errors at the very end:\n    Try(() => logger().warn(endable.name + \".end() rejected: \" + err))\n  })\n}\n\nfunction vacuumEndables() {\n  endablesByRank.filterInPlace((_, v) => !v.ended)\n  logger().debug(\n    \"vacuumEndables()\",\n    endablesByRank.entriesArray().map(([k, v]) => [k, v.map(ea => ea.name)])\n  )\n}\n\nexport const endEndables = lazy(async () => {\n  const endTimeoutMs = isSingleSpecTests() ? 250 : undefined\n\n  logger().info(\"endEndables()\", { isTest, isSingleSpecTests })\n  if (!isTest) _ending = true\n  vacuumEndables()\n  for (const rank of EndableRanks.values) {\n    const arr = orElse(endablesByRank.get(rank), [])\n    if (isNotEmpty(arr)) {\n      logger().debug(\"endEndables(): ending \" + rank)\n      await Promise.all(arr.map(ea => end(ea, endTimeoutMs)))\n    }\n  }\n})\n", "import { cpus } from \"os\"\nimport { delimiter, join } from \"path\"\nimport { diff, sortBy, uniq } from \"../../fe/Array\"\nimport { blank, mapNotBlankOr, notBlank } from \"../../fe/Blank\"\nimport { minuteMs, secondMs } from \"../../fe/Date\"\nimport { FitSizeValues } from \"../../fe/ImageSizes\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { entries, values } from \"../../fe/Object\"\nimport { GB, KB } from \"../../fe/Units\"\nimport { defaultCacheDir } from \"../DefaultCacheDir\"\nimport { isEnvTrue } from \"../Env\"\nimport { defaultLogDir } from \"../LogDir\"\nimport { isProd as _isProd } from \"../NodeEnv\"\nimport { channel } from \"../PhotoStructureVersion\"\nimport { defaultPicturesDir } from \"../PicturesDir\"\nimport { isDocker, isElectron, isLinux, isMac, isWin } from \"../Platform\"\nimport { PriorityClasses } from \"../PriorityClass\"\nimport { DefaultLensMakes } from \"../tags/DefaultLensMakes\"\nimport { SidecarExts } from \"../tags/SidecarExts\"\nimport {\n  BooleanSetting,\n  BoundedFloatSetting,\n  BoundedIntegerSetting,\n  FloatSetting,\n  IntegerSetting,\n  LibraryCategories,\n  MaybeStringSetting,\n  SettingCategories,\n  StringArraySetting,\n  StringEnumSetting,\n  StringEnumsSetting,\n  StringSetting,\n  SystemCategories\n} from \"./Setting\"\nimport _p = require(\"process\")\n\nconst DefaultPosixPaths = Object.freeze([\n  // From Ubuntu's /etc/environment:\n  \"/usr/local/sbin\",\n  \"/usr/local/bin\",\n  \"/opt/local/sbin\", // macports\n  \"/opt/local/bin\", // macports\n  \"/usr/sbin\",\n  \"/usr/bin\",\n  \"/sbin\",\n  \"/bin\"\n])\n\n// exposed so tests can pretend we're in production:\nexport const isProd = lazy(() => _isProd)\nconst isTest = () => !isProd()\n\n// Only exported for testing:\nexport const DefaultPaths = Object.freeze(\n  isWin\n    ? [\n        ...mapNotBlankOr(\n          _p.env.SYSTEMROOT,\n          ea => [\n            ea,\n            join(_p.env.SYSTEMROOT!, \"System32\"),\n            join(_p.env.SYSTEMROOT!, \"System32\", \"webm\")\n          ],\n          () => []\n        ),\n        \"C:\\\\cygwin64\\\\bin\"\n      ]\n    : DefaultPosixPaths\n)\n\n// Most all Setting instances have keys that are prefixed with `PS_`, which let\n// them be used in environment variables without colliding with other\n// environment variables. The `PS_` prefix isn't needed otherwise.\n\n// Only Setting instances should be included in this namespace:\nexport const Settings = {\n  copyAssetsToLibrary: new BooleanSetting({\n    category: SettingCategories.Paths,\n    description: `Should PhotoStructure copy photos and videos to your PhotoStructure Library? This setting holds the value for the welcome page's \"May PhotoStructure organize your photos and videos?\" section. Read more about this setting here: <https://photostructure.com/getting-started/automatic-library-organization/>.`,\n    defaultValue: true,\n    advanced: () => false\n  }),\n\n  libraryPath: new MaybeStringSetting({\n    envAliases: [\"PS_LIBRARY\", \"PS_LIBRARY_DIR\"],\n    category: SettingCategories.Paths,\n    description:\n      \"This is the absolute path to your PhotoStructure library. If missing, or set to an empty string, the welcome page will be shown when PhotoStructure launches. Use native file separators (so on windows, use back-slashes).\",\n    exampleValue: () =>\n      isTest()\n        ? \"/home/test/Pictures\"\n        : isDocker()\n        ? \"/ps/library\"\n        : defaultPicturesDir(),\n    defaultValue: () => (isDocker() && !isTest() ? \"/ps/library\" : undefined),\n    advanced: () => false\n  }),\n\n  previewsDir: new StringSetting({\n    category: SettingCategories.Paths,\n    description: `This is the directory that PhotoStructure uses to store preview images. This defaults to the \".photostructure/previews\" directory inside your PhotoStructure library. Absolute paths here are supported, but if you keep your library and previews directory separated, take care when you open your library on different computers, as this setting needs to be adjusted for those computers as well.\\nNOTE: \"originalDirs\" is recommended instead of this setting; If you get \"previewsDir\" wrong, your library won't work. If you get \"originalsDir\" wrong, you just break full-screen zoom and non-transcoded videos.`,\n    defaultValue: () => \".photostructure/previews\"\n  }),\n\n  originalsDir: new StringSetting({\n    category: SettingCategories.Paths,\n    description: `This is the directory that PhotoStructure uses to store original images when \"copyAssetsToLibrary\" is enabled. Absolute paths are supported. Relative paths are evaluated from your libraryPath. This setting defaults to \".\", which is the same as your PhotoStructure library directory.\\nIf you open your PhotoStructure library on a different computer, and that computer doesn't have access to your originals volume, full-screen zoom won't work, and non-transcoded videos will not play.\\nThis system setting needs to be set appropriately on different computers (it won't be set automatically!)\\nIf you have a large library and want to use an SSD, we recommend you set your libraryPath to your SSD, and use this setting to store your originals on a larger volume, rather than using the \"previewsDir\" setting.`,\n    defaultValue: () => \".\"\n  }),\n\n  forceOpen: new BooleanSetting({\n    category: SettingCategories.Paths,\n    description:\n      \"DANGEROUS: if set, all previously-existing library locks will be removed. This should only be necessary if the prior PhotoStructure process was not shut down gracefully.\",\n    defaultValue: false,\n    transient: true\n  }),\n\n  scanAllDrives: new BooleanSetting({\n    category: SettingCategories.Paths,\n    description:\n      \"Should PhotoStructure scan all folders on all drives available to this computer for photos and videos?\",\n    defaultValue: true,\n    advanced: () => false\n  }),\n\n  scanMyPictures: new BooleanSetting({\n    category: SettingCategories.Paths,\n    description:\n      \"Deprecated, and will be removed in the next version. If set, PhotoStructure will automatically add your pictures directory to your `scanPaths` setting.\",\n    defaultValue: false,\n    advanced: () => false\n  }),\n\n  scanPaths: new StringArraySetting({\n    category: SettingCategories.Paths,\n    description: `This holds an array of absolute paths to scan for assets. If you are setting this via an environment variable, you may use either standard PATH formatting, like \\`PS_SCAN_PATHS=\"/path/one:/path/two\"\\`, or use JSON encoding, like \\`PS_SCAN_PATHS='[\"/path/one\",\"/path/two\"]'\\`.`,\n    advanced: () => false,\n    exampleValue: () =>\n      isTest() ? [\"/path/one\", \"/path/two\"] : [defaultPicturesDir()]\n  }),\n\n  cacheDir: new StringSetting({\n    category: SettingCategories.Paths,\n    description:\n      \"Where would you like PhotoStructure's scratch file directory? This must be a fast, local disk with several gigabytes free. Note that if PS_FORCE_LOCAL_DB_REPLICA is enabled, the local DB replica will be stored in this directory.\",\n    exampleValue: () => (isTest() ? \"/tmp/ps_cache_dir\" : defaultCacheDir()),\n    defaultValue: () => defaultCacheDir()\n  }),\n\n  neverIgnored: new StringArraySetting({\n    category: SettingCategories.Paths,\n    description:\n      \"Paths to files or directories that should not be ignored, even if they are hidden or have .nomedia files.\"\n  }),\n\n  pidfile: new MaybeStringSetting({\n    envAliases: [\"PIDFILE\"],\n    category: SettingCategories.Paths,\n    description:\n      \"This is the absolute path to the PID file for the main process. This is optional and only used by PhotoStructure for Servers.\",\n    exampleValue: () => \"/var/run/photostructure.pid\"\n  }),\n\n  scanLibraryFirst: new BooleanSetting({\n    category: SettingCategories.Paths,\n    description:\n      \"Should PhotoStructure scan your library before all other paths are synchronized?\",\n    defaultValue: false\n  }),\n\n  scanLibraryLast: new BooleanSetting({\n    category: SettingCategories.Paths,\n    description:\n      \"Should PhotoStructure scan your library after all other paths are synchronized?\",\n    defaultValue: true\n  }),\n\n  //\n  // LOGGING\n  //\n\n  logLevel: new StringSetting({\n    envAliases: [\"PS_LOG\", \"LOG\"],\n    category: SettingCategories.Logging,\n    description:\n      \"Determines which level of log messages are emitted to log files. May be 'debug', 'info', 'warn', 'error', or a log level followed by a context (like 'debug:rpc').\",\n    defaultValue: () => (isProd() ? \"error\" : \"info\")\n  }),\n\n  logDir: new StringSetting({\n    category: SettingCategories.Logging,\n    description: \"Determines the directory that log files will be written to.\",\n    defaultValue: () => defaultLogDir(),\n    exampleValue: () => (isTest() ? \"/var/log/photostructure\" : undefined)\n  }),\n\n  logCompression: new BooleanSetting({\n    category: SettingCategories.Logging,\n    description: \"Should log files be compressed as they are rotated?\",\n    defaultValue: () => isProd() // don't compress in test or dev so logtail is happy\n  }),\n\n  logElapsedMs: new BooleanSetting({\n    category: SettingCategories.Logging,\n    description:\n      \"Prefix log entries by a timestamp (if set to false), or by the number of milliseconds since startup (if set to true).\",\n    defaultValue: () => false\n  }),\n\n  logWebRequests: new BooleanSetting({\n    category: SettingCategories.Logging,\n    description: \"Write an access log for all web requests?\",\n    defaultValue: false\n  }),\n\n  logWebDir: new MaybeStringSetting({\n    category: SettingCategories.Logging,\n    description:\n      \"Determines the directory that log files will be written to. If unset, will use logDir.\"\n  }),\n\n  logStdout: new BooleanSetting({\n    envAliases: [\"LOG_STDOUT\", \"PS_STDOUT\"],\n    category: SettingCategories.Logging,\n    description:\n      \"Log to stdout? This should be false unless you're running a service by hand.\",\n    defaultValue: false,\n    transient: true\n  }),\n\n  tailLogs: new BooleanSetting({\n    category: SettingCategories.Logging,\n    description:\n      \"Output all logs from currently running PhotoStructure processes? This should be false unless you're running a service by hand.\",\n    defaultValue: false,\n    transient: true\n  }),\n\n  logColor: new BooleanSetting({\n    category: SettingCategories.Logging,\n    description:\n      \"Output all logs with terminal escape codes to colorize output. If NO_COLOR is set, this defaults to false. See <https://no-color.org/>.\",\n    defaultValue: () => blank(_p.env.NO_COLOR)\n  }),\n\n  logSql: new BooleanSetting({\n    category: SettingCategories.Logging,\n    description:\n      \"Log SQL queries to the default log level. *This is really chatty* and impacts performance. Normally these log messages are completely disabled.\",\n    defaultValue: () => false\n  }),\n\n  //\n  // Networking\n  //\n\n  localhost: new StringSetting({\n    category: SettingCategories.Networking,\n    description: `If \"exposeNetworkWithoutAuth\" is false, what value should PhotoStructure use for localhost? (Some firewalls are OK with \"127.0.0.1\", some require \"localhost\"). See <https://letsencrypt.org/docs/certificates-for-localhost/> and <https://photostructure.com/faq/troubleshooting/#windows-firewall-issues>.`,\n    // See https://letsencrypt.org/docs/certificates-for-localhost/\n    // and https://tools.ietf.org/html/draft-ietf-dnsop-let-localhost-be-localhost-02\n    defaultValue: () => \"127.0.0.1\"\n  }),\n\n  httpPort: new IntegerSetting({\n    category: SettingCategories.Networking,\n    description: \"Network port for HTTP access to your PhotoStructure library.\",\n    defaultValue: 1787\n  }),\n\n  trustProxy: new StringSetting({\n    category: SettingCategories.Networking,\n    description: `Support for PhotoStructure instances running behind a reverse proxy. See <http://expressjs.com/en/guide/behind-proxies.html>. This setting should either be \"false\" (don't trust any proxies), \"loopback\", (only trust localhost), a single subnet (like \"127.0.0.0/8\"), or a comma-delimited set of subnets.`,\n    defaultValue: \"false\"\n  }),\n\n  exposeNetworkWithoutAuth: new BooleanSetting({\n    category: SettingCategories.Networking,\n    description:\n      \"Normally the web service is only accessible to the computer running PhotoStructure. Setting this to true will expose your library to all computers on your network. You should own or trust all systems on that network, as there is no auth in PhotoStructure currently. Future versions of PhotoStructure will add authorization mechanisms, at which point this setting will be deleted.\\n**Don't enable this unless you know what you are doing**.\",\n    defaultValue: () => isDocker() && !isTest()\n  }),\n\n  rpcPort: new IntegerSetting({\n    category: SettingCategories.Networking,\n    description: `Network port for rpc access to your PhotoStructure library. Only binds to loopback (even if exposeNetworkWithoutAuth is true).`,\n    defaultValue: 1807\n  }),\n\n  //\n  // Process management\n  //\n\n  exiftoolProcsPerChild: new BoundedIntegerSetting({\n    category: SettingCategories.Processes,\n    description:\n      \"Each PhotoStructure process spins up an ExifTool when needed. Note that the `web`, `sync`, and `sync-file` services all use exiftool, so the total number of exiftool processes can be many times larger than this value.\",\n    min: 1,\n    max: 8,\n    defaultValue: 2\n  }),\n\n  sensitiveEnvRegExp: new StringSetting({\n    category: SettingCategories.Processes,\n    description: `PhotoStructure spawns a number of processes (including \"exiftool\" and \"ffmpeg\"), and passes through environment variables, mostly to ensure locale and TZ settings are correct. To prevent environment values that contain sensitive information, like API access tokens, from either being logged, or being accessed by external tools, all environment variables whose key matches this setting will be removed. This regex is applied case-insensitively.`,\n    defaultValue: \"key|secret|pass|_user|aws_\"\n  }),\n\n  bounceMinutes: new IntegerSetting({\n    category: SettingCategories.Processes,\n    description:\n      \"PhotoStructure will bounce the web and sync processes periodically. Set to 0 to disable.\",\n    defaultValue: 60 * (isTest() ? 5 : isMac ? 2 : 5)\n  }),\n\n  setupTimeoutMs: new IntegerSetting({\n    category: SettingCategories.Processes,\n    description: `To prevent unhealthy services running as zombies, they self-terminate if the setup processes are not complete within this amount of time. Note that only the environment variable value is used for this setting.`,\n    defaultValue: 35 * secondMs\n  }),\n\n  probationMs: new IntegerSetting({\n    category: SettingCategories.Processes,\n    description:\n      \"Normally when subsystems crash, PhotoStructure restarts them after a delay. Unfortunately, if there is a persistent error, this means PhotoStructure keeps trying something that won't ever work; it looks busy, but it's just busy failing. To prevent this situation, PhotoStructure will shut down if there are high error rates within 2 minutes of starting. (2 minutes should be long enough to spin up the web process, sync process, and import at least one pending file). Setting this to 0 will prevent PhotoStructure from exiting due to high error rates.\",\n    defaultValue: 2 * minuteMs\n  }),\n\n  minTimeBetweenServiceRestartsMs: new IntegerSetting({\n    category: SettingCategories.Processes,\n    description:\n      \"If a service (like web, sync, or sync-file) is restarted due to an error, how many ms must elapse before another restart is allowed? This helps prevent system load due to service flapping.\",\n    defaultValue: 7 * secondMs\n  }),\n\n  fatalErrorRatePerMinute: new IntegerSetting({\n    category: SettingCategories.Processes,\n    description:\n      \"If PhotoStructure sees errors at a higher rate per minute than this setting, PhotoStructure will shut down. If this value is too high, PhotoStructure may look busy, but it's just busyfailing. If this value is set too low, temporary errors (due to network flakiness or USB hiccups) might shut down PhotoStructure needlessly.\",\n    defaultValue: 10\n  }),\n\n  minDiskFreeGb: new IntegerSetting({\n    category: SettingCategories.Processes,\n    description:\n      \"PhotoStructure will pause processing if the GB free on the disk that your library is stored on drops below this value. The value provided here will be multiplied by 1000^3. Note that many OSes will corrupt themselves when disks fill up, and SSDs can fail as they approach full capacity. A value of less than 8 may be unsafe (due to hibernation and os update files).\",\n    defaultValue: 6\n  }),\n\n  cpuLoadPercent: new BoundedIntegerSetting({\n    category: SettingCategories.Processes,\n    description:\n      \"PhotoStructure runs many things in parallel during library synchronization. The maximum number of concurrent file imports that PhotoStructure will schedule at a time will be the number of CPUs that this system has multiplied by this percent. A higher value here will allow PhotoStructure to run more tasks in parallel, but may impact your system's responsiveness. 75% should be a reasonable balance between keeping your system responsive and importing your library quickly. Setting this value to 0 will still allow 1 task to run concurrently. System memory will also be taken into account to try to prevent swapping.\",\n    defaultValue: 75,\n    min: 0,\n    max: 200\n  }),\n\n  processPriority: new StringEnumSetting({\n    category: SettingCategories.Processes,\n    description: `By default, PhotoStructure runs child processes with a \"below normal\" priority, so your system remains usable while imports run. Changing this value to \"normal\" or \"above normal\" may speed up imports but cause your system to be unresponsive. Changing this value to \"idle\" may prevent imports from running at all.`,\n    defaultValue: () => PriorityClasses.BelowNormal,\n    validValues: PriorityClasses.values\n  }),\n\n  maxMemoryMb: new BoundedIntegerSetting({\n    category: SettingCategories.Processes,\n    description:\n      \"PhotoStructure will restart services if they use more than this value (measured in megabytes, or 1,000,000 bytes). Note that this is not the allocated memory. See maxRssMemoryMb for total allocated.\",\n    defaultValue: 500,\n    min: 256,\n    max: 8000\n  }),\n\n  maxRssMemoryMb: new BoundedIntegerSetting({\n    category: SettingCategories.Processes,\n    description:\n      \"PhotoStructure will restart services if their' resident set size consumes more than this value (measured in megabytes, or 1,000,000 bytes).\",\n    defaultValue: 1000,\n    min: 250,\n    max: 8000\n  }),\n\n  maxTasksPerProcess: new BoundedIntegerSetting({\n    category: SettingCategories.Processes,\n    description:\n      \"PhotoStructure will recycle sync-file processes after they handle this number of requests. Smaller values may reduce overall memory pressure. Larger values amortize startup costs over fewer restarts.\",\n    defaultValue: () => (isTest() ? 10 : 200),\n    min: 1,\n    max: 5000\n  }),\n\n  pollIntervalMs: new IntegerSetting({\n    category: SettingCategories.Processes,\n    description:\n      \"The number of milliseconds we wait between polling for changes in remote filesystems. This defaults to 1 minute, to minimize remote filesystem load.\",\n    defaultValue: () => (isProd() ? minuteMs : 5 * secondMs)\n  }),\n\n  inspect: new BooleanSetting({\n    category: SettingCategories.Processes,\n    description:\n      \"Should processes run with --inspect? This should only be enabled temporarily, as it impacts both performance and security.\",\n    defaultValue: false,\n    transient: true,\n    advanced: () => true\n  }),\n\n  ignoreUnhealthyVolumes: new BooleanSetting({\n    category: SettingCategories.Volumes,\n    description:\n      \"When true, PhotoStructure ignores volumes that are not healthy (due to needing filesystem checks, or remote filesystems that are not available).\",\n    defaultValue: true\n  }),\n\n  validateMountpoints: new BooleanSetting({\n    category: SettingCategories.Volumes,\n    description:\n      \"When true, PhotoStructure ignores volumes whose mountpoints do not exist.\",\n    defaultValue: true\n  }),\n\n  readVolumeUuidFiles: new BooleanSetting({\n    category: SettingCategories.Volumes,\n    description: `When true, PhotoStructure uses \".uuid\" files found in the root directory of volumes as the volume UUID, which can help with cross-host library portability. Set this to false if you don't want PhotoStructure to read these \".uuid\" files. See https://photostructure.com/faq/what-is-a-volume for more information.`,\n    defaultValue: true\n  }),\n\n  writeVolumeUuidFiles: new BooleanSetting({\n    category: SettingCategories.Volumes,\n    description: `When true, PhotoStructure (tries to) write \".uuid\" files into the root directory of volumes, which enables cross-host library portability. Set this to false if you don't want PhotoStructure to try to write these \".uuid\" files. See https://photostructure.com/faq/what-is-a-volume for more information.`,\n    defaultValue: true\n  }),\n\n  // TODO: (this requires the thumbnails to be built on the fly)\n  // ,skipThumbs: new BooleanPref({\n  //   key: \"PS_SKIP_THUMBS\",\n  //   description:\n  //     \"If set, no thumbnails or websized previews will be created during library imports, which makes library importing much faster. Browsing, however, is much slower, as previews must be created on the fly\",\n  //   defaultValue: false,\n  //   persisted: true\n  // })\n\n  //\n  // DB\n  //\n\n  // Use primary/replica terminology:\n\n  forceLocalDbReplica: new BooleanSetting({\n    category: SettingCategories.Paths, // because it will be specific to the system, not the library.\n    description:\n      \"Libraries on remote filesystems can suffer from bad performance and inconsistent transactions due to slow file I/O and missing file locking mechanics. When opening libraries on remote filesystems, or if this setting is `true`, PhotoStructure will copy the library database to the `cacheDir` and perform I/O against this local replica. Changes made to the local db replica are then periodically copied back to the remote library.\",\n    defaultValue: () => isDocker() && !isTest()\n  }),\n\n  // From https://sqlite.org/pragma.html#pragma_optimize\n\n  // \"Long-running applications might also benefit from setting a timer to run\n  // \"PRAGMA optimize\" every few hours.\"\n\n  dbBackupsCount: new IntegerSetting({\n    category: SettingCategories.Db,\n    description:\n      \"How many prior backups should PhotoStructure retain? These will typically be 10-500 MB, depending on the size of your library.\",\n    defaultValue: 20\n  }),\n\n  maxBusyDbMs: new IntegerSetting({\n    category: SettingCategories.Db,\n    description:\n      \"SQLite supports concurrent readers but concurrent writers may collide, causing a LOCKED or BUSY error. PhotoStructure will retry the db operation for maxBusyDbMs milliseconds. This defaults to 2 minutes, which seems like a long time, but hard drives and network filesystems can take 10-20 seconds to spin up if asleep.\",\n    defaultValue: () => 2 * minuteMs\n  }),\n\n  dbTimeoutMs: new IntegerSetting({\n    category: SettingCategories.Db,\n    description:\n      \"SQLite can time out requests if the db file is unavailable. PhotoStructure will retry those requests (up to `maxBusyDbMs`). A shorter time may help overall throughput, but may require more work done in retry logic. A longer time may be better for slower machines and slower disks. Note that setting this value to be lower than disk I/O latency (~1ms-100ms) will cause all database queries to fail.\",\n    defaultValue: () => secondMs\n  }),\n\n  // We're using a bounded float so we can get fractional minutes for test, and\n  // users don't have to think in milliseconds.\n  dbBackupIntervalMinutes: new BoundedFloatSetting({\n    category: SettingCategories.Db,\n    description:\n      \"How many minutes should elapse between backing of your library database? Note that PhotoStructure vacuums and optimizes the database before a backup is taken. You want this period to be frequent enough such that data loss isn't too painful. Note that backups can cause the webserver to be momentarily unresponsive. Default is every hour.\",\n    min: isTest() ? 0.5 : 1, // < force a backup in the middle of the SyncService and ModelDbUpdater tests to exercise pause-for-vacuum\n    max: 60 * 12,\n    defaultValue: () => (isTest() ? 0.5 : 30)\n  }),\n\n  dbCacheSizeMb: new IntegerSetting({\n    category: SettingCategories.Db,\n    description:\n      \"PhotoStructure uses SQLite, and the cache_size pragma should ideally be set such that the whole DB can be in memory. See https://sqlite.org/pragma.html#pragma_cache_size for more information.\",\n    defaultValue: 192\n  }),\n\n  dbBatchSelectSize: new BoundedIntegerSetting({\n    category: SettingCategories.Db,\n    description:\n      \"How many objects can be selected at at time? The default should be fine. (Exposed for performance tests).\",\n    defaultValue: 128,\n    min: 1,\n    max: 900\n  }),\n\n  dbBatchUpsertSize: new BoundedIntegerSetting({\n    category: SettingCategories.Db,\n    description:\n      \"How many objects can be upserted at at time? The default should be fine. (Exposed for performance tests).\",\n    defaultValue: 16,\n    min: 1,\n    max: 500\n  }),\n\n  //\n  // Health checks\n  //\n\n  healthCheckExiftool: new BooleanSetting({\n    category: SettingCategories.HealthChecks,\n    description:\n      \"When true, PhotoStructure verifies ExifTool is available and a valid version.\",\n    defaultValue: true\n  }),\n\n  healthCheckLibraryIsWritable: new BooleanSetting({\n    category: SettingCategories.HealthChecks,\n    description:\n      \"When true, PhotoStructure verifies the library directory exists, and is writable.\",\n    defaultValue: true\n  }),\n\n  healthCheckVolumes: new BooleanSetting({\n    category: SettingCategories.HealthChecks,\n    description:\n      \"When true, PhotoStructure verifies volumes as part of periodic health checks.\",\n    defaultValue: true\n  }),\n\n  healthCheckFreeSpace: new BooleanSetting({\n    category: SettingCategories.HealthChecks,\n    description:\n      \"When true, PhotoStructure verifies that the library and cache volumes have sufficient free space.\",\n    defaultValue: true\n  }),\n\n  healthCheckDb: new BooleanSetting({\n    category: SettingCategories.HealthChecks,\n    description:\n      \"When true, PhotoStructure verifies that the library database can be read from and written to.\",\n    defaultValue: true\n  }),\n\n  //\n  // TOOLS\n  //\n\n  enableSIMD: new BooleanSetting({\n    category: SettingCategories.Tools,\n    description: `Should PhotoStructure enable SIMD extensions when running image operations? This defaults to false on macOS due to instability on that platform.`,\n    // isTest() to make the result consistent across CI:\n    defaultValue: () => (isTest() || isMac ? false : true)\n  }),\n\n  enableVipsCache: new BooleanSetting({\n    category: SettingCategories.Tools,\n    description: `Should PhotoStructure enable VIPS caching, which may help speed up image operations? This defaults to false to reduce memory consumption.`,\n    defaultValue: () => false\n  }),\n\n  showFileInFolderUsesThunar: new BooleanSetting({\n    category: SettingCategories.Tools,\n    description: `If we're on Linux, should we use Thunar (via dbus) to \"show file in folder\"?`,\n    defaultValue: false\n  }),\n\n  showFileInFolderUsesFileUri: new BooleanSetting({\n    category: SettingCategories.Tools,\n    description: `Does the showFileInFolderCommand expect a file: URI to the file? If this is false, the native path will be appended instead.`,\n    exampleValue: () => true,\n    defaultValue: () => isLinux\n  }),\n\n  showFileInFolderCommand: new StringArraySetting({\n    category: SettingCategories.Tools,\n    description: `If set, the first argument will be used as a command (or path to command), and the subsequent arguments (if present) will be used as arguments. The native path to the file or the file: URI will be appended, based on the value given to the \"showFileInFolderUsesFileUri\" setting. If this is set to an empty array, the default tool for your platform will be used instead: \"nautilus -s\" on linux, \"open -R\" on mac, and \"explorer /select\" on Windows.\\nThis is provided to support Linux desktops that don't use Gnome.`,\n    defaultValue: []\n  }),\n\n  dcraw_emuPath: new StringSetting({\n    category: SettingCategories.Tools,\n    description: `This should be the absolute, native path to the \"dcraw_emu\" binary on this system. If this is set to \"dcraw_emu\", PhotoStructure will search your $PATH. See <https://www.libraw.org/docs/Samples-LibRaw.html>.`,\n    defaultValue: \"dcraw_emu\"\n  }),\n\n  ffmpegPath: new StringSetting({\n    category: SettingCategories.Tools,\n    description: `This should be the absolute, native path to the \"ffmpeg\" binary on this system. If this is set to \"ffmpeg\", PhotoStructure will search your $PATH. PhotoStructure prefers using ffmpeg to vlc. See <https://photostructure.com/getting-started/video-support/>.`,\n    defaultValue: \"ffmpeg\"\n  }),\n\n  ffmpegTranscodeArgs: new StringArraySetting({\n    category: SettingCategories.Tools,\n    description: `The following are the default arguments added to transcode requests made to ffmpeg (when ffmpeg is available). The following arguments will proceed the command: \"-loglevel error -threads T -i INPUT_FILE_PATH\" (where T is replaced by ~half the available CPU threads, and INPUT_FILE_PATH is the full native pathname to the source video). The following arguments will follow the arguments in this setting: \"-b:v VIDEO_BITRATE_KBPS OUTPUT_FILE_PATH\".\\nCAUTION: this is an advanced setting. Editing this may cause videos that require transcoding to not be imported, or not be viewable on all browsers and platforms. See <https://forum.photostructure.com/t/hardware-accelerated-encoding-transcoding/166> for more details.`,\n    defaultValue: [\n      \"-c:a\",\n      \"aac\",\n      \"-c:v\",\n      \"libx264\",\n      // pix_fmt and profile are required by firefox (!!)\n      \"-pix_fmt\",\n      \"yuv420p\",\n      \"-profile:v\",\n      \"high\"\n    ]\n  }),\n\n  heifConvertPath: new StringSetting({\n    category: SettingCategories.Tools,\n    description: `This should be the absolute, native path to the \"heif-convert\" binary on this system. If this is set to \"heif-convert\", PhotoStructure will search your $PATH. See <https://photostructure.com/getting-started/heif-support/>.`,\n    defaultValue: \"heif-convert\"\n  }),\n\n  powerShellArgs: new StringArraySetting({\n    category: SettingCategories.Tools,\n    description: `The following are the default arguments added to spin up PowerShell on Windows devices.\\nSee <https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_powershell_exe?view=powershell-5.1> for all arguments that PowerShell.exe accepts.\\nSee <https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_execution_policies?view=powershell-5.1> for a description of Bypass.\\nSee <https://forum.photostructure.com/t/eliminate-powershell-profile-and-execution-policy-related-errors/184> for more details about why this needs to be configurable.\\n(Versions prior to v1.0.0 only specified \"-NoLogo\").`,\n    defaultValue: [\"-NoLogo\", \"-NoProfile\", \"-ExecutionPolicy\", \"Bypass\"]\n  }),\n\n  powerShellCulture: new StringSetting({\n    category: SettingCategories.Tools,\n    description:\n      \"If set to a non-blank value, PhotoStructure on Windows machines will set PowerShell's `[System.Threading.Thread]::CurrentThread.CurrentCulture` to this value. This allows PhotoStructure to parse PowerShell output reliably.\",\n    defaultValue: () => \"en-US\"\n  }),\n\n  toolPaths: new StringArraySetting({\n    category: SettingCategories.Tools,\n    description: `These paths are appended to the PATH to ensure PhotoStructure can find and run external tools like ffmpeg. Use your operating system's separator to separate paths (\":\" for mac and linux, \";\" for windows).`,\n    defaultValue: () =>\n      (isEnvTrue(\"SETTINGS_IO_TEST\")\n        ? DefaultPosixPaths\n        : DefaultPaths) as string[]\n  }),\n\n  vlcPath: new StringSetting({\n    category: SettingCategories.Tools,\n    description: `This should be the absolute, native path to the \"vlc\" binary on this system. If this is set to \"vlc\", PhotoStructure will search your $PATH.`,\n    defaultValue: \"vlc\"\n  }),\n\n  //\n  // Electron\n  //\n\n  openAtLogin: new BooleanSetting({\n    category: SettingCategories.Desktops,\n    description:\n      \"Set to true to have PhotoStructure start automatically on login. Only supported on PhotoStructure for Desktops on macOS and Windows 10.\",\n    defaultValue: false,\n    advanced: () => !isElectron\n  }),\n\n  updateChannel: new StringEnumSetting({\n    category: SettingCategories.Desktops,\n    description:\n      'TL:DR; keep this on \"latest.\" This setting only applies to PhotoStructure for Desktops, and controls which builds of PhotoStructure you are eligible to automatically update to. Please note that \"alpha\" builds may not even launch, and \"beta\" builds have not been thoroughly tested. Please only consider changing this if customer support asks you to, and that you have recent backups of your system.',\n    defaultValue: () => channel(),\n    validValues: [\"alpha\", \"beta\", \"latest\"]\n  }),\n\n  updateOnLaunch: new BooleanSetting({\n    category: SettingCategories.Desktops,\n    description:\n      \"If true, PhotoStructure will check for updates automatically on launch.\",\n    defaultValue: true\n  }),\n\n  updateCheckMinutes: new IntegerSetting({\n    category: SettingCategories.Desktops,\n    description:\n      \"While running, PhotoStructure will check periodically for updates. The default is daily.\",\n    defaultValue: 60 * 24\n  }),\n\n  autoHideMenuBar: new BooleanSetting({\n    category: SettingCategories.Desktops,\n    description:\n      \"If true, PhotoStructure for Desktops on Windows and Linux will auto hide the menu bar unless the Alt key is pressed.\",\n    defaultValue: false\n  }),\n\n  email: new MaybeStringSetting({\n    category: SettingCategories.Reporting,\n    description:\n      \"If set, this email will be used for license subscriptions and added to error reports, so we can contact you to help debug the issue. It is not required. Setting a value here does not subscribe you to any marketing emails.\",\n    exampleValue: () => \"email@example.com\",\n    advanced: () => false\n  }),\n\n  reportErrors: new BooleanSetting({\n    category: SettingCategories.Reporting,\n    description:\n      \"If true, PhotoStructure will send crash reports when it encounters errors. Crash reports may include the path to the file that caused an error, system metadata, and recent log messages.\",\n    defaultValue: true,\n    advanced: () => false\n  }),\n\n  maxErrorsPerDay: new IntegerSetting({\n    category: SettingCategories.Reporting,\n    description:\n      \"Set this to zero to remove all bugs in PhotoStructure.\\nHUR HUR #DADJOKE\\nIf your system generates more than this number of errors in the course of a day, the subsequent error reports will not be reported.\",\n    defaultValue: 3\n  }),\n\n  //\n  // WEB\n  //\n\n  minStreamCorrPct: new BoundedIntegerSetting({\n    category: SettingCategories.Web,\n    description: `Streams (shown on the asset page) are coalesced when the dice coefficient of their contents are greater than this value. A value of 100 requires streams to match exactly. A value of ~50 allows streams with a couple differences to be considered the \"same\" stream.`,\n    defaultValue: () => 50,\n    max: 100,\n    min: 1\n  }),\n\n  hiddenHomeTags: new StringArraySetting({\n    category: SettingCategories.Web,\n    description: `The given root tags will be omitted from the home page. (Valid values include \"When\", \"Camera\", \"Lens\", \"Type\", and \"Keyword\").`,\n    defaultValue: () => [\"Type\"]\n  }),\n\n  placeholderThumbs: new BooleanSetting({\n    category: SettingCategories.Web,\n    description:\n      \"Render missing asset previews as placeholder images (only useful for customer support).\",\n    defaultValue: false,\n    transient: true\n  }),\n\n  cspReportOnly: new BooleanSetting({\n    category: SettingCategories.Web,\n    description:\n      \"Only report CSP violations. See <https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP>.\",\n    defaultValue: () => false\n  }),\n\n  cspDirective: new MaybeStringSetting({\n    category: SettingCategories.Web,\n    description:\n      \"If you're seeing CSP errors with older browsers, add your externally-available base URL to this setting, and it will be appended to the CSP directives. See <https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/script-src>.\",\n    exampleValue: () => \"https://myphotos.example.com\"\n  }),\n\n  // TODO:\n\n  // sessionTimeoutHours: new BoundedIntegerSetting({\n  //   category: SettingCategories.Web,\n  //   description:\n  //     \"How long should unused HTTP sessions exist before requiring visitors to log back in? This defaults to 180 days, just to maximize convenience.\",\n  //   defaultValue: 24 * 30 * 6,\n  //   max: 24 * 365,\n  //   min: 1\n  // }),\n\n  //\n  // Sync\n  //\n\n  readdirCacheSeconds: new IntegerSetting({\n    category: SettingCategories.Sync,\n    description:\n      \"readdir() can take a long time over slow network shares and when directories are very large. This setting controls how long to cache readdir results that are slow (which take >= .5 seconds). Set to 0 to disable readdir() caching.\",\n    defaultValue: 300\n  }),\n\n  verifyFileCopies: new BooleanSetting({\n    category: SettingCategories.Sync,\n    description: `Should PhotoStructure verify all file copies by comparing SHAs of the source and destination? This shouldn't be necessary on most OSes and filesystems, and slows down library imports.`,\n    defaultValue: true\n  }),\n\n  assetSubdirectoryDatestampFormat: new StringSetting({\n    category: SettingCategories.Sync,\n    envAliases: [\"PS_ASSET_SUBDIR_FORMAT\"],\n    description: `If you chose to copy assets into your library, they will be copied into <originals directory>/<result of this pattern>/<original imagename>.\\n- See the originalsDir system setting for what your <originals directory> is (it defaults to your library root directory).\\n- Please encode this path with forward-slashes, even if you're on Windows.\\n- If you want to add a static path, escape the pathname with single quotes (like \"'photos'/y/MM/dd\").\\n- This will always be interpreted as a relative path from your PhotoStructure library.\\n- See <https://moment.github.io/luxon/docs/class/src/datetime.js~DateTime.html#instance-method-toFormat> and <https://moment.github.io/luxon/docs/manual/formatting.html#table-of-tokens>.`,\n    defaultValue: \"y/y-MM-dd\"\n  }),\n\n  transcodeVideos: new BooleanSetting({\n    category: SettingCategories.Sync,\n    description: `Should videos that are not in a browser-supported format be transcoded during import? Note that this is a plus-only feature. FFmpeg or VLC must be installed. Note that this *dramatically* slows down imports, and *dramatically* increases the disk space your library will need to use, but allows you to see videos that aren't directly supported by your browser. If this is set to false, your browser will only render videos directly supported by your OS.`,\n    defaultValue: true\n  }),\n\n  transcodeBitrateQVGA: new IntegerSetting({\n    category: SettingCategories.Sync,\n    description:\n      \"What max bitrate should PhotoStructure encode QVGA (320 \u00D7 240) videos? Videos with resolutions between QVGA and UHD will use an interpolated value between these two settings, and will not exceed the encoded bitrate of the original video. This value is in kilobytes per second.\",\n    defaultValue: 800\n  }),\n\n  transcodeBitrateUHD: new IntegerSetting({\n    category: SettingCategories.Sync,\n    description:\n      \"What max bitrate should PhotoStructure encode UHD (3840\u2009\u00D7\u20092160) videos? Videos with resolutions between QVGA and UHD will use an interpolated value between these two settings, and will not exceed the encoded bitrate of the original video. This value is in kilobytes per second.\",\n    defaultValue: 18_000\n  }),\n\n  doNotTranscodeMimetypes: new StringArraySetting({\n    category: SettingCategories.Sync,\n    description: `Videos are transcoded when the \"transcodeVideos\" is set to true and is not one of the following mimetypes. See https://www.iana.org/assignments/media-types/media-types.xhtml#video for a complete list. If you are setting this via an environment variable, you can separate the values either like a PATH (like \"video/quicktime:video/mp4\") or use JSON encoding (like \"['video/quicktime','video/mp4']\").`,\n    defaultValue: () => [\n      \"video/quicktime\",\n      \"video/mp4\",\n      \"video/mpv\",\n      \"video/mp2t\"\n    ]\n  }),\n\n  doNotTranscodeVideoCodecs: new StringArraySetting({\n    category: SettingCategories.Sync,\n    description: `Videos are transcoded when the \"transcodeVideos\" is set to true and is not one of the following video codecs. The video codec may be stored in the \"VideoCodec\", \"CompressorID\", or \"CompressorName\" tags.`,\n    defaultValue: () => [\"avc1\"] // CompressorID: \"hvc1\" is HEVC.\n  }),\n\n  doNotTranscodeAudioCodecs: new StringArraySetting({\n    category: SettingCategories.Sync,\n    description: `Videos are transcoded when the \"transcodeVideos\" is set to true and is not one of the following audio codecs. The audio codec is stored in the \"AudioCodec\" tag.`,\n    defaultValue: () => [\"mp4a\", \"sowt\"]\n  }),\n\n  statTimeoutSeconds: new BoundedIntegerSetting({\n    category: SettingCategories.Sync,\n    description: `Filesystem traversal can be dangerous business with scratched CDROMs and old busted hard drives. To prevent PhotoStructure from getting \"stuck\" when trying to read these devices, it will timeout directory iteration if reading a directory entry exceeds this value. The default of 30 seconds should cover most issues with spun-down hard drives and NAS/WAN latency.`,\n    defaultValue: 30,\n    min: 1,\n    max: 300\n  }),\n\n  startPaused: new BooleanSetting({\n    category: SettingCategories.Sync,\n    description:\n      \"Should processing be paused by default when PhotoStructure starts? You'll have the manually resume processing via the system tray or nav menu.\",\n    defaultValue: false\n  }),\n\n  syncIntervalHours: new IntegerSetting({\n    category: SettingCategories.Sync,\n    description:\n      \"This value controls both how often the sync process discovers new or changed files for any given volume.\\nNote that this value is the duration between the last completion time and when the next sync should be scheduled.\\nWARNING: Setting this value to a small value will mean PhotoStructure is constantly scanning your disks, which will add wear and tear and possibly reduce the lifespan of your storage media.\\nNote that setting this to a zero or negative value will disable automatic scheduling of the sync process.\",\n    defaultValue: 24\n  }),\n\n  rebuild: new BooleanSetting({\n    category: SettingCategories.Sync,\n    description:\n      \"When set, all files in your library will be re-imported (caution: slow!).\",\n    defaultValue: false,\n    transient: true\n  }),\n\n  forceSync: new BooleanSetting({\n    category: SettingCategories.Sync,\n    description:\n      \"When set, all files will be visited, even if the asset seems in sync with the filesystem.\",\n    defaultValue: false,\n    transient: true\n  }),\n\n  skipModelUpdates: new BooleanSetting({\n    category: SettingCategories.Sync,\n    description: \"When set, skip any pending library database updates.\",\n    defaultValue: false,\n    transient: true\n  }),\n\n  exitWhenDone: new BooleanSetting({\n    category: SettingCategories.Sync,\n    description:\n      \"When set, the sync process will exit after jobs are completed (used internally and for tests).\",\n    defaultValue: false,\n    transient: true\n  }),\n\n  matchSidecarsCaseInsensitively: new BooleanSetting({\n    category: SettingCategories.Sidecars,\n    description: `If set to true, PhotoStructure will look for sidecar files that match file basenames (with or without the file extension), regardless of case (for example: \"IMAGE.XMP\" will be a sidecar for \"image.jpg\").\\nIf set to false, sidecars must match case (so only \"image.jpg.xmp\" and \"image.xmp\" will match for \"image.jpg\").\\nThis defaults to false just to be conservative, but true should be fine in normal cases.`,\n    defaultValue: false\n  }),\n\n  defaultSidecarType: new StringEnumSetting({\n    category: SettingCategories.Sidecars,\n    description:\n      \"What type of sidecar file do you want to generate for non-destructive edits?\",\n    defaultValue: \"XMP\",\n    validValues: SidecarExts\n  }),\n\n  writeMetadataToSidecarsIfImage: new BooleanSetting({\n    category: SettingCategories.Sidecars,\n    description: `If set to true, PhotoStructure will write metadata changes made to images into sidecars. If set to false, PhotoStructure will overwrite original images with metadata changes.`,\n    defaultValue: true\n  }),\n\n  writeMetadataToSidecarsIfVideo: new BooleanSetting({\n    category: SettingCategories.Sidecars,\n    description: `If set to true, PhotoStructure will write metadata changes made to videos into sidecars. If set to false, PhotoStructure will overwrite original videos with metadata changes. This defaults to false, as most software does not use sidecars except for images.`,\n    defaultValue: false\n  }),\n\n  overwriteOriginal: new BooleanSetting({\n    category: SettingCategories.Sync,\n    description: `Should changes made through the UI, like rotations, captions, and keywords, overwrite the original file? This is potentially dangerous, as your original may be lost if the disk has errors, or there are issues in rewriting the file contents. If this is set to false, the original file will be retained in the same directory. \"image.jpg\" will be stored as \"image_original.jpg\".`,\n    defaultValue: false\n  }),\n\n  fuzzyDateParsing: new BooleanSetting({\n    category: SettingCategories.Sync,\n    description: `When enabled, PhotoStructure will first attempt to parse datetime strings with strict ISO-compliant parsers, and then use additional, \"fuzzy\" parsers. When disabled, only ISO-compliant parsers are used.`,\n    defaultValue: true\n  }),\n\n  fuzzyYearParsing: new BooleanSetting({\n    category: SettingCategories.Sync,\n    description: `When enabled, PhotoStructure will use directories starting with a number that looks year-like (four digits, 1826-the present) to infer the captured-at time, if all other date parsers have failed. Note that setting this to true \"forces\" the \"fuzzyDateParsing\" setting to be true.\\nTo elaborate: PhotoStructure first looks for metadata with a date, then looks for an ISO-compliant YMD timestamp in the filename or path, and then, if \"fuzzyDateParsing\" or this setting is enabled, a YMD or YM datestamp, and then finally, if this setting is enabled, it looks for a directory that begins with a number that is between 1826-2020.`,\n    defaultValue: false\n  }),\n\n  minValidYear: new IntegerSetting({\n    category: SettingCategories.Sync,\n    description: `If PhotoStructure encounters a year that is less than this value, it will consider it invalid and look elsewhere for dates. The default value, 1826, is the first year a photograph was captured, as per <https://en.wikipedia.org/wiki/History_of_photography>. If you have paintings or other imagery from before this time, you'll want to make this value less than the earliest image in your library.`,\n    defaultValue: 1826\n  }),\n\n  useStatToInferDates: new BooleanSetting({\n    category: SettingCategories.Sync,\n    description: `When enabled, and the \"captured-at\" time isn't found in metadata, PhotoStructure will also look for the captured-at datetime encoded in the file \"birthtime\" (on Windows), or the lesser value of \"mtime\" and \"ctime\" (on macOS and Linux). Note that these values are not very reliable, as file transfers and backups frequently don't retain these values correctly.`,\n    defaultValue: true\n  }),\n\n  usePathsToInferDates: new BooleanSetting({\n    category: SettingCategories.Sync,\n    description: `When enabled, and the \"captured-at\" time isn't found in metadata, PhotoStructure will also look for the captured-at datetime encoded in file paths.`,\n    defaultValue: true\n  }),\n\n  useLibraryPathsToInferDates: new BooleanSetting({\n    category: SettingCategories.Sync,\n    description: `When enabled, and the \"captured-at\" time isn't found in metadata, PhotoStructure will also look for the captured-at datetime encoded in file paths *for files that are in your PhotoStructure library. This defaults to false, as prior versions of PhotoStructure may have placed files into incorrect datestamped directories.`,\n    defaultValue: false\n  }),\n\n  maxDuplicatePathElements: new IntegerSetting({\n    category: SettingCategories.Sync,\n    description:\n      \"How many times can a given path element exist in a directory before it is considered within an infinite filesystem loop, and should be skipped from import?\",\n    defaultValue: 7\n  }),\n\n  skipAssetFileUpdates: new BooleanSetting({\n    category: SettingCategories.Sync,\n    description: `Should outdated AssetFiles be ignored on startup? (Only used for tests).`,\n    defaultValue: false,\n    transient: true\n  }),\n\n  skipAssetUpdates: new BooleanSetting({\n    category: SettingCategories.Sync,\n    description: `Should outdated Assets be ignored on startup? (Only used for tests).`,\n    defaultValue: false,\n    transient: true\n  }),\n\n  resyncAssetOnVisit: new BooleanSetting({\n    category: SettingCategories.Sync,\n    description: `Should Assets be automatically re-synchronized whenever their info panel is viewed? This can make sure Assets are in-sync with the filesystem, but this can slow down current imports, and add load to slower computers. This defaults to true only if the current machine has >= 8 CPUs.`,\n    defaultValue: () => (isTest() ? true : cpus().length >= 8)\n  }),\n\n  excludeNoMediaAssetsOnRebuild: new BooleanSetting({\n    category: SettingCategories.Sync,\n    description: `Should previously-imported assets that are found to have *any* files in NoMedia directories be excluded from your library?`,\n    defaultValue: () => true\n  }),\n\n  // TODO: noMediaAssetAction (hide in library, exclude from library, trash from filesystem)\n\n  //\n  // Deduping\n  //\n\n  strictDeduping: new BooleanSetting({\n    category: SettingCategories.Deduping,\n    description: `How strict should PhotoStructure de-duplicate files? If this is false, we consider files to be equivalent if sufficient metadata matches (even if the image hash is different). If this is true, we will always compare image hashes. NOTE: This will most likely cause RAW and JPEG pairs to not always merge to the same asset, especially if your camera uses extensive computational imagery. ALSO NOTE: If this is true, \"useImageHashes\" will be forced to true.`,\n    defaultValue: false\n  }),\n\n  useImageHashes: new BooleanSetting({\n    category: SettingCategories.Deduping,\n    description: `Building image hashes slows down imports, but supports more robust asset merging heuristics, and allows for dominant color tagging and browsing. If you set this from false to true, and you'd previously imported new assets, you may want to rebuild your library to re-aggregate your assets.`,\n    defaultValue: true\n  }),\n\n  includeSharpDominantColor: new BooleanSetting({\n    category: SettingCategories.Deduping,\n    description: `PhotoStructure's image library, sharp, computes the dominant color using a 4096-bin 3D histogram. This doubles image hashing time, but the most-dominant color might be more accurate.`,\n    defaultValue: false\n  }),\n\n  minExposureSettingsCoeffPct: new BoundedIntegerSetting({\n    category: SettingCategories.Deduping,\n    description:\n      \"This is the minimum similarity coefficient between exposure setting values two images must be to be considered equivalent. Many cameras actually report different exposure setting values between JPG and RAW: values within 90% of each other should avoid false-positives.\",\n    defaultValue: () => 90,\n    max: 100,\n    min: 0\n  }),\n\n  minImageCoeffPct: new BoundedIntegerSetting({\n    category: SettingCategories.Deduping,\n    description:\n      \"This is the minimum image hash similarity coefficient for images to be considered similar, and controls how aggressively images are merged with each other. A higher number requires stronger image similarity. 100 (or 100%) requires exact image correlation, and is not recommended. A value of less than 50% is fairly low image correlation, and can lead to false positives.\",\n    defaultValue: () => 75,\n    max: 100,\n    min: 0\n  }),\n\n  minImageGreyscaleCoeffPct: new BoundedIntegerSetting({\n    category: SettingCategories.Deduping,\n    description:\n      \"This is the minimum image hash similarity coefficient for greyscale images to be considered similar, and controls how aggressively images are merged with each other. A higher number requires stronger image correlation. 100 (or 100%) requires exact image correlation, and is not recommended. A value of less than 50% is fairly low image correlation, and can lead to false positives.\",\n    defaultValue: () => 93,\n    max: 100,\n    min: 0\n  }),\n\n  minColorCoeffPct: new BoundedIntegerSetting({\n    category: SettingCategories.Deduping,\n    description:\n      \"This is the minimum similarity coefficient found between dominant image colors, and controls how aggressively images are merged with each other. A higher number requires stronger dominant color correlation. 100 (or 100%) requires exact dominant color correlation. A value of less than 50% indicates fairly low correlation of dominant colors, and can lead to false positives.\",\n    defaultValue: () => 75,\n    max: 100,\n    min: 0\n  }),\n\n  minMeanCoeffPct: new BoundedIntegerSetting({\n    category: SettingCategories.Deduping,\n    description:\n      \"If the average of image and color similarity coefficients exceeds this score, the image will be considered a match.\",\n    defaultValue: () => 65, // Raw/IMG_20181029_140706.dng needs 65\n    max: 100,\n    min: 0\n  }),\n\n  fuzzyDateImageCoeffWeight: new BoundedFloatSetting({\n    category: SettingCategories.Deduping,\n    description: `Image similar, by default, is somewhat lax to ensure JPG+RAW and downsampled or edited images are matched together. This is OK when dates must match, and the date is exactly correct. When dates are manually set to something \"fuzzy\", with perhaps only the year, month, and day, or is inferred by siblings, we need to be more discriminate with image contents to prevent incorrectly grouping photos from that day into a single asset. This value is multiplied with minImageCorrPct and minColorCorrPct to make them more stringent. For example, by default, the minImageCorrPct is 80%, and when the dates are manually set, and this weight is 1.2, the minImageCorrPct for manually-set-date files will be 90%.`,\n    defaultValue: () => 1.4,\n    max: 2,\n    min: 0.5\n  }),\n\n  greyscaleColorThreshold: new BoundedIntegerSetting({\n    category: SettingCategories.Deduping,\n    description:\n      \"When looking at each pixel in L*a*b* space, a greyscale image is expected to have a* and b* values around 0. If the absolute value of every a* and b* value is under this setting's value, the image will be considered to be greyscale. A value of 0 will force all images to be considered non-greyscale.\",\n    defaultValue: 5,\n    max: 128,\n    min: 0\n  }),\n\n  modeCorrCieDiffWeight: new BoundedFloatSetting({\n    category: SettingCategories.Deduping,\n    description: `Comparing 2 images with N dominant colors requires finding matching color pairs. This weight will be applied to the CIE94 color delta e. Smaller values apply a larger discount to color deltas.`,\n    defaultValue: () => 0.6,\n    max: 2,\n    min: 0\n  }),\n\n  modeCorrIndexDiffWeight: new BoundedFloatSetting({\n    category: SettingCategories.Deduping,\n    description: `Comparing 2 images with N dominant colors requires finding matching color pairs. This weight will be applied to difference between the color indexes. Smaller values apply a larger discount to index differences.`,\n    defaultValue: () => 0.6,\n    max: 2,\n    min: 0\n  }),\n\n  gpsErrorMeters: new IntegerSetting({\n    category: SettingCategories.Deduping,\n    description: `What's the maximum number of meters between GPS fixpoints that should be considered equivalent locations? Note that JPG+RAW pairs from smartphones frequently have different GPS locations due to one being recorded from a rough WiFi fix, and another from aGPS.\\nGPS position error is ~10-100m. Cellular position error is ~500-750m.`,\n    defaultValue: 500\n  }),\n\n  lensMakes: new StringArraySetting({\n    category: SettingCategories.Deduping,\n    description: `Used to match lensId when Google Takeout has stripped metadata.`,\n    defaultValue: () => DefaultLensMakes\n  }),\n\n  variantSortCriteria: new StringArraySetting({\n    category: SettingCategories.Previews,\n    description: `How should PhotoStructure pick the \"best\" asset file variant for a given asset? You may reorder the default fields. Only \"resolution\", \"fileSize\", \"mtime\", \"schemeIdx\", \"isCover\", \"count\", and \"isBrowserSupported\" are understood: other field names will be ignored. Details about these fields are here: <https://photostructure.com/faq/what-do-you-mean-by-dedupe/#how-does-photostructure-pick-which-file-to-show>.`,\n    defaultValue: [\n      \"resolution\",\n      \"mtime\",\n      \"schemeIdx\",\n      \"isCover\",\n      \"count\",\n      \"isBrowserSupported\",\n      \"fileSize\"\n    ]\n  }),\n\n  variantSortCriteriaPower: new BoundedFloatSetting({\n    category: SettingCategories.Deduping,\n    description: `Larger variant sort criteria, \"resolution\" and \"fileSize\", are scaled to ignore smaller (irrelevant) differences. Scalars are raised to this power to reduce them, so a value of 1 means the criterion is unchanged from the \"raw\" value.`,\n    defaultValue: () => 0.15,\n    max: 1,\n    min: 1e-6\n  }),\n\n  //\n  // Previews\n  //\n\n  jpegQuality: new BoundedIntegerSetting({\n    category: SettingCategories.Previews,\n    description:\n      \"JPEG output quality for previews. Smaller values produce smaller images with lower quality. The default value of 85 strikes a balance that has almost no noticeable compression artifacts, yet still compresses images reasonably well. Values less than ~50-70 can produce noticeable artifacts (depending on the image).\",\n    defaultValue: () => 85,\n    max: 100,\n    min: 10\n  }),\n\n  dcrawEmuArgs: new StringArraySetting({\n    category: SettingCategories.Previews,\n    description: `What options do you want to pass to dcraw_emu? Note that \"-T -o 1 -j -Z -\" will always be added (as we need TIFF, sRGB, raw pixels send to stdout). The \"-h\" arg will be added if the preview image needed is less than half the resolution of the original.\\nRun \"dcraw_emu\" with no arguments to get usage help.\\n\"-q 1\" sets interpolation quality to \"0\".\\n\"-H 2\" turns on highlight blending.\\n\"-w\" uses the camera-set white balance.\\nNote: changing these values can dramatically (> 10x!) increase the time it takes to render RAW images.`,\n    defaultValue: [\"-q\", \"0\", \"-w\"]\n  }),\n\n  iccProfileMappings: new StringArraySetting({\n    category: SettingCategories.Previews,\n    description: `Maps an original image profile to a filename stored in the \"icc\" directory. See that directory's _info.md for more information about this settings.`,\n    defaultValue: [\n      \"Display P3:DisplayP3Compat-v2-magic.icc\",\n      \"Adobe RGB:AdobeCompat-v2.icc\"\n    ]\n  }),\n\n  squareThumbStrategy: new StringEnumSetting({\n    category: SettingCategories.Previews,\n    description:\n      'When PhotoStructure crops images and videos to square thumbnails, it needs to crop non-square images to a square. The default, \"attention,\" focuses on faces and higher image energy, but is more expensive than simply cropping to the center of the image (which is faster, but will mean less-nice cropping, where faces are chopped in half). More details are available here: <https://sharp.pixelplumbing.com/api-resize>.',\n    defaultValue: \"attention\",\n    validValues: [\"center\", \"entropy\", \"attention\"]\n  }),\n\n  videoFrameAtSec: new FloatSetting({\n    category: SettingCategories.Previews,\n    description: `When capturing a frame from videos for thumbnails, how many seconds should be passed over before capturing a frame? A value of 0 means capture from the start of the video. Frequently, though, videos start out of focus, so we default to 1 for better frame clarity.\\nNote that if a video is shorter than this value, the frame will be captured from the middle of the video.`,\n    defaultValue: 1.5\n  }),\n\n  // TODO: add this to the settings page:\n  sharpen: new BooleanSetting({\n    category: SettingCategories.Previews,\n    description: `Should previews be sharpened? This can make the images \"pop\" a bit more, but almost doubles the time it takes to make the thumbnails.`,\n    defaultValue: false\n  }),\n\n  progressive: new BooleanSetting({\n    category: SettingCategories.Previews,\n    description: `Should preview JPEGs be progressively encoded? If set, thumbnails will take ~15% longer to generate, but FHD/QHD/UHD previews will be smaller.`,\n    defaultValue: true\n  }),\n\n  // TODO: add this to the settings page:\n  previewResolutions: new StringEnumsSetting({\n    category: SettingCategories.Previews,\n    description:\n      \"This controls the resolutions that PhotoStructure creates for every asset. Note that resolutions will be skipped if there already is a preview value with 2.5x the megapixels, so even though there are a lot of sizes here, you'll only see 3-4 images on your disk per asset.\",\n    defaultValue: diff(FitSizeValues, [\"uhd8k\", \"uhd5k\", \"qqvga\"]),\n    validValues: FitSizeValues\n  }),\n\n  embeddedPreviews: new StringArraySetting({\n    category: SettingCategories.Previews,\n    description: `For larger source images that are greater than 15MP, what embedded image preview tags should be used when present? Using these embedded images speeds up image preview generation, but if the embedded image doesn't match the full-sized image, the image preview will be incorrect.\\nOrder matters here: the first embedded image with sufficient resolution will be used.\\nSet this to an empty array to disable using embedded previews.`,\n    defaultValue: [\"PreviewImage\", \"PreviewTIFF\", \"JpgFromRaw\"]\n  }),\n\n  embeddedThumbnails: new StringArraySetting({\n    category: SettingCategories.Previews,\n    description: `Should embedded image thumbnails be used when available? This speeds up image hashing, but if the embedded image thumbnail doesn't match the full-sized image, the image hash will be incorrect.\\nOrder matters here: the first embedded image with sufficient resolution will be used.\\nSet this to an empty array to disable using embedded previews.`,\n    defaultValue: [\"ThumbnailImage\", \"ThumbnailTIFF\"]\n  }),\n\n  skipPreviews: new BooleanSetting({\n    category: SettingCategories.Previews,\n    description: `No previews will be built. The UI will be broken if this is set.`,\n    defaultValue: false\n  }),\n\n  //\n  // Filters\n  //\n\n  requireMakeModel: new BooleanSetting({\n    category: SettingCategories.Filters,\n    description:\n      \"Normally PhotoStructure requires images to have EXIF tags for Make and Model. This prevents unwanted preview images from other photo apps and screenshots from being imported. If you have images you want in your library that don't have these tags, set this to false. Note that this is ignored for video files, as those files seldom have Make and Model set (and would prevent most video files from being imported).\",\n    defaultValue: false\n  }),\n\n  minImageDimension: new IntegerSetting({\n    category: SettingCategories.Filters,\n    description:\n      \"What's the minimum number of pixels an image's dimensions must meet or exceed to be imported? Note that this value is applied to both the height and width of the image. The default comes from the VGA standard of 640x480.\",\n    defaultValue: 480\n  }),\n\n  minVideoDimension: new IntegerSetting({\n    category: SettingCategories.Filters,\n    description:\n      \"What's the minimum number of pixels a video's dimensions must meet or exceed to be imported? Note that this value is applied to both the height and width of the video. The default comes from the QVGA standard of 320x240.\",\n    defaultValue: 240\n  }),\n\n  minVideoDurationSec: new FloatSetting({\n    category: SettingCategories.Filters,\n    description:\n      \"What's the minimum number of seconds for a video to be imported?\",\n    defaultValue: 2\n  }),\n\n  minAssetFileSizeBytes: new IntegerSetting({\n    envAliases: [\n      \"PS_MIN_ASSET_SIZE_BYTES\",\n      \"PS_MIN_ASSET_SIZE\",\n      \"PS_MIN_FILE_SIZE_BYTES\"\n    ],\n    category: SettingCategories.Filters,\n    description:\n      \"What's the minimum photo or video size you want imported into your library? (This can prevent small GIFs and screenshots from being imported).\",\n    defaultValue: 50 * KB\n  }),\n\n  maxAssetFileSizeBytes: new IntegerSetting({\n    envAliases: [\n      \"PS_MAX_ASSET_SIZE_BYTES\",\n      \"PS_MAX_ASSET_SIZE\",\n      \"PS_MAX_FILE_SIZE_BYTES\"\n    ],\n    category: SettingCategories.Filters,\n    description:\n      \"What's the maximum photo or video size you want imported into your library? (This can prevent movies from being pulled into and filling up your library).\",\n    defaultValue: 0.5 * GB\n  }),\n\n  // TODO: add this to the settings page:\n  validateJpegImages: new BooleanSetting({\n    category: SettingCategories.Filters,\n    description: `Should JPEG photos be validated before importing? If a JPEG has any decoding errors, and this setting is true, that file will not be imported into your library. Enabling this feature slows down imports.`,\n    defaultValue: true\n    // advanced: () => false\n  }),\n\n  // TODO: add this to the settings page:\n  validateRawImages: new BooleanSetting({\n    category: SettingCategories.Filters,\n    description: `Should raw-format images (like NEF, CR2, ARW, and ORF) be validated before importing? If an image has any decoding errors, and this setting is true, that file will not be imported into your library. Enabling this feature slows down imports.`,\n    defaultValue: true\n    // advanced: () => false\n  }),\n\n  // TODO: add this to the settings page:\n  validateVideos: new BooleanSetting({\n    category: SettingCategories.Filters,\n    description: `Should videos be validated before importing? If a video has any decoding errors, and this setting is true, that file will not be imported into your library. Enabling this feature slows down imports, as videos must be fully decoded (or \"played\") to be validated. Only ffmpeg currently supports video validation; if you use VLC, this setting is ignored.`,\n    defaultValue: () => (isTest() ? true : false) // < tests want to validate this setting\n    // advanced: () => false\n  }),\n\n  validationErrorBlocklist: new StringArraySetting({\n    category: SettingCategories.Filters,\n    description: `If any of the following patterns match a validation error found in a photo or video, the file will be considered corrupt and not be imported into your library.\\nNote the patterns are case-insensitive, will be converted into a regular expression, and only need to partially match the error message, so, for example, a value of \"caution\" will ignore any error message that contains the string \"caution\".`,\n    defaultValue: () => [\n      \"Cannot determine format of input stream\",\n      \"corrupt\",\n      \"error\",\n      \"failed\",\n      \"invalid\",\n      \"not a .+ file\", // Not a JPEG file\n      \"nothing was written into output file\",\n      \"partial file\",\n      \"Premature end of .+ file\" // Premature end of JPEG file\n    ]\n  }),\n\n  //\n  // Tagging\n  //\n\n  tagCamera: new BooleanSetting({\n    category: SettingCategories.Tagging,\n    description: `Should assets be tagged with cameras' make and model?`,\n    defaultValue: true\n  }),\n\n  tagLens: new BooleanSetting({\n    category: SettingCategories.Tagging,\n    description: `Should assets be tagged with lens' make and model?`,\n    defaultValue: true\n  }),\n\n  tagFullLensModel: new BooleanSetting({\n    category: SettingCategories.Tagging,\n    description: `Should PhotoStructure tag assets with the full lens model (like \"Canon EF-M 15-45mm f/3.5-6.3 IS STM\") or a just the lens information (\"15-45mm f/3.5-6.3\")? (If you change this value, you'll need to \"Rebuild\" your library to make the setting take effect).`,\n    defaultValue: true\n  }),\n\n  tagYMD: new StringEnumSetting({\n    category: SettingCategories.Tagging,\n    description: `Should assets be tagged with \"When > Year\" (the \"y\" option), or \"When > Year > Month\" (the \"ym\" option), or \"When > Year > Month > Day\" (the \"ymd\" option)? Setting this to \"\" will disable date tagging.`,\n    defaultValue: \"ym\",\n    validValues: [\"y\", \"ym\", \"ymd\", \"\"]\n  }),\n\n  tagDateFromStat: new BooleanSetting({\n    category: SettingCategories.Tagging,\n    description: `Should PhotoStructure tag assets with a date if the captured at time was only found in filesystem metadata? Filesystem metadata is not as reliable as EXIF metadata, as it can be changed arbitrarily when files are backed up.`,\n    defaultValue: () => (isTest() ? false : true)\n  }),\n\n  tagKeywordsFromPath: new BooleanSetting({\n    category: SettingCategories.Tagging,\n    description: `Should assets be tagged with keywords extracted from file pathnames?`,\n    defaultValue: true\n  }),\n\n  tagKeywordsFromMetadata: new BooleanSetting({\n    category: SettingCategories.Tagging,\n    description: `Should assets be tagged with keywords extracted from file metadata, as well as sidecar metadata?`,\n    defaultValue: true\n  }),\n\n  keywordDelimiters: new StringSetting({\n    category: SettingCategories.Tagging,\n    description: `PhotoStructure splits apart keywords, by default, when they are delimited by a comma or semicolon. For example, \"car, blue, tree\" will be interpreted as having the keywords \"car\", \"blue\", and \"tree\". After changing this value, you must force-resync your library for the changes to take affect.`,\n    defaultValue: \",;\"\n  }),\n\n  keywordPathSeparators: new StringSetting({\n    category: SettingCategories.Tagging,\n    description: `PhotoStructure interprets keywords as hierarchical if a path separator character is found in a keyword. This allows for tags like \"Family/Einstein/Albert\", \"Flora|Fruit|Orange\", \"Objects\u2283Tools\u2283Hammer\", or \"Fauna>Oceanic>Pelican\". By default, these separators are the forward-slash, vertical-bar, and greater-than characters. If you don't want to interpret keywords as hierarchical, change this value to an empty string (\"\"). After changing this value, you must force-resync your entire library for the changes to take affect.`,\n    defaultValue: \"/|>\u2283\" // 20200307: thought about and discarded the idea of including \"\u203A\" and \"\u00BB\". \"\u2E27\" isn't in iOS. 20201201: Also deleted \"\u227B\".\n  }),\n\n  tagFileType: new BooleanSetting({\n    category: SettingCategories.Tagging,\n    envAliases: [\"PS_TAG_TYPE\"],\n    description: `Should assets be tagged with their file type (like \"Type/Image/JPEG\")?`,\n    defaultValue: true\n  }),\n\n  tagWhoSynonyms: new StringArraySetting({\n    category: SettingCategories.Tagging,\n    description: `List hierarchical tags that PhotoStructure should interpret to be face names. Digicam uses \"People\". This is matched case-insensitively.`,\n    defaultValue: () => [\"People\", \"Face\", \"Faces\"]\n  }),\n\n  tagJsonFaces: new BooleanSetting({\n    category: SettingCategories.Tagging,\n    description: `Google Takeout provides .json sidecars that may contain the names of the people (or pets) found in the image. Should PhotoStructure import these tags under \"Who\"?.`,\n    defaultValue: true\n  }),\n\n  tagFaceRegions: new BooleanSetting({\n    category: SettingCategories.Tagging,\n    description: `Picasa and other software supports embedding face names within \"RegionInfo\" metadata. If this setting is enabled, PhotoStructure will import these tags under \"Who\".`,\n    defaultValue: true\n  }),\n\n  tagWhoNames: new StringArraySetting({\n    category: SettingCategories.Tagging,\n    description: `This is a list of tags that will be examined for strings or string arrays. All values associated to these fields will be interpreted as names. Note that \"dotted notation\" is supported.\\nSet this value to an empty array to disable scanning for person names.`,\n    defaultValue: [\n      \"People\",\n      \"PersonInImage\",\n      \"PersonInImageWDetails.PersonName\",\n      \"PersonInImageName\"\n    ]\n  }),\n\n  tagNamesFormatter: new StringEnumSetting({\n    category: SettingCategories.Tagging,\n    description: `How should PhotoStructure format the \"Who\" tags for assets whose files are tagged with \"people\" strings?\\n\"as-is\" will tag names directly to \"Who\", so, \"Who/Albert Einstein\".\\n\"family/given\" will tag \"Who/Einstein/Albert\" (for regions that provide given names first). The default is \"as-is,\" because discerning given and family names aren't reliably inferable.\\nSee <https://en.wikipedia.org/wiki/Personal_name#Name_order>.`,\n    defaultValue: \"as-is\",\n    validValues: [\"as-is\", \"family/given\"]\n  }),\n\n  tagNamesDefaultFamily: new StringSetting({\n    category: SettingCategories.Tagging,\n    description: `If a name is missing a family name, if this value is not blank, it will be provided as a default. If this value is blank, the name tag will be Who/given. Note that this setting is only used if \"tagNamesFormatter\" is set to \"family/given\".`,\n    defaultValue: \"-\"\n  }),\n\n  tagNamesCapitalizedAsFamily: new BooleanSetting({\n    category: SettingCategories.Tagging,\n    description: `Assume uppercased names are family names (this is common practice in geneology).`,\n    defaultValue: true\n  }),\n\n  tagNamesOrder: new StringEnumSetting({\n    category: SettingCategories.Tagging,\n    description: `How should PhotoStructure parse people's names? Note that this setting is only used if \"tagNamesFormatter\" is set to \"family/given\". See <https://en.wikipedia.org/wiki/Personal_name#Name_order>.`,\n    defaultValue: \"western\",\n    validValues: [\"western\", \"eastern\"]\n  }),\n\n  tagNamesSurnamePrefixes: new StringArraySetting({\n    category: SettingCategories.Tagging,\n    description: `List all family name prefixes to be considered part of the family name. These are matched case-insensitively. This setting is used by the \"tagNamesFormatter\" if it is set to \"family/given\".`,\n    defaultValue: () => [\n      \"A\",\n      \"D\u2019\",\n      \"Da\",\n      \"De la\",\n      \"De las\",\n      \"De\",\n      \"Del\",\n      \"Della\",\n      \"Den\",\n      \"Des\",\n      \"Di\",\n      \"Du\",\n      \"La\",\n      \"Las\",\n      \"Le\",\n      \"Li\",\n      \"Lo\",\n      \"Mc\",\n      \"Mac\",\n      \"op de\",\n      \"ten\",\n      \"ter\",\n      \"Van \u2018t\",\n      \"van der\",\n      \"van\",\n      \"von der\",\n      \"von\",\n      \"z\",\n      \"zu\"\n    ]\n  }),\n\n  tagNamesSurnames: new StringArraySetting({\n    category: SettingCategories.Tagging,\n    description: `List all family names you expect in tags that are not single words that are found at the end of a tagged name. Hyphenated family names (like \"Ocasio-Cortez\") do not need to be listed here: only compound family names, and if your language doesn't separate family names with whitespace. In the latter case, either include all family names, or include all givenNames (whatever's easier for you). This setting is used by the \"tagNamesFormatter\" if it is set to \"family/given\".`,\n    defaultValue: () => []\n  }),\n\n  tagNamesGiven: new StringArraySetting({\n    category: SettingCategories.Tagging,\n    description: `List all given names you expect in tags that are not single words. Hyphenated given names (like \"Rose-Ann\") do not need to be listed here. If your language doesn't separate family names and given names with whitespace, either include all given names, or include all familyNames (whatever's easier for you). This setting is used by the \"tagNamesFormatter\" if it is set to \"family/given\".`,\n    defaultValue: () => []\n  }),\n\n  tagNamesFamilySurrounds: new StringArraySetting({\n    category: SettingCategories.Tagging,\n    description: `This setting contains pairs of characters. When name portions are surrounded by these pairs, the contents will be added as a family name. As an example, if you use the default \"()\", then \"Michelle LaVaughn (Robinson) Obama\" will be name tagged with both \"Who/Robinson/Michelle LaVaughn\" and \"Who/Obama/Michell LaVaugn\". This setting is used by the \"tagNamesFormatter\" if it is set to \"family/given\".`,\n    defaultValue: [\"()\"]\n  }),\n\n  tagNamesGivenSurrounds: new StringArraySetting({\n    category: SettingCategories.Tagging,\n    description: `This setting contains pairs of characters. When name portions are surrounded by these pairs, the contents will be added to the end of the given name with the surrounds retained. As an example, if you use the defaults of \"[]\" and double-quotes, then \"Joe \"Joey\" Smith\" will be name tagged with Who/Smith/Joe \"Joey\". This setting is used by the \"tagNamesFormatter\" if it is set to \"family/given\".`,\n    defaultValue: [\"[]\", '\"\"']\n  }),\n\n  tagNamesLexical: new BooleanSetting({\n    category: SettingCategories.Tagging,\n    description: `Assume any name with a comma is in \"lexical name order\", which is always \"lastname, given name(s)\". If the given name is found to be \"sr.\", \"senior\", \"jr.\", or \"junior\", the name will be considered to be in western order ($givenNames $familyName, $modifier), and the $modifier will be added to the $givenNames. If this is set to false, commas are ignored.`,\n    defaultValue: true\n  }),\n\n  excludedRootTags: new StringArraySetting({\n    category: SettingCategories.Tagging,\n    description: `Keywords starting with the given roots will be omitted from your PhotoStructure library.`,\n    defaultValue: () => [\"http:\", \"https:\"]\n  }),\n\n  tagDisplayNameFS: new StringSetting({\n    category: SettingCategories.Tagging,\n    description: `What should PhotoStructure call the \"root\" tag for browsing by filesystem paths? Note that this value is only for the UI, and will update the \"_displayName\" of the /fs/ tag: this value won't change the URL path from be \"/tag/fs/.../\". Reasonable options that have been suggested include \"Folder\", \"Directory\", \"Drive\", \"File\", \"Path\", \"Volume\", or \"Computer\".`,\n    defaultValue: \"Folder\"\n  }),\n\n  tagAlbums: new BooleanSetting({\n    category: SettingCategories.Tagging,\n    description: `Should PhotoStructure look for $tagJsonAlbumFilename (by default, \"metadata.json\") files in the same directory as asset files for album titles?`,\n    defaultValue: true\n  }),\n\n  tagAlbumFilenames: new StringArraySetting({\n    category: SettingCategories.Tagging,\n    description: `If you have enabled \"tagJsonAlbums\", what's the name of the file that PhotoStructure should look for with album metadata? This can be JSON, XMP, MIE, or EXIF encoded.`,\n    defaultValue: [\"metadata.json\"]\n  }),\n\n  tagAlbumTitle: new StringSetting({\n    category: SettingCategories.Tagging,\n    description: `If you have enabled \"tagJsonAlbums\", what's the name of the field encoded in the album file? Object hierarchies are separated with a \".\".`,\n    defaultValue: \"albumData.title\"\n  }),\n\n  tagAlbumTitleHierarchies: new BooleanSetting({\n    category: SettingCategories.Tagging,\n    description: `If true, album titles will be split as hierarchical keywords. If false, album titles will not be split, and all albums will be under the \"Albums\" root tag.`,\n    defaultValue: false\n  }),\n\n  tagAlbumDescription: new StringSetting({\n    category: SettingCategories.Tagging,\n    description: `If you have enabled \"tagJsonAlbums\", what's the name of the field encoded in the album file? Object hierarchies are separated with a \".\".`,\n    defaultValue: \"albumData.description\"\n  }),\n\n  tagAlbumDate: new StringSetting({\n    category: SettingCategories.Tagging,\n    description: `If you have enabled \"tagJsonAlbums\", what's the name of the field encoded in the album file? Object hierarchies are separated with a \".\".`,\n    defaultValue: \"albumData.date\"\n  }),\n\n  tagAlbumsExcluded: new StringArraySetting({\n    category: SettingCategories.Tagging,\n    description: `For \"metadata.json\" albums, some are automatically generated. If the title or description includes any given string, it will be ignored.`,\n    defaultValue: [\"Album for automatically uploaded content\"]\n  }),\n\n  // TODO:\n  // tagColor: new BooleanSetting({\n  //   name: \"tagColor\",\n  //   key: \"PS_TAG_COLOR\",\n  //   category: SettingCategories.Tagging,\n  //   description: `Should assets be tagged with their dominant color (like \"Color/Yellow\")?`,\n  //   defaultValue: true,\n  //   persisted: true\n  // }),\n\n  //\n  // Subscriptions\n  //\n\n  pickPlanOnWelcome: new BooleanSetting({\n    category: SettingCategories.Subscriptions,\n    description: `If set to true, the welcome page flow will redirect to https://account.photostructure.com/plans to have you pick between \"plus\" and \"lite\". If set to false, the welcome page will continue directly to the settings page with a \"lite\" license. You can still upgrade to a paid plan later from the main menu or the about page, even if this is false.`,\n    defaultValue: true\n  }),\n\n  autoRefreshLicense: new BooleanSetting({\n    category: SettingCategories.Subscriptions,\n    description: `PhotoStructure uses cryptographically signed licenses to locally store your current plan subscription status. These licenses are only valid for the current subscription period, and must be refreshed when your subscription renews or converts from a free trial to a paid subscription. To minimize the hassle of license renewals, PhotoStructure can automatically renew expired licenses in the background.\\nIf the current license has expired and this value is true, PhotoStructure will make one secure POST request to https://account.photostructure.com/ that contains several lossy one-way hashes of current system metadata. We hash all identifying metadata to only 15 characters to alleviate any privacy concerns. If your plan subscription is active, a new license will be added to your library.\\nSet this to false and set the \"reportErrors\" setting to false if you don't want PhotoStructure \"phoning home\" for any reason.\\nNote that if this is disabled, license renewals will require manual intervention: click \"Upgrade\" from the main menu, pick your plan, authenticate, and the license will automatically refresh.`,\n    defaultValue: true\n  }),\n\n  license: new MaybeStringSetting({\n    category: SettingCategories.Subscriptions,\n    description: `Subscription licenses are normally saved automatically into both your library and system configuration directories. This setting just provides users with an alternative way to provide a license, if it's more convenient. Any value provided to this setting will be considered in addition to existing license files when PhotoStructure is trying to find the \"best\" license available.`\n  })\n}\n\nfor (const [k, v] of entries(Settings)) {\n  v._setName(k)\n}\n\n/**\n * Force the given path-separated paths to be the suggested values on the\n * welcome page.\n */\nexport const SuggestedDirsEnvKey = \"SUGGESTED_DIRS\"\n\n// Only exported for testing:\nexport function withDefaultPaths(paths: Maybe<string>): string {\n  const p = (blank(paths) ? \"\" : paths).split(delimiter)\n  if (isWin && blank(_p.env.SYSTEMROOT)) {\n    throw new Error(\"%SYSTEMROOT% is not set\")\n  }\n  p.push(...Settings.toolPaths.valueOrDefault)\n  return uniq(p).filter(notBlank).join(delimiter)\n}\n\nexport const pathWithDefaults = lazy(() => withDefaultPaths(_p.env.PATH))\n\nexport const persistedSettings = lazy(() => {\n  const arr = values(Settings).filter(ea => !ea.transient)\n  return sortBy(arr, s => [\n    s.categoryType === \"system\" ? 0 : 1,\n    SettingCategories.indexOf(s.category),\n    s.advanced,\n    s.name\n  ])\n})\n\nexport const persistedSystemSettings = lazy(() =>\n  persistedSettings().filter(ea => SystemCategories.includes(ea.category))\n)\n\nexport const persistedLibrarySettings = lazy(() =>\n  persistedSettings().filter(ea => LibraryCategories.includes(ea.category))\n)\n", "import { strEnum, StrEnumKeys } from \"./StrEnum\"\n\nexport const FitSizes = strEnum(\n  \"uhd8k\",\n  \"uhd5k\",\n  \"uhd4k\",\n  \"qhd\",\n  \"fhd\",\n  \"hd\",\n  \"wvga\",\n  \"qvga\",\n  \"qqvga\"\n)\nexport type FitSize = StrEnumKeys<typeof FitSizes>\nexport const FitSizeValues = FitSizes.values\n\nexport const SqSizes = strEnum(\"s480\", \"s240\", \"s120\", \"s60\")\nexport type SqSize = StrEnumKeys<typeof SqSizes>\n\nexport const SqWidths = [60, 120, 240, 480]\n\nexport type ImageSizeName = FitSize | SqSize\n", "import { mapNotBlank } from \"./Blank\"\nimport { lazy } from \"./Lazy\"\nimport { Maybe } from \"./MaybeTypes\"\nimport { isNumber, sigFigs, toInt } from \"./Number\"\nimport { strEnum, StrEnumKeys } from \"./StrEnum\"\nimport { replaceAll } from \"./String\"\n\n// these instances are expensive to create, and can be reused for a given\n// locale.\nconst numberFormat = lazy(() => new Intl.NumberFormat())\n\nexport const thousandsSep = lazy(() =>\n  replaceAll(numberFormat().format(1111), \"1\", \"\").charAt(0)\n)\n\nexport const decimalSep = lazy(() =>\n  replaceAll(numberFormat().format(1.1), \"1\", \"\").charAt(0)\n)\n\nexport function fmt(i: number): string {\n  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/NumberFormat\n  return numberFormat().format(i)\n}\n\n/**\n * Like `Number.toInt`, but accepts `fmt`ed strings by stripping thousands\n * separators before parsing.\n */\nexport function fmtToInt(s: Maybe<string>): Maybe<number> {\n  return mapNotBlank(s, ea => toInt(replaceAll(ea, thousandsSep(), \"\")))\n}\n\n// See https://en.wikipedia.org/wiki/Mebibyte\nexport const KB = 1000\nexport const MB = KB * 1000\nexport const GB = MB * 1000\nexport const TB = GB * 1000\n\nexport const KiB = 1024\nexport const MiB = KiB * 1024\nexport const GiB = MiB * 1024\nexport const TiB = GiB * 1024\n\nconst byteUnits = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\nconst mebiUnits = [\"B\", \"KiB\", \"MiB\", \"GiB\", \"TiB\", \"PiB\"]\n\nexport function fmtBytes(bytes: number, sigfigs = 3): string {\n  if (bytes === 0) return \"0\"\n  if (!isNumber(bytes)) return \"-\"\n  const l = Math.floor(Math.log10(bytes))\n  const mag = Math.floor(l / 3)\n  const val = Math.pow(10, mag * 3)\n  const name = byteUnits[mag]\n  return sigFigs(bytes / val, sigfigs) + \" \" + name\n}\n\nexport function fmtMebi(bytes: number, sigfigs = 3): string {\n  const l = Math.floor(Math.log2(bytes))\n  const mag = Math.floor(l / 10)\n  const val = Math.pow(2, mag * 10)\n  const name = mebiUnits[mag]\n  return sigFigs(bytes / val, sigfigs) + \" \" + name\n}\n\nexport const MP = 1e6\n\nexport function megapixels(pixels: number): number {\n  return sigFigs(pixels / MP, 2)\n}\n\nexport const SizeDescriptions = strEnum(\n  \"tiny\",\n  \"small\",\n  \"medium\",\n  \"large\",\n  \"original\"\n)\nexport type SizeDescription = StrEnumKeys<typeof SizeDescriptions>\n\nexport function pixels2size(pixels: number): SizeDescription {\n  return pixels < 320 * 240 // qvga\n    ? \"tiny\"\n    : pixels < 720 * 480 // wvga\n    ? \"small\"\n    : pixels < 1920 * 1080 // fhd\n    ? \"medium\"\n    : \"large\"\n}\n\nexport function plur(\n  i: number,\n  singular: string,\n  plural: string = singular + \"s\"\n) {\n  return fmt(i) + \" \" + (i === 1 ? singular : plural)\n}\n\nexport interface Metric {\n  count: string\n  desc: string\n}\n\nexport function plurMetric(\n  i: number,\n  singular: string,\n  plural: string = singular + \"s\"\n) {\n  return { count: fmt(i), desc: i === 1 ? singular : plural }\n}\n", "import fs from \"fs\"\nimport fse from \"fs-extra\"\nimport _p from \"path\"\nimport { createGzip } from \"zlib\"\nimport { blank, mapNotBlankOr, notBlank } from \"../../fe/Blank\"\nimport { map, mapOr, orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { toInt } from \"../../fe/Number\"\nimport { toS } from \"../../fe/toS\"\nimport { first } from \"../Array\"\nimport { resolvedWithin, thenMapOr } from \"../async/Promise\"\nimport { thenOrTimeout } from \"../async/thenOrTimeout\"\nimport { isPosix, isWin } from \"../Platform\"\nimport {\n  ensureSuffix,\n  equalsIgnoreCase,\n  leftPad,\n  spliceCapture,\n  stripPrefix\n} from \"../String\"\nimport { MountpointsTtlMs } from \"../volumes/VolumeTtls\"\nimport { SimpleFile } from \"./SimpleFile\"\nimport { StatTimeoutMs } from \"./StatTimeout\"\nimport { pipelineAsync } from \"./Streams\"\n\nconst posix = _p.posix\n\nexport function posix2native(posixPath: string, hostname?: string): string {\n  if (blank(posixPath)) return posixPath\n  if (_p.sep === posix.sep) return posixPath\n  const prefix = notBlank(hostname) ? _p.sep + _p.sep + hostname + _p.sep : \"\"\n  const split = posixPath.split(posix.sep)\n  if (equalsIgnoreCase(split[0], hostname)) split.unshift()\n  return prefix + split.join(_p.sep)\n}\n\nexport function native2posix(nativePath: string): string {\n  if (blank(nativePath)) return nativePath\n  if (_p.sep === posix.sep) return nativePath\n  return posix.sep === _p.sep\n    ? nativePath\n    : nativePath.split(_p.sep).join(posix.sep)\n}\n\nconst driveRe = /^([A-Z]:)[\\\\/]?(.*)$/i\n\nfunction upcaseDriveLetters(path: string): string {\n  const match = driveRe.exec(path)\n  return match != null ? match[1].toUpperCase() + \"\\\\\" + match[2] : path\n}\n\nexport function resolveSimpleFile(path: string | SimpleFile) {\n  return orElse(path[\"nativePath\"], () => resolve(path.toString()))\n}\n\nexport function resolve(...paths: string[]): string {\n  const path = _p.join(...paths)\n  return _p.resolve(isWin ? upcaseDriveLetters(path) : path)\n}\n\nexport interface ParsedFile {\n  /** \"/home/user/dir\" of \"/home/user/dir/file.txt\" */\n  readonly dir: string\n  /** \"file.txt\" of \"/home/user/dir/file.txt\" */\n  readonly base: string\n  /** \"file\" of \"/home/user/dir/file.txt\" */\n  readonly name: string\n  /** \".txt\" or \".log.gz\" of \"/home/user/dir/file.txt\" */\n  readonly ext: string\n}\n\nexport function parsePosixPath(posixPath: string): ParsedFile {\n  return parseNativePath(posix2native(posixPath))\n}\n\n/** @return \".txt\" or \".log.gz\" of \"/home/user/dir/file.txt\" */\nexport function extname(nativePath: string): string {\n  return parseNativePath(nativePath).ext\n}\n\nconst CompressedExtRE = /(\\.(?:gz|z|7z|xz|bz2))$/i\n\n/**\n * Supports hidden files and extracting \".log.gz\" as the `ext` for \"file.log.gz\"\n */\nexport function parseNativePath(nativePath: string): ParsedFile {\n  const r = spliceCapture(nativePath, CompressedExtRE)\n  const p = _p.parse(orElse(r?.uncaptured, nativePath))\n  return {\n    ...p,\n    ...(r == null\n      ? {}\n      : {\n          ext: p.ext + r.captured,\n          base: p.base + r.captured\n        })\n  }\n}\n\nexport function containedBy(\n  childPosixPath: Maybe<string>,\n  parentPosixPath: Maybe<string>\n): boolean {\n  return (\n    notBlank(childPosixPath) &&\n    notBlank(parentPosixPath) &&\n    (childPosixPath === parentPosixPath ||\n      childPosixPath.startsWith(ensureSuffix(parentPosixPath, posix.sep)))\n  )\n}\n\nexport function containedByNativePath(\n  childNativePath: Maybe<string>,\n  parentNativePath: Maybe<string>\n): boolean {\n  return (\n    notBlank(childNativePath) &&\n    notBlank(parentNativePath) &&\n    (childNativePath === parentNativePath ||\n      childNativePath.startsWith(ensureSuffix(parentNativePath, _p.sep)))\n  )\n}\n\nexport function pathnames(nativePath: string) {\n  return stripPrefix(nativePath, _p.sep).split(_p.sep)\n}\n\nexport type NativePathed = Pick<SimpleFile, \"nativePath\">\n\nexport function posixPathFrom(\n  parent: NativePathed,\n  child: NativePathed\n): string {\n  return parent.nativePath === child.nativePath\n    ? \"\"\n    : // The ensureSuffix handles windows drive letters properly:\n      stripPrefix(\n        native2posix(child.nativePath),\n        ensureSuffix(native2posix(parent.nativePath), \"/\")\n      )\n}\n\nexport function posixPathFromGrandparent(nativePath: string): string {\n  return pathnames(nativePath).slice(-3).join(\"/\")\n}\n\nconst countRE = /(.*?)(?:-(\\d{1,4})|\\((\\d{1,4})\\))$/\nexport function nameWithoutCount(name: string): string {\n  return mapOr(\n    toS(name).match(countRE),\n    m => m[1],\n    () => name\n  )\n    .toLowerCase()\n    .normalize()\n}\n\nexport function countFromName(name: string): Maybe<number> {\n  return map(toS(name).match(countRE), m => first([m[2], m[3]], toInt))\n}\n\nexport function addNameSuffix(basename_: string, suffix: string): string {\n  const p = parseNativePath(basename_)\n  return `${p.base}${suffix}${p.ext}`\n}\n\nexport function isDirectorySync(nativePath: Maybe<string>) {\n  if (blank(nativePath)) return false\n  try {\n    return fs.statSync(nativePath).isDirectory()\n  } catch {\n    return false\n  }\n}\n\nexport async function stat(nativePath: Maybe<string>) {\n  if (blank(nativePath)) return\n  try {\n    return await thenOrTimeout(fse.stat(nativePath), MountpointsTtlMs)\n  } catch {\n    return\n  }\n}\n\nexport async function notExists(nativePath: string) {\n  return null == (await stat(nativePath))\n}\n\nexport async function isEmpty(nativePath: string) {\n  const s = await stat(nativePath)\n  return s == null || (s.isFile() && s.size === 0)\n}\n\nexport async function isDirectory(nativePath: Maybe<string>): Promise<boolean> {\n  return thenMapOr(\n    stat(nativePath),\n    ea => ea.isDirectory(),\n    () => false\n  )\n}\n\nexport function firstExistingDirectory(paths: Maybe<string>[]): Maybe<string> {\n  for (const ea of paths) {\n    if (notBlank(ea)) {\n      const d = resolve(ea)\n      if (isDirectorySync(d)) return d\n    }\n  }\n  return undefined\n}\n\nexport function posixPathExistsSync(posixPath: Maybe<string>) {\n  return mapNotBlankOr(\n    posixPath,\n    ea => nativePathExistsSync(posix2native(ea)),\n    false\n  )\n}\n\nexport async function nativePathExists(\n  nativePath: Maybe<string>\n): Promise<boolean> {\n  if (blank(nativePath)) return false\n  try {\n    return null != (await stat(nativePath))\n  } catch {\n    return false\n  }\n}\n\nexport function nativePathExistsSync(nativePath: Maybe<string>) {\n  if (blank(nativePath)) return false\n  try {\n    return fs.existsSync(nativePath)\n  } catch {\n    return false\n  }\n}\n\nexport async function nativePathIsReadableDirectory(\n  nativePath: Maybe<string>,\n  timeoutMs = StatTimeoutMs\n) {\n  if (blank(nativePath)) return false\n  try {\n    const s = await thenOrTimeout(stat(nativePath), timeoutMs)\n    if (s == null || !s.isDirectory()) return false\n    return await resolvedWithin(\n      fse.access(\n        nativePath,\n        fs.constants.R_OK | (isWin ? 0 : fs.constants.X_OK)\n      ),\n      timeoutMs\n    )\n  } catch {\n    return false\n  }\n}\n\nexport function isUNC(nativePath: string) {\n  return nativePath.startsWith(\"\\\\\\\\\")\n}\n\nexport function isAbsolute(nativePath: string) {\n  return (\n    (isPosix && nativePath.startsWith(\"/\")) ||\n    (isWin && (isUNC(nativePath) || nativePath.match(driveRe) != null))\n  )\n}\n\nexport interface EnsureNewOptions {\n  nativePath: string\n  emptyIsNew?: boolean\n  maxVersions?: number\n  requireNumber?: boolean\n  leftPad?: number\n  startIndex?: number\n}\n\nexport const DefaultEnsureNewOptions: Omit<\n  Required<EnsureNewOptions>,\n  \"nativePath\"\n> = Object.freeze({\n  emptyIsNew: true,\n  maxVersions: 512,\n  requireNumber: false,\n  leftPad: 1,\n  startIndex: 1\n})\n\nfunction isEmptyFile(s: fs.Stats) {\n  return s == null || (s.isFile() && s.size === 0)\n}\n\nexport async function ensureNewNativePath_(\n  options: EnsureNewOptions\n): Promise<string> {\n  const opts: Required<EnsureNewOptions> = {\n    ...DefaultEnsureNewOptions,\n    ...options\n  }\n\n  const p = parseNativePath(opts.nativePath)\n\n  await fse.mkdirp(p.dir)\n\n  {\n    const s = await stat(opts.nativePath)\n    if (\n      !opts.requireNumber &&\n      (s == null || (opts.emptyIsNew && isEmptyFile(s)))\n    )\n      return opts.nativePath\n  }\n  for (let i = opts.startIndex; i <= opts.maxVersions; i++) {\n    const f = _p.join(\n      p.dir,\n      `${p.name}-${leftPad(i, opts.leftPad, \"0\")}${p.ext}`\n    )\n    const s = await stat(f)\n    if (s == null || (opts.emptyIsNew && isEmptyFile(s))) {\n      return f\n    }\n  }\n  throw new Error(\n    \"There are already more than \" + opts.maxVersions + \" of \" + opts.nativePath\n  )\n}\n\nexport async function gzip_(nativePath: string): Promise<string> {\n  if (nativePath.endsWith(\".gz\")) return nativePath\n  const out = nativePath + \".gz\"\n  await pipelineAsync([\n    fs.createReadStream(nativePath),\n    createGzip(),\n    fs.createWriteStream(out)\n  ])\n  await fse.unlink(nativePath)\n  return out\n}\n", "import { PromiseMaybe } from \"./MaybeTypes\"\nimport { MaybeNullSyncOrAsync, MaybeSyncOrAsync, SyncOrAsync } from \"./OptAsync\"\nimport { toA } from \"./toA\"\n\n/**\n * Safe calls for Optional promises:\n */\nexport async function thenMap<T1, T2>(\n  objP: MaybeNullSyncOrAsync<T1>,\n  f: (t: T1) => MaybeSyncOrAsync<T2>\n): PromiseMaybe<T2> {\n  const obj = await objP\n  return obj == null ? undefined : f(obj)\n}\n\n/**\n * Serialized promise gathering and compaction\n * @see ../core/async/Promise#tuples\n */\nexport async function thenCollect<T1, T2>(\n  arr: MaybeSyncOrAsync<MaybeSyncOrAsync<T1>[]>,\n  f: (t: T1) => MaybeSyncOrAsync<T2>\n): Promise<T2[]> {\n  const result: T2[] = []\n  for (const eaP of toA(await arr)) {\n    if (eaP != null) {\n      const ea = await eaP\n      if (ea != null) {\n        const r = await f(ea)\n        if (r != null) result.push(r)\n      }\n    }\n  }\n  return result\n}\n\nexport async function thenTap<T>(\n  p: SyncOrAsync<T>,\n  f: (t: T) => any = console.dir.bind(console)\n): Promise<T> {\n  const result = await p\n  // We await f so if it raises errors, thenTap will propagate the error:\n  await f(result)\n  return result\n}\n\nexport function isPromise(o: any): o is Promise<any> {\n  return (\n    o != null &&\n    typeof o[\"then\"] === \"function\" &&\n    typeof o[\"catch\"] === \"function\"\n  )\n}\n", "import { PromiseState } from \"./PromiseState\"\n\n// This is used by logging, so it can't have any dependencies.\n\n/**\n * Simple one-count concurrent barrier\n */\nexport class Latch implements PromiseLike<void> {\n  // Expose `promise` so we can have a honest-to-goodness Promise\n  readonly promise: Promise<void>\n  private _state: PromiseState = \"pending\"\n  private _resolve!: () => void\n  private _reject!: (err?: Error) => void\n\n  constructor(readonly id?: any) {\n    this.promise = new Promise<void>((resolve, reject) => {\n      this._resolve = resolve\n      this._reject = reject\n    })\n  }\n\n  resolve(): Latch {\n    if (this.pending) {\n      this._resolve()\n      this._state = \"resolved\"\n    }\n    return this\n  }\n\n  reject(err?: Error): Latch {\n    if (this.pending) {\n      this._reject(err)\n      this._state = \"rejected\"\n    }\n    return this\n  }\n\n  finally(f: () => any): this {\n    this.promise.finally(f)\n    return this\n  }\n\n  observe(p: Promise<any>): this {\n    p.then(\n      () => this.resolve(),\n      err => this.reject(err)\n    )\n    return this\n  }\n\n  observeQuietly(p: Promise<any>): this {\n    p.then(\n      () => this.resolve(),\n      () => this.resolve()\n    )\n    return this\n  }\n\n  get pending(): boolean {\n    return this._state === \"pending\"\n  }\n\n  get settled() {\n    return !this.pending\n  }\n\n  get resolved() {\n    return this._state === \"resolved\"\n  }\n\n  get rejected() {\n    return this._state === \"rejected\"\n  }\n\n  get state(): PromiseState {\n    return this._state\n  }\n\n  then<T1, T2>(\n    onfulfilled?: ((v: void) => T1 | PromiseLike<T1>) | undefined | null,\n    onrejected?: ((reason: any) => T2 | PromiseLike<T2>) | undefined | null\n  ): Promise<T1 | T2> {\n    return this.promise.then(onfulfilled, onrejected)\n  }\n}\n", "import { cpus, freemem, totalmem } from \"os\"\nimport { later } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { clamp } from \"../../fe/Number\"\nimport { GB, MB } from \"../../fe/Units\"\nimport { onClearCache } from \"../event/EventEmitter\"\nimport { Settings } from \"../settings/Settings\"\n\nvoid later(() => {\n  onClearCache(() => {\n    estimatedFreeMem.unset()\n    totalCpus.unset()\n    maxCpus.unset()\n    sharpThreadsPerSystem.unset()\n    maxSyncFileJobs.unset()\n    sharpThreadsPerJob.unset()\n    maxPendingSyncFileJobs.unset()\n  })\n})\n\n// lazy for testing\nexport const estimatedFreeMem = lazy(() => (freemem() * 2 + totalmem()) / 3)\n\nexport const totalCpus = lazy(() => cpus().length)\n\nexport const maxCpus = lazy(() => {\n  // they may bloat, but they'll recycle if they get too big.\n  const worstCaseMemPerProc = 1 * GB\n  // We don't want to over-subscribe system memory, but we need to run at\n  // least one:\n  const maxProcs = Math.max(\n    1,\n    Math.floor(estimatedFreeMem() / worstCaseMemPerProc)\n  )\n  const cpuCount = (Settings.cpuLoadPercent.valueOrDefault / 100) * totalCpus()\n  return clamp(1, maxProcs, Math.floor(cpuCount))\n})\n\nexport const sharpThreadsPerSystem = lazy(() => {\n  const worstCasePerSharpThread = 500 * MB\n  const maxThreadsForMem = Math.floor(\n    estimatedFreeMem() / worstCasePerSharpThread\n  )\n  const maxThreads = Math.max(\n    1,\n    Math.floor(\n      1.5 * totalCpus() * (Settings.cpuLoadPercent.valueOrDefault / 100)\n    )\n  )\n  return clamp(1, maxThreads, maxThreadsForMem)\n})\n\nexport const maxSyncFileJobs = lazy(() => {\n  // We can host 2-6 sharp threads per sync-file. It's better for concurrency to\n  // have > 1 sync-file than > 1 sharp thread, but that uses more memory.\n  return clamp(1, 24, maxCpus())\n})\n\n// Now that we've decided how many sync-file jobs we can run, we can decide how\n// many sharp threads we use per sync-file:\nexport const sharpThreadsPerJob = lazy(() =>\n  // Even if we've got tons of RAM, we don't get a huge performance win with >\n  // 8 graphics threads. 6 is fine.\n  clamp(1, 6, Math.ceil(sharpThreadsPerSystem() / maxSyncFileJobs()))\n)\n\n// 20200929 don't enqueue too many jobs so we don't get timeouts, and  UI sync\n// jobs can be processed in a timely fashion\nexport const maxPendingSyncFileJobs = maxSyncFileJobs\n", "import { EventEmitter } from \"events\"\nimport { mkLogger } from \"../Logger\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { SimpleEventEmitter } from \"./SimpleEventEmitter\"\nimport { TestEventEmitter } from \"./TestEventEmitter\"\n\n// THIS CANNOT IMPORT ANY CORE CODE. It's used everywhere.\n\nconst _testEventEmitter = lazy(() => new TestEventEmitter())\nconst _prodEventEmitter = lazy(() => {\n  const ee = new EventEmitter()\n  ee.setMaxListeners(50) // because of onClearCache()\n  return ee\n})\n\nexport let eventEmitter: SimpleEventEmitter = _prodEventEmitter()\n\nexport function useTestEventEmitter() {\n  return (eventEmitter = _testEventEmitter())\n}\nexport function useProductionEventEmitter() {\n  return (eventEmitter = _prodEventEmitter())\n}\n\nexport function emitClearCache() {\n  mkLogger(\"EventEmitter\").info(\"emitClearCache()\")\n  eventEmitter.emit(\"clearCache\")\n}\n\nexport function onClearCache(thunk: () => any) {\n  eventEmitter.on(\"clearCache\", thunk)\n}\n\nexport function emitIdle() {\n  eventEmitter.emit(\"idle\")\n}\n\nexport function onIdle(listener: () => any) {\n  eventEmitter.on(\"idle\", listener)\n}\n\nexport function emitMigration(migrationName: string) {\n  eventEmitter.emit(\"migration\", migrationName)\n}\n\nexport function onMigration(listener: (migrationName: string) => any) {\n  eventEmitter.on(\"migration\", listener)\n}\n\nexport function emitPause() {\n  eventEmitter.emit(\"pause\")\n}\n\nexport function onPause(listener: () => any) {\n  eventEmitter.on(\"pause\", listener)\n}\n\nexport function emitResume() {\n  eventEmitter.emit(\"resume\")\n}\n\nexport function onResume(listener: () => any) {\n  eventEmitter.on(\"resume\", listener)\n}\n\nexport function emitFileChanged(nativePath?: string) {\n  eventEmitter.emit(\"fileChanged\", nativePath)\n}\n\nexport function onFileCopied(\n  listener: (srcNativePath: string, destNativePath: string) => any\n) {\n  eventEmitter.on(\"fileCopied\", listener)\n}\n\nexport function emitFileCopied(\n  srcNativePath?: string,\n  destNativePath?: string\n) {\n  eventEmitter.emit(\"fileCopied\", srcNativePath, destNativePath)\n}\n\nexport function onFileChanged(listener: (nativePath?: string) => any) {\n  eventEmitter.on(\"fileChanged\", listener)\n}\n\nexport function emitFocus(argv: string[], cwd: string) {\n  eventEmitter.emit(\"focus\", argv, cwd)\n}\n\nexport function onFocus(listener: (argv: string[], cwd: string) => any) {\n  eventEmitter.on(\"focus\", listener)\n}\n\n// NOTE: no emitFatal or emitNonFatal: use onError instead.\n\nexport function onFatal(listener: (message: string, error?: Error) => any) {\n  eventEmitter.on(\"fatal\", ({ message, error }) => listener(message, error))\n}\n\nexport function onNonFatal(listener: (message: string, error?: Error) => any) {\n  eventEmitter.on(\"nonFatal\", ({ message, error }) => listener(message, error))\n}\n\nexport function emitRpcServerChange() {\n  eventEmitter.emit(\"rpcServerChange\")\n}\n\nexport function onRpcServerChange(listener: () => any) {\n  eventEmitter.on(\"rpcServerChange\", listener)\n}\n\nexport let readyToUpdate = false\n\nexport function emitReadyToUpdate() {\n  readyToUpdate = true\n  eventEmitter.emit(\"readyToUpdate\")\n}\n\nexport function onReadyToUpdate(listener: () => any) {\n  eventEmitter.on(\"readyToUpdate\", listener)\n}\n\nexport function emitVolumesChanged() {\n  eventEmitter.emit(\"volumesChanged\")\n}\n\nexport function onVolumesChanged(listener: () => any) {\n  eventEmitter.on(\"volumesChanged\", listener)\n}\n\nexport function emitSettingsChanged() {\n  eventEmitter.emit(\"settingsChanged\")\n}\n\nexport function onSettingsChanged(listener: () => any) {\n  eventEmitter.on(\"settingsChanged\", listener)\n}\n\nexport function emitVacuuming() {\n  eventEmitter.emit(\"settingsChanged\")\n}\n\nexport function onVacuuming(listener: (isVacuuming: boolean) => any) {\n  eventEmitter.on(\"vacuuming\", listener)\n}\n\nexport function emitWriteRecentLogEntries() {\n  eventEmitter.emit(\"writeRecentLogEntries\")\n}\n\nexport function onWriteRecentLogEntries(listener: () => any) {\n  eventEmitter.on(\"writeRecentLogEntries\", listener)\n}\n", "import { EventEmitter } from \"events\"\n\nimport { Event } from \"./Event\"\n\nexport class TestEventEmitter extends EventEmitter {\n  readonly events: Event[] = []\n  emit(name: string | symbol, ...args: any[]): boolean {\n    super.emit(name, ...args)\n    this.events.push({ name, args })\n    return true\n  }\n  clear() {\n    this.events.length = 0\n  }\n}\n", "import { clearTimeout } from \"timers\"\nimport { inspect } from \"util\"\nimport { asError } from \"../../fe/Error\"\nimport { stringify } from \"../../fe/JSON\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { PromiseState, PromiseStates } from \"../../fe/PromiseState\"\nimport { isIgnorableError } from \"../error/ErrorTypes\"\nimport { Logger, mkLogger } from \"../Logger\"\nimport { Pojo } from \"../Object\"\nimport { isString } from \"../String\"\nimport { setUnrefTimeout } from \"./Timers\"\n\n/**\n * Deferred resolution of a promise with synchronous state\n */\nexport class Deferred<T> implements PromiseLike<T> {\n  private readonly logger: Logger\n  readonly start = Date.now()\n  private end?: number\n  private state: PromiseState = PromiseStates.pending\n  private _value?: T\n  readonly promise: Promise<T>\n  private _resolve!: (value: T) => void\n  private _reject!: (reason?: any) => void\n  private _error: Maybe<Error>\n  private priorTimeout: Maybe<NodeJS.Timeout>\n\n  /**\n   * @param name can be either a string or a data payload to associate with the\n   * promise.\n   */\n  constructor(readonly name: string | Pojo) {\n    this.promise = new Promise<T>((resolve, reject) => {\n      this._resolve = resolve\n      this._reject = reject\n    })\n    this.logger = mkLogger(\"Deferred(\" + this.toString() + \")\")\n  }\n\n  toString() {\n    return isString(this.name) ? this.name : stringify(this.name)\n  }\n\n  [inspect.custom]() {\n    return {\n      ctor: \"Deferred\",\n      name: this.toString(),\n      start: this.start,\n      end: this.end,\n      state: this.state\n    }\n  }\n\n  observeQuietly(p: Promise<T>): Deferred<Maybe<T>> {\n    p.then(resolution => {\n      this.resolve(resolution)\n    }).catch(err => {\n      this.logger.warn(\"observeQuietly.reject()\", err)\n      this.resolve(undefined as any)\n    })\n    return this as any\n  }\n\n  observe(p: Promise<T>): this {\n    p.then(resolution => {\n      this.maybeResolve(resolution)\n    }).catch(err => {\n      this.maybeReject(err)\n    })\n    return this\n  }\n\n  /**\n   * Reject the promise if it hasn't been resolved or rejected within\n   * `timeoutMs`\n   */\n  setTimeout(timeoutMs: number): this {\n    map(this.priorTimeout, clearTimeout)\n    // unref so it doesn't prevent node from exiting:\n    this.priorTimeout = setUnrefTimeout(() => {\n      if (this.pending) {\n        const msg =\n          \"TIMEOUT: \" + this.name + \" after \" + (Date.now() - this.start) + \"ms\"\n        this.reject(msg)\n      }\n    }, timeoutMs)\n    return this\n  }\n\n  get stateStr(): string {\n    return this.pending ? \"pending\" : this.resolved ? \"resolved\" : \"rejected\"\n  }\n\n  get pending() {\n    return this.state === PromiseStates.pending\n  }\n\n  /**\n   * @return the resolved value for this Deferred, or `undefined` if this\n   * is either still pending or rejected.\n   */\n  get value(): Maybe<T> {\n    return this.resolved ? this._value : undefined\n  }\n\n  get error(): Maybe<Error> {\n    return this._error\n  }\n\n  /**\n   * true iff either resolved or rejected.\n   */\n  get settled() {\n    return this.state !== PromiseStates.pending\n  }\n\n  get resolved() {\n    return this.state === PromiseStates.resolved\n  }\n\n  get rejected() {\n    return this.state === PromiseStates.rejected\n  }\n\n  get settledMs(): number | undefined {\n    return this.end == null ? undefined : this.end - this.start\n  }\n\n  /**\n   * Resolves the internal promise. Cannot be invoked more than once.\n   */\n  resolve(value: T): this {\n    return this.settle(() => {\n      this.state = PromiseStates.resolved\n      this._value = value\n      this._resolve(value)\n    })\n  }\n\n  maybeResolve(value: T): this {\n    return this.pending ? this.resolve(value) : this\n  }\n\n  reject(reason?: any): this {\n    this.logger.log(\n      isIgnorableError(reason) ? \"info\" : \"warn\",\n      \".reject()\",\n      reason\n    )\n    const err = asError(reason)\n    return this.settle(() => {\n      this._error = err\n      this.state = PromiseStates.rejected\n      this._reject(err)\n    })\n  }\n\n  maybeReject(reason?: any): this {\n    return this.pending ? this.reject(reason) : this\n  }\n\n  finally(f: () => any): this {\n    this.promise.finally(f)\n    return this\n  }\n\n  /**\n   * @param f will be called with the resolved value\n   */\n  then<U>(f: (value: T) => U | PromiseLike<U>): Promise<U> {\n    return this.promise.then(f)\n  }\n\n  catch<U>(onrejected: (reason: any) => U | PromiseLike<U>): Promise<T | U> {\n    return this.promise.catch(err => onrejected(err))\n  }\n\n  private settle(firstback: () => void): this {\n    if (this.state === PromiseStates.pending) {\n      map(this.priorTimeout, clearTimeout)\n      firstback()\n      this.end = Date.now()\n      const ms = this.settledMs!\n      if (this.resolved && ms > 5000) {\n        const level = ms > 5000 ? \"info\" : \"debug\"\n        this.logger.log(level, \"Completed in \" + ms + \"ms\")\n      }\n    } else {\n      this.logger.warn(\n        \"settled multiple times (already \" + this.stateStr + \")\",\n        { value: this._value }\n      )\n    }\n    return this\n  }\n}\n", "import { compactBlankish, uniq } from \"./Array\"\nimport { blank, blankish, mapNotBlank, notBlank } from \"./Blank\"\nimport { Maybe } from \"./MaybeTypes\"\nimport { ellipsize } from \"./String\"\nimport { toA } from \"./toA\"\nimport { toS } from \"./toS\"\n\nexport function errorToS(err: any): string {\n  if (blankish(err)) return \"\"\n  const result =\n    err instanceof Error\n      ? uniq(\n          compactBlankish([\n            toS(err.name).trim(),\n            mapNotBlank((err as any).code, ea => `code ${ea.trim()}`),\n            toS(err.message).trim()\n          ])\n        ).join(\": \")\n      : toS(err)\n  return ellipsize(result, 255)\n}\n\nexport function errorToVerbose(err: any): string {\n  if (err == null) return \"(undefined)\"\n  return [errorToS(err), ...toA(shortStack(err.stack))].join(\"\\n\")\n}\n\nexport function shortStack(stack?: string): Maybe<string[]> {\n  return blank(stack) ? undefined : toS(stack).split(\"\\n\").slice(0, 6)\n}\n\nexport function asError(reason?: any): Error {\n  if (blank(reason)) {\n    throw new Error(\"undefined error\")\n  } else if (reason instanceof Error) {\n    return reason\n  } else if (Array.isArray(reason)) {\n    const first = reason[0]\n    if (first instanceof Error) {\n      if (reason.length > 1) {\n        ;(first as any).errors = reason.slice(1)\n      }\n      return first\n    } else {\n      return new Error(\n        reason\n          .map(ea => toS(ea))\n          .filter(notBlank)\n          .join(\", \")\n      )\n    }\n  } else {\n    // Errors render as \"Error: something bad happened\". If you create a new\n    // Error from that string, you'll get an Error that toString's to \"Error:\n    // Error: something bad happened\", so strip the name of the error and give\n    // it to the return value:\n    const s = errorToS(reason)\n    const reasonNameIdx = s.indexOf(\":\")\n    if (reasonNameIdx > 2 && reasonNameIdx < 15) {\n      const e = new Error(s.slice(reasonNameIdx + 1).trim())\n      e.name = s.slice(0, reasonNameIdx).trim()\n      return e\n    } else {\n      return new Error(s)\n    }\n  }\n}\n\nexport function isError(err: any): err is Error {\n  return err instanceof Error\n}\n", "import { strEnum, StrEnumKeys } from \"./StrEnum\"\n\nexport const PromiseStates = strEnum(\"pending\", \"resolved\", \"rejected\")\nexport type PromiseState = StrEnumKeys<typeof PromiseStates>\n", "import { errorToS } from \"../../fe/Error\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { ending } from \"../async/Endable\"\nimport { isFalse, isTrue } from \"../../fe/Boolean\"\n\n// I could also go with a \u26A0\uFE0F\uD83D\uDED1\uD83D\uDCA5 or \"\uD83D\uDD01\u23F9\u23CF\uFE0F\" \uFE0Fbut these seem less cutesy:\nexport const FatalErrorFlag = \"\u00B9\"\nexport const NonRetriableErrorFlag = \"\u00B2\"\nexport const IgnorableErrorFlag = \"\u00B3\"\nexport const PleaseSendErrorFlag = \"\u2074\"\nexport const HealthCheckErrorFlag = \"\u2075\"\nexport const DoNotSendErrorFlag = \"\u2076\"\nexport const RetriableErrorFlag = \"\u2077\"\n\n// \u2070\u00B9\u00B2\u00B3\u2074\u2075\u2076\u2077\u2078\u2079\u2080\u2081\u2082\u2083\u2084\u2085\u2086\u2087\u2088\u2089\n\nexport const ErrorFlags = [\n  FatalErrorFlag,\n  NonRetriableErrorFlag,\n  IgnorableErrorFlag,\n  PleaseSendErrorFlag,\n  HealthCheckErrorFlag,\n  DoNotSendErrorFlag,\n  RetriableErrorFlag\n]\n\nexport type ErrorFlag =\n  | typeof FatalErrorFlag\n  | typeof NonRetriableErrorFlag\n  | typeof IgnorableErrorFlag\n  | typeof PleaseSendErrorFlag\n  | typeof HealthCheckErrorFlag\n  | typeof DoNotSendErrorFlag\n  | typeof RetriableErrorFlag\n\nexport function addErrorFlags(msg: string, ...flags: Maybe<ErrorFlag>[]) {\n  return msg + flags.filter(ea => ea != null && !msg.includes(ea)).join(\"\")\n}\nconst ErrorFlagsRE = /[\u2070\u00B9\u00B2\u00B3\u2074\u2075\u2076\u2077\u2078\u2079\u2080\u2081\u2082\u2083\u2084\u2085\u2086\u2087\u2088\u2089]/g\n\nexport function stripErrorFlags(err: string): string {\n  return err.replace(ErrorFlagsRE, \"\")\n}\n\nexport function extractErrorFlags(err: string): string {\n  return err\n    .split(\"\")\n    .filter(ea => ErrorFlags.includes(ea))\n    .join(\"\")\n}\n\nexport function hasErrorFlag(err: string): boolean {\n  return err.match(ErrorFlagsRE) != null\n}\n\nexport function isHealthCheckError(err: any): boolean {\n  return errorToS(err).includes(HealthCheckErrorFlag)\n}\n\nexport function isPleaseSendError(err: any): boolean {\n  return errorToS(err).includes(PleaseSendErrorFlag)\n}\n\nconst ignorablePatterns = [\n  IgnorableErrorFlag,\n  \"0 output files created\", // From exiftool\n  \"BatchCluster has ended, cannot enqueue\", // when sync-file is stopped before it's done\n  \"called while not idle\", // From old versions of batch-cluster\n  \"Can't set headers after they are sent\", // ignorable internal error\n  \"debugger attached\", //nodeJS inspector issues\n  \"debugger listening on\", //nodeJS inspector issues\n  \"diskutil: interrupted\", // dang flaky macOS tool\n  \"ECONNRESET\", // read ECONNRESET from broken socket\n  \"end() called before task completed\", // when sync-file is stopped before it's done\n  \"EPIPE\", // meh whatev\n  \"for help\", //nodeJS inspector issues\n  \"Format error in file\", // from exiftool\n  \"https://nodejs.org/en/docs/inspector\", //nodeJS inspector issues\n  \"Invalid data found when processing input\", // from invalid ffmpeg file\n  \"Missing expected status message\", // From exiftool\n  \"net::ERR_\", //See https://cs.chromium.org/codesearch/f/chromium/src/net/base/net_error_list.h  like net::ERR_TIMED_OUT\n  \"onExit(exit) called end()\", // From old versions of batch-cluster\n  \"This socket has been ended by the other party\", // so rude\n  \"Unexpected error while trimming\", // From sharp\n  \"Warning\" // I mean it's a warning\n].map(ea => ea.toLowerCase())\n\n/**\n * Ignorable errors are expected, and not even important enough to log.\n */\nexport function isIgnorableError(err: any): boolean {\n  if (err == null) return true\n  const msg = errorToS(err).toLowerCase()\n  const matchesIgnorable = ignorablePatterns.some(ea => msg.includes(ea))\n  return (\n    ending() ||\n    (!isPleaseSendError(err) && !isFatalError(err) && matchesIgnorable)\n  )\n\n  // return mkLogger().tap({\n  //   msg: \"isIgnorableError\",\n  //   result:\n  //     ending() ||\n  //     (!isPleaseSendError(err) && !isFatalError(err) && matchesIgnorable),\n  // meta: {\n  //   err: errorToS(err),\n  //   ending: ending(),\n  //   isPleaseSend: isPleaseSendError(err),\n  //   isFatal: isFatalError(err),\n  //   matchesIgnorable\n  // }\n}\n\nconst BusyErrorRe = /SQLITE_BUSY|database is locked/i\n\nexport function isSqliteBusyError(err: any): boolean {\n  return err.code === \"SQLITE_BUSY\" || null != errorToS(err).match(BusyErrorRe)\n}\n\nexport function isSqliteDisconnectedError(err: any): boolean {\n  return null != errorToS(err).match(/database .+ not open/i)\n}\n\nexport function isSqliteConstraintError(err: any): boolean {\n  return null != errorToS(err).match(/SQLITE_CONSTRAINT|constraint failed/i)\n}\n\nexport function isRetriableError(err: any): boolean {\n  return (\n    !isFatalError(err) &&\n    !errorToS(err).includes(NonRetriableErrorFlag) &&\n    !isSqliteConstraintError(err) &&\n    !isFalse(err.retriable)\n  )\n}\n\nexport function isNonRetriableError(err: any): boolean {\n  return !isRetriableError(err)\n}\n\n/**\n * These may be fatal errors (like loss of library lock), and the user will care\n * about them, but we don't need to tell Sentry about them.\n */\nexport function isDoNotSendError(err: any): boolean {\n  if (isPleaseSendError(err)) return false\n  if (isTrue(err?.doNotSend)) return true // WrappedError\n\n  const msg = errorToS(err).toLowerCase()\n  return doNotSendPatterns.some(ea => msg.includes(ea)) || isIgnorableError(msg)\n}\n\nconst doNotSendPatterns = [\n  DoNotSendErrorFlag,\n  \"Corrupt JPEG data\", // invalid jpeg, don't tell me.\n  \"premature end of data segment\", // invalid jpeg, don't tell me.\n  \"VipsJpeg\" // invalid jpeg, don't tell me.\n]\n\n/**\n * Default errors that indicate serious problems\n */\nexport const FatalErrorRe = new RegExp(\n  // (?! ... ) is a negative lookahead:\n  \"SQLITE_(FULL|IOERR|NOMEM)|ON CONFLICT|Error: Cannot find module|\" +\n    FatalErrorFlag,\n  \"i\"\n)\n\n/**\n * Does `err` represent a \"fatal\" error?\n */\nexport function isFatalError(err: any): boolean {\n  if (err == null) return false\n  if (isTrue(err.fatal)) return true\n  return FatalErrorRe.exec(errorToS(err)) != null\n}\n", "import { count, filterInPlace } from \"../../fe/Array\"\nimport { Latch } from \"../../fe/Latch\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { clamp } from \"../../fe/Number\"\nimport { isFunction } from \"../../fe/ObjectType\"\nimport { Average } from \"../math/Average\"\nimport { Pojo } from \"../Object\"\nimport { maxCpus } from \"../work/MaxCpus\"\nimport { Deferred } from \"./Deferred\"\nimport { Later, LaterMaybe } from \"./Later\"\n\n/**\n * Aggregate promises efficiently\n *\n * Note that `N` is either a descriptive name for the promise, or can be a data\n * payload associated to the promise.\n */\nexport class Promises<N extends string | Pojo = string> {\n  private _pushCount = 0\n  lastPushTs = 0\n  private readonly _arr: Deferred<any>[] = []\n  private readonly nextSettledLatches: Latch[] = []\n  readonly serialLatencyAvg = new Average()\n  readonly applyListeners: ((name: N) => any)[] = []\n\n  private get arr() {\n    filterInPlace(this._arr, ea => ea.pending)\n    return this._arr\n  }\n\n  get pushCount() {\n    return this._pushCount\n  }\n\n  /**\n   * Listener that will be called once the given push()ed or serial()ed or\n   * maybeRun()ed promise is started.\n   */\n  onApply(listener: (name: N) => any) {\n    this.applyListeners.push(listener)\n  }\n\n  private _emitApply(name: N) {\n    for (const ea of this.applyListeners) {\n      ea(name)\n    }\n  }\n\n  push<T>(name: N, promiseOrLater: Promise<T> | Later<T>): Promise<T> {\n    this._emitApply(name)\n    return this._push(name, promiseOrLater)\n  }\n\n  private _push<T>(name: N, promiseOrLater: Promise<T> | Later<T>) {\n    this._pushCount++\n    this.lastPushTs = Date.now()\n    // We observe quietly here so one rejected promise doesn't kill all the\n    // following. Note that `this.arr` (not this._arr) does garbage collection:\n    const p = isFunction(promiseOrLater) ? promiseOrLater() : promiseOrLater\n    this.arr.push(\n      new Deferred(name).observeQuietly(p).finally(() => this.emitSettled())\n    )\n    return p\n  }\n\n  private emitSettled() {\n    for (const ea of this.nextSettledLatches) {\n      void ea.resolve()\n    }\n    this.nextSettledLatches.length = 0\n  }\n\n  awaitNextSettled(): Latch {\n    const l = new Latch()\n    this.nextSettledLatches.push(l)\n    return l\n  }\n\n  /**\n   * Run f() after all prior-enqueued promises have resolved.\n   */\n  serial<T>(name: N, f: () => Promise<T>): Promise<T> {\n    const start = Date.now()\n    return this._push(\n      name,\n      this.awaitAll().then(() => {\n        this.serialLatencyAvg.push(Date.now() - start)\n        this._emitApply(name)\n        return f()\n      })\n    )\n  }\n\n  /**\n   * Run f() after all prior-enqueued promises have resolved.\n   */\n  serialByName<T>(name: N, f: () => Promise<T>): Promise<T> {\n    const start = Date.now()\n    return this._push(\n      name,\n      this.awaitAllByName(name).then(() => {\n        this.serialLatencyAvg.push(Date.now() - start)\n        this._emitApply(name)\n        return f()\n      })\n    )\n  }\n\n  /**\n   * Only run f() if all prior have finished, otherwise, no-op and wait until\n   * all pending have resolved.\n   */\n  oneRunAtATime<T>(name: N, f: () => Promise<T>): PromiseMaybe<T> {\n    return this.pending ? this.awaitAll() : this.serial(name, f)\n  }\n\n  /**\n   * If you don't care about the returned promise: only run f() if all prior have\n   * finished, and return no-op otherwise\n   */\n  maybeRun<T>(name: N, f: () => Promise<T>): Maybe<Promise<T>> {\n    return this.maybeRunConcurrent(name, f, 1)\n  }\n\n  /**\n   * If you don't care about the returned promise: only run f() if fewer than maxConcurrent\n   */\n  maybeRunConcurrent<T>(\n    name: N,\n    f: () => Promise<T>,\n    maxConcurrent = maxCpus()\n  ): Maybe<Promise<T>> {\n    return this.pendingCount >= maxConcurrent ? undefined : this.push(name, f)\n  }\n\n  get pendingCount() {\n    // We don't want to muck with _arr state, so use this._arr directly:\n    return count(this._arr, ea => ea.pending)\n  }\n\n  get pending() {\n    return this.pendingCount > 0\n  }\n\n  pendingNames(): N[] {\n    return this.arr.map(ea => ea.name) as N[]\n  }\n\n  get settled() {\n    // this.arr is a getter that does vacuuming\n    return this.arr.length === 0\n  }\n\n  /**\n   * @return a promise that will be resolved when all previously-pushed Promises\n   * are resolved. Any promise rejection will throw the whole chain.\n   */\n  async awaitAll() {\n    // NOTE: don't use Promise.all here, it doesn't seem to scale.\n    for (const ea of [...this.arr]) {\n      await ea.promise\n    }\n    return undefined\n  }\n\n  async awaitAllByName(name: N) {\n    // NOTE: don't use Promise.all here, it doesn't seem to scale.\n    for (const ea of [...this.arr]) {\n      if (ea.name === name) await ea.promise\n    }\n    return undefined\n  }\n\n  async pushAll<T>({\n    name,\n    laters,\n    maxConcurrent = maxCpus()\n  }: {\n    name: N\n    laters: Later<T>[]\n    maxConcurrent?: number\n  }): Promise<T[]> {\n    maxConcurrent = clamp(1, maxCpus() * 2, maxConcurrent)\n    const results: Promise<T>[] = []\n    for (const later of laters) {\n      while (this.pendingCount >= maxConcurrent) {\n        await this.awaitNextSettled()\n      }\n      results.push(this.push(name, later))\n    }\n    return Promise.all(results)\n  }\n}\n\n/**\n * Run the given thunk never more than once concurrently. Invocations while\n * prior runs were invoked will return after prior runs have completed but will\n * be no-ops.\n */\nexport function oneRunAtATime<T>(name: string, l: Later<T>): LaterMaybe<T> {\n  const p = new Promises()\n  return () => p.oneRunAtATime(name, l)\n}\n\n/**\n * Run the given thunk never more than once concurrently. Invocations while\n * prior runs were invoked will return after prior runs have completed but will\n * be no-ops.\n */\nexport function maybeRun<T>(\n  name: string,\n  l: Later<T>\n): () => Maybe<Promise<T>> {\n  const p = new Promises()\n  return () => p.maybeRun(name, l)\n}\n\n/**\n * Run the given thunk never more than once concurrently. Invocations while\n * prior runs were invoked will be started after all prior runs have finished.\n */\nexport function serially<T>(name: string, l: Later<T>): Later<T> {\n  const p = new Promises()\n  return () => p.serial(name, l)\n}\n\nexport async function withBoundedConcurrency<T>({\n  name,\n  laters,\n  maxConcurrent\n}: {\n  name: string\n  laters: Later<T>[]\n  maxConcurrent?: number\n}): Promise<T[]> {\n  // SITS: NOTE: if we share the same Promises instance, and a code block within\n  // withBoundedConcurrency calls withBoundedConcurrency, we'll starve.\n  return new Promises().pushAll({ name, laters, maxConcurrent })\n}\n", "import { compact, isEmpty, isNotEmpty, sortBy, uniq } from \"../../fe/Array\"\nimport { isFalse, isTrue } from \"../../fe/Boolean\"\nimport { secondMs } from \"../../fe/Date\"\nimport { unrefDelay } from \"../../fe/Delay\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport {\n  Maybe,\n  MaybeNull,\n  MaybePromiseMaybe,\n  PromiseMaybe\n} from \"../../fe/MaybeTypes\"\nimport { isFunction } from \"../../fe/ObjectType\"\nimport { MaybeSyncOrAsync, SyncOrAsync } from \"../../fe/OptAsync\"\nimport { Primitive } from \"../../fe/Primitive\"\nimport { thenMap } from \"../../fe/Promise\"\nimport { Thunk } from \"../../fe/Thunk\"\nimport { toA } from \"../../fe/toA\"\nimport { batches, greatestBy } from \"../Array\"\nimport { identity } from \"../Object\"\nimport { withBoundedConcurrency } from \"./Promises\"\nimport { thenOrTimeout } from \"./thenOrTimeout\"\n\n// TODO: INLINE\nexport { thenMap } from \"../../fe/Promise\"\n\nexport async function thenCollectBatched<T1, T2>(\n  arr: MaybeSyncOrAsync<MaybeSyncOrAsync<T1>[]>,\n  batchSize: number,\n  f: (arr: T1[]) => MaybeSyncOrAsync<T2[]>\n) {\n  const result: T2[] = []\n  for (const batchArr of batches(toA(await arr), batchSize)) {\n    const batchInput: T1[] = []\n    for (const ea of batchArr) {\n      if (ea != null) {\n        const v = await ea\n        if (v != null) {\n          batchInput.push(v)\n        }\n      }\n    }\n    for (const ea of toA(await f(batchInput))) {\n      if (ea != null) {\n        result.push(ea)\n      }\n    }\n  }\n  return result\n}\n\nexport async function thenMapResolved<T1, T2>(\n  objP: MaybeSyncOrAsync<T1>,\n  f: (t: T1) => MaybeSyncOrAsync<T2>\n): PromiseMaybe<T2> {\n  if (objP == null) return Promise.resolve(undefined)\n  try {\n    return await thenMap(objP, f)\n  } catch (e) {\n    return undefined\n  }\n}\n\nexport function resolvedWithin<T>(\n  p: Promise<T>,\n  withinMs: number\n): Promise<boolean> {\n  return Promise.race([\n    p.then(() => true),\n    unrefDelay(withinMs).then(() => false)\n  ]).catch(() => false)\n}\n\nexport async function resolved(p: Promise<any>): Promise<boolean> {\n  try {\n    await p\n    return true\n  } catch (e) {\n    return false\n  }\n}\n\nexport async function rejected(p: Promise<any>): Promise<boolean> {\n  return !(await resolved(p))\n}\n\nexport async function thenDefined(p: Promise<any>): Promise<boolean> {\n  return (await p) != null\n}\n\nexport async function allSerial<T>(\n  arr: Maybe<() => MaybePromiseMaybe<T>>[]\n): Promise<T[]> {\n  const result: Maybe<T>[] = []\n  for (const ea of compact(arr)) {\n    result.push(await ea())\n  }\n  return compact(result)\n}\n\nexport async function awaitAll(\n  arr: Maybe<(PromiseMaybe<any> | any)[]>\n): Promise<void> {\n  const ea = compact(arr)\n  if (isNotEmpty(ea)) {\n    await Promise.all(ea)\n  }\n}\n\n// maybeist champion:\nexport async function thenFlatten<T>(\n  arr: MaybeSyncOrAsync<MaybeSyncOrAsync<T | MaybeSyncOrAsync<T>[]>[]>\n): Promise<T[]> {\n  const result: T[] = []\n  for (const ea of toA(await arr)) {\n    const v = await ea\n    if (v != null) {\n      if (Array.isArray(v)) {\n        for (const ea2 of v) {\n          const v2 = await ea2\n          if (v2 != null) result.push(v2)\n        }\n      } else {\n        result.push(v)\n      }\n    }\n  }\n  return result\n}\n\nexport async function thenCompact<T>(\n  arr: MaybeSyncOrAsync<MaybeSyncOrAsync<T>[]>\n): Promise<T[]> {\n  const c = compact(await arr)\n  return isEmpty(c) ? [] : compact(await Promise.all(c))\n}\n\nexport async function thenUniq<T>(\n  arr: MaybeSyncOrAsync<MaybeSyncOrAsync<T>[]>\n): Promise<T[]> {\n  const result: T[] = []\n  for (const ea of toA(await arr)) {\n    const v = await ea\n    if (v != null) {\n      result.push(v)\n    }\n  }\n  return uniq(result)\n}\n\nexport async function asyncFind<T>(\n  arr: T[],\n  f: (t: T) => Promise<boolean>\n): PromiseMaybe<T> {\n  for (const ea of arr) {\n    if (await f(ea)) return ea\n  }\n  return\n}\n\n/**\n * For each in `V[]`, apply `f(v)` concurrently, returning `[v, await f(v)]`\n * @see thenCollect\n */\nexport async function thenCollectParallel<T, V>(\n  arr: Maybe<MaybeSyncOrAsync<Maybe<T>[]>>,\n  f: (t: T, index: number) => SyncOrAsync<Maybe<V>>,\n  maxConcurrent?: number\n): Promise<[V, T][]> {\n  if (arr == null) return []\n  const array = compact(await arr)\n  if (isEmpty(array)) return []\n  const t = await withBoundedConcurrency({\n    name: \"thenCollectParallel\",\n    laters: array.map((ea, index) => async () =>\n      [await f(ea, index), ea] as [V, T]\n    ),\n    maxConcurrent\n  })\n  return t.filter(([k, v]) => k != null && v != null)\n}\n\nexport async function mapAsync<T, V>(\n  arr: Maybe<MaybeSyncOrAsync<Maybe<T>[]>>,\n  f: (t: T, index: number) => SyncOrAsync<Maybe<V>>,\n  maxConcurrent?: number\n): Promise<V[]> {\n  return (await thenCollectParallel(arr, f, maxConcurrent)).map(ea => ea[0])\n}\n\n/**\n * @return all items in `arr` that `f` returns true or Promise<true>\n */\nexport async function filterAsync<T>(\n  arr: Maybe<T>[],\n  f: (t: T) => Maybe<boolean> | PromiseMaybe<boolean>,\n  maxConcurrent?: number\n): Promise<T[]> {\n  const t = await thenCollectParallel(compact(arr), f, maxConcurrent)\n  return t.filter(([b]) => b).map(([, v]) => v)\n}\n\nexport async function partitionAsync<T>(\n  arr: T[],\n  filter: (t: T, index: number) => MaybeSyncOrAsync<boolean>\n): Promise<[T[], T[]]> {\n  const t = await thenCollectParallel(arr, filter)\n  return [\n    t.filter(([ea]) => isTrue(ea)).map(([, ea]) => ea),\n    t.filter(([ea]) => isFalse(ea)).map(([, ea]) => ea)\n  ]\n}\n\nexport async function tryAsync<T>(f: () => T | Promise<T>) {\n  try {\n    return await f()\n  } catch {\n    return\n  }\n}\n\nexport const DefaultTryAllTimeoutMs = 30 * secondMs\n\nexport async function tryAll(\n  arr: (any | (() => any))[],\n  onError = (err: Error) => console.error(err),\n  timeoutMs = DefaultTryAllTimeoutMs\n): Promise<void> {\n  for (const ea of arr) {\n    try {\n      await thenOrTimeout(ea, timeoutMs)\n    } catch (err) {\n      onError(err)\n    }\n  }\n  return\n}\n\nexport async function thenFinally<T>(\n  p: SyncOrAsync<T> | (() => SyncOrAsync<T>),\n  err_: (err: Error | any) => any = () => {\n    // no-op\n  },\n  finally_: (r: T | Error) => any = () => {\n    // no-op\n  }\n): Promise<T> {\n  let result: T\n  let caught = null\n  try {\n    result = await (isFunction(p) ? p() : p)\n  } catch (err) {\n    caught = err\n    try {\n      await err_(err)\n    } catch {\n      // no-op\n    }\n  }\n  try {\n    await finally_(caught != null ? caught : result!)\n  } catch {\n    // no-op\n  }\n  if (caught != null) {\n    throw caught\n  } else {\n    return result!\n  }\n}\n\nexport async function thenNot(\n  p: MaybePromiseMaybe<boolean>,\n  nullIsFalse = true\n): Promise<boolean> {\n  if (p == null) return nullIsFalse\n  const r = await p\n  return r == null ? nullIsFalse : !isTrue(r)\n}\n\nexport async function thenMap2<T1, T2, T3>(\n  objP1: MaybeSyncOrAsync<T1>,\n  objP2: MaybeSyncOrAsync<T2>,\n  f: (t1: T1, t2: T2) => MaybeSyncOrAsync<T3>\n): PromiseMaybe<T3> {\n  const o1 = await objP1\n  if (o1 == null) return\n  const o2 = await objP2\n  if (o2 == null) return\n  return f(o1, o2)\n}\n\n/**\n * Safe calls for Optional promises, with default\n */\nexport async function thenMapOr<T1, T2, T3>(\n  objP: MaybeSyncOrAsync<T1>,\n  f: (t: T1) => MaybeSyncOrAsync<T2>,\n  ifUndefined: () => SyncOrAsync<T3>\n): Promise<T2 | T3> {\n  const obj = await objP\n  if (obj == null) return ifUndefined()\n  const result = await f(obj)\n  return result == null ? ifUndefined() : result\n}\n/**\n * Safe calls for Optional promises, with default\n */\nexport async function thenMap2Or<A1, A2, R1, R2>(\n  objP1: MaybeSyncOrAsync<A1>,\n  objP2: MaybeSyncOrAsync<A2>,\n  f: (t1: A1, t2: A2) => MaybeSyncOrAsync<R1>,\n  ifUndefined: () => SyncOrAsync<R2>\n): Promise<R1 | R2> {\n  const o1 = await objP1\n  if (o1 == null) return ifUndefined()\n  const o2 = await objP2\n  if (o2 == null) return ifUndefined()\n  const result = await f(o1, o2)\n  return result == null ? ifUndefined() : result\n}\n\n/**\n * Only call f if the promise resolves to truthy\n */\nexport async function thenAnd<T>(\n  predicatePromise: MaybeNull<Promise<true | any>>,\n  f: () => SyncOrAsync<T>\n): PromiseMaybe<T> {\n  return predicatePromise != null && isTrue(await predicatePromise)\n    ? f()\n    : undefined\n}\n\nexport async function thenOrElse<T>(\n  objP: Promise<MaybeNull<T>> | MaybeNull<T>,\n  f: () => SyncOrAsync<T>\n): Promise<T> {\n  return orElse(await objP, f)\n}\n\n/**\n * Just like `firstDefinedPromise` but applies a function to all defined\n * elements in `arr`.\n */\nexport async function first<T, R>(\n  arr: Maybe<Maybe<T>[]>,\n  f: (t: T, index: number) => SyncOrAsync<MaybeNull<R>>\n): PromiseMaybe<R> {\n  if (arr != null) {\n    let index = -1\n    for (const t of arr) {\n      index++\n      try {\n        if (t == null) continue\n        const r = await f(t, index)\n        if (r != null) {\n          return r\n        }\n      } catch {\n        // no-op\n      }\n    }\n  }\n  return undefined\n}\n\n/**\n * @see #firstDefinedLater\n */\nexport async function firstDefinedPromise<T, U = T>(\n  promiseThunks: Thunk<MaybeSyncOrAsync<T>>[],\n  filter: (t: T) => SyncOrAsync<Maybe<U>> = identity as any\n): PromiseMaybe<U> {\n  for (const ea of promiseThunks) {\n    const o = await ea()\n    if (o != null) {\n      const result = await filter(o)\n      if (result != null) {\n        return result\n      }\n    }\n  }\n  return\n}\n\nexport async function firstResolvedDefinedPromise<T>(\n  promiseThunks: Thunk<MaybeSyncOrAsync<T>>[],\n  onError: (err: Error) => void\n): PromiseMaybe<T> {\n  for (const t of promiseThunks) {\n    try {\n      const result = await t()\n      if (result != null) {\n        return result\n      }\n    } catch (err) {\n      onError(err)\n    }\n  }\n  return\n}\n\nexport async function firstTruePromise<T>(\n  predicate: (t: T) => Maybe<boolean> | PromiseMaybe<boolean>,\n  ...promiseThunks: (() => MaybeSyncOrAsync<T>)[]\n): PromiseMaybe<T> {\n  for (const thunk of promiseThunks) {\n    try {\n      const ea = await thunk()\n      if (ea != null && (await predicate(ea)) === true) {\n        return ea\n      }\n    } catch (_) {\n      //\n    }\n  }\n  return\n}\n\nexport async function thenGreatest<T, V extends Primitive | Primitive[]>(\n  arr: T[],\n  f: (t: T) => PromiseMaybe<V>\n): PromiseMaybe<T> {\n  return map(\n    greatestBy(await thenCollectParallel(arr, f), ea => ea[0]),\n    ea => ea[1]\n  )\n}\n\n/**\n * @return `arr` sorted by the tuples in f. elements that `f` returns undefined\n * will be removed from the returned array.\n * @see https://en.wikipedia.org/wiki/Schwartzian_transform\n */\nexport async function sortByAsync<T, V extends Primitive | Primitive[]>(\n  arr: T[],\n  f: (t: T) => PromiseMaybe<V>\n): Promise<T[]> {\n  return sortBy(await thenCollectParallel(arr, f), ea => ea[0]).map(ea => ea[1])\n}\n", "import { readFileSync } from \"fs\"\nimport { arch, platform } from \"os\"\nimport _p from \"process\"\nimport { notBlank } from \"../fe/Blank\"\nimport { lazy } from \"../fe/Lazy\"\nimport { map } from \"../fe/Maybe\"\nimport { toS } from \"../fe/toS\"\nimport { isTrue } from \"../fe/Boolean\"\nimport { isEnvTrue } from \"./Env\"\n\nconst _platform = platform()\n\nexport const inspectFlag =\n  _p.argv.includes(\"--inspect\") || isTrue(_p.env.NODE_INSPECT)\n\n// Expect __filename to be something like\n// '/home/mrm/src/photostructure/src/library/dist/core/Platform.js' if we're not\n// web-packed.\nexport const isPacked = !toS(__filename).includes(\"Platform\")\n\nexport const isWin = _platform === \"win32\" || _platform === \"cygwin\"\nexport const isWinPortable = isWin && notBlank(_p.env.PORTABLE_EXECUTABLE_DIR)\n\nexport const isMac = _platform === \"darwin\"\n\nexport const isLinux = _platform === \"linux\"\nexport const isLinux_x64 = isLinux && arch() === \"x64\"\nexport const isArm = arch() === \"arm\"\nexport const isLinux_arm = isLinux && isArm\nexport const isLinuxAppImage =\n  isLinux && (notBlank(_p.env.APPIMAGE) || notBlank(_p.env.APPDIR))\nexport const isLinuxSnap = isLinux && notBlank(_p.env.SNAP_USER_DATA)\n\nexport const isPosix = isMac || isLinux\n\nexport const PS_IS_ELECTRON = \"PS_IS_ELECTRON\"\nexport const PS_IS_DOCKER = \"PS_IS_DOCKER\"\n\nexport const isElectron =\n  // PS_IS_ELECTRON is a workaround because versions.electron doesn't exist if\n  // ELECTRON_RUN_AS_NODE is set (!!)\n  _p.versions[\"electron\"] != null || isTrue(_p.env[PS_IS_ELECTRON])\n\nexport function setIsDocker(b: boolean) {\n  if (b) {\n    _p.env[PS_IS_DOCKER] = \"1\"\n  } else {\n    delete _p.env[PS_IS_DOCKER]\n  }\n}\n\n// NOTE: don't lazy this without fixing setIsDocker\nexport function isDocker() {\n  // PS_IS_DOCKER is set by the Dockerfile and by tests:\n  return (\n    isLinux &&\n    (isEnvTrue(PS_IS_DOCKER) ||\n      // TODO: this was set in earlier Dockerfiles (and could probably be removed)\n      isEnvTrue(\"PS_DOCKER\"))\n  )\n\n  // NOTE TO THE FUTURE: we used to parse out the owner from /proc/1/cgroup\n  // but that wasn't guaranteed to be \"docker\". Just using an environment flag\n  // is much safer.\n}\n\nexport const isRaspberryPi = lazy(\n  () => isLinux_arm && toS(procDeviceModel()).startsWith(\"Raspberry Pi\")\n)\n\n/**\n * This seems to only be set on Raspberry PIs:\n */\nexport const procDeviceModel = lazy(() => {\n  try {\n    return isLinux\n      ? map(readFileSync(\"/proc/device-tree/model\"), toS)\n      : undefined\n  } catch {\n    return\n  }\n})\n\n/**\n * Compatible with electron-builder:\n */\nexport type Platform = \"win\" | \"mac\" | \"linux\"\n\nexport const platformName: Platform = isWin\n  ? \"win\"\n  : isMac\n  ? \"mac\"\n  : isLinux\n  ? \"linux\"\n  : (_platform as any) // < punt\n", "import { hourMs, minuteMs, secondMs } from \"../../fe/Date\"\nimport { MiB } from \"../../fe/Units\"\n\n/**\n * This needs to be short enough to pick up when drives are inserted or ejected\n * in reasonable-ish time, but not so often it breaks the OS\n */\nexport const MountpointsTtlMs = 15 * secondMs\n\n/**\n * Update frequently enough to detect substantive changes in available bytes\n */\nexport const LongMountpointsTtlMs = 5 * minuteMs\n\n/**\n * How long the `df` or `wmic` should be allowed to run before timing out. Note\n * that external hard drives can take longer than 10 seconds to spin up...\n */\n// There were filesystem timeout errors with 25 seconds, so bumping up to 35.\nexport const CmdTimeoutMs = 35 * secondMs\n\n/**\n * For commands that don't need to wait for a disk to spin up, and only return\n * something like --version:\n */\nexport const ShortCmdTimeoutMs = 7 * secondMs\n\n/**\n * Volume UUIDs should never change, so this is long.\n */\nexport const LongTtlMs = 1 * hourMs\n\n/**\n * The worst-expected transfer rate for file I/O:\n */\nexport const MinIoRate = secondMs / (2 * MiB)\n", "import { secondMs } from \"../../fe/Date\"\n\nexport const StatTimeoutMs = 25 * secondMs\n", "import { ChildProcess } from \"child_process\"\nimport { Socket } from \"net\"\nimport {\n  Duplex,\n  pipeline,\n  Readable,\n  Transform,\n  TransformCallback\n} from \"stream\"\nimport { promisify } from \"util\"\nimport { unrefDelay } from \"../../fe/Delay\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe, MaybeNull } from \"../../fe/MaybeTypes\"\nimport { maybeCall } from \"../../fe/Object\"\nimport { NoOp } from \"../../fe/Thunk\"\nimport { ending } from \"../async/Endable\"\nimport { isIgnorableError } from \"../error/ErrorTypes\"\nimport { Try } from \"../Object\"\n\nexport class ReadableBuffer extends Readable {\n  constructor(buffer: Buffer) {\n    super()\n    this.push(buffer)\n    this.push(null)\n  }\n}\n\nexport class PassthroughStream extends Duplex {\n  _write(chunk: any, encoding: BufferEncoding) {\n    this.push(chunk, encoding)\n  }\n}\n\n// I don't want to just Pick<Writable, \"end\"> because I don't want to require\n// all the overloaded signatures as well.\nexport interface EndableStream {\n  end(chunk: any, cb?: () => void): void\n}\n\nexport async function endStream(\n  endable: MaybeNull<EndableStream>\n): Promise<void> {\n  if (endable == null) return\n  Try(() => maybeCall(endable, \"unref\"))\n  if (ending()) {\n    endable.end(null)\n  } else {\n    // Half-closes the socket (!!)\n    await new Promise<void>(resolve => endable.end(null, resolve))\n  }\n  await unrefDelay(50)\n\n  // Ensures that no more I/O activity happens on this socket\n  Try(() => maybeCall(endable, \"destroy\"))\n  return\n}\n\nexport interface ClosableStream {\n  close(callback: () => void): void\n}\n\nexport async function closeStream(\n  closable: Maybe<ClosableStream>\n): Promise<void> {\n  if (closable == null) return\n  Try(() => maybeCall(closable, \"unref\"))\n  if (ending()) {\n    closable.close(NoOp)\n  } else {\n    await new Promise<void>(resolve => closable.close(resolve))\n  }\n  // I don't think this is necessary (and caused errors with electron last year):\n  // await delay(50)\n  // Try(() => maybeCall(closable, \"destroy\"))\n  return\n}\n\nexport function onChildError(\n  cp: ChildProcess,\n  f: (src: \"cp\" | \"stdin\" | \"stdout\" | \"stderr\", err: Error) => void\n): void {\n  ;[\n    { name: \"cp\", ea: cp },\n    { name: \"stdin\", ea: cp.stdin },\n    { name: \"stdout\", ea: cp.stdout },\n    { name: \"stderr\", ea: cp.stderr }\n  ].forEach(({ name, ea }) =>\n    map(ea, ea2 =>\n      ea2.on(\"error\", err => {\n        if (!isIgnorableError(err)) f(name as any, err)\n      })\n    )\n  )\n}\n\nexport function closeStreams(cp: ChildProcess) {\n  for (const ea of [cp?.stdin, cp?.stdout, cp?.stderr]) {\n    try {\n      ea?.destroy()\n    } catch {\n      //\n    }\n  }\n}\n\nexport const pipelineAsync = promisify(pipeline)\n\nexport type Pipeline = [\n  NodeJS.ReadableStream,\n  ...(NodeJS.ReadWriteStream | NodeJS.WritableStream)[]\n]\n\nexport function remoteDesc(s: Socket): string {\n  return s.destroyed\n    ? \"destroyed\"\n    : `${s.remoteFamily}:${s.remoteAddress}:${s.remotePort}`\n}\n\nexport class ByteCounter extends Transform {\n  private bytes = 0\n  constructor(readonly onProgress: (bytes: number) => any) {\n    super({\n      transform: (\n        chunk: any,\n        _encoding: BufferEncoding,\n        callback: TransformCallback\n      ) => {\n        this.onProgress((this.bytes += chunk.length))\n        callback(chunk)\n      }\n    })\n  }\n}\n", "import { homedir } from \"os\"\nimport { resolve } from \"path\"\nimport { compactBlanks } from \"../fe/Array\"\nimport { lazy } from \"../fe/Lazy\"\nimport { getEnv } from \"./Env\"\nimport { isDirectorySync } from \"./fs/Path\"\nimport { isWin } from \"./Platform\"\n\nexport const homeDir = lazy(() => {\n  const paths = []\n  if (isWin) {\n    // cygwin may mess with HOMEPATH and HOME. Only trust USERPROFILE.\n    paths.push(getEnv(\"USERPROFILE\"))\n  } else {\n    paths.push(getEnv(\"HOME\"))\n  }\n  for (const ea of compactBlanks(paths)) {\n    const d = resolve(ea)\n    if (isDirectorySync(d)) return d\n  }\n  return homedir()\n})\n", "import { compactBlanks } from \"../fe/Array\"\nimport { AppName } from \"./AppName\"\nimport { getEnv } from \"./Env\"\nimport { isDirectorySync, resolve } from \"./fs/Path\"\nimport { homeDir } from \"./HomeDir\"\nimport { isDocker, isMac, isWin } from \"./Platform\"\n\nexport function defaultCacheDir() {\n  if (isDocker() && isDirectorySync(\"/ps/cache\")) {\n    return \"/ps/cache\"\n  }\n\n  if (isWin) {\n    for (const ea of compactBlanks([getEnv(\"TEMP\"), getEnv(\"LOCALAPPDATA\")])) {\n      if (isDirectorySync(ea)) return resolve(ea, AppName())\n    }\n  }\n\n  if (isMac) {\n    const d = resolve(homeDir(), \"Library\", \"Caches\")\n    if (isDirectorySync(d)) return resolve(d, AppName())\n  }\n\n  // .cache directories on posix seem to be uniformly lowercase:\n  return resolve(homeDir(), \".cache\", AppName().toLowerCase())\n}\n", "import { resolve } from \"path\"\nimport { appData } from \"./AppData\"\nimport { SimpleAppName } from \"./AppName\"\nimport { homeDir } from \"./HomeDir\"\nimport { isDocker, isMac } from \"./Platform\"\n\nexport function defaultLogDir() {\n  return isDocker()\n    ? \"/ps/logs\"\n    : isMac\n    ? resolve(homeDir(), \"Library\", \"Logs\", SimpleAppName.toLowerCase())\n    : defaultPosixLogDir()\n}\n\nexport function defaultPosixLogDir() {\n  return resolve(appData(), SimpleAppName.toLowerCase(), \"logs\")\n}\n", "import { statSync } from \"fs\"\nimport { mkdirpSync } from \"fs-extra\"\nimport { resolve } from \"path\"\nimport { env } from \"process\"\nimport { compactBlanks } from \"../fe/Array\"\nimport { lazy } from \"../fe/Lazy\"\nimport { getEnv } from \"./Env\"\nimport { FatalErrorFlag } from \"./error/ErrorTypes\"\nimport { homeDir } from \"./HomeDir\"\nimport { isDocker, isMac, isPosix, isWin } from \"./Platform\"\n\n/**\n * @return PS_CONFIG_DIR, ~/AppData/Roaming, or ~/Library/Application Support, or ~/.config\n */\nexport const appData = lazy(() => {\n  // lazy because this hits the filesystem and shouldn't ever change\n  const maybePaths = [\n    // We're not resolving the env value. If they give us something crazy, just go with it.\n    env.PS_CONFIG_DIR, // < this should override APPDATA or XDG_*_HOME values.\n    isDocker() ? \"/ps/config\" : undefined\n  ]\n\n  // %APPDATA% is C:\\Users\\username\\AppData\\Roaming\n  if (isWin) {\n    maybePaths.push(getEnv(\"APPDATA\"))\n    maybePaths.push(resolve(homeDir(), \"AppData\", \"Roaming\"))\n  }\n\n  if (isMac) {\n    maybePaths.push(resolve(homeDir(), \"Library\", \"Application Support\"))\n  }\n\n  // See https://specifications.freedesktop.org/freedesktop-platform-specs/1.0/basedir-spec-0.6/ar01s03.html\n  if (!isMac && isPosix) {\n    maybePaths.push(\n      getEnv(\"XDG_DATA_HOME\"),\n      getEnv(\"XDG_CONFIG_HOME\"),\n      resolve(homeDir(), \".config\")\n    )\n  }\n\n  const paths = compactBlanks(maybePaths)\n\n  // Return the first path that exists:\n  for (const ea of paths) {\n    try {\n      if (statSync(ea).isDirectory()) return ea\n    } catch {\n      //\n    }\n  }\n\n  // Otherwise, try to return the first path that we can make:\n  for (const ea of paths) {\n    try {\n      mkdirpSync(ea)\n      return ea\n    } catch {\n      console.error(\"Failed to mkdirp \" + ea)\n    }\n  }\n\n  throw new Error(\"Cannot determine appData\" + FatalErrorFlag)\n})\n", "export const version = \"1.0.0-alpha.1\";\nexport const release = \"1.0.0-alpha.1+20210314162034\";\nexport const gitSha = \"35109a3849a633155ab4c6b37c09648c754e6669\";\nexport const gitDate = new Date(1615764034000);\nexport default { version, release, gitSha, gitDate };\n", "import { version } from \"./Version\"\n\nexport const isAlphaVersion = () => version.includes(\"-alpha\")\nexport const isBetaVersion = () => version.includes(\"-beta\")\nexport const channel = () =>\n  isAlphaVersion() ? \"alpha\" : isBetaVersion() ? \"beta\" : \"latest\"\n\n/**\n * @return \"1.2.3\", even if `version` is \"1.2.3-alpha.0\" or \"1.2.3-beta.32\"\n */\nexport const baseVersion = () => version.split(\"-\")[0]\n", "import { resolve } from \"path\"\nimport { notBlank } from \"../fe/Blank\"\nimport { lazy } from \"../fe/Lazy\"\nimport { homeDir } from \"./HomeDir\"\nimport { isWin } from \"./Platform\"\nimport { PowerShell } from \"./pwsh/PowerShell\"\n\nexport async function picturesDirWindows() {\n  return isWin\n    ? PowerShell.instance().executeJson(\n        `Get-ItemPropertyValue \"Registry::HKEY_CURRENT_USER\\\\SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Explorer\\\\User Shell Folders\" -name \"My Pictures\"`\n      )\n    : undefined\n}\n\nexport const picturesDir = lazy(async () => {\n  if (isWin) {\n    const result = await picturesDirWindows()\n    if (notBlank(result)) return result\n  }\n  return defaultPicturesDir()\n})\n\nexport const defaultPicturesDir = lazy(() => resolve(homeDir(), \"Pictures\"))\n", "import { BatchCluster, Parser, Task } from \"batch-cluster\"\nimport { blank, mapNotBlankOr, notBlank } from \"../../fe/Blank\"\nimport { minuteMs, secondMs } from \"../../fe/Date\"\nimport { later } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { Endable, EndableRanks, ending } from \"../async/Endable\"\nimport { thenMap } from \"../async/Promise\"\nimport { thenOrTimeout } from \"../async/thenOrTimeout\"\nimport { until } from \"../async/until\"\nimport { BatchClusterObserver } from \"../BatchClusterObserver\"\nimport { execFile } from \"../child/ChildProcess\"\nimport { elapsedAsync } from \"../Elapsed\"\nimport { onClearCache } from \"../event/EventEmitter\"\nimport { ms2level } from \"../log/Logger\"\nimport { mkLogger } from \"../Logger\"\nimport { isTest } from \"../NodeEnv\"\nimport { Pojo } from \"../Object\"\nimport { isWin } from \"../Platform\"\nimport { Settings } from \"../settings/Settings\"\nimport { ellipsize, ensureSuffix, stripPrefix } from \"../String\"\nimport { CmdTimeoutMs, ShortCmdTimeoutMs } from \"../volumes/VolumeTtls\"\nimport { maxCpus } from \"../work/MaxCpus\"\n\nconst maxProcAgeMillis = 10 * minuteMs\n\nconst Done = \"{ready}\"\n\nconst ConvertToCompressedJson = \" | ConvertTo-Json -Compress\"\n\nexport type Result = { stdout: string; stderr?: string; passed: boolean }\n\nexport interface PowerShellVersion {\n  Major: number\n  Minor: number\n  Build: number\n  Revision: number\n  MajorRevision: number\n  MinorRevision: number\n}\n\nexport function pwshQuote(s: string): string {\n  const s2 = s\n    .replace(/['`\"\u201C\u201D#]/g, ea => \"`\" + ea)\n    .replace(/\\0/g, \"`0\")\n    .replace(/\\n/g, \"`n\")\n    .replace(/\\r/g, \"`r\")\n    .replace(/\\t/g, \"`t\")\n    .replace(/\\v/g, \"`v\")\n  return '\"' + s2 + '\"'\n}\n\nfunction versionCommand() {\n  return [\n    `function prompt {\"${Done}\"}`,\n    ...mapNotBlankOr(\n      Settings.powerShellCulture.valueOrDefault,\n      ea => [\n        `[System.Threading.Thread]::CurrentThread.CurrentCulture = '${ea}'`,\n        `[System.Threading.Thread]::CurrentThread.CurrentUICulture = '${ea}'`\n      ],\n      []\n    )\n  ].join(\";\")\n}\n\nlater(() => onClearCache(() => PowerShell.instance.prior()?.clearMockResults()))\n\nexport class PowerShell implements Endable {\n  readonly name = \"PowerShell\"\n  static readonly instance = lazy(() => {\n    if (!isWin) throw new Error(\"PowerShell isn't available on this platform\")\n    return new PowerShell()\n  })\n  private readonly logger = mkLogger(\"PowerShell\")\n  private readonly bco: BatchClusterObserver<BatchCluster>\n  private readonly pwsh: BatchCluster\n  private readonly mockResults = new Map<string, Result>()\n\n  private constructor() {\n    this.bco = new BatchClusterObserver(\n      \"PowerShell\",\n      new BatchCluster({\n        processFactory: () =>\n          execFile(\n            \"powershell\",\n            Settings.powerShellArgs.values,\n            maxProcAgeMillis\n          ),\n        logger: () => mkLogger(\"PowerShell\"),\n        versionCommand: versionCommand(),\n        pass: Done,\n        fail: \"Error\",\n        exitCommand: \"exit\",\n        maxProcs: maxCpus() > 6 ? 3 : 2,\n        maxTasksPerProcess: 150, // based on absolutely nothing\n        taskTimeoutMillis: CmdTimeoutMs,\n        cleanupChildProcs: false\n      }),\n      EndableRanks.postdb // last to shut down.\n    )\n    this.pwsh = this.bco.t\n  }\n\n  get lastStartError() {\n    return this.bco.lastStartError\n  }\n\n  get lastTaskError() {\n    return this.bco.lastTaskError\n  }\n\n  end() {\n    return this.pwsh.end()\n  }\n\n  get ended() {\n    return this.pwsh.ended\n  }\n\n  versionPojo(): PromiseMaybe<PowerShellVersion> {\n    return this.executeJson(\"$PSVersionTable.PSVersion\")\n  }\n\n  version(): PromiseMaybe<string> {\n    return thenMap(\n      this.executeJson(\"$PSVersionTable.PSVersion\"),\n      ea => `${ea.Major}.${ea.Minor}.${ea.Build}`\n    )\n  }\n\n  get spawnedProcs() {\n    return this.pwsh.spawnedProcs\n  }\n\n  pushMockJsonResult(cmd: string, result: Result) {\n    this.pushMockResult(ensureSuffix(cmd, ConvertToCompressedJson), result)\n  }\n\n  pushMockResult(cmd: string, result: Result) {\n    this.mockResults.set(cmd, result)\n  }\n\n  clearMockResults() {\n    this.mockResults.clear()\n  }\n\n  async execute<T>(cmd: string, parser: Parser<T>): PromiseMaybe<T> {\n    if (this.pwsh.ended || ending()) {\n      this.logger.warn(\"execute() failed (ended)\", { cmd })\n      return\n    }\n\n    if (isTest && this.mockResults.has(cmd)) {\n      const f = this.mockResults.get(cmd)!\n      return parser(f.stdout, f.stderr, f.passed)\n    }\n\n    try {\n      this.logger.debug(\"execute()\", { cmd })\n      const r = await elapsedAsync(() =>\n        this.pwsh.enqueueTask(\n          new Task(\n            cmd,\n            (stdout: string, stderr: string | undefined, passed: boolean) =>\n              parser(map(stdout, ea => stripPrefix(ea, cmd))!, stderr, passed)\n          )\n        )\n      )\n      // launching PowerShell may take upwards of 3-4 seconds normally:\n      this.logger.log(ms2level(r.elapsedMs, 7 * secondMs), \"execute()\", {\n        cmd,\n        elapsedMs: r.elapsedMs\n      })\n      return r.result\n    } catch (err) {\n      this.logger.warn(\"execute() failed: \" + err, { cmd })\n      return\n    }\n  }\n\n  async executeJson(cmd: string): PromiseMaybe<any> {\n    const r = await this.execute(\n      ensureSuffix(cmd, ConvertToCompressedJson),\n      (stdout, stderr, passed) => ({ stdout, stderr, passed })\n    )\n    if (r == null) {\n      this.logger.warn(\"executeJson(): null result\", { cmd })\n      return\n    }\n    if (blank(r.stdout) || notBlank(r.stderr) || !r.passed) {\n      this.logger.warn(\"executeJson(): failed result\", { cmd, ...r })\n      return\n    }\n    try {\n      return JSON.parse(r.stdout)\n    } catch (err) {\n      const fixed = r.stdout.replace(/\\\\/g, \"\\\\\\\\\")\n      this.logger.info(\n        \"executeJson(): parsing failed, trying dub-whack fix...\",\n        { before: ellipsize(r.stdout), after: ellipsize(fixed) }\n      )\n      return JSON.parse(fixed)\n    }\n  }\n\n  async executeJsonToA(cmd: string): PromiseMaybe<Pojo[]> {\n    return thenMap(this.executeJson(cmd), json =>\n      Array.isArray(json) ? json : [json]\n    )\n  }\n}\n\nexport async function checkPowerShell() {\n  if (!isWin) return\n  const ps = PowerShell.instance()\n  if (ps.ended || ending()) return\n  const version = await thenOrTimeout(() => ps.version(), 7 * secondMs)\n  if (version == null) {\n    const err = await until(() => orElse(ps.lastStartError, ps.lastTaskError), {\n      timeoutMs: ShortCmdTimeoutMs,\n      timeBetweenMs: 250\n    })\n    if (err != null) throw err\n    else throw new Error(\"(unknown error)\")\n  }\n  return\n}\n", "import { isFalse, isTrue } from \"../../fe/Boolean\"\nimport { delay, unrefDelay } from \"../../fe/Delay\"\nimport { orElse } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { clamp } from \"../../fe/Number\"\nimport { isFunction } from \"../../fe/ObjectType\"\nimport { MaybeSyncOrAsync } from \"../../fe/OptAsync\"\nimport { randomInt } from \"../../fe/Random\"\n\nexport type UntilOpts<T> = {\n  timeoutMs?: number\n  timeBetweenMs?: number\n  acceptable?: (t: Maybe<T>) => boolean\n  timeoutResult?: T\n  unref?: boolean\n}\n\nexport async function until<T>(\n  f: () => MaybeSyncOrAsync<T>,\n  { timeoutMs, timeBetweenMs, acceptable, timeoutResult, unref }: UntilOpts<T>\n): PromiseMaybe<T> {\n  const timeoutAt = timeoutMs == null ? undefined : timeoutMs + Date.now()\n  while (timeoutAt == null || Date.now() < timeoutAt) {\n    const start = Date.now()\n    const result = await f()\n    if (\n      result == null ||\n      (isFunction(acceptable) ? !acceptable(result) : (result as any) === false)\n    ) {\n      const elapsed = Date.now() - start\n      const delayMs = orElse(timeBetweenMs, () =>\n        clamp(100, 5000, elapsed * randomInt(4, 10))\n      )\n      await (isFalse(unref) ? delay(delayMs) : unrefDelay(delayMs))\n    } else {\n      return result\n    }\n  }\n  return timeoutResult\n}\n\n/**\n * Run the given thunk until the promise is resolved to true, or the timeout\n * passes.\n * @return false on timeout, or true when the the given Later returned true.\n */\n\nexport async function untilTrue(\n  f: () => MaybeSyncOrAsync<boolean>,\n  opts: UntilOpts<boolean>\n) {\n  return until(f, {\n    ...opts,\n    acceptable: (ea: Maybe<boolean>) => isTrue(ea),\n    timeoutResult: false\n  }) as Promise<boolean>\n}\n", "import { BatchCluster } from \"batch-cluster\"\nimport { ChildProcess } from \"child_process\"\nimport { ExifTool } from \"exiftool-vendored\"\nimport _p from \"process\"\nimport { minuteMs, secondMs } from \"../fe/Date\"\nimport { map } from \"../fe/Maybe\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { EndableRank, EndableRanks, ending } from \"./async/Endable\"\nimport { EndableWrapper } from \"./async/EndableWrapper\"\nimport { endProcess } from \"./child/ChildProcess\"\nimport { onError } from \"./error/Error\"\nimport { isIgnorableError } from \"./error/ErrorTypes\"\nimport { addPid } from \"./Pids\"\nimport { renice } from \"./Renice\"\nimport { CmdTimeoutMs } from \"./volumes/VolumeTtls\"\n\n/**\n * Rather than spork (the technical term for monkeypatching an instance that was\n * invented here) in a name field into the exiftool or batch cluster singleton,\n * just facade it to be an Endable\n */\nexport class BatchClusterObserver<\n  T extends ExifTool | BatchCluster\n> extends EndableWrapper {\n  lastStartError: Maybe<Error>\n  lastInternalError: Maybe<Error>\n  lastTaskError: Maybe<Error>\n\n  constructor(\n    readonly name: string,\n    readonly t: T,\n    rank: EndableRank = EndableRanks.service,\n    addExitHandler = false\n  ) {\n    super(\n      name,\n      () => this.t.end(),\n      rank,\n      () => this.t.ended,\n      name === \"sync-file\" ? CmdTimeoutMs : secondMs\n    )\n\n    t.on(\"childStart\", (cp: ChildProcess) => {\n      this.logger.info(\"Started child process \" + name + \":\" + cp.pid)\n      renice(cp.pid).catch(err =>\n        this.onError(\"renice failed for \" + name, err)\n      )\n\n      // zombie prevention of ExifTool on Alpine:\n      if (addExitHandler) {\n        cp.on(\"exit\", () => endProcess(cp, 5 * secondMs))\n      }\n\n      addPid(\n        {\n          pid: cp.pid,\n          ppid: _p.pid,\n          cmd: name,\n          maxAgeMs: t.options.maxProcAgeMillis + minuteMs\n        },\n        new Date()\n      ).catch(err => this.onError(\"addPid failed for \" + name, err))\n    })\n    t.on(\"startError\", error => {\n      this.lastStartError = error\n      this.onError(\"failed to start\", error)\n    })\n    t.on(\"taskError\", (error, task) => {\n      this.lastTaskError = error\n      this.onError(\"failed to run \" + map(task, ea => ea.command), error)\n    })\n    t.on(\"internalError\", error => {\n      this.lastInternalError = error\n      this.onError(\"internal error\", error)\n    })\n    t.on(\"endError\", err => {\n      this.logger.error(\"observeBatchCluster.endError()\", err)\n    })\n  }\n\n  onError(reason: string, error: Error) {\n    // Avoid stack overflow on end (where end error asks services to shut down,\n    // which causes an end error, which ...)\n    if (!this.t.ended && !ending() && !isIgnorableError(error)) {\n      onError(this.name + \": \" + reason, error)\n    } else {\n      this.logger.warn(\"onError() (ending or ignorable): \" + reason, error)\n    }\n  }\n}\n", "import { mapOr } from \"../../fe/Maybe\"\nimport { Logger, mkLogger } from \"../Logger\"\nimport { addEndable, Endable, EndableRank } from \"./Endable\"\nimport { awaitAll } from \"./Promise\"\n\n/**\n * Base class for Endables.\n */\nexport class EndableWrapper implements Endable {\n  readonly logger: Logger\n  protected readonly onEnds: (() => any)[] = []\n  private _ended = false\n  /**\n   * @param name for logging\n   * @param _onEnd called by `this.end()`. May return a promise.\n   * @param _isEnded if the wrapped instance can end from other state mutations,\n   * providing this method will allow this wrapper to be garbage collected.\n   */\n  // TODO: destructure?\n  constructor(\n    readonly name: string,\n    onEnd: () => Promise<any> | any,\n    rank: EndableRank,\n    private readonly _isEnded?: () => boolean,\n    readonly endTimeoutMs?: number\n  ) {\n    this.logger = mkLogger(name)\n    this.onEnds.push(onEnd)\n    addEndable(rank, this)\n  }\n\n  get ended() {\n    return (\n      mapOr(\n        this._isEnded,\n        f => f(),\n        () => false\n      ) || this._ended\n    )\n  }\n\n  end() {\n    // don't run onEnds more than once:\n    if (this._ended) return\n    this._ended = true\n    return awaitAll(this.onEnds.map(ea => ea()))\n  }\n}\n", "import _cp from \"child_process\"\nimport _p from \"process\"\nimport { retryOnReject } from \"../../fe/AsyncRetry\"\nimport { notBlank } from \"../../fe/Blank\"\nimport { secondMs } from \"../../fe/Date\"\nimport { delay, unrefDelay } from \"../../fe/Delay\"\nimport { stringify } from \"../../fe/JSON\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { denull, orElse } from \"../../fe/Maybe\"\nimport { gt0 } from \"../../fe/Number\"\nimport { omit, pick } from \"../../fe/Object\"\nimport { isFunction } from \"../../fe/ObjectType\"\nimport { toS } from \"../../fe/toS\"\nimport { Deferred } from \"../async/Deferred\"\nimport { thenNot } from \"../async/Promise\"\nimport { setUnrefTimeout } from \"../async/Timers\"\nimport { untilTrue } from \"../async/until\"\nimport { errorContains } from \"../error/Error\"\nimport { isIgnorableError } from \"../error/ErrorTypes\"\nimport { closeStreams, endStream } from \"../fs/Streams\"\nimport { mkLogger } from \"../Logger\"\nimport { isSingleSpecTests } from \"../NodeEnv\"\nimport { Try } from \"../Object\"\nimport { addPid, killPid, pidExists, Pids } from \"../Pids\"\nimport { isWin } from \"../Platform\"\nimport { renice } from \"../Renice\"\nimport { gist } from \"../String\"\nimport { spawnOptions } from \"./ChildEnv\"\n\nconst logger = lazy(() => mkLogger(\"ChildProcess\"))\n\nfunction cp2log(cp: _cp.ChildProcess) {\n  return pick(cp as any, \"pid\", \"killed\", \"connected\", \"exitCode\", \"signalCode\")\n}\n\nexport function waitForExit(pid: number, timeoutMs: number): Promise<boolean> {\n  return untilTrue(() => thenNot(pidExists(pid)), { timeoutMs })\n}\n\nexport async function endProcess(\n  cp: _cp.ChildProcess,\n  timeoutMs = 30 * secondMs\n): Promise<boolean> {\n  if (cp == null) return false\n\n  const pid = cp.pid\n  logger().debug(\"endProcess(\" + pid + \")\", {\n    killed: cp.killed,\n    connected: cp.connected\n  })\n  if (pid <= 0) {\n    logger().warn(\"endProcess(): asked to end invalid pid\", cp2log(cp))\n    return false\n  }\n  if (pid === _p.pid) {\n    logger().warn(\"endProcess(): asked to end MY pid\", cp2log(cp))\n    return false\n  }\n\n  // Let streams flush before closing:\n  await delay(250)\n  await closeStreams(cp)\n\n  {\n    // Send a SIGTERM\n    const killResult = cp.kill()\n    logger().debug(\"endProcess(\" + pid + \")\", {\n      killResult,\n      childGotSigterm: cp.killed\n    })\n    if (!killResult) {\n      await killPid(pid).catch(err => {\n        logger().warn(\"endProcess(): kill(\" + pid + \",false) failed: \" + err)\n      })\n    }\n  }\n\n  // We don't use messaging, but in case we do later:\n  // TODO: do we need to do this?\n  // if (cp.connected) Try(() => cp.disconnect())\n\n  // We can exit even if this child is still running:\n  Try(() => cp.unref())\n\n  // don't wait for cleanup if we're running tests:\n  if (isSingleSpecTests()) return true\n\n  if (await waitForExit(pid, timeoutMs)) {\n    logger().debug(\"endProcess(): exitted\", cp2log(cp))\n    return true\n  }\n\n  {\n    // OK, shite got real. time for kill -9.\n    void Pids.instance().onKill(pid)\n    const killResult = cp.kill(\"SIGKILL\")\n    logger().warn(\"endProcess(\" + pid + \") had to resort to SIGKILL\", {\n      killResult\n    })\n    if (!killResult) {\n      await killPid(pid, true).catch(err => {\n        logger().warn(\"endProcess(): kill(\" + pid + \",true) failed: \" + err)\n      })\n    }\n  }\n\n  // Give the OS some time to clean up:\n  return waitForExit(pid, 5000)\n}\n\nexport function niceable(\n  cmd: string,\n  args: string[] | readonly string[]\n): boolean {\n  return (\n    cmd !== \"renice\" &&\n    cmd !== \"which\" &&\n    cmd !== \"where\" && // windows version of \"which\"\n    [cmd, ...args].every(\n      ea =>\n        !ea.endsWith(\"web.js\") &&\n        !ea.endsWith(\"db.js\") &&\n        !ea.includes(\"sqlite3\")\n    )\n  )\n}\n\n// NOTE: MUST NOT BE ASYNC\nfunction newProc(\n  cp: _cp.ChildProcess,\n  cmd: string,\n  args: ReadonlyArray<string>,\n  maxAgeMs: number\n) {\n  const start = new Date()\n  // If we write the pidfile now and hold up processing, `cp.stderr` and\n  // `cp.stdout` event listeners will miss initial data, so we put this in a\n  // timeout for later.\n\n  // Note that THIS IS NOT UNREF'ed! We want pids to be cleaned up!\n\n  let exitted = false\n  cp.on(\"exit\", () => (exitted = true))\n\n  const _niceable = niceable(cmd, args)\n\n  setUnrefTimeout(\n    async () => {\n      if (exitted) return\n      await untilTrue(() => gt0(cp.pid), { timeoutMs: 5 * secondMs })\n      const pid = cp.pid\n      if (!gt0(pid)) {\n        logger().info(\n          \"newProc(): not writing pidfile, child_process has no pid\",\n          {\n            cmd,\n            cp: cp2log(cp)\n          }\n        )\n        return\n      } else {\n        if (_niceable) await renice(pid)\n        return addPid({ pid, cmd, maxAgeMs, ppid: _p.pid }, start)\n      }\n    },\n    isWin ? 500 : 250 // < windows regularly takes hundreds of millis to exec, and the fs is slow, so be nice/gentle on windows.\n  )\n  return cp\n}\n\nexport function spawn(\n  command: string,\n  args: ReadonlyArray<string>,\n  maxAgeMs: number,\n  options?: _cp.SpawnOptions\n): _cp.ChildProcess {\n  const opts = spawnOptions(options)\n  logger().debug(\"spawn()\", { command, args, maxAgeMs, opts })\n  return newProc(_cp.spawn(command, args, opts), command, args, maxAgeMs)\n}\n\nexport type ExecFileOptions =\n  | _cp.ExecFileOptions\n  | _cp.ExecFileOptionsWithBufferEncoding\n  | _cp.ExecFileOptionsWithStringEncoding\n\nexport function execFile(\n  command: string,\n  args: ReadonlyArray<string>,\n  maxAgeMs: number,\n  options?: ExecFileOptions\n): _cp.ChildProcess {\n  const opts = spawnOptions(options)\n  return newProc(_cp.execFile(command, args, opts), command, args, maxAgeMs)\n}\n\nexport type StdoutOpts = {\n  timeout: number\n  maxRetries?: number\n  quiet?: boolean\n  disconnect?: boolean\n  ignoreStderr?: boolean\n  ignoreExitCode?: boolean\n  isIgnorableError?: (err: any) => boolean\n} & _cp.ExecFileOptions\n\nexport type StdoutResult = {\n  result: string\n  pid: number\n  code?: number\n}\n\n/**\n * @throws on errors\n */\nexport async function stdoutResult(\n  cmd: string,\n  args: string[],\n  opts: StdoutOpts\n): Promise<StdoutResult> {\n  return retryOnReject(() => _stdoutResult(cmd, args, opts), {\n    timeoutMs: opts.timeout,\n    maxRetries: orElse(opts.maxRetries, 3),\n    onRetryWaitUntil: retryCount => unrefDelay(100 * retryCount),\n    errorIsRetriable: error =>\n      logger().tap({\n        msg: \"stdoutResult.errorIsRetriable()\",\n        result: errorContains(error, /EPERM/),\n        meta: { error, cmd, args }\n      })\n  })\n}\n\nasync function _stdoutResult(\n  cmd: string,\n  args: string[],\n  opts: StdoutOpts\n): Promise<StdoutResult> {\n  const quiet = orElse(opts.quiet, false)\n  const ignoreStderr = orElse(opts.ignoreStderr, false)\n  const ignoreExitCode = orElse(opts.ignoreExitCode, false)\n\n  const dataChunks: (Buffer | string)[] = []\n  logger().debug(\"stdoutResult(): execFile\", { cmd, args })\n  const proc = await execFile(\n    cmd,\n    args,\n    opts.timeout,\n    omit(\n      opts,\n      \"timeout\",\n      \"quiet\",\n      \"disconnect\",\n      \"ignoreStderr\",\n      \"ignoreExitCode\"\n    )\n  )\n\n  if (opts.disconnect === true) {\n    proc.disconnect()\n    return { result: \"\", pid: proc.pid }\n  }\n\n  const name = stringify({ cmd, args })\n  const d = new Deferred<StdoutResult>(name)\n  setTimeout(() => {\n    if (d.pending) {\n      logger().warn(\"stdoutResult(): SLOW COMMAND\", { cmd, args })\n    }\n  }, opts.timeout / 3).unref()\n\n  // timeout on linux and windows doesn't seem to work. We'll take care of it:\n  d.setTimeout(opts.timeout)\n\n  const onError = (ctx: string, error: any) => {\n    if (\n      isIgnorableError(error) ||\n      (isFunction(opts.isIgnorableError) && opts.isIgnorableError(error))\n    ) {\n      logger().debug(\"stdoutResult(): ignorable error for \" + ctx, {\n        cmd,\n        args,\n        opts,\n        error\n      })\n      return\n    }\n    if (proc.pid != null) {\n      void endProcess(proc)\n    }\n    if (!quiet)\n      logger().warn(\"stdoutResult(): \" + ctx, { cmd, args, opts, error })\n    if (d.pending) d.reject(error)\n  }\n  try {\n    proc.on(\"error\", err => onError(\"on(error)\", err))\n    proc.on(\"close\", code => {\n      const elapsedMs = Date.now() - d.start\n      const level = code !== 0 ? \"warn\" : \"debug\"\n      const result = dataChunks.join(\"\")\n      if (!quiet) {\n        logger().log(level, \"stdoutResult(): on(close)\", {\n          cmd,\n          code,\n          args,\n          elapsedMs,\n          result: gist(result, 160, 160)\n        })\n      }\n      if (!ignoreExitCode && code !== 0)\n        d.reject(\n          new Error(\"non-zero exit code: \" + stringify({ code, cmd, args }))\n        )\n      else d.resolve({ result, code: denull(code), pid: proc.pid })\n    })\n    void endStream(proc.stdin)\n    proc.stdout?.on(\"data\", ea => {\n      if (ea != null) dataChunks.push(ea)\n    })\n    proc.stderr?.on(\"error\", err => onError(\"stderr(error)\", err))\n    proc.stderr?.on(\"data\", err =>\n      ignoreStderr\n        ? logger().warn(\"stdoutResult(): stderr(data): \" + toS(err))\n        : onError(\"stderr(data)\", err)\n    )\n  } catch (err) {\n    onError(\"try/catch\", err)\n  }\n  return await d.promise\n}\n\n/**\n * @return just the stdout stream\n * @see stdoutResult if you need more information about the command.\n */\nexport function stdout(\n  cmd: string,\n  args: string[],\n  opts: StdoutOpts\n): Promise<string> {\n  return stdoutResult(cmd, args, opts).then(ea => ea.result)\n}\n\n/**\n * ONLY FOR SANITIZED INPUTS\n * @return just the stdout stream\n */\nexport function execStdout(cmd: string): Promise<string> {\n  return new Promise((resolve, reject) => {\n    _cp.exec(cmd, (err, sout, serr) =>\n      err != null ? reject(err) : notBlank(serr) ? reject(serr) : resolve(sout)\n    )\n  })\n}\n", "import { unrefDelay } from \"./Delay\"\nimport { orElse } from \"./Maybe\"\nimport { Maybe } from \"./MaybeTypes\"\nimport { gt0 } from \"./Number\"\nimport { opt } from \"./Opt\"\nimport { SyncOrAsync } from \"./OptAsync\"\n\nexport async function thenOrTimeout<T>(\n  p: () => Promise<T>,\n  timeoutMs: number\n): Promise<T> {\n  let resolved: Maybe<boolean>\n  return Promise.race([\n    p().then(ea => {\n      if (resolved == null) {\n        resolved = true\n        return ea\n      } else {\n        return\n      }\n    }),\n    // This delay must be unref'ed so as to not prevent node from exitting:\n    unrefDelay(timeoutMs).then(() => {\n      if (resolved == null) {\n        resolved = false\n        throw new Error(\"timeout\")\n      }\n      return\n    })\n  ]) as Promise<T>\n}\n\nexport function retryOnReject<T>(\n  f: () => Promise<T>,\n  opts: {\n    maxRetries: number\n    timeoutMs?: number\n    retryDelay?: number\n    onRetryWaitUntil?: (retryCount: number) => any\n    errorIsRetriable?: (error: Error) => SyncOrAsync<boolean>\n  }\n): Promise<T> {\n  const g = gt0(opts.timeoutMs) ? () => thenOrTimeout(f, opts.timeoutMs!) : f\n\n  if (opts.maxRetries <= 0) {\n    return g()\n  }\n  const onRetryWaitUntil = opt(\n    opts.onRetryWaitUntil\n  ).getOrElse(() => (retry: number) =>\n    unrefDelay((opts.retryDelay ?? 250) * orElse(retry, 1))\n  )\n  let retryCount = 0\n  const h: () => Promise<T> = async () => {\n    try {\n      return await g()\n    } catch (err) {\n      if (\n        false === (await opts.errorIsRetriable?.(err)) ||\n        retryCount > opts.maxRetries\n      ) {\n        throw err\n      } else {\n        retryCount++\n        await onRetryWaitUntil(retryCount)\n        return h()\n      }\n    }\n  }\n  return h()\n}\n", "import { inspect } from \"util\"\nimport { minuteMs, secondMs } from \"../../fe/Date\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { sigFigs } from \"../../fe/Number\"\nimport { mapGt0, mapGte0f } from \"../Number\"\nimport { TTLArray } from \"../TTLArray\"\nimport { avg, weightedAvg } from \"./Vector\"\n\nexport class Rate {\n  private _eventCount = 0\n  private _lastEventTime = 0\n  private readonly eventDeltas: TTLArray<number>\n\n  constructor(readonly ttlMs: number) {\n    if (ttlMs <= 0) throw new Error(\"ttlMs must be positive\")\n    this.eventDeltas = new TTLArray<number>(ttlMs)\n  }\n\n  [inspect.custom]() {\n    return this.stats()\n  }\n\n  stats() {\n    return {\n      ctor: \"Rate\",\n      epm: this.eventsPerMinute,\n      eventCount: this._eventCount,\n      msSinceLastEvent: this.msSinceLastEvent\n    }\n  }\n\n  onEvent() {\n    const now = Date.now()\n    if (this._lastEventTime > 0) {\n      this.eventDeltas.push(now - this._lastEventTime)\n    }\n    this._lastEventTime = now\n    this._eventCount++\n  }\n\n  clear() {\n    this._lastEventTime = 0\n    this._eventCount = 0\n    this.eventDeltas.clear()\n  }\n\n  get lastEventTime(): number {\n    return this._lastEventTime\n  }\n\n  get msSinceLastEvent() {\n    return Date.now() - this._lastEventTime\n  }\n\n  get eventCount(): number {\n    return this._eventCount\n  }\n\n  get avgMsBetweenEvent(): Maybe<number> {\n    return mapGt0(this.eventDeltas.length, () => weightedAvg(this.eventDeltas))\n  }\n\n  get msPerEvent(): Maybe<number> {\n    return avg(this.eventDeltas)\n  }\n\n  get eventsPerMs(): Maybe<number> {\n    return mapGte0f(this.msPerEvent, ea => 1 / ea)\n  }\n\n  get eventsPerSecond(): Maybe<number> {\n    return mapGte0f(this.eventsPerMs, ea => sigFigs(secondMs * ea, 3))\n  }\n\n  get eventsPerMinute(): Maybe<number> {\n    return mapGte0f(this.eventsPerMs, ea => sigFigs(minuteMs * ea, 3))\n  }\n}\n", "import { Maybe } from \"../fe/MaybeTypes\"\nimport { times } from \"../fe/Number\"\n\nexport class TTLArray<T> implements Iterable<T> {\n  private readonly times: number[] = []\n  private readonly a: T[] = []\n  constructor(readonly ttlMs: number, readonly maxLength?: number) {}\n\n  [Symbol.iterator](): Iterator<T, any, undefined> {\n    this.vacuum()\n    const arr = [...this.a]\n    function* iter(): IterableIterator<T> {\n      for (const k of arr) {\n        yield k\n      }\n    }\n    return iter()\n  }\n\n  push(...t: T[]) {\n    times(t.length, () => this.times.push(Date.now()))\n    this.a.push(...t)\n    if (this.maxLength != null) this.vacuum()\n  }\n\n  pushUniq(...t: T[]) {\n    t.forEach(ea => {\n      if (!this.includes(ea)) this.push(ea)\n    })\n  }\n\n  includes(t: T) {\n    this.vacuum()\n    return this.a.indexOf(t) >= 0\n  }\n\n  shift() {\n    this.vacuum()\n    this.times.shift()\n    return this.a.shift()\n  }\n\n  first() {\n    this.vacuum()\n    return this.a[0]\n  }\n\n  shiftOrFirst() {\n    return this.length > 1 ? this.shift() : this.first()\n  }\n\n  pop() {\n    this.vacuum()\n    this.times.pop()\n    return this.a.pop()\n  }\n\n  get length(): number {\n    this.vacuum()\n    return this.a.length\n  }\n\n  clear(): this {\n    this.times.length = 0\n    this.a.length = 0\n    return this\n  }\n\n  get values(): T[] {\n    this.vacuum()\n    return [...this.a]\n  }\n\n  oldestEntryAge(): Maybe<number> {\n    this.vacuum()\n    return this.times[0]\n  }\n\n  /**\n   * Remove all expired entries\n   */\n  private vacuum() {\n    if (this.a.length === 0) return\n    if (this.maxLength != null) {\n      const deleteCount = this.a.length - this.maxLength\n      this.times.splice(0, deleteCount)\n      this.a.splice(0, deleteCount)\n    }\n    const minTime = Date.now() - this.ttlMs\n    const firstGoodIndex = this.times.findIndex(ea => ea > minTime)\n    if (firstGoodIndex === -1) {\n      this.clear()\n    } else if (firstGoodIndex > 0) {\n      this.times.splice(0, firstGoodIndex)\n      this.a.splice(0, firstGoodIndex)\n    }\n  }\n}\n", "import { mapOr } from \"../../fe/Maybe\"\nimport { toS } from \"../../fe/toS\"\nimport { stripSuffix } from \"../String\"\n\nexport function describeError(ea: string) {\n  const key = stripSuffix(toS(ea).trim().toUpperCase(), \":\")\n  return mapOr(\n    ErrorCodes[key],\n    ec => ec.description,\n    () => ea\n  )\n}\n\nconst ErrorCodes = Object.freeze({\n  UNKNOWN: { errno: -1, description: \"unknown error\" },\n  OK: { errno: 0, description: \"success\" },\n  EOF: { errno: 1, description: \"end of file\" },\n  EADDRINFO: { errno: 2, description: \"getaddrinfo error\" },\n  EACCES: { errno: 3, description: \"permission denied\" },\n  EAGAIN: { errno: 4, description: \"resource temporarily unavailable\" },\n  EADDRINUSE: { errno: 5, description: \"address already in use\" },\n  EADDRNOTAVAIL: { errno: 6, description: \"address not available\" },\n  EAFNOSUPPORT: { errno: 7, description: \"address family not supported\" },\n  EALREADY: { errno: 8, description: \"connection already in progress\" },\n  EBADF: { errno: 9, description: \"bad file descriptor\" },\n  EBUSY: { errno: 10, description: \"resource busy or locked\" },\n  ECONNABORTED: { errno: 11, description: \"software caused connection abort\" },\n  ECONNREFUSED: { errno: 12, description: \"connection refused\" },\n  ECONNRESET: { errno: 13, description: \"connection reset by peer\" },\n  EDESTADDRREQ: { errno: 14, description: \"destination address required\" },\n  EFAULT: { errno: 15, description: \"bad address in system call argument\" },\n  EHOSTUNREACH: { errno: 16, description: \"host is unreachable\" },\n  EINTR: { errno: 17, description: \"interrupted system call\" },\n  EINVAL: { errno: 18, description: \"invalid argument\" },\n  EISCONN: { errno: 19, description: \"socket is already connected\" },\n  EMFILE: { errno: 20, description: \"too many open files\" },\n  EMSGSIZE: { errno: 21, description: \"message too long\" },\n  ENETDOWN: { errno: 22, description: \"network is down\" },\n  ENETUNREACH: { errno: 23, description: \"network is unreachable\" },\n  ENFILE: { errno: 24, description: \"file table overflow\" },\n  ENOBUFS: { errno: 25, description: \"no buffer space available\" },\n  ENOMEM: { errno: 26, description: \"not enough memory\" },\n  ENOTDIR: { errno: 27, description: \"not a directory\" },\n  EISDIR: { errno: 28, description: \"illegal operation on a directory\" },\n  ENONET: { errno: 29, description: \"machine is not on the network\" },\n  ENOTCONN: { errno: 31, description: \"socket is not connected\" },\n  ENOTSOCK: { errno: 32, description: \"socket operation on non-socket\" },\n  ENOTSUP: { errno: 33, description: \"operation not supported on socket\" },\n  ENOENT: { errno: 34, description: \"no such file or directory\" },\n  ENOSYS: { errno: 35, description: \"function not implemented\" },\n  EPIPE: { errno: 36, description: \"broken pipe\" },\n  EPROTO: { errno: 37, description: \"protocol error\" },\n  EPROTONOSUPPORT: { errno: 38, description: \"protocol not supported\" },\n  EPROTOTYPE: { errno: 39, description: \"protocol wrong type for socket\" },\n  ETIMEDOUT: { errno: 40, description: \"connection timed out\" },\n  ECHARSET: { errno: 41, description: \"invalid Unicode character\" },\n  EAIFAMNOSUPPORT: {\n    errno: 42,\n    description: \"address family for hostname not supported\"\n  },\n  EAISERVICE: {\n    errno: 44,\n    description: \"servname not supported for ai_socktype\"\n  },\n  EAISOCKTYPE: { errno: 45, description: \"ai_socktype not supported\" },\n  ESHUTDOWN: {\n    errno: 46,\n    description: \"cannot send after transport endpoint shutdown\"\n  },\n  EEXIST: { errno: 47, description: \"file already exists\" },\n  ESRCH: { errno: 48, description: \"no such process\" },\n  ENAMETOOLONG: { errno: 49, description: \"name too long\" },\n  EPERM: { errno: 50, description: \"operation not permitted\" },\n  ELOOP: { errno: 51, description: \"too many symbolic links encountered\" },\n  EXDEV: { errno: 52, description: \"cross-device link not permitted\" },\n  ENOTEMPTY: { errno: 53, description: \"directory not empty\" },\n  ENOSPC: { errno: 54, description: \"no space left on device\" },\n  EIO: { errno: 55, description: \"i/o error\" },\n  EROFS: { errno: 56, description: \"read-only file system\" },\n  ENODEV: { errno: 57, description: \"no such device\" },\n  ESPIPE: { errno: 58, description: \"invalid seek\" },\n  ECANCELED: { errno: 59, description: \"operation canceled\" }\n})\n", "import { compactBlanks } from \"../../fe/Array\"\nimport { blank, notBlank } from \"../../fe/Blank\"\nimport { isTrue } from \"../../fe/Boolean\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { errorToS, errorToVerbose } from \"../../fe/Error\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { lt } from \"../../fe/Number\"\nimport { toS } from \"../../fe/toS\"\nimport { ending } from \"../async/Endable\"\nimport { eventEmitter } from \"../event/EventEmitter\"\nimport { currentFileLogger, mkLogger } from \"../Logger\"\nimport { Rate } from \"../math/Rate\"\nimport { isMainService } from \"../ServiceNames\"\nimport { Settings } from \"../settings/Settings\"\nimport { ellipsize, stripAnsiEsc, stripPrefix } from \"../String\"\nimport { describeError } from \"./ErrorCodes\"\nimport {\n  extractErrorFlags,\n  isFatalError,\n  isIgnorableError,\n  stripErrorFlags\n} from \"./ErrorTypes\"\n\nconst StartTs = Date.now()\n\nconst logger = lazy(() => mkLogger(\"Error\"))\n\nconst errorRate = new Rate(minuteMs)\nconst fatalErrorRate = new Rate(minuteMs)\n\nexport function mapError<T>(obj: any, f: (error: Error) => T): Maybe<T> {\n  return obj instanceof Error ? f(obj) : undefined\n}\n\nexport function errorContains(err: any, re: RegExp): boolean {\n  return re.exec(errorToS(err)) != null\n}\n\n/**\n * Should this error be considered fatal to this process?\n */\nexport function isFatalErrorAllowed(): boolean {\n  const postProbation =\n    Date.now() > StartTs + Settings.probationMs.valueOrDefault\n\n  const lowErrorRate = lt(\n    fatalErrorRate.eventsPerMinute,\n    Settings.fatalErrorRatePerMinute.valueOrDefault\n  )\n\n  // The only time a fatal error should not be considered fatal is by the main\n  // service, after passing probation, and the error rate is not too high:\n\n  return logger().tap({\n    level: \"info\",\n    msg: \"isFatalErrorAllowed()\",\n    result: isMainService() && postProbation && lowErrorRate,\n    meta: {\n      mainService: isMainService(),\n      postProbation,\n      lowErrorRate,\n      fatalErrorRatePerMin: fatalErrorRate.eventsPerMinute,\n      errorRatePerMin: errorRate.eventsPerMinute,\n      fatalErrorRatePerMinuteSetting:\n        Settings.fatalErrorRatePerMinute.valueOrDefault\n    }\n  })\n}\n\nexport function throws(f: () => any): boolean {\n  try {\n    f()\n    return false\n  } catch {\n    return true\n  }\n}\n\nexport function stack(): string[] {\n  const e: any = {}\n  Error.captureStackTrace(e, stack)\n  return e.stack.split(/\\n(?:\\s*at\\s+)?/).slice(1)\n}\n\nconst trimPatterns = [\n  /^error:? /i,\n  /^code\\b/i,\n  /^unhandledRejection:? /i,\n  /^uncaughtException:? /i,\n  /^[0-9T.: -]+Z? /i,\n  /\\[object Object]/i\n]\n\nexport function trimErrorMessage(msg: string): string {\n  let result = stripErrorFlags(stripAnsiEsc(msg))\n  let prior = result\n  do {\n    prior = result\n    result = trimPatterns.reduce((s, re) => s.replace(re, \"\"), result).trim()\n  } while (prior !== result)\n\n  return compactBlanks(\n    result.split(/\\s+/).map(ea => {\n      if (ea.startsWith(\"E\")) {\n        const desc = describeError(ea)\n        if (result.toLowerCase().includes(desc.toLowerCase())) {\n          return \"\"\n        } else {\n          return desc + \":\"\n        }\n      }\n      return ea\n    })\n  ).join(\" \")\n}\n\nexport function errorToHumanString(\n  err: string | Error,\n  maxChars = 256\n): string {\n  const s = errorToS(err)\n  const flags = extractErrorFlags(s)\n  return ellipsize(trimErrorMessage(s), maxChars - flags.length) + flags\n}\n\nexport function cleanError(msg: string, context: string): string {\n  return toS(msg)\n    .split(/\\r?\\n/)\n    .map(ea => stripPrefix(ea, context))\n    .map(ea => ea.replace(/: ?/, \"\"))\n    .filter(notBlank)\n    .join(\", \")\n}\n\nexport function onError(message: string, error?: Error, context?: any): void {\n  if (blank(message) && error == null) {\n    logger().warn(\"onError() with empty args\", stack())\n    return\n  }\n  const s = errorToS(message) + errorToS(error) + errorToS(context)\n  const fatal = isFatalError(error) || isFatalError(s) || isTrue(context?.fatal)\n  if (!fatal && isIgnorableError(s)) {\n    logger().info(\"onError(): (ignorable): \" + errorToVerbose(error), {\n      message,\n      ...context\n    })\n    return\n  }\n\n  void map(currentFileLogger(), ea => ea.writeRecentLogEntries())\n\n  errorRate.onEvent()\n  if (fatal) fatalErrorRate.onEvent()\n  const event = !fatal || isFatalErrorAllowed() ? \"nonFatal\" : \"fatal\"\n  logger().log(\n    event === \"fatal\" ? \"error\" : \"warn\",\n    \"onError(): \" + errorToVerbose(error),\n    {\n      event,\n      message,\n      ...orElse(context, {})\n    }\n  )\n  if (!ending()) {\n    // Only propagate errors if we're not ending.\n    eventEmitter.emit(event, { message, error })\n  }\n}\n\nexport function addMessage(error: Maybe<Error>, message: Maybe<string>) {\n  if (error == null) return new Error(message)\n\n  if (notBlank(message)) {\n    if (!error.message.toLowerCase().includes(message.toLowerCase())) {\n      error.message += \": \" + message\n    }\n  }\n  return error\n}\n", "import _cp from \"child_process\"\nimport _p from \"process\"\nimport { compact, flatten, isEmpty, sortBy, uniq } from \"../fe/Array\"\nimport { notBlank } from \"../fe/Blank\"\nimport { ago, minuteMs, secondMs } from \"../fe/Date\"\nimport { lazy } from \"../fe/Lazy\"\nimport { map, orElse } from \"../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../fe/MaybeTypes\"\nimport { gt0, toInt } from \"../fe/Number\"\nimport { opt } from \"../fe/Opt\"\nimport { toA } from \"../fe/toA\"\nimport { toS } from \"../fe/toS\"\nimport { Endable, EndableRanks, ending } from \"./async/Endable\"\nimport { EndableWrapper } from \"./async/EndableWrapper\"\nimport { thenMap, thenNot } from \"./async/Promise\"\nimport { Promises } from \"./async/Promises\"\nimport { setUnrefInterval } from \"./async/Timers\"\nimport { onError } from \"./error/Error\"\nimport { FifoCache } from \"./FifoCache\"\nimport { BaseFile } from \"./fs/BaseFile\"\nimport { parseNativePath } from \"./fs/Path\"\nimport { mkLogger } from \"./Logger\"\nimport { toMapAsync } from \"./Map\"\nimport { mapGt0 } from \"./Number\"\nimport { identity, Try } from \"./Object\"\nimport { isWin } from \"./Platform\"\nimport { pidInfo, pidInfos, ProcEntry } from \"./Ps\"\nimport { PowerShell } from \"./pwsh/PowerShell\"\nimport { userData } from \"./UserData\"\n\nconst logger = lazy(() => mkLogger(\"Pids\"))\n\nexport interface PidfileInfo {\n  pid: number\n  cmd: string // < only for debugging\n  ppid: number // < if ppid is gone, reap.\n  /**\n   * If <= 0, the process can run indefinitely (like web or sync)\n   */\n  maxAgeMs: number\n}\n\nexport interface PidfileJson extends PidfileInfo {\n  startTime: number\n  timeoutTime?: number\n}\n\n// yeah, it's a lot of slop, but addPid() is called after a timeout, so start\n// isn't really the start time.\nconst AllowableStartSlopMs = 10 * secondMs\n\nfunction matchesPidfileInfo(\n  info: Maybe<PidfileJson>,\n  entry: Maybe<ProcEntry>\n): boolean {\n  if (info == null || entry == null) return false\n\n  // The start times need to match, ish:\n  const entryStartTime = map(entry.start, ea => ea.getTime())\n  const fileStartTime = info.startTime\n  return (\n    gt0(entryStartTime) &&\n    gt0(fileStartTime) &&\n    Math.abs(entryStartTime - fileStartTime) < AllowableStartSlopMs\n  )\n\n  // Command names can change, so we just use the start time to match PIDs.\n}\n\nasync function matchesPidfile(\n  pidfile: Maybe<BaseFile>,\n  entry: Maybe<ProcEntry>\n): Promise<boolean> {\n  if (pidfile == null || entry == null) return false\n  if (pidfile.name !== toS(entry.pid)) return false\n  return matchesPidfileInfo(await pidfile.readJson<PidfileJson>(), entry)\n}\n\nfunction killWinTaskkill(pid: number, force = false) {\n  const args = [\"/PID\", toS(toInt(pid)), \"/T\"]\n  if (force) {\n    args.push(\"/F\")\n  }\n  _cp.execFile(\"taskkill\", args)\n}\n\nasync function killWin(pid: number, force = false) {\n  if (ending() || PowerShell.instance().ended) {\n    return killWinTaskkill(pid, force)\n  }\n\n  try {\n    // https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.management/stop-process?view=powershell-6\n    const cmd = compact([\n      \"Stop-Process\",\n      \"-Id\",\n      toInt(pid),\n      force ? \"-Force\" : undefined\n    ]).join(\" \")\n    await PowerShell.instance().execute(cmd, identity)\n  } catch (err) {\n    logger().warn(\"killWin(): pwsh error, using TASKKILL: \" + err)\n    killWinTaskkill(pid, force)\n  }\n}\nasync function killPosix(pid: number, force = false) {\n  try {\n    _p.kill(pid, force ? \"SIGKILL\" : \"SIGTERM\")\n  } catch (err) {\n    if (!String(err).includes(\"ESRCH\")) throw err\n  }\n}\n\n/**\n * Send a signal to the given process id.\n *\n * @export\n * @param {number} pid the process id. Required.\n * @param {boolean} [force=false] if true, and the current user has\n * permissions to send the signal, the pid will be forced to shut down.\n */\nexport function killPid(\n  pid: number,\n  force = false,\n  rewritePidfileOnForce = true\n) {\n  if (pid === _p.pid || pid === _p.ppid) {\n    throw new Error(\"cannot self-terminate\")\n  }\n  if (force && rewritePidfileOnForce) {\n    void Pids.instance().onKill(pid)\n  }\n  return isWin ? killWin(pid, force) : killPosix(pid, force)\n}\n\nexport async function pidExists(pid: number): Promise<boolean> {\n  const pi = await pidInfo(pid)\n  return pi != null\n}\n\nexport function pidNotExists(pid: number): Promise<boolean> {\n  return thenNot(pidExists(pid))\n}\n\nexport class Pids {\n  static readonly instance = lazy(() => new Pids())\n  private readonly p = new Promises()\n  private readonly recentPids = new FifoCache<Promise<BaseFile>>(10 * secondMs)\n  constructor(readonly pidsDir = BaseFile.for(userData()).join(\"pids\")) {}\n\n  async addPid(\n    info: PidfileInfo,\n    start: Date,\n    force = false\n  ): Promise<BaseFile> {\n    if (info == null) {\n      throw new Error(\"undefined info\")\n    }\n    const pid = info.pid\n    if (!gt0(pid)) {\n      throw new Error(\"undefined pid\")\n    }\n    const key = info.ppid + \":\" + info.pid\n    if (force) this.recentPids.delete(key)\n    return this.recentPids.getOrSet(key, async () => {\n      const f = this.pidsDir.join(info.pid + \".json\")\n      const cmd = opt(Try(() => parseNativePath(info.cmd).base))\n        .filter(notBlank)\n        .getOrElse(() => info.cmd)\n\n      const startTime = start.getTime()\n      const timeoutTime = mapGt0(info.maxAgeMs, ea => startTime + ea)\n      const json: PidfileJson = {\n        ...info,\n        cmd,\n        startTime,\n        timeoutTime\n      }\n      if (null == (await f.writeJsonMaybe(json))) {\n        return logger().throw(\"Failed to write to \" + f, { info, force })\n      }\n      logger().debug(\"addPid() wrote \" + f, json)\n      return f\n    })\n  }\n\n  pidfiles() {\n    return this.pidsDir\n      .clear()\n      .children(ea => ea.ext === \".json\" && null != toInt(ea.name))\n  }\n\n  async onKill(pid: number): PromiseMaybe<BaseFile> {\n    const pidfile = this.pidsDir.join(pid + \".json\")\n    return thenMap(pidfile.clear().readJson<PidfileJson>(), priorInfo =>\n      this.addPid({ ...priorInfo, maxAgeMs: 1 }, ago(minuteMs), true).catch(\n        err => {\n          logger().info(\"onKill(): failed to rewrite pidfile: \" + err, { pid })\n          return undefined\n        }\n      )\n    )\n  }\n\n  /**\n   * Remove all pidfiles that aren't running anymore\n   */\n  private async vacuumPids() {\n    const pidfiles = await this.pidfiles()\n    const pids = toA(pidfiles)\n      .map(ea => toInt(ea.name))\n      .filter(gt0)\n    if (isEmpty(pids)) return\n\n    const entries = await pidInfos(pids)\n    if (entries == null) {\n      onError(\"Failed to get pidInfo for pids \" + pids)\n      return\n    }\n    logger().debug(\"vacuumPids\", {\n      pids,\n      pidfiles: toA(pidfiles).map(ea => ea.base),\n      entries\n    })\n    for (const pidfile of pidfiles!) {\n      const psEntry = entries.find(ea => toS(ea.pid) === pidfile.name)\n      if (psEntry == null || !(await matchesPidfile(pidfile, psEntry))) {\n        logger().debug(\"vacuumPids(): Removing old pidfile \" + pidfile.base, {\n          psEntry,\n          pidfile: await pidfile\n            .readFile()\n            .then(toS)\n            .catch(err => \"(failed to read file: \" + err + \")\")\n        })\n        await pidfile.unlink()\n      }\n    }\n    return\n  }\n\n  /**\n   * @param everything if `true`, ignore pidfile maxAgeMs.\n   * @param force given to `kill`.\n   */\n  readonly killOldProcs = (\n    opts: {\n      everything?: boolean\n      force?: boolean\n      everythingBefore?: number\n    } = {}\n  ) =>\n    this.p.serial(\"killOldProcs()\", async () => {\n      const everything = orElse(opts.everything, false)\n      const force = orElse(opts.force, isWin)\n      const pidfiles = await this.pidfiles()\n      const pid2pidfile = await toMapAsync(pidfiles, ea =>\n        thenMap(\n          ea.readJson<PidfileJson>(),\n          info => [info.pid, info] as [number, PidfileJson]\n        )\n      )\n      const pids = uniq(\n        flatten(toA(pid2pidfile.values()).map(ea => [ea.pid, ea.ppid]))\n      )\n      if (isEmpty(pids)) {\n        logger().debug(\"killOldProcs(): no pidfiles\")\n        return []\n      }\n      const allEntries = await pidInfos(pids)\n      logger().debug(\"killOldProcs()\", { pids, allEntries })\n      if (allEntries == null) {\n        onError(\"Pids.killOldProcs(): failed to get process information\")\n        return\n      }\n      const runningPids = new Set(allEntries.map(ea => ea.pid))\n      const trackedEntries = allEntries.filter(ea => pid2pidfile.has(ea.pid))\n\n      const trackedPids: (ProcEntry & PidfileJson)[] = sortBy(\n        compact(\n          trackedEntries.map(ea =>\n            map(pid2pidfile.get(ea.pid), info =>\n              matchesPidfileInfo(info, ea) ? { ...info!, ...ea } : undefined\n            )\n          )\n        ),\n        ea => ea.pid\n      ).filter(ea => _p.pid !== ea.pid) // < no suicide\n\n      const victims = everything\n        ? trackedPids\n        : trackedPids.filter(\n            ea =>\n              !runningPids.has(ea.ppid) || // if the parent pid is dead, kill.\n              !runningPids.has(ea.pid) || // if the pid is dead, kill.\n              (gt0(ea.timeoutTime) && Date.now() >= ea.timeoutTime) ||\n              (opts.everythingBefore != null &&\n                ea.startTime < opts.everythingBefore)\n          )\n      logger().debug(\"killOldProcs()\", {\n        trackedEntries,\n        victims,\n        pidfiles: toA(pid2pidfile.values())\n      })\n\n      for (const entry of victims) {\n        logger().debug(\"killOldProcs(): killing\", { entry })\n        void killPid(entry.pid, force, false)\n      }\n      await this.vacuumPids()\n      return sortBy(victims, ea => ea.pid)\n    })\n}\n\nexport function addPid(info: PidfileInfo, start: Date): Promise<BaseFile> {\n  return Pids.instance().addPid(info, start)\n}\n\n// Should only be invoked by MainService\nexport const ProcCleaner = lazy<Endable>(() => {\n  const timers = [\n    // TCBH: prime intervals so they don't collide unnecessarily:\n    { everything: false, force: false, intervalMs: 5 * minuteMs },\n    { everything: false, force: true, intervalMs: 17 * minuteMs }\n  ].map(ea =>\n    setUnrefInterval(() => Pids.instance().killOldProcs(ea), ea.intervalMs)\n  )\n  return new EndableWrapper(\n    \"ProcCleaner\",\n    () => {\n      timers.map(clearInterval)\n      return Pids.instance().killOldProcs()\n    },\n    EndableRanks.predb\n  )\n})\n", "import { inspect } from \"util\"\nimport { isNotEmpty, uniq } from \"../fe/Array\"\nimport { GetOrSet } from \"../fe/GetOrSet\"\nimport { orElse } from \"../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../fe/MaybeTypes\"\nimport { gt0, round } from \"../fe/Number\"\nimport { toS } from \"../fe/toS\"\nimport { thenOrTimeout } from \"./async/thenOrTimeout\"\nimport { setUnrefInterval } from \"./async/Timers\"\nimport { until } from \"./async/until\"\nimport { union } from \"./Set\"\n\n// simple null-safe keys()\nfunction keys(o: any): string[] {\n  return o == null ? [] : Object.keys(o)\n}\n\n/**\n * First-in-first-out cache. Implementation inspired by\n * https://github.com/dominictarr/hashlru.\n *\n * https://en.wikipedia.org/wiki/Cache_replacement_policies\n */\nexport class FifoCache<V> implements GetOrSet<string, V> {\n  private currentCache!: Record<string, V>\n  private setsSinceLastSpill: number = 0\n  private priorCache!: Record<string, V>\n  private clearInterval?: NodeJS.Timeout\n\n  private readonly expireListeners: ((k: string, v: V) => void)[] = []\n\n  constructor(readonly maxSize: number, readonly clearEveryMs?: number) {\n    if (maxSize < 1) {\n      throw new Error(\"maxSize must be positive\")\n    }\n    if (maxSize > 30_000) {\n      // 30 seconds\n      throw new Error(\"maxSize is too big\")\n    }\n    // Set up _size and caches:\n    this.clear()\n    if (gt0(clearEveryMs)) {\n      this.clearInterval = setUnrefInterval(() => {\n        this.spill()\n      }, round(clearEveryMs / 2))\n    }\n  }\n\n  private spill() {\n    if (\n      this.priorCache != null &&\n      this.currentCache != null &&\n      isNotEmpty(this.expireListeners)\n    ) {\n      for (const k in this.priorCache) {\n        if (this.currentCache[k] == null) {\n          const v = this.priorCache[k]\n          if (v != null) {\n            for (const el of this.expireListeners) {\n              el(k, v)\n            }\n          }\n        }\n      }\n    }\n    this.priorCache = this.currentCache ?? Object.create(null)\n    this.currentCache = Object.create(null)\n    this.setsSinceLastSpill = 0\n  }\n\n  [inspect.custom]() {\n    return {\n      ...this.priorCache,\n      ...this.currentCache\n    }\n  }\n\n  end() {\n    if (this.clearInterval != null) clearInterval(this.clearInterval)\n  }\n\n  clear(): this {\n    this.visit((k, v) => {\n      for (const el of this.expireListeners) {\n        el(k, v)\n      }\n    })\n    this.currentCache = Object.create(null)\n    this.priorCache = Object.create(null)\n    this.setsSinceLastSpill = 0\n    return this\n  }\n\n  get size(): number {\n    if (this.currentCache == null || this.priorCache == null) return 0\n    let sum = 0\n    for (const k of union(keys(this.priorCache), keys(this.currentCache))) {\n      if (this.has(k)) sum++\n    }\n    return sum\n  }\n\n  // private get currentSize(): number {\n  //   if (this.currentCache == null) return 0\n  //   let sum = 0\n  //   for (const k in this.currentCache) {\n  //     if (this.currentCache[k] != null) sum++\n  //   }\n  //   return sum\n  // }\n\n  has(key: string): boolean {\n    return this.currentCache[key] != null || this.priorCache[key] != null\n  }\n\n  keys(): string[] {\n    return uniq([...keys(this.priorCache), ...keys(this.currentCache)]).filter(\n      k => null != this.currentCache[k] ?? this.priorCache[k]\n    )\n  }\n\n  delete(key: string) {\n    // We don't decrement size here, because we don't use `delete\n    // this.currentCache[key]` (because it's slow)\n    const v = this.currentCache[key]\n    if (v != null) {\n      this.currentCache[key] = undefined as any\n      for (const el of this.expireListeners) {\n        el(key, v)\n      }\n    }\n    const v2 = this.priorCache[key]\n    if (v2 != null) {\n      this.priorCache[key] = undefined as any\n      if (v == null) {\n        for (const el of this.expireListeners) {\n          el(key, v2)\n        }\n      }\n    }\n  }\n\n  visit(visitor: (key: string, value: V) => any) {\n    for (const k of union(keys(this.priorCache), keys(this.currentCache))) {\n      const v = this.currentCache[k] ?? this.priorCache[k]\n      if (v != null) visitor(k, v)\n    }\n  }\n\n  deleteIf(predicate: (key: string, value: V) => boolean) {\n    for (const k of this.keys()) {\n      const v = orElse(this.currentCache[k], this.priorCache[k])\n      if (v != null) {\n        if (predicate(k, v)) {\n          this.delete(k)\n        }\n      }\n    }\n  }\n\n  get(key: string | number) {\n    key = toS(key)\n    return this.currentCache[key] ?? this.priorCache[key]\n  }\n\n  set(key: string | number, value: V) {\n    key = toS(key)\n    if (this.currentCache[key] == null) {\n      if (this.setsSinceLastSpill >= this.maxSize) this.spill()\n      this.setsSinceLastSpill++\n    }\n    this.currentCache[key] = value\n  }\n\n  getOrSet(key: string | number, valueThunk: () => V): V {\n    key = toS(key)\n    const prior = this.get(key)\n    if (prior != null) return prior\n\n    const v = valueThunk()\n    this.set(key, v)\n    return v\n  }\n\n  on(_event: \"expire\", listener: (k: string, v: V) => void) {\n    this.expireListeners.push(listener)\n  }\n}\n\nexport interface Placeholder {\n  __uid: number\n  __start: number\n}\n\nexport class FifoCacheAsync<V> {\n  private uid = 0\n  private cacheSyncHits = 0\n  private cacheAsyncHits = 0\n  private cacheMisses = 0\n  private timeouts = 0\n  readonly cache: FifoCache<V | Placeholder>\n  constructor(\n    readonly opts: { maxSize: number; timeoutMs: number; clearEveryMs?: number }\n  ) {\n    this.cache = new FifoCache(opts.maxSize, opts.clearEveryMs)\n  }\n\n  get size() {\n    return this.cache.size\n  }\n\n  stats() {\n    return {\n      size: this.size,\n      cacheSyncHits: this.cacheSyncHits,\n      cacheAsyncHits: this.cacheAsyncHits,\n      cacheMisses: this.cacheMisses,\n      timeouts: this.timeouts\n    }\n  }\n\n  get(key: string): Maybe<V> {\n    const v = this.cache.get(key)\n    return v == null || v[\"__uid\"] != null ? undefined : (v as V)\n  }\n\n  clear() {\n    this.cache.clear()\n    this.cacheSyncHits = 0\n    this.cacheAsyncHits = 0\n    this.cacheMisses = 0\n    this.timeouts = 0\n  }\n\n  deleteIf(predicate: (key: string) => boolean) {\n    for (const k of this.cache.keys()) {\n      if (predicate(k)) {\n        this.cache.delete(k)\n      }\n    }\n  }\n\n  async getOrSetAsync(\n    key: string,\n    later: () => Promise<V>,\n    retries = 1\n  ): PromiseMaybe<V> {\n    key = toS(key)\n    {\n      const result = this.get(key)\n      if (result != null) {\n        this.cacheSyncHits++\n        // logger().debug(\"getOrSetAsync(): prior value\")\n        return result\n      }\n    }\n\n    const __uid = this.uid++\n    const __start = Date.now()\n    const prior = this.cache.getOrSet(key, () => ({\n      __uid,\n      __start\n    }))\n    // logger().debug(\"getOrSetAsync(): prior\", {\n    //   key,\n    //   prior,\n    //   current: { __uid, __start }\n    // })\n    if (prior[\"__uid\"] === __uid) {\n      // logger().debug(\"getOrSetAsync(): applying later...\", {\n      //   key,\n      //   prior,\n      //   current: { __uid, __start }\n      // })\n      this.cacheMisses++\n\n      // I get to run the later, yay!\n      return thenOrTimeout(\n        later,\n        this.opts.timeoutMs,\n        () => {\n          this.timeouts++\n          if (this.cache.get(key)?.[\"__uid\"] === __uid) this.cache.delete(key)\n          return\n        },\n        v => {\n          // logger().debug(\"getOrSetAsync(): onSuccess(): stored new value\", {\n          //   key,\n          //   __uid,\n          //   elapsedMs: Date.now() - __start\n          // })\n          this.cache.set(key, v)\n        }\n      )\n    } else {\n      // Remaining time for prior call:\n      const priorStart = prior[\"__start\"]\n      if (priorStart != null) {\n        const priorTimeoutAt = priorStart + this.opts.timeoutMs\n        const priorTimeoutMs = priorTimeoutAt - Date.now()\n        if (priorTimeoutMs > 0) {\n          // logger().debug(\n          //   \"getOrSetAsync(): waiting for concurrent resolution...\",\n          //   { priorTimeoutMs }\n          // )\n          const v = until(() => this.get(key), {\n            timeoutMs: priorTimeoutMs\n          })\n          if (v != null) {\n            this.cacheAsyncHits++\n            // logger().debug(\"getOrSetAsync(): returning concurrent prior\", {\n            //   key\n            // })\n            return v\n          }\n        }\n      }\n      return retries > 0\n        ? this.getOrSetAsync(key, later, retries - 1)\n        : undefined\n    }\n  }\n}\n", "import fs from \"fs\"\nimport fse from \"fs-extra\"\nimport { join, sep } from \"path\"\nimport { Readable, Transform } from \"stream\"\nimport { inspect } from \"util\"\nimport { createBrotliCompress, createGunzip, createGzip } from \"zlib\"\nimport {\n  compact,\n  flatten,\n  includesAll,\n  isEmpty,\n  isNotEmpty,\n  startsWith,\n  uniq\n} from \"../../fe/Array\"\nimport { retryOnReject } from \"../../fe/AsyncRetry\"\nimport { blank, notBlank } from \"../../fe/Blank\"\nimport { fmtYMDHMS, minuteMs, secondMs, unixtime } from \"../../fe/Date\"\nimport { delay } from \"../../fe/Delay\"\nimport { stringify } from \"../../fe/JSON\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, map3, mapOr, orElse } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { closeTo } from \"../../fe/Number\"\nimport { opt } from \"../../fe/Opt\"\nimport { newlineRe } from \"../../fe/String\"\nimport { toA } from \"../../fe/toA\"\nimport { toS } from \"../../fe/toS\"\nimport { MiB } from \"../../fe/Units\"\nimport { leastIndex, max } from \"../Array\"\nimport { Deferred } from \"../async/Deferred\"\nimport { apply, Predicate } from \"../async/Predicate\"\nimport {\n  filterAsync,\n  thenCompact,\n  thenDefined,\n  thenMap,\n  thenMap2Or,\n  thenMapOr,\n  thenNot,\n  thenOrElse\n} from \"../async/Promise\"\nimport { withBoundedConcurrency } from \"../async/Promises\"\nimport { time } from \"../async/PromiseTimer\"\nimport { untilTrue } from \"../async/until\"\nimport { stdout } from \"../child/ChildProcess\"\nimport { elapsedAsync } from \"../Elapsed\"\nimport { eql, eqlAsync } from \"../Eql\"\nimport { isNonRetriableError, NonRetriableErrorFlag } from \"../error/ErrorTypes\"\nimport { emitFileChanged, emitFileCopied } from \"../event/EventEmitter\"\nimport { LogLevel } from \"../log/LogLevel\"\nimport { mkLogger } from \"../Logger\"\nimport { min } from \"../math/Vector\"\nimport { Try } from \"../Object\"\nimport { isMac, isWin } from \"../Platform\"\nimport { PowerShell, pwshQuote } from \"../pwsh/PowerShell\"\nimport { Settings } from \"../settings/Settings\"\nimport { equalsIgnoreCase, pad2, stripPrefix, stripSuffix } from \"../String\"\nimport { diceCoeff } from \"../StringSimilarity\"\nimport { CmdTimeoutMs, MinIoRate } from \"../volumes/VolumeTtls\"\nimport { crlf, splitLines } from \"./CRLF\"\nimport { DirectoryEntry, StatDirent } from \"./DirectoryEntry\"\nimport { FileCache } from \"./FileCache\"\nimport { fileSha } from \"./Hash\"\nimport { LineReader } from \"./LineReader\"\nimport {\n  ensureNewNativePath_,\n  EnsureNewOptions,\n  isAbsolute,\n  isUNC,\n  nameWithoutCount,\n  native2posix,\n  parseNativePath,\n  posixPathFrom,\n  resolve\n} from \"./Path\"\nimport { PullProgressObserver, PushProgressObserver } from \"./ProgressObservers\"\nimport { ProjectPath } from \"./ProjectPath\"\nimport { SimpleFile } from \"./SimpleFile\"\nimport { onDataChunked } from \"./StreamChunker\"\nimport { ByteCounter, pipelineAsync } from \"./Streams\"\nimport { zCopyToBuffer_, zCopyTo_ } from \"./zcat\"\n\nexport const WipPrefix = isWin ? \"wip-\" : \".\"\n\nexport type WriteOptions = Partial<{\n  encoding: BufferEncoding\n  fd: number\n  mode: number\n  flags: string\n  emitClose: boolean\n  autoClose: boolean\n  start: number\n}>\n\nexport interface FileProgress {\n  path: string\n  /**\n   * operation (like \"sha\" or \"cp\")\n   */\n  op: string\n  /**\n   * percent complete\n   */\n  pct: number\n}\nconst cache = new FileCache<BaseFile>()\n\n/**\n * Extracted from PosixFile, this superclass is used by the FileLogger.\n *\n * It must not depend on core code that also requires a Logger.\n */\nexport class BaseFile implements SimpleFile {\n  protected readonly bflog = lazy(() =>\n    mkLogger(\"BaseFile(\" + this.nativePath + \")\")\n  )\n\n  protected static attrTTL = 3 * minuteMs\n  readonly posixPath: string\n  readonly nativePath: string\n\n  /** \"/home/user/dir\" of \"/home/user/dir/file.txt\" */\n  readonly dir: string\n  /** \"file.txt\" of \"/home/user/dir/file.txt\" */\n  readonly base: string\n  /** \"file\" of \"/home/user/dir/file.txt\" */\n  readonly name: string\n  /** \".txt\" of \"/home/user/dir/file.txt\" */\n  readonly ext: string\n\n  protected constructor(nativePath: string, private dirent?: DirectoryEntry) {\n    if (dirent != null) {\n      this.nativePath = dirent.nativePath\n      this.dir = dirent.dir\n      this.base = dirent.base\n      this.name = dirent.name\n      this.ext = dirent.ext\n    } else {\n      this.nativePath = resolve(nativePath)\n      const parsed = parseNativePath(this.nativePath)\n      this.dir = parsed.dir\n      this.base = parsed.base\n      this.name = parsed.name\n      this.ext = parsed.ext\n    }\n    this.posixPath = native2posix(this.nativePath)\n\n    cache.set(nativePath, this)\n  }\n\n  toJSON() {\n    return {\n      nativePath: this.nativePath\n    }\n  }\n\n  [inspect.custom]() {\n    return this.toJSON()\n  }\n\n  static async withFastestAccess<F extends BaseFile>(\n    files: Maybe<F>[]\n  ): PromiseMaybe<F> {\n    const arr = compact(files)\n    const msArr = await Promise.all(arr.map(f => f.shaMs()))\n    return arr[leastIndex(msArr)]\n  }\n\n  static projectRoot = lazy(() => {\n    const root = ProjectPath.Root()\n    if (root == null) {\n      throw new Error(\"Cannot find project path\")\n    } else {\n      return BaseFile.for(root)\n    }\n  })\n\n  static forPosix(posixPathOrFile: string | BaseFile) {\n    return posixPathOrFile instanceof BaseFile\n      ? posixPathOrFile\n      : this.for(posixPathOrFile.split(\"/\").join(sep))\n  }\n\n  static forDirectoryEntry(de: DirectoryEntry) {\n    return this.for(de.nativePath, de)\n  }\n\n  static for(nativePathOrFile: string | BaseFile, dirent?: DirectoryEntry) {\n    if (nativePathOrFile instanceof BaseFile) {\n      return nativePathOrFile\n    }\n    // PERF: resolve() is expensive.\n    const prior = cache.get(nativePathOrFile)\n    if (prior != null) return prior\n    const resolvedPath = resolve(nativePathOrFile)\n    return cache.getOrSet(\n      resolvedPath,\n      () => new BaseFile(resolvedPath, dirent)\n    )\n\n    // return new BaseFile(resolve(nativePathOrFile), dirent)\n  }\n\n  /**\n   * Wipe the instance cache and caches of all instances.\n   *\n   * This should only be used by tests.\n   *\n   * @param fromPath if undefined, all instances will be cleared.\n   */\n  static clear(fromPath?: string) {\n    emitFileChanged(fromPath)\n  }\n\n  for(path: string, dirent?: DirectoryEntry): this {\n    return BaseFile.for(path, dirent) as this\n  }\n\n  clear(): this {\n    this.dirent = undefined\n    this._childDirectoryEntries.unset()\n    this.stat.unset()\n    this.statSync.unset()\n    this.shaResult.unset()\n    return this\n  }\n\n  clearThisAndParent(): this {\n    emitFileChanged(this.dir)\n    return this\n  }\n\n  toString() {\n    return this.nativePath\n  }\n\n  valueOf() {\n    return this.pathnames\n  }\n\n  eql(that: Maybe<string | BaseFile>): boolean {\n    return that == null\n      ? false\n      : that instanceof BaseFile\n      ? this.nativePath === that.nativePath\n      : this.nativePath === BaseFile.for(that).nativePath\n  }\n\n  get isUNC() {\n    return isUNC(this.nativePath)\n  }\n\n  /**\n   * posix path from parent\n   */\n  get baseWithParent(): string {\n    return (this.isRoot\n      ? \"/\"\n      : this.parent().isRoot\n      ? \"/\" + this.base\n      : (this.parent().parent().isRoot ? \"/\" : \"\") + // <  prefixes the path with a / if grandparent is root.\n        this.parent().base +\n        \"/\" +\n        this.base\n    ).normalize()\n  }\n\n  /**\n   * posix path from grandparent\n   */\n  get baseWithGrandparent(): string {\n    return (this.isRoot\n      ? \"/\"\n      : this.parent().isRoot\n      ? this.baseWithParent\n      : this.parent().baseWithParent + \"/\" + this.base\n    ).normalize()\n  }\n\n  posixPathFrom(from: BaseFile): string {\n    return posixPathFrom(from, this)\n  }\n\n  async directoryEntry(): PromiseMaybe<DirectoryEntry> {\n    if (this.dirent == null) {\n      this.dirent = await thenMap(\n        this.stat(),\n        ea => new DirectoryEntry(this.dir, new StatDirent(this.base, ea))\n      )\n    }\n    return this.dirent\n  }\n\n  private readonly _childDirectoryEntries = lazy(() =>\n    thenMap(this.directoryEntry(), de => de.children())\n  )\n\n  async childDirectoryEntries(f?: Predicate<DirectoryEntry>) {\n    const dirents = await this._childDirectoryEntries()\n    return dirents == null || f == null || isEmpty(dirents)\n      ? dirents\n      : await filterAsync(dirents, f)\n  }\n\n  _directoryEntryChild(de: DirectoryEntry) {\n    return this.for(join(this.nativePath, de.base), de)\n  }\n\n  /**\n   * @return the basename of the children of `this`, locale sorted.\n   */\n  childNames() {\n    return thenMap(this.childDirectoryEntries(), arr => arr.map(ea => ea.base))\n  }\n\n  async children(predicate?: Predicate<DirectoryEntry>): PromiseMaybe<this[]> {\n    return (await this.childDirectoryEntries(predicate))?.map(ea =>\n      this._directoryEntryChild(ea)\n    )\n  }\n\n  async childFiles(f?: Predicate<this>): PromiseMaybe<this[]> {\n    // PERF: unrolled from thenMap\n    const result: this[] = []\n    for (const de of toA(await this.childDirectoryEntries())) {\n      if (de.isFile()) {\n        const ea = this._directoryEntryChild(de)\n        if (f == null || (await f(ea))) {\n          result.push(ea)\n        }\n      }\n    }\n    return result\n  }\n\n  async childDirectories(predicate?: Predicate<this>): PromiseMaybe<this[]> {\n    return thenMap(this.childDirectoryEntries(), arr =>\n      thenCompact(\n        arr\n          .filter(ea => ea.isDirectory())\n          .map(async ea => apply(this._directoryEntryChild(ea), predicate))\n      )\n    )\n  }\n\n  /**\n   * ONLY FOR TESTS\n   */\n  childrenSync(): this[] {\n    return orElse(\n      this.trapSync(\"childrenSync\", () =>\n        fs.readdirSync(this.nativePath).map(ea => this.join(ea))\n      ),\n      []\n    )\n  }\n\n  async hasChildren(childNames?: string[]) {\n    const actualChildNames = await this.childNames()\n    return isNotEmpty(childNames)\n      ? includesAll(actualChildNames, childNames)\n      : isNotEmpty(actualChildNames)\n  }\n\n  async hasNoChildren() {\n    return (await this.isFile()) || isEmpty(await this.childNames())\n  }\n\n  /**\n   * Depth-first recursion, includes child directories.\n   */\n  async visitDescendants(\n    f: (descendant: this) => any | Promise<any>\n  ): Promise<void> {\n    return thenMap(this.children(), async children => {\n      for (const child of children) {\n        await child.visitDescendants(f)\n        await f(child)\n      }\n    })\n  }\n\n  /**\n   * Breadth-first recursion\n   *\n   * @return all files (no directories) that pass the given predicate.\n   */\n  async descendants(predicate: Predicate<this>): PromiseMaybe<this[]> {\n    const result: this[] = []\n    for (const ea of toA(await this.childFiles())) {\n      if (await predicate(ea)) result.push(ea)\n    }\n\n    const dirs = await this.childDirectories()\n    if (dirs == null) return\n    await withBoundedConcurrency({\n      name: \"descendants\",\n      laters: dirs.map(dir => () =>\n        thenMap(dir.descendants(predicate), ea => result.push(...ea))\n      )\n    })\n    return result\n  }\n\n  async ancestorWithChildren(childNames: string[]): PromiseMaybe<this> {\n    if (await this.hasChildren(childNames)) {\n      return this\n    } else if (this.isRoot) {\n      return undefined\n    } else {\n      return this.parent().ancestorWithChildren(childNames)\n    }\n  }\n\n  async siblings(f?: Predicate<DirectoryEntry>): PromiseMaybe<this[]> {\n    const p = this.parent()\n    return (await this.siblingDirectoryEntries(f))?.map(ea =>\n      p._directoryEntryChild(ea)\n    )\n  }\n\n  async siblingDirectoryEntries(\n    f?: Predicate<DirectoryEntry>\n  ): PromiseMaybe<DirectoryEntry[]> {\n    return this.parent().childDirectoryEntries(\n      async ea => ea.base !== this.base && (f == null || (await f(ea)))\n    )\n  }\n\n  async selfAndSiblings() {\n    return this.parent().children()\n  }\n\n  async firstExistingSelfOrAncestor(): Promise<this> {\n    return this.isRoot || (await this.exists())\n      ? this\n      : this.parent().firstExistingSelfOrAncestor()\n  }\n\n  /**\n   * @return [\"C:\", \"Users\", \"Bob\", \"image.jpg\"] on win, [\"home\", \"bob\",\n   * \"image.jpg\"] on !win\n   */\n  get pathnames(): string[] {\n    return this.nativePath.split(sep).filter(ea => ea != null && ea !== \"\")\n  }\n\n  get pathnamesWithoutDrive(): string[] {\n    return isWin ? this.pathnames.slice(1) : this.pathnames\n  }\n\n  /**\n   * @return 0 for \"/\" or \"C:\\\", 1 for \"C:\\Users\" or \"/etc\", ...\n   */\n  get depth(): number {\n    return this.pathnames.length - (isWin ? 1 : 0)\n  }\n\n  get isRoot(): boolean {\n    return this.pathnames.length === (isWin ? 1 : 0)\n  }\n\n  /**\n   * @param depth The number of directories from root to include. For example,\n   * \"C:\\\" or \"/\" for 0, \"C:\\Users\" or \"/home\" for depth 1\n   */\n  root(depth: number = 0): this {\n    // \"/\".root(1) should return \"/\"\n    return this.depth <= depth ? this : this.parent().root(depth)\n  }\n\n  parent(): this {\n    // MEMLEAK: don't cache this: this.for will do that for us.\n    return this.isRoot ? this : (this.for(this.dir) as this)\n  }\n\n  isAncestorOf(maybeDescendant: Maybe<BaseFile>): boolean {\n    return (\n      maybeDescendant != null &&\n      (this.nativePath === maybeDescendant.nativePath ||\n        // Don't use nativePath + path: that doesn't handle roots correctly.\n        startsWith(maybeDescendant.pathnames, this.pathnames))\n    )\n  }\n\n  isDescendantOf(maybeAncestor: Maybe<BaseFile>): boolean {\n    return maybeAncestor != null && maybeAncestor.isAncestorOf(this)\n  }\n\n  parentsAndSelf(): this[] {\n    return [...this.parents(), this]\n  }\n\n  selfAndParents(depth: number): this[] {\n    return [\n      this,\n      ...(this.isRoot || depth <= 0\n        ? []\n        : this.parent().selfAndParents(depth - 1))\n    ]\n  }\n\n  /**\n   * Root-first order of paths (so [/, /var, /var/tmp, ...]\n   */\n  parents(): this[] {\n    const p = this.parent()\n    // NOTE: ALWAYS RETURN A NEW ARRAY, because consumers may .reverse or do\n    // other nasty things to it.\n    return this.isRoot ? [] : [...p.parents(), p]\n  }\n\n  /**\n   * Paths from URIs can have differently-encoded unicode paths (which switching\n   * from macOS to linux or Windows, for example.)\n   *\n   * If `this` exists, return it.\n   *\n   * If it doesn't, walk from the root of the path and try to find elements that,\n   * when unicode-normalized, match the current filesystem.\n   *\n   * As a last-ditch effort, try a case-insensitive match.\n   *\n   * If none of these work, `undefined` will be returned.\n   */\n  async normalize(): PromiseMaybe<this> {\n    // Don't need to handle UNC paths (they are always windows-only):\n    if (this.isUNC) return this\n\n    if ((await this.exists()) || this.isRoot) return this\n\n    return thenMap(this.parent().normalize(), async p => {\n      // We don't fetch .children(), as we don't want to instantiate all those\n      // BaseFiles unnecessarily.\n      const siblingNames = await p.childNames()\n\n      if (isNotEmpty(siblingNames)) {\n        for (const ea of siblingNames) {\n          if (ea === this.base) return p.join(ea)\n        }\n\n        const normalizedBase = this.base.normalize()\n        for (const ea of siblingNames) {\n          if (ea.normalize() === normalizedBase) return p.join(ea)\n        }\n\n        if (isMac || isWin) {\n          for (const ea of siblingNames) {\n            if (equalsIgnoreCase(ea, this.base)) return p.join(ea)\n          }\n        }\n      }\n\n      return\n    })\n  }\n\n  sibling(base: string): this {\n    return this.parent().join(base)\n  }\n\n  withPrefix(prefix: string): this {\n    return this.sibling(prefix + this.base)\n  }\n\n  withNameSuffix(suffix: string): this {\n    return this.sibling(this.name + suffix + this.ext)\n  }\n\n  siblingOf(possibleSibling: BaseFile): boolean {\n    return (\n      this.nativePath !== possibleSibling.nativePath &&\n      this.dir === possibleSibling.dir\n    )\n  }\n\n  /**\n   * Allows ../... directory traversals.\n   */\n  join(...paths: string[]): this {\n    if (isEmpty(paths) || eql([\".\"], paths)) return this\n    return isAbsolute(paths[0])\n      ? this.for(join(...paths))\n      : this.for(join(this.nativePath, ...paths))\n  }\n\n  joinYMD(d = new Date()): Maybe<this> {\n    return map3(\n      d?.getFullYear(),\n      d?.getMonth(),\n      d?.getDate(),\n      (year, month, day) => this.join(toS(year), pad2(month + 1), pad2(day))\n    )\n  }\n\n  /**\n   * Prevents `..` directory traversals\n   * @param paths\n   */\n  child(...paths: string[]): this {\n    if (isEmpty(paths)) return this\n    const pathElements = flatten(paths.map(ea => ea.split(sep))).filter(\n      ea => ea !== \"..\"\n    )\n    // Convert to posix to prevent \"\\\\\" and \"/\" from confusing the split:\n    return this.join(...pathElements)\n  }\n\n  //  _  _    _\n  // (_)| |_ ( )___    __ _\n  // | || __||// __|  / _` |\n  // | || |_   \\__ \\ | (_| | _  _  _\n  // |_| \\__|  |___/  \\__,_|(_)(_)(_)\n  protected async trap<T>(\n    methodName: string,\n    p: () => PromiseMaybe<T>,\n    errLogLevel: LogLevel = \"warn\"\n  ): PromiseMaybe<T> {\n    try {\n      return await time(\"fs.\" + methodName, p)\n      // this.bflog().trace(\n      //   `trap ${methodName}()`,\n      //   Buffer.isBuffer(result) ? \"<Buffer>\" : result\n      //   // Used for https://gitlab.com/photostructure/photostructure/issues/87:\n      //   // , { callstack: stack().slice(0, 10) }\n      // )\n      // return result\n    } catch (err) {\n      this.bflog().log(errLogLevel, `trap: ${methodName}() failed: ${err}`)\n      return undefined\n    }\n  }\n\n  // Return true if p() doesn't raise an error, else return false.\n  protected async trapOr(\n    methodName: string,\n    p: () => Promise<any>,\n    errLogLevel: LogLevel = \"warn\"\n  ): Promise<boolean> {\n    try {\n      this.bflog().trace(`trapOr ${methodName}()`)\n      await p()\n      return true\n    } catch (err) {\n      this.bflog().log(errLogLevel, `trapOr: ${methodName}() failed: ${err}`)\n      return false\n    }\n  }\n\n  protected trapSync<T>(methodName: string, p: () => T): Maybe<T> {\n    try {\n      this.bflog().trace(`trapSync ${methodName}()`)\n      return p()\n    } catch (err) {\n      this.bflog().warn(`trapSync: ${methodName}() failed: ${err}`)\n      return undefined\n    }\n  }\n\n  readonly stat = lazy<PromiseMaybe<fs.Stats>>(\n    // Don't log these errors:\n    () =>\n      this.trap(\"stat\", () => fse.stat(this.nativePath).catch(() => undefined)),\n    BaseFile.attrTTL\n  )\n\n  readonly statSync = lazy<Maybe<fs.Stats>>(\n    // Don't log these errors:\n    () =>\n      this.trapSync(\"statSync\", () => Try(() => fs.statSync(this.nativePath))),\n    BaseFile.attrTTL\n  )\n\n  async exists(): Promise<boolean> {\n    return this.dirent != null || (await thenDefined(this.stat()))\n  }\n\n  existsSync(): boolean {\n    return this.dirent != null || this.statSync() != null\n  }\n\n  async notExists(): Promise<boolean> {\n    return thenNot(this.exists())\n  }\n\n  mtime(): PromiseMaybe<Date> {\n    return thenMap(this.stat(), s => s.mtime)\n  }\n\n  mtimeMs(): PromiseMaybe<number> {\n    return thenMap(this.stat(), s => Math.floor(s.mtimeMs))\n  }\n\n  mtimeSec(): PromiseMaybe<number> {\n    return thenMap(this.stat(), s => unixtime(s.mtime))\n  }\n\n  async lastModifiedUtc(): PromiseMaybe<string> {\n    return thenMap(this.stat(), s => s.mtime.toUTCString())\n  }\n\n  // The mtime, rather than the birthtime, will actually be the capture\n  // time if the file is \"copied and pasted\" via the Windows explorer\n  // (rather than using `rsync --times` or `cp --preserve=all`).\n\n  // Birthtime isn't supported by default in linux, and seems to just return\n  // the ctime.\n\n  statTimes(): PromiseMaybe<number[]> {\n    return thenMap(this.stat(), s =>\n      // birthtimeMs will be 0 on OSes that don't support it.\n      // remember that ctime is directory-change-time, not create-time!\n      uniq(\n        [s.birthtimeMs, s.mtimeMs, s.ctimeMs].filter(\n          ea => ea != null && ea !== 0\n        )\n      )\n    )\n  }\n\n  maxStatMs(): PromiseMaybe<number> {\n    return thenMap(this.statTimes(), max)\n  }\n\n  maxStatDate(): PromiseMaybe<Date> {\n    return thenMap(this.maxStatMs(), ea => new Date(ea))\n  }\n\n  minStatMs(): PromiseMaybe<number> {\n    return thenMap(this.statTimes(), min)\n  }\n\n  minStatDate(): PromiseMaybe<Date> {\n    return thenMap(this.minStatMs(), ea => new Date(ea))\n  }\n\n  size(): PromiseMaybe<number> {\n    return thenMap(this.stat(), s => s.size)\n  }\n\n  async access(mode: number): Promise<boolean> {\n    try {\n      await fse.access(this.nativePath, mode)\n      return true\n    } catch {\n      return false\n    }\n  }\n\n  /**\n   * @return Promise<true> if the file is executable (not relevant on windows)\n   */\n  isExecutable() {\n    return this.access(fs.constants.R_OK | (isWin ? 0 : fs.constants.X_OK))\n  }\n\n  isReadable(): Promise<boolean> {\n    return this.access(fs.constants.R_OK)\n  }\n\n  isNotReadable(): Promise<boolean> {\n    return thenNot(this.isReadable())\n  }\n\n  isReadWritable(): Promise<boolean> {\n    return this.access(fs.constants.R_OK | fs.constants.W_OK)\n  }\n\n  isNotReadWritable(): Promise<boolean> {\n    return thenNot(this.isReadWritable())\n  }\n\n  isHiddenPosix(): boolean {\n    return this.base.startsWith(\".\")\n  }\n\n  async isEmpty(bytesConsideredEmpty = 0): Promise<boolean> {\n    if (await this.isDirectory()) {\n      return isNotEmpty(await this.childNames())\n    } else {\n      const s = await this.size()\n      return s == null || s <= bytesConsideredEmpty\n    }\n  }\n\n  isNonEmpty(minSizeBytes = 1): Promise<boolean> {\n    return thenNot(this.isEmpty(minSizeBytes))\n  }\n\n  async isNonEmptyFile(minSizeBytes = 1): Promise<boolean> {\n    return (await this.isFile()) && (await this.isNonEmpty(minSizeBytes))\n  }\n\n  async modifiedGTE(mtime: Date): PromiseMaybe<boolean> {\n    return thenMap(\n      this.mtime(),\n      thisMtime =>\n        // Filesystems have only second-level resolution\n        unixtime(thisMtime) >= unixtime(mtime)\n    )\n  }\n\n  async modifiedCloseTo(\n    mtimeMs: number,\n    deltaMs: number\n  ): PromiseMaybe<boolean> {\n    return thenMap(\n      this.mtimeMs(),\n      thisMtimeMs => Math.abs(thisMtimeMs - mtimeMs) <= deltaMs\n    )\n  }\n\n  async isRecent(agoMs: number): Promise<boolean> {\n    const mtime = await this.maxStatMs()\n    return mtime != null && mtime > Date.now() - agoMs\n  }\n\n  async modifiedGT(mtime: Maybe<Date>): PromiseMaybe<boolean> {\n    if (mtime == null) return\n    return thenMap(\n      this.mtime(),\n      thisMtime =>\n        // Filesystems have only second-level resolution\n        unixtime(thisMtime) > unixtime(mtime)\n    )\n  }\n\n  async isDirectory(): Promise<boolean> {\n    if (this.dirent != null) return this.dirent.isDirectory()\n    return thenMapOr(\n      this.stat(),\n      ea => ea.isDirectory(),\n      () => false\n    )\n  }\n\n  async isNotDirectory(): Promise<boolean> {\n    return thenNot(this.isDirectory())\n  }\n\n  isDirectorySync(): boolean {\n    if (this.dirent != null) return this.dirent.isDirectory()\n    return mapOr(\n      this.statSync(),\n      ea => ea.isDirectory(),\n      () => false\n    )\n  }\n\n  async nearestDir(): Promise<this> {\n    return (await this.isDirectory()) ? this : this.parent()\n  }\n\n  async isFile(): Promise<boolean> {\n    if (this.dirent != null) return this.dirent.isFile()\n    return this.stat().then(stat =>\n      opt(stat)\n        .map(ea => ea.isFile())\n        .getOrElse(() => false)\n    )\n  }\n\n  isFileSync(): boolean {\n    if (this.dirent != null) return this.dirent.isFile()\n    return opt(this.statSync()).filter(ea => ea.isFile()).isDefined\n  }\n\n  rmdir(errLogLevel: LogLevel = \"warn\"): Promise<boolean> {\n    this.clear()\n    return this.trapOr(\"rmdir\", () => fse.rmdir(this.nativePath), errLogLevel)\n  }\n\n  /**\n   * @throws on error\n   */\n  async mkdirp_(): Promise<this> {\n    // Try simple call first:\n    try {\n      await fse.mkdirp(this.nativePath)\n    } catch (err) {\n      // race condition:\n      if (err.code !== \"EEXIST\") throw err\n    }\n    // // SITS: workaround for linux fs-extra's failure to copy files to NTFS\n    // // partitions due to lag. Hypothetically we should be able to just\n    // // mkdirp() and be done, but that doesn't work.\n    // if (null == (await this.parent().mkdirp())) {\n    //   throw new Error(\"Failed to mkdirp parent of \" + this)\n    // }\n    // await fse.mkdirp(this.nativePath)\n    if (\n      // kernel FS lag can't be longer than a second or two\n      false ===\n      (await untilTrue(() => this.clear().isDirectory(), {\n        timeoutMs: 2 * secondMs,\n        timeBetweenMs: 200\n      }))\n    ) {\n      throw new Error(\"Failed to mkdirp \" + this)\n    } else {\n      // this and parent because parent caches children.\n      return this.clearThisAndParent()\n    }\n  }\n\n  async mkdirp(): PromiseMaybe<this> {\n    if ((await this.clear().isDirectory()) || this.isRoot) return this\n    return this.trap(\"mkdirp\", async () => this.mkdirp_())\n  }\n\n  /**\n   * @throws on error\n   */\n  mkdirpSync_(): this {\n    fse.mkdirpSync(this.nativePath)\n    return this.clearThisAndParent()\n  }\n\n  mkdirpSync(): Maybe<this> {\n    if (this.isRoot) return this\n    return this.trapSync(\"mkdirpSync\", () => this.mkdirpSync_())\n  }\n\n  readonly shaResult = lazy(async () => {\n    const size = await this.size()\n    if (size === 0 || size == null) {\n      return undefined\n    }\n    const observer =\n      size > 5 * MiB\n        ? new PushProgressObserver(\n            { op: \"Computing SHA of\", path: this.nativePath },\n            size\n          )\n        : undefined\n    const result = await elapsedAsync(() =>\n      this.trap(\"sha\", () => fileSha([this.nativePath], { observer }))\n    )\n    const b64 = map(result.result, ea => ea.toString(\"base64\"))\n    return {\n      elapsedMs: result.elapsedMs,\n      buffer: result.result,\n      b64\n    }\n  }, BaseFile.attrTTL)\n\n  /**\n   * base64 encoded SHA-512/192 (ish)\n   */\n  sha(): PromiseMaybe<string> {\n    return thenMap(this.shaResult(), r => r.b64)\n  }\n\n  /**\n   * @return ms to gather the sha for this file\n   */\n  shaMs(): PromiseMaybe<number> {\n    return thenMap(this.shaResult(), r => r.elapsedMs)\n  }\n\n  /**\n   * @throws so when readables encounter errors in the midst of reading, they\n   * can propagate the error to the caller\n   */\n  async writeStream_(\n    readable: Readable,\n    options?: WriteOptions & { onProgress?: (bytes: number) => any }\n  ): PromiseMaybe<this> {\n    await pipelineAsync(\n      compact([\n        readable,\n        map(options?.onProgress, f => new ByteCounter(f)),\n        fse.createWriteStream(this.nativePath, options)\n      ])\n    )\n    return this.clearThisAndParent()\n  }\n\n  async writeJsonMaybe(\n    object: any,\n    options: WriteOptions & {\n      replacer?: (key: string, value: any) => any\n      spaces?: number\n    } = {}\n  ): PromiseMaybe<this> {\n    // outputJSON is almost the same as writeJson, except that if the directory\n    // does not exist, it's created\n    return this.trap(\"writeJsonMaybe\", () => this.writeJSON_(object, options))\n  }\n\n  /**\n   * @throws on error\n   */\n  async writeJSON_(\n    object: any,\n    options: WriteOptions & {\n      replacer?: (key: string, value: any) => any\n      spaces?: number\n    } = {}\n  ): PromiseMaybe<this> {\n    // outputJSON is almost the same as writeJson, except that if the directory\n    // does not exist, it's created\n    await this.parent().mkdirp()\n    // fs-extra's writeJSON seemed to delete the file first, so we're using\n    // writeFile with the overwrite mode flag:\n    await fse.writeFile(\n      this.nativePath,\n      stringify(object, options.replacer, options.spaces),\n      { flag: \"w\", ...options }\n    )\n    return this.clearThisAndParent()\n  }\n\n  readJson<T>(errLogLevel: LogLevel = \"warn\"): PromiseMaybe<T> {\n    return this.trap(\n      \"readJson\",\n      () =>\n        retryOnReject(\n          async () =>\n            (await this.isNonEmptyFile())\n              ? fse.readJson(this.nativePath)\n              : undefined,\n          {\n            maxRetries: 1,\n            onRetryWaitUntil: () => delay(errLogLevel === \"warn\" ? 250 : 25),\n            errorIsRetriable: err => err[\"errno\"] !== -2 // ENOENT\n          }\n        ),\n      errLogLevel\n    )\n  }\n\n  readJsonSync(): Maybe<any> {\n    return this.trapSync(\"readJsonSync\", () =>\n      fse.readJsonSync(this.nativePath)\n    )\n  }\n\n  readFileSync_() {\n    return fse.readFileSync(this.nativePath)\n  }\n\n  readFile_() {\n    return fse.readFile(this.nativePath)\n  }\n\n  readFile(errLogLevel: LogLevel = \"warn\"): PromiseMaybe<Buffer> {\n    return this.trap(\"readFile\", () => this.readFile_(), errLogLevel)\n  }\n\n  /**\n   * `readFile`, but on-the-fly decompression for .gz and .br\n   * @throws on error\n   */\n  async zReadFile_(options?: {\n    start?: number\n    end?: number\n  }): PromiseMaybe<Buffer> {\n    return zCopyToBuffer_(this.nativePath, options)\n  }\n\n  async zcat(options?: { start?: number; end?: number }): PromiseMaybe<string> {\n    return this.trap(\"zcat\", () => thenMap(this.zReadFile_(options), toS))\n  }\n\n  async zCopyFile(dest: this, options?: { start?: number; end?: number }) {\n    return this.trap(\"zCopyFile\", async () => {\n      await dest.parent().mkdirp()\n      await zCopyTo_(\n        this.nativePath,\n        fs.createWriteStream(dest.nativePath),\n        options\n      )\n      return dest\n    })\n  }\n\n  readLines(): PromiseMaybe<string[]> {\n    return thenMap(this.readFile(), buf => splitLines(buf.toString()))\n  }\n\n  readFileSync(): Maybe<string> {\n    return Try(() => map(fs.readFileSync(this.nativePath), toS))\n  }\n\n  /**\n   * @throws on error\n   */\n  writeTxt_(txt: string) {\n    return this.writeFile_(crlf(txt))\n  }\n\n  /**\n   * @throws on error\n   */\n  async writeFile_(data: string | Buffer) {\n    // Don't try to make the mountpoint (or, say, \"c:\")\n    await this.parent().mkdirp()\n    await fse.writeFile(this.nativePath, data)\n    return this.clearThisAndParent()\n  }\n\n  wip(wipPrefix = WipPrefix): this {\n    return this.sibling(wipPrefix + this.base)\n  }\n\n  /**\n   * @throws if there are errors\n   */\n  async unwip_(wipPrefix = WipPrefix): Promise<this> {\n    const dest = this.sibling(stripPrefix(this.base, wipPrefix))\n    return this.mv_(dest, { overwrite: true })\n  }\n\n  private async dest(destOrDestDir: this): Promise<this> {\n    const destOrDir = destOrDestDir.clear() // < bust cache\n    return (notBlank(this.ext) && blank(destOrDir.ext)) ||\n      (await destOrDir.isDirectory())\n      ? destOrDir.join(this.base)\n      : destOrDir\n  }\n\n  /**\n   * Atomically overwrite `destOrDestDir.join(paths)` with the contents of\n   * `this`. Use `.ensureNew` on destOrDestDir if you want to prevent\n   * overwriting.\n   *\n   * If the result of joining `destOrDestDir` and `paths` results in an\n   * extensionless name, the path will be assumed to be a containing directory,\n   * and this name will be appended to the result.\n   *\n   * @throws if there are any errors\n   */\n  copyFile_(destFileOrDir: this): Promise<this> {\n    return time(\"fs.copyFile\", async () => {\n      const dest = (await this.dest(destFileOrDir)).clear()\n      if (this.nativePath === dest.nativePath) {\n        return this\n      }\n      const mkdir = await dest.parent().mkdirp()\n      if (mkdir == null) return this.bflog().throw(\"Cannot mkdirp \" + dest.dir)\n\n      try {\n        return await this._copyFile(dest)\n      } catch (error) {\n        if (isNonRetriableError(error)) {\n          throw error\n        } else {\n          this.bflog().warn(\"_copyFile failed, trying _nativeCopyFile\", {\n            src: this.nativePath,\n            dest: dest.nativePath,\n            error\n          })\n          return await this._nativeCopyFile(dest)\n        }\n      } finally {\n        this.clearThisAndParent()\n      }\n    })\n  }\n\n  private async _copyFile(dest: this): Promise<this> {\n    let obs: Maybe<PullProgressObserver>\n    let wipDest: Maybe<this>\n    let result = dest\n    try {\n      const stat = await thenOrElse(this.stat(), () => this.clear().stat())\n      if (stat == null) {\n        return this.bflog().throw(\n          \"Can't copy missing files\" + NonRetriableErrorFlag\n        )\n      }\n      if (stat.size === 0) {\n        // empty file, skip copy\n        await dest.touch(stat.mtime, stat.atime)\n      } else {\n        if (Settings.verifyFileCopies.valueOrDefault) {\n          if ((await this.sha()) == null) {\n            return this.bflog().throw(\n              \"Can't copy file without SHA\" + NonRetriableErrorFlag\n            )\n          }\n        }\n        wipDest = dest.wip()\n        const p = fse.copyFile(this.nativePath, wipDest.nativePath)\n        if (stat.size > 5 * MiB) {\n          obs = new PullProgressObserver(\n            {\n              op: \"Copying\",\n              path: this.nativePath,\n              dest: dest.nativePath\n            } as any,\n            stat.size,\n            () => wipDest!.clear().size()\n          )\n        }\n        await p\n        const sizeMatches = await untilTrue(\n          async () => stat.size === (await wipDest!.clear().size()),\n          { timeoutMs: CmdTimeoutMs }\n        )\n        if (Settings.verifyFileCopies.valueOrDefault) {\n          const shaMatches =\n            sizeMatches &&\n            (await untilTrue(\n              () => eqlAsync(this.sha(), wipDest!.clear().sha()),\n              { timeoutMs: CmdTimeoutMs }\n            ))\n          if (!shaMatches) {\n            return this.bflog().throw(\"copyFile_() failed\", {\n              sizeMatches,\n              shaMatches\n            })\n          }\n        }\n        if (!sizeMatches) {\n          return this.bflog().throw(\"copyFile_() failed\", {\n            expectedSize: stat.size,\n            actualSize: await wipDest.clear().size()\n          })\n        }\n        result = await wipDest.unwip_()\n        if (result == null) {\n          return this.bflog().throw(\n            \"copyFile_(\" + dest + \") failed: .unwip() was null\"\n          )\n        }\n        await fse.utimes(result.nativePath, stat.atime, stat.mtime)\n      }\n      try {\n        await fse.chmod(result.nativePath, stat.mode)\n      } catch (err) {\n        this.bflog().debug(\n          `copyFile_(${result.nativePath}) warning: couldn't chmod to ${stat.mode}: ${err}`\n        )\n      }\n      this.bflog().debug(`copyFile_(${dest.nativePath}): success`)\n      emitFileCopied(this.nativePath, dest.nativePath)\n      return dest\n    } catch (err) {\n      this.bflog().warn(`copyFile_(${wipDest?.nativePath}) failed: ${err}`)\n      await wipDest?.unlink()\n      await dest.unlink()\n      throw err\n    } finally {\n      map(obs, ea => ea.end())\n    }\n  }\n\n  async copyTimeoutMs(): Promise<number> {\n    return thenMapOr(\n      this.size(),\n      bytes => Math.max(CmdTimeoutMs, bytes * MinIoRate),\n      () => CmdTimeoutMs\n    )\n  }\n\n  private async _nativeCopyFile(dest: this): Promise<this> {\n    let obs: Maybe<PullProgressObserver>\n    try {\n      if (null == (await dest.parent().mkdirp())) {\n        return this.bflog().throw(\"Can't mkdir destination directory\", {\n          src: this.nativePath,\n          dest: dest.nativePath\n        })\n      }\n      const stat = await this.stat()\n      const size = map(stat, ea => ea.size)\n      if (stat == null || size == null) {\n        return this.bflog().throw(\"Can't copy missing files\")\n      }\n      if (size > 5 * MiB) {\n        obs = new PullProgressObserver(\n          {\n            op: \"Copying\",\n            path: this.nativePath,\n            dest: dest.nativePath\n          } as any,\n          size,\n          () => dest.clear().size()\n        )\n      }\n\n      if (isWin) {\n        await PowerShell.instance().execute(\n          `Copy-Item -LiteralPath ${pwshQuote(\n            this.nativePath\n          )} -Destination ${pwshQuote(dest.nativePath)}`,\n          ea => ea\n        )\n      } else {\n        // -a means archive, or -pPR on macOS or -dR --preserve=all on debian\n        // -f means force. If existing dest cannot be opened, remove it and try again.\n        await stdout(\"cp\", [\"-a\", \"-f\", this.nativePath, dest.nativePath], {\n          timeout: await this.copyTimeoutMs()\n        })\n      }\n\n      emitFileCopied(this.nativePath, dest.nativePath)\n      return dest.clearThisAndParent()\n    } catch (err) {\n      return this.bflog().throw(\"_nativeCopyFile(\" + dest + \"): \" + err)\n    } finally {\n      map(obs, ea => ea.end())\n    }\n  }\n\n  async touch(\n    mtime: Date | number = Date.now(),\n    atime?: Date | number\n  ): PromiseMaybe<this> {\n    return this.trap(\"touch\", () =>\n      thenMap(this.ensureFile(), () => this.utimes(mtime, atime))\n    )\n  }\n\n  async utimes(\n    mtime?: Date | number,\n    atime?: Date | number\n  ): PromiseMaybe<this> {\n    const _mtime = orElse(mtime, Date.now())\n    const _atime = orElse(atime, _mtime)\n    return this.trap(\"utimes\", () =>\n      fse\n        .utimes(this.nativePath, unixtime(_atime), unixtime(_mtime))\n        .then(() => this.clearThisAndParent())\n    )\n  }\n\n  /**\n   * Deletes the current file.\n   * @return Promise<true> if unlink was successful\n   */\n  async unlink(errLogLevel: LogLevel = \"warn\") {\n    return this.trap(\n      \"unlink\",\n      async () => {\n        await fse.unlink(this.nativePath)\n        return this.clearThisAndParent()\n      },\n      errLogLevel\n    )\n  }\n\n  /**\n   * Delete files or directories. Should only be needed by tests or applied to\n   * cache dirs.\n   *\n   * Note that the promise may be returned before the file op is actually\n   * complete due to a (bug?) in fs-extra.\n   */\n  async rmrf(logLevel: LogLevel = \"info\"): PromiseMaybe<this> {\n    return this.trap(\"rmrf\", async () => {\n      this.bflog().log(logLevel, \"rmrf()\")\n      await fse.remove(this.nativePath)\n      return this.clearThisAndParent()\n    })\n  }\n\n  /**\n   * SITS: Mac sometimes locks files when they've been copied. No, I couldn't\n   * find out why, but if I own the file, I can chflags the file back to being\n   * unlocked.\n   *\n   * This should only be applied to newly-copied files, not files that I don't\n   * own (or have created).\n   */\n  async unlock(): Promise<this> {\n    if (isMac && (await this.clear().exists())) {\n      await stdout(\"chflags\", [\"nouchg\", this.nativePath], {\n        timeout: CmdTimeoutMs\n      })\n    }\n    return this\n  }\n\n  /**\n   * @throws on error\n   */\n  async renameWithNameSuffix_(nameSuffix: string): PromiseMaybe<this> {\n    return thenMap(\n      this.withNameSuffix(nameSuffix).ensureNew_({ emptyIsNew: true }),\n      dest => dest.unlink(\"debug\").then(() => this.mv_(dest))\n    )\n  }\n\n  /**\n   * @return the file that was copied into\n   * @throws error if there are issues\n   */\n  async mv_(\n    destFileOrDir: this,\n    opts: fse.MoveOptions = { overwrite: false }\n  ): Promise<this> {\n    const dest = await this.dest(destFileOrDir)\n    if (this.nativePath === dest.nativePath) {\n      this.bflog().warn(\"mv(): no-op\", new Error(\"internal error\"))\n      return this\n    }\n    await dest.parent().mkdirp()\n    this.bflog().debug(\"mv\", dest)\n    // https://github.com/jprichardson/node-fs-extra/blob/master/docs/move.md\n    // Moves a file or directory, even across devices:\n    try {\n      await fse.move(this.nativePath, dest.nativePath, opts)\n    } catch (err) {\n      this.bflog().warn(\n        \"mv() try #1 failed. Calling unlock() and waiting for source to be non-empty.\",\n        err\n      )\n      await Promise.all([this.unlock(), dest.unlock()])\n      await untilTrue(() => this.clear().isNonEmptyFile(), {\n        timeoutMs: 7 * secondMs\n      })\n      await fse.move(this.nativePath, dest.nativePath, opts)\n    }\n    await dest.unlock()\n    this.clearThisAndParent()\n    return dest.clearThisAndParent()\n  }\n\n  /**\n   * Supports gzip/gunzip/brotli/whatever transform you've got:\n   */\n  private async pipeTo(base: string, transform: Transform) {\n    return this.trap(\"pipeTo(\" + base + \")\", async () => {\n      const dest = await this.sibling(base).ensureNew_()\n      await pipelineAsync([\n        fs.createReadStream(this.nativePath),\n        transform,\n        fs.createWriteStream(dest.nativePath)\n      ])\n      await this.unlink()\n      return dest\n    })\n  }\n\n  async gunzip(): PromiseMaybe<this> {\n    return this.pipeTo(stripSuffix(this.base, \".gz\"), createGunzip())\n  }\n\n  async gzip(): PromiseMaybe<this> {\n    return this.pipeTo(this.base + \".gz\", createGzip())\n  }\n\n  async compressBrotli(): PromiseMaybe<this> {\n    return this.pipeTo(this.base + \".br\", createBrotliCompress())\n  }\n\n  ensureFile(): PromiseMaybe<this> {\n    return this.trap(\"ensureFile\", () =>\n      fse.ensureFile(this.nativePath).then(() => this.clearThisAndParent())\n    )\n  }\n\n  /**\n   * @throws on error\n   */\n  ensureFileSync_() {\n    fse.ensureFileSync(this.nativePath)\n    return this.clearThisAndParent()\n  }\n\n  /**\n   * @return \"P12345\" from \"/var/tmp/P12345-01.JPG\"\n   */\n  get nameWithoutCount(): string {\n    return nameWithoutCount(this.name)\n  }\n\n  /**\n   * @return \"P12345.JPG\" from \"/var/tmp/P12345-01.JPG\"\n   */\n  get baseWithoutCount(): string {\n    return this.nameWithoutCount + this.ext\n  }\n\n  get baseWithoutCountWithParent(): string {\n    return this.parent().base + \"/\" + this.baseWithoutCount\n  }\n\n  get siblingWithoutCount(): this {\n    return this.sibling(this.baseWithoutCount)\n  }\n\n  /**\n   * Returns a basename in this directory with this same .ext and prefixed with\n   * this.name which either doesn't exist or is zero length.\n   *\n   * If `options.emptyIsNew` is `true`, the file may exist, but must be\n   * zero-length. If `options.emptyIsNew` is `false`, the returned path will be\n   * nonexistent.\n   */\n  async ensureNewNativePath(\n    options: Omit<EnsureNewOptions, \"nativePath\">\n  ): Promise<string> {\n    return ensureNewNativePath_({ nativePath: this.nativePath, ...options })\n  }\n\n  /**\n   * @throws if errors\n   */\n  ensureNew_(opts: Partial<EnsureNewOptions> = {}): Promise<this> {\n    return this.ensureNewNativePath(opts).then(p => this.for(p))\n  }\n\n  /**\n   * @throws if errors\n   */\n  async renameYMDHMS_(subdir?: string): Promise<this> {\n    if (await this.clear().notExists()) {\n      throw new Error(\"Cannot rename: \" + this + \" doesn't exist.\")\n    }\n    const ts = fmtYMDHMS(await thenOrElse(this.mtime(), () => new Date()))\n    const destDir = mapOr(\n      subdir,\n      ea => this.parent().join(ea),\n      () => this.parent()\n    )\n    return this.mv_(destDir.join(this.name + \"-\" + ts + this.ext), {\n      overwrite: true\n    })\n  }\n\n  /**\n   * If `this` exists and has new contents for this current directory, rename it\n   * to a new file with the given base (and possibly a count, to ensure new\n   * overwriting).\n   *\n   * If `this` is empty, or already has the same contents as another file in\n   * this directory, return that file and unlink this file.\n   */\n  async saveIfNewOrDelete(base: string): PromiseMaybe<this> {\n    if (await this.clear().isEmpty()) {\n      // don't complain about removing a missing file:\n      await this.unlink(\"trace\")\n      return\n    }\n    const prior = await this.siblingWithSameContents()\n    if (prior != null) {\n      await this.unlink()\n      return prior\n    }\n    const dest = await this.sibling(base).ensureNew_()\n    return this.mv_(dest)\n  }\n\n  /**\n   * Make sure you encode `mode` in octal! 0o644\n   */\n  async chmod(mode: string | number): Promise<this> {\n    await fse.chmod(this.nativePath, mode)\n    return this.clear()\n  }\n\n  zreadline(): LineReader {\n    return fs\n      .createReadStream(this.nativePath)\n      .on(\"error\", (err: any) => {\n        throw new Error(\"Failed to read from \" + this + \": \" + err)\n      })\n      .pipe(createGunzip())\n      .on(\"error\", (err: any) => {\n        throw new Error(\"Failed to gunzip \" + this + \": \" + err)\n      })\n      .pipe(new LineReader())\n  }\n\n  // /**\n  //  * Just like `zcat`, this decompresses iff the file suffix is .gz, or returns\n  //  * the plain file contents if the file suffix is anything else.\n  //  */\n  // zcat(): PromiseMaybe<Buffer> {\n  //   if (!this.ext.endsWith(\".gz\")) {\n  //     return thenMap(this.readFile(), buf => buf.toString())\n  //   }\n  //   return this.trap(\"zcat\", async () => {\n  //     const wb = new WritableToBuffer()\n  //     await new Promise((res, rej) =>\n  //       pipeline(\n  //         fse.createReadStream(this.nativePath),\n  //         createGunzip(),\n  //         wb,\n  //         err => (err == null ? res() : rej(err))\n  //       )\n  //     )\n  //     return wb.buffer\n  //   })\n  // }\n\n  async siblingWithSameContents(): PromiseMaybe<this> {\n    return this.parent().childWithSameContents(this)\n  }\n\n  async childWithSameContents(target: this): PromiseMaybe<this> {\n    return time(\"fs.childWithSameContents\", async () => {\n      if ((await this.notExists()) || !(await this.isDirectory())) {\n        return\n      }\n      const targetSize = await target.size()\n      const children = await this.children()\n      const sameSize: this[] = []\n      for (const child of toA(children)) {\n        if ((await child.size()) === targetSize && !target.eql(child)) {\n          sameSize.push(child)\n        }\n      }\n      // Don't need to sha target if none are the same size:\n      if (isEmpty(sameSize)) {\n        return\n      }\n      const targetSha = await target.sha()\n      // Assume similar names are more likely to be the same. Try those first.\n      for (const child of sameSize\n        .sort((a, b) => diceCoeff(a.base, b.base))\n        .reverse()) {\n        if ((await child.sha()) === targetSha) {\n          return child\n        }\n      }\n      return\n    })\n  }\n\n  async applyWip<T>(\n    f: (destination: this) => Promise<T>,\n    minSizeBytes = 0,\n    ttlMs = 15 * secondMs\n  ): PromiseMaybe<T> {\n    const wip = this.wip()\n    try {\n      await wip.parent().mkdirp()\n\n      // If the wip file exists and is recent, try waiting for a bit to see if someone else built it:\n      if (\n        (await wip.clear().isRecent(ttlMs)) ||\n        (await this.clear().isRecent(ttlMs))\n      ) {\n        this.bflog().info(\n          \"applyWip(): recent WIP exists. Waiting for a bit to see if someone else will do my work.\"\n        )\n        if (\n          await untilTrue(() => this.clear().isNonEmpty(minSizeBytes), {\n            timeoutMs: ttlMs * 2,\n            timeBetweenMs: 500\n          })\n        ) {\n          this.bflog().info(\"applyWip(): yay, someone else did my work.\")\n          return\n        }\n      }\n      // Try to prevent race conditions:\n      await this.touch()\n      // note can't touch WIP file because of EXIFTOOL no clobber policy\n      await wip.unlink(\"trace\")\n      const result = await f(wip)\n      const isNonEmpty = await untilTrue(() => wip.clear().isNonEmptyFile(), {\n        timeoutMs: secondMs\n      })\n      if (isNonEmpty) {\n        await wip.unwip_() // throws errors if issues\n        return result\n      } else {\n        throw new Error(\"applyWip(): empty after apply for \" + this)\n      }\n    } catch (err) {\n      await wip.unlink()\n      await this.unlink()\n      throw err\n    }\n  }\n\n  /**\n   * @throws !!!\n   */\n  async applyIfEmpty_(\n    f: (destination: this) => Promise<any>,\n    minSizeBytes = 0\n  ): PromiseMaybe<this> {\n    if (await this.clear().isNonEmpty(minSizeBytes)) {\n      this.bflog().debug(\"applyIfEmpty(): non-empty\")\n    } else {\n      this.bflog().debug(\"applyIfEmpty(): empty, applying...\")\n      // throws if there is a problem:\n      await this.applyWip(f, minSizeBytes)\n    }\n    // Always touch (to prevent img cache from removing currently-used caches):\n    return this.touch()\n  }\n\n  firstMatchingLine(re: RegExp): PromiseMaybe<RegExpMatchArray> {\n    const d = new Deferred<Maybe<RegExpMatchArray>>(\n      \"firstMatchingLine(\" + this + \")\"\n    )\n    const r = fs.createReadStream(this.nativePath, { flags: \"r\" })\n    r.on(\"error\", (err: any) => {\n      if (err.errno === -2 || err.code === \"ENOENT\") {\n        d.maybeResolve(undefined)\n        r.close()\n      } else {\n        d.maybeReject(err)\n      }\n    })\n    r.on(\"close\", () => d.maybeResolve(undefined))\n    void onDataChunked(r, newlineRe, ea => {\n      const m = re.exec(ea)\n      if (m != null) {\n        d.maybeResolve(m)\n        r.close()\n      }\n    })\n    return d.promise\n  }\n\n  contemporary(b: BaseFile, maxDiffMs: number): Promise<boolean> {\n    return thenMap2Or(\n      this.statTimes(),\n      b.statTimes(),\n      (arr1, arr2) => {\n        for (const i of arr1) {\n          for (const j of arr2) {\n            if (closeTo(i, j, maxDiffMs)) {\n              return true\n            }\n          }\n        }\n        return false\n      },\n      () => false\n    )\n  }\n}\n\nexport function execDir(): BaseFile {\n  return BaseFile.for(process.execPath).parent()\n}\n", "import { compact } from \"../../fe/Array\"\nimport { mapOr } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { SyncOrAsync } from \"../../fe/OptAsync\"\nimport { filterAsync } from \"./Promise\"\n\nexport interface SyncPredicate<T> {\n  (t: T): boolean\n}\n\nexport interface Predicate<T> {\n  (t: T): SyncOrAsync<boolean>\n}\n\nexport const True: Predicate<any> = () => true\n\nexport function not<T>(p: SyncPredicate<T>): SyncPredicate<T> {\n  return (item: T) => {\n    return !p(item)\n  }\n}\n\nexport function and<T>(...arr: SyncPredicate<T>[]): SyncPredicate<T> {\n  return (item: T) => {\n    for (const ea of arr) {\n      if (!ea(item)) return false\n    }\n    return true\n  }\n}\n\nexport function or<T>(...arr: SyncPredicate<T>[]): SyncPredicate<T> {\n  return (item: T) => {\n    for (const ea of arr) {\n      if (ea(item)) return true\n    }\n    return false\n  }\n}\n\nexport function all<T>(arr: T[], p: SyncPredicate<T>): boolean {\n  for (const e of arr) {\n    if (!p(e)) return false\n  }\n  return true\n}\n\nexport function some<T>(arr: T[], p: SyncPredicate<T>): boolean {\n  for (const e of arr) {\n    if (p(e)) return true\n  }\n  return false\n}\n\nexport function none<T>(arr: T[], p: SyncPredicate<T>): boolean {\n  for (const e of arr) {\n    if (p(e)) return false\n  }\n  return true\n}\n\nexport function find<T>(arr: T[], p: SyncPredicate<T>): Maybe<T> {\n  for (const ea of arr) {\n    if (p(ea)) {\n      return ea\n    }\n  }\n  return\n}\n\nexport async function filter<T>(\n  arr: Maybe<Maybe<T>[]>,\n  p?: Predicate<T>\n): Promise<T[]> {\n  if (arr == null || p == null) return mapOr(arr, compact, () => [])\n  return filterAsync(arr, p)\n}\n\nexport async function apply<T>(\n  t: Maybe<T>,\n  p: Maybe<Predicate<T>>\n): PromiseMaybe<T> {\n  return t == null || p == null ? t : (await p(t)) ? t : undefined\n}\n", "import { map } from \"../fe/Maybe\"\nimport { SyncOrAsync } from \"../fe/OptAsync\"\nimport { Thunk } from \"../fe/Thunk\"\nimport { Logger } from \"./Logger\"\n\nexport class Elapsed {\n  private ts = Date.now()\n  constructor(\n    readonly l: Logger,\n    readonly listener?: (name: string, elapsedMs: number) => any\n  ) {}\n\n  elapsed(msg: string) {\n    const now = Date.now()\n    const diff = now - this.ts\n    this.ts = now\n    map(this.listener, ea => ea(msg, diff))\n    if (diff > 2) {\n      this.l.log(diff > 500 ? \"warn\" : diff > 100 ? \"info\" : \"debug\", msg, {\n        elapsedMs: diff\n      })\n    }\n  }\n}\n\nexport function elapsed<T>(t: Thunk<T>): { elapsedMs: number; result: T } {\n  const start = Date.now()\n  const result = t()\n  return { elapsedMs: Date.now() - start, result }\n}\n\nexport async function elapsedAsync<T>(\n  t: () => SyncOrAsync<T>\n): Promise<{ elapsedMs: number; result: T }> {\n  const start = Date.now()\n  const result = await t()\n  return { elapsedMs: Date.now() - start, result }\n}\n\nexport async function thenElapsed<T>(\n  p: Promise<T>\n): Promise<{ elapsedMs: number; result: T }> {\n  const start = Date.now()\n  const result = await p\n  return { elapsedMs: Date.now() - start, result }\n}\n", "import { mapNotEmpty, sortBy } from \"../../fe/Array\"\nimport { secondMs } from \"../../fe/Date\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { getOrSet } from \"../../fe/Map\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { mapFinite, round, sigFigs } from \"../../fe/Number\"\nimport { compactValues, fromEntries, omit, tap } from \"../../fe/Object\"\nimport { opt } from \"../../fe/Opt\"\nimport { SyncOrAsync } from \"../../fe/OptAsync\"\nimport { CountingSet } from \"../CountingSet\"\nimport { Elapsed } from \"../Elapsed\"\nimport { Logger, mkLogger } from \"../Logger\"\nimport { Average, AverageStats } from \"../math/Average\"\nimport { Pojo } from \"../Object\"\nimport { EndableRanks } from \"./Endable\"\nimport { EndableWrapper } from \"./EndableWrapper\"\n\nconst MinMs = 15\n\nexport class PromiseTimer {\n  private readonly errors = new CountingSet<string>()\n  private readonly times = new Map<string, Average>()\n\n  async time<T>(\n    desc: string,\n    p: () => SyncOrAsync<T>,\n    post?: (result: T | Error, elapsed: number) => void\n  ): Promise<T> {\n    const start = Date.now()\n    try {\n      const result = await p()\n      const elapsed = Date.now() - start\n      if (post != null) post(result, elapsed)\n      this.push(desc, elapsed)\n      if (elapsed > 2 * secondMs) {\n        mkLogger(\"time(\" + desc + \")\").warn(\"slow\", { elapsed })\n      }\n      return result\n    } catch (err) {\n      this.errors.incr(desc)\n      if (post != null) post(err, Date.now() - start)\n      throw err\n    }\n  }\n\n  get entriesBySumDesc() {\n    return sortBy([...this.times.entries()], ([, v]) => -v.sum)\n  }\n\n  stats(namePrefix: string) {\n    const arr = this.entriesBySumDesc.filter(([k]) => k.startsWith(namePrefix))\n    const merged = arr.reduce(\n      (agg, ea) => Average.merge(ea[1], agg),\n      new Average()\n    )\n    const stats = arr.map(\n      ([name, avg]) => [name, avg.stats()] as [string, AverageStats]\n    )\n    return fromEntries([[\"merged\", merged.stats()], ...stats])\n  }\n\n  mkElapsed(l: Logger) {\n    return new Elapsed(l, (s, ts) => this.push(s, ts))\n  }\n\n  push(name: string, elapsedMs: number) {\n    if (elapsedMs > MinMs) {\n      getOrSet(this.times, name, () => new Average()).push(elapsedMs)\n    }\n  }\n\n  weightedAvg(name: string): Maybe<number> {\n    return opt(this.times.get(name))\n      .map(avg => avg.weightedSampleAvg)\n      .get()\n  }\n\n  errorCounts() {\n    return this.errors.entriesByCountDesc()\n  }\n\n  callCounts(): { [name: string]: number } {\n    return [...this.times.entries()].reduce(\n      (o, [k, v]) => ({ ...o, [k]: v.n }),\n      {}\n    )\n  }\n\n  weightedAvgs(): { [name: string]: number } {\n    return compactValues(\n      [...this.times.entries()].reduce(\n        (o, [k, v]) => ({ ...o, [k]: mapFinite(v.weightedSampleAvg, round) }),\n        {}\n      )\n    ) as any\n  }\n\n  report(): { [name: string]: Pojo } {\n    // Sort by most time first:\n    return this.entriesBySumDesc.reduce(\n      (o, [k, v]) => ({\n        ...o,\n        [k]: {\n          sumSec: sigFigs(v.sum / secondMs, 3),\n          ...omit(v.stats(), \"sum\")\n        }\n      }),\n      {}\n    )\n  }\n}\n\nconst instance = lazy(() =>\n  tap(\n    new PromiseTimer(),\n    timer =>\n      new EndableWrapper(\n        \"PromiseTimer\",\n        () => {\n          const l = mkLogger(\"PromiseTimer\")\n          l.info(\"timings:\\n\", timer.report())\n          mapNotEmpty(timer.errorCounts(), err =>\n            l.warn(\"error counts:\\n\", err)\n          )\n        },\n        EndableRanks.service\n      )\n  )\n)\n\nexport function mkElapsed(name: string) {\n  return instance().mkElapsed(mkLogger(name))\n}\n\nexport function time<T>(\n  name: string,\n  p: () => SyncOrAsync<T>,\n  post?: (result: T | Error, elapsed: number) => void\n): Promise<T> {\n  return instance().time(name, p, post)\n}\n\nexport function timeStats(namePrefix: string) {\n  return instance().stats(namePrefix)\n}\n\nexport function timeReport() {\n  return instance().report()\n}\n\nexport function timedLazy<T>(\n  name: string,\n  thunk: () => SyncOrAsync<T>,\n  ttlMs?: number\n) {\n  return lazy(async () => time(name, thunk), ttlMs)\n}\n", "import { randomBytes } from \"crypto\"\nimport { blank } from \"../../fe/Blank\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { isFunction } from \"../../fe/ObjectType\"\nimport { decuss } from \"../Cuss\"\nimport { identity } from \"../Object\"\nimport { splitEvery } from \"../String\"\n\nconst zero: any = BigInt(0)\n\nexport function encodeDigits(base: number, i: number, minLength = 0): number[] {\n  if (!isFinite(i) || base <= 1) return []\n\n  const digits: number[] = []\n  // use push and reverse instead of unshift to make sure we're prematurely\n  // optimizing all the things:\n  if (i === 0) {\n    digits.push(0)\n  } else {\n    while (i > 0) {\n      digits.push(i % base)\n      i = Math.floor(i / base)\n      // console.log(\"encodeDigits\", { i, base, digits })\n    }\n  }\n  while (digits.length < minLength) digits.push(0)\n  return digits.reverse()\n}\n\nexport class Radix {\n  readonly base: number\n  constructor(\n    readonly name: string,\n    readonly numerals: string,\n    readonly decodePreparser: (s: string) => string = identity\n  ) {\n    this.base = numerals.length\n  }\n\n  private digitsToNumerals(digits: number[]): string {\n    return digits.map(d => this.numerals[d]).join(\"\")\n  }\n\n  encode(num: number, minLength: number = 0): string {\n    if (!isFinite(num)) return \"\"\n    // r is a reversed array of chars:\n    const negate = num < 0\n    if (negate) {\n      num = Math.abs(num)\n      minLength-- // accommodate the sign\n    }\n    return (\n      (negate ? \"-\" : \"\") +\n      this.digitsToNumerals(encodeDigits(this.base, num, minLength))\n    )\n  }\n\n  encodeBigInt(bi: BigInt): string {\n    if (typeof bi !== \"bigint\") throw new Error(\"bad input\")\n    if (bi === zero) return this.numerals[0]\n\n    const digits: number[] = []\n    const b = BigInt(this.base)\n    let i: any = bi\n\n    while (i > zero) {\n      digits.push(Number(i % b))\n      i = i / b\n    }\n    return this.digitsToNumerals(digits.reverse())\n  }\n\n  encodeBuffer(buf: Buffer): string {\n    if (buf == null || buf.length === 0) return \"\"\n    const digits = [0]\n    for (let b of buf) {\n      digits.forEach((d, i) => {\n        // const b0 = b\n        b += d << 8\n        digits[i] = b % this.base\n        b = Math.floor(b / this.base)\n        // console.dir({ i, b0, b, d0: d, d: digits[i], digits })\n      })\n\n      while (b > 0) {\n        digits.push(b % this.base)\n        b = Math.floor(b / this.base)\n        // console.dir({ b, digits })\n      }\n    }\n    return this.digitsToNumerals(digits.reverse())\n  }\n\n  decode(s: Maybe<string>): Maybe<number> {\n    return map(this.decodeBigInt(s), ea => {\n      if (ea > BigInt(Number.MAX_SAFE_INTEGER)) {\n        throw new Error(\"decode(\" + s + \") is > 2^53\")\n      } else {\n        return Number(ea)\n      }\n    })\n  }\n\n  normalize(s: string): string {\n    return this.decodePreparser(s)\n  }\n\n  decodeBigInt(s: Maybe<string>): Maybe<bigint> {\n    if (s == null || blank(s)) return\n    s = isFunction(this.decodePreparser) ? this.decodePreparser(s) : s\n    const negate = s[0] === \"-\"\n    if (negate) {\n      s = s.slice(1)\n    }\n    const b = BigInt(this.base)\n    let acc = BigInt(0)\n    for (const ch of s) {\n      const idx = this.numerals.indexOf(ch)\n      if (idx < 0) {\n        return undefined\n      }\n      acc = acc * b + BigInt(idx)\n    }\n    return negate ? BigInt(-1) * acc : acc\n  }\n\n  randomChars(length: number): string {\n    // bits per char is Math.log2(this.base).\n\n    // we need bpc * length / 8 = random bytes.\n\n    // all these radix are < 256, so just fetch a couple extra bytes and trim:\n    return this.encodeBuffer(randomBytes(length + 3)).slice(1, length + 1)\n  }\n\n  safeRandomChars(length: number): string {\n    return decuss(() => this.randomChars(length))\n  }\n\n  /**\n   * UIDs are easier to parse or read if dashes break up the string.\n   *\n   * Reading 4-char groups is comfortable, 5 chars \"won-aye-six-gee-why\" is\n   * doable, I think, so split every 5?\n   *\n   * For GeoRadix, each char encodes 5 bits, so 20 chars is only 100 bits of\n   * entropy. 24 chars is 120. We need 32 chars for 160 bits, that's a lot.\n   */\n  randomUid(chars = 20, splitEveryN = 5, sepChar = \"-\"): string {\n    return splitEvery(this.randomChars(chars), splitEveryN).join(sepChar)\n  }\n\n  safeRandomUid(chars: number, splitEveryN = 5, sepChar = \"-\"): string {\n    return decuss(() => this.randomUid(chars, splitEveryN, sepChar))\n  }\n\n  tokenEql(a: string, b: string, minLen: number): boolean {\n    const an = this.normalizeToken(a)\n    const bn = this.normalizeToken(b)\n    return an.length >= minLen && an === bn\n  }\n\n  normalizeToken(a: string) {\n    return this.decodePreparser(a.trim())\n      .split(\"\")\n      .filter(ea => this.numerals.includes(ea))\n      .join(\"\")\n  }\n}\n\nexport const Hex = new Radix(\"hex\", \"0123456789abcdef\", s => s.toLowerCase())\n\n/**\n * URL-safe charset used for bitcoin and IPFS hashes\n * @see https://en.wikipedia.org/wiki/Base58\n */\nexport const Radix58 = new Radix(\n  \"Radix58\",\n  \"123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz\"\n)\n\n/**\n * Used by StringSimilarity.radixDiff\n */\nexport const RadixAlphaNum = new Radix(\n  \"RadixAlphaNum\",\n  \"0123456789abcdefghijklmnopqrstuvwxyz\",\n  s => s.toLowerCase()\n)\n\n/**\n * Base 32 charset for case-insensitive filesystems and human consumption\n * @see https://en.wikipedia.org/wiki/Geohash\n */\nexport const GeoRadix = new Radix(\n  \"GeoRadix\",\n  \"0123456789bcdefghjkmnpqrstuvwxyz\", // y no a?\n  s => s.toLowerCase()\n)\n\n/**\n * Base 32 charset for case-insensitive filesystems and human consumption.\n *\n * Similar glyphs include 0O, 1lI, 2z, 5S, 9g\n */\nexport const TokenRadix = new Radix(\n  \"TokenRadix\",\n  \"0123456789abcdefhjkmnpqrtuvwxy\",\n  s =>\n    s\n      .toLowerCase()\n      .replace(/[o]/g, \"0\")\n      .replace(/[il]/g, \"1\")\n      .replace(/[z]/g, \"2\")\n      .replace(/[s]/g, \"5\")\n      .replace(/[g]/g, \"9\")\n)\n\nexport const AlphaRadix = new Radix(\"AlphaRadix\", \"abcdefghjkmnpqrtuvwxyz\")\n\nexport const NumericRadix = new Radix(\"NumericRadix\", \"0123456789\", s =>\n  s\n    .toLowerCase()\n    .replace(/[o]/g, \"0\")\n    .replace(/[il]/g, \"1\")\n    .replace(/[z]/g, \"2\")\n    .replace(/[s]/g, \"5\")\n    .replace(/[g]/g, \"9\")\n)\n", "import { gunzipSync, gzipSync } from \"zlib\"\nimport { stepRange } from \"../../fe/Array\"\nimport { mapNotBlank } from \"../../fe/Blank\"\nimport { orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { absdiff } from \"../../fe/Number\"\nimport { zip } from \"../Array\"\nimport { hammRatioBigInt } from \"../Number\"\nimport { cosineSimilarity } from \"./Vector\"\n\nexport function hex2b64(hex: string): string {\n  return Buffer.from(hex, \"hex\").toString(\"base64\")\n}\n\nconst b64charset =\n  \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\"\n\nexport function b64encode(i: number | BigInt): string {\n  if (typeof i === \"number\" && i < b64charset.length) {\n    return b64charset[i]\n  }\n  let hex = i.toString(16)\n  // Make sure we're padded to even characters:\n  if (hex.length % 2 === 1) {\n    hex = \"0\" + hex\n  }\n  return Buffer.from(hex, \"hex\").toString(\"base64\")\n}\n\nexport function b64decode(base64: string): BigInt {\n  return BigInt(\"0x0\" + Buffer.from(base64, \"base64\").toString(\"hex\"))\n}\n\nexport function b64encodeString(s: string): string {\n  return Buffer.from(s, \"utf8\").toString(\"base64\")\n}\n\nexport function b64decodeString(b64: string): string {\n  return Buffer.from(b64, \"base64\").toString(\"utf8\")\n}\n\n// use gzip rather than brotli as a head-fake to licensing\nexport function gz64encodeString(s: string): string {\n  return gzipSync(Buffer.from(s, \"utf8\")).toString(\"base64\")\n}\n\nexport function d(s: string): string {\n  return gunzipSync(Buffer.from(s, \"base64\")).toString(\"utf8\")\n}\n\nexport const gz64decodeString = d\n\n/**\n * hamm...ratio...operator\n */\nexport function b64hammRatio(\n  a: Maybe<string>,\n  b: Maybe<string>\n): Maybe<number> {\n  return mapNotBlank(a, ea1 =>\n    mapNotBlank(b, ea2 => hammRatioBigInt(b64decode(ea1), b64decode(ea2)))\n  )\n}\n\nexport function b64decodeSmall(s: string): number {\n  if (s == null || s.length === 0) return -1\n  const a = s.split(\"\")\n  let acc = 0\n  for (const c of a) {\n    const idx = b64charset.indexOf(c)\n    if (idx === -1) return -1\n    if (acc > 2 ** (52 - 6))\n      throw new Error(\"b64decodeSmall(\" + s + \"): overflow\")\n    acc = acc * 64 + idx\n  }\n  return acc\n}\n\nexport function uint8toB64(i: number[]): string {\n  return Buffer.from(Uint8ClampedArray.from(i).buffer).toString(\"base64\")\n}\n\nexport function uint6toB64(arr: number[]): string {\n  return arr.map(i => b64charset[i & 0b111111]).join(\"\")\n}\n\nexport function uint12toB64(arr: number[]): string {\n  const r: string[] = []\n  arr.forEach(i => {\n    r.push(b64encode((i >> 6) & 0b111111))\n    r.push(b64encode(i & 0b111111))\n  })\n  return r.join(\"\")\n}\n\nfunction toValues(b64str: string, bitdepth: 6 | 12 = 6): number[] {\n  const step = bitdepth / 6\n  return stepRange(0, b64str.length, step, i =>\n    b64decodeSmall(b64str.substr(i, step))\n  )\n}\n\n/**\n * Given two vectors of values, b64 encoded, where either 1 or two characters\n * encode a pixel value, return a value between 0 and 1, where 1 is a perfect\n * match.\n * @return [-1,1], 1 meaning perfect correlation, -1 meaning perfect\n * anti-correlation (the inverse of an image, for example)\n */\nexport function b64corr(\n  a: string,\n  b: string,\n  bitdepth: 6 | 12 = 6\n): Maybe<number> {\n  if (a === b) return 1\n  const x = toValues(a, bitdepth)\n  const y = toValues(b, bitdepth)\n  // cosine simularity assumes values are well-distributed around 0. b64 is\n  // only ever positive, so shift values to the left:\n  const mean = Math.pow(2, bitdepth - 1)\n  return cosineSimilarity(\n    x.map(i => i - mean),\n    y.map(i => i - mean)\n  )\n}\n\n/**\n * The larger the number, the larger the difference\n */\nexport function b64diff(a: string, b: string, bitdepth: 6 | 12 = 6): number {\n  if (a === b) return 0\n  return zip(toValues(a, bitdepth), toValues(b, bitdepth)).reduce(\n    (agg, ea) => orElse(absdiff(ea[0], ea[1]), 0) + agg,\n    0\n  )\n}\n", "import { lazy } from \"../fe/Lazy\"\nimport { d } from \"./math/b64\"\n\n// Created by CussMk on 2021-03-08T19:05:54.222Z\n// from 2,618 words\n\nexport const CussWords = lazy(() =>\n  d(\n    \"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\"\n  ).split(\",\")\n)\n", "import { flatten } from \"../fe/Array\"\n\nexport function l33t(s: string): string {\n  return s\n    .replace(/o/g, \"0\")\n    .replace(/[il]/g, \"1\")\n    .replace(/e/g, \"3\")\n    .replace(/a/g, \"4\")\n    .replace(/s/g, \"5\")\n    .replace(/b/g, \"6\")\n    .replace(/t/g, \"7\")\n    .replace(/g/g, \"9\")\n}\n\nexport function unl33t(s: string): string[] {\n  return un1eet(\n    s\n      .replace(/0/g, \"o\")\n      .replace(/3/g, \"e\")\n      .replace(/4/g, \"a\")\n      .replace(/5/g, \"s\")\n      .replace(/6/g, \"b\")\n      .replace(/7/g, \"t\")\n      .replace(/9/g, \"g\")\n  )\n}\n\nfunction un1eet(s: string): string[] {\n  const i = s.indexOf(\"1\")\n  if (i === -1) {\n    return [s]\n  } else {\n    const pre = s.substr(0, i)\n    const suffs = un1eet(s.substr(i + 1))\n    return flatten(suffs.map(ea => [pre + \"l\" + ea, pre + \"i\" + ea]))\n  }\n}\n", "import { lazy } from \"../fe/Lazy\"\nimport { CussWords } from \"./CussWords\"\nimport { unl33t } from \"./Leet\"\nimport { MultiMap } from \"./MultiMap\"\nimport { stripDiacritics, stripEmoji } from \"./String\"\n\nconst cussTrie = lazy(() => asTrie(CussWords()))\n\n// uuid spec passes fastest with 3:\nconst TriePrefixLength = 3\n\nfunction asTrie(words: string[]) {\n  const trie = new MultiMap<string, string>()\n  const small: string[] = []\n  for (const ea of words) {\n    if (ea.length < TriePrefixLength) {\n      small.push(ea)\n    } else {\n      trie.add(ea.slice(0, TriePrefixLength), ea)\n    }\n  }\n  // console.log(\n  //   \"asTrie(): \" +\n  //     words.length +\n  //     \" words, \" +\n  //     trie.store.size +\n  //     \" prefixes, \" +\n  //     small.length +\n  //     \" too small\"\n  // )\n  return { trie, small }\n}\n\nexport function getCuss(s: string, naughtyWords?: string[]) {\n  const lc = stripEmoji(stripDiacritics(s.toLowerCase().normalize()))\n  const { small, trie } =\n    naughtyWords == null ? cussTrie() : asTrie(naughtyWords)\n  for (const w of [lc.replace(/[^a-z]/gi, \"\"), ...unl33t(lc)]) {\n    const smol = small.find(ea => w.includes(ea))\n    if (smol != null) return smol\n    for (let i = 0; i < w.length - (TriePrefixLength - 1); i++) {\n      const arr = trie.get(w.substr(i, TriePrefixLength))\n      if (arr != null) {\n        const sub = w.substr(i)\n        const bad = arr.find(ea => sub.startsWith(ea))\n        if (bad != null) {\n          return bad\n        }\n      }\n    }\n  }\n  return\n}\n\nexport function isCussy(s: string) {\n  return getCuss(s) != null\n}\n\nexport function decuss(f: () => string): string {\n  let retries = 10\n  let s = \"\"\n  do {\n    s = f()\n  } while (retries-- > 0 && isCussy(s.replace(/[^a-z]/gi, \"\")))\n\n  return s\n}\n", "import { commonPrefixLength, compactBlanks, count, sortBy } from \"../fe/Array\"\nimport { blank } from \"../fe/Blank\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { clamp, mapNumericOr, times, toInt } from \"../fe/Number\"\nimport { Primitive } from \"../fe/Primitive\"\nimport { toS } from \"../fe/toS\"\nimport { RadixAlphaNum } from \"./math/Radix\"\nimport { Array2D } from \"./Number\"\nimport { firstThunk } from \"./Object\"\nimport { intersection } from \"./Set\"\nimport { leftPad, stripDiacritics } from \"./String\"\n\n// export function commonPrefixChars(a: Maybe<string>, b: Maybe<string>): number {\n//   if (a == null || b == null) return 0\n//   const idx = a.split(\"\").findIndex((c, i) => c !== b[i])\n//   return idx === -1 ? a.length : idx\n// }\n\n/**\n * @return [0,1], where 0 means no common string, and 1 is equality\n */\nexport function commonSubstringRatio(a: string, b: string): number {\n  return [a, b].some(blank)\n    ? 0\n    : lcs(a, b).length / Math.max(a.length, b.length)\n}\n\n/**\n * @see https://en.wikipedia.org/wiki/Longest_common_substring_problem\n */\nexport function lcs(a: string, b: string): string {\n  if (a == null) return b\n  if (b == null) return a\n  a = a.normalize()\n  b = b.normalize()\n  if (a === b || b.includes(a)) return a\n  if (a.includes(b)) return b\n  const m = new Array2D(a.length)\n  let z = 0\n  let ret = \"\"\n  for (let i = 0; i < a.length; i++) {\n    for (let j = 0; j < b.length; j++) {\n      if (a[i] === b[j]) {\n        if (i === 0 || j === 0) {\n          m.set(i, j, 1)\n        } else {\n          m.set(i, j, m.get(i - 1, j - 1) + 1)\n        }\n        if (m.get(i, j) >= z) {\n          z = m.get(i, j)\n          ret = a.substr(i - z + 1, z)\n        }\n      }\n    }\n  }\n  return ret\n}\n\n/**\n * Hamming distance. Note that `a` and `b` must be the same length.\n * @see https://en.wikipedia.org/wiki/Hamming_distance\n */\nexport function hamming(a: string, b: string): Maybe<number> {\n  if (a == null || b == null) return undefined\n  a = a.normalize()\n  b = b.normalize()\n  return a.length !== b.length\n    ? undefined\n    : a\n        .split(\"\")\n        .reduce((acc, ea, idx) => (ea === b.charAt(idx) ? acc : acc + 1), 0)\n}\n\n/**\n * Return the S\u00F8rensen\u2013Dice similarity index between two strings.\n * @see https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n * @return [0,1]. O for no match, 1 for full, case-insensitive match.\n */\nexport function diceCoeff(a: string, b: string): number {\n  const A = a.toUpperCase().normalize()\n  const B = b.toUpperCase().normalize()\n\n  return firstThunk<number>(\n    () => (A === B ? 1 : undefined),\n    () => (blank(a) !== blank(b) ? 0 : undefined),\n    () => (a.length === 1 && b.length === 1 ? 0 : undefined),\n    () => {\n      const aGrams = bigrams(A)\n      const bGrams = bigrams(B)\n      const intersections = nonUniqIntersection(aGrams, bGrams).length\n      return (2 * intersections) / (aGrams.length + bGrams.length)\n    }\n  )!\n}\n\n/**\n * Convert \"abcd\" to [\"ab\", \"bc\", \"cd\"]\n */\nexport function bigrams(s: string): string[] {\n  return s == null || s.length === 0\n    ? []\n    : s\n        .slice(0, -1)\n        .split(\"\")\n        .map((ea, i) => ea + s[i + 1])\n}\n\nexport function nonUniqIntersection<T extends Primitive>(a: T[], b: T[]): T[] {\n  const uniqIntersections = intersection(a, b)\n  const i: T[] = []\n  uniqIntersections.forEach(ea => {\n    const n = Math.min(\n      count(a, s => s === ea),\n      count(b, s => s === ea)\n    )\n    times(n, () => i.push(ea))\n  })\n  return i\n}\n\n/**\n * Tries to prevent numeric overflow:\n */\nfunction diffWithoutCommonPrefix(\n  a: string,\n  b: string,\n  f: (s: string) => number\n): number {\n  const cpc = commonPrefixLength(a, b)\n  return f(a.substr(cpc)) - f(b.substr(cpc))\n}\n\n/**\n * Return the value of the longest string of digits in `s`\n */\nfunction longestNumericString(s: string): Maybe<string> {\n  const digits = compactBlanks(toS(s).split(/[^\\d]+/))\n  return sortBy(digits, ea => -ea.length)[0]\n}\n\nexport function lnsDiff(a: string, b: string): number {\n  const [a1, b1] = [a, b]\n    .map(longestNumericString)\n    .map(ea => (blank(ea) ? \"\" : ea))\n  return diffWithoutCommonPrefix(a1, b1, s => toInt(s, { defaultValue: 0 })!)\n}\n\nconst notAlphaNumRe = /[^0-9a-z]+/gi\nexport function radixDiff(a: string, b: string): number {\n  const [a1, b1] = [a, b].map(s =>\n    stripDiacritics(s).replace(notAlphaNumRe, \"\").toLowerCase()\n  )\n  return diffWithoutCommonPrefix(a1, b1, s => RadixAlphaNum.decode(s)!)\n}\n\nexport function str(a: string, b: string) {\n  return {\n    pref: commonPrefixLength(a, b),\n    ham: hamming(a, b),\n    dice: diceCoeff(a, b),\n    lns: lnsDiff(a, b),\n    radixDiff: radixDiff(a, b)\n  }\n}\n\n/**\n * @return the number of non-lower-case characters in `s`\n */\nexport function lcdiff(s: string): number {\n  return count(\n    s.normalize().split(\"\"),\n    ea => ea.toLowerCase().localeCompare(ea) !== 0\n  )\n}\n\n/**\n * @return the weighted average of the character differences per character index\n */\nexport function positionalDiff(a: string, b: string) {\n  let result: Maybe<number>\n  for (let i = Math.max(a.length, b.length); i >= 0; i--) {\n    const aChar = mapNumericOr(a.charCodeAt(i), ea => ea, 256)\n    const bChar = mapNumericOr(b.charCodeAt(i), ea => ea, 256)\n    const diff = clamp(-256, 256, aChar - bChar)\n    if (result == null) result = diff\n    else result = (result + diff) / 2\n  }\n  return result\n}\n\nexport function paddedPositionalDiff(a: string, b: string, minLen = 8) {\n  return positionalDiff(leftPad(a, minLen, \" \"), leftPad(b, minLen, \" \"))\n}\n", "import { flatten } from \"../../fe/Array\"\nimport { toS } from \"../../fe/toS\"\nimport { isWin } from \"../Platform\"\nimport { newlineRe } from \"../String\"\n\nexport function crlf(s: string): string {\n  const result = s + \"\\n\"\n  return isWin ? result.replace(newlineRe, \"\\r\\n\") : result\n}\n\nexport function splitLines(...arr: string[]): string[] {\n  return flatten(arr.map(ea => toS(ea).split(newlineRe)))\n}\n", "import { Dirent, Stats } from \"fs\"\nimport { stat, unlink } from \"fs-extra\"\nimport { join, parse, sep } from \"path\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { SyncOrAsync } from \"../../fe/OptAsync\"\nimport { toA } from \"../../fe/toA\"\nimport { thenMap, thenOrElse } from \"../async/Promise\"\nimport { mkLogger } from \"../Logger\"\nimport { stripSuffix } from \"../String\"\nimport { ParsedFile, parseNativePath } from \"./Path\"\nimport { isSimpleDirent, readdir_, SimpleDirent } from \"./Readdir\"\nimport { SimpleFile } from \"./SimpleFile\"\n\n// DON'T REFERENCE POSIXFILE HERE, you'll have circular deps.\n\nexport class StatDirent implements Partial<Pick<Stats, \"size\" | \"mtimeMs\">> {\n  readonly isFile: boolean\n  readonly isDirectory: boolean\n  readonly size: Maybe<number>\n  readonly mtimeMs: Maybe<number>\n  // Allow the Stats instance to be GC'ed by copying what I need out of it:\n  constructor(readonly base: string, s: Stats | Dirent | SimpleDirent) {\n    if (isSimpleDirent(s)) {\n      // TODO: assert that base === s.basename\n      this.isFile = s.isFile\n      this.isDirectory = s.isDirectory\n    } else {\n      this.isFile = s.isFile()\n      this.isDirectory = s.isDirectory()\n      // isSymbolicLink is always false unless you use lstat, which we never use.\n    }\n    if (s instanceof Stats) {\n      this.size = s.size\n      this.mtimeMs = s.mtimeMs\n    }\n  }\n}\n\nconst logger = lazy(() => mkLogger(\"DirectoryEntry\"))\n\nexport class DirectoryEntry implements ParsedFile, SimpleFile {\n  /**\n   * Full path\n   */\n  readonly nativePath: string\n\n  /**\n   * @return extension (`.jpg` for `image.jpg`)\n   */\n  readonly ext: string\n\n  /**\n   * Should only be constructed by BaseFile\n   *\n   * @param dir The full parent directory path such as `/home/user/dir` or\n   * `c:\\\\path\\\\dir` for `/home/user/dir/file.txt` or `c:\\\\path\\\\dir\\\\file.txt`\n   */\n  constructor(readonly dir: string, readonly dirent: StatDirent) {\n    this.nativePath = join(this.dir, dirent.base)\n    this.ext = parseNativePath(dirent.base).ext\n  }\n\n  static async for(nativePath: string): PromiseMaybe<DirectoryEntry> {\n    const p = parseNativePath(nativePath)\n    try {\n      const s = await stat(nativePath)\n      return new DirectoryEntry(p.dir, new StatDirent(p.base, s))\n    } catch {\n      return\n    }\n  }\n\n  async join(...path: string[]) {\n    return DirectoryEntry.for(join(this.nativePath, ...path))\n  }\n\n  /**\n   * @return the full basename `image.jpg`\n   */\n  get base() {\n    return this.dirent.base\n  }\n\n  /**\n   * @return basename without the ext (`image` for `image.jpg`)\n   */\n  get name() {\n    return stripSuffix(this.base, this.ext)\n  }\n\n  get pathnames(): string[] {\n    return this.nativePath.split(sep)\n  }\n\n  toString() {\n    return this.nativePath\n  }\n\n  isFile() {\n    return this.dirent.isFile\n  }\n\n  isDirectory() {\n    return this.dirent.isDirectory\n  }\n\n  get isRoot() {\n    return this.dir === parse(this.dir).dir\n  }\n\n  parent(): SyncOrAsync<Maybe<this>> {\n    const p = parseNativePath(this.dir)\n    return p.dir === this.dir\n      ? this // root\n      : (new DirectoryEntry(p.dir, {\n          base: p.base,\n          isFile: false,\n          isDirectory: true,\n          mtimeMs: undefined as any,\n          size: undefined as any\n        }) as this)\n  }\n\n  async childNames() {\n    try {\n      return !this.isDirectory()\n        ? undefined\n        : (await readdir_(this.nativePath)).map(ea => ea.basename)\n    } catch (err) {\n      logger().warn(\n        \"childNames() failed to readdir(\" + this.nativePath + \")\",\n        err\n      )\n      return\n    }\n  }\n\n  async children() {\n    try {\n      if (!this.isDirectory()) return undefined\n      const arr = await readdir_(this.nativePath)\n      return arr.map(\n        ea =>\n          new DirectoryEntry(\n            this.nativePath,\n            new StatDirent(ea.basename, ea)\n          ) as this\n      )\n    } catch (err) {\n      logger().warn(\n        \"children() failed to readdir(\" + this.nativePath + \")\",\n        err\n      )\n      return\n    }\n  }\n\n  async visitDescendantFiles(f: (child: this) => any) {\n    for (const ea of toA(await this.children())) {\n      await (ea.isFile()\n        ? f(ea)\n        : ea.isDirectory()\n        ? ea.visitDescendantFiles(f)\n        : undefined)\n    }\n  }\n\n  async filterDescendantFiles(f: (child: this) => SyncOrAsync<boolean>) {\n    const arr: this[] = []\n    await this.visitDescendantFiles(async ea => {\n      if (true === (await f(ea))) arr.push(ea)\n    })\n    return arr\n  }\n\n  stat() {\n    return stat(this.nativePath).catch(() => undefined)\n  }\n\n  async size(): PromiseMaybe<number> {\n    return thenOrElse(this.dirent.size, () =>\n      thenMap(this.stat(), ea => ea.size)\n    )\n  }\n\n  async mtimeMs(): PromiseMaybe<number> {\n    return thenOrElse(this.dirent.mtimeMs, () =>\n      thenMap(this.stat(), ea => ea.mtimeMs)\n    )\n  }\n\n  unlink_() {\n    return unlink(this.nativePath)\n  }\n}\n", "import { mkdirp, readdir, stat } from \"fs-extra\"\nimport { join } from \"path\"\nimport { notBlank } from \"../../fe/Blank\"\nimport { minuteMs, secondMs } from \"../../fe/Date\"\nimport { later } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { untilTrue } from \"../async/until\"\nimport { isBoolean } from \"../../fe/Boolean\"\nimport { thenElapsed } from \"../Elapsed\"\nimport { onClearCache, onFileChanged } from \"../event/EventEmitter\"\nimport { FifoCacheAsync } from \"../FifoCache\"\nimport { mkLogger } from \"../Logger\"\nimport { Settings } from \"../settings/Settings\"\nimport { sortByCaseInsensitive, splitEvery } from \"../String\"\nimport { CmdTimeoutMs } from \"../volumes/VolumeTtls\"\nimport { shortFsStringSha } from \"./Hash\"\nimport { outputJsonGz_, readJsonGz_ } from \"./zcat\"\n\n/** horrible short field names to minimize json size */\nexport interface SimpleDirent {\n  /**  isFile */\n  isFile: boolean\n  /**  isDirectory */\n  isDirectory: boolean\n  /** full base name */\n  basename: string\n}\n\nexport const ReadDirCacheName = \"readdircache\"\n\nexport const readdirCacheDir = lazy(async () => {\n  const path = join(Settings.cacheDir.valueOrDefault, ReadDirCacheName)\n  await mkdirp(path)\n  return path\n}, minuteMs)\n\nexport async function cachedReadDirJson(nativePath: string) {\n  return join(\n    await readdirCacheDir(),\n    ...splitEvery(shortFsStringSha(nativePath) + \".json.gz\", 2, 3)\n  )\n}\n\nconst logger = lazy(() => mkLogger(\"Readdir\"))\n\nexport function isSimpleDirent(d: any): d is SimpleDirent {\n  return (\n    d != null &&\n    notBlank(d.basename) &&\n    isBoolean(d.isFile) &&\n    isBoolean(d.isDirectory)\n  )\n}\n\nlater(() => {\n  onClearCache(() => path2cache.prior()?.clear())\n  onFileChanged((nativePath?: string | undefined) => {\n    nativePath == null\n      ? path2cache.prior()?.clear()\n      : path2cache.prior()?.deleteIf(ea => ea.startsWith(nativePath))\n  })\n})\n\nconst path2cache = lazy(\n  () =>\n    new FifoCacheAsync<SimpleDirent[]>({\n      maxSize: 500,\n      timeoutMs: CmdTimeoutMs,\n      clearEveryMs: minuteMs\n    })\n)\n\n/**\n * @throws if readdir() fails.\n */\nexport async function readdir_(nativePath: string): Promise<SimpleDirent[]> {\n  const result = await path2cache().getOrSetAsync(nativePath, () =>\n    _readdir_(nativePath)\n  )\n  if (result == null) {\n    throw new Error(\"readdir() timeout for \" + nativePath)\n  } else {\n    return result\n  }\n}\n\nasync function _readdir_(nativePath: string): Promise<SimpleDirent[]> {\n  const cache = await cachedReadDirJson(nativePath)\n  try {\n    const mtime = (await stat(cache)).mtimeMs\n    if (\n      Date.now() - mtime <\n      Settings.readdirCacheSeconds.valueOrDefault * secondMs\n    ) {\n      // If the cache file exists, it may be in progress:\n      let prior: any\n\n      if (\n        await untilTrue(\n          async () => {\n            prior = await readJsonGz_(cache)\n            return (\n              prior != null &&\n              Array.isArray(prior) &&\n              prior.every(isSimpleDirent)\n            )\n          },\n          { timeoutMs: CmdTimeoutMs - secondMs, timeBetweenMs: 250 }\n        )\n      ) {\n        return prior!\n      }\n    }\n  } catch (err) {\n    if (err.code !== \"ENOENT\")\n      logger().debug(\"Failed to read from readdir cache\", err)\n  }\n  // NOTE: this may throw:\n  const r = await thenElapsed(readdir(nativePath, { withFileTypes: true }))\n\n  const arr = sortByCaseInsensitive(\n    r.result.map(ea => ({\n      basename: ea.name,\n      isFile: ea.isFile(),\n      isDirectory: ea.isDirectory()\n    })),\n    ea => ea.basename\n  )\n\n  if (r.elapsedMs >= 500) {\n    try {\n      // outputJson, vs writeJson, does a mkdirp beforehand:\n      await outputJsonGz_(cache, arr)\n      logger().debug(\"Wrote readdir cache for slow directory\", {\n        nativePath,\n        elapsedMs: r.elapsedMs\n      })\n    } catch (err) {\n      logger().debug(\"Failed to write to readdir cache\", err)\n    }\n  }\n  return arr\n}\n", "import crypto from \"crypto\"\nimport fs from \"fs\"\nimport { stringify } from \"../../fe/JSON\"\nimport { orElse } from \"../../fe/Maybe\"\nimport { thenCollect } from \"../../fe/Promise\"\nimport { GeoRadix, Radix58 } from \"../math/Radix\"\nimport { PushProgressObserver } from \"./ProgressObservers\"\n\n// Secure hash research:\n\n// SHA1 has known collisions. It should be expected for a nerd to have sample\n// images that collide on their laptop.\n\n// SHA2 224 and 256 uses 32 bit operations.  SHA-512/224 provides length\n// protection and is 20-50% faster than SHA224 on 64 bit hardware, but NodeJS'\n// crypto only supports SHA-512 (not the SHA-512/224 or SHA-512/256 variant),\n// which is simply SHA-512's leftmost N bits with a different initialization\n// vector.\n\n// I don't see why these SHA values would need to be externally consumed, so\n// people shouldn't care if the SHA in the db isn't a FIPS standard. I don't\n// want to pull in another native library dependency if I can help it.\n\n// ALSO: I don't need that many bits to ensure uniqueness! 160 was enough for\n// SHA1, 192 should be plenty, and only takes 32 base64 characters (and doesn't\n// waste chars on padding).\n\n// HOWEVER: versions pre-v0.3.5 used the most significant 224 bits, so when we\n// build SHAs of strings (like for volume UIDs), we maintain backward\n// compatibility by slicing MSB 224 bits. If we slice 192 bits and we use a\n// non-8-bit-divisible radix, the values change.\n\n// See https://news.ycombinator.com/item?id=10011472\n\n// `shasum -a 512224` implements SHA-512/224.\n// `shasum -a 512256` implements SHA-512/256.\n\nexport const HashBits = 192\n\n/**\n * @return a Buffer with the first 192 bits of a SHA512 digest.\n * @throws on read error\n */\nexport async function fileSha(\n  filenames: string[],\n  opts?: {\n    observer?: PushProgressObserver\n    msbits?: number\n  }\n): Promise<Buffer> {\n  const hash = crypto.createHash(\"sha512\")\n  let bytesRead = 0\n  const msb = orElse(opts?.msbits, HashBits) / 8\n  await thenCollect(\n    filenames,\n    filename =>\n      new Promise<void>((resolve, reject) => {\n        const input = fs.createReadStream(filename, { autoClose: true })\n        input.on(\"error\", (err: Error) => reject(err))\n        input.on(\"data\", (chunk: string | Buffer) => {\n          bytesRead += chunk.length\n          opts?.observer?.onProgress(bytesRead)\n          hash.update(chunk)\n        })\n        input.on(\"end\", () => resolve())\n      })\n  )\n  return hash.digest().slice(0, msb)\n}\n\nexport function stringSha(input: string, msbits = HashBits): Buffer {\n  return crypto\n    .createHash(\"sha512\")\n    .update(input)\n    .digest()\n    .slice(0, msbits / 8)\n}\n\n/**\n * Encoding of the SHA of `input`.\n */\nexport function shortStringSha(\n  input: string,\n  len = 9,\n  radix = Radix58,\n  msbits = 224 // < pre-v0.3.5 used 224 bits, so this keeps those SHAs stable\n): string {\n  return radix.encodeBuffer(stringSha(input, msbits)).substring(0, len)\n}\n\n// filesystem-safe short shas\nexport function shortFsStringSha(\n  input: string,\n  len = 24,\n  radix = GeoRadix,\n  msbits = 224 // < pre-v0.3.5 used 224 bits, so this keeps those SHAs stable\n): string {\n  return shortStringSha(input, len, radix, msbits)\n}\n\n// /**\n//  * Take the SHA of a readable\n//  */\n// export async function readableShaB64(reader: Readable): Promise<string> {\n//   const hash = crypto.createHash(\"sha512\")\n//   await  pipelinePromise([reader, hash])\n//   return sliced(hash.digest()).toString(\"base64\")\n// }\n\nexport function numericSha(obj: any, msbits = 48): number {\n  return parseInt(stringSha(stringify(obj), msbits).toString(\"hex\"), 16)\n}\n", "import { createReadStream } from \"fs\"\nimport { outputFile, stat } from \"fs-extra\"\nimport { Writable } from \"stream\"\nimport { promisify } from \"util\"\nimport { createBrotliDecompress, createGunzip, gzip } from \"zlib\"\nimport { isNotEmpty } from \"../../fe/Array\"\nimport { stringify } from \"../../fe/JSON\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { thenMap } from \"../../fe/Promise\"\nimport { toS } from \"../../fe/toS\"\nimport { mkLogger } from \"../Logger\"\nimport { WrappedError } from \"../error/WrappedError\"\nimport { Pipeline, pipelineAsync } from \"./Streams\"\nimport { WritableToBuffer } from \"./WritableToBuffer\"\n\nconst logger = lazy(() => mkLogger(\"zcat\"))\n\nexport async function zcat(\n  nativePath: string,\n  options?: { start?: number; end?: number }\n) {\n  try {\n    return thenMap(zCopyToBuffer_(nativePath, options), toS)\n  } catch (err) {\n    logger().warn(\"zcat failed to read \" + nativePath, err)\n    return undefined\n  }\n}\n\nexport async function zCopyTo_(\n  nativePath: string,\n  outputStream: Writable,\n  options?: { start?: number; end?: number }\n) {\n  const s = await stat(nativePath)\n  if (s.size === 0) return\n\n  const errs: Error[] = []\n  const p: Pipeline = [\n    createReadStream(nativePath, { autoClose: true, ...options }).on(\n      \"error\",\n      err => errs.push(err)\n    )\n  ]\n  if (nativePath.toLowerCase().endsWith(\".gz\")) {\n    p.push(createGunzip().on(\"error\", err => errs.push(err)))\n  } else if (nativePath.toLowerCase().endsWith(\".br\")) {\n    p.push(createBrotliDecompress().on(\"error\", err => errs.push(err)))\n  }\n  p.push(outputStream)\n  await pipelineAsync(p)\n  if (isNotEmpty(errs)) {\n    throw new WrappedError({\n      message: \"zReadFile(\" + nativePath + \") failed\",\n      cause: errs[0]\n    })\n  }\n}\n\n/**\n * `readFile`, but on-the-fly decompression for .gz and .br\n * @throws on error\n */\nexport async function zCopyToBuffer_(\n  nativePath: string,\n  options?: { start?: number; end?: number }\n): Promise<Buffer> {\n  const s = await stat(nativePath)\n  if (s.size === 0) return Buffer.from([])\n  const w = new WritableToBuffer()\n  await zCopyTo_(nativePath, w, options)\n  return await w.buffer\n}\n\nexport async function readJsonGz_(nativePath: string) {\n  return JSON.parse((await zCopyToBuffer_(nativePath)).toString())\n}\n\nconst async_gzip = promisify(gzip)\n\nexport async function outputJsonGz_(nativePath: string, obj: any) {\n  const json = stringify(obj)\n  const out = await async_gzip(json)\n  return outputFile(nativePath, out)\n}\n", "import { compactBlanks } from \"../../fe/Array\"\nimport { mapNotBlank } from \"../../fe/Blank\"\nimport { errorToS } from \"../../fe/Error\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { stripPrefix, uniqSubstr } from \"../String\"\nimport {\n  addErrorFlags,\n  DoNotSendErrorFlag,\n  FatalErrorFlag,\n  IgnorableErrorFlag,\n  NonRetriableErrorFlag,\n  PleaseSendErrorFlag,\n  RetriableErrorFlag,\n  stripErrorFlags\n} from \"./ErrorTypes\"\n\nfunction buildErrorMessage({\n  message,\n  cause,\n  retriable,\n  ignorable,\n  fatal,\n  doNotSend\n}: {\n  message: Maybe<string>\n  cause: Maybe<Error>\n  retriable: boolean\n  ignorable: boolean\n  fatal: boolean\n  doNotSend: boolean\n}): string {\n  const arr = [message]\n  mapNotBlank(stripPrefix(errorToS(cause), \"Error: \"), ea => arr.push(ea))\n  const s = uniqSubstr(compactBlanks(arr)).join(\": \")\n\n  fatal = fatal || s.includes(FatalErrorFlag)\n  retriable =\n    (retriable || s.includes(RetriableErrorFlag)) &&\n    !s.includes(NonRetriableErrorFlag)\n  doNotSend = doNotSend || !s.includes(PleaseSendErrorFlag)\n  ignorable = ignorable || s.includes(IgnorableErrorFlag)\n\n  return addErrorFlags(\n    stripErrorFlags(s),\n    fatal ? FatalErrorFlag : undefined,\n    doNotSend ? DoNotSendErrorFlag : undefined,\n    ignorable && !fatal ? IgnorableErrorFlag : undefined,\n    !retriable && !fatal ? NonRetriableErrorFlag : undefined,\n    retriable && !fatal ? RetriableErrorFlag : undefined\n  )\n}\n\nexport class WrappedError extends Error {\n  readonly cause?: Error\n  readonly retriable: boolean\n  readonly fatal: boolean\n  constructor({\n    cause,\n    message,\n    retriable = true,\n    ignorable = false,\n    fatal = false,\n    doNotSend = false\n  }: {\n    cause?: Error\n    message?: string\n    retriable?: boolean\n    ignorable?: boolean\n    fatal?: boolean\n    doNotSend?: boolean\n  }) {\n    super(\n      buildErrorMessage({\n        message,\n        cause,\n        retriable,\n        ignorable,\n        fatal,\n        doNotSend\n      })\n    )\n    this.cause = cause\n    if (cause != null) this.stack = cause.stack\n    this.retriable = retriable\n    this.fatal = fatal\n  }\n}\n", "import { Writable, WritableOptions } from \"stream\"\nimport { Deferred } from \"../async/Deferred\"\n\n/**\n * Concats the result of a stream's data into a `Buffer`\n */\nexport class WritableToBuffer extends Writable {\n  private readonly deferred = new Deferred<Buffer>(\"WritableToBuffer\")\n  private readonly _buf: Buffer[] = []\n\n  constructor(opts?: WritableOptions) {\n    super(opts)\n    this.on(\"finish\", () => {\n      this.deferred.resolve(this.data)\n    })\n    this.on(\"error\", err => {\n      this.deferred.reject(err)\n    })\n  }\n\n  get data(): Buffer {\n    return Buffer.concat(this._buf)\n  }\n\n  /**\n   * Final result. Will only be resolved on finish.\n   */\n  get buffer(): Promise<Buffer> {\n    return this.deferred.promise\n  }\n\n  _write(chunk: any, encoding: BufferEncoding, next: () => void) {\n    this._buf.push(\n      Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding)\n    )\n    next()\n  }\n}\n", "import { blank } from \"../../fe/Blank\"\nimport { later } from \"../../fe/Delay\"\nimport { onClearCache, onFileChanged } from \"../event/EventEmitter\"\nimport { FifoCache } from \"../FifoCache\"\nimport { BaseFile } from \"./BaseFile\"\n\nexport const InstanceCacheMaxSize = 64\n\nexport class FileCache<T extends BaseFile> extends FifoCache<T> {\n  constructor() {\n    super(InstanceCacheMaxSize)\n    // break circular deps:\n    later(() => onFileChanged(path => this.clearFromPath(path)))\n    later(() => onClearCache(() => this.clear()))\n    // Prevent memory leaks:\n    this.on(\"expire\", (_k, v) => v?.clear())\n  }\n\n  clearFromPath(fromPath?: string) {\n    // NOTE: We don't delete these values so we can clear them later:\n    // (tests will fail if this is changed from .visit to .deleteIf)\n    blank(fromPath)\n      ? this.clear()\n      : this.visit((k, v) => {\n          if (k.startsWith(fromPath)) {\n            v.clear()\n          }\n        })\n  }\n}\n\nexport class NoOpFileCache<T extends BaseFile> {\n  get(_key: string) {\n    return undefined\n  }\n  set(_key: string, _value: T) {\n    return this\n  }\n  getOrSet(_key: string, valueThunk: () => T): T {\n    return valueThunk()\n  }\n}\n", "import { Transform, TransformCallback } from \"stream\"\nimport { unrefDelay } from \"../../fe/Delay\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { newlineRe } from \"../../fe/String\"\nimport { toS } from \"../../fe/toS\"\n\nexport class LineReader extends Transform {\n  private _prior: Maybe<string>\n\n  constructor() {\n    super({ objectMode: false, autoDestroy: true })\n  }\n\n  async _transform(\n    chunk: any,\n    _encoding: BufferEncoding,\n    done: TransformCallback\n  ) {\n    const lines = (toS(this._prior) + toS(chunk)).split(newlineRe)\n    const last = lines.pop()\n    // if the last line is \"\", we ended with a newline, and we don't have a prior.\n    this._prior = last === \"\" ? undefined : last\n    for (const ea of lines) {\n      if (!this.push(ea)) {\n        await unrefDelay(1)\n      }\n    }\n    done()\n  }\n\n  _flush(done: TransformCallback): void {\n    if (this._prior != null) this.push(this._prior)\n    this._prior = undefined\n    done()\n  }\n}\n", "import { clearInterval, setInterval } from \"timers\"\nimport {\n  emitProgressEvt,\n  ProgressEvt,\n  ProgressEvtWithoutPct\n} from \"../../core/event/ProgressEvt\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe, MaybePromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { clamp, round } from \"../../fe/Number\"\nimport { throttle, Throttled } from \"../../fe/Throttle\"\nimport { thenMap } from \"../async/Promise\"\n\nconst DefaultThrottleMs = 500\n\nexport class PushProgressObserver {\n  private readonly start = Date.now()\n  private current?: number\n  private readonly emit: Throttled<void>\n  constructor(\n    readonly context: ProgressEvtWithoutPct,\n    readonly total: number,\n    readonly throttleMs: number = DefaultThrottleMs\n  ) {\n    this.emit = throttle(\n      () => {\n        emitProgressEvt({\n          ...this.context,\n          pct: this.pct,\n          elapsedMs: this.elapsedMs\n        })\n      },\n      this.throttleMs,\n      true\n    )\n  }\n\n  incrProgress(incremental: number) {\n    this.onProgress(incremental + orElse(this.current, 0))\n  }\n\n  onProgress(current?: number) {\n    this.current = clamp(\n      0,\n      this.total,\n      orElse(current, orElse(this.current, 0) + 1)\n    )\n    this.emit()\n  }\n\n  get pct() {\n    return round((100 * orElse(this.current, 0)) / this.total)\n  }\n\n  get elapsedMs() {\n    return Date.now() - this.start\n  }\n}\n\nexport class PullProgressObserver {\n  private readonly start = Date.now()\n  private timer?: NodeJS.Timer\n  private readonly onInterval: Throttled<any>\n\n  constructor(\n    readonly ctx: Pick<ProgressEvt, \"path\" | \"op\">,\n    readonly total: number,\n    readonly progress: () => Maybe<number> | MaybePromiseMaybe<number>,\n    readonly throttleMs: number = DefaultThrottleMs\n  ) {\n    this.onInterval = throttle(\n      () => thenMap(this.progress(), ea => this.emit(ea)),\n      this.throttleMs\n    )\n    this.timer = setInterval(() => this.onInterval(), DefaultThrottleMs)\n  }\n\n  observe<T>(p: Promise<T>): Promise<T> {\n    // we throw this promise chain away:\n    p.then(() => this.completed()).catch(() => this.end())\n    return p\n  }\n\n  private emit(current: Maybe<number>) {\n    map(current, ea =>\n      emitProgressEvt({\n        ...this.ctx,\n        pct: (100 * clamp(0, this.total, ea)) / this.total,\n        elapsedMs: Date.now() - this.start\n      })\n    )\n  }\n\n  completed() {\n    if (Date.now() - this.start > DefaultThrottleMs) {\n      this.emit(this.total)\n    }\n    this.end()\n  }\n\n  end() {\n    map(this.timer, ea => clearInterval(ea))\n    this.timer = undefined\n  }\n}\n", "import { notBlank } from \"../../fe/Blank\"\nimport { clamp, round } from \"../../fe/Number\"\nimport { within } from \"../Number\"\nimport { eventEmitter } from \"./EventEmitter\"\n\n// \"ProgressEvent\" is part of lib.dom. Let's not collide.\nexport interface ProgressEvt {\n  path: string\n  op: string\n  pct: number\n  elapsedMs?: number\n}\n\nexport type ProgressEvtWithoutPct = Pick<ProgressEvt, \"path\" | \"op\">\n\nexport function isProgressEvt(o: any): o is ProgressEvt {\n  return (\n    o != null && notBlank(o.path) && notBlank(o.op) && within(0, 100, o.pct)\n  )\n}\n\nconst EventName = \"progress\"\n\nexport function emitProgressEvt(p: ProgressEvt) {\n  if (isProgressEvt(p)) {\n    eventEmitter.emit(EventName, {\n      ...p,\n      pct: round(clamp(0, 100, p.pct))\n    })\n  }\n}\n\nexport function onProgressEvt(listener: (p: ProgressEvt) => any) {\n  eventEmitter.on(EventName, listener)\n}\n\nexport function removeProgressEvtListener(listener: (p: ProgressEvt) => any) {\n  return eventEmitter.removeListener(EventName, listener)\n}\n", "import { Maybe } from \"./MaybeTypes\"\n\nexport interface Throttled<T> {\n  (...args: any[]): Maybe<T>\n  count(): number\n}\n\nexport function throttle<T>(\n  f: (...args: any[]) => T,\n  waitMs: number,\n  initialWait = false\n): Throttled<T> {\n  let next = initialWait ? Date.now() + waitMs : 0\n  let count = 0\n  const r: any = (...args: any[]) => {\n    const now = Date.now()\n    if (now >= next) {\n      next = now + waitMs\n      count++\n      return f(...args)\n    } else {\n      return\n    }\n  }\n  r.count = () => count\n  return r\n}\n", "import { dirname, join } from \"path\"\nimport { cwd } from \"process\"\nimport { compactBlanks } from \"../../fe/Array\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { SimpleAppName } from \"../AppName\"\nimport { uniqInPlace } from \"../Array\"\nimport { isDocker, isElectron, isMac } from \"../Platform\"\nimport { hasChildren, ancestors } from \"./Ancestors\"\n\nexport const execDir = lazy(() => dirname(process.execPath))\n\nexport namespace ProjectPath {\n  export const Root = lazy(() => {\n    const projectDirs = [\"icc\", \"migrations\", \"public\", \"views\"] // < no tools in server!\n    const dirs: string[] = []\n    if (isDocker()) {\n      dirs.push(\"/ps/app\")\n    }\n    if (isElectron) {\n      dirs.push(\n        join(execDir(), \"resources\"), // win electron\n        join(execDir(), \"..\", \"Resources\") // mac electron\n      )\n    }\n    dirs.push(...compactBlanks([execDir(), cwd(), __dirname]))\n    uniqInPlace(dirs)\n    for (const dir of dirs) {\n      if (hasChildren(dir, projectDirs)) return dir\n      // don't go too far up:\n      for (const parent of ancestors(dir).slice(0, 4)) {\n        if (hasChildren(parent, projectDirs)) return parent\n        const npx = join(dir, \"node_modules\", \"photostructure\")\n        if (hasChildren(npx, projectDirs)) return npx\n      }\n    }\n    throw new Error(\"Failed to find project root. Looked in \" + dirs)\n  })\n  const pathTo = (child: string) => lazy(() => join(Root(), child))\n  export const Bin = pathTo(\"bin\") // only present in docker and node\n  export const ICC = pathTo(\"icc\")\n  export const Migrations = pathTo(\"migrations\")\n  export const Public = pathTo(\"public\")\n  export const Tools = pathTo(\"tools\")\n  export const Views = pathTo(\"views\")\n\n  export async function isInDMG(projectPathRoot = Root()) {\n    if (!isMac) return false\n\n    // If PhotoStructure.app has a sibling called .background with a\n    // nobg-background.tiff, we're still in the DMG, but that will break if we\n    // change the DMG background. We could also check to see that we live in an\n    // Applications directory, but that's also not guaranteed.\n\n    // if (root.includes(`/Applications/${SimpleAppName}.app`)) {\n    //   logger().debug(\"notInDMG(): we're in an Applications dir, excellent.\")\n    //   return\n    // }\n\n    const dmgRE = new RegExp(\n      `^\\\\/Volumes\\\\/${SimpleAppName}[^\\\\/]*\\\\/${SimpleAppName}.app\\\\/`,\n      \"i\"\n    )\n    return dmgRE.exec(projectPathRoot) != null\n  }\n}\n", "import { readdirSync } from \"fs\"\nimport { dirname } from \"path\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\n\nexport function ancestors(path: string): string[] {\n  const arr = []\n  while (path !== dirname(path)) {\n    path = dirname(path)\n    arr.push(path)\n  }\n  return arr\n}\n\nexport function childrenSync(path: string): string[] {\n  try {\n    return readdirSync(path)\n  } catch (err) {\n    return []\n  }\n}\nexport function hasChildren(path: string, childNames: string[]): boolean {\n  const actual = childrenSync(path)\n  return childNames.every(ea => actual.includes(ea))\n}\n\nexport function ancestorWithChildren(\n  path: string,\n  childNames: string[]\n): Maybe<string> {\n  return ancestors(path).find(ea => hasChildren(ea, childNames))\n}\n", "import { notBlank } from \"../../fe/Blank\"\nimport { Latch } from \"../../fe/Latch\"\n\nexport function onDataChunked(\n  r: NodeJS.ReadableStream,\n  sep: string | RegExp,\n  onData: (data: string) => any\n): Latch {\n  const c = new Chunker(sep, onData, true)\n  c.read(r)\n  return c.done\n}\n\n/**\n * Handles data streams that may come in with disjoint chunks (like `[\"hel\",\n * \"lo\\n\"]`)\n */\nexport class Chunker {\n  private incompleteChunk = \"\"\n  readonly done = new Latch()\n\n  constructor(\n    readonly sep: string | RegExp,\n    readonly onData: (data: string) => any,\n    readonly filterBlanks = true\n  ) {}\n\n  onChunk(chunk: string | Buffer) {\n    if (chunk == null) return\n    const s = this.incompleteChunk + chunk.toString()\n    const split = s.split(this.sep)\n    // If s is not terminated by a separator, the last element in the array will\n    // be non-blank. If the string ends in a separator, an empty string will be\n    // the last element of the array, and this \"clears out\" incompleteChunk (as\n    // we'd want), so both cases are handled appropriately here:\n    this.incompleteChunk = split.pop()!\n    split.forEach(ea => {\n      if (!this.filterBlanks || notBlank(ea)) {\n        this.onData(ea)\n      }\n    })\n  }\n\n  clear() {\n    this.onChunk(\"\")\n    if (notBlank(this.incompleteChunk)) this.onData(this.incompleteChunk)\n    this.incompleteChunk = \"\"\n  }\n\n  read(r: NodeJS.ReadableStream) {\n    r.on(\"data\", ea => this.onChunk(ea))\n    r.on(\"end\", () => {\n      this.clear()\n      void this.done.resolve()\n    })\n    return this\n  }\n}\n", "import { compact } from \"../fe/Array\"\nimport { map } from \"../fe/Maybe\"\nimport { Maybe, MaybePromiseMaybe } from \"../fe/MaybeTypes\"\nimport { toA } from \"../fe/toA\"\nimport { concat } from \"./Array\"\n\nexport function hasAll<K>(m: Map<K, any> | Set<K>, arr: K[]): boolean {\n  return arr.every(ea => m.has(ea))\n}\n\nexport function flatMap<T, K, V>(iter: T[], f: (t: T) => [K, V][]): Map<K, V> {\n  return new Map<K, V>(concat(...iter.map(ea => f(ea))))\n}\n\nexport function compactMap<K, V>(\n  m: Iterable<Maybe<[Maybe<K>, Maybe<V>]>>\n): Map<K, V> {\n  const arr = compact(m).filter(([k, v]) => k != null && v != null) as [K, V][]\n  return new Map<K, V>(arr)\n}\n\nexport function toMap<T, K, V>(\n  i: Maybe<Iterable<Maybe<T>>>,\n  f: (entry: T) => Maybe<[Maybe<K>, Maybe<V>]>\n): Map<K, V> {\n  return compactMap(compact(i).map(f))\n}\n\nexport async function toMapAsync<T, K, V>(\n  iterable: Maybe<Iterable<Maybe<T>>>,\n  f: (entry: T) => MaybePromiseMaybe<[Maybe<K>, Maybe<V>]>\n): Promise<Map<K, V>> {\n  if (iterable == null) return new Map()\n  const entries = await Promise.all(compact(toA(iterable)).map(ea => f(ea)))\n  return compactMap(entries)\n}\n\nexport function toObj<T>(m: Map<string, T>): { [key: string]: T } {\n  const obj = {}\n  for (const [k, v] of m) {\n    obj[k] = v\n  }\n  return obj\n}\n\nexport function filter<K, V>(\n  m: Map<K, V>,\n  f: (key: K, value: V) => boolean\n): Map<K, V> {\n  return new Map<K, V>([...m.entries()].filter(([k, v]) => f(k, v)))\n}\n\n/**\n * Only retain the entries in m where f() returns true.\n */\nexport function filterInPlace<K, V>(\n  m: Map<K, V>,\n  retainIfTrue: (key: K, value: V) => boolean\n): void {\n  ;[...m.entries()].forEach(([k, v]) => retainIfTrue(k, v) || m.delete(k))\n}\n\nexport function pickKeys<K, V>(m: Map<K, V>, keys: K[]): Map<K, V> {\n  return filter(m, k => keys.indexOf(k) >= 0)\n}\n\n/**\n * Return the first value associated to the key that matches the given predicate\n */\nexport function getLike<K, V>(\n  m: Map<K, V>,\n  predicate: (k: K) => boolean\n): Maybe<V> {\n  return map(\n    [...m.entries()].find(([k]) => predicate(k)),\n    ([, v]) => v\n  )\n}\n\nexport function inverse<K, V>(m: Map<K, V>): Map<V, K> {\n  return new Map([...m.entries()].map(([k, v]) => [v, k] as [V, K]))\n}\n", "import _p from \"process\"\nimport { arrayEql, isEmpty, isNotEmpty, sortBy, uniq } from \"../fe/Array\"\nimport { notBlank } from \"../fe/Blank\"\nimport { secondMs } from \"../fe/Date\"\nimport { stringify } from \"../fe/JSON\"\nimport { lazy } from \"../fe/Lazy\"\nimport { orElse } from \"../fe/Maybe\"\nimport { PromiseMaybe } from \"../fe/MaybeTypes\"\nimport { gt0, toInt } from \"../fe/Number\"\nimport { onlyReqValued } from \"../fe/Object\"\nimport { thenTap } from \"../fe/Promise\"\nimport { toA } from \"../fe/toA\"\nimport { toS } from \"../fe/toS\"\nimport { ending } from \"./async/Endable\"\nimport { thenMap } from \"./async/Promise\"\nimport { stdout, stdoutResult } from \"./child/ChildProcess\"\nimport { parseFixed } from \"./Fixed\"\nimport { wmic } from \"./fs/PathTo\"\nimport { mkLogger } from \"./Logger\"\nimport { start } from \"./NodeEnv\"\nimport { isWin } from \"./Platform\"\nimport { PowerShell } from \"./pwsh/PowerShell\"\nimport { pwshJsonDate, wmiDate } from \"./WinDate\"\n\nexport interface ProcEntry {\n  pid: number\n  start: Date\n  cmd: string\n}\n\nconst logger = lazy(() => mkLogger(\"Ps\"))\n\nfunction isProcEntry(pe: any): pe is ProcEntry {\n  return pe != null && gt0(pe.pid) && pe.start != null && notBlank(pe.cmd)\n}\n\nexport async function ps(): Promise<ProcEntry[]> {\n  const procs = await (isWin ? psWin() : psPosix())\n  return orElse(\n    sortBy(procs.filter(isProcEntry), ea => ea.pid),\n    []\n  )\n}\n\nexport async function pidInfo(pid: number): PromiseMaybe<ProcEntry> {\n  return thenMap(pidInfos([pid]), arr => toA(arr).find(ea => ea.pid === pid))\n}\n\nexport async function existingPids(pids: number[]): PromiseMaybe<number[]> {\n  if (isEmpty(pids) || arrayEql([_p.pid], pids)) return toA(pids)\n  return thenMap(pidInfos(pids), arr => arr.map(ea => ea.pid))\n}\n\nexport async function notExistingPids(pids: number[]): PromiseMaybe<number[]> {\n  if (isEmpty(pids)) return []\n  return thenMap(existingPids(pids), arr => {\n    const alive = [_p.pid, ...arr]\n    return pids.filter(ea => !alive.includes(ea))\n  })\n}\n\nexport async function pidInfos(pids: number[]): PromiseMaybe<ProcEntry[]> {\n  const arr = toA(pids).filter(gt0)\n  if (isEmpty(arr)) throw new Error(\"Invalid pids: \" + stringify(pids))\n\n  return thenTap(\n    thenMap(isWin ? pidInfoWin(arr) : pidInfoPosix(arr), infos =>\n      infos.filter(ea => isProcEntry(ea) && arr.includes(ea.pid))\n    ),\n    result => logger().debug(\"pidInfo()\", { pids: arr, result })\n  )\n}\n\nfunction win2pe(arr: any[]): ProcEntry[] {\n  return arr.map((entry: any) => ({\n    pid: entry.Id,\n    start: pwshJsonDate(entry.StartTime),\n    cmd: entry.ProcessName\n  })) as ProcEntry[]\n}\n\nconst PsWinCmd = \"Get-Process\"\nconst PsWinSelectObj = \"| Select-Object -Property Id,ProcessName,StartTime\"\n\nasync function psWin(): Promise<ProcEntry[]> {\n  if (PowerShell.instance().ended) return psWinWmic()\n  const result = await PowerShell.instance().executeJsonToA(\n    [PsWinCmd, PsWinSelectObj].join(\" \")\n  )\n  return result == null ? psWinWmic() : win2pe(result)\n}\n\nfunction pidToS(pids: number[]): string {\n  return uniq([...pids.filter(gt0), _p.pid]).join(\",\")\n}\n\nasync function pidInfoWin(pids: number[]): PromiseMaybe<ProcEntry[]> {\n  if (ending() || PowerShell.instance().ended) return psWinWmic(pids)\n  const cmd = [\n    PsWinCmd,\n    \"-Id\",\n    // PowerShell wants the IDs joined by comma:\n    pidToS(pids),\n    \"-ErrorAction SilentlyContinue\", // I expect it not to find some pids\n    PsWinSelectObj\n  ].join(\" \")\n  return thenMap(PowerShell.instance().executeJsonToA(cmd), ea => win2pe(ea))\n}\n\nconst stdoutOpts = {\n  maxBuffer: 1024 * 1024, // windows process lists can be enormous\n  timeout: 15 * secondMs, // ps sometimes takes a long time\n  ignoreExitCode: true,\n  ignoreStderr: true\n}\n\nconst headers: (\"CommandLine\" | \"CreationDate\" | \"ProcessId\")[] = [\n  \"CommandLine\",\n  \"CreationDate\",\n  \"ProcessId\"\n]\n\n// NOTE: only used if powershell is shut down\nexport async function psWinWmic(pids?: number[]): Promise<ProcEntry[]> {\n  const args = [\"process\"]\n  if (isNotEmpty(pids)) {\n    // wmic wants multiple PIDs as or clauses, like\n    // wmic process where \"ProcessId=11308 or ProcessId=9416\"\n    const processIdClause = uniq([...pids.filter(gt0), _p.pid])\n      .map(ea => `ProcessId=${ea}`)\n      .join(\" or \")\n    args.push(\"where\", processIdClause)\n  }\n  args.push(\"get\", headers.join(\",\"))\n  const result = await stdoutResult(wmic(), args, stdoutOpts)\n  const results = onlyReqValued(\n    parseFixed(headers, result.result).map(ea => ({\n      pid: toInt(ea.ProcessId, { defaultValue: -1 })!,\n      start: wmiDate(ea.CreationDate),\n      cmd: toS(ea.CommandLine)\n    }))\n  )\n  if (!results.find(ea => ea.pid === _p.pid)) {\n    results.push({\n      pid: _p.pid,\n      start: new Date(start),\n      cmd: \"node \" + _p.title\n    })\n  }\n  return results\n}\n\nfunction psStdout2ProcEntry(result: string): ProcEntry[] {\n  return parseFixed(\n    [\"PID\", { greedyLeft: true, text: \"STARTED\" }, \"COMMAND\"],\n    result\n  ).map(ea => ({\n    pid: toInt(ea.PID, { defaultValue: -1 })!,\n    start: new Date(ea.STARTED),\n    cmd: toS(ea.COMMAND)\n  }))\n}\n\nasync function psPosix(): Promise<ProcEntry[]> {\n  return psStdout2ProcEntry(\n    await stdout(\"ps\", [\"-ewwwo\", \"pid,lstart,command\"], stdoutOpts)\n  )\n}\n\n/**\n * @param pid the pid to look for\n * @return an array of either just this process, or the process and the requested pid.\n */\nasync function pidInfoPosix(pids: number[]): Promise<ProcEntry[]> {\n  const r = await stdoutResult(\n    \"ps\",\n    // we include the current pid to prevent either `ps` or the fixed parser\n    // from grumping at us:\n    [\"-p\", pidToS(pids), \"-wwwo\", \"pid,lstart,command\"],\n    {\n      ...stdoutOpts,\n      ignoreExitCode: true\n    }\n  )\n  return psStdout2ProcEntry(r.result)\n}\n", "import { toS } from \"../fe/toS\"\n\nexport type IndexedString = [string, number]\n\n/**\n * Given a RegExp and string, return all first-capture-groups and their starting\n * index.\n */\nexport function captures(regex: RegExp, str: string): IndexedString[] {\n  const result: IndexedString[] = []\n  let m: RegExpExecArray | null\n  while ((m = regex.exec(str)) != null) {\n    // This is necessary to avoid infinite loops with zero-width matches\n    if (m.index === regex.lastIndex) {\n      regex.lastIndex++\n    } else {\n      result.push([m[1], m.index])\n    }\n  }\n  return result\n}\n\nexport function escapeRegExp(s: string) {\n  return toS(s).replace(/[-.,\\\\^$*+?()|[\\]{}]/g, \"\\\\$&\")\n}\n\nexport function matchQuotes(s: string) {\n  return s.replace(/[\u2018\u2019']/g, \"[\u2018\u2019']\").replace(/[\u201C\u201D\u201E\u201D\u00AB\u00BB\u3003\"]/g, `[\u201C\u201D\u201E\u201D\u00AB\u00BB\u3003\"]`)\n}\n\nexport function joinPatterns(arr: string[], flags?: string): RegExp {\n  const result = []\n  for (const ea of arr) {\n    try {\n      new RegExp(ea)\n      result.push(ea)\n    } catch {\n      result.push(escapeRegExp(ea))\n    }\n  }\n  return new RegExp(result.join(\"|\"), flags)\n}\n", "import { count, filterInPlace, range, sortBy } from \"../fe/Array\"\nimport { blank, notBlank } from \"../fe/Blank\"\nimport { lazy } from \"../fe/Lazy\"\nimport { map, orElse } from \"../fe/Maybe\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { times } from \"../fe/Number\"\nimport { fromEntries, values } from \"../fe/Object\"\nimport { toA } from \"../fe/toA\"\nimport { toS } from \"../fe/toS\"\nimport { mkLogger } from \"./Logger\"\nimport { escapeRegExp } from \"./RegExp\"\nimport { diff } from \"./Set\"\nimport { padReplace } from \"./String\"\n\nexport interface Header<T> {\n  text: string & keyof T\n  greedyLeft?: boolean\n}\n\nclass IndexedHeader<T> {\n  readonly text: string & keyof T\n  readonly greedyLeft: boolean\n  indexOf?: number\n  leftIdx?: number\n  rightIdx?: number\n  constructor(readonly h: Header<T> | (string & keyof T)) {\n    this.text = orElse(h[\"text\"], toS(h))\n    this.greedyLeft = orElse(h[\"greedyLeft\"], false)\n  }\n\n  toEntry(row: string): [string, string] {\n    return [this.text, row.substring(this.leftIdx!, this.rightIdx).trim()]\n  }\n}\n\nconst logger = lazy(() => mkLogger(\"Fixed\"))\n\nexport type Headers<T> = (Header<T> | (string & keyof T))[]\n\n/**\n * Parse fixed-width input into an array of objects\n */\nexport function parseFixed<T>(\n  headers: Headers<T>,\n  table: string,\n  warnIfMissingHeaders = true\n): T[] {\n  return new Fixed(headers, table, warnIfMissingHeaders).entries\n}\n\nexport class Fixed<T> {\n  readonly headers: IndexedHeader<T>[]\n  readonly headerRow: string\n  readonly rows: string[]\n  readonly col2blanks: Map<number, number>\n  readonly entries: T[]\n\n  constructor(\n    headers: Headers<T>,\n    table: string,\n    readonly warnIfMissingHeaders = true\n  ) {\n    const rows = table.split(/[\\r\\n]{1,2}/)\n    this.headerRow = rows[0]\n    this.rows = rows.slice(1)\n    const maxrowlen = Math.max(...this.rows.map(ea => ea.length))\n    this.col2blanks = new Map(\n      times(\n        maxrowlen,\n        col => [col, count(this.rows, ea => blank(ea[col]))] as [number, number]\n      )\n    )\n    this.headers = this.extractHeaders(headers.map(ea => new IndexedHeader(ea)))\n    this.entries = this.rows\n      .map(row => this.headers.map(h => h.toEntry(row)))\n      .map(arr => fromEntries(arr))\n      // Remove rows that have all blank values:\n      .filter(row => values(row).some(notBlank))\n  }\n\n  private extractHeaders(headers: IndexedHeader<T>[]): IndexedHeader<T>[] {\n    let headerLine = this.headerRow\n    // We only want to find each header once.\n    // First order the headers by length, desc, so we find longest matches first:\n    sortBy(headers, ea => -ea.text.length)\n    // logger().trace(\"extractHeaders()\", headers)\n    // then for each header, remove the text from the headerline as we find them\n    // so we have no header index collisions for substring matches:\n    headers.forEach(ea => {\n      const re = new RegExp(`\\\\b${escapeRegExp(ea.text)}\\\\b`, \"i\")\n      const match = re.exec(headerLine)\n      if (match == null) {\n        if (this.warnIfMissingHeaders)\n          logger().warn(\"extractHeaders(): Failed to find header!\", {\n            re,\n            headerLine\n          })\n      } else {\n        ea.indexOf = match.index\n        headerLine = padReplace(headerLine, match.index, ea.text.length, \" \")\n      }\n    })\n    const present = headers.filter(ea => ea.indexOf != null)\n    const byAppearance = sortBy(present, ea => ea.indexOf!)\n    // logger().trace(\"extractHeaders()\", { byAppearance })\n\n    // OK, the left index is the leftmost blank column as the left idx.\n    byAppearance.forEach((header, idx) => {\n      const from = header.indexOf!\n      const prior = byAppearance[idx - 1]\n      // length - 1 because end is exclusive\n      const to = idx === 0 ? 0 : prior.indexOf! + prior.text.length - 1\n      const [l, r] = header.greedyLeft ? [to, from] : [from, to]\n      header.leftIdx = map(this.firstBlankColumn(l, r), ea => ea + 1)\n      if (idx === 0 && header.leftIdx == null) {\n        header.leftIdx = 0\n      }\n      // logger().trace(\"extractHeaders(): finding leftIdx\", { from, to, header })\n      if (header.leftIdx == null) {\n        logger().warn(\n          \"no blank column for \" +\n            header.text +\n            \" between \" +\n            from +\n            \" and \" +\n            to\n        )\n      }\n    })\n    filterInPlace(byAppearance, ea => ea.leftIdx != null)\n\n    // We don't need to set the rightId of the last header, so slice(0, -1):\n    byAppearance.slice(0, -1).forEach((header, idx) => {\n      const next = byAppearance[idx + 1]\n      header.rightIdx = next.leftIdx! - 1\n    })\n    const missingHeaders = toA(\n      diff(\n        headers.map(ea => ea.text),\n        byAppearance.map(ea => ea.text)\n      )\n    )\n    if (missingHeaders.length > 0) {\n      logger().warn(\"Missing headers\", { missingHeaders })\n    }\n    return byAppearance\n  }\n\n  /**\n   * @param fromIdx inclusive\n   * @param toIdx exclusive\n   */\n  private firstBlankColumn(fromIdx: number, toIdx: number): Maybe<number> {\n    return range(fromIdx, toIdx).find(\n      idx => this.col2blanks.get(idx) === this.rows.length\n    )\n  }\n}\n", "// import { env } from \"process\"\n\n// import { compactBlanks } from \"../../fe/Array\"\n// import { firstTruePromise } from \"../async/Promise\"\n// import { stdout } from \"../child/ChildProcess\"\n// import { secondMs } from \"../date/Date\"\n// import { isWin } from \"../settings/Settings\"\n// import { mkLogger } from \"../Logger\"\n// import { BaseFile } from \"./BaseFile\"\n// import { map } from \"../../fe/Maybe\"\n\n// /**\n//  * PATHs on Windows seem to be fairly regularly screwed up. Try to find the\n//  * given system utility\n//  */\n// export async function pathTo(\n//   binaryName: string,\n//   testArgs: string[],\n//   systemrootSubpath: string[] = isWin ? [\"System32\"] : []\n// ): Promise<string> {\n//   const logger = mkLogger(\"pathTo(\" + binaryName + \")\")\n//   try {\n//     await stdout(binaryName, testArgs, { timeout: 10 * secondMs })\n//     logger.info(\"found in the PATH\")\n//     return binaryName\n//   } catch (err) {\n//     logger.warn(\"missing from PATH, I'll try SYSTEMROOT.\" + err)\n//   }\n//   const dirs = compactBlanks(\n//     isWin\n//       ? [env.SYSTEMROOT, \"C:\\\\Windows\"]\n//       : [\"/bin\", \"/usr/bin\", \"/sbin\", \"/usr/sbin\"]\n//   )\n//   const path = await firstTruePromise(\n//     ea => ea.executable(),\n//     ...dirs.map(ea => () =>\n//       BaseFile.for(ea).join(...systemrootSubpath, binaryName)\n//     )\n//   )\n//   if (path == null) {\n//     logger.error(\"missing! (looked in \" + dirs + \")\")\n//     throw new Error(\"Cannot find required system process '\" + binaryName + \"'.\")\n//   }\n\n//   try {\n//     await stdout(path.nativePath, testArgs, { timeout: 10 * secondMs })\n//     return path.nativePath\n//   } catch (err) {\n//     logger.error(path + \" doesn't seem to be valid\")\n//     throw new Error(\n//       \"Cannot find required system process 'fsutil' (looked in SYSTEMROOT)\"\n//     )\n//   }\n// }\n\n// TODO: INLINE\n\nexport const wmic = () => \"wmic\"\nexport const fsutil = () => \"fsutil\"\nexport const nslookupWin = () => \"nslookup\"\nexport const pingWin = () => \"ping\"\nexport const arpWin = () => \"arp\"\n\n// export const wmic = lazy(() => pathTo(\"wmic\", [\"OS\", \"GET\", \"localdatetime\"], [\"System32\", \"wbem\"]) )\n// export const fsutil = lazy(() => pathTo(\"fsutil\", []))\n// export const nslookupWin = lazy(() => pathTo(\"nslookup\", [\"127.0.0.1\"]))\n// export const pingWin = lazy(() => pathTo(\"ping\", [\"-n\", \"1\", \"localhost\"]))\n// export const arpWin = lazy(() => pathTo(\"arp\", [\"-a\"]))\n", "import { dayMs, minuteMs } from \"../fe/Date\"\nimport { allDefined } from \"../fe/Maybe\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { toInt } from \"../fe/Number\"\nimport { opt } from \"../fe/Opt\"\nimport { within } from \"./Number\"\n\nconst wmi = /((?:19|20)\\d\\d)([01]\\d)([0123]\\d)([012]\\d)([012345]\\d)([012345]\\d)\\.(\\d{6})([+-]\\d{3})?/\n/**\n * yyyymmddHHMMSS.mmmmmmsUUU or 20190415124112.947119-420\n *\n * @see https://msdn.microsoft.com/en-us/library/aa387237(v=vs.85).aspx\n */\nexport function wmiDate(s: string): Maybe<Date> {\n  const m = wmi.exec(s)\n  if (m == null) return\n  const arr = m.slice(1, 8).map(ea => toInt(ea))\n  if (!allDefined(arr)) return undefined\n  const [year, mon, day, hour, min, sec, micros] = arr as number[]\n  const offset = toInt(m[8], { defaultValue: 0 })!\n\n  // console.dir({ s, m, year, mon, day, hour, min, sec, micros, offset })\n  return new Date(\n    Date.UTC(year, mon - 1, day, hour, min, sec, micros / 1000) -\n      offset * minuteMs\n  )\n}\n\nconst WinDateRe = /Date\\((\\d+)\\)/\n\n/**\n * PowerShell renders Dates in JSON structures as \"/Date(1552014999676)/\"\n */\nexport function pwshJsonDate(s: string): Maybe<Date> {\n  return opt(s)\n    .flatMap(ea => WinDateRe.exec(ea))\n    .flatMap(ea => ea[1])\n    .flatMap(toInt)\n    .filter(ea => within(0, Date.now() + dayMs, ea))\n    .map(ea => new Date(ea))\n    .get()\n}\n", "import { resolve } from \"path\"\nimport { env } from \"process\"\nimport { notBlankOr } from \"../fe/Blank\"\nimport { appData } from \"./AppData\"\nimport { AppName } from \"./AppName\"\n\n/**\n * @return PS_CONFIG_DIR or ${appData()}/PhotoStructure\n */\nexport function userData() {\n  return notBlankOr(env.PS_CONFIG_DIR, () =>\n    resolve(appData(), AppName().toLowerCase())\n  )\n}\n", "import { strEnum, StrEnumKeys } from \"../fe/StrEnum\"\n\n// From https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.processpriorityclass?view=netframework-4.8\n\n// AboveNormal Specifies that the process has priority higher than Normal but\n// lower than High.\n\n// BelowNormal Specifies that the process has priority above Idle but below\n// Normal.\n\n// High Specifies that the process performs time-critical tasks that must be\n// executed immediately, such as the Task List dialog, which must respond\n// quickly when called by the user, regardless of the load on the operating\n// system. The threads of the process preempt the threads of normal or idle\n// priority class processes. Use extreme care when specifying High for the\n// process's priority class, because a high priority class application can use\n// nearly all available processor time.\n\n// Idle Specifies that the threads of this process run only when the system is\n// idle, such as a screen saver. The threads of the process are preempted by the\n// threads of any process running in a higher priority class. This priority\n// class is inherited by child processes.\n\n// Normal Specifies that the process has no special scheduling needs.\n\nexport const PriorityClasses = strEnum(\n  \"AboveNormal\",\n  \"Normal\",\n  \"BelowNormal\",\n  \"Idle\"\n)\n\nexport type PriorityClass = StrEnumKeys<typeof PriorityClasses>\n\nexport const NiceLevel = Object.freeze({\n  AboveNormal: -1,\n  Normal: 0,\n  BelowNormal: 9,\n  Idle: 19\n})\n", "import { Maybe } from \"../fe/MaybeTypes\"\nimport { tap } from \"../fe/Object\"\n\nexport class TTLSet<T> implements Set<T> {\n  readonly [Symbol.toStringTag]: \"Set\"\n  private readonly expireListeners: ((k: T) => void)[] = []\n\n  // Maps entries to insertion time values. Entries should expire after ttlMs.\n  private readonly delegate = new Map<T, number>()\n\n  constructor(readonly ttlMs: number) {}\n\n  get size(): number {\n    this.vacuum()\n    return this.delegate.size\n  }\n\n  add(value: T, ttlMs: number = this.ttlMs): this {\n    this.delegate.set(value, Date.now() + (ttlMs - this.ttlMs))\n    return this\n  }\n\n  addIfMissing<R>(value: T, onMissing: () => R): Maybe<R> {\n    const prior = this.delegate.get(value)\n    if (prior == null || this.isEntryExpired(value, prior)) {\n      this.add(value)\n      return onMissing()\n    } else {\n      return\n    }\n  }\n\n  clear(): this {\n    this.delegate.clear()\n    return this\n  }\n\n  delete(value: T): boolean {\n    return this.delegate.delete(value)\n  }\n\n  forEach(callbackfn: (value: T, index: T, set: Set<T>) => void): void {\n    for (const [value, ctime] of this.delegate) {\n      if (!this.isEntryExpired(value, ctime)) {\n        callbackfn(value, value, this)\n      }\n    }\n  }\n\n  has(value: T): boolean {\n    return !this.isEntryExpired(value, this.delegate.get(value))\n  }\n\n  readonly keys = this.values.bind(this)\n\n  values(): IterableIterator<T> {\n    // eslint-disable-next-line @typescript-eslint/no-this-alias\n    const self = this\n    function* iter(): IterableIterator<T> {\n      for (const [k, v] of self.delegate.entries()) {\n        if (!self.isEntryExpired(k, v)) {\n          yield k\n        }\n      }\n    }\n    return iter()\n  }\n\n  entries(): IterableIterator<[T, T]> {\n    // eslint-disable-next-line @typescript-eslint/no-this-alias\n    const self = this\n    function* iter(): IterableIterator<[T, T]> {\n      for (const [k, v] of self.delegate.entries()) {\n        if (!self.isEntryExpired(k, v)) {\n          yield [k, k]\n        }\n      }\n    }\n    return iter()\n  }\n\n  toA(): T[] {\n    this.vacuum()\n    return [...this.delegate.keys()]\n  }\n\n  [Symbol.iterator](): IterableIterator<T> {\n    return this.values()\n  }\n\n  on(_event: \"expire\", listener: (k: T) => void) {\n    this.expireListeners.push(listener)\n  }\n\n  /**\n   * ctime is the create time associated to the key.\n   */\n  private isEntryExpired(key: T, ctime?: number): boolean {\n    return tap(ctime == null || ctime + this.ttlMs <= Date.now(), expired => {\n      if (ctime != null && expired) {\n        this.expireListeners.forEach(ea => ea(key))\n        this.delegate.delete(key)\n      }\n    })\n  }\n\n  /**\n   * remove all expired entries\n   */\n  private vacuum() {\n    this.delegate.forEach((entry: number, key: T) => {\n      this.isEntryExpired(key, entry)\n    })\n  }\n}\n", "import { minuteMs, secondMs } from \"../fe/Date\"\nimport { later } from \"../fe/Delay\"\nimport { lazy } from \"../fe/Lazy\"\nimport { orElse } from \"../fe/Maybe\"\nimport { toS } from \"../fe/toS\"\nimport { stdoutResult } from \"./child/ChildProcess\"\nimport { onClearCache } from \"./event/EventEmitter\"\nimport { mkLogger } from \"./Logger\"\nimport { mapGt0 } from \"./Number\"\nimport { isWin } from \"./Platform\"\nimport { NiceLevel, PriorityClass, PriorityClasses } from \"./PriorityClass\"\nimport { PowerShell } from \"./pwsh/PowerShell\"\nimport { Settings } from \"./settings/Settings\"\nimport { TTLSet } from \"./TTLSet\"\n\nconst logger = lazy(() => mkLogger(\"Renice\"))\n\nlater(() => onClearCache(() => reniced.prior()?.clear()))\n\nconst reniced = lazy(() => new TTLSet<number>(minuteMs))\n\nexport async function renice(pid: number) {\n  if (reniced().has(pid)) return\n  reniced().add(pid)\n\n  // both the batch cluster observer and child services renice, which makes sync-file get\n  // double-renice-d. That's twice as nice as it needs to be.\n  const validPc = Settings.processPriority.valueOrDefault as PriorityClass\n\n  return mapGt0(pid, async () => {\n    try {\n      await (isWin\n        ? reniceWin(pid, validPc)\n        : renicePosix(pid, orElse(NiceLevel[validPc], NiceLevel.BelowNormal)))\n      logger().info(\"Renice pid \" + pid + \" to \" + validPc)\n    } catch (err) {\n      // Probably because the process already ended:\n      logger().info(\"Failed to renice pid \" + pid + \"\", err)\n      return\n    }\n  })\n}\n\nasync function reniceWin(pid: number, pc: PriorityClass) {\n  return mapGt0(pid, _pid =>\n    PriorityClasses.mapValid(pc, _pc =>\n      PowerShell.instance().execute(\n        `(Get-Process -Id ${pid}).PriorityClass = \"${pc}\"`,\n        ea => ea\n      )\n    )\n  )\n}\n\nasync function renicePosix(pid: number, nice = 19) {\n  return stdoutResult(\"renice\", [nice, \"-p\", pid].map(toS), {\n    timeout: 10 * secondMs,\n    isIgnorableError: () => true,\n    ignoreExitCode: true,\n    maxRetries: 0\n  })\n}\n", "import { SpawnOptions } from \"child_process\"\nimport _p from \"process\"\nimport { later } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport {\n  compactValues,\n  filter,\n  omit,\n  sortedKeys,\n  StringValued,\n  values\n} from \"../../fe/Object\"\nimport { childProcLocale } from \"../Locale\"\nimport { nodeEnv } from \"../NodeEnv\"\nimport { mapEntries } from \"../Object\"\nimport { isDocker, isElectron } from \"../Platform\"\nimport { Setting } from \"../settings/Setting\"\nimport {\n  pathWithDefaults,\n  persistedSettings,\n  Settings\n} from \"../settings/Settings\"\n\nconst SettingsKeys = lazy(() => new Set(values(Settings).map(ea => ea.key)))\n\nexport function psenv(): StringValued {\n  const set = SettingsKeys()\n  return sortedKeys(filter(_p.env, k => k === \"NODE_ENV\" || set.has(k)))\n}\n\nexport const settingsForChildProcs = lazy(\n  () => persistedSettings().filter(ea => ea.hasValue()) as Setting<any>[]\n)\n\nfunction onSettingsChange() {\n  settingsForChildProcs.unset()\n}\n\nconst sensitiveEnvRE = lazy(() => {\n  try {\n    return new RegExp(Settings.sensitiveEnvRegExp.valueOrDefault, \"i\")\n  } catch (err) {\n    console.error(\n      `Invalid setting for \"sensitiveEnvRegExp\": ${err}. Using default value.`\n    )\n    return new RegExp(Settings.sensitiveEnvRegExp.defaultValue, \"i\")\n  }\n})\n\nlater(() => {\n  Settings.sensitiveEnvRegExp.addListener(() => {\n    sensitiveEnvRE.unset()\n    sanitizedEnv.unset()\n  })\n\n  for (const ea of persistedSettings()) {\n    ea.addListener(onSettingsChange)\n  }\n})\n\nexport const sanitizedEnv = lazy(() => {\n  const re = sensitiveEnvRE()\n  return mapEntries(_p.env, (k, v) => (re.exec(k) != null ? undefined : v))\n})\n\nexport function childEnvSettings() {\n  return settingsForChildProcs().reduce((prev, ea) => ea.maybeAddToEnv(prev), {\n    NODE_ENV: nodeEnv, // < shouldn't be necessary, but ensures it's set properly\n    // Pass on the \"isDocker\" flag:\n    ...(isDocker() ? { PS_IS_DOCKER: \"1\" } : {}),\n    // Pass on the \"isElectron\" flag:\n    ...(isElectron ? { ELECTRON_RUN_AS_NODE: \"1\", PS_IS_ELECTRON: \"1\" } : {})\n  })\n}\n\nexport type SpawnOptionsWithLocale = SpawnOptions & { forceCLocale?: boolean }\n\nexport function spawnOptions(maybeOpts?: SpawnOptionsWithLocale): SpawnOptions {\n  const opts: SpawnOptionsWithLocale = orElse(maybeOpts, {})\n  const forceCLocale = orElse(opts.forceCLocale, true)\n  return {\n    ...omit(opts, \"forceCLocale\"),\n    env: childEnv(opts.env, forceCLocale),\n    detached: false,\n    shell: false\n    // NOTE: don't use windowsHide: true, it doesn't work!\n  }\n}\n\nexport function childEnv(\n  overrides: Maybe<StringValued>,\n  forceCLocale: boolean\n) {\n  const e: StringValued = compactValues({\n    // Include all (non-sensitive) env values, because things like `gio` need\n    // GNOME* and DBUS* variables set:\n    ...sanitizedEnv(),\n    PATH: pathWithDefaults(),\n    ...(forceCLocale ? childProcLocale() : {}),\n    ...childEnvSettings(),\n    ...orElse(overrides, {}) // < env param wins\n  })!\n\n  // children must not log to stdout:\n  Settings.logStdout.deleteFromEnv(e)\n\n  // and only the parent should tail logs:\n  Settings.tailLogs.deleteFromEnv(e)\n\n  return e\n}\n", "import _p from \"process\"\nimport { compact } from \"../fe/Array\"\nimport { blank } from \"../fe/Blank\"\nimport { secondMs } from \"../fe/Date\"\nimport { lazy } from \"../fe/Lazy\"\nimport { firstDefined, map } from \"../fe/Maybe\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { fromEntries } from \"../fe/Object\"\nimport { thenOpt } from \"../fe/OptAsync\"\nimport { firstDefinedLater } from \"./async/Later\"\nimport { thenMap } from \"./async/Promise\"\nimport { stdout } from \"./child/ChildProcess\"\nimport { Pojo } from \"./Object\"\nimport { isMac, isPosix, isWin } from \"./Platform\"\nimport { PowerShell } from \"./pwsh/PowerShell\"\nimport { equalsIgnoreCase } from \"./String\"\n\nexport const defaultLocale = \"en\"\n\n/**\n * @see https://en.wikipedia.org/wiki/ISO_639\n */\nexport const locale = lazy(async () => {\n  return lc2locale(\n    await firstDefinedLater(\n      () => extractLocale(),\n      () => (isWin ? localeWin() : undefined),\n      () => (isMac ? localeMac() : undefined),\n      () => (isPosix ? localePosix() : undefined)\n    )\n  )\n})\n\n// See https://wiki.archlinux.org/index.php/Locale\nfunction extractLocale(env: Pojo = _p.env) {\n  return firstDefined<string>(\n    env.LC_ALL,\n    env.LC_MESSAGES,\n    env.LANG,\n    env.LANGUAGE\n  )\n}\n\n// Like \"en_US.UTF-8\"\nconst regex = /^([a-z]{2,3})(?:(?:[_-])([a-z]{2,3}))?/i\n\nexport function lc2locale(lc: Maybe<string>): string {\n  // Some people set their locale to \"C\":\n  if (blank(lc) || equalsIgnoreCase(\"c\", lc) || equalsIgnoreCase(\"posix\", lc)) {\n    return defaultLocale\n  } else {\n    // locales can be en_US or en-US. standardize on dash:\n    const m = regex.exec(lc)\n    if (m == null) return defaultLocale\n    return compact([m[1], m[2]]).join(\"-\")\n  }\n}\n\nexport function localeWin() {\n  return thenMap(\n    PowerShell.instance().executeJson(\n      \"Get-WinSystemLocale | Select-Object -Property Name\"\n    ),\n    ea => ea.Name\n  )\n}\n\nconst opts = {\n  timeout: 10 * secondMs\n}\n\nexport function localeMac() {\n  return thenOpt(\n    stdout(\"defaults\", [\"read\", \"-globalDomain\", \"AppleLocale\"], opts)\n  )\n    .flatMap(lc2locale)\n    .get()\n}\n\nconst nonEmpty = /^([a-z_]+)\\s*=\\s*\"(.+)\"$/i\n\nexport function localePosix() {\n  return thenOpt(stdout(\"locale\", [], opts))\n    .flatMap(result =>\n      result.split(\"\\n\").map(\n        ea => map(ea.match(nonEmpty), m => [m[1], m[2]] as [string, string]) // < SITS: TS\n      )\n    )\n    .flatMap(fromEntries)\n    .flatMap(extractLocale)\n    .flatMap(lc2locale)\n    .get()\n}\n\nexport function childProcLocale() {\n  return {\n    LANG: \"C\",\n    LC_ALL: \"C\"\n  }\n}\n", "import { map, orElse } from \"./Maybe\"\nimport { Maybe, MaybeNull } from \"./MaybeTypes\"\n\nexport type SyncOrAsync<T> = T | Promise<T>\n\nexport type MaybeSyncOrAsync<T> = Maybe<SyncOrAsync<Maybe<T>>>\nexport type MaybeNullSyncOrAsync<T> = Maybe<SyncOrAsync<MaybeNull<T>>>\nexport type MaybeOptAsync<T> =\n  | MaybeSyncOrAsync<T>\n  | Maybe<SyncOrAsync<OptAsync<T>>>\n\n/**\n * @see http://www.scala-lang.org/api/current/scala/Option.html\n */\nexport class OptAsync<A> {\n  constructor(private readonly a: Maybe<() => MaybeOptAsync<A>>) {}\n\n  private async _map<T>(\n    f: (a: A) => SyncOrAsync<T>,\n    ifNone: () => SyncOrAsync<T>\n  ): Promise<T> {\n    const opt = this.a != null ? await this.a() : undefined\n    const a = isOptAsync<A>(opt) ? await opt.get() : opt\n    return a != null ? f(a) : ifNone()\n  }\n\n  /**\n   * @return true if the option is an instance of Some, false otherwise\n   */\n  async isDefined() {\n    return this._map(\n      () => true,\n      () => false\n    )\n  }\n\n  /**\n   * @return true if the option is None, false otherwise\n   */\n  async isEmpty(): Promise<boolean> {\n    return this._map(\n      () => false,\n      () => true\n    )\n  }\n\n  /**\n   * @return the option's value.\n   */\n  async get(): Promise<Maybe<A>> {\n    return this._map(\n      ea => ea,\n      () => undefined as any\n    )\n  }\n\n  /**\n   * @return the option's value.\n   */\n  async getRequired(): Promise<A> {\n    return this._map(\n      ea => ea,\n      () => {\n        throw new Error(\"unexpectedly undefined\")\n      }\n    )\n  }\n\n  /**\n   * @return true if this option is nonempty and the predicate `p` returns true\n   * when applied to this Option's value.\n   */\n  async exists(p: (a: A) => SyncOrAsync<boolean>): Promise<boolean> {\n    return this._map(p, () => false)\n  }\n\n  /**\n   * @return a `Some` containing the result of applying `f` to this `Option`'s value\n   * if this `Option` is nonempty.\n   */\n  map<B>(f: (a: A) => SyncOrAsync<B>): OptAsync<B> {\n    return new OptAsync<B>(async () => this._map(f, () => undefined as any))\n  }\n\n  /**\n   * @return the result of applying `f` to this `Option`'s value if this\n   * `Option` is nonempty. By supporting `undefined` or `B`, we make caller's\n   * lives a little easier--we'll wrap the result in an `Option` for you.\n   */\n  flatMap<B>(f: (a: A) => MaybeOptAsync<B>): OptAsync<B> {\n    return new OptAsync<B>(async () => this._map(f as any, () => undefined))\n  }\n\n  /**\n   * @return this `Option` if it is both nonempty\n   * and applying the predicate `p` to this `Option`'s value returns true.\n   */\n  filter(p: (a: A) => SyncOrAsync<boolean>): OptAsync<A> {\n    return new OptAsync<A>(async () =>\n      this._map(\n        async ea => ((await p(ea)) ? ea : undefined),\n        () => undefined as any\n      )\n    )\n  }\n\n  /**\n   * @return this `Option` if it is both nonempty\n   * and applying the predicate `p` to this `Option`'s value returns true.\n   */\n  catch(onError: (err: Error | any) => Maybe<SyncOrAsync<A>>): OptAsync<A> {\n    return new OptAsync<A>(() => this.get().catch(async err => onError(err)))\n  }\n\n  /**\n   * Apply the given procedure `f` to the `Option`'s value\n   * if this `Option` is nonempty.\n   * @return this (for fluent or chaining calls)\n   */\n  forEach(f: (a: A) => void): OptAsync<A> {\n    return new OptAsync<A>(async () => {\n      const a = await this.get()\n      await map(a, f)\n      return a\n    })\n  }\n\n  /**\n   * @return this `Option`'s value if this `Option` is nonempty,\n   * otherwise return the result of evaluating `f`.\n   */\n  async getOrElse(f: () => SyncOrAsync<A>): Promise<A> {\n    return orElse(await this.get(), f)\n  }\n\n  /**\n   * @return this `Option`'s value if this `Option` is nonempty,\n   * otherwise return the result of evaluating `f`.\n   */\n  orElse(f: () => SyncOrAsync<Maybe<A | OptAsync<A>>>): OptAsync<A> {\n    return new OptAsync<A>(async () => {\n      const a = await this.get()\n      const result = a == null ? await f() : a\n      return isOptAsync(result) ? result.get() : result\n    })\n  }\n}\n\nfunction isOptAsync<A>(a: any): a is OptAsync<A> {\n  return a instanceof OptAsync\n}\n\nexport function thenOpt<T>(o: MaybeOptAsync<T>): OptAsync<T> {\n  return isOptAsync(o) ? o : new OptAsync(() => o)\n}\n", "import { isTrue } from \"../../fe/Boolean\"\nimport { Maybe, MaybePromiseMaybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { MaybeSyncOrAsync } from \"../../fe/OptAsync\"\n\nexport interface Later<T> {\n  (): Promise<T>\n}\n\nexport namespace Later {\n  export const and = async (\n    ...arr: Later<Maybe<boolean>>[]\n  ): Promise<boolean> => {\n    for (const ea of arr) {\n      if (!isTrue(await ea())) return false\n    }\n    return true\n  }\n  export const or = async (\n    ...arr: Later<Maybe<boolean>>[]\n  ): Promise<boolean> => {\n    for (const ea of arr) {\n      if (isTrue(await ea())) return true\n    }\n    return false\n  }\n}\n\nexport interface LaterMaybe<T> {\n  (): PromiseMaybe<T>\n}\n\nexport interface MaybeLaterMaybe<T> {\n  (): MaybePromiseMaybe<T>\n}\n\n/**\n * Wrap a Later to get a promise that will be resolved or rejected when the\n * returned thunk is called.\n */\nexport function laterPromise<T>(\n  later: () => T | Promise<T>\n): { promise: Promise<T>; later: Later<T> } {\n  // We could use Deferred here, but I want to minimize cross-dependencies.\n  let resolve: (t: T | Promise<T>) => void\n  let reject: (error: any) => void\n  const promise = new Promise<T>((res, rej) => {\n    resolve = res\n    reject = rej\n  })\n  return {\n    promise,\n    later: async () => {\n      try {\n        const r = await later()\n        resolve(r)\n        return r\n      } catch (err) {\n        reject(err)\n        throw err\n      }\n    }\n  }\n}\n\nexport async function firstDefinedLater<T>(\n  ...arr: Maybe<() => MaybeSyncOrAsync<T>>[]\n): PromiseMaybe<T> {\n  if (arr == null) return\n  for (const ea of arr) {\n    if (ea == null) continue\n    const result = await ea()\n    if (result != null) return result\n  }\n  return\n}\n", "import { isError, shortStack } from \"../../fe/Error\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { isObject } from \"../../fe/ObjectType\"\nimport { isPrimitive, isPrimitiveArray } from \"../../fe/Primitive\"\nimport { mapEntries } from \"../Object\"\n\nexport const ContextLines = 24\n\n/**\n * Prepare a log entry's `meta` for serialization\n */\nexport function prepMeta(meta: any, levels = 2): any {\n  if (levels <= 0) return meta\n  if (meta == null) {\n    return undefined\n  }\n  if (isPrimitiveArray(meta)) {\n    return meta\n  }\n  if (Array.isArray(meta)) {\n    return arr2log(meta)\n  }\n  if (isPrimitive(meta)) {\n    return meta\n  }\n  if (isError(meta)) {\n    return { ...meta, stack: shortStack(meta.stack) }\n  }\n  if (isObject(meta)) {\n    return mapEntries(meta, (_, v) => prepMeta(v, levels - 1))\n  }\n\n  // Otherwise give up:\n  return meta\n}\n\n/**\n * Summarize an array to json for logging\n */\nexport function arr2log(\n  a: Maybe<any[]>,\n  transform: (t: any) => any = prepMeta\n) {\n  if (a == null) {\n    return undefined\n  } else if (a.length <= ContextLines) {\n    return a.map(transform)\n  } else {\n    return [\n      ...a.slice(0, ContextLines).map(transform),\n      `\u2026 (${a.length} total items)`\n    ]\n  }\n}\n", "import { fromEntries } from \"../../fe/Object\"\nimport { strEnum, StrEnumKeys } from \"../../fe/StrEnum\"\n\n/**\n * These are driven by the `console` API\n */\nexport const LogLevels = strEnum(\"error\", \"warn\", \"info\", \"debug\", \"trace\")\nexport type LogLevel = StrEnumKeys<typeof LogLevels>\n\nconst LevelToIndex = fromEntries(LogLevels.values.map((k, i) => [k, i]))\n\nexport function levelIndex(logLevel: string): number {\n  return LevelToIndex[logLevel] ?? LevelToIndex.trace\n}\n", "import { sortBy } from \"../../fe/Array\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { fromEntries, values } from \"../../fe/Object\"\nimport { BoundedList } from \"../BoundedList\"\nimport { LogEntry } from \"./LogEntry\"\nimport { LogLevel, LogLevels } from \"./LogLevel\"\n\nexport const SentLogLevels = lazy(() =>\n  LogLevels.values.filter(ea => ea !== LogLevels.trace)\n)\n\nconst MaxPerLevel = 48\n\n// https://github.com/Microsoft/TypeScript/issues/24220#issuecomment-449325451\ntype Level2Recent = { [l in LogLevel]: BoundedList<LogEntry> }\n\n/**\n * These are log entries that were *not* written to the log file (but will be\n * interesting if we want to \"send recent logs\".\n *\n * They are flushed to the logfile by log.error or by calling\n * writeRecentLogEntries()\n */\nconst recentLogEntriesByLevel = lazy<Level2Recent>(() =>\n  fromEntries(\n    SentLogLevels().map(ea => [ea, new BoundedList<LogEntry>(MaxPerLevel)])\n  )\n)\n\nexport function clearRecentLogEntries() {\n  values(recentLogEntriesByLevel()).forEach(ea => ea.clear())\n}\n\nexport function addRecentLogEntry(le: LogEntry) {\n  recentLogEntriesByLevel()[le.l]?.push(le)\n}\n\nexport function recentLogEntries() {\n  const arr: LogEntry[] = []\n  for (const bl of values(recentLogEntriesByLevel())) {\n    arr.push(...bl.toA())\n  }\n  return sortBy(arr, ea => ea.ts)\n}\n", "import { Logger } from \"batch-cluster\"\nimport { compactBlanks } from \"../../fe/Array\"\nimport { asError, errorToVerbose } from \"../../fe/Error\"\nimport { stringify } from \"../../fe/JSON\"\nimport { mapOr, orElse } from \"../../fe/Maybe\"\nimport { omit } from \"../../fe/Object\"\nimport { NoOp } from \"../../fe/Thunk\"\nimport { toS } from \"../../fe/toS\"\nimport {\n  isFatalError,\n  isIgnorableError,\n  isRetriableError\n} from \"../error/ErrorTypes\"\nimport { Try } from \"../Object\"\nimport { WrappedError } from \"../error/WrappedError\"\nimport { logFilter } from \"./LogFilter\"\nimport { LogLevel } from \"./LogLevel\"\nimport { prepMeta } from \"./LogMeta\"\nimport { addRecentLogEntry } from \"./RecentLogs\"\n\nexport function ms2level(elapsedMs: number, errorMs: number): LogLevel {\n  return elapsedMs >= errorMs\n    ? \"error\"\n    : elapsedMs >= errorMs / 2\n    ? \"warn\"\n    : elapsedMs >= errorMs / 4\n    ? \"info\"\n    : \"debug\"\n}\n\nexport interface SimpleLogger {\n  /**\n   * Implementations of `log` can rely on a wrapper class (probably\n   * `ContextualLogger`) to call `enabled` for any given log invocation.\n   */\n  log(level: LogLevel, context: string, msg: string, meta?: any): void\n\n  flush(): Promise<void>\n\n  end(): any\n}\n\nexport const NoOpLogger: SimpleLogger & Logger = {\n  log: NoOp,\n  flush: () => Promise.resolve(),\n  end: NoOp,\n  error: NoOp,\n  warn: NoOp,\n  info: NoOp,\n  debug: NoOp,\n  trace: NoOp\n}\n\n// TODO: MOVE TO ../../fe/Try.ts\nasync function tryAsync<T>(f: () => T | Promise<T>) {\n  try {\n    return await f()\n  } catch {\n    return\n  }\n}\n\nexport function safeLogger(logger: SimpleLogger): SimpleLogger {\n  return {\n    log: (level: LogLevel, context: string, msg: string, meta?: any) =>\n      Try(() => logger.log(level, context, msg, meta)),\n    flush: () => tryAsync(() => logger.flush()),\n    end: () => tryAsync(() => logger.end())\n  }\n}\n\nconst ctxRe = /^[a-z]*/i\n\n/**\n * Delegates to a SimpleLogger, applying filters, and exposing level-specific\n * log methods.\n */\nexport class ContextualLogger implements SimpleLogger, Logger {\n  readonly filterContext: string\n  constructor(\n    readonly context: string,\n    readonly loggers: () => SimpleLogger[]\n  ) {\n    this.filterContext = mapOr(\n      ctxRe.exec(toS(this.context)),\n      ea => ea[0],\n      () => this.context\n    )\n  }\n\n  addContext(s: string) {\n    return new ContextualLogger(this.context + s, this.loggers)\n  }\n\n  throw(\n    e: string | Error,\n    meta?: { fatal?: boolean; retriable?: boolean; ignorable?: boolean } & any\n  ): never {\n    const fatal = isFatalError(e) || meta?.fatal\n    const nonRetriable = meta?.retriable === false\n    const retriable = !nonRetriable && isRetriableError(e)\n    const ignorable = isIgnorableError(e) || meta?.ignorable\n    meta =\n      meta == null\n        ? undefined\n        : prepMeta(omit(meta, \"fatal\", \"retriable\", \"ignorable\"))\n    const err = new WrappedError({\n      cause: asError(e),\n      message: compactBlanks([\n        this.context,\n        meta == null ? undefined : stringify(meta)\n      ]).join(\" \"),\n      fatal,\n      retriable,\n      ignorable\n    })\n    this.log(ignorable === true ? \"warn\" : \"error\", errorToVerbose(e), meta)\n    throw err\n  }\n\n  tap<T>(o: { level?: LogLevel; msg: string; result: T; meta?: any }): T {\n    this.log(orElse(o.level, \"debug\"), o.msg, { result: o.result, ...o.meta })\n    return o.result\n  }\n\n  log(level: LogLevel, message: string, meta?: any): void {\n    meta = prepMeta(meta)\n    // Loggers (ConsoleLogger and LogWriter) don't check enabled.\n    if (logFilter().enabled(level, this.context)) {\n      for (const ea of this.loggers()) {\n        ea.log(level, this.context, message, meta)\n      }\n    } else {\n      if (level !== \"trace\") {\n        addRecentLogEntry({\n          ts: Date.now(),\n          l: level as any,\n          ctx: this.context,\n          msg: message,\n          meta\n        })\n      }\n    }\n  }\n\n  async flush() {\n    for (const ea of this.loggers()) {\n      await ea.flush()\n    }\n  }\n\n  async end() {\n    for (const ea of this.loggers()) {\n      await ea.end()\n    }\n  }\n\n  // Using fat arrows force the methods to stay bound to this instance:\n\n  readonly error = (msg: string, args?: any) => {\n    this.log(\"error\", msg, args)\n  }\n\n  readonly warn = (msg: string, args?: any) => {\n    this.log(\"warn\", msg, args)\n  }\n\n  readonly info = (msg: string, args?: any) => {\n    this.log(\"info\", msg, args)\n  }\n\n  readonly debug = (msg: string, args?: any) => {\n    this.log(\"debug\", msg, args)\n  }\n\n  readonly trace = (msg: string, args?: any) => {\n    this.log(\"trace\", msg, args)\n  }\n}\n", "export const DefaultLensMakes = [\n  \"7artisans\",\n  \"Bower\",\n  \"Canon\",\n  \"Carl Zeiss\",\n  \"Cosina\",\n  \"Fuji\",\n  \"Fujifilm\",\n  \"Goerz\",\n  \"Hasselblad\",\n  \"Hirox\",\n  \"Hoya\",\n  \"Konica\",\n  \"Leica\",\n  \"Leidolf\",\n  \"Lensbaby\",\n  \"Meike\",\n  \"Meopta\",\n  \"Minolta\",\n  \"Neewer\",\n  \"Nikon\",\n  \"Olympus\",\n  \"Opteka\",\n  \"Panasonic\",\n  \"Pentacon\",\n  \"Pentax\",\n  \"Ricoh\",\n  \"Rodenstock\",\n  \"Rokinon\",\n  \"Ross\",\n  \"Samsung\",\n  \"Samyang\",\n  \"Seiko\",\n  \"Sigma\",\n  \"Silor\",\n  \"Soligor\",\n  \"Sony\",\n  \"Sunpak\",\n  \"Tamron\",\n  \"Tiffen\",\n  \"Tokina\",\n  \"Topcon\",\n  \"Venus\",\n  \"Voigtl\u00E4nder\",\n  \"Wray\",\n  \"Yongnuo\",\n  \"Zhong Yi\",\n  \"Zuiko\"\n]\n", "export const SidecarExts = [\"EXIF\", \"EXV\", \"MIE\", \"XMP\"]\n", "import { delimiter } from \"path\"\nimport { env } from \"process\"\nimport {\n  compactBlankish,\n  filterInPlace,\n  flatten,\n  mapNotEmpty,\n  uniq\n} from \"../../fe/Array\"\nimport { blankish, mapNotBlank, notBlank } from \"../../fe/Blank\"\nimport { toBoolean } from \"../../fe/Boolean\"\nimport { stringify } from \"../../fe/JSON\"\nimport { map, mapOr, orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { clamp, toFloat, toInt } from \"../../fe/Number\"\nimport { StringValued } from \"../../fe/Object\"\nimport { opt } from \"../../fe/Opt\"\nimport { strEnum, StrEnumKeys } from \"../../fe/StrEnum\"\nimport { Thunk, tot } from \"../../fe/Thunk\"\nimport { toA } from \"../../fe/toA\"\nimport { toS } from \"../../fe/toS\"\nimport { eql } from \"../Eql\"\nimport { mkLogger } from \"../Logger\"\nimport { isProd } from \"../NodeEnv\"\nimport { camel2snake } from \"../StringCase\"\n\nexport function envkey(name: string): string {\n  return \"PS_\" + camel2snake(name).toUpperCase()\n}\n\n// LIMIT DEPS TO FE AND BASE CLASSES! #NODEPLOOPS\n\n// only exposed for tests\n// eslint-disable-next-line @typescript-eslint/no-non-null-assertion\nexport const envAtStartup = opt({ ...env })\n  .map(ea => (isProd ? Object.freeze(ea) : ea))\n  .get()!\n\nexport const SettingCategories = strEnum(\n  // System settings:\n  \"Paths\",\n  \"Logging\",\n  \"Networking\",\n  \"Processes\",\n  \"Tools\",\n  \"Updates\",\n  \"Desktops\",\n  \"Volumes\",\n  // Library settings:\n  \"Db\",\n  \"HealthChecks\",\n  \"Filters\",\n  \"Previews\",\n  \"Reporting\",\n  \"Deduping\",\n  \"Sidecars\",\n  \"Sync\",\n  \"Tagging\",\n  \"Web\",\n  \"Subscriptions\"\n)\nexport type SettingCategory = StrEnumKeys<typeof SettingCategories>\n\nexport const LibraryCategories: ReadonlyArray<SettingCategory> = Object.freeze([\n  SettingCategories.Db,\n  SettingCategories.HealthChecks,\n  SettingCategories.Filters,\n  SettingCategories.Previews,\n  // desire to report errors or how many per day is OK.\n  // we include reporting in the library because their email won't change\n  SettingCategories.Reporting,\n  SettingCategories.Deduping,\n  SettingCategories.Sidecars,\n  SettingCategories.Sync,\n  SettingCategories.Tagging,\n  SettingCategories.Web,\n  SettingCategories.Subscriptions\n])\n\n// System is everything not library:\nexport const SystemCategories: ReadonlyArray<SettingCategory> = Object.freeze(\n  SettingCategories.values.filter(ea => !LibraryCategories.includes(ea))\n)\n\nexport interface BaseSettingOpts<T> {\n  readonly envAliases?: string[]\n  readonly category: SettingCategory\n  readonly description: string\n  readonly exampleValue?: Thunk<Maybe<T>>\n  readonly transient?: boolean // defaults to false\n  readonly advanced?: Thunk<boolean>\n}\n\ninterface Converters<T> {\n  readonly toEnv: (value: Maybe<T>) => Maybe<string>\n  readonly fromEnv: (value: Maybe<string>) => Maybe<T>\n}\n\nexport interface DefaultValued<T> {\n  defaultValue: T | Thunk<T>\n}\n\nexport type SettingOpts<T> = BaseSettingOpts<T> & DefaultValued<T>\n\nexport interface SavedSetting {\n  key: string\n  value: any\n}\n\nexport interface SettingListener<T> {\n  (newValue: Maybe<T>): any\n}\n\nconst notBlankToS = (s: Maybe<any>) =>\n  notBlank(s) && s !== \"undefined\" ? toS(s).trim() : undefined\n\n/**\n * Supports env-overridden preferences that can be persisted to a file.\n *\n * 1. Setting an environment variable or command-line argument must not be\n *    persisted to the settings file, as that would become the default value.\n * 2. Settings file values should not override the command-line or environment's\n *    values, as that would cause the env or CLI value to be ignored.\n *\n * SO: we have to be able to distinguish between env or cli values and persisted\n * values.\n */\nexport class Setting<T> {\n  private _name!: string\n  private _key!: string\n  private _persist = false\n  private _value: Maybe<T>\n  private readonly listeners: SettingListener<T>[] = []\n\n  constructor(readonly opts: SettingOpts<T> & Converters<T>) {}\n\n  hasValue() {\n    return this._value != null\n  }\n\n  isUnset() {\n    return !this.hasValue()\n  }\n\n  // Only for tests or temporary value setting (see LogFilter.withLogLevel)\n  getState() {\n    return { value: this._value, persist: this._persist }\n  }\n\n  setState(s: ReturnType<this[\"getState\"]>) {\n    this._persist = s.persist\n    this._value = s.value\n  }\n\n  /**\n   * Read the value from the given `pojo` or the ENV.\n   *\n   * THIS DOESN'T CHANGE ANY STATE. If you want to import from the env, use\n   * `importFromEnv`.\n   */\n  readFromEnv(pojo?: StringValued) {\n    const _env = orElse(pojo, env)\n    for (const k of [this.key, ...toA(this.opts.envAliases)]) {\n      const v = map(_env[k], ea => this.opts.fromEnv(ea))\n      if (v != null) return v\n    }\n    return\n  }\n\n  /**\n   * Should only be used directly by tests, as env shouldn't be wiggling around\n   * after a process starts.\n   */\n  importFromEnv(environment: StringValued = env): Maybe<T> {\n    if (this._persist) return\n    return map(this.readFromEnv(environment), value => {\n      // We don't need to convert it back and forth from the ENV, as we just did that:\n      // return (this._value = value)\n      return this.setValue(value)\n    })\n  }\n\n  importFromFile(value: Maybe<T>): Maybe<T> {\n    if (this.hasValue() && !this._persist) return\n    // We don't need to set persist here: only if the user changes the value.\n    return this.setValue(value)\n  }\n\n  addListener(l: SettingListener<T>) {\n    this.listeners.push(l)\n    if (this._persist) {\n      // SITS: this allows the call to addListener() reference classes or\n      // instances that haven't been parsed yet:\n      setImmediate(() => l(this.value))\n    }\n  }\n\n  removeListener(l: SettingListener<T>) {\n    filterInPlace(this.listeners, ea => ea === l)\n  }\n\n  private onChange() {\n    const v = this.value\n    this.listeners.forEach(ea => ea(v))\n  }\n\n  get name(): string {\n    return this._name\n  }\n\n  _setName(name: string) {\n    if (this._name != null) throw new Error(\"cannot set name twice\")\n    this._name = name\n    this._key = envkey(name)\n    this.importFromEnv()\n  }\n\n  get persist(): boolean {\n    return this._persist\n  }\n\n  /**\n   * This is the environment variable name for this setting:\n   */\n  get key(): string {\n    return this._key\n  }\n\n  get category(): SettingCategory {\n    return this.opts.category\n  }\n\n  get categoryType(): \"system\" | \"library\" {\n    return LibraryCategories.includes(this.category) ? \"library\" : \"system\"\n  }\n\n  get transient(): boolean {\n    return this.opts.transient === true\n  }\n\n  /**\n   * Is this setting an \"advanced\" option (and can be initially hidden)?\n   */\n  get advanced(): boolean {\n    return mapOr(\n      this.opts.advanced,\n      ea => ea(),\n      () => true\n    )\n  }\n\n  get value(): Maybe<T> {\n    return this._value\n  }\n\n  /**\n   * Set the value for the current process, and persist this value in the\n   * settings.toml.\n   */\n  set value(t: Maybe<T>) {\n    this._persist = true\n    this.setValue(t)\n  }\n\n  maybeSetValue(t: Maybe<T>) {\n    if (t != null) this.value = t\n  }\n\n  set valueAndEnv(t: Maybe<T>) {\n    this.value = t\n    this.addToEnv(env, t)\n  }\n\n  /**\n   * @return the env value encoding `this.valueOrDefault`\n   */\n  get envValueOrDefault(): Maybe<string> {\n    return this.opts.toEnv(this.valueOrDefault)\n  }\n\n  /**\n   * Set the value for the current process, but don't persist this value in the\n   * settings.toml. Should be used when the value set temporarily by environment\n   * variables.\n   */\n  set tmpValue(t: Maybe<T>) {\n    this._persist = false\n    // Allow these options to pass through to child processes:\n    this.addToEnv(env, t)\n    this.setValue(t)\n  }\n\n  set tmpValueIfUnset(t: Maybe<T>) {\n    if (this.isUnset()) this.tmpValue = t\n  }\n\n  private setValue(t: Maybe<T>) {\n    const prior = this._value\n    const toEnv = this.opts.toEnv(t)\n    const fromEnv = this.opts.fromEnv(toEnv)\n    this._value = fromEnv\n    if (!eql(prior, this._value)) this.onChange()\n    return this._value\n  }\n\n  get defaultValue(): T {\n    return tot(this.opts.defaultValue)\n  }\n\n  get exampleValue(): T {\n    return opt(this.opts.exampleValue)\n      .flatMap(ea => ea())\n      .filter(notBlank)\n      .getOrElse(() => this.defaultValue)\n  }\n\n  get valueOrDefault(): T {\n    // inlined orElse because this is called so frequently:\n    return this.value != null ? this.value : this.defaultValue\n  }\n\n  maybeAddToEnv<SV extends StringValued>(pojo?: SV, overrideValue?: T): SV {\n    const e = orElse(pojo, env)\n    // If we don't have a value, let the child take the default, or the\n    // persisted value. This fixes\n    // https://gitlab.com/photostructure/photostructure/issues/202\n    if (this.hasValue()) {\n      e[this.key] = notBlankToS(\n        this.opts.toEnv(orElse(overrideValue, this.valueOrDefault))\n      )\n    }\n    return e as SV\n  }\n\n  addToEnv<SV extends StringValued>(pojo?: SV, overrideValue?: T): SV {\n    const e = orElse(pojo, env)\n    e[this.key] = notBlankToS(\n      this.opts.toEnv(orElse(overrideValue, this.valueOrDefault))\n    )\n    return e as SV\n  }\n\n  deleteFromEnv<SV extends StringValued>(pojo?: SV): SV {\n    const e = orElse(pojo, env) as SV\n    delete e[this.key]\n    map(this.opts.envAliases, arr =>\n      arr.forEach(ea => {\n        delete e[ea]\n      })\n    )\n    return e\n  }\n\n  valueToPersist(savedValue: Maybe<T>): Maybe<T> {\n    return this._persist ? this._value : savedValue\n  }\n\n  unset() {\n    this._value = undefined\n    this._persist = false\n    this.deleteFromEnv()\n    this.onChange()\n    mkLogger(\"Settings.\" + this.name).info(\".unset()\")\n    return this\n  }\n\n  addToJSON() {\n    return {}\n  }\n\n  toJSON() {\n    return {\n      key: this.key,\n      value: this.value,\n      defaultValue: this.opts.defaultValue\n    }\n  }\n}\n\nexport class MaybeStringSetting extends Setting<Maybe<string>> {\n  constructor(\n    opts: BaseSettingOpts<Maybe<string>> & Partial<SettingOpts<Maybe<string>>>\n  ) {\n    super({\n      toEnv: notBlankToS,\n      fromEnv: notBlankToS,\n      defaultValue: undefined,\n      ...opts\n    })\n  }\n\n  hasValue() {\n    return notBlank(this.value)\n  }\n}\n\nfunction trim(s: Maybe<string>) {\n  return s == null ? undefined : s.trim()\n}\n\nexport class StringSetting extends Setting<string> {\n  constructor(opts: SettingOpts<string>) {\n    super({\n      toEnv: trim,\n      fromEnv: trim,\n      ...opts\n    })\n  }\n\n  hasValue() {\n    return notBlank(this.value)\n  }\n}\n\nfunction asValidValue(s: Maybe<string>, validValues: string[]): Maybe<string> {\n  const l = toS(s).toLowerCase()\n  return validValues.find(ea => ea.toLowerCase() === l)\n}\n\nexport class StringEnumSetting extends Setting<string> {\n  readonly validValues: string[]\n\n  constructor(opts: SettingOpts<string> & { validValues: string[] }) {\n    super({\n      toEnv: s => asValidValue(s, opts.validValues),\n      fromEnv: s => asValidValue(s, opts.validValues),\n      ...opts\n    })\n    // NOTE: do not compactBlanks! A blank may be a valid value!\n    this.validValues = opts.validValues\n    const dv = this.defaultValue\n    // Allow defaultValue to be undefined:\n    if (dv != null && !this.validValues.includes(this.defaultValue)) {\n      throw new Error(\n        `validValues, ${this.validValues}, doesn't include defaultValue, ${opts.defaultValue}`\n      )\n    }\n  }\n  addToJSON() {\n    return { validValues: this.validValues }\n  }\n}\n\nfunction _split(s: Maybe<string>): Maybe<string[]> {\n  return mapNotBlank(toS(s).trim(), str => {\n    if (str.startsWith(\"[\") && str.endsWith(\"]\")) {\n      try {\n        return flatten(JSON.parse(str)).map(toS)\n      } catch {\n        //\n      }\n    }\n    // broken pipe kept for backward compatibility:\n    for (const ea of [\"\u00A6\", delimiter]) {\n      if (str.includes(ea)) {\n        return str.split(ea)\n      }\n    }\n    return [str]\n  })\n}\n\nexport function splitStringArray(s: Maybe<string>): Maybe<string[]> {\n  return blankish(s) ? undefined : mapNotEmpty(_split(s), _uniqNonBlanks)\n}\n\nfunction _join(arr: Maybe<string[]>): Maybe<string> {\n  return mapNotEmpty(_uniqNonBlanks(arr), stringify)\n}\n\nfunction _uniqNonBlanks(arr: Maybe<string[]>) {\n  return uniq(compactBlankish(arr))\n}\n\nexport class StringArraySetting extends Setting<string[]> {\n  constructor(\n    opts: BaseSettingOpts<string[]> & Partial<DefaultValued<string[]>>\n  ) {\n    super({\n      defaultValue: [],\n      fromEnv: splitStringArray,\n      toEnv: _join,\n      ...opts\n    })\n  }\n\n  push(...values: string[]) {\n    this.value = _uniqNonBlanks([...this.valueOrDefault, ...values])\n  }\n\n  get values(): string[] {\n    return _uniqNonBlanks(this.valueOrDefault)\n  }\n\n  set values(arr: string[]) {\n    this.value = _uniqNonBlanks(arr)\n  }\n\n  removeValueFromEnv(v: string) {\n    map(this.value, arr => (this.tmpValue = arr.filter(ea => ea !== v)))\n  }\n}\n\nfunction parseStringEnum(\n  str: Maybe<string>,\n  validValues: string[]\n): Maybe<string[]> {\n  return filterStringEnum(splitStringArray(str), validValues)\n}\n\nfunction filterStringEnum(\n  arr: Maybe<Maybe<string>[]>,\n  validValues: string[]\n): Maybe<string[]> {\n  if (arr == null) return undefined\n  // PERF: unrolled\n  const result: string[] = []\n  for (const ea of arr) {\n    const r = asValidValue(ea, validValues)\n    if (r != null) result.push(r)\n  }\n  return result\n}\n\nexport class StringEnumsSetting extends Setting<string[]> {\n  readonly validValues: string[]\n  constructor(\n    opts: BaseSettingOpts<string[]> & {\n      defaultValue: string[]\n      validValues: string[]\n    }\n  ) {\n    super({\n      fromEnv: s => parseStringEnum(s, opts.validValues),\n      toEnv: arr => map(arr, ea => stringify(uniq(ea))),\n      ...opts\n    })\n    this.validValues = opts.validValues\n  }\n\n  asValidValues(o: any) {\n    return filterStringEnum(o, this.validValues)\n  }\n\n  addToJSON() {\n    return { validValues: this.validValues }\n  }\n}\n\nexport class IntegerSetting extends Setting<number> {\n  constructor(opts: SettingOpts<number>) {\n    super({\n      ...opts,\n      toEnv: notBlankToS,\n      fromEnv: toInt\n    })\n  }\n}\n\nexport class MaybeIntegerSetting extends Setting<Maybe<number>> {\n  constructor(opts: BaseSettingOpts<Maybe<number>>) {\n    super({\n      ...opts,\n      toEnv: notBlankToS,\n      fromEnv: toInt,\n      defaultValue: undefined\n    })\n  }\n}\n\nexport class FloatSetting extends Setting<number> {\n  constructor(opts: SettingOpts<number>) {\n    super({\n      ...opts,\n      toEnv: notBlankToS,\n      fromEnv: toFloat\n    })\n  }\n}\n\nexport class BoundedIntegerSetting extends Setting<number> {\n  constructor(\n    readonly options: SettingOpts<number> & { min: number; max: number }\n  ) {\n    super({\n      ...options,\n      toEnv: notBlankToS,\n      fromEnv: (value: Maybe<string>) =>\n        opt(value)\n          .flatMap(parseInt)\n          .map(ea => clamp(options.min, options.max, ea))\n          .get()\n    })\n  }\n  addToJSON() {\n    return { minValue: this.options.min, maxValue: this.options.max }\n  }\n}\n\nexport class BoundedFloatSetting extends Setting<number> {\n  constructor(\n    readonly options: SettingOpts<number> & { min: number; max: number }\n  ) {\n    super({\n      ...options,\n      toEnv: notBlankToS,\n      fromEnv: (value: Maybe<string>) =>\n        opt(value)\n          .flatMap(parseFloat)\n          .map(ea => clamp(options.min, options.max, ea))\n          .get()\n    })\n  }\n  addToJSON() {\n    return { minValue: this.options.min, maxValue: this.options.max }\n  }\n}\n\nexport class BooleanSetting extends Setting<boolean> {\n  constructor(opts: SettingOpts<boolean>) {\n    super({\n      ...opts,\n      toEnv: notBlankToS,\n      fromEnv: toBoolean\n    })\n  }\n}\n", "import { toS } from \"../fe/toS\"\n\nexport function camel2snake(s: string): string {\n  return toS(s)\n    .replace(/([A-Z])([a-z])/g, (_, a, b) => \"_\" + a.toLowerCase() + b)\n    .replace(/[A-Z]+|[0-9]+/g, ea => \"_\" + ea)\n    .replace(/^_/, \"\")\n}\n\nexport function camel2words(s: string): string {\n  return toS(s)\n    .replace(/([A-Z])([a-z])/g, (_, a, b) => \" \" + a.toLowerCase() + b)\n    .replace(/[A-Z]+|[0-9]+/g, ea => \" \" + ea)\n    .trim()\n}\n", "import { compactBlanks } from \"../../fe/Array\"\nimport { blank, notBlank } from \"../../fe/Blank\"\nimport { secondMs } from \"../../fe/Date\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { SyncOrAsync } from \"../../fe/OptAsync\"\nimport { toS } from \"../../fe/toS\"\nimport { isTest } from \"../NodeEnv\"\nimport { Settings } from \"../settings/Settings\"\nimport { levelIndex, LogLevel, LogLevels } from \"./LogLevel\"\n\nexport interface LogFilter {\n  highlight(context: string): boolean\n\n  /**\n   * @return true iff the given level and context are not configured to be\n   * squelched/omitted from downstream log writers.\n   */\n  enabled(level: LogLevel, context?: string): boolean\n  /**\n   * The level index that is enabled by default (ignoring context-specific overrides)\n   */\n  readonly defaultLevelIndex: number\n  silent: boolean\n}\n\nexport namespace PermissiveLogFilter {\n  export const highlight = () => false\n  export const silent: boolean = false\n  export const enabled = () => !silent\n  export const defaultLevelIndex = levelIndex(\"trace\")\n}\n\nconst LogLevelRe = /^(?:(.+?):)?(error|warn|info|debug|trace)$/i\n\ninterface LogLevelContext {\n  prefix: string\n  levelIndex: number\n}\n\nexport class LogFilterImpl implements LogFilter {\n  silent = false\n  defaultLevelIndex!: number\n  private readonly contexts: LogLevelContext[] = []\n\n  /**\n   * Parse out directives like LOG=ExifTag:debug,FileIterator:info,warn\n   */\n  constructor(e?: Maybe<string>) {\n    this.setup(e)\n  }\n\n  setup(e?: Maybe<string>) {\n    this.contexts.length = 0\n    let defaultLevelIndex = levelIndex(Settings.logLevel.defaultValue)\n    const log = notBlank(e) ? e : Settings.logLevel.valueOrDefault\n    compactBlanks(log.split(\",\")).forEach(ea => {\n      const match = LogLevelRe.exec(ea.trim())\n      if (match == null) {\n        if (!isTest) {\n          console.error(\"LogFilterImpl: Ignoring '\" + ea + \"' from \" + e)\n        }\n      } else {\n        const prefix = toS(match[1]).toLowerCase()\n        const idx = levelIndex(match[2])\n        if (blank(prefix)) {\n          defaultLevelIndex = idx\n        } else {\n          this.contexts.push({ prefix, levelIndex: idx })\n        }\n      }\n    })\n    this.defaultLevelIndex = defaultLevelIndex\n  }\n\n  private contextOverride(context?: string): Maybe<LogLevelContext> {\n    if (this.contexts.length === 0 && blank(context)) return\n    const s = toS(context).toLowerCase()\n    return this.contexts.find(ea => s.startsWith(ea.prefix))\n  }\n\n  enabled(level: LogLevel, context?: string): boolean {\n    if (this.silent) return false\n    const li = levelIndex(level)\n    // PERF: unrolled from Opt\n    if (li <= this.defaultLevelIndex) {\n      return true\n    }\n    const co = this.contextOverride(context)\n    const result = co != null && li <= co.levelIndex\n    return result\n  }\n\n  highlight(context: string) {\n    // PERF: unrolled from Opt\n    const co = this.contextOverride(context)\n    return co != null && co.levelIndex >= this.defaultLevelIndex\n  }\n}\n\nlet _logFilter: Maybe<LogFilterImpl>\n\nexport function logFilter(): LogFilter {\n  if (_logFilter == null) {\n    _logFilter = new LogFilterImpl()\n    Settings.logLevel.addListener(() => _logFilter!.setup())\n  }\n  return _logFilter\n}\n\nexport const defaultLogLevel = lazy(\n  () => LogLevels.values[logFilter().defaultLevelIndex],\n  5 * secondMs\n)\n\nexport function silently<T>(f: () => T): T {\n  try {\n    logFilter().silent = true\n    return f()\n  } finally {\n    logFilter().silent = false\n  }\n}\n\nexport async function silentlyAsync<T>(f: () => PromiseLike<T>): Promise<T> {\n  try {\n    logFilter().silent = true\n    return await f()\n  } finally {\n    logFilter().silent = false\n  }\n}\n\nexport async function withLogLevel<T>(\n  logLevel: LogLevel,\n  f: () => SyncOrAsync<T>\n): Promise<T> {\n  const prior = Settings.logLevel.getState()\n  Settings.logLevel.tmpValue = logLevel\n  try {\n    return await f()\n  } finally {\n    Settings.logLevel.setState(prior)\n  }\n}\n\n/**\n * Apply `f()` if the given logLevel is enabled.\n */\nexport function ifLog<T>(logLevel: LogLevel, f: () => T): Maybe<T> {\n  return logFilter().enabled(logLevel) ? f() : undefined\n}\n", "import { last } from \"../fe/Array\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { Comparable, gte, lt } from \"../fe/Primitive\"\n\nexport class SortedArray<T> {\n  readonly store: T[] = []\n\n  constructor(readonly valueOf: (t: T) => Maybe<Comparable>) {}\n\n  get length() {\n    return this.store.length\n  }\n\n  add(t: Maybe<T>) {\n    if (t == null) {\n      return\n    }\n    const v = this.valueOf(t)\n    if (v == null) {\n      return\n    }\n    if (this.store.length === 0) {\n      this.store.push(t)\n      return\n    }\n    // use lt versus lte to preserve .add() order\n    if (lt(v, this.valueOf(this.store[0]))) {\n      this.store.unshift(t)\n      return\n    }\n    for (let i = this.store.length - 1; i >= 0; i--) {\n      if (gte(this.valueOf(t), this.valueOf(this.store[i]))) {\n        this.store.splice(i + 1, 0, t)\n        return\n      }\n    }\n    // this backstop should never need to be called:\n    this.store.unshift(t)\n  }\n\n  /**\n   * Remove all the entries less than the given entry\n   */\n  shiftLt(c: Comparable): T[] {\n    if (this.length === 0) return []\n    let count = 0\n    if (lt(this.valueOf(last(this.store)!), c)) {\n      // the whole store is shift-able:\n      count = this.store.length\n    } else {\n      // look from the head:\n      while (lt(this.valueOf(this.store[count]), c)) {\n        count++\n      }\n    }\n    const result = count === 0 ? [] : this.splice(0, count)\n    // console.log(\"shiftLt(\" + c + \"):\", {\n    //   count,\n    //   result: result.map(this.valueOf),\n    //   store: this.store.map(this.valueOf)\n    // })\n    return result\n  }\n\n  /**\n   * Removes elements from an array and, if necessary, inserts new elements in their place, returning the deleted elements.\n   * @param start The zero-based location in the array from which to start removing elements.\n   * @param deleteCount The number of elements to remove.\n   */\n  splice(start: number, deleteCount?: number): T[] {\n    return this.store.splice(start, deleteCount)\n  }\n}\n", "import { env } from \"process\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Settings } from \"../settings/Settings\"\nimport { ColoredLogFormatter } from \"./ColoredLogFormatter\"\nimport { PlaintextLogFormatter } from \"./PlaintextLogFormatter\"\n\nconst setupListener = lazy(() => {\n  Settings.logColor.addListener(() => DefaultLogFormatter.unset())\n})\n\nexport const DefaultLogFormatter = lazy(() => {\n  if (env.NO_COLOR != null) Settings.logColor.tmpValue = false\n  setupListener()\n  return Settings.logColor.valueOrDefault\n    ? new ColoredLogFormatter({ processName: () => \"\" })\n    : new PlaintextLogFormatter()\n})\n", "import { inspect } from \"util\"\nimport { compactBlanks } from \"../../fe/Array\"\nimport { orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { Thunk } from \"../../fe/Thunk\"\nimport { toS } from \"../../fe/toS\"\nimport { blue, cyan, darkGrey, redBright, yellow, yellowBright } from \"../Chalk\"\nimport { isTest } from \"../NodeEnv\"\nimport { colorProcessName, processName } from \"../ServiceNames\"\nimport { dateForLog } from \"./LogCommon\"\nimport { LogEntry } from \"./LogEntry\"\nimport { logFilter } from \"./LogFilter\"\nimport { FormatterOptions, LogFormatter } from \"./LogFormatter\"\nimport { LogLevel } from \"./LogLevel\"\nimport { ContextLines, prepMeta } from \"./LogMeta\"\n\nexport class ColoredLogFormatter implements LogFormatter {\n  private readonly logLevels = {\n    trace: \"trace\",\n    debug: darkGrey(\"debug\"),\n    info: cyan(\"info \"),\n    error: redBright(\"error\"),\n    warn: yellowBright(\"warn \")\n  }\n\n  static defaultInspectOptions: Thunk<FormatterOptions> = () => ({\n    showHidden: false,\n    depth: 4,\n    colors: true,\n    compact: true,\n    customInspect: true,\n    maxArrayLength: ContextLines + 1,\n    processName: processName\n  })\n  private readonly inspectOptions: FormatterOptions\n  constructor(inspectOptions: Partial<FormatterOptions> = {}) {\n    this.inspectOptions = {\n      ...ColoredLogFormatter.defaultInspectOptions(),\n      ...inspectOptions\n    }\n    if (isTest) {\n      this.inspectOptions.breakLength = 255\n    }\n  }\n\n  formatMeta(meta?: Maybe<any[]>) {\n    if (meta == null) return undefined\n    const m = prepMeta(meta)\n    return m == null ? undefined : inspect(m, this.inspectOptions)\n  }\n\n  formatLogEntry(le: LogEntry): string {\n    const contextColor = logFilter().highlight(le.ctx) ? yellow : blue\n    return compactBlanks([\n      dateForLog(le.ts),\n      colorProcessName(\n        orElse(le.from, () => this.inspectOptions.processName())\n      ),\n      this.logLevels[le.l],\n      contextColor(le.ctx),\n      le.msg,\n      this.formatMeta(le.meta)\n    ])\n      .map(ea => toS(ea))\n      .join(\" \")\n  }\n\n  format(\n    level: LogLevel,\n    context: string,\n    message: string,\n    meta?: any\n  ): string {\n    return this.formatLogEntry({\n      ts: Date.now(),\n      l: level,\n      from: processName(),\n      ctx: context,\n      msg: message,\n      meta\n    })\n  }\n}\n", "import { Duration } from \"luxon\"\nimport { darkGrey, yellow } from \"../Chalk\"\nimport { isTest } from \"../NodeEnv\"\nimport { Settings } from \"../settings/Settings\"\n\nconst start = Date.now()\n\nexport function dateForLog(ts: number) {\n  const result = Settings.logElapsedMs.valueOrDefault\n    ? // inlined the msToHMS to prevent logging from pulling in Date:\n      Duration.fromMillis(ts - start).toFormat(\"hhhh:mm:ss.SSS\")\n    : new Date(ts).toISOString()\n\n  if (Settings.logColor.valueOrDefault) {\n    return Settings.logElapsedMs.valueOrDefault\n      ? yellow(result)\n      : darkGrey(result)\n  } else {\n    return result\n  }\n}\n\nexport const DefaultLogFlushMs = isTest ? 250 : 750\n", "import { inspect, InspectOptions } from \"util\"\nimport { compactBlanks } from \"../../fe/Array\"\nimport { map } from \"../../fe/Maybe\"\nimport { fromEntries } from \"../../fe/Object\"\nimport { toS } from \"../../fe/toS\"\nimport { processName } from \"../ServiceNames\"\nimport { rightPad, stripAnsiEsc } from \"../String\"\nimport { dateForLog } from \"./LogCommon\"\nimport { LogEntry } from \"./LogEntry\"\nimport { LogFormatter } from \"./LogFormatter\"\nimport { LogLevel, LogLevels } from \"./LogLevel\"\n\nexport class PlaintextLogFormatter implements LogFormatter {\n  constructor(\n    readonly inspectOptions: InspectOptions = {\n      colors: false,\n      depth: 4,\n      compact: true,\n      customInspect: true\n    }\n  ) {}\n\n  readonly paddedLogLevels = fromEntries(\n    LogLevels.values.map(ea => [ea, rightPad(ea, 5, \" \")])\n  )\n\n  formatLogEntry(le: LogEntry): string {\n    return compactBlanks([\n      dateForLog(le.ts),\n      processName(),\n      this.paddedLogLevels[le.l],\n      stripAnsiEsc(le.ctx),\n      stripAnsiEsc(le.msg),\n      map(le.meta, ea => inspect(ea, this.inspectOptions))\n    ])\n      .map(ea => toS(ea))\n      .join(\" \")\n  }\n\n  format(\n    level: LogLevel,\n    context: string,\n    message: string,\n    meta?: any\n  ): string {\n    return this.formatLogEntry({\n      ts: Date.now(),\n      l: level,\n      from: processName(),\n      ctx: context,\n      msg: message,\n      meta\n    })\n  }\n}\n", "import { sortByInPlace } from \"../../fe/Array\"\nimport { LogLevel } from \"./LogLevel\"\n\n/**\n * field names are abbreviated as they are encoded in JSON on disk.\n */\nexport interface LogEntry {\n  /**\n   * timestamp\n   */\n  ts: number\n  /**\n   * log level\n   */\n  l: LogLevel\n  /**\n   * context\n   */\n  ctx: string\n  /** message */\n  msg: string\n  meta?: any[]\n  from?: string\n}\n\nexport function logEntrySorter(ea: LogEntry) {\n  return ea?.ts\n}\n\nexport function sortLogEntriesInPlace(arr: LogEntry[]) {\n  sortByInPlace(arr, ea => ea.ts)\n}\n", "import { SortedArray } from \"../SortedArray\"\nimport { DefaultLogFormatter } from \"./DefaultLogFormatter\"\nimport { DefaultLogFlushMs } from \"./LogCommon\"\nimport { LogEntry, logEntrySorter } from \"./LogEntry\"\n\n// Separated from LogTail to break require chains\n\nlet _logTailEnabled = false\n\nexport function logTailEnabled() {\n  return _logTailEnabled\n}\n\nexport function setLogTailEnabled(b: boolean) {\n  _logTailEnabled = b\n}\n\nconst logEntries = new SortedArray<LogEntry>(logEntrySorter)\n\nexport function pushLogEntries(...arr: LogEntry[]) {\n  // PERF: for loop instead of .forEach\n  for (const ea of arr) {\n    // don't use Settings.logTail:\n    if (_logTailEnabled) {\n      logEntries.add(ea)\n    } else {\n      console.log(DefaultLogFormatter().formatLogEntry(ea))\n    }\n  }\n}\n\n/**\n * @param ttl if zero, pop everything (we're shutting down)\n */\nexport function popExpiredLogEntries(ttl = DefaultLogFlushMs * 2) {\n  return logEntries.shiftLt(Date.now() - ttl)\n}\n", "import { lazy } from \"../../fe/Lazy\"\nimport { processName } from \"../ServiceNames\"\nimport { logFilter } from \"./LogFilter\"\nimport { SimpleLogger } from \"./Logger\"\nimport { LogLevel } from \"./LogLevel\"\nimport { pushLogEntries } from \"./LogTailEntries\"\n\n/**\n * Works in concert with LogTail so both local and remote log messages are mixed\n * together.\n */\nexport class ConsoleLogger implements SimpleLogger {\n  static readonly instance = lazy(() => new ConsoleLogger())\n\n  log(level: LogLevel, context: string, msg: string, meta?: any) {\n    pushLogEntries({\n      ts: Date.now(),\n      l: level,\n      from: processName(),\n      ctx: context,\n      msg,\n      meta\n    })\n  }\n\n  enabled(level: LogLevel, context: string): boolean {\n    return logFilter().enabled(level, context)\n  }\n\n  async flush() {\n    // no op\n  }\n\n  end() {\n    // no op\n  }\n}\n", "import _fs = require(\"fs\")\nimport { join } from \"path\"\nimport { clearInterval } from \"timers\"\nimport { compact, compactBlanks } from \"../../fe/Array\"\nimport { fmtIsoDate, secondMs } from \"../../fe/Date\"\nimport { unrefDelay } from \"../../fe/Delay\"\nimport { stringify } from \"../../fe/JSON\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { thenMap } from \"../../fe/Promise\"\nimport { addLoggerEndable, Endable } from \"../async/Endable\"\nimport { Promises } from \"../async/Promises\"\nimport { setUnrefInterval } from \"../async/Timers\"\nimport { splitLines } from \"../fs/CRLF\"\nimport { ensureNewNativePath_, gzip_, nameWithoutCount } from \"../fs/Path\"\nimport { SimpleFile } from \"../fs/SimpleFile\"\nimport { endStream } from \"../fs/Streams\"\nimport { zcat } from \"../fs/zcat\"\nimport { mapParsed } from \"../JSON\"\nimport { processName } from \"../ServiceNames\"\nimport { Settings } from \"../settings/Settings\"\nimport { stripAnsiEsc } from \"../String\"\nimport { ConsoleLogger } from \"./ConsoleLogger\"\nimport { DefaultLogFlushMs } from \"./LogCommon\"\nimport { LogEntry } from \"./LogEntry\"\nimport { ContextProvider } from \"./LogFormatter\"\nimport { SimpleLogger } from \"./Logger\"\nimport { LogLevel } from \"./LogLevel\"\nimport { clearRecentLogEntries, recentLogEntries } from \"./RecentLogs\"\n\nexport type WritableStream = NodeJS.WritableStream\n\nexport class CaptureLogger implements SimpleLogger {\n  readonly logEntries: LogEntry[] = []\n  log(level: LogLevel, context: string, message: string, meta?: any) {\n    this.logEntries.push({\n      ts: Date.now(),\n      l: level,\n      ctx: context,\n      msg: message,\n      meta\n    })\n  }\n\n  enabled() {\n    return true\n  }\n\n  end() {\n    // no-op\n  }\n\n  async flush() {\n    // no-op\n  }\n}\n\nexport interface LogWriterOptions {\n  maxLinesPerFile: number\n  errorLogger: SimpleLogger\n  flushEveryMs: number\n}\n\n/**\n * Writes to logDir/YYYY-MM-DD/name-00N.log\n */\nexport class LogWriter implements SimpleLogger, Endable {\n  readonly name: string\n  ended = false\n  private readonly mutex = new Promises()\n  private readonly opts: Required<LogWriterOptions & ContextProvider>\n  private _linesSinceRotate: number = 0\n  private _currentFile: Maybe<string>\n  private _stream: Maybe<WritableStream>\n  private readonly pendingWrites: string[] = []\n  private flushInterval: Maybe<NodeJS.Timer>\n  private _startIndex = 0\n\n  // gzipping the logfiles should not take longer than 10 seconds (assuming logs\n  // are on fast local disk)\n  readonly endTimeoutMs = 15 * secondMs\n\n  constructor(\n    readonly logDir: string,\n    options: Partial<LogWriterOptions & ContextProvider> = {}\n  ) {\n    this.name = \"LogWriter(\" + logDir + \")\"\n    this.opts = {\n      maxLinesPerFile: 250000, // ~ 10-20 Mb\n      errorLogger: ConsoleLogger.instance(),\n      flushEveryMs: DefaultLogFlushMs,\n      processName: processName,\n      ...options\n    }\n    this.flushInterval = setUnrefInterval(\n      () => this.maybeFlush(),\n      this.opts.flushEveryMs\n    )\n    addLoggerEndable(this)\n  }\n\n  log(level: LogLevel, context: string, msg: string, meta?: any) {\n    if (this.ended && level === \"error\") {\n      // If it's bad, send the message someplace, at least.\n      this.opts.errorLogger.log(level, context, msg, meta)\n    } else {\n      const entry: LogEntry = { ts: Date.now(), l: level, ctx: context, msg }\n      if (meta != null) entry.meta = meta\n      if (level === \"error\") {\n        // If we push entry before this, the recentLogEntries show out of order:\n        this.writeRecentLogEntries()\n        void this.flush()\n      }\n      this.pendingWrites.push(stringify(entry) + \"\\n\")\n    }\n  }\n\n  // must not be async (so this.log can stay sync)\n  writeRecentLogEntries() {\n    this.pendingWrites.push(\n      ...recentLogEntries().map(ea => stringify(ea) + \"\\n\")\n    )\n    // we don't want to write these entries more than once:\n    clearRecentLogEntries()\n  }\n\n  readonly end = lazy(async () => {\n    this.ended = true\n    map(this.flushInterval, clearInterval)\n    this.flushInterval = undefined\n    await this.flush()\n    return this.mutex.serial(\"close\", () => {\n      return this._closeCurrent()\n    })\n  })\n\n  private readonly maybeFlush = () =>\n    this.mutex.maybeRun(\"maybeFlush\", () => this._flush())\n\n  readonly shouldRotate = () =>\n    this._stream == null || this._linesSinceRotate >= this.opts.maxLinesPerFile\n\n  async flush() {\n    await this.mutex.serial(\"flush\", () => this._flush())\n  }\n\n  private async _flush() {\n    const toFlush = [...this.pendingWrites]\n    this.pendingWrites.length = 0\n    while (toFlush.length > 0) {\n      if (this.shouldRotate()) await this._rotate()\n      const stream = this._stream\n      if (stream == null) {\n        this.opts.errorLogger.log(\n          \"error\",\n          \"LogWriter.flush()\",\n          \"this._rotate() returned an empty stream\"\n        )\n        return\n      }\n      const remainingCapacity =\n        this.opts.maxLinesPerFile - this._linesSinceRotate\n      const lines = toFlush.splice(0, remainingCapacity)\n      this._linesSinceRotate += lines.length\n      stream.write(lines.join(\"\"))\n    }\n    return\n  }\n\n  private errback(source: string) {\n    return (err: any) =>\n      this.opts.errorLogger.log(\"error\", \"Caught error from \" + source, err)\n  }\n\n  private async _rotate(): Promise<void> {\n    await this._closeCurrent()\n    this._currentFile = await ensureNewNativePath_({\n      nativePath: join(\n        this.logDir,\n        fmtIsoDate(new Date()),\n        stripAnsiEsc(this.opts.processName()) + \".log\"\n      ),\n      emptyIsNew: true,\n      startIndex: ++this._startIndex,\n      requireNumber: true,\n      leftPad: 3 // we're in trouble if we're writing more than 100 log files a day.\n    })\n    this._stream = _fs\n      .createWriteStream(this._currentFile)\n      .on(\"error\", this.errback(\"file write stream\"))\n    return\n  }\n\n  private async _closeCurrent() {\n    // not this.end(), because we don't want to flush:\n    const priorStream = this._stream\n    this._stream = undefined\n    this._linesSinceRotate = 0\n    const priorFile = this._currentFile\n    this._currentFile = undefined\n\n    await endStream(priorStream)\n    if (Settings.logCompression.valueOrDefault) {\n      // let logtail see the result of the file:\n      await unrefDelay(this.opts.flushEveryMs)\n      await map(priorFile, gzip_)\n    }\n  }\n}\n\nexport async function readLogEntries(\n  f: SimpleFile,\n  options?: { start?: number; end?: number }\n): PromiseMaybe<LogEntry[]> {\n  const from = nameWithoutCount(f.name)\n  return thenMap(zcat(f.nativePath, options), s =>\n    compact(\n      compactBlanks(splitLines(s)).map(ea =>\n        mapParsed(ea, le => ({ ...le, from } as LogEntry))\n      )\n    )\n  )\n}\n", "import { notBlank } from \"../fe/Blank\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { Pojo } from \"./Object\"\n\nexport function parseMaybe<T = Pojo>(s: string): Maybe<T> {\n  // perf: unrolled\n  try {\n    if (notBlank(s)) {\n      return JSON.parse(s)\n    }\n  } catch {\n    //\n  }\n  return\n}\n\nexport function mapParsed<T>(s: string, f: (o: Pojo) => T): Maybe<T> {\n  try {\n    if (notBlank(s)) {\n      return f(JSON.parse(s))\n    }\n  } catch {\n    //\n  }\n  return\n}\n", "import { lazy } from \"../fe/Lazy\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { end } from \"./async/Endable\"\nimport { ConsoleLogger } from \"./log/ConsoleLogger\"\nimport { ContextualLogger, SimpleLogger } from \"./log/Logger\"\nimport { LogWriter } from \"./log/LogWriter\"\nimport { Settings } from \"./settings/Settings\"\n\n//\n// This file integrates PhotoStructure with the log package.\n//\n\n// the logger is a process singleton. This should only be called at the\n// beginning of the process, and sets up the directory for the logger.\n\n// mkLogger() should always point to the current value of the process logger.\n\nconst rootLoggers = lazy<SimpleLogger[]>(() => [ConsoleLogger.instance()])\n\nexport function currentFileLogger(): Maybe<LogWriter> {\n  return rootLoggers().find(ea => ea instanceof LogWriter) as LogWriter\n}\n\nexport function setupLogger() {\n  const logDir = Settings.logDir.valueOrDefault\n  let fl = currentFileLogger()\n  if (fl == null || fl.logDir !== logDir) {\n    void end(fl)\n    fl = new LogWriter(logDir)\n  }\n  const arr: SimpleLogger[] = [fl]\n  if (Settings.logStdout.valueOrDefault || Settings.tailLogs.valueOrDefault) {\n    arr.push(ConsoleLogger.instance())\n  }\n  rootLoggers.set(arr)\n}\n\nexport function writeRecentLogEntries() {\n  return currentFileLogger()?.writeRecentLogEntries()\n}\n\nexport type Logger = ContextualLogger // TODO: inline?\n\nexport function mkLogger(context: string): ContextualLogger {\n  return new ContextualLogger(context, rootLoggers)\n}\n", "import { Command } from \"commander\"\nimport { stdout } from \"process\"\nimport { wrap } from \"../../fe/String\"\n\nconst year = new Date().getFullYear()\n\nexport const descriptionFooter = `Please visit <https://photostructure.com/support/> for detailed usage and configuration instructions.\n\nCopyright \u00A9 2017-${year}, PhotoStructure Inc.\n\nRunning this software indicates your agreement to all the terms of this license: <https://photostructure.com/eula/>`\n\nexport const CliDesc = {\n  main:\n    \"PhotoStructure's main process manager. Runs and manages web and sync services.\",\n  info: \"Configuration, file metadata and import diagnostics tool. \",\n  list: \"List all paths in a Library.\",\n  logcat: \"Chronologically sort and pretty-print PhotoStructure logfiles.\",\n  logtail:\n    \"View the log messages of currently-running PhotoStructure processes. (Like `tail -f`).\",\n  web: \"PhotoStructure's web service. Automatically started by main.\",\n  sync:\n    \"PhotoStructure's directory synchronization service. Automatically started by main.\",\n  \"sync-file\":\n    \"PhotoStructure's file synchronization service. Automatically started by sync.\"\n}\n\nexport function addFooter(c: Command): Command {\n  return c.on(\"--help\", () => {\n    console.log(\n      \"\\n\" +\n        wrap(descriptionFooter, {\n          maxLineLen: stdout.columns ?? 78,\n          prefix: \"\"\n        }).join(\"\\n\") +\n        \"\\n\"\n    )\n  })\n}\n", "import p from \"process\"\nimport { isTrue } from \"../../fe/Boolean\"\nimport { blank } from \"../../fe/Blank\"\n\nexport interface DaemonOptions {\n  daemon?: boolean\n  pidfile?: string\n  stop?: boolean\n}\n\nexport function isDaemon(opts?: DaemonOptions) {\n  return (\n    isTrue(p.env.__is_daemon) || isTrue(opts?.daemon) || !blank(opts?.pidfile)\n  )\n}\n", "import { Command } from \"commander\"\nimport { isTrue } from \"../../fe/Boolean\"\nimport { Pojo } from \"../../core/Object\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { map } from \"../../fe/Maybe\"\nimport { isDaemon } from \"./IsDaemon\"\n\n/**\n * Used by logcat and logtail\n */\nexport const LogArgs = {\n  beforeParse: (cmd: Command, skipInfoVerbose = false) => {\n    cmd.option(\n      \"--warn\",\n      `Emit \"warn\" and \"error\" messages from this process to stdout. Sets PS_LOG_LEVEL to \"warn\" and PS_LOG_STDOUT to true. Ignored if daemonized.`\n    )\n    if (!skipInfoVerbose) {\n      cmd.option(\n        \"--info|--verbose\",\n        `Emit \"info\", \"warn\", and \"error\" messages from this process to stdout. Sets PS_LOG_LEVEL to \"info\" and PS_LOG_STDOUT to true. Ignored if daemonized.`\n      )\n    }\n    cmd\n      .option(\n        \"--debug\",\n        `Emit \"debug\", \"info\", \"warn\", and \"error\" messages from this process to stdout. CAUTION: VERY NOISY. Sets PS_LOG_LEVEL to \"debug\" and PS_LOG_STDOUT to true. When run from the main service, all other process logs will also be emitted. Ignored if daemonized.`\n      )\n      .option(\"--color\", \"Enable ASCII terminal colors\", true)\n      .option(\"--no-color\", \"Disable ASCII terminal colors\")\n\n    return cmd\n  },\n  afterParse: (opts: Pojo) => {\n    map(opts.color, ea => (Settings.logColor.tmpValue = ea))\n\n    const warn = isTrue(opts.warn)\n    const info = isTrue(opts.info) || isTrue(opts.verbose)\n    const debug = isTrue(opts.debug)\n\n    if (warn) Settings.logLevel.tmpValue = \"warn\"\n    if (info) Settings.logLevel.tmpValue = \"info\"\n    if (debug) Settings.logLevel.tmpValue = \"debug\"\n\n    if (!isDaemon(opts) && (warn || info || debug)) {\n      Settings.logStdout.tmpValue = true\n    }\n  }\n}\n", "import { Command } from \"commander\"\nimport { CommandPlugin } from \"../../core/cli/CLI\"\nimport { isDaemon } from \"../../core/cli/IsDaemon\"\nimport { LogArgs } from \"../../core/cli/LogArgs\"\nimport { Pojo } from \"../../core/Object\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { isTrue } from \"../../fe/Boolean\"\n\n/**\n * Used by all services that log (which should be everything except logtail)\n */\nexport const CommonArgs: CommandPlugin = {\n  beforeParse: (cmd: Command) => {\n    const skipInfoVerbose = true\n    cmd\n      .option(\n        \"--info\",\n        `Emit \"info\", \"warn\", and \"error\" messages from this process to stdout. Sets PS_LOG_LEVEL to \"info\" and PS_LOG_STDOUT to true. Ignored if daemonized.`\n      )\n      .option(\n        \"--verbose\",\n        `Verbose logging from all processes. Shortcut for \"--info --tail\". Caution: noisy during imports!`\n      )\n      .option(\n        \"--tail\",\n        `Emit log messages from both this process and all other concurrently running PhotoStructure processes on this host to stdout. This can be really helpful in seeing how PhotoStructure's processes are coordinating work. Caution: very noisy especially during imports. Sets PS_TAIL_LOGS to true. Ignored if daemonized.`\n      )\n\n    LogArgs.beforeParse(cmd, skipInfoVerbose)\n\n    cmd.option(\n      \"--force-open,--forceOpen\",\n      `DANGEROUS: removes all previously-existing library locks. This should only be necessary if the prior PhotoStructure process was not shut down gracefully.`\n    )\n\n    return cmd\n  },\n  // This makes logtail sorting not work correctly:\n  // .option(\n  //   \"--elapsed\",\n  //   `Prefix log entries with elapsed time since process start, rather than absolute time. Sets PS_LOG_ELAPSED_MS to \"true\"`\n  // )\n\n  afterParse: (opts: Pojo) => {\n    LogArgs.afterParse(opts)\n\n    if (isTrue(opts.elapsed)) {\n      Settings.logElapsedMs.tmpValue = opts.elapsed\n    }\n    if (isDaemon(opts as any)) {\n      // don't log to stdout if we're a daemon:\n      Settings.logStdout.tmpValue = false\n      Settings.tailLogs.tmpValue = false\n    } else {\n      const verbose = isTrue(opts.verbose)\n      if (verbose && Settings.logLevel.isUnset()) {\n        Settings.logLevel.tmpValue = \"info\"\n      }\n\n      if (isTrue(opts.tail) || verbose) {\n        Settings.tailLogs.tmpValue = true\n      }\n\n      if (isTrue(opts.forceOpen)) {\n        Settings.forceOpen.tmpValue = true\n      }\n    }\n  }\n}\n", "// (separated into own file to break dep circles)\nexport const ExitWhenDone = \"--exit-when-done\"\n", "import { Command } from \"commander\"\nimport { CommandPlugin } from \"../../core/cli/CLI\"\nimport { Pojo } from \"../../core/Object\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { isTrue } from \"../../fe/Boolean\"\nimport { ExitWhenDone } from \"./ExitWhenDone\"\n\n/**\n * Used by sync and sync-file\n */\nexport const ExitWhenDoneArg: CommandPlugin = {\n  beforeParse: (cmd: Command) =>\n    cmd.option(\n      ExitWhenDone + \",--exitWhenDone\",\n      \"Exit after jobs are completed. Defaults to false unless paths are specified on the command line.\"\n    ),\n  afterParse: (opts: Pojo) => {\n    if (isTrue(opts.exitWhenDone)) {\n      Settings.exitWhenDone.tmpValue = true\n    }\n  }\n}\n", "import { mkdirp } from \"fs-extra\"\nimport { thenMapOr } from \"../core/async/Promise\"\nimport { cacheDir } from \"../core/CacheDir\"\nimport { shortStringSha } from \"../core/fs/Hash\"\nimport { PosixFile } from \"../core/fs/PosixFile\"\nimport { mkLogger } from \"../core/Logger\"\nimport { TokenRadix } from \"../core/math/Radix\"\nimport { AssetFileVersion, AssetVersion } from \"../core/PhotoStructureVersions\"\nimport { Settings } from \"../core/settings/Settings\"\nimport { stringify } from \"../fe/JSON\"\nimport { lazy } from \"../fe/Lazy\"\nimport { orElse } from \"../fe/Maybe\"\n\nconst logger = lazy(() => mkLogger(\"StatsDbDir\"))\n\nexport async function cacheDirs(): Promise<PosixFile[]> {\n  return thenMapOr(\n    cacheDir().clear().children(),\n    arr => arr.filter(ea => ea.name.startsWith(CacheDirPrefix)),\n    () => []\n  )\n}\n\nexport const CacheDirPrefix = \"sync-state-\"\n\n// TCBH: By including the settings in the cache dir, we reset the cache dir if\n// the settings change. Note that this is a short SHA, as there won't be many\n// items (therefore not many chances for collisions). 3 chars would be most\n// likely be fine.\n/**\n * @throws if the directory can't be created.\n */\nexport async function statsDbDir(createIfMissing = true): Promise<PosixFile> {\n  // Really only library settings should invalidate a cache dir:\n  const values: [string, any][] = []\n  // Rather than push the version, we'll push db versions, which only change\n  // when something in the asset processing pipeline changes to warrant\n  // re-syncing everything.\n  values.push([\"Asset version\", AssetVersion])\n  values.push([\"Asset file version\", AssetFileVersion])\n  values.push([\"Library path\", Settings.libraryPath.value])\n  const suffix = shortStringSha(stringify(values), 10, TokenRadix)\n  const dir = cacheDir().join(CacheDirPrefix + suffix)\n  if (!createIfMissing) return dir\n\n  await mkdirp(dir.nativePath)\n  await dir.join(\"README.txt\").applyIfEmpty_(ea =>\n    ea\n      .writeTxt_(\n        `This folder holds state for library synchronization of\n\n${Settings.libraryPath.value}\n\nIf you delete or modify the contents of this directory, you will need to\nrestart PhotoStructure. The next sync will rescan all your drives.\n\nIf you have any questions, please visit <https://photostructure.com/support/>.\n\n` + values.map(([k, v]) => `${k}: ${v}`).join(\"\\n\")\n      )\n      .catch(err => {\n        logger().warn(\"Failed to write README to \" + dir, err)\n      })\n  )\n  logger().info(\"Set up statsDbDir dir \" + dir)\n  return dir\n}\n\nexport async function clearCacheDir(dir?: PosixFile) {\n  const d = orElse(dir, await statsDbDir())\n  if (!d.name.startsWith(CacheDirPrefix)) {\n    throw new Error(\"Refusing to remove directory \" + d)\n  }\n  await d.rmrf()\n  return\n}\n\nexport async function vacuumCacheDirs() {\n  const currentCacheDir = await statsDbDir()\n  for (const dir of await cacheDirs()) {\n    if (!dir.eql(currentCacheDir)) await clearCacheDir(dir)\n  }\n  return\n}\n\nexport async function clearCacheDirs() {\n  for (const dir of await cacheDirs()) {\n    await clearCacheDir(dir)\n  }\n  return\n}\n", "import { sep } from \"path\"\nimport {\n  commonPrefixLength,\n  flatten,\n  mapNotEmpty,\n  sort,\n  sortBy\n} from \"../../fe/Array\"\nimport { blank, notBlank, notBlankOr } from \"../../fe/Blank\"\nimport { secondMs, unixtime } from \"../../fe/Date\"\nimport { lazy, MemoizedThunk } from \"../../fe/Lazy\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { gt0 } from \"../../fe/Number\"\nimport { StringValued } from \"../../fe/Object\"\nimport { opt } from \"../../fe/Opt\"\nimport { thenOpt } from \"../../fe/OptAsync\"\nimport { ensurePrefix } from \"../../fe/String\"\nimport { toA } from \"../../fe/toA\"\nimport { toS } from \"../../fe/toS\"\nimport { contextFilter, greatestBy } from \"../Array\"\nimport { sortByAsync, thenMap, thenMapOr } from \"../async/Promise\"\nimport { stdout } from \"../child/ChildProcess\"\nimport { emitFileChanged } from \"../event/EventEmitter\"\nimport { mkLogger } from \"../Logger\"\nimport { Radix58 } from \"../math/Radix\"\nimport { groupBy } from \"../MultiMap\"\nimport { isMac, isWin } from \"../Platform\"\nimport { Settings } from \"../settings/Settings\"\nimport { equalsIgnoreCase } from \"../String\"\nimport { isSidecarExt } from \"../tags/FileExts\"\nimport { nativePath2uri, uri2nativePath } from \"../uri/FileURI\"\nimport { toURI, URI } from \"../uri/URI\"\nimport { isUri } from \"../uri/UriNormalization\"\nimport { mountpoints } from \"../volumes/Mountpoints\"\nimport { BaseFile } from \"./BaseFile\"\nimport { DirectoryEntry } from \"./DirectoryEntry\"\nimport { FileCache } from \"./FileCache\"\nimport { fileSha } from \"./Hash\"\nimport { hidden } from \"./Hidden\"\nimport { ignorableDirectory, ignorableFile, ignorablePath } from \"./Ignorable\"\nimport { hasNoMedia } from \"./NoMedia\"\nimport { containedByNativePath, nameWithoutCount, resolve } from \"./Path\"\nimport { SimpleFile } from \"./SimpleFile\"\n\nconst cache = new FileCache<PosixFile>()\n\nexport function groupByMountpoint(paths: PosixFile[], mounts: PosixFile[]) {\n  return groupBy(paths, path =>\n    map(path.bestMountpoint(mounts), ea => ea.nativePath)\n  )\n}\n\nfunction sortFiles(paths: PosixFile[]) {\n  return sortBy(paths, ea => ea.nativePath)\n}\n\nexport function uniquePrefixes(paths: PosixFile[]) {\n  return contextFilter(\n    sortFiles(paths),\n    // This also does a uniq():\n    (ea, _idx, last) => last == null || !ea.isDescendantOf(last)\n  )\n}\n\n/**\n * Given a set of paths and a set of mountpoints, coalesce any paths from the\n * same mountpoint that overlap.\n */\nexport function coalesce(paths: PosixFile[], mounts: PosixFile[]): PosixFile[] {\n  const byMountpoint = groupByMountpoint(paths, mounts)\n  return sortFiles(flatten(toA(byMountpoint.values()).map(uniquePrefixes)))\n}\n\n/**\n * Ensures a given path is only \"posix-ized\" once, and holds promises for more\n * expensive information about the file, like inode stats, SHA1, and EXIF tags.\n */\nexport class PosixFile extends BaseFile implements SimpleFile {\n  protected readonly pflog = lazy(() =>\n    mkLogger(\"PosixFile(\" + this.nativePath + \")\")\n  )\n\n  protected constructor(readonly nativePath: string, dirent?: DirectoryEntry) {\n    super(nativePath, dirent)\n    // cache.set(nativePath, this)\n  }\n\n  static forDirectoryEntry(de: DirectoryEntry) {\n    return this.for(de.nativePath, de)\n  }\n\n  static for(\n    nativePathOrFile: string | BaseFile | PosixFile,\n    dirent?: DirectoryEntry\n  ): PosixFile {\n    if (blank(nativePathOrFile)) throw new Error(\"unexpectedly empty path\")\n    if (nativePathOrFile instanceof PosixFile) {\n      return nativePathOrFile\n    }\n    if (nativePathOrFile instanceof BaseFile) {\n      return this.for(nativePathOrFile.nativePath, dirent)\n    }\n    if (isUri(nativePathOrFile)) throw new Error(\"use forUri\")\n\n    // PERF: resolve() is expensive.\n    const prior = cache.get(nativePathOrFile)\n    if (prior != null) return prior\n    const resolvedPath = resolve(nativePathOrFile)\n\n    return cache.getOrSet(\n      resolvedPath,\n      () => new PosixFile(resolvedPath, dirent)\n    )\n\n    // return new PosixFile(resolve(pathOrFile), dirent)\n  }\n\n  static forPosix(path: string): PosixFile {\n    return this.for(path.replace(/\\//g, sep))\n  }\n\n  static forUri(uri: string, mountpoint?: string): PromiseMaybe<PosixFile> {\n    return thenMap(uri2nativePath(uri, mountpoint), nativePath =>\n      this.for(nativePath)\n    )\n  }\n\n  for(path: string, dirent?: DirectoryEntry): this {\n    return PosixFile.for(path, dirent) as this\n  }\n\n  clear(): this {\n    super.clear()\n    this.uriObject.unset()\n    this.uri.unset()\n    this.fileuri.unset()\n    this.mountpoint.unset()\n    this.etag.unset()\n    this.sidecars.unset()\n    return this\n  }\n\n  readonly uriObject = lazy(() => nativePath2uri(this.nativePath))\n  readonly uri = lazy(() => thenMap(this.uriObject(), toS))\n  readonly fileuri = lazy(() => URI.file(this.nativePath).toString())\n\n  readonly mountpoint = lazy(() => {\n    if (isWin && this.nativePath.startsWith(\"\\\\\\\\\")) {\n      return this.for(this.nativePath.split(\"\\\\\").slice(0, 4).join(\"\\\\\"))\n    }\n    return thenMap(mountpoints(), arr =>\n      this.bestMountpoint(arr.map(ea => this.for(ea)))\n    )\n  })\n\n  bestMountpoint(mounts: (this | string)[]): Maybe<this> {\n    return greatestBy(\n      mounts\n        .filter(ea => containedByNativePath(this.nativePath, ea.toString()))\n        .map(ea => PosixFile.for(ea) as this),\n      mount =>\n        opt(commonPrefixLength(this.pathnames, mount.pathnames))\n          .filter(len => len >= mount.pathnames.length) // if the mountpoint isn't an ancestor, this isn't from that mountpoint.\n          .get()\n    )\n  }\n\n  /**\n   * @return true iff this file or directory doesn't exist, and the mountpoint\n   * is currently mounted, or some parent directory exists.\n   */\n  async isDeleted(uri?: URI | string): PromiseMaybe<boolean> {\n    uri = await notBlankOr(uri, () => this.uri() as any)\n    if (this.isUNC) {\n      return this.pflog().tap({\n        result: undefined,\n        msg: \"isDeleted(): UNC not supported\"\n      })\n    }\n\n    // We know it's not deleted if this exists!\n    if (await this.exists()) {\n      return this.pflog().tap({\n        result: false,\n        msg: \"isDeleted(): file exists\"\n      })\n    }\n\n    if (uri == null) {\n      return this.pflog().tap({\n        result: undefined,\n        level: \"warn\",\n        msg: \"isDeleted(): missing URI\"\n      })\n    }\n\n    // So at this point, we know this file doesn't exist.\n\n    uri = toURI(uri)\n\n    if (uri.isRootPath()) {\n      // don't descend any farther, we're at (least a prior) mountpoint\n      return this.pflog().tap({\n        result: undefined,\n        msg: \"isDeleted(): uri isRootPath\",\n        meta: { uri }\n      })\n    }\n\n    // Is the uri relevant to this path?\n\n    if (toS(uri.pathBase).normalize() !== this.base.normalize()) {\n      return this.pflog().tap({\n        level: \"warn\",\n        result: undefined,\n        msg: \"isDeleted(): uri isn't correct\",\n        meta: { uri, expectedBase: this.base, uriBase: uri.pathBase }\n      })\n    }\n\n    // If we can make any claim about a parent, we know I've been deleted.\n\n    const parentDeleted = await this.parent().isDeleted(uri.parent())\n\n    if (parentDeleted == null) {\n      return this.pflog().tap({\n        result: undefined,\n        msg: \"isDeleted(): parent().isDeleted was undefined\",\n        meta: { uri }\n      })\n    } else {\n      return this.pflog().tap({\n        result: true,\n        msg:\n          \"isDeleted(): parent was either deleted or not deleted, which means I am deleted.\",\n        meta: { parentDeleted, uri }\n      })\n    }\n  }\n\n  readonly etag = lazy(() =>\n    thenMap(this.stat(), s =>\n      [s.size, s.mtime.getTime()].map(n => Radix58.encode(n)).join(\"-\")\n    )\n  )\n\n  async httpHeaders(): Promise<StringValued> {\n    return {\n      ETag: await this.etag(),\n      \"Last-Modified\": await this.lastModifiedUtc()\n    }\n  }\n\n  async hide(): PromiseMaybe<this> {\n    const out = await (isWin\n      ? stdout(\"attrib\", [\"+h\", this.nativePath], {\n          timeout: 10 * secondMs\n        }).catch(err => err)\n      : isMac\n      ? stdout(\"chflags\", [\"hidden\", this.nativePath], {\n          timeout: 10 * secondMs\n        }).catch(err => err)\n      : \"\")\n    if (notBlank(out)) {\n      this.pflog().warn(\"hide(\" + this.nativePath + \") failed: \" + out)\n      return undefined\n    } else {\n      return this.clear()\n    }\n  }\n\n  /**\n   * Is the nearest directory hidden? (This lets us only check folders)\n   */\n  ignorableParent() {\n    return this.trapOr(\"ignorableParent\", () =>\n      this.nearestDir().then(d => d.ignorable())\n    )\n  }\n\n  /**\n   * @throws on error\n   */\n  async mkNoMedia_() {\n    if (await this.isFile()) {\n      throw new Error(\"mkNoMedia(): \" + this + \" is a file.\")\n    }\n    await this.mkdirp_() // < throws on error\n    const f = this.join(\".NoMedia\")\n    if ((await f.isNotDirectory()) && (await f.isEmpty())) {\n      await f.writeTxt_(\n        [\n          `This directory's contents are excluded from PhotoStructure libraries.`,\n          ``,\n          `See <https://photostructure.com/nomedia/> for details.`\n        ].join(\"\\n\")\n      )\n      emitFileChanged(this.nativePath)\n    }\n  }\n\n  /**\n   * @return this, not the .NoMedia file, so the method can be chained.\n   */\n\n  async mkNoMedia(): PromiseMaybe<this> {\n    try {\n      await this.mkNoMedia_()\n      return this\n    } catch (err) {\n      this.pflog().warn(\"Could not add .NoMedia file to \" + this, err)\n      return undefined\n    }\n  }\n\n  hasNoMedia(): PromiseMaybe<boolean> {\n    return hasNoMedia(this)\n  }\n\n  ignorableCheap() {\n    return ignorablePath(this.nativePath)\n  }\n\n  async ignorable() {\n    return (await this.isDirectory())\n      ? ignorableDirectory(this)\n      : ignorableFile(this)\n  }\n\n  hidden() {\n    return hidden(this)\n  }\n\n  readonly isMountpoint = lazy(\n    async () =>\n      (await this.isDirectory()) &&\n      (await thenMapOr(\n        mountpoints(),\n        arr => arr.includes(this.nativePath),\n        () => false\n      ))\n  )\n\n  isSidecar() {\n    return isSidecarExt(this.ext)\n  }\n\n  /**\n   * @return oldest sidecars first (so newest sidecar metadata wins, as they are\n   * layered on top of eachother)\n   */\n  readonly sidecars = lazy<Promise<this[]>>(async () => {\n    if (this.isSidecar()) return [] // < sidecars don't have sidecars\n    const arr = await this.parent().childDirectoryEntries(\n      ea =>\n        ea.base !== this.base &&\n        isSidecarExt(ea.ext) &&\n        (ea.name === this.name ||\n          ea.name === this.base ||\n          (Settings.matchSidecarsCaseInsensitively.valueOrDefault\n            ? equalsIgnoreCase(ea.name, this.name) ||\n              equalsIgnoreCase(ea.name, this.base)\n            : false) ||\n          nameWithoutCount(ea.name) === nameWithoutCount(this.name) ||\n          (Settings.matchSidecarsCaseInsensitively.valueOrDefault\n            ? equalsIgnoreCase(\n                nameWithoutCount(ea.name),\n                nameWithoutCount(this.name)\n              )\n            : false))\n    )\n\n    if (arr == null) return []\n    const posixFiles = arr.map(ea => this.parent()._directoryEntryChild(ea))\n    return sortByAsync(posixFiles, ea => ea.maxStatMs())\n  })\n\n  /**\n   * should only be used for writes\n   */\n  async sidecar() {\n    return thenOpt(this.sidecars())\n      .flatMap(arr => arr[arr.length - 1])\n      .getOrElse(() =>\n        this.sibling(\n          this.base +\n            ensurePrefix(\n              Settings.defaultSidecarType.valueOrDefault,\n              \".\"\n            ).toLowerCase()\n        )\n      )\n  }\n\n  // TODO: Add observer to fileSha()\n  readonly shaWithSidecars: MemoizedThunk<Promise<string>> = lazy(async () => {\n    const filenames = [this, ...(await this.sidecars())].map(\n      ea => ea.nativePath\n    )\n    const buffer = await fileSha(sort(filenames))\n    return buffer.toString(\"base64\")\n  }, BaseFile.attrTTL)\n\n  async jsonSidecars(): PromiseMaybe<this[]> {\n    // Try not to readdir if possible:\n    const results = await this.siblings(\n      ea =>\n        equalsIgnoreCase(ea.ext, \".json\") &&\n        (ea.name === this.name ||\n          ea.name === this.base ||\n          nameWithoutCount(ea.name) === nameWithoutCount(this.name))\n    )\n    return this.pflog().tap({\n      msg: \"jsonSidecars()\",\n      result:\n        results == null\n          ? undefined\n          : await sortByAsync(results, ea => ea.maxStatMs())\n    })\n  }\n\n  /**\n   * @return whatever was touched latest (this file or a sidecar)\n   */\n  thisOrSidecareMaxMtimeMs(): PromiseMaybe<number> {\n    return this.trap(\"mtimeOrSidecarMs\", async () => {\n      const thisMaxStatMs = await this.mtimeMs()\n      const sidecars = await this.sidecars()\n      const sidecarMaxStats = await Promise.all(\n        toA(sidecars).map(ea => ea.mtimeMs())\n      )\n      const arr = [thisMaxStatMs, ...sidecarMaxStats].filter(gt0)\n      return mapNotEmpty(arr, ea => Math.floor(Math.max(...ea)))\n    })\n  }\n\n  thisOrSidecareMaxMtimeSec(): PromiseMaybe<number> {\n    return thenMap(this.thisOrSidecareMaxMtimeMs(), ea => unixtime(ea))\n  }\n}\n", "import { compact } from \"../../fe/Array\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, mapOr } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { strEnum, StrEnumKeys } from \"../../fe/StrEnum\"\nimport { toS } from \"../../fe/toS\"\nimport { MultiMap } from \"../MultiMap\"\nimport { SidecarExts } from \"./SidecarExts\"\n\n// All file types from https://exiftool.org/#supported\n// that don't have a \"-\" in the EXIF column, as well as the PGM/PPM/PBM formats\n\n// 1. Used firefox to pull out table\n// 2. replace /^([^\\t]+)\\t.*?\\t(.+)$/ with `[[\"$1\"],  \"$2\"],`\n// 3. replace /, ([^ ])/ with `\", \"$1`\n\n// TODO: These descriptions will be used in the details pane at some point\n\n// Note that if I don't have an example image, I'm commenting out support (in an\n// effort to be conservative with what we advertise support for)\n\nexport const fileExtsToDesc = [\n  [[\"360\"], \"GoPro 360 video (QuickTime-based)\"],\n  [[\"3FR\"], \"Hasselblad RAW (TIFF-based)\"],\n  [[\"3G2\", \"3GP2\"], \"3rd Gen. Partnership Project 2 a/v (QuickTime-based)\"],\n  [[\"3GP\", \"3GPP\"], \"3rd Gen. Partnership Project a/v (QuickTime-based)\"],\n  // [[\"A\"], \"Unix static library code Archive\"],\n  // [[\"AA\"], \"Audible Audiobook\"],\n  // [[\"AAE\"], \"Apple edit information (XML PLIST-based)\"],\n  // [[\"AAX\"], \"Audible Enhanced Audiobook (QuickTime-based)\"],\n  // [[\"ACR\"], \"American College of Radiology ACR-NEMA (DICOM-like)\"],\n  // [[\"AFM\", \"ACFM\", \"AMFM\"], \"Adobe [Composite/Multiple Master] Font Metrics\"],\n  // [[\"AI\", \"AIT\"], \"Adobe Illustrator [Template] (PS or PDF)\"],\n  // [[\"AIFF\", \"AIF\", \"AIFC\"], \"Audio Interchange File Format [Compressed]\"],\n  // [[\"APE\"], \"Monkey's Audio\"],\n  [[\"ARQ\"], \"Sony Alpha Pixel-Shift RAW (TIFF-based)\"],\n  [[\"ARW\"], \"Sony Alpha RAW (TIFF-based)\"],\n  [[\"ASF\"], \"Microsoft Advanced Systems Format\"],\n  [[\"AVI\"], \"Audio Video Interleaved (RIFF-based)\"],\n  [[\"AVIF\"], \"AV1 Image File Format (QuickTime-based)\"],\n  // [[\"BMP\", \"DIB\"], \"Windows BitMaP / Device Independent Bitmap\"],\n  // [[\"BPG\"], \"Better Portable Graphics\"],\n  // [[\"BTF\"], \"BigTIFF (64-bit Tagged Image File Format)\"],\n  // [[\"CHM\"], \"Microsoft Compiled HTML format\"],\n  // [[\"COS\"], \"Capture One Settings (XML-based)\"],\n  [[\"CR2\"], \"Canon RAW 2 (TIFF-based) (CR2 spec)\"],\n  [[\"CR3\"], \"Canon RAW 3 (QuickTime-based) (CR3 spec)\"],\n  [[\"CRM\"], \"Canon RAW Movie (QuickTime-based)\"],\n  [[\"CRW\", \"CIFF\"], \"Canon RAW Camera Image File Format (CRW spec)\"],\n  // [[\"CS1\"], \"Sinar CaptureShop 1-shot RAW (PSD-based)\"],\n  // [[\"CSV\"], \"Comma-Separated Values\"],\n  [[\"CZI\"], \"Zeiss Integrated Software RAW (ZISRAW)\"],\n  // [\n  //   [\"DCM\", \"DC3\", \"DIC\", \"DICM\"],\n  //   \"DICOM - Digital Imaging and Communications in Medicine\"\n  // ],\n  [[\"DCP\"], \"DNG Camera Profile (DNG-like)\"],\n  [[\"DCR\"], \"Kodak Digital Camera RAW (TIFF-based)\"],\n  // [[\"DFONT\"], \"Macintosh Data Fork Font\"],\n  // [[\"DIVX\"], \"DivX media format (ASF-based)\"],\n  // [[\"DJVU\", \"DJV\"], \"DjVu image (AIFF-like)\"],\n  [[\"DNG\"], \"Digital Negative (TIFF-based)\"],\n  // [[\"DOC\", \"DOT\"], \"Microsoft Word Document/Template (FPX-like)\"],\n  // [[\"DOCX\", \"DOCM\"], \"Office Open XML Document [Macro-enabled]\"],\n  // [[\"DOTX\", \"DOTM\"], \"Office Open XML Document Template [Macro-enabled]\"],\n  // [[\"DPX\"], \"Digital Picture Exchange\"],\n  // [[\"DR4\"], \"Canon DPP version 4 Recipe\"],\n  // [[\"DSS\", \"DS2\"], \"Digital Speech Standard [2]\"],\n  // [[\"DYLIB\"], \"MacOS Mach-O executable and library files\"],\n  [[\"DV\"], \"Digital Video\"],\n  // [[\"DVB\"], \"Digital Video Broadcasting (QuickTime-based)\"],\n  // [[\"DVR-MS\"], \"Microsoft Digital Video Recording (ASF-based)\"],\n  // [[\"EIP\"], \"Capture One Enhanced Image Package (ZIP-based)\"],\n  // [[\"EPS\", \"EPSF\", \"PS\"], \"[Encapsulated] PostScript Format\"],\n  // [[\"EPUB\"], \"Electronic Publication (ZIP/XML-based)\"],\n  [[\"ERF\"], \"Epson RAW Format (TIFF-based)\"],\n  // [[\"EXE\", \"DLL\"], \"DOS/Windows executable and library files\"],\n  [[\"EXIF\"], \"Exchangeable Image File Format metadata (TIFF-based)\"],\n  // [[\"EXR\"], \"Open EXR (Extended Range)\"],\n  [[\"EXV\"], \"Exiv2 metadata file (JPEG-based)\"],\n  // [\n  //   [\"F4A\", \"F4B\", \"F4P\", \"F4V\"],\n  //   \"Adobe Flash Player 9+ Audio/Video (QuickTime-based)\"\n  // ],\n  [[\"FFF\"], \"Hasselblad Flexible File Format (TIFF-based)\"],\n  [[\"FFF\"], \"FLIR Systems thermal image File Format\"],\n  // [[\"FITS\"], \"Flexible Image Transport System\"],\n  // [[\"FLA\"], \"Macromedia/Adobe Flash project (FPX-like)\"],\n  // [[\"FLAC\"], \"Free Lossless Audio Codec\"],\n  // [[\"FLIF\"], \"Free Lossless Image Format\"],\n  // [[\"FLV\"], \"Flash Video\"],\n  // [[\"FPF\"], \"FLIR Public image Format\"],\n  // [[\"FPX\"], \"FlashPix image\"],\n  [[\"GIF\"], \"Compuserve Graphics Interchange Format\"],\n  [[\"GPR\"], \"GoPro RAW (DNG-based)\"],\n  // [[\"GZ\", \"GZIP\"], \"GNU ZIP compressed archive\"],\n  [\n    [\"HDP\", \"WDP\", \"JXR\"],\n    \"Windows HD Photo / Media Photo / JPEG XR (TIFF-based)\"\n  ],\n  [[\"HDR\"], \"Radiance RGBE High Dynamic-Range\"],\n  [[\"HEIC\", \"HEIF\", \"HIF\"], \"High Efficiency Image Format (QuickTime-based)\"],\n  // [[\"HTML\", \"HTM\", \"XHTML\"], \"[Extensible] HyperText Markup Language\"],\n  // [[\"ICC\", \"ICM\"], \"International Color Consortium color profile\"],\n  // [[\"ICS\", \"ICAL\"], \"iCalendar Schedule\"],\n  // [[\"IDML\"], \"Adobe InDesign Markup Language (ZIP/XML-based)\"],\n  [[\"IIQ\"], \"Phase One Intelligent Image Quality RAW (TIFF-based)\"],\n  // [[\"IND\", \"INDD\", \"INDT\"], \"Adobe InDesign Document/Template\"],\n  [[\"INSP\"], \"Insta360 Picture (JPEG-based)\"],\n  [[\"INSV\"], \"Insta360 Video (QuickTime-based)\"],\n  // [[\"INX\"], \"Adobe InDesign Interchange (XML-based)\"],\n  // [[\"ISO\"], \"ISO 9660 disk image\"],\n  // [[\"ITC\"], \"iTunes Cover Flow artwork\"],\n  [[\"J2C\", \"J2K\", \"JPC\"], \"JPEG 2000 codestream\"],\n  [[\"JP2\", \"JPF\", \"JPM\", \"JPX\"], \"JPEG 2000 image [Compound/Extended]\"],\n  [[\"JPEG\", \"JPG\", \"JPE\"], \"Joint Photographic Experts Group image\"],\n  // [[\"JSON\"], \"JavaScript Object Notation\"],\n  // [[\"K25\"], \"Kodak DC25 RAW (TIFF-based)\"],\n  // [[\"KDC\"], \"Kodak Digital Camera RAW (TIFF-based)\"],\n  // [[\"KEY\", \"KTH\"], \"Apple iWork '09 Keynote presentation/Theme\"],\n  // [[\"LA\"], \"Lossless Audio (RIFF-based)\"],\n  // [[\"LFP\", \"LFR\"], \"Lytro Light Field Picture\"],\n  // [[\"LNK\"], \"Microsoft Shell Link (Windows shortcut)\"],\n  // [[\"LRV\"], \"Low-Resolution Video (QuickTime-based)\"],\n  [\n    [\"M2TS\", \"MTS\", \"M2T\" /* \"TS\" */], // skip .ts files\n    \"MPEG-2 Transport Stream (used for AVCHD video)\"\n  ],\n  [[\"M4A\", \"M4B\", \"M4P\", \"M4V\"], \"MPEG-4 Audio/Video (QuickTime-based)\"],\n  // [[\"MACOS\"], \"MacOS ._ sidecar file (may have any extension)\"],\n  // [[\"MAX\"], \"3D Studio MAX (FPX-like)\"],\n  [[\"MEF\"], \"Mamiya (RAW) Electronic Format (TIFF-based)\"],\n  [[\"MIE\"], \"Meta Information Encapsulation (MIE specification)\"],\n  // [[\"MIFF\", \"MIF\"], \"Magick Image File Format\"],\n  // [[\"MKA\", \"MKV\", \"MKS\"], \"Matroska Audio/Video/Subtitle\"],\n  // [[\"MOBI\", \"AZW\", \"AZW3\"], \"Mobipocket electronic book (Palm-based)\"],\n  // [[\"MODD\"], \"Sony Picture Motion metadata (XML PLIST-based)\"],\n  // [[\"MOI\"], \"MOD Information file\"],\n  // [[\"MOS\"], \"Creo Leaf Mosaic (TIFF-based)\"],\n  [[\"MOV\", \"QT\"], \"Apple QuickTime Movie\"],\n  // [[\"MP3\"], \"MPEG-1 layer 3 audio\"],\n  [[\"MP4\"], \"Motion Picture Experts Group version 4 (QuickTime-based)\"],\n  // [[\"MPC\"], \"Musepack Audio\"],\n  [[\"MPEG\", \"MPG\", \"M2V\"], \"Motion Picture Experts Group version 1 or 2\"],\n  // [[\"MPO\"], \"Extended Multi-Picture format (JPEG with MPF extensions)\"],\n  [[\"MQV\"], \"Sony Mobile QuickTime Video\"],\n  [[\"MRW\"], \"Minolta RAW\"],\n  // [[\"MXF\"], \"Material Exchange Format\"],\n  [[\"NEF\"], \"Nikon (RAW) Electronic Format (TIFF-based)\"],\n  // [[\"NMBTEMPLATE\"], \"Apple iWork '09 Numbers Template\"],\n  [[\"NRW\"], \"Nikon RAW (2) (TIFF-based)\"],\n  // [[\"NUMBERS\"], \"Apple iWork '09 Numbers spreadsheet\"],\n  // [[\"O\"], \"Unix compiled code Object\"],\n  // [\n  //   [\"ODB\", \"ODC\", \"ODF\", \"ODG\", \"ODI\", \"ODP\", \"ODS\", \"ODT\"],\n  //   \"Open Document Database/Chart/Formula/Graphics/Image/Presentation/Spreadsheet/Text (ZIP/XML-based)\"\n  // ],\n  // [[\"OFR\"], \"OptimFROG audio (RIFF-based)\"],\n  // [[\"OGG\", \"OGV\"], \"Ogg bitstream container\"],\n  // [[\"ONP\"], \"ON1 Presets\"],\n  // [[\"OPUS\"], \"Ogg Opus audio\"],\n  [[\"ORF\"], \"Olympus RAW Format (TIFF-based)\"],\n  // [[\"OTF\"], \"Open Type Font\"],\n  // [[\"PAC\"], \"Lossless Predictive Audio Compression (RIFF-based)\"],\n  // [[\"PAGES\"], \"Apple iWork '09 Pages document\"],\n  // [[\"PCD\"], \"Kodak Photo CD Image Pac\"],\n  // [[\"PCX\"], \"PC Paintbrush\"],\n  // [[\"PDB\", \"PRC\"], \"Palm Database\"],\n  // [[\"PDF\"], \"Adobe Portable Document Format\"],\n  [[\"PEF\"], \"Pentax (RAW) Electronic Format (TIFF-based)\"],\n  // [[\"PFA\", \"PFB\"], \"PostScript Font ASCII/Binary\"],\n  // [[\"PFM\"], \"Printer Font Metrics\"],\n  // [[\"PGF\"], \"Progressive Graphics File\"],\n  // [[\"PICT\", \"PCT\"], \"Apple Picture file\"],\n  // [[\"PLIST\"], \"Apple Property List (binary and XML formats)\"],\n  // [[\"PMP\"], \"Sony DSC-F1 Cyber-Shot image\"],\n  [[\"PNG\", \"JNG\", \"MNG\"], \"Portable/JPEG/Multiple-image Network Graphics\"],\n  [[\"PPM\", \"PBM\", \"PGM\"], \"Portable Pixel/Bit/Gray Map\"],\n  // [\n  //   [\"PPT\", \"PPS\", \"POT\"],\n  //   \"PowerPoint Presentation/Slideshow/Template (FPX-like)\"\n  // ],\n  // [[\"POTX\", \"POTM\"], \"Office Open XML Presentation Template [Macro-enabled]\"],\n  // [[\"PPAX\", \"PPAM\"], \"Office Open XML Presentation Addin [Macro-enabled]\"],\n  // [[\"PPSX\", \"PPSM\"], \"Office Open XML Presentation Slideshow [Macro-enabled]\"],\n  // [[\"PPTX\", \"PPTM\"], \"Office Open XML Presentation [Macro-enabled]\"],\n  // [[\"PSD\", \"PSB\", \"PSDT\"], \"PhotoShop Document / Large Document / Template\"],\n  // [[\"PSP\", \"PSPIMAGE\"], \"Paint Shop Pro\"],\n  // [[\"QTIF\", \"QTI\", \"QIF\"], \"QuickTime Image File\"],\n  // [[\"R3D\"], \"Redcode RAW video\"],\n  // [[\"RA\"], \"Real Audio\"],\n  [[\"RAF\"], \"FujiFilm RAW Format\"],\n  // [[\"RAM\", \"RPM\"], \"Real Audio/Plug-in Metafile\"],\n  // [[\"RAR\"], \"RAR Archive\"],\n  [[\"RAW\"], \"Kyocera Contax N Digital RAW\"],\n  [[\"RAW\"], \"Panasonic RAW (TIFF-based)\"],\n  // [[\"RIFF\", \"RIF\"], \"Resource Interchange File Format\"],\n  // [[\"RM\", \"RV\", \"RMVB\"], \"Real Media/Video [Variable Bitrate]\"],\n  // [[\"RSRC\"], \"Mac OS Resource\"],\n  // [[\"RTF\"], \"Rich Text Format\"],\n  [[\"RW2\"], \"Panasonic RAW 2 (TIFF-based)\"],\n  [[\"RWL\"], \"Leica RAW (TIFF-based)\"],\n  // [[\"RWZ\"], \"Rawzor compressed image\"],\n  // [[\"SEQ\"], \"FLIR Systems image Sequence\"],\n  // [[\"SKETCH\"], \"Sketch design file\"],\n  // [[\"SO\"], \"Unix ELF executable and Shared Object files\"],\n  [[\"SR2\"], \"Sony RAW 2 (TIFF-based)\"],\n  [[\"SRF\"], \"Sony RAW Format (TIFF-based)\"],\n  [[\"SRW\"], \"Samsung RAW format (TIFF-based)\"],\n  // [[\"SVG\"], \"Scalable Vector Graphics (XML-based)\"],\n  // [[\"SWF\"], \"Shockwave Flash\"],\n  // [[\"THM\"], \"Thumbnail image (JPEG)\"], // don't need to import these.\n  // [[\"THMX\"], \"Office Open XML Theme\"],\n  [[\"TIFF\", \"TIF\"], \"Tagged Image File Format\"],\n  // [[\"TTF\", \"TTC\"], \"True Type Font/Collection\"],\n  // [[\"TORRENT\"], \"BitTorrent description file\"],\n  // [[\"TXT\"], \"Text files\"],\n  // [[\"VCF\", \"VCARD\"], \"Virtual Card\"],\n  // [[\"VOB\"], \"Video Object (MPEG-based)\"],\n  // [[\"VRD\"], \"Canon DPP Recipe Data\"],\n  // [[\"VSD\"], \"Microsoft Visio Drawing (FPX-like)\"],\n  // [[\"WAV\"], \"Windows digital audio WAVeform (RIFF-based)\"],\n  [[\"WEBM\"], \"Google Web Movie (Matroska-based)\"],\n  [[\"WEBP\"], \"Google Web Picture (RIFF-based)\"],\n  [[/*\"WMA\",*/ \"WMV\"], \"Windows Media Audio/Video (ASF-based)\"], // skipping WMA: no audio\n  // [[\"WTV\"], \"Windows recorded TV show\"],\n  // [[\"WV\"], \"WavePack lossless audio (RIFF-based)\"],\n  [[\"X3F\"], \"Sigma/Foveon RAW\"],\n  // [[\"XCF\"], \"GIMP native image format\"],\n  // [[\"XLS\", \"XLT\"], \"Microsoft Excel Spreadsheet/Template (FPX-like)\"],\n  // [\n  //   [\"XLSX\", \"XLSM\", \"XLSB\"],\n  //   \"Office Open XML Spreadsheet [Macro-enabled/Binary]\"\n  // ],\n  // [[\"XLTX\", \"XLTM\"], \"Office Open XML Spreadsheet Template [Macro-enabled]\"],\n  [[\"XMP\"], \"Extensible Metadata Platform sidecar file\"]\n  // [[\"ZIP\"], \"ZIP archive\"]\n] as [string[], string][]\n\nexport const ExtTypes = strEnum(\n  \"RawImage\",\n  \"Sharp\",\n  \"Video\",\n  \"Sidecar\",\n  \"AssetFile\",\n  \"Exif\",\n  \"SupportedByCurrentBrowser\",\n  \"SupportedByOldBrowser\"\n)\n\nexport type ExtType = StrEnumKeys<typeof ExtTypes>\n\nconst ext2types = lazy(() => {\n  const m = new MultiMap<string, ExtType>()\n\n  // First add all base types:\n\n  const RawImageExts = [\n    \"ARQ\",\n    \"ARW\",\n    \"CR2\",\n    \"CR3\",\n    \"CRW\",\n    \"DNG\",\n    \"GPR\",\n    \"MEF\",\n    \"MRW\",\n    \"NEF\",\n    \"NRW\",\n    \"ORF\",\n    \"RAF\",\n    \"RAW\",\n    \"RW2\",\n    \"RWL\",\n    \"SR2\",\n    \"SRF\",\n    \"SRW\"\n  ]\n  for (const ext of RawImageExts) {\n    m.add(ext, ExtTypes.RawImage)\n  }\n\n  const SharpExts = compact([\"GIF\", \"JPEG\", \"PNG\", \"PPM\", \"TIFF\", \"WEBP\"])\n\n  for (const ext of SharpExts) {\n    m.add(ext, ExtTypes.Sharp)\n  }\n\n  const VideoExts = [\n    \"3G2\",\n    \"3GP\",\n    \"ASF\",\n    \"AVI\",\n    \"CRM\",\n    \"M4A\",\n    \"MOV\",\n    \"MP4\",\n    \"MPEG\",\n    \"MQV\",\n    \"MTS\",\n    \"WEBM\",\n    \"WMV\"\n  ]\n  for (const ext of VideoExts) {\n    m.add(ext, ExtTypes.Video)\n  }\n\n  const AssetFileExts = [...SharpExts, \"HEIC\", ...RawImageExts, ...VideoExts]\n\n  for (const ext of AssetFileExts) {\n    m.add(ext, ExtTypes.AssetFile)\n  }\n\n  for (const ext of SidecarExts) {\n    m.add(ext, ExtTypes.Sidecar)\n  }\n\n  for (const ext of [...AssetFileExts, ...SidecarExts]) {\n    m.add(ext, ExtTypes.Exif)\n  }\n\n  for (const ext of [\"GIF\", \"JPEG\", \"MP4\", \"PNG\", \"WEBM\", \"WEBP\"]) {\n    m.add(ext, ExtTypes.SupportedByCurrentBrowser)\n  }\n\n  for (const ext of [\"GIF\", \"JPEG\", \"MP4\", \"PNG\"]) {\n    m.add(ext, ExtTypes.SupportedByOldBrowser)\n  }\n\n  // Then expand with extension \"synonyms\"\n  const exts = fileExtsToDesc.map(ea => ea[0])\n\n  for (const ext of m.keys()) {\n    const aliases = exts.find(ea => ea.includes(ext))\n    if (aliases != null && aliases.length > 0) {\n      const values = m.get(ext)!\n      for (const alias of aliases) {\n        if (!m.has(alias)) {\n          m.set(alias, values)\n        }\n      }\n    }\n  }\n\n  return m\n})\n\nexport function extTypes(ext: Maybe<string>): Maybe<ExtType[]> {\n  return map(normalizeExt(ext), ea => ext2types().get(ea))\n}\n\nconst shortExtRe = /\\.?([a-z0-9]{2,4})$/i\n\nexport function normalizeExt(ext: Maybe<string>): Maybe<string> {\n  return map(shortExtRe.exec(toS(ext)), m => m[1].toUpperCase())\n}\n\nexport function isExtType(ext: Maybe<string>, extType: ExtType) {\n  return mapOr(\n    extTypes(ext),\n    ea => ea.includes(extType),\n    () => false\n  )\n}\n\nexport function mimeRootType(\n  ext: Maybe<string>\n): undefined | \"image\" | \"video\" {\n  const arr = extTypes(ext)\n  return arr == null\n    ? undefined\n    : arr.includes(ExtTypes.Sharp) || arr.includes(ExtTypes.RawImage)\n    ? \"image\"\n    : arr.includes(ExtTypes.Video)\n    ? \"video\"\n    : undefined\n}\n\nexport function isRawImageExt(ext: Maybe<string>): boolean {\n  return isExtType(ext, ExtTypes.RawImage)\n}\nexport function isSharpExt(ext: Maybe<string>): boolean {\n  return isExtType(ext, ExtTypes.Sharp)\n}\nexport function isVideoExt(ext: Maybe<string>): boolean {\n  return isExtType(ext, ExtTypes.Video)\n}\nexport function isSidecarExt(ext: Maybe<string>): boolean {\n  return isExtType(ext, ExtTypes.Sidecar)\n}\nexport function isAssetFileExt(ext: Maybe<string>): boolean {\n  return isExtType(ext, ExtTypes.AssetFile)\n}\nexport function isExifExt(ext: Maybe<string>): boolean {\n  return isExtType(ext, ExtTypes.Exif)\n}\nexport function isSupportedByCurrentBrowserExt(ext: Maybe<string>): boolean {\n  return isExtType(ext, ExtTypes.SupportedByCurrentBrowser)\n}\nexport function isSupportedByOldBrowserExt(ext: Maybe<string>): boolean {\n  return isExtType(ext, ExtTypes.SupportedByOldBrowser)\n}\n", "import { isEmpty } from \"./Array\"\nimport { entries, Valued } from \"./Object\"\nimport { PrimitiveValued } from \"./Primitive\"\nimport { toS } from \"./toS\"\n\nexport function assembleUri(\n  path: string,\n  query: Valued<string | (string | null)[]>\n): string {\n  const q = joinQuery(query)\n  return q === \"\" ? path : path + \"?\" + q\n}\n\nexport function joinQuery(\n  query: PrimitiveValued | Valued<string | (string | null)[]>\n) {\n  if (query == null) return \"\"\n  const e = entries(query).filter(([, v]) => v != null)\n  if (isEmpty(e)) return \"\"\n  return e.map(ea => ea.map(toS).map(encodeURIComponent).join(\"=\")).join(\"&\")\n}\n\n// Note that \"pslib\" is not a schema that is registered by IANA, but it doesn't\n// collide with anything there, so we should be fine. See\n// https://www.iana.org/assignments/uri-schemes/uri-schemes.xhtml\n\n// Node URL parsing uses \"protocol\" instead of \"scheme\", and protocol is always\n// suffixed with a colon.\n\n/**\n * URI scheme used for asset files found in the PhotoStructure Library directory\n * hierarchy\n */\nexport const PS_LIBRARY_PROTOCOL = \"pslib\"\n\n/**\n * URI scheme used for asset files found on a local disk volume\n */\nexport const PS_LOCAL_FILE_PROTOCOL = \"psfile\"\n\n/**\n * URI scheme used for asset files found on a network filesystem\n */\nexport const PS_NETWORK_FILESYSTEM_PROTOCOL = \"psnet\"\n", "import { promises as dns } from \"dns\"\nimport { blank, notBlank } from \"../../fe/Blank\"\nimport { minuteMs, secondMs } from \"../../fe/Date\"\nimport { later } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { toInt } from \"../../fe/Number\"\nimport { toS } from \"../../fe/toS\"\nimport { memoizeAsync } from \"../async/MemoizedAsyncFunc\"\nimport { thenMap2Or } from \"../async/Promise\"\nimport { thenOrTimeout } from \"../async/thenOrTimeout\"\nimport { onClearCache } from \"../event/EventEmitter\"\nimport { mkLogger } from \"../Logger\"\nimport { within } from \"../Number\"\nimport { equalsIgnoreCase } from \"../String\"\nimport { ShortCmdTimeoutMs } from \"../volumes/VolumeTtls\"\nimport { ipv4Re } from \"./ping\"\n\nconst octetRE = new RegExp(\"^\" + ipv4Re.source + \"$\")\n\n/**\n * Try to return the \"canonical\" name for the given `ipOrName`.\n */\nexport const friendlyname = memoizeAsync(\n  async (ipOrName: string) => {\n    const result =\n      octetRE.exec(ipOrName) == null ? ipOrName : await nslookup(ipOrName)\n    return toS(result).toLowerCase().normalize()\n  },\n  { maxSize: 128, timeoutMs: ShortCmdTimeoutMs }\n)\n\nconst loopbackRE = /^(?:(?:localhost(?:\\.?(?:localdomain\\.?)?))|(?:127(?:\\.\\d{1,3}){3}))$/i\n\nexport function isLoopback(name: string): boolean {\n  return loopbackRE.exec(name) != null\n}\n\nexport function octets(nameOrIp: string): Maybe<number[]> {\n  const result: number[] = nameOrIp\n    .split(\".\")\n    .map(ea => toInt(ea))\n    .filter(ea => within(0, 255, ea)) as number[]\n  return result.length === 4 ? result : undefined\n}\n\n/**\n * @return 1 or more IPv4 addresses for the given name or IP address\n */\nexport const resolve4 = memoizeAsync(\n  async (nameOrIp: string): PromiseMaybe<string[]> => {\n    if (blank(nameOrIp)) return\n    if (octets(nameOrIp) != null) return [nameOrIp]\n    try {\n      return await dns.resolve4(nameOrIp)\n    } catch (err) {\n      logger().warn(\"No name found for \" + nameOrIp)\n      return\n    }\n  },\n  { maxSize: 256, timeoutMs: ShortCmdTimeoutMs, clearEveryMs: 10 * minuteMs }\n)\n\nconst logger = lazy(() => mkLogger(\"nslookup\"))\n\nlater(() => onClearCache(() => nslookup.clear()))\n\n/**\n * @return the name or IP address\n */\nexport const nslookup = memoizeAsync(\n  async (nameOrIp: string) => {\n    try {\n      const names = await thenOrTimeout(\n        () =>\n          isLoopback(nameOrIp)\n            ? nameOrIp.startsWith(\"127.\")\n              ? [\"localhost\"]\n              : [\"127.0.0.1\"]\n            : octets(nameOrIp) != null\n            ? dns.reverse(nameOrIp)\n            : dns.resolve4(nameOrIp),\n        5 * secondMs // < DNS resolution should be milliseconds.\n      )\n      if (names == null) {\n        logger().info(\"nslookup(\" + nameOrIp + \"): timeout\")\n        return nameOrIp\n      }\n      const firstNonBlank = names.find(notBlank)\n      if (firstNonBlank == null) {\n        logger().warn(\"No name found for \" + nameOrIp)\n        return nameOrIp\n      } else {\n        return firstNonBlank\n      }\n    } catch (err) {\n      logger().warn(\"Failed to look up \" + nameOrIp + \", using name.\", err)\n      return nameOrIp\n    }\n  },\n  { maxSize: 256, timeoutMs: ShortCmdTimeoutMs, clearEveryMs: 10 * minuteMs }\n)\n\nexport async function isEquivalentHost(\n  a: Maybe<string>,\n  b: Maybe<string>\n): Promise<boolean> {\n  if (blank(a) || blank(b)) return false\n  if (equalsIgnoreCase(a, b)) return true\n  if (isLoopback(a) && isLoopback(b)) return true\n  return thenMap2Or(\n    resolve4(a),\n    resolve4(b),\n    (aAddrs, bAddrs) => aAddrs.some(ea => bAddrs.includes(ea)),\n    () => false\n  )\n}\n", "import { stringify } from \"../../fe/JSON\"\nimport { SyncOrAsync } from \"../../fe/OptAsync\"\nimport { FifoCacheAsync } from \"../FifoCache\"\n\nexport interface MemoizedAsyncFunc<A, R> {\n  (a: A): Promise<R>\n  clear(a?: A): void\n  size(): number\n  callCount(): number\n}\n\nexport function memoizeAsync<A, R>(\n  f: (a: A) => SyncOrAsync<R>,\n  opts: { maxSize: number; timeoutMs: number; clearEveryMs?: number }\n): MemoizedAsyncFunc<A, R> {\n  let callCount = 0\n  const store = new FifoCacheAsync<R>(opts)\n  const r: any = (a: A) => {\n    callCount++\n    return store.getOrSetAsync(stringify(a), async () => f(a))\n  }\n  r.clear = (a?: A) => {\n    if (a == null) {\n      store.clear()\n    } else {\n      const aKey = stringify(a)\n      store.deleteIf(ea => aKey === ea)\n    }\n  }\n  r.size = () => store.size\n  r.callCount = () => callCount\n  return r\n}\n", "import { notBlank } from \"../../fe/Blank\"\nimport { minuteMs, secondMs } from \"../../fe/Date\"\nimport { times } from \"../../fe/Number\"\nimport { opt } from \"../../fe/Opt\"\nimport { toS } from \"../../fe/toS\"\nimport { memoizeAsync } from \"../async/MemoizedAsyncFunc\"\nimport { stdout } from \"../child/ChildProcess\"\nimport { pingWin } from \"../fs/PathTo\"\nimport { isWin } from \"../Platform\"\nimport { ShortCmdTimeoutMs } from \"../volumes/VolumeTtls\"\n\nexport const ping = memoizeAsync(\n  async (target: string) => {\n    const cmd = isWin ? await pingWin() : \"ping\"\n    return stdout(cmd, [isWin ? \"-n\" : \"-c\", \"1\", target], {\n      timeout: 5 * secondMs\n    })\n  },\n  { maxSize: 255, timeoutMs: ShortCmdTimeoutMs, clearEveryMs: 10 * minuteMs }\n)\n\nexport const ipv4Re = new RegExp(\n  \"\\\\b\" + times(4, () => \"[0-9]{1,3}\").join(\"\\\\.\") + \"\\\\b\"\n)\n\nexport const ipAddrFromPing = memoizeAsync(\n  async (target: string) => {\n    return opt(\n      await ping(target).catch(err => {\n        console.warn(\"failed to ping: \" + err)\n        return undefined\n      })\n    )\n      .filter(notBlank)\n      .flatMap(result => ipv4Re.exec(toS(result)))\n      .map(match => match[0])\n      .get()\n  },\n  { maxSize: 255, timeoutMs: ShortCmdTimeoutMs, clearEveryMs: 10 * minuteMs }\n)\n", "import { compact } from \"../../fe/Array\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map } from \"../../fe/Maybe\"\nimport { filterAsync, thenMapOr } from \"../async/Promise\"\nimport { stdout } from \"../child/ChildProcess\"\nimport { eql } from \"../Eql\"\nimport { BaseFile } from \"../fs/BaseFile\"\nimport { CmdTimeoutMs, MountpointsTtlMs } from \"./VolumeTtls\"\n\n// /dev/disk1s1 on / (apfs, local, journaled)\nconst parseRe = /^([a-z0-9/ -_]+) on (.+?) \\((.+)\\)$/i\n\nexport interface Mount {\n  filesystem: string\n  mountpoint: string\n  options: string[]\n}\nexport async function mounts() {\n  const _mounts = await stdout(\"mount\", [], { timeout: CmdTimeoutMs })\n  return compact(\n    _mounts.split(\"\\n\").map(ea => {\n      return map(parseRe.exec(ea), m => {\n        const [filesystem, mountpoint, opts] = m.slice(1)\n        const options = opts.split(\",\").map(opt => opt.trim())\n        return {\n          filesystem,\n          mountpoint,\n          options\n        }\n      })\n    })\n  )\n}\n\nexport const ignorableMacFilesystems = lazy(async () => {\n  return filterAsync(await mounts(), async m => {\n    return (\n      m.options.includes(\"nobrowse\") ||\n      m.options.includes(\"quarantine\") ||\n      (await isInstallDmg(m.mountpoint))\n    )\n  }).then(arr => arr.map(ea => ea.filesystem))\n}, MountpointsTtlMs)\n\nexport async function isInstallDmg(mountpoint: string) {\n  const f = BaseFile.for(mountpoint)\n  const names = await thenMapOr(\n    await f.childNames(),\n    arr =>\n      arr\n        .filter(ea => !ea.startsWith(\".\"))\n        .map(ea => ea.toLowerCase())\n        .sort(),\n    () => []\n  )\n  return eql(names, [\"applications\", \"photostructure.app\"])\n}\n", "import { notBlank } from \"../../fe/Blank\"\nimport { toInt } from \"../../fe/Number\"\nimport { toS } from \"../../fe/toS\"\nimport { stdout } from \"../child/ChildProcess\"\nimport { parseFixed } from \"../Fixed\"\nimport { isMac } from \"../Platform\"\nimport { ignorableMacFilesystems } from \"./Mount\"\nimport { DfVolume } from \"./Volume\"\nimport { CmdTimeoutMs } from \"./VolumeTtls\"\n\nfunction k2b(s: string): number {\n  return toInt(s, { defaultValue: 0 })! * 1024\n}\n\nconst ignorableMacFsTypes = [\"devfs\"]\n// NOTE: DO NOT EXCLUDE \"/dev/mapper/ubuntu--vg-root\", that may be the root (and\n// only!) filesystem\n// TODO: is it bad to include tmpfs?\nconst ignorableLinuxFsTypes = [\"udev\", \"tmpfs\", \"devtmpfs\", \"shm\"]\nconst ignorableFsTypes = isMac ? ignorableMacFsTypes : ignorableLinuxFsTypes\n\nconst ignorableMountpoints = [\"/boot/efi\", \"/dev/shm\"]\n\nexport async function dfPosixRaw(\n  localsOnly: boolean,\n  path?: string\n): Promise<DfVolume[]> {\n  const ignoreFs = isMac ? await ignorableMacFilesystems() : []\n  const args = [\"-k\", \"-P\"]\n  if (localsOnly) args.push(\"-l\")\n  if (notBlank(path)) args.push(path)\n  const output = await stdout(\"df\", args, {\n    timeout: CmdTimeoutMs,\n    // https://askubuntu.com/questions/1227667/df-command-throws-error-on-run-user-1000-doc-folder\n    ignoreStderr: true,\n    ignoreExitCode: true\n  })\n  const parsed = parseFixed(\n    [\n      \"Filesystem\",\n      \"1024-blocks\",\n      \"Used\",\n      \"Available\",\n      \"Capacity\",\n      \"Mounted on\"\n    ],\n    output\n  )\n  return parsed\n    .map(ea => ({\n      filesystem: ea[\"Filesystem\"],\n      size: k2b(ea[\"1024-blocks\"]),\n      used: k2b(ea[\"Used\"]),\n      available: k2b(ea[\"Available\"]),\n      mountpoint: ea[\"Mounted on\"]\n    }))\n    .filter(ea => {\n      const fs = toS(ea.filesystem)\n      const mp = toS(ea.mountpoint)\n      return (\n        notBlank(mp) &&\n        !ignorableMountpoints.includes(mp) &&\n        notBlank(fs) &&\n        !ignoreFs.includes(fs) &&\n        !ignorableFsTypes.includes(fs)\n      )\n    }) as DfVolume[]\n}\n", "import { mapNotBlank, notBlank } from \"../../fe/Blank\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map } from \"../../fe/Maybe\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { opt } from \"../../fe/Opt\"\nimport { memoizeAsync } from \"../async/MemoizedAsyncFunc\"\nimport { thenFlatten, thenMap, thenMapOr } from \"../async/Promise\"\nimport { thenOrTimeout } from \"../async/thenOrTimeout\"\nimport { stdout, stdoutResult } from \"../child/ChildProcess\"\nimport { BaseFile } from \"../fs/BaseFile\"\nimport { mkLogger } from \"../Logger\"\nimport { isDocker, isLinux } from \"../Platform\"\nimport { stripPrefix, stripSuffix } from \"../String\"\nimport { dfPosixRaw } from \"./DfPosixRaw\"\nimport { Volume } from \"./Volume\"\nimport {\n  CmdTimeoutMs,\n  LongMountpointsTtlMs,\n  MountpointsTtlMs,\n  ShortCmdTimeoutMs\n} from \"./VolumeTtls\"\n\nexport const isGioSupported = lazy(async () => {\n  if (!isLinux || isDocker()) {\n    return false\n  }\n\n  try {\n    const result = await stdoutResult(GioCommand, [\"version\"], {\n      timeout: CmdTimeoutMs,\n      ignoreStderr: true\n    })\n    return result.code === 0\n  } catch (err) {\n    return false\n  }\n})\n\nexport const GioCommand = \"gio\"\nexport const GioMountMonitorArgs = [\"mount\", \"--monitor\", \"--anonymous\"]\n\nconst gvlog = lazy(() => mkLogger(\"Gio.gioVolumes()\"))\n\n/**\n * The `gio` subsystem may not be installed, in which case, we have to poll\n * the results of `df`.\n */\n/**\n * These volumes won't be in a `df` list.\n */\n// DO NOT USE keyedLazy here, as mountpoints() uses this function!\nexport const gioVolumes = lazy(\n  () =>\n    thenOrTimeout(\n      async () => {\n        // We need to find the FUSE mountpoints that gvfs is using:\n        const dirs = await gvfsFuseDirectories()\n        const vols: Volume[] = (\n          await thenFlatten(\n            dirs.map(async dir => {\n              const rawVols = await dfPosixRaw(false, dir.nativePath).catch(\n                err => {\n                  gvlog().warn(\"Failed to df \" + dir + \": \" + err)\n                  return\n                }\n              )\n              const vol = map(rawVols, ea => ea[0])\n              map(vol, ea => (ea.mountpoint = dir.nativePath))\n              return vol\n            })\n          )\n        ).filter(vol => vol.size > 0)\n\n        return Promise.all(\n          vols.map(async vol =>\n            thenMapOr(\n              getRemoteInfo(vol.mountpoint),\n              remoteInfo => {\n                vol.remoteHost = remoteInfo.remoteHost\n                vol.remoteShare = remoteInfo.remoteShare\n                vol.label = remoteInfo.displayName\n                vol.remote = true\n                return vol\n              },\n              () => vol\n            )\n          )\n        )\n      },\n      MountpointsTtlMs,\n      () =>\n        mkLogger(\"Gio.gioVolumes\").warn(\n          \"timed out after \" + MountpointsTtlMs + \"ms\"\n        )\n    ),\n  LongMountpointsTtlMs\n)\n\nconst riLog = mkLogger(\"Gio.getRemoteInfo()\")\n\nconst getRemoteInfo = memoizeAsync(\n  async (mountpoint: string) => {\n    try {\n      const lines = (\n        await stdout(GioCommand, [\"info\", mountpoint], {\n          timeout: CmdTimeoutMs\n        })\n      ).split(/[\\n\\r]+/)\n      const uri = mapNotBlank(\n        lines.find(ea => ea.startsWith(\"uri: \")),\n        ea => new URL(stripPrefix(ea, \"uri: \"))\n      )\n      return {\n        displayName: map(\n          lines.find(ea => ea.startsWith(\"display name: \")),\n          ea => stripPrefix(ea, \"display name: \")\n        ),\n        remoteHost: map(uri, ea => ea.hostname),\n        remoteShare: opt(uri)\n          .flatMap(ea => ea.pathname)\n          .flatMap(ea => stripPrefix(ea, \"/\"))\n          .flatMap(ea => stripSuffix(ea, \"/\"))\n          .flatMap(decodeURIComponent)\n          .filter(notBlank)\n          .get()\n      }\n    } catch (err) {\n      riLog.warn(\"gio info failed\", { mountpoint, err })\n      return\n    }\n  },\n  { maxSize: 255, timeoutMs: ShortCmdTimeoutMs, clearEveryMs: 10 * minuteMs }\n)\n\n// $ grep gvfs /etc/mtab\n// gvfsd-fuse /run/user/1000/gvfs fuse.gvfsd-fuse rw,nosuid,nodev,relatime,user_id=1000,group_id=1000 0 0\n\nexport const mtabEntries = lazy<PromiseMaybe<string[]>>(async () => {\n  return thenMap(BaseFile.for(\"/proc/mounts\").readLines(), lines =>\n    lines\n      .filter(line => line.startsWith(\"gvfsd-fuse \"))\n      .map(line => line.split(\" \")[1])\n  )\n}, LongMountpointsTtlMs)\n\nasync function gvfsFuseDirectories(): Promise<BaseFile[]> {\n  if (!(await isGioSupported())) return []\n  return thenFlatten(\n    await thenMap(mtabEntries(), arr =>\n      arr.map(ea => BaseFile.for(ea).clear().childDirectories())\n    )\n  )\n}\n", "import { DateObject, DateTime, Duration, Info } from \"luxon\"\nimport { notBlank } from \"../../fe/Blank\"\nimport { isDate, secondMs } from \"../../fe/Date\"\nimport { map, mapOr } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { gt0, round, toInt } from \"../../fe/Number\"\nimport { opt } from \"../../fe/Opt\"\nimport { cmp } from \"../../fe/Primitive\"\nimport { pad2 } from \"../String\"\n\nexport function cmpDate(a?: Date, b?: Date): number {\n  const aTime = mapOr(\n    a,\n    d => d.getTime(),\n    () => 0\n  )\n  const bTime = mapOr(\n    b,\n    d => d.getTime(),\n    () => 0\n  )\n  return cmp(aTime, bTime)\n}\n\nexport function msUntil(d?: Date): number {\n  if (d == null) return 0\n  const ts = d.getTime()\n  const n = Date.now()\n  return ts <= n ? 0 : ts - n\n}\n\nexport function closeTo(a: Maybe<Date>, b: Maybe<Date>, maxMsDelta: number) {\n  return (\n    a != null && b != null && Math.abs(a.getTime() - b.getTime()) <= maxMsDelta\n  )\n}\n\nexport function nowish(d: Maybe<number | Date>, maxMsDelta = 2500): boolean {\n  return d == null\n    ? false\n    : isDate(d)\n    ? closeTo(d, new Date(), maxMsDelta)\n    : Math.abs(d - Date.now()) < maxMsDelta\n}\n\nexport function isRecentMs(\n  timeMs: Maybe<number>,\n  delta = 5 * secondMs\n): boolean {\n  return gt0(timeMs) && Date.now() - timeMs <= delta\n}\n\nexport function datestampUTC(d: Date = new Date()): string {\n  return (\n    d.getUTCFullYear() +\n    \"-\" +\n    pad2(d.getUTCMonth() + 1) +\n    \"-\" +\n    pad2(d.getUTCDate())\n  )\n}\n\nexport function filestamp(d: Date = new Date()): string {\n  return [\n    d.getFullYear(),\n    pad2(d.getMonth() + 1),\n    pad2(d.getDate()),\n    \"-\",\n    pad2(d.getHours()),\n    pad2(d.getMinutes()),\n    pad2(d.getSeconds())\n  ].join(\"\")\n}\n\nexport function filestampUTC(d: Date = new Date()): string {\n  return [\n    d.getUTCFullYear(),\n    pad2(d.getUTCMonth() + 1),\n    pad2(d.getUTCDate()),\n    \"-\",\n    pad2(d.getUTCHours()),\n    pad2(d.getUTCMinutes()),\n    pad2(d.getUTCSeconds())\n  ].join(\"\")\n}\n\nexport function fmtMs(ms: number): string {\n  return Duration.fromMillis(ms).toFormat(\"m:s.S\")\n}\n\nexport function durationToPaddedHMS(ms: number): string {\n  return Duration.fromMillis(ms).toFormat(\"hhhh:mm:ss.SSS\")\n}\n\nexport function durationHMS(ms: number): string {\n  return Duration.fromMillis(round(ms / secondMs) * secondMs).toFormat(\n    \"h:mm:ss\"\n  )\n}\n\nexport function isoNow() {\n  return new Date().toISOString()\n}\n\nexport function utcIsoToTs(iso: Maybe<string>): Maybe<number> {\n  return opt(iso)\n    .filter(notBlank)\n    .map(ea => DateTime.fromISO(ea))\n    .filter(ea => ea.isValid)\n    .map(ea => ea.toMillis())\n    .get()\n}\n\nexport function nowLocal() {\n  return agoLocal(0)\n}\n\nexport function agoLocal(agoMs: number) {\n  return dateTimeToLocal(DateTime.local().plus(-agoMs))!\n}\n\nexport function dateTimeToLocal(d: DateTime): Maybe<number> {\n  return map(\n    dateTimeToLocalSec(d),\n    ea => ea * 100 + millisToLocalSuffix(d.millisecond)\n  )\n}\n\nexport function dateTimeToLocalSec(d: DateTime): Maybe<number> {\n  return d == null || !d.isValid ? undefined : toInt(d.toFormat(\"yMMddHHmmss\"))\n}\n\nexport function millisToLocalSuffix(ms: number) {\n  // NOTE: we floor here rather than rounding as we don't want to deal with\n  // rounding up to a different minute or hour (or day or year)\n  // HONEST IT'S OK IT'S ONLY +/- 5 milliseconds.\n  return Math.floor(ms / 10)\n}\n\nexport function localToDateObject(\n  local: Maybe<number>,\n  offset?: Maybe<number>\n): Maybe<DateObject> {\n  if (local == null || local < 0) return\n  let i = local\n  const pop2 = () => {\n    const result = i % 100\n    i = Math.floor(i / 100)\n    return result\n  }\n  const millisecond = 10 * pop2()\n  const second = pop2()\n  const minute = pop2()\n  const hour = pop2()\n  const day = pop2()\n  const month = pop2()\n  const year = i\n  return {\n    year,\n    month,\n    day,\n    hour,\n    minute,\n    second,\n    millisecond,\n    zone: map(offset, ea => Info.normalizeZone(ea))\n  }\n}\n\nexport function localToDateTime(\n  local: Maybe<number>,\n  offset?: Maybe<number>\n): Maybe<DateTime> {\n  return map(localToDateObject(local, offset), ea => DateTime.fromObject(ea))\n}\n\n/**\n * Convert local numeric to millis-from-common-epoch timestamp\n */\nexport function localToTs(\n  local: Maybe<number>,\n  offset?: Maybe<number>\n): Maybe<number> {\n  return map(localToDateTime(local, offset), ea => ea.toMillis())\n}\n\n/**\n * This should only be used by tests, as a timestamp has already lost relevant\n * timezone offset.\n * @param ts is a millis-from-common-epoch timestamp\n */\nexport function tsToLocal(ts: number): number {\n  const d = new Date(ts)\n  return toInt(\n    [\n      d.getFullYear(),\n      ...[\n        d.getMonth() + 1,\n        d.getDate(),\n        d.getHours(),\n        d.getMinutes(),\n        d.getSeconds(),\n        millisToLocalSuffix(d.getUTCMilliseconds())\n      ].map(pad2)\n    ].join(\"\")\n  )!\n}\n\n/**\n * @return local numeric of `local` plus `ms` millis\n */\nexport function localPlusMs(local: number, ms: number): number {\n  return dateTimeToLocal(localToDateTime(local)!.plus(ms))!\n}\n", "import { ChildProcess } from \"child_process\"\nimport { compact } from \"../../fe/Array\"\nimport { notBlank } from \"../../fe/Blank\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { errorToS, isError } from \"../../fe/Error\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, mapOr } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { gt } from \"../../fe/Number\"\nimport { opt } from \"../../fe/Opt\"\nimport { toS } from \"../../fe/toS\"\nimport {\n  addEndable,\n  Endable,\n  EndableRank,\n  EndableRanks,\n  ending\n} from \"../async/Endable\"\nimport { thenNot } from \"../async/Promise\"\nimport { Promises } from \"../async/Promises\"\nimport { isRecentMs } from \"../date/Date\"\nimport { onError } from \"../error/Error\"\nimport {\n  FatalErrorFlag,\n  isFatalError,\n  isIgnorableError\n} from \"../error/ErrorTypes\"\nimport { WrappedError } from \"../error/WrappedError\"\nimport { onDataChunked } from \"../fs/StreamChunker\"\nimport { endStream } from \"../fs/Streams\"\nimport { mkLogger } from \"../Logger\"\nimport { Rate } from \"../math/Rate\"\nimport { Try } from \"../Object\"\nimport { pidExists } from \"../Pids\"\nimport { serviceShutdownTimeoutMs } from \"../ServiceNames\"\nimport { Settings } from \"../settings/Settings\"\nimport { ellipsize } from \"../String\"\nimport { endProcess, spawn } from \"./ChildProcess\"\n\nexport interface WatchedChildOpts {\n  name: string\n  childFactory: () => ChildProcess | Promise<ChildProcess>\n  dataSep?: string | RegExp\n  maxErrorsPerMinute?: number\n  endableRank?: EndableRank\n  exitCommand?: string\n  restartOnExit?: boolean // should only be false when we test sync\n}\n\nexport interface WatchedChildListener {\n  onStdout(data: string): void\n\n  /**\n   * @return true if the error should be propagated to onError\n   */\n  onStderr?(data: string): boolean\n\n  /**\n   * @return true if the error requires the child process to be restarted\n   */\n  onError(source: string, error: any): boolean\n\n  onRestart?(): void\n\n  /**\n   * Is it OK to start if we can't shut down a prior child process?\n   */\n  ignoreStopErrors: boolean // should be true for non-PS daemons\n}\n\n// so basic\nexport function mkBasicWatchedChild(\n  args: {\n    cmd: string\n    args: string[]\n  } & Partial<WatchedChildListener>\n) {\n  const wc: WatchedChild = new WatchedChild({\n    name: compact([args.cmd, ...args.args]).join(\" \"),\n    childFactory: () => {\n      // Restart every 30 minutes to prevent memory leaks:\n      return spawn(args.cmd, args.args, 30 * minuteMs)\n    },\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\n    onStdout: () => {},\n    onError: () => true,\n    ignoreStopErrors: true,\n    ...args\n  })\n  return wc\n}\n\n/**\n * BatchCluster is for ephemeral clusters of stateless processes.\n *\n * To watch a single, long-lived process, though, we need different management\n * heuristics than what batch-cluster gives us:\n *\n * 1. Start the child on construction\n * 2. Delegate all stdout, and errors to the provided listener\n * 3. Restart the child if it crashes/ends and this process hasn't ended\n * 4. The caller may need to specifically stop(), and then arbitrarily later, start()\n * 5. Notify the listener if the error rate is too high, or restarts are\n *    \"flapping\" (more than N restarts per some period of where the child spins\n *    up and immediately fails). It's up to the listener to then do something\n *    with that state information (including potentially end the current\n *    process).\n *\n * This class is used for `gio`, `findmnt`, `diskutil`, as well as the `sync`\n * and `web` PhotoStructure daemons.\n */\nexport class WatchedChild implements Endable {\n  readonly name: string\n  readonly startMs = Date.now()\n  private _stopped = false\n  private readonly logger = lazy(() =>\n    mkLogger(\"WatchedChild(\" + compact([this.name, this.pid]).join(\":\") + \")\")\n  )\n  readonly startRate = new Rate(2 * minuteMs)\n  readonly mutex = new Promises()\n  readonly opts: Required<WatchedChildOpts> & WatchedChildListener\n  private _ended = false\n  private lastError?: WrappedError\n  private cp?: ChildProcess\n\n  readonly endTimeoutMs: number\n\n  constructor(opts: WatchedChildOpts & WatchedChildListener) {\n    this.name = opts.name\n    this.opts = {\n      dataSep: \"\\n\",\n      maxErrorsPerMinute: 3,\n      endableRank: EndableRanks.first,\n      exitCommand: \"\",\n      restartOnExit: true,\n      ...opts\n    }\n    // Let the web or db service take some time to close, vacuum, and back up the db.\n    this.endTimeoutMs = serviceShutdownTimeoutMs(this.name as any)\n    addEndable(this.opts.endableRank, this)\n    void this._restart()\n  }\n\n  get stopped() {\n    return this._stopped\n  }\n\n  get ended() {\n    return this._ended\n  }\n\n  async end() {\n    this._ended = true\n    return this._stop()\n  }\n\n  get proc(): Maybe<ChildProcess> {\n    return this.cp\n  }\n\n  get pid(): Maybe<number> {\n    return map(this.cp, ea => ea.pid)\n  }\n\n  get msSinceLastStart(): number {\n    return this.startRate.msSinceLastEvent\n  }\n\n  running(): Promise<boolean> {\n    return mapOr(\n      this.pid,\n      ea => pidExists(ea),\n      async () => false\n    )\n  }\n\n  notRunning(): Promise<boolean> {\n    return thenNot(this.running())\n  }\n\n  /**\n   * Shuts down the current process. The process won't start again until restart() is called.\n   * @return false if stop failed\n   */\n  async stop(): Promise<boolean> {\n    this.logger().info(\"stop()\")\n    this._stopped = true\n    return this.mutex.serial(`WatchedChild(${this.name}).stop`, () => {\n      this._stopped = true\n      return this._stop()\n    })\n  }\n\n  private async _stop(): Promise<boolean> {\n    this.logger().info(\"_stop()\", {\n      stopped: this._stopped,\n      ended: this._ended\n    })\n    const cp = this.cp\n    this.cp = undefined\n    if (cp == null) return true // nothing to stop\n    return this.stopChild(cp)\n  }\n\n  private async stopChild(cp: ChildProcess) {\n    // Send the exit command, if it isn't blank, and stdin is still open:\n    await opt(this.opts.exitCommand)\n      .filter(notBlank)\n      .flatMap(cmd =>\n        opt(cp)\n          .flatMap(ea => ea.stdin)\n          .filter(ea => ea.writable)\n          .forEach(ea => Try(() => ea.write(cmd + \"\\n\"))) // prevent EPIPE if proc has ended\n          .map(endStream)\n          .get()\n      )\n    return endProcess(cp, this.endTimeoutMs)\n  }\n\n  readonly onError = async (src: string, err: Buffer | string | Error) => {\n    const fatal = isFatalError(src) || isFatalError(err)\n    const error = new WrappedError({\n      message: src + map(err, errorToS),\n      cause: isError(err) ? err : undefined\n    })\n    const ignorable = isIgnorableError(error)\n    const ctx = { src, fatal, ignorable, errToS: errorToS(err) }\n    this.logger().log(ignorable ? \"warn\" : \"error\", \"onError()\", ctx)\n    if (this._ended || ignorable) {\n      return\n    }\n\n    this.lastError = error\n    onError(src, error)\n\n    if (fatal) {\n      return this.end()\n    }\n\n    const requiresRestart = this.opts.onError(src, err)\n    if (requiresRestart) {\n      this.logger().warn(\"onError requested restart\", ctx)\n      return this._restart()\n    } else {\n      return\n    }\n  }\n\n  isErrorRateExceeded() {\n    return this.logger().tap({\n      msg: \"isErrorRateExceeded()\",\n      result: gt(this.startRate.eventsPerMinute, this.opts.maxErrorsPerMinute),\n      meta: {\n        startRatePerMin: this.startRate.eventsPerMinute,\n        maxErrorsPerMin: this.opts.maxErrorsPerMinute\n      }\n    })\n  }\n\n  async restart(force = false) {\n    this.logger().info(\"restart()\", {\n      stopped: this._stopped,\n      ended: this._ended\n    })\n    if (this._ended || ending()) return false\n    if (\n      !force &&\n      this.startRate.msSinceLastEvent <\n        Settings.minTimeBetweenServiceRestartsMs.valueOrDefault\n    ) {\n      this.logger().info(\"restart(): last restart was too recent. Ignoring.\", {\n        msSinceLastEvent: this.startRate.msSinceLastEvent,\n        minTimeBetweenServiceRestartsMs:\n          Settings.minTimeBetweenServiceRestartsMs.valueOrDefault\n      })\n      return\n    }\n    return this.mutex.serial(`WatchedChild(${this.name}).restart`, async () => {\n      await this._stop()\n      this._stopped = false\n      return this._start()\n    })\n  }\n\n  async start() {\n    this.logger().info(\"start()\", {\n      stopped: this._stopped,\n      ended: this._ended\n    })\n    return this.mutex.serial(`WatchedChild(${this.name}).start`, async () => {\n      this._stopped = false\n      return this._start()\n    })\n  }\n\n  /**\n   * Only called by onError/onExit, and pauses restarts if error rate is too high.\n   * @return false if errors\n   */\n  private async _restart() {\n    this.logger().info(\"_restart()\", {\n      stopped: this._stopped,\n      ended: this._ended\n    })\n    return this.mutex.maybeRun(\n      `WatchedChild(${this.name})._restart`,\n      async () => {\n        await this._stop()\n        if (this._stopped || this._ended) return false\n        if (this.isErrorRateExceeded()) {\n          this.logger().warn(\n            \"Cannot restart, error/restart rate is too high.\",\n            {\n              errorsPerMinute: this.startRate.eventsPerMinute,\n              msSinceLastStart: this.startRate.msSinceLastEvent\n            }\n          )\n          // If we're just spinning up, die.\n          if (isRecentMs(this.startMs, Settings.probationMs.valueOrDefault)) {\n            onError(\n              \"Can't restart \" +\n                this.name +\n                \", failure rate is too high.\" +\n                FatalErrorFlag,\n              this.lastError\n            )\n          }\n          return false\n        }\n        this.logger().info(\"restart()\", {\n          currentPid: this.pid,\n          startRate: this.startRate,\n          maxErrorsPerMinute: this.opts.maxErrorsPerMinute\n        })\n\n        // eslint-disable-next-line no-unused-expressions\n        this.opts.onRestart?.()\n\n        return this._start()\n      }\n    )\n  }\n\n  // CAREFUL: this must be protected by this.mutex!\n\n  /**\n   * @return true if new pid was started\n   */\n  private async _start(): Promise<boolean> {\n    this.logger().info(\"_start()\", {\n      stopped: this._stopped,\n      ended: this._ended\n    })\n    if (this._stopped || this._ended) return false\n    if (await this.running()) return false\n    this.startRate.onEvent()\n    const cp = (this.cp = await this.opts.childFactory())\n\n    // Pick up the new PID:\n    this.logger.unset()\n    this.logger().info(\"_start(): spawned pid \" + this.pid)\n\n    const ctx = \"cp(\" + cp.pid + \")\"\n    ;[\n      { o: cp, desc: \"\" },\n      { o: cp.stdin, desc: \".stdin\" },\n      { o: cp.stdout, desc: \".stdout\" },\n      { o: cp.stderr, desc: \".stderr\" }\n    ].forEach(({ o, desc }) => {\n      map(o, ea =>\n        ea.on(\"error\", err => this.onError(ctx + desc + \".on(error)\", err))\n      )\n    })\n\n    void map(this.cp.stdout, sout =>\n      onDataChunked(sout, this.opts.dataSep, ea => {\n        this.logger().trace(\"onDataChunked()\", ea)\n        this.opts.onStdout(ea)\n      })\n    )\n\n    void map(this.cp.stderr, serr =>\n      serr.on(\"data\", s => {\n        if (toS(s).includes(\"Error: Cannot find module\")) {\n          onError(\n            \"Failed to start \" + this.name + FatalErrorFlag,\n            new Error(ellipsize(s, 256))\n          )\n        }\n        if (this.opts.onStderr?.(s) === true) {\n          void this.onError(ctx + \".stderr.on(data)\", s)\n        }\n      })\n    )\n\n    this.cp.on(\"exit\", async (code: number | null, signal: string | null) => {\n      this.logger().info(\"onExit\", {\n        code,\n        signal,\n        stopped: this._stopped,\n        ended: this._ended\n      })\n      if (this.opts.restartOnExit) {\n        await this._restart()\n        this.logger().info(\n          \"onExit(): finished setting up new child \" + this.pid\n        )\n      } else {\n        this.logger().info(\n          \"onExit(): this.opts.restartOnExit is false. Ending \" + this.pid\n        )\n        void this.end()\n      }\n    })\n    return true\n  }\n}\n", "import { clearTimeout } from \"timers\"\nimport { map } from \"../fe/Maybe\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { setUnrefTimeout } from \"./async/Timers\"\n\nexport interface Debounced {\n  (...args: any[]): void\n  reset(): void\n  now(): void\n}\n\n/**\n * Node-specific debounce. Not for frontend use.\n */\nexport function debounce(\n  f: (...args: any[]) => void,\n  timeoutMs: number\n): Debounced {\n  timeoutMs = Math.ceil(timeoutMs)\n  let lastTimeout: Maybe<NodeJS.Timeout>\n  let args: any[] = []\n  const r: any = (...a: any[]) => {\n    args = a\n    map(lastTimeout, clearTimeout)\n    lastTimeout = setUnrefTimeout(() => f(...args), timeoutMs)\n  }\n  r.reset = () => {\n    map(lastTimeout, clearTimeout)\n    lastTimeout = undefined\n  }\n  r.now = () => {\n    r.reset()\n    f()\n  }\n  return r\n}\n", "import { compactBlanks } from \"../../fe/Array\"\nimport { map } from \"../../fe/Maybe\"\nimport { thenMap } from \"../async/Promise\"\nimport { mkLogger } from \"../Logger\"\nimport { dfPosixRaw } from \"./DfPosixRaw\"\nimport { gioVolumes, isGioSupported } from \"./Gio\"\n\nconst log = mkLogger(\"Mountpoints.localMountpointSetup()\")\n\nexport async function mountpointsPosix() {\n  const mountpoints = await thenMap(dfPosixRaw(false), vols =>\n    compactBlanks(vols.map(vol => vol.mountpoint))\n  )\n  if (mountpoints != null && (await isGioSupported())) {\n    try {\n      await thenMap(gioVolumes(), gioVols =>\n        mountpoints.push(...gioVols.map(ea => ea.mountpoint))\n      )\n    } catch (err) {\n      // may fail due to timeouts. It's better to have *some* volumes than crash:\n      log.warn(\"Failed to fetch gio volumes\", err)\n    }\n  }\n  return map(mountpoints, arr =>\n    arr.filter(ea => !ea.startsWith(\"/snap/\") && ea !== \"/dev\")\n  )\n}\n", "import { isNotEmpty } from \"../../fe/Array\"\nimport { secondMs } from \"../../fe/Date\"\nimport { thenOpt } from \"../../fe/OptAsync\"\nimport { stdout } from \"../child/ChildProcess\"\nimport { fsutil } from \"../fs/PathTo\"\nimport { PowerShell } from \"../pwsh/PowerShell\"\n\nconst driveletterRe = /\\s([A-Z]:\\\\)/g\n\n/**\n * @throws on error\n */\nexport const mountpointsWin = async () => {\n  return thenOpt(\n    PowerShell.instance().executeJsonToA(\n      \"Get-PSDrive -PSProvider FileSystem | Select-Object -Property Root\"\n    )\n  )\n    .flatMap<string[]>(arr => arr.map(ea => ea.Root))\n    .filter(isNotEmpty)\n    .orElse(() => mountpointsWinFsutil())\n    .map(ea => ea.sort())\n    .getRequired()\n}\n\n/**\n * fsutil-based list of all currently active drive letters\n *\n * @return [\"C:\\\", \"D:\\\", ...]\n */\nexport const mountpointsWinFsutil = async () => {\n  // Note that `fsutil fsinfo drives` seems to be about an order of magnitude\n  // faster than ` wmic logicaldisk get caption`.\n\n  // Example output: Drives: C:\\ H:\\ I:\\\"\"\n  const sout = (\n    await stdout(await fsutil(), [\"fsinfo\", \"drives\"], {\n      timeout: 10 * secondMs\n    })\n  ).trim()\n  const result: string[] = []\n  let match: RegExpExecArray | null\n  while ((match = driveletterRe.exec(sout)) !== null) {\n    result.push(match[1])\n  }\n  return result\n}\n", "import { retryOnReject } from \"../../fe/AsyncRetry\"\nimport { secondMs } from \"../../fe/Date\"\nimport { later, unrefDelay } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { end } from \"../async/Endable\"\nimport { firstDefinedLater, LaterMaybe } from \"../async/Later\"\nimport { awaitAll } from \"../async/Promise\"\nimport { stdoutResult } from \"../child/ChildProcess\"\nimport { mkBasicWatchedChild } from \"../child/WatchedChild\"\nimport { debounce } from \"../Debounce\"\nimport { onError } from \"../error/Error\"\nimport { onClearCache } from \"../event/EventEmitter\"\nimport { mkLogger } from \"../Logger\"\nimport { isLinux, isMac, isWin } from \"../Platform\"\nimport { isRpcServer } from \"../ServiceNames\"\nimport {\n  GioCommand,\n  GioMountMonitorArgs,\n  gioVolumes,\n  isGioSupported,\n  mtabEntries\n} from \"./Gio\"\nimport { mountpointsPosix } from \"./MountpointsPosix\"\nimport { mountpointsWin } from \"./MountpointsWin\"\nimport {\n  CmdTimeoutMs,\n  LongMountpointsTtlMs,\n  MountpointsTtlMs\n} from \"./VolumeTtls\"\n\nexport const nonRpcMountpoints = () =>\n  isWin ? mountpointsWin() : mountpointsPosix()\n\nlet rpcMountpoints: Maybe<LaterMaybe<string[]>>\n\nexport function setRpcMountpointsImpl(f: typeof rpcMountpoints) {\n  rpcMountpoints = f\n  void localMountpointSetup() // < make sure we run setup\n}\n\nexport const localMountpointSetup = lazy(async () => {\n  if (isRpcServer()) {\n    later(async () => {\n      const log = mkLogger(\"Mountpoints.localMountpointSetup()\")\n      if (isMac) {\n        log.info(\"Setting up Mac diskutil activity watcher\")\n        mountpoints.setTTL(LongMountpointsTtlMs)\n        diskUtilActivity()\n      }\n      if (isLinux) {\n        if (await isGioSupported()) {\n          log.info(\"Setting up Linux gio mount monitor\")\n          mountpoints.setTTL(LongMountpointsTtlMs)\n          gioMountMonitor()\n        }\n        if (await isFindmntSupported()) {\n          log.info(\"Setting up Linux findmnt mount monitor\")\n          mountpoints.setTTL(LongMountpointsTtlMs)\n          findmntPoll()\n        }\n      }\n    }, 30 * secondMs).unref() // let startup go faster. This can wait.\n  } else {\n    await awaitAll([\n      end(diskUtilActivity.clear()),\n      end(gioMountMonitor.clear()),\n      end(findmntPoll.clear())\n    ])\n  }\n})\n\n/**\n * @return undefined if errors are raised\n */\nexport const mountpoints = lazy(async () => {\n  const impl = () => firstDefinedLater(rpcMountpoints, nonRpcMountpoints)\n  const result = await retryOnReject(impl, {\n    maxRetries: 3,\n    onRetryWaitUntil: i => unrefDelay(i * 1500)\n  }).catch(err => {\n    onError(\"mountpoints() failed\", err)\n    return undefined\n  })\n  return result?.sort()\n}, MountpointsTtlMs)\n\nlater(() => onClearCache(() => mountpoints.unset()))\n\n/**\n * Provides near-real-time updates when volumes change on macs:\n */\nexport const diskUtilActivity = lazy(() =>\n  mkBasicWatchedChild({\n    cmd: \"diskutil\",\n    args: [\"activity\"],\n    onStdout: debounce(() => mountpoints.unset(), 1.5 * secondMs)\n  })\n)\n\nexport const gioMountMonitor = lazy(() =>\n  mkBasicWatchedChild({\n    cmd: GioCommand,\n    args: GioMountMonitorArgs,\n    onStdout: debounce(() => {\n      gioVolumes.unset()\n      mtabEntries.unset()\n      mountpoints.unset()\n    }, 1.5 * secondMs)\n  })\n)\n\nconst isFindmntSupported = lazy(async () => {\n  if (!isLinux) return false\n  try {\n    const result = await stdoutResult(\"findmnt\", [\"--version\"], {\n      timeout: CmdTimeoutMs,\n      ignoreStderr: true\n    })\n    return result.code === 0\n  } catch (err) {\n    return false\n  }\n})\n\nexport const findmntPoll = lazy(() =>\n  mkBasicWatchedChild({\n    cmd: \"findmnt\",\n    args: [\"--poll\"],\n    onStdout: debounce(() => {\n      mtabEntries.unset()\n      mountpoints.unset()\n    }, 1.5 * secondMs)\n  })\n)\n", "import { retryOnReject } from \"../../fe/AsyncRetry\"\nimport { later } from \"../../fe/Delay\"\nimport { MemoizedThunk } from \"../../fe/Lazy\"\nimport { Later } from \"../async/Later\"\nimport { timedLazy } from \"../async/PromiseTimer\"\nimport { isIgnorableError } from \"../error/ErrorTypes\"\nimport { onClearCache } from \"../event/EventEmitter\"\nimport { mountpoints } from \"./Mountpoints\"\nimport { CmdTimeoutMs, LongTtlMs } from \"./VolumeTtls\"\n\n/**\n * lazy-ify `l` with retries\n */\nexport function lazyFsAsync<T>(\n  name: string,\n  l: Later<T>\n): MemoizedThunk<Promise<T>> {\n  const result = timedLazy(\n    \"vol.\" + name,\n    () =>\n      retryOnReject(l, {\n        maxRetries: 2,\n        timeoutMs: CmdTimeoutMs,\n        errorIsRetriable: err => isIgnorableError(err)\n      }),\n    LongTtlMs\n  )\n  mountpoints.onChange(() => result.unset())\n  later(() => onClearCache(() => result.unset()))\n  return result\n}\n", "import { thenMap } from \"../async/Promise\"\nimport { dfPosixRaw } from \"./DfPosixRaw\"\nimport { gioVolumes, isGioSupported } from \"./Gio\"\nimport { lazyFsAsync } from \"./LazyFsAsync\"\n\nconst localMountpoints = lazyFsAsync(\n  \"localMountpoints\",\n  // We'll assume gio mountpoints are always remote, so we can ignore gio stuff\n  // here:\n  () => thenMap(dfPosixRaw(true), vols => vols.map(vol => vol.mountpoint))\n)\n\nexport const dfPosix = lazyFsAsync(\"dfPosix\", async () => {\n  const vols = await dfPosixRaw(false)\n  if (vols == null) return\n  await thenMap(localMountpoints(), locals => {\n    vols.forEach(vol => {\n      vol.remote = !locals.includes(vol.mountpoint)\n    })\n  })\n  if (await isGioSupported()) {\n    await thenMap(gioVolumes(), gv => vols.push(...gv))\n  }\n  return vols\n})\n", "import { compact } from \"../../fe/Array\"\nimport { blank, notBlank } from \"../../fe/Blank\"\nimport { secondMs } from \"../../fe/Date\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { opt } from \"../../fe/Opt\"\nimport { toS } from \"../../fe/toS\"\nimport { thenMap } from \"../async/Promise\"\nimport { stdout } from \"../child/ChildProcess\"\nimport { parseFixed } from \"../Fixed\"\nimport { wmic } from \"../fs/PathTo\"\nimport { toMap } from \"../Map\"\nimport { Try } from \"../Object\"\nimport { isWin } from \"../Platform\"\nimport { PowerShell } from \"../pwsh/PowerShell\"\nimport { ensureSuffix } from \"../String\"\nimport { lazyFsAsync } from \"./LazyFsAsync\"\nimport { Volume } from \"./Volume\"\n\n/*\n$ wmic netuse get LocalName, RemoteName, COnnectionState, Status\nConnectionState  LocalName  RemoteName        Status\nConnected        H:         \\\\10.1.1.7\\homes  OK\nDisconnected     I:         \\\\10.1.1.3\\mrm    Unavailable\n*/\n\nexport async function addRemoteVolumeInfoWin(\n  volumes: Volume[],\n  netInfos?: NetInfo[]\n): Promise<Volume[]> {\n  if (!isWin) throw new Error(\"wtf\")\n  await thenMap(\n    orElse<NetInfo[] | PromiseMaybe<NetInfo[]>>(netInfos, () => netInfoWin()),\n    arr => {\n      const m = toMap(arr, ea => [ea.mountpoint, ea])\n      volumes.forEach(vol => {\n        map(m.get(vol.mountpoint), netInfo => {\n          vol.remote = true\n          vol.remoteHost = netInfo.host\n          vol.remoteShare = netInfo.share\n          vol.ok = netInfo.ok\n        })\n      })\n    }\n  )\n  return volumes\n}\n\nconst columns = [\"LocalName\", \"RemoteName\", \"Status\"]\nconst netuseCmd = [\"NETUSE\", \"get\", columns.join(\",\")]\n\nexport interface NetInfo {\n  /** \"H:\\\" */\n  mountpoint: string\n  /** probably the IP address of the remote share */\n  host: string\n  /** the name of the share */\n  share: string\n  /** true if the Status of the share is \"OK\" */\n  ok: boolean\n}\n\nconst UNC_RE = /^\\\\\\\\(.+?)\\\\(.+)$/\nconst driveLetterRE = /^[a-z]:\\\\?$/i\n\nexport const NetInfoCmd = `Get-WmiObject Win32_NetworkConnection | Select-Object -Property LocalName,RemoteName,ConnectionState,Status`\n\nasync function _netInfoWin(): Promise<NetInfo[]> {\n  const result = await PowerShell.instance().executeJsonToA(\n    `Get-WmiObject Win32_NetworkConnection | Select-Object -Property LocalName,RemoteName,ConnectionState,Status`\n  )\n\n  return result == null\n    ? _netInfoWinWmic()\n    : compact(\n        result\n          .filter((ea: any) => notBlank(ea.LocalName)) // can't do anything if we don't have a localname.\n          .map((ea: any) =>\n            map(parseRemoteName(ea.RemoteName), ({ host, share }) =>\n              map(driveLetterRE.exec(toS(ea.LocalName)), driveLetter => ({\n                mountpoint: ensureSuffix(driveLetter[0], \"\\\\\"),\n                host,\n                share,\n                ok: ea.Status === \"OK\" && ea.ConnectionState === \"Connected\"\n              }))\n            )\n          )\n      )\n}\n\nexport function parseRemoteName(\n  remoteName: string\n): Maybe<{ host: string; share: string }> {\n  if (blank(remoteName)) return\n\n  return opt(remoteName)\n    .flatMap(ea => UNC_RE.exec(ea))\n    .map(ea => ({\n      host: ea[1],\n      share: ea[2]\n    }))\n    .orElse(() =>\n      opt(remoteName)\n        .flatMap(url => Try(() => new URL(url)))\n        .filter(url => notBlank(url.hostname))\n        .map(url => ({\n          host: url.hostname,\n          share: opt(url.pathname)\n            .filter(notBlank)\n            .getOrElse(() => \"/\")\n        }))\n    )\n    .get()\n}\n\nexport async function _netInfoWinWmic(): Promise<NetInfo[]> {\n  const cmd = wmic()\n  const sout = await stdout(cmd, netuseCmd, { timeout: 15 * secondMs })\n  const parsed = parseFixed(columns, sout)\n  return compact(\n    parsed.map(ea =>\n      map(UNC_RE.exec(toS(ea.RemoteName)), remoteName =>\n        map(driveLetterRE.exec(toS(ea.LocalName)), driveLetter => ({\n          mountpoint: ensureSuffix(driveLetter[0], \"\\\\\"),\n          host: remoteName[1],\n          share: remoteName[2],\n          ok: ea.Status === \"OK\"\n        }))\n      )\n    )\n  )\n}\n\nconst netInfoWin = lazyFsAsync(\"netInfoWin\", _netInfoWin)\n", "import { sort, uniq } from \"../../fe/Array\"\nimport { notBlank, notBlankAnd } from \"../../fe/Blank\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { gt0 } from \"../../fe/Number\"\nimport { compactBlankValues } from \"../../fe/Object\"\nimport { thenCollect } from \"../../fe/Promise\"\nimport { toS } from \"../../fe/toS\"\nimport { onError } from \"../error/Error\"\nimport { mkLogger } from \"../Logger\"\nimport { Pojo } from \"../Object\"\nimport { PowerShell } from \"../pwsh/PowerShell\"\nimport { equalsIgnoreCase } from \"../String\"\nimport { lazyFsAsync } from \"./LazyFsAsync\"\nimport { parseRemoteName } from \"./RemoteVolumesWin\"\nimport { Volume } from \"./Volume\"\n\nconst logger = lazy(() => mkLogger(\"DfWin\"))\n\nexport const dfWin = lazyFsAsync(\"dfWin\", async () => {\n  // Try to fetch local and net volumes. If that times out, downgrade to just\n  // local volumes:\n  const disks = await volumeInfoWin()\n  return disks.filter(d => d.ok !== false && gt0(d.size))\n})\n\n// Returns network-mapped drives, but doesn't get operational status or UUIDs:\nexport const GetPsDrive =\n  \"Get-PSDrive -PSProvider FileSystem | Select-Object -Property Root,DisplayRoot,Description,Used,Free\"\n\nfunction parseGetPsDriveRow(ea: Pojo): Maybe<Volume> {\n  return notBlank(ea.Root) && ea.Free != null && ea.Used != null\n    ? {\n        mountpoint: ea.Root,\n        label: ea.Description,\n        size: ea.Used + ea.Free,\n        used: ea.Used,\n        available: ea.Free,\n        remote: notBlank(ea.DisplayRoot),\n        ...map(parseRemoteName(ea.DisplayRoot), remote => ({\n          remoteHost: remote.host,\n          remoteShare: remote.share\n        }))\n      }\n    : undefined\n}\n\n// Get-Disk and Get-Partition return physical (not logical) disk info.\n\n// No remote drives, but we get UUIDs:\nexport const GetVolume =\n  \"Get-Volume | Select-Object -Property DriveLetter,FileSystem,FileSystemLabel,Size,SizeRemaining,HealthStatus,OperationalStatus,UniqueId\"\n\nconst uuidRE = /\\{([-a-z0-9]{7,})\\}/i\n\n/**\n * @param s \"\\\\?\\Volume{717926df-0000-0000-0000-50e01f000000}\\\"\n */\nfunction uniqueId2uuid(s: Maybe<string>) {\n  return logger().tap({\n    msg: \"uniqueId2uuid\",\n    result: map(uuidRE.exec(toS(s)), m => m[1]),\n    meta: { s }\n  })\n}\n\nfunction parseGetVolumeRow(o: Pojo): Maybe<Volume> {\n  // We don't care about system recovery volumes:\n  if (\n    o.DriveLetter == null ||\n    o.DriveLetter === \"null\" ||\n    o.FileSystemLabel === \"System Reserved\"\n  ) {\n    return\n  }\n  const ok =\n    o.Size != null &&\n    o.SizeRemaining != null &&\n    notBlank(o.DriveLetter) &&\n    (notBlankAnd(o.HealthStatus, ea => equalsIgnoreCase(ea, \"Healthy\")) ||\n      notBlankAnd(o.OperationalStatus, ea => equalsIgnoreCase(ea, \"OK\")))\n  return {\n    mountpoint: o.DriveLetter + \":\\\\\",\n    filesystem: o.FileSystem,\n    label: o.FileSystemLabel,\n    uuid: uniqueId2uuid(o.UniqueId),\n    size: o.Size,\n    used: o.Size - o.SizeRemaining,\n    available: o.SizeRemaining,\n    remote: false, // Get-Volume only returns local drives.\n    ok\n  }\n}\n\nexport async function volumeInfoWin(): Promise<Volume[]> {\n  const getPsDrive = await thenCollect(\n    PowerShell.instance()\n      .executeJsonToA(GetPsDrive)\n      .catch(err => {\n        onError(\"volumeInfoWin(): LocalAndNetCmd failed\", err)\n        return []\n      }),\n    ea => compactBlankValues(parseGetPsDriveRow(ea))\n  )\n\n  const getVolumes = await thenCollect(\n    PowerShell.instance()\n      .executeJsonToA(GetVolume)\n      .catch(err => {\n        onError(\"_localAndNet(): LocalCmd failed\", err)\n        return []\n      }),\n    ea => compactBlankValues(parseGetVolumeRow(ea))\n  )\n\n  // Don't include any mountpoints that are unhealthy:\n  const unhealthy = uniq(\n    [...getPsDrive, ...getVolumes]\n      .filter(ea => ea.ok === false)\n      .map(ea => ea.mountpoint)\n  )\n\n  const mountpoints = sort(\n    uniq([...getPsDrive, ...getVolumes].map(ea => ea.mountpoint)).filter(\n      ea => !unhealthy.includes(ea)\n    )\n  )\n\n  logger().info(\"volumeInfoWin()\", {\n    getPsDrive,\n    getVolumes,\n    mountpoints,\n    unhealthy\n  })\n\n  return mountpoints.map(mountpoint => ({\n    ...getPsDrive.find(ea => mountpoint === ea.mountpoint)!,\n    ...getVolumes.find(ea => mountpoint === ea.mountpoint)!\n  })) as Volume[]\n}\n", "import { blank } from \"../../fe/Blank\"\nimport { mapOr } from \"../../fe/Maybe\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { thenMap } from \"../../fe/Promise\"\nimport { stdout } from \"../child/ChildProcess\"\nimport { toMap } from \"../Map\"\nimport { hasAnyIgnoreCase } from \"../String\"\nimport { lazyFsAsync } from \"./LazyFsAsync\"\nimport { DfVolume, Volume } from \"./Volume\"\nimport { CmdTimeoutMs } from \"./VolumeTtls\"\n\n/*\n$ diskutil info -all\nDevice Identifier:        disk0s7\nDevice Node:              /dev/disk0s7\nWhole:                    No\nPart of Whole:            disk0\nDevice / Media Name:      Untitled 7\n\nVolume Name:              Not applicable (no file system)\n\nMounted:                  Not applicable (no file system)\n\nFile System:              None\n\nPartition Type:           Apple_Boot\nOS Can Be Installed:      No\nMedia Type:               Generic\nProtocol:                 SATA\nSMART Status:             Verified\nVolume UUID:              476B3B07-6CFE-3D16-B776-36D0A61244A9\nDisk / Partition UUID:    8F500ACC-D8D9-4135-9234-C3644C543F1D\n\nTotal Size:               650.0 MB (650002432 Bytes) (exactly 1269536 512-Byte-Units)\nVolume Free Space:        Not applicable (no file system)\nDevice Block Size:        512 Bytes\n\nRead-Only Media:          No\nRead-Only Volume:         Not applicable (no file system)\n\nDevice Location:          Internal\nRemovable Media:          No\n\nSolid State:              Yes\n\n**********\n\nDevice Identifier:        disk0s8\nDevice Node:              /dev/disk0s8\nWhole:                    No\nPart of Whole:            disk0\nDevice / Media Name:      Untitled 4\n\nVolume Name:              Untitled 4\n\nMounted:                  Yes\nMount Point:              /Volumes/Untitled 4\n\nFile System Personality:  Journaled HFS+\nType (Bundle):            hfs\nName (User Visible):      Mac OS Extended (Journaled)\nJournal:                  Journal size 24576 KB at offset 0x68f000\nOwners:                   Enabled\n\nPartition Type:           Apple_HFS\nOS Can Be Installed:      Yes\nMedia Type:               Generic\nProtocol:                 SATA\nSMART Status:             Verified\nVolume UUID:              D97628B4-1ADA-3DEC-A500-6636193E26EE\nDisk / Partition UUID:    3BC4303B-DD12-4AFF-9513-5B37BB53B778\n\nTotal Size:               225.0 GB (225000001536 Bytes) (exactly 439453128 512-Byte-Units)\nVolume Free Space:        223.8 GB (223788535808 Bytes) (exactly 437086984 512-Byte-Units)\nDevice Block Size:        512 Bytes\nAllocation Block Size:    4096 Bytes\n\nRead-Only Media:          No\nRead-Only Volume:         No\n\nDevice Location:          Internal\nRemovable Media:          No\n\nSolid State:              Yes\n\n**********\n*/\n\nexport async function addLocalVolumeInfoMac(\n  vols: DfVolume[]\n): PromiseMaybe<Volume[]> {\n  return thenMap(mnt2uuidMac(), uuids =>\n    vols.map(vol =>\n      mapOr(\n        uuids.get(vol.mountpoint),\n        info => ({ ...vol, ...info }),\n        () => vol\n      )\n    )\n  )\n}\n\nexport const mnt2uuidMac = lazyFsAsync(\"mnt2uuidMac\", async () => {\n  const sout = await stdout(\"diskutil\", [\"info\", \"-all\"], {\n    timeout: CmdTimeoutMs\n  })\n  const volumes = sout.split(/^\\s*\\*{8,12}\\s*$/m)\n  return toMap(volumes, volumeLines => {\n    const volumeInfo = toMap(volumeLines.split(/\\s*\\n+\\s*/), line => {\n      const [key, val] = line.split(\":\").map(ea => ea.trim())\n      return hasAnyIgnoreCase([\"not applicable\", \"no file system\"], val)\n        ? undefined\n        : [key.toLowerCase(), val]\n    })\n    const mountpoint = volumeInfo.get(\"mount point\")\n    const label = volumeInfo.get(\"volume name\")\n    const uuid = volumeInfo.get(\"volume uuid\")\n    // There's a lot more interesting metadata we're throwing away here, maybe\n    // TODO look at this later?\n    return blank(mountpoint) ? undefined : [mountpoint, { label, uuid }]\n  })\n})\n", "import { StringValued } from \"../fe/Object\"\nimport { splitLines } from \"./fs/CRLF\"\nimport { stripPreSuff } from \"./String\"\n\n/**\n * Parser for sh environment variable assignments, like `FOO=\"bar\"`.\n *\n * Pairs may be one per line or joined on a single line.\n *\n * \\# Comments are removed.\n */\nexport function parseEnvTokens({\n  input,\n  lowerCaseKeys\n}: {\n  input: string\n  lowerCaseKeys: boolean\n}): StringValued {\n  const result = {}\n  let m\n  for (const line of splitLines(input).filter(\n    ea => ea.match(/^\\s*#/) == null\n  )) {\n    const re = /([a-z_]+)\\s*=\\s*([\"'])?((?:\\\\[\"']|.)*?)(\\2)(?:$|\\s+|#.*?)/gim\n    while ((m = re.exec(line)) != null) {\n      const [, key, quot, val] = m\n      result[lowerCaseKeys ? key.toLowerCase() : key] = stripPreSuff(\n        val,\n        quot,\n        quot\n      )\n    }\n  }\n  return result\n}\n", "import { uniq } from \"../../fe/Array\"\nimport { blank } from \"../../fe/Blank\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { map2Numeric, toInt } from \"../../fe/Number\"\nimport { thenMap } from \"../../fe/Promise\"\nimport { mapAsync } from \"../async/Promise\"\nimport { stdout } from \"../child/ChildProcess\"\nimport { parseEnvTokens } from \"../EnvTokens\"\nimport { splitLines } from \"../fs/CRLF\"\nimport { isDirectory } from \"../fs/Path\"\nimport { mkLogger } from \"../Logger\"\nimport { isDocker } from \"../Platform\"\nimport { sortIgnoreCase } from \"../String\"\nimport { lazyFsAsync } from \"./LazyFsAsync\"\nimport { DfVolume, Volume } from \"./Volume\"\nimport { CmdTimeoutMs } from \"./VolumeTtls\"\n\n/*\n * lsblk --json! I LOVE YOU but I can't have you\n$ lsblk --json --output mountpoint,uuid\n{\n   \"blockdevices\": [\n      {\"mountpoint\": \"/snap/vlc/190\", \"uuid\": null},\n      {\"mountpoint\": null, \"uuid\": null},\n      {\"mountpoint\": \"/home/archive\", \"uuid\": \"5bcd3874-036b-4c80-ad00-258d34f5a097\"},\n      {\"mountpoint\": null, \"uuid\": null},\n      {\"mountpoint\": \"/boot/efi\", \"uuid\": \"32BA-03AC\"},\n      {\"mountpoint\": \"/\", \"uuid\": \"45e94248-490a-4224-b067-3ea48bb062e5\"},\n      {\"mountpoint\": \"[SWAP]\", \"uuid\": \"f8fbf87c-3ba3-4618-b733-74dab6f67cf2\"},\n      {\"mountpoint\": \"/home\", \"uuid\": \"bf676327-0a04-42ff-8088-313fad5082f7\"}\n   ]\n}\n\nbecause --json is fairly new (requires 2.27+). SO SAD.\n\nThis works with debian jessie:\n\n$ lsblk -P --output mountpoint,uuid\nMOUNTPOINT=\"/snap/kde-frameworks-5/26\" UUID=\"\"\nMOUNTPOINT=\"/snap/spotify/16\" UUID=\"\"\nMOUNTPOINT=\"/snap/core/4650\" UUID=\"\"\nMOUNTPOINT=\"/snap/inkscape/4019\" UUID=\"\"\nMOUNTPOINT=\"/snap/spotify/13\" UUID=\"\"\nMOUNTPOINT=\"/snap/vlc/365\" UUID=\"\"\nMOUNTPOINT=\"/snap/core/4917\" UUID=\"\"\nMOUNTPOINT=\"/snap/ffmpeg/13\" UUID=\"\"\nMOUNTPOINT=\"/snap/core/4830\" UUID=\"\"\nMOUNTPOINT=\"/snap/vlc/190\" UUID=\"\"\nMOUNTPOINT=\"/snap/docker/179\" UUID=\"\"\nMOUNTPOINT=\"\" UUID=\"\"\nMOUNTPOINT=\"\" UUID=\"fRFzBv-zld2-4ZJR-zbYw-C3sX-K9pI-KjnP1v\"\nMOUNTPOINT=\"/\" LABEL=\"root\" UUID=\"a7713a75-f1d9-4aba-8cdf-028a9339faee\"\n\n */\n\nconst logger = lazy(() => mkLogger(\"LocalVolumesPosix\"))\n\nexport async function addLocalVolumeInfoPosix(vols: DfVolume[]) {\n  return thenMap(await localVolumeInfoPosix(), infos => {\n    const mountpoints = sortIgnoreCase(\n      uniq([\n        ...infos.filter(ea => !ea.ignorable).map(ea => ea.mountpoint),\n        ...vols.map(ea => ea.mountpoint)\n      ])\n    )\n\n    return mountpoints.map(mountpoint => ({\n      ...vols.find(ea => ea.mountpoint === mountpoint),\n      ...infos.find(ea => ea.mountpoint === mountpoint)\n    })) as Volume[]\n  })\n}\n\nexport const localVolumeInfoPosix = lazyFsAsync(\n  \"localVolumeInfoPosix\",\n  async () => {\n    const sout = await stdout(\n      \"lsblk\",\n      [\"-P\", \"-b\", \"--output\", \"mountpoint,label,fsused,fsavail,uuid\"],\n      {\n        timeout: CmdTimeoutMs // we may need to wait for spinning rust to spin up.\n      }\n    )\n    const allMountpoints = splitLines(sout)\n      .map(input => parseEnvTokens({ input, lowerCaseKeys: true }))\n      .filter(ea => ea != null)\n\n    const result = await mapAsync(allMountpoints, async ea => {\n      const ignorable =\n        blank(ea.mountpoint) ||\n        ea.mountpoint.startsWith(\"/snap/\") ||\n        ea.mountpoint === \"/boot\" ||\n        ea.mountpoint.startsWith(\"/boot/\") ||\n        !(await isDirectory(ea.mountpoint)) // < docker can bind-mount files. Ignore those.\n      return map2Numeric(\n        toInt(ea.fsused),\n        toInt(ea.fsavail),\n        (used, available) => ({\n          mountpoint: ea.mountpoint,\n          label: ea.label as Maybe<string>,\n          uuid: ea.uuid,\n          ignorable,\n          used,\n          available,\n          size: used + available,\n          ...(!isDocker() ? { remote: false } : undefined)\n        })\n      )\n    })\n\n    return logger().tap({\n      msg: \"lsblk\",\n      result\n    })\n  }\n)\n", "import { map, mapOr } from \"../../fe/Maybe\"\nimport { toS } from \"../../fe/toS\"\nimport { Volume } from \"./Volume\"\n\n/* \n\non mac el capitan for SMB/CIFS:\n\n//mrm@rusty._smb._tcp.local/homes ...\n//mrm@rusty.local/photos ...\n//mrm@rusty/web ...\n\non ubuntu 18:\n\n//10.1.1.7/homes ...\n\nWith NFS:\n\n192.168.1.10:/opt/Media ...\n\n*/\n\nconst smbRe = /^\\/\\/(?:.+@)?(.+?)(?:\\._(?:smb|afs|nfs|tcp)){0,2}(?:\\.local)?\\/(.+)$/i\n\nexport const nfsRe = /^([^:\\s]+):(\\/.+)$/\n\nexport async function addRemoteVolumeInfoPosix(\n  volumes: Volume[]\n): Promise<Volume[]> {\n  volumes\n    .filter(ea => ea.remote)\n    .forEach(ea => {\n      mapOr(\n        smbRe.exec(toS(ea.filesystem)),\n        m => {\n          ea.remoteHost = m[1]\n          ea.remoteShare = m[2]\n        },\n        () =>\n          map(nfsRe.exec(toS(ea.filesystem)), m => {\n            ea.remoteHost = m[1]\n            ea.remoteShare = m[2]\n          })\n      )\n    })\n  return volumes\n}\n", "import { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { MaybeSyncOrAsync } from \"../../fe/OptAsync\"\nimport { onError } from \"../error/Error\"\nimport { thenOrTimeout } from \"./thenOrTimeout\"\n\nexport async function tryWithErrorHandling<T>(\n  f: () => MaybeSyncOrAsync<T>,\n  opts: {\n    context?: string\n    message: string\n    timeoutMs?: number\n  }\n): PromiseMaybe<T> {\n  try {\n    return await (opts.timeoutMs == null\n      ? f()\n      : thenOrTimeout(f, opts.timeoutMs, () =>\n          onError(opts.message + \": timeout\", undefined, opts.context)\n        ))\n  } catch (error) {\n    onError(opts.message, error, opts.context)\n    return undefined\n  }\n}\n", "import { randomBytes } from \"crypto\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { decuss } from \"../Cuss\"\n\n/**\n * Type-4 UUID\n *\n * @see https://en.wikipedia.org/wiki/Universally_unique_identifier\n */\nexport function uuid() {\n  const b = randomBytes(16)\n\n  // Set the version bits:\n  b[6] = (b[6] & 0x0f) | 0x40\n\n  // RFC 4122 Section 3 requires that the characters be generated in lower case\n  const s = b.toString(\"hex\")\n\n  // canonical 8-4-4-4-12 format string:\n  return [\n    s.slice(0, 8),\n    s.slice(8, 12),\n    s.slice(12, 16),\n    s.slice(16, 20),\n    s.slice(20)\n  ].join(\"-\")\n}\n\n/**\n * Type-4 UUID without naughty words\n */\nexport function safeUUID(): string {\n  return decuss(uuid)\n}\n\n// only useful for tests:\nexport const UUIDRegExp = lazy(() => /^\\w{8}-\\w{4}-\\w{4}-\\w{4}-\\w{12}$/)\n", "import { thenOrTimeout } from \"../../fe/AsyncRetry\"\nimport { notBlank, notBlankOr } from \"../../fe/Blank\"\nimport { isFalse, isTrue } from \"../../fe/Boolean\"\nimport { later } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { getOrSet } from \"../../fe/Map\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { thenOpt } from \"../../fe/OptAsync\"\nimport { thenMap } from \"../async/Promise\"\nimport { withBoundedConcurrency } from \"../async/Promises\"\nimport { tryWithErrorHandling } from \"../async/TryWithErrorHandling\"\nimport { onClearCache } from \"../event/EventEmitter\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { mkLogger } from \"../Logger\"\nimport { safeUUID } from \"../math/UUID\"\nimport { Settings } from \"../settings/Settings\"\nimport { mountpoints } from \"./Mountpoints\"\nimport { Volume } from \"./Volume\"\nimport { MountpointsTtlMs } from \"./VolumeTtls\"\n\nconst logger = lazy(() => mkLogger(\"VolumeUUID\"))\n\nexport const VolumeUuidTimeoutMs = MountpointsTtlMs / 2\n\n// This isn't a TTLMap because we don't expect to have bajillions of\n// mountpoints, they don't expire, and we force-clear it whenever mountpoints\n// change.\nconst cache = new Map<string, PromiseMaybe<string>>()\n\nlater(() => {\n  onClearCache(() => cache.clear())\n  mountpoints.onChange(() => cache.clear())\n})\n\nexport async function addVolumeUUIDs(vols: Volume[]): Promise<void> {\n  await withBoundedConcurrency({\n    name: \"addVolumeUUIDs\",\n    laters: vols.map(ea => () => addVolumeUUID(ea))\n  })\n}\n\n/**\n * Prefer the UUID stored on the mountpoint/.uuid.\n *\n * If that cannot be read, use the UUID already on the volume.\n *\n * If that is missing/timesout, use the last-set UUID for that volume, stored in\n * APP_DATA/mountpoint-uuids.json\n */\nasync function addVolumeUUID(v: Volume): Promise<void> {\n  if (isTrue(v.ignorable)) {\n    // Don't bother reading the .uuid.\n    logger().debug(\"volumeUUID(): ignorable is true for \" + v.mountpoint)\n    return\n  }\n\n  if (isFalse(v.ok)) {\n    // We don't want to touch this filesystem, it'll probably hang!\n    logger().debug(\"volumeUUID(): remoteOK is false for \" + v.mountpoint)\n    return\n  }\n\n  await thenMap(\n    getOrSet(cache, v.mountpoint, () =>\n      thenOrTimeout(\n        () =>\n          tryWithErrorHandling(() => readVolumeUUID(v), {\n            message: \"readVolumeUUID(\" + v.mountpoint + \")\"\n          }),\n        VolumeUuidTimeoutMs\n      )\n    ),\n    uuid => (v.uuid = uuid)\n  )\n}\n\n/**\n * If the vol UUID file exists, use that instead of the device UUID.\n */\nexport async function readVolumeUUID(v: Volume): PromiseMaybe<string> {\n  const volUuidFile = PosixFile.for(v.mountpoint).join(\".uuid\")\n\n  if (Settings.readVolumeUuidFiles.valueOrDefault) {\n    const uuid = await thenOrTimeout(\n      () =>\n        thenOpt(volUuidFile.readFile(\"debug\")) // isn't worthy of a warn\n          .map(ea => ea.toString().trim())\n          .filter(notBlank)\n          .get(),\n      VolumeUuidTimeoutMs\n    )\n\n    if (uuid != null && uuid.length > 6) {\n      logger().debug(\"Serving UUID from .uuid\", {\n        uuid,\n        mountpoint: v.mountpoint\n      })\n      return uuid\n    }\n  }\n\n  // Don't try to write to the root directory:\n  if (v.mountpoint === \"/\") return v.uuid\n\n  if (Settings.writeVolumeUuidFiles.valueOrDefault) {\n    // Try to persist the UUID for later (or if the volume is remotely mounted)\n    const uuid = notBlankOr(v.uuid, safeUUID)\n\n    // Don't try to write if the directory (typically the root directory\n    // for the volume) is not writable:\n    if (await volUuidFile.parent().isReadWritable()) {\n      try {\n        await volUuidFile.writeTxt_(uuid)\n        logger().info(\"volumeUUID(): Saved new UUID for \" + v.mountpoint, {\n          uuid\n        })\n        return uuid\n      } catch (err) {\n        // Only return the UUID if we can persist it successfully.\n        logger().warn(\n          \"volumeUUID(): Failed to save new UUID for \" + v.mountpoint,\n          err\n        )\n      }\n    }\n  }\n\n  // Only return the hardware uuid if we couldn't persist the mkuuid for later\n  return v.uuid\n}\n", "import {\n  commonPrefixLength,\n  compact,\n  filterInPlace,\n  isEmpty,\n  mapNotEmpty,\n  sortBy\n} from \"../../fe/Array\"\nimport { blank, mapNotBlank, notBlank } from \"../../fe/Blank\"\nimport { isFalse, isTrue } from \"../../fe/Boolean\"\nimport { secondMs } from \"../../fe/Date\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { orElse } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { opt } from \"../../fe/Opt\"\nimport { greatestBy } from \"../Array\"\nimport { firstDefinedLater, LaterMaybe } from \"../async/Later\"\nimport { asyncFind, thenMap } from \"../async/Promise\"\nimport { withBoundedConcurrency } from \"../async/Promises\"\nimport { thenOrTimeout } from \"../async/thenOrTimeout\"\nimport { getEnv } from \"../Env\"\nimport { eql } from \"../Eql\"\nimport { onError } from \"../error/Error\"\nimport { emitVolumesChanged } from \"../event/EventEmitter\"\nimport {\n  containedByNativePath,\n  nativePathIsReadableDirectory\n} from \"../fs/Path\"\nimport { StatTimeoutMs } from \"../fs/StatTimeout\"\nimport { mkLogger } from \"../Logger\"\nimport { friendlyname } from \"../net/nslookup\"\nimport { isMac, isWin } from \"../Platform\"\nimport { Settings } from \"../settings/Settings\"\nimport { ensureSuffix, equalsIgnoreCase } from \"../String\"\nimport { dfPosix } from \"./DfPosix\"\nimport { dfWin } from \"./DfWin\"\nimport { lazyFsAsync } from \"./LazyFsAsync\"\nimport { addLocalVolumeInfoMac } from \"./LocalVolumesMac\"\nimport { addLocalVolumeInfoPosix } from \"./LocalVolumesPosix\"\nimport { addRemoteVolumeInfoPosix } from \"./RemoteVolumesPosix\"\nimport { addRemoteVolumeInfoWin } from \"./RemoteVolumesWin\"\nimport { Volume } from \"./Volume\"\nimport { MountpointsTtlMs } from \"./VolumeTtls\"\nimport { addVolumeUUIDs } from \"./VolumeUUID\"\n\nconst logger = lazy(() => mkLogger(\"Volumes\"))\n\nasync function nonRpcVolumes(): PromiseMaybe<Volume[]> {\n  const rawDfVols = await thenOrTimeout(\n    isWin ? dfWin() : dfPosix(),\n    MountpointsTtlMs,\n    () => onError(\"Timed out getting local volume metadata\")\n  )\n  if (rawDfVols == null) {\n    logger().warn(\"df failed\")\n    return\n  }\n\n  const dfVols = Settings.validateMountpoints.valueOrDefault\n    ? compact(\n        await withBoundedConcurrency({\n          name: \"nonRpcVolumes: filter unhealthy volumes\",\n          laters: rawDfVols.map(vol => async () => {\n            try {\n              // Exclude volumes whose mountpoint doesn't exist (like unhealthy gio\n              // mountpoints):\n              const isDir = await nativePathIsReadableDirectory(\n                vol.mountpoint,\n                StatTimeoutMs / 2\n              )\n              if (isDir) {\n                return vol\n              } else {\n                logger().info(\n                  \"validateMountpoints(): \" +\n                    vol.mountpoint +\n                    \" is not a directory\"\n                )\n              }\n            } catch (err) {\n              logger().info(\n                \"validateMountpoints(): failed to stat \" + vol.mountpoint,\n                err\n              )\n            }\n            return\n          })\n        })\n      )\n    : rawDfVols\n\n  // We only need to fetch remote volume information if there are remote volumes\n  // that are missing remoteHost:\n  if (dfVols.some(ea => ea.remote && blank(ea[\"remoteHost\"]))) {\n    await thenOrTimeout(\n      isWin ? addRemoteVolumeInfoWin(dfVols) : addRemoteVolumeInfoPosix(dfVols),\n      10 * secondMs // < windows NET USE is flaky\n    ).catch(err => {\n      onError(\"Failed to get remote volume info\", err)\n    })\n  }\n  const vols: Volume[] = orElse(\n    await (isWin\n      ? dfVols\n      : isMac\n      ? addLocalVolumeInfoMac(dfVols)\n      : addLocalVolumeInfoPosix(dfVols)),\n    dfVols\n  )\n\n  filterInPlace(vols, ea => !isTrue(ea.ignorable))\n\n  if (Settings.ignoreUnhealthyVolumes.valueOrDefault) {\n    filterInPlace(vols, ea => !isFalse(ea.ok))\n  }\n\n  // Fix hostnames:\n  for (const vol of vols) {\n    vol.remote = isTrue(vol.remote)\n    mapNotBlank(\n      vol.remoteHost,\n      // remote hosts cannot be case sensitive\n      ea => (vol.remoteHost = ea.toLowerCase().normalize().trim())\n    )\n  }\n\n  // undefine any blank labels:\n  for (const vol of vols) {\n    if (blank(vol.label)) delete vol.label\n  }\n\n  logger().debug(\"nonRpcVolumes(): before addVolumeUUIDs\", vols)\n  await addVolumeUUIDs(vols)\n\n  const sorted = sortBy(vols, ea => ea.mountpoint)\n  logger().debug(\"_volumes(): final result\", { sorted })\n  return Object.freeze(sorted) as Volume[]\n}\n\nlet rpcVolumes: Maybe<LaterMaybe<Volume[]>>\n\nexport function setRpcVolumesImpl(f: typeof rpcVolumes) {\n  rpcVolumes = f\n}\n\n// require(\"./dist/core/volumes/Volumes\").volumes().then(console.dir)\n\nlet priorVolumeMountpoints: string[] = []\n\nconst volumesImpl = async () => {\n  try {\n    // DO NOT USE orElse here, it tries to apply function pointers.\n    const result = await firstDefinedLater(rpcVolumes, nonRpcVolumes)\n    mapNotEmpty(result, arr => {\n      const volumeMountpoints = arr.map(ea => ea.mountpoint).sort()\n      if (!eql(priorVolumeMountpoints, volumeMountpoints)) {\n        emitVolumesChanged()\n        priorVolumeMountpoints = volumeMountpoints\n      }\n    })\n    return result\n  } catch (err) {\n    onError(\"volumes() failed\", err)\n    return undefined\n  }\n}\n\nexport const volumes = lazyFsAsync(\"volumes\", volumesImpl)\n\nexport const rootPath = lazy(() =>\n  isWin\n    ? opt(getEnv(\"SystemDrive\")) // < looks like \"C:\", not \"C:\\\"\n        .filter(notBlank)\n        .orElse(() => \"C:\")\n        .map(ea => ensureSuffix(ea, \"\\\\\"))\n        .get()!\n    : \"/\"\n)\n\nexport function rootVolume(): PromiseMaybe<Volume> {\n  return volumeFor(rootPath())\n}\n\nexport async function volumeFor(nativePath: string): PromiseMaybe<Volume> {\n  return thenMap(volumes(), vols => bestVolume(vols, nativePath))\n}\n\nexport function bestVolume(vols: Volume[], nativePath: string): Maybe<Volume> {\n  const candidates = vols.filter(vol =>\n    containedByNativePath(nativePath, vol.mountpoint)\n  )\n  return greatestBy(candidates, vol =>\n    commonPrefixLength(vol.mountpoint, nativePath)\n  )\n}\n\nexport async function remoteVolumeFor(\n  remoteHost: string,\n  remoteShare: string\n): PromiseMaybe<Volume> {\n  return thenMap(volumes(), vols =>\n    bestRemoteVolume(remoteHost, remoteShare, vols)\n  )\n}\n\n/**\n * Find the first volume in `vols` that matches (case-insensitively) the given\n * `remoteHost` and `remoteShare`.\n */\nexport async function bestRemoteVolume(\n  remoteHost: string,\n  remoteShare: string,\n  vols: Volume[]\n): PromiseMaybe<Volume> {\n  // Share names may be mostly unique, and they aren't messed with, so filter by that first:\n  const withCorrectShare = vols.filter(vol =>\n    equalsIgnoreCase(remoteShare, vol.remoteShare)\n  )\n  if (isEmpty(withCorrectShare)) return\n\n  const withExactHostname = withCorrectShare.find(\n    vol =>\n      isTrue(vol.remote) &&\n      notBlank(vol.remoteHost) &&\n      equalsIgnoreCase(remoteHost, vol.remoteHost)\n  )\n  if (withExactHostname != null) return withExactHostname\n\n  const friendlyRemoteHost = await friendlyname(remoteHost)\n  return asyncFind(withCorrectShare, async vol =>\n    equalsIgnoreCase(friendlyRemoteHost, await friendlyname(vol.remoteHost!))\n  )\n}\n", "import { join, sep } from \"path\"\nimport { blank, mapNotBlank, notBlank } from \"../../fe/Blank\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { later } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { ensurePrefix } from \"../../fe/String\"\nimport { PS_LOCAL_FILE_PROTOCOL } from \"../../fe/URI\"\nimport { thenMap } from \"../async/Promise\"\nimport { onClearCache } from \"../event/EventEmitter\"\nimport { shortStringSha } from \"../fs/Hash\"\nimport { native2posix } from \"../fs/Path\"\nimport { compactMap } from \"../Map\"\nimport { memoize } from \"../MemoizedFunc\"\nimport { Volume } from \"../volumes/Volume\"\nimport { volumeFor, volumes } from \"../volumes/Volumes\"\nimport { URI } from \"./URI\"\n\nexport const volsha = memoize(\n  (uuid: Maybe<string>) => mapNotBlank(uuid, shortStringSha),\n  { maxSize: 128, ttlMs: minuteMs }\n)\n\n// Prevent circular module reference problems:\nlater(() => {\n  onClearCache(() => volshaToMountpoint.unset())\n  volumes.onChange(() => volshaToMountpoint.unset())\n})\n\nconst volshaToMountpoint = lazy(async () => {\n  return thenMap(volumes(), vols =>\n    compactMap(vols.map(vol => [volsha(vol.uuid), vol.mountpoint]))\n  )\n})\n\nexport function nativePath2psfile(nativePath: string, vol: Maybe<Volume>) {\n  if (blank(nativePath) || vol == null || blank(vol.uuid)) return\n\n  const fullPath = native2posix(nativePath)\n  const volPath = native2posix(vol.mountpoint)\n  if (!fullPath.normalize().startsWith(volPath.normalize())) return\n  const path = ensurePrefix(fullPath.slice(volPath.length), \"/\")\n\n  return URI.from({\n    scheme: PS_LOCAL_FILE_PROTOCOL,\n    authority: volsha(vol.uuid),\n    path\n  })\n}\n\nexport function joinMountpoint(mountpoint: string, posixPath: string) {\n  return join(mountpoint, ...posixPath.split(\"/\").slice(1))\n}\n\nexport async function psfile2nativePath(\n  uri: URI,\n  mountpoint?: string\n): PromiseMaybe<string> {\n  if (uri.scheme !== PS_LOCAL_FILE_PROTOCOL) {\n    throw new Error(\"invalid URI: \" + uri + \" (bad scheme)\")\n  }\n  if (blank(uri.authority)) {\n    throw new Error(\"invalid URI: \" + uri + \" (missing authority)\")\n  }\n\n  // Best-case, the volsha matches the mountpoint:\n\n  // Don't look at the mountpoint unless it includes a separator character for\n  // the current platform (windows or posix):\n\n  const mountpointMatchesPlatform =\n    mountpoint != null && mountpoint.includes(sep)\n\n  if (mountpointMatchesPlatform) {\n    const vol = await volumeFor(mountpoint!)\n    if (vol?.uuid != null) {\n      const authority = volsha(vol.uuid)\n      if (authority === uri.authority) {\n        return joinMountpoint(mountpoint!, uri.path)\n      }\n    }\n  }\n\n  // Dang, the mountpoint doesn't match. See if we can resolve the volsha:\n\n  const shaMountpoint = await thenMap(volshaToMountpoint(), m =>\n    m.get(uri.authority)\n  )\n  if (notBlank(shaMountpoint)) {\n    return joinMountpoint(shaMountpoint, uri.path)\n  }\n\n  if (mountpointMatchesPlatform) {\n    return joinMountpoint(mountpoint!, uri.path)\n  }\n\n  return undefined\n}\n", "import { stringify } from \"../fe/JSON\"\nimport { FifoCache } from \"./FifoCache\"\n\nexport interface MemoizedFunc<A, R> {\n  (a: A): R\n  clear(a?: A): void\n  size(): number\n  callCount(): number\n}\n\nexport function memoize<A, R>(\n  f: (a: A) => R,\n  opts: { maxSize: number; ttlMs?: number }\n): MemoizedFunc<A, R> {\n  let callCount = 0\n  const store = new FifoCache<R>(opts.maxSize, opts.ttlMs)\n  const r: any = (a: A) => {\n    callCount++\n    return store.getOrSet(stringify(a), () => f(a))\n  }\n  r.clear = (a?: A) => (a == null ? store.clear() : store.delete(stringify(a)))\n  r.size = () => store.size\n  r.callCount = () => callCount\n  return r\n}\n", "// see https://github.com/microsoft/vscode/blob/master/src/vs/base/common/uri.ts\nimport { posix, win32 } from \"path\"\nimport { toUnicode } from \"punycode\"\nimport { inspect } from \"util\"\nimport { notBlank } from \"../../fe/Blank\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { ensureSuffix } from \"../../fe/String\"\nimport { findLast } from \"../Array\"\nimport { CharCode } from \"../CharCode\"\nimport { isWin, isWinPortable } from \"../Platform\"\n\nconst _schemePattern = /^\\w[\\w\\d+.-]*$/\nconst _singleSlashStart = /^\\//\nconst _doubleSlashStart = /^\\/\\//\n\nfunction _validateUri(ret: URI, _strict?: boolean): void {\n  // scheme, must be set\n  if (!ret.scheme && _strict === true) {\n    throw new Error(\n      `[UriError]: Scheme is missing: {scheme: \"\", authority: \"${ret.authority}\", path: \"${ret.path}\", query: \"${ret.query}\", fragment: \"${ret.fragment}\"}`\n    )\n  }\n\n  // scheme, https://tools.ietf.org/html/rfc3986#section-3.1\n  // ALPHA *( ALPHA / DIGIT / \"+\" / \"-\" / \".\" )\n  if (ret.scheme && !_schemePattern.test(ret.scheme)) {\n    throw new Error(\"[UriError]: Scheme contains illegal characters.\")\n  }\n\n  // path, http://tools.ietf.org/html/rfc3986#section-3.3\n  // If a URI contains an authority component, then the path component\n  // must either be empty or begin with a slash (\"/\") character.  If a URI\n  // does not contain an authority component, then the path cannot begin\n  // with two slash characters (\"//\").\n  if (ret.path) {\n    if (ret.authority) {\n      if (!_singleSlashStart.test(ret.path)) {\n        throw new Error(\n          '[UriError]: If a URI contains an authority component, then the path component must either be empty or begin with a slash (\"/\") character'\n        )\n      }\n    } else {\n      if (_doubleSlashStart.test(ret.path)) {\n        throw new Error(\n          '[UriError]: If a URI does not contain an authority component, then the path cannot begin with two slash characters (\"//\")'\n        )\n      }\n    }\n  }\n}\n\n// for a while we allowed uris *without* schemes and this is the migration\n// for them, e.g. an uri without scheme and without strict-mode warns and falls\n// back to the file-scheme. that should cause the least carnage and still be a\n// clear warning\nfunction _schemeFix(scheme: string, _strict: boolean): string {\n  if (!scheme && !_strict) {\n    return \"file\"\n  }\n  return scheme\n}\n\n// implements a bit of https://tools.ietf.org/html/rfc3986#section-5\nfunction _referenceResolution(scheme: string, path: string): string {\n  // the slash-character is our 'default base' as we don't\n  // support constructing URIs relative to other URIs. This\n  // also means that we alter and potentially break paths.\n  // see https://tools.ietf.org/html/rfc3986#section-5.1.4\n  switch (scheme) {\n    case \"https\":\n    case \"http\":\n    case \"file\":\n      if (!path) {\n        path = _slash\n      } else if (path[0] !== _slash) {\n        path = _slash + path\n      }\n      break\n  }\n  return path\n}\n\nconst _empty = \"\"\nconst _slash = \"/\"\nconst _regexp = /^(([^:/?#]+?):)?(\\/\\/([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?/\n\n/**\n * Uniform Resource Identifier (URI) http://tools.ietf.org/html/rfc3986.\n * This class is a simple parser which creates the basic component parts\n * (http://tools.ietf.org/html/rfc3986#section-3) with minimal validation\n * and encoding.\n *\n * ```txt\n *       foo://example.com:8042/over/there?name=ferret#nose\n *       \\_/   \\______________/\\_________/ \\_________/ \\__/\n *        |           |            |            |        |\n *     scheme     authority       path        query   fragment\n *        |   _____________________|__\n *       / \\ /                        \\\n *       urn:example:animal:ferret:nose\n * ```\n */\nexport class URI implements UriComponents {\n  static isUri(thing: any): thing is URI {\n    if (thing instanceof URI) {\n      return true\n    }\n    if (thing == null) {\n      return false\n    }\n    return (\n      typeof (<URI>thing).authority === \"string\" &&\n      typeof (<URI>thing).fragment === \"string\" &&\n      typeof (<URI>thing).path === \"string\" &&\n      typeof (<URI>thing).query === \"string\" &&\n      typeof (<URI>thing).scheme === \"string\" &&\n      typeof (<URI>thing).fsPath === \"function\" &&\n      typeof (<URI>thing).with === \"function\" &&\n      typeof (<URI>thing).toString === \"function\"\n    )\n  }\n\n  /**\n   * scheme is the 'http' part of 'http://www.msft.com/some/path?query#fragment'.\n   * The part before the first colon.\n   */\n  readonly scheme: string\n\n  /**\n   * authority is the 'www.msft.com' part of 'http://www.msft.com/some/path?query#fragment'.\n   * The part between the first double slashes and the next slash.\n   */\n  readonly authority: string\n\n  /**\n   * path is the '/some/path' part of 'http://www.msft.com/some/path?query#fragment'.\n   */\n  readonly path: string\n\n  /**\n   * query is the 'query' part of 'http://www.msft.com/some/path?query#fragment'.\n   */\n  readonly query: string\n\n  /**\n   * fragment is the 'fragment' part of 'http://www.msft.com/some/path?query#fragment'.\n   */\n  readonly fragment: string\n\n  /**\n   * @internal\n   */\n  protected constructor(\n    scheme: string,\n    authority?: string,\n    path?: string,\n    query?: string,\n    fragment?: string,\n    _strict?: boolean\n  )\n\n  /**\n   * @internal\n   */\n  protected constructor(components: UriComponents)\n\n  /**\n   * @internal\n   */\n  protected constructor(\n    schemeOrData: string | UriComponents,\n    authority?: string,\n    path?: string,\n    query?: string,\n    fragment?: string,\n    _strict: boolean = false\n  ) {\n    if (typeof schemeOrData === \"object\") {\n      this.scheme = schemeOrData.scheme || _empty\n      this.authority = schemeOrData.authority || _empty\n      this.path = schemeOrData.path || _empty\n      this.query = schemeOrData.query || _empty\n      this.fragment = schemeOrData.fragment || _empty\n      // no validation because it's this URI\n      // that creates uri components.\n      // _validateUri(this);\n    } else {\n      this.scheme = _schemeFix(schemeOrData, _strict)\n      this.authority = orElse(authority, _empty)\n      this.path = _referenceResolution(this.scheme, orElse(path, _empty))\n      this.query = orElse(query, _empty)\n      this.fragment = orElse(fragment, _empty)\n\n      _validateUri(this, _strict)\n    }\n  }\n\n  // ---- filesystem path -----------------------\n\n  /**\n\t * Returns a string representing the corresponding file system path of this URI.\n\t * Will handle UNC paths, normalizes windows drive letters to lower-case, and uses the\n\t * platform specific path separator.\n\t *\n\t * * Will *not* validate the path for invalid characters and semantics.\n\t * * Will *not* look at the scheme of this URI.\n\t * * The result shall *not* be used for display purposes but for accessing a file on disk.\n\t *\n\t *\n\t * The *difference* to `URI#path` is the use of the platform specific separator and the handling\n\t * of UNC paths. See the below sample of a file-uri with an authority (UNC path).\n\t *\n\t * ```ts\n\t\tconst u = URI.parse('file://server/c$/folder/file.txt')\n\t\tu.authority === 'server'\n\t\tu.path === '/shares/c$/file.txt'\n\t\tu.fsPath === '\\\\server\\c$\\folder\\file.txt'\n\t```\n\t *\n\t * Using `URI#path` to read a file (using fs-apis) would not be enough because parts of the path,\n\t * namely the server name, would be missing. Therefore `URI#fsPath` exists - it's sugar to ease working\n\t * with URIs that represent files on disk (`file` scheme).\n\t */\n  get fsPath(): string {\n    // if (this.scheme !== 'file') {\n    // \tconsole.warn(`[UriError] calling fsPath with scheme ${this.scheme}`);\n    // }\n    return uriToFsPath(this, false)\n  }\n\n  // ---- modify to new -------------------------\n\n  with(change: {\n    scheme?: string\n    authority?: string | null\n    path?: string | null\n    query?: string | null\n    fragment?: string | null\n  }): URI {\n    if (change == null) {\n      return this\n    }\n\n    let { scheme, authority, path, query, fragment } = change\n    if (scheme === undefined) {\n      scheme = this.scheme\n    } else if (scheme === null) {\n      scheme = _empty\n    }\n    if (authority === undefined) {\n      authority = this.authority\n    } else if (authority === null) {\n      authority = _empty\n    }\n    if (path === undefined) {\n      path = this.path\n    } else if (path === null) {\n      path = _empty\n    }\n    if (query === undefined) {\n      query = this.query\n    } else if (query === null) {\n      query = _empty\n    }\n    if (fragment === undefined) {\n      fragment = this.fragment\n    } else if (fragment === null) {\n      fragment = _empty\n    }\n\n    if (\n      scheme === this.scheme &&\n      authority === this.authority &&\n      path === this.path &&\n      query === this.query &&\n      fragment === this.fragment\n    ) {\n      return this\n    }\n\n    return new Uri(scheme, authority, path, query, fragment)\n  }\n\n  // ---- parse & validate ------------------------\n\n  /**\n   * Creates a new URI from a string, e.g. `http://www.msft.com/some/path`,\n   * `file:///usr/home`, or `scheme:with/path`.\n   *\n   * @param value A string which represents an URI (see `URI#toString`).\n   */\n  static parse(value: string, _strict: boolean = false): URI {\n    const match = _regexp.exec(value)\n    if (!match) {\n      return new Uri(_empty, _empty, _empty, _empty, _empty)\n    }\n    const scheme = match[2] || _empty\n    const authority = percentDecode(match[4] || _empty)\n    const path = (match[5] || _empty).split(\"/\").map(percentDecode).join(\"/\")\n    const fixedPath =\n      scheme === \"psfile\" && path.startsWith(\"//\") ? path.slice(1) : path // TODO SITS\n    const query = percentDecode(match[7] || _empty)\n    const fragment = percentDecode(match[9] || _empty)\n    return new Uri(scheme, authority, fixedPath, query, fragment, _strict)\n  }\n\n  /**\n\t * Creates a new URI from a file system path, e.g. `c:\\my\\files`,\n\t * `/usr/home`, or `\\\\server\\share\\some\\path`.\n\t *\n\t * The *difference* between `URI#parse` and `URI#file` is that the latter treats the argument\n\t * as path, not as stringified-uri. E.g. `URI.file(path)` is **not the same as**\n\t * `URI.parse('file://' + path)` because the path might contain characters that are\n\t * interpreted (# and ?). See the following sample:\n\t * ```ts\n\tconst good = URI.file('/coding/c#/project1');\n\tgood.scheme === 'file';\n\tgood.path === '/coding/c#/project1';\n\tgood.fragment === '';\n\tconst bad = URI.parse('file://' + '/coding/c#/project1');\n\tbad.scheme === 'file';\n\tbad.path === '/coding/c'; // path is now broken\n\tbad.fragment === '/project1';\n\t```\n\t *\n\t * @param path A file system path (see `URI#fsPath`)\n\t */\n  static file(path: string): URI {\n    let authority = _empty\n\n    // normalize to fwd-slashes on windows,\n    // on other systems bwd-slashes are valid\n    // filename character, eg /f\\oo/ba\\r.txt\n    if (isWin) {\n      path = path.replace(/\\\\/g, _slash)\n    }\n\n    // check for authority as used in UNC shares\n    // or use the path as given\n    if (path[0] === _slash && path[1] === _slash) {\n      const idx = path.indexOf(_slash, 2)\n      if (idx === -1) {\n        authority = path.substring(2)\n        path = _slash\n      } else {\n        authority = path.substring(2, idx)\n        path = path.substring(idx) || _slash\n      }\n    }\n\n    return new Uri(\"file\", authority, path, _empty, _empty)\n  }\n\n  static from(components: {\n    scheme: string\n    authority?: string\n    path?: string\n    query?: string\n    fragment?: string\n  }): URI {\n    return new Uri(\n      components.scheme,\n      components.authority,\n      components.path,\n      components.query,\n      components.fragment\n    )\n  }\n\n  /**\n   * Join a URI path with path fragments and normalizes the resulting path.\n   *\n   * @param uri The input URI.\n   * @param pathFragment The path fragment to add to the URI path.\n   * @returns The resulting URI.\n   */\n  static joinPath(uri: URI, ...pathFragment: string[]): URI {\n    if (!uri.path) {\n      throw new Error(`[UriError]: cannot call joinPaths on URI without path`)\n    }\n    let newPath: string\n    if (isWin && uri.scheme === \"file\") {\n      newPath = URI.file(win32.join(uriToFsPath(uri, true), ...pathFragment))\n        .path\n    } else {\n      newPath = posix.join(uri.path, ...pathFragment)\n    }\n    return uri.with({ path: newPath })\n  }\n\n  isRootPath(): boolean {\n    return this.path == null || this.path === _slash\n  }\n\n  get pathBase(): Maybe<string> {\n    return this.isRootPath()\n      ? \"\"\n      : map(this.path, path => findLast(path.split(_slash), notBlank))\n  }\n\n  parent(): URI {\n    if (this.isRootPath()) return this\n    return this.with({\n      path: this.path.slice(0, this.path.lastIndexOf(_slash))\n    })\n  }\n\n  join(...path: string[]): URI {\n    return this.with({\n      path: ensureSuffix(this.path, _slash) + path.join(_slash)\n    })\n  }\n\n  // ---- printing/externalize ---------------------------\n\n  /**\n   * Creates a string representation for this URI. It's guaranteed that calling\n   * `URI.parse` with the result of this function creates an URI which is equal\n   * to this URI.\n   *\n   * * The result shall *not* be used for display purposes but for externalization or transport.\n   * * The result will be encoded using the percentage encoding and encoding happens mostly\n   * ignore the scheme-specific encoding rules.\n   *\n   * @param skipEncoding Do not encode the result, default is `false`\n   */\n  toString(skipEncoding: boolean = false): string {\n    return _asFormatted(this, skipEncoding)\n  }\n\n  toJSON(): UriComponents {\n    return this\n  }\n\n  [inspect.custom]() {\n    return this.toString()\n  }\n}\n\nexport interface UriComponents {\n  scheme: string\n  authority: string\n  path: string\n  query: string\n  fragment: string\n}\n\ninterface UriState extends UriComponents {\n  $mid: number\n  external: string\n  fsPath: string\n  _sep: 1 | undefined\n}\n\nconst _pathSepMarker = isWinPortable ? 1 : undefined\n\n// This class exists so that URI is compatible with vscode.Uri (API).\nclass Uri extends URI {\n  _formatted: string | null = null\n  _fsPath: string | null = null\n\n  get fsPath(): string {\n    if (this._fsPath == null) {\n      this._fsPath = uriToFsPath(this, false)\n    }\n    return this._fsPath\n  }\n\n  toString(skipEncoding: boolean = false): string {\n    if (!skipEncoding) {\n      if (this._formatted == null) {\n        this._formatted = _asFormatted(this, false)\n      }\n      return this._formatted\n    } else {\n      // we don't cache that\n      return _asFormatted(this, true)\n    }\n  }\n\n  toJSON(): UriComponents {\n    const res = <UriState>{\n      $mid: 1\n    }\n    // cached state\n    if (this._fsPath != null) {\n      res.fsPath = this._fsPath\n      res._sep = _pathSepMarker\n    }\n    if (this._formatted != null) {\n      res.external = this._formatted\n    }\n    // uri components\n    if (this.path) {\n      res.path = this.path\n    }\n    if (this.scheme) {\n      res.scheme = this.scheme\n    }\n    if (this.authority) {\n      res.authority = this.authority\n    }\n    if (this.query) {\n      res.query = this.query\n    }\n    if (this.fragment) {\n      res.fragment = this.fragment\n    }\n    return res\n  }\n}\n\n// reserved characters: https://tools.ietf.org/html/rfc3986#section-2.2\nconst encodeTable: { [ch: number]: string } = {\n  [CharCode.Colon]: \"%3A\", // gen-delims\n  [CharCode.Slash]: \"%2F\",\n  [CharCode.QuestionMark]: \"%3F\",\n  [CharCode.Hash]: \"%23\",\n  [CharCode.OpenSquareBracket]: \"%5B\",\n  [CharCode.CloseSquareBracket]: \"%5D\",\n  [CharCode.AtSign]: \"%40\",\n\n  [CharCode.ExclamationMark]: \"%21\", // sub-delims\n  [CharCode.DollarSign]: \"%24\",\n  [CharCode.Ampersand]: \"%26\",\n  [CharCode.SingleQuote]: \"%27\",\n  [CharCode.OpenParen]: \"%28\",\n  [CharCode.CloseParen]: \"%29\",\n  [CharCode.Asterisk]: \"%2A\",\n  [CharCode.Plus]: \"%2B\",\n  [CharCode.Comma]: \"%2C\",\n  [CharCode.Semicolon]: \"%3B\",\n  [CharCode.Equals]: \"%3D\",\n\n  [CharCode.Space]: \"%20\"\n}\n\nexport function encodeURIComponentFast(\n  uriComponent: string,\n  allowSlash: boolean\n): string {\n  let res: string | undefined\n  let nativeEncodePos = -1\n\n  for (let pos = 0; pos < uriComponent.length; pos++) {\n    const code = uriComponent.charCodeAt(pos)\n\n    // unreserved characters: https://tools.ietf.org/html/rfc3986#section-2.3\n    if (\n      (code >= CharCode.a && code <= CharCode.z) ||\n      (code >= CharCode.A && code <= CharCode.Z) ||\n      (code >= CharCode.Digit0 && code <= CharCode.Digit9) ||\n      code === CharCode.Dash ||\n      code === CharCode.Period ||\n      code === CharCode.Underline ||\n      code === CharCode.Tilde ||\n      (allowSlash && code === CharCode.Slash)\n    ) {\n      // check if we are delaying native encode\n      if (nativeEncodePos !== -1) {\n        res += encodeURIComponent(uriComponent.substring(nativeEncodePos, pos))\n        nativeEncodePos = -1\n      }\n      // check if we write into a new string (by default we try to return the param)\n      if (res !== undefined) {\n        res += uriComponent.charAt(pos)\n      }\n    } else {\n      // encoding needed, we need to allocate a new string\n      if (res === undefined) {\n        res = uriComponent.substr(0, pos)\n      }\n\n      // check with default table first\n      const escaped = encodeTable[code]\n      if (escaped !== undefined) {\n        // check if we are delaying native encode\n        if (nativeEncodePos !== -1) {\n          res += encodeURIComponent(\n            uriComponent.substring(nativeEncodePos, pos)\n          )\n          nativeEncodePos = -1\n        }\n\n        // append escaped variant to result\n        res += escaped\n      } else if (nativeEncodePos === -1) {\n        // use native encode only when needed\n        nativeEncodePos = pos\n      }\n    }\n  }\n\n  if (nativeEncodePos !== -1) {\n    res += encodeURIComponent(uriComponent.substring(nativeEncodePos))\n  }\n\n  return res !== undefined ? res : uriComponent\n}\n\nfunction encodeURIComponentMinimal(path: string): string {\n  let res: string | undefined\n  for (let pos = 0; pos < path.length; pos++) {\n    const code = path.charCodeAt(pos)\n    if (code === CharCode.Hash || code === CharCode.QuestionMark) {\n      if (res === undefined) {\n        res = path.substr(0, pos)\n      }\n      res += encodeTable[code]\n    } else {\n      if (res !== undefined) {\n        res += path[pos]\n      }\n    }\n  }\n  return res !== undefined ? res : path\n}\n\n/**\n * Compute `fsPath` for the given uri\n */\nexport function uriToFsPath(uri: URI, keepDriveLetterCasing: boolean): string {\n  let value: string\n  if (uri.authority && uri.path.length > 1 && uri.scheme === \"file\") {\n    // unc path: file://shares/c$/far/boo\n    value = `//${uri.authority}${uri.path}`\n  } else if (\n    uri.path.charCodeAt(0) === CharCode.Slash &&\n    ((uri.path.charCodeAt(1) >= CharCode.A &&\n      uri.path.charCodeAt(1) <= CharCode.Z) ||\n      (uri.path.charCodeAt(1) >= CharCode.a &&\n        uri.path.charCodeAt(1) <= CharCode.z)) &&\n    uri.path.charCodeAt(2) === CharCode.Colon\n  ) {\n    if (!keepDriveLetterCasing) {\n      // windows drive letter: file:///c:/far/boo\n      value = uri.path[1].toLowerCase() + uri.path.substr(2)\n    } else {\n      value = uri.path.substr(1)\n    }\n  } else {\n    // other path\n    value = uri.path\n  }\n  if (isWin) {\n    value = value.replace(/\\//g, \"\\\\\")\n  }\n  return value\n}\n\n/**\n * Create the external version of a uri\n */\nfunction _asFormatted(uri: URI, skipEncoding: boolean): string {\n  const encoder = !skipEncoding\n    ? encodeURIComponentFast\n    : encodeURIComponentMinimal\n\n  let res = \"\"\n  const { scheme, query, fragment } = uri\n  let { authority, path } = uri\n  if (scheme) {\n    res += scheme\n    res += \":\"\n  }\n  if (authority || scheme === \"file\") {\n    res += _slash\n    res += _slash\n  }\n  if (authority) {\n    let idx = authority.indexOf(\"@\")\n    if (idx !== -1) {\n      // <user>@<auth>\n      const userinfo = authority.substr(0, idx)\n      authority = authority.substr(idx + 1)\n      idx = userinfo.indexOf(\":\")\n      if (idx === -1) {\n        res += encoder(userinfo, false)\n      } else {\n        // <user>:<pass>@<auth>\n        res += encoder(userinfo.substr(0, idx), false)\n        res += \":\"\n        res += encoder(userinfo.substr(idx + 1), false)\n      }\n      res += \"@\"\n    }\n    // MRM 20200815: DON'T DOWNCASE:\n    // authority = authority.toLowerCase()\n    idx = authority.indexOf(\":\")\n    if (idx === -1) {\n      res += encoder(authority, false)\n    } else {\n      // <auth>:<port>\n      res += encoder(authority.substr(0, idx), false)\n      res += authority.substr(idx)\n    }\n  }\n  if (path) {\n    // lower-case windows drive letters in /C:/fff or C:/fff\n    if (\n      path.length >= 3 &&\n      path.charCodeAt(0) === CharCode.Slash &&\n      path.charCodeAt(2) === CharCode.Colon\n    ) {\n      const code = path.charCodeAt(1)\n      if (code >= CharCode.A && code <= CharCode.Z) {\n        path = `/${String.fromCharCode(code + 32)}:${path.substr(3)}` // \"/c:\".length === 3\n      }\n    } else if (path.length >= 2 && path.charCodeAt(1) === CharCode.Colon) {\n      const code = path.charCodeAt(0)\n      if (code >= CharCode.A && code <= CharCode.Z) {\n        path = `${String.fromCharCode(code + 32)}:${path.substr(2)}` // \"/c:\".length === 3\n      }\n    }\n    // encode the rest of the path\n    res += encoder(path, true)\n  }\n  if (query) {\n    res += \"?\"\n    res += encoder(query, false)\n  }\n  if (fragment) {\n    res += \"#\"\n    res += !skipEncoding ? encodeURIComponentFast(fragment, false) : fragment\n  }\n  return res\n}\n\n// --- decode\n\nfunction decodeURIComponentGraceful(str: string): string {\n  try {\n    return decodeURIComponent(str)\n  } catch {\n    if (str.length > 3) {\n      return str.substr(0, 3) + decodeURIComponentGraceful(str.substr(3))\n    } else {\n      return str\n    }\n  }\n}\n\nconst _rEncodedAsHex = /(%[0-9A-Za-z][0-9A-Za-z])+/g\n\nfunction percentDecode(str: string): string {\n  if (str.startsWith(\"xn--\")) return toUnicode(str)\n  if (!str.match(_rEncodedAsHex)) {\n    return str\n  }\n  return str.replace(_rEncodedAsHex, match => decodeURIComponentGraceful(match))\n}\n\nexport function toURI(u: string | URI): URI {\n  return URI.isUri(u) ? u : URI.parse(u)\n}\n", "/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\n// Names from https://blog.codinghorror.com/ascii-pronunciation-rules-for-programmers/\n\n/**\n * An inlined enum containing useful character codes (to be used with String.charCodeAt).\n * Please leave the const keyword such that it gets inlined when compiled to JavaScript!\n */\nexport const enum CharCode {\n  Null = 0,\n  /**\n   * The `\\b` character.\n   */\n  Backspace = 8,\n  /**\n   * The `\\t` character.\n   */\n  Tab = 9,\n  /**\n   * The `\\n` character.\n   */\n  LineFeed = 10,\n  /**\n   * The `\\r` character.\n   */\n  CarriageReturn = 13,\n  Space = 32,\n  /**\n   * The `!` character.\n   */\n  ExclamationMark = 33,\n  /**\n   * The `\"` character.\n   */\n  DoubleQuote = 34,\n  /**\n   * The `#` character.\n   */\n  Hash = 35,\n  /**\n   * The `$` character.\n   */\n  DollarSign = 36,\n  /**\n   * The `%` character.\n   */\n  PercentSign = 37,\n  /**\n   * The `&` character.\n   */\n  Ampersand = 38,\n  /**\n   * The `'` character.\n   */\n  SingleQuote = 39,\n  /**\n   * The `(` character.\n   */\n  OpenParen = 40,\n  /**\n   * The `)` character.\n   */\n  CloseParen = 41,\n  /**\n   * The `*` character.\n   */\n  Asterisk = 42,\n  /**\n   * The `+` character.\n   */\n  Plus = 43,\n  /**\n   * The `,` character.\n   */\n  Comma = 44,\n  /**\n   * The `-` character.\n   */\n  Dash = 45,\n  /**\n   * The `.` character.\n   */\n  Period = 46,\n  /**\n   * The `/` character.\n   */\n  Slash = 47,\n\n  Digit0 = 48,\n  Digit1 = 49,\n  Digit2 = 50,\n  Digit3 = 51,\n  Digit4 = 52,\n  Digit5 = 53,\n  Digit6 = 54,\n  Digit7 = 55,\n  Digit8 = 56,\n  Digit9 = 57,\n\n  /**\n   * The `:` character.\n   */\n  Colon = 58,\n  /**\n   * The `;` character.\n   */\n  Semicolon = 59,\n  /**\n   * The `<` character.\n   */\n  LessThan = 60,\n  /**\n   * The `=` character.\n   */\n  Equals = 61,\n  /**\n   * The `>` character.\n   */\n  GreaterThan = 62,\n  /**\n   * The `?` character.\n   */\n  QuestionMark = 63,\n  /**\n   * The `@` character.\n   */\n  AtSign = 64,\n\n  A = 65,\n  B = 66,\n  C = 67,\n  D = 68,\n  E = 69,\n  F = 70,\n  G = 71,\n  H = 72,\n  I = 73,\n  J = 74,\n  K = 75,\n  L = 76,\n  M = 77,\n  N = 78,\n  O = 79,\n  P = 80,\n  Q = 81,\n  R = 82,\n  S = 83,\n  T = 84,\n  U = 85,\n  V = 86,\n  W = 87,\n  X = 88,\n  Y = 89,\n  Z = 90,\n\n  /**\n   * The `[` character.\n   */\n  OpenSquareBracket = 91,\n  /**\n   * The `\\` character.\n   */\n  Backslash = 92,\n  /**\n   * The `]` character.\n   */\n  CloseSquareBracket = 93,\n  /**\n   * The `^` character.\n   */\n  Caret = 94,\n  /**\n   * The `_` character.\n   */\n  Underline = 95,\n  /**\n   * The ``(`)`` character.\n   */\n  BackTick = 96,\n\n  a = 97,\n  b = 98,\n  c = 99,\n  d = 100,\n  e = 101,\n  f = 102,\n  g = 103,\n  h = 104,\n  i = 105,\n  j = 106,\n  k = 107,\n  l = 108,\n  m = 109,\n  n = 110,\n  o = 111,\n  p = 112,\n  q = 113,\n  r = 114,\n  s = 115,\n  t = 116,\n  u = 117,\n  v = 118,\n  w = 119,\n  x = 120,\n  y = 121,\n  z = 122,\n\n  /**\n   * The `{` character.\n   */\n  OpenCurlyBrace = 123,\n  /**\n   * The `|` character.\n   */\n  Pipe = 124,\n  /**\n   * The `}` character.\n   */\n  CloseCurlyBrace = 125,\n  /**\n   * The `~` character.\n   */\n  Tilde = 126,\n\n  U_Combining_Grave_Accent = 0x0300, //\tU+0300\tCombining Grave Accent\n  U_Combining_Acute_Accent = 0x0301, //\tU+0301\tCombining Acute Accent\n  U_Combining_Circumflex_Accent = 0x0302, //\tU+0302\tCombining Circumflex Accent\n  U_Combining_Tilde = 0x0303, //\tU+0303\tCombining Tilde\n  U_Combining_Macron = 0x0304, //\tU+0304\tCombining Macron\n  U_Combining_Overline = 0x0305, //\tU+0305\tCombining Overline\n  U_Combining_Breve = 0x0306, //\tU+0306\tCombining Breve\n  U_Combining_Dot_Above = 0x0307, //\tU+0307\tCombining Dot Above\n  U_Combining_Diaeresis = 0x0308, //\tU+0308\tCombining Diaeresis\n  U_Combining_Hook_Above = 0x0309, //\tU+0309\tCombining Hook Above\n  U_Combining_Ring_Above = 0x030a, //\tU+030A\tCombining Ring Above\n  U_Combining_Double_Acute_Accent = 0x030b, //\tU+030B\tCombining Double Acute Accent\n  U_Combining_Caron = 0x030c, //\tU+030C\tCombining Caron\n  U_Combining_Vertical_Line_Above = 0x030d, //\tU+030D\tCombining Vertical Line Above\n  U_Combining_Double_Vertical_Line_Above = 0x030e, //\tU+030E\tCombining Double Vertical Line Above\n  U_Combining_Double_Grave_Accent = 0x030f, //\tU+030F\tCombining Double Grave Accent\n  U_Combining_Candrabindu = 0x0310, //\tU+0310\tCombining Candrabindu\n  U_Combining_Inverted_Breve = 0x0311, //\tU+0311\tCombining Inverted Breve\n  U_Combining_Turned_Comma_Above = 0x0312, //\tU+0312\tCombining Turned Comma Above\n  U_Combining_Comma_Above = 0x0313, //\tU+0313\tCombining Comma Above\n  U_Combining_Reversed_Comma_Above = 0x0314, //\tU+0314\tCombining Reversed Comma Above\n  U_Combining_Comma_Above_Right = 0x0315, //\tU+0315\tCombining Comma Above Right\n  U_Combining_Grave_Accent_Below = 0x0316, //\tU+0316\tCombining Grave Accent Below\n  U_Combining_Acute_Accent_Below = 0x0317, //\tU+0317\tCombining Acute Accent Below\n  U_Combining_Left_Tack_Below = 0x0318, //\tU+0318\tCombining Left Tack Below\n  U_Combining_Right_Tack_Below = 0x0319, //\tU+0319\tCombining Right Tack Below\n  U_Combining_Left_Angle_Above = 0x031a, //\tU+031A\tCombining Left Angle Above\n  U_Combining_Horn = 0x031b, //\tU+031B\tCombining Horn\n  U_Combining_Left_Half_Ring_Below = 0x031c, //\tU+031C\tCombining Left Half Ring Below\n  U_Combining_Up_Tack_Below = 0x031d, //\tU+031D\tCombining Up Tack Below\n  U_Combining_Down_Tack_Below = 0x031e, //\tU+031E\tCombining Down Tack Below\n  U_Combining_Plus_Sign_Below = 0x031f, //\tU+031F\tCombining Plus Sign Below\n  U_Combining_Minus_Sign_Below = 0x0320, //\tU+0320\tCombining Minus Sign Below\n  U_Combining_Palatalized_Hook_Below = 0x0321, //\tU+0321\tCombining Palatalized Hook Below\n  U_Combining_Retroflex_Hook_Below = 0x0322, //\tU+0322\tCombining Retroflex Hook Below\n  U_Combining_Dot_Below = 0x0323, //\tU+0323\tCombining Dot Below\n  U_Combining_Diaeresis_Below = 0x0324, //\tU+0324\tCombining Diaeresis Below\n  U_Combining_Ring_Below = 0x0325, //\tU+0325\tCombining Ring Below\n  U_Combining_Comma_Below = 0x0326, //\tU+0326\tCombining Comma Below\n  U_Combining_Cedilla = 0x0327, //\tU+0327\tCombining Cedilla\n  U_Combining_Ogonek = 0x0328, //\tU+0328\tCombining Ogonek\n  U_Combining_Vertical_Line_Below = 0x0329, //\tU+0329\tCombining Vertical Line Below\n  U_Combining_Bridge_Below = 0x032a, //\tU+032A\tCombining Bridge Below\n  U_Combining_Inverted_Double_Arch_Below = 0x032b, //\tU+032B\tCombining Inverted Double Arch Below\n  U_Combining_Caron_Below = 0x032c, //\tU+032C\tCombining Caron Below\n  U_Combining_Circumflex_Accent_Below = 0x032d, //\tU+032D\tCombining Circumflex Accent Below\n  U_Combining_Breve_Below = 0x032e, //\tU+032E\tCombining Breve Below\n  U_Combining_Inverted_Breve_Below = 0x032f, //\tU+032F\tCombining Inverted Breve Below\n  U_Combining_Tilde_Below = 0x0330, //\tU+0330\tCombining Tilde Below\n  U_Combining_Macron_Below = 0x0331, //\tU+0331\tCombining Macron Below\n  U_Combining_Low_Line = 0x0332, //\tU+0332\tCombining Low Line\n  U_Combining_Double_Low_Line = 0x0333, //\tU+0333\tCombining Double Low Line\n  U_Combining_Tilde_Overlay = 0x0334, //\tU+0334\tCombining Tilde Overlay\n  U_Combining_Short_Stroke_Overlay = 0x0335, //\tU+0335\tCombining Short Stroke Overlay\n  U_Combining_Long_Stroke_Overlay = 0x0336, //\tU+0336\tCombining Long Stroke Overlay\n  U_Combining_Short_Solidus_Overlay = 0x0337, //\tU+0337\tCombining Short Solidus Overlay\n  U_Combining_Long_Solidus_Overlay = 0x0338, //\tU+0338\tCombining Long Solidus Overlay\n  U_Combining_Right_Half_Ring_Below = 0x0339, //\tU+0339\tCombining Right Half Ring Below\n  U_Combining_Inverted_Bridge_Below = 0x033a, //\tU+033A\tCombining Inverted Bridge Below\n  U_Combining_Square_Below = 0x033b, //\tU+033B\tCombining Square Below\n  U_Combining_Seagull_Below = 0x033c, //\tU+033C\tCombining Seagull Below\n  U_Combining_X_Above = 0x033d, //\tU+033D\tCombining X Above\n  U_Combining_Vertical_Tilde = 0x033e, //\tU+033E\tCombining Vertical Tilde\n  U_Combining_Double_Overline = 0x033f, //\tU+033F\tCombining Double Overline\n  U_Combining_Grave_Tone_Mark = 0x0340, //\tU+0340\tCombining Grave Tone Mark\n  U_Combining_Acute_Tone_Mark = 0x0341, //\tU+0341\tCombining Acute Tone Mark\n  U_Combining_Greek_Perispomeni = 0x0342, //\tU+0342\tCombining Greek Perispomeni\n  U_Combining_Greek_Koronis = 0x0343, //\tU+0343\tCombining Greek Koronis\n  U_Combining_Greek_Dialytika_Tonos = 0x0344, //\tU+0344\tCombining Greek Dialytika Tonos\n  U_Combining_Greek_Ypogegrammeni = 0x0345, //\tU+0345\tCombining Greek Ypogegrammeni\n  U_Combining_Bridge_Above = 0x0346, //\tU+0346\tCombining Bridge Above\n  U_Combining_Equals_Sign_Below = 0x0347, //\tU+0347\tCombining Equals Sign Below\n  U_Combining_Double_Vertical_Line_Below = 0x0348, //\tU+0348\tCombining Double Vertical Line Below\n  U_Combining_Left_Angle_Below = 0x0349, //\tU+0349\tCombining Left Angle Below\n  U_Combining_Not_Tilde_Above = 0x034a, //\tU+034A\tCombining Not Tilde Above\n  U_Combining_Homothetic_Above = 0x034b, //\tU+034B\tCombining Homothetic Above\n  U_Combining_Almost_Equal_To_Above = 0x034c, //\tU+034C\tCombining Almost Equal To Above\n  U_Combining_Left_Right_Arrow_Below = 0x034d, //\tU+034D\tCombining Left Right Arrow Below\n  U_Combining_Upwards_Arrow_Below = 0x034e, //\tU+034E\tCombining Upwards Arrow Below\n  U_Combining_Grapheme_Joiner = 0x034f, //\tU+034F\tCombining Grapheme Joiner\n  U_Combining_Right_Arrowhead_Above = 0x0350, //\tU+0350\tCombining Right Arrowhead Above\n  U_Combining_Left_Half_Ring_Above = 0x0351, //\tU+0351\tCombining Left Half Ring Above\n  U_Combining_Fermata = 0x0352, //\tU+0352\tCombining Fermata\n  U_Combining_X_Below = 0x0353, //\tU+0353\tCombining X Below\n  U_Combining_Left_Arrowhead_Below = 0x0354, //\tU+0354\tCombining Left Arrowhead Below\n  U_Combining_Right_Arrowhead_Below = 0x0355, //\tU+0355\tCombining Right Arrowhead Below\n  U_Combining_Right_Arrowhead_And_Up_Arrowhead_Below = 0x0356, //\tU+0356\tCombining Right Arrowhead And Up Arrowhead Below\n  U_Combining_Right_Half_Ring_Above = 0x0357, //\tU+0357\tCombining Right Half Ring Above\n  U_Combining_Dot_Above_Right = 0x0358, //\tU+0358\tCombining Dot Above Right\n  U_Combining_Asterisk_Below = 0x0359, //\tU+0359\tCombining Asterisk Below\n  U_Combining_Double_Ring_Below = 0x035a, //\tU+035A\tCombining Double Ring Below\n  U_Combining_Zigzag_Above = 0x035b, //\tU+035B\tCombining Zigzag Above\n  U_Combining_Double_Breve_Below = 0x035c, //\tU+035C\tCombining Double Breve Below\n  U_Combining_Double_Breve = 0x035d, //\tU+035D\tCombining Double Breve\n  U_Combining_Double_Macron = 0x035e, //\tU+035E\tCombining Double Macron\n  U_Combining_Double_Macron_Below = 0x035f, //\tU+035F\tCombining Double Macron Below\n  U_Combining_Double_Tilde = 0x0360, //\tU+0360\tCombining Double Tilde\n  U_Combining_Double_Inverted_Breve = 0x0361, //\tU+0361\tCombining Double Inverted Breve\n  U_Combining_Double_Rightwards_Arrow_Below = 0x0362, //\tU+0362\tCombining Double Rightwards Arrow Below\n  U_Combining_Latin_Small_Letter_A = 0x0363, //\tU+0363\tCombining Latin Small Letter A\n  U_Combining_Latin_Small_Letter_E = 0x0364, //\tU+0364\tCombining Latin Small Letter E\n  U_Combining_Latin_Small_Letter_I = 0x0365, //\tU+0365\tCombining Latin Small Letter I\n  U_Combining_Latin_Small_Letter_O = 0x0366, //\tU+0366\tCombining Latin Small Letter O\n  U_Combining_Latin_Small_Letter_U = 0x0367, //\tU+0367\tCombining Latin Small Letter U\n  U_Combining_Latin_Small_Letter_C = 0x0368, //\tU+0368\tCombining Latin Small Letter C\n  U_Combining_Latin_Small_Letter_D = 0x0369, //\tU+0369\tCombining Latin Small Letter D\n  U_Combining_Latin_Small_Letter_H = 0x036a, //\tU+036A\tCombining Latin Small Letter H\n  U_Combining_Latin_Small_Letter_M = 0x036b, //\tU+036B\tCombining Latin Small Letter M\n  U_Combining_Latin_Small_Letter_R = 0x036c, //\tU+036C\tCombining Latin Small Letter R\n  U_Combining_Latin_Small_Letter_T = 0x036d, //\tU+036D\tCombining Latin Small Letter T\n  U_Combining_Latin_Small_Letter_V = 0x036e, //\tU+036E\tCombining Latin Small Letter V\n  U_Combining_Latin_Small_Letter_X = 0x036f, //\tU+036F\tCombining Latin Small Letter X\n\n  /**\n   * Unicode Character 'LINE SEPARATOR' (U+2028)\n   * http://www.fileformat.info/info/unicode/char/2028/index.htm\n   */\n  LINE_SEPARATOR = 0x2028,\n  /**\n   * Unicode Character 'PARAGRAPH SEPARATOR' (U+2029)\n   * http://www.fileformat.info/info/unicode/char/2029/index.htm\n   */\n  PARAGRAPH_SEPARATOR = 0x2029,\n  /**\n   * Unicode Character 'NEXT LINE' (U+0085)\n   * http://www.fileformat.info/info/unicode/char/0085/index.htm\n   */\n  NEXT_LINE = 0x0085,\n\n  // http://www.fileformat.info/info/unicode/category/Sk/list.htm\n  U_CIRCUMFLEX = 0x005e, // U+005E\tCIRCUMFLEX\n  U_GRAVE_ACCENT = 0x0060, // U+0060\tGRAVE ACCENT\n  U_DIAERESIS = 0x00a8, // U+00A8\tDIAERESIS\n  U_MACRON = 0x00af, // U+00AF\tMACRON\n  U_ACUTE_ACCENT = 0x00b4, // U+00B4\tACUTE ACCENT\n  U_CEDILLA = 0x00b8, // U+00B8\tCEDILLA\n  U_MODIFIER_LETTER_LEFT_ARROWHEAD = 0x02c2, // U+02C2\tMODIFIER LETTER LEFT ARROWHEAD\n  U_MODIFIER_LETTER_RIGHT_ARROWHEAD = 0x02c3, // U+02C3\tMODIFIER LETTER RIGHT ARROWHEAD\n  U_MODIFIER_LETTER_UP_ARROWHEAD = 0x02c4, // U+02C4\tMODIFIER LETTER UP ARROWHEAD\n  U_MODIFIER_LETTER_DOWN_ARROWHEAD = 0x02c5, // U+02C5\tMODIFIER LETTER DOWN ARROWHEAD\n  U_MODIFIER_LETTER_CENTRED_RIGHT_HALF_RING = 0x02d2, // U+02D2\tMODIFIER LETTER CENTRED RIGHT HALF RING\n  U_MODIFIER_LETTER_CENTRED_LEFT_HALF_RING = 0x02d3, // U+02D3\tMODIFIER LETTER CENTRED LEFT HALF RING\n  U_MODIFIER_LETTER_UP_TACK = 0x02d4, // U+02D4\tMODIFIER LETTER UP TACK\n  U_MODIFIER_LETTER_DOWN_TACK = 0x02d5, // U+02D5\tMODIFIER LETTER DOWN TACK\n  U_MODIFIER_LETTER_PLUS_SIGN = 0x02d6, // U+02D6\tMODIFIER LETTER PLUS SIGN\n  U_MODIFIER_LETTER_MINUS_SIGN = 0x02d7, // U+02D7\tMODIFIER LETTER MINUS SIGN\n  U_BREVE = 0x02d8, // U+02D8\tBREVE\n  U_DOT_ABOVE = 0x02d9, // U+02D9\tDOT ABOVE\n  U_RING_ABOVE = 0x02da, // U+02DA\tRING ABOVE\n  U_OGONEK = 0x02db, // U+02DB\tOGONEK\n  U_SMALL_TILDE = 0x02dc, // U+02DC\tSMALL TILDE\n  U_DOUBLE_ACUTE_ACCENT = 0x02dd, // U+02DD\tDOUBLE ACUTE ACCENT\n  U_MODIFIER_LETTER_RHOTIC_HOOK = 0x02de, // U+02DE\tMODIFIER LETTER RHOTIC HOOK\n  U_MODIFIER_LETTER_CROSS_ACCENT = 0x02df, // U+02DF\tMODIFIER LETTER CROSS ACCENT\n  U_MODIFIER_LETTER_EXTRA_HIGH_TONE_BAR = 0x02e5, // U+02E5\tMODIFIER LETTER EXTRA-HIGH TONE BAR\n  U_MODIFIER_LETTER_HIGH_TONE_BAR = 0x02e6, // U+02E6\tMODIFIER LETTER HIGH TONE BAR\n  U_MODIFIER_LETTER_MID_TONE_BAR = 0x02e7, // U+02E7\tMODIFIER LETTER MID TONE BAR\n  U_MODIFIER_LETTER_LOW_TONE_BAR = 0x02e8, // U+02E8\tMODIFIER LETTER LOW TONE BAR\n  U_MODIFIER_LETTER_EXTRA_LOW_TONE_BAR = 0x02e9, // U+02E9\tMODIFIER LETTER EXTRA-LOW TONE BAR\n  U_MODIFIER_LETTER_YIN_DEPARTING_TONE_MARK = 0x02ea, // U+02EA\tMODIFIER LETTER YIN DEPARTING TONE MARK\n  U_MODIFIER_LETTER_YANG_DEPARTING_TONE_MARK = 0x02eb, // U+02EB\tMODIFIER LETTER YANG DEPARTING TONE MARK\n  U_MODIFIER_LETTER_UNASPIRATED = 0x02ed, // U+02ED\tMODIFIER LETTER UNASPIRATED\n  U_MODIFIER_LETTER_LOW_DOWN_ARROWHEAD = 0x02ef, // U+02EF\tMODIFIER LETTER LOW DOWN ARROWHEAD\n  U_MODIFIER_LETTER_LOW_UP_ARROWHEAD = 0x02f0, // U+02F0\tMODIFIER LETTER LOW UP ARROWHEAD\n  U_MODIFIER_LETTER_LOW_LEFT_ARROWHEAD = 0x02f1, // U+02F1\tMODIFIER LETTER LOW LEFT ARROWHEAD\n  U_MODIFIER_LETTER_LOW_RIGHT_ARROWHEAD = 0x02f2, // U+02F2\tMODIFIER LETTER LOW RIGHT ARROWHEAD\n  U_MODIFIER_LETTER_LOW_RING = 0x02f3, // U+02F3\tMODIFIER LETTER LOW RING\n  U_MODIFIER_LETTER_MIDDLE_GRAVE_ACCENT = 0x02f4, // U+02F4\tMODIFIER LETTER MIDDLE GRAVE ACCENT\n  U_MODIFIER_LETTER_MIDDLE_DOUBLE_GRAVE_ACCENT = 0x02f5, // U+02F5\tMODIFIER LETTER MIDDLE DOUBLE GRAVE ACCENT\n  U_MODIFIER_LETTER_MIDDLE_DOUBLE_ACUTE_ACCENT = 0x02f6, // U+02F6\tMODIFIER LETTER MIDDLE DOUBLE ACUTE ACCENT\n  U_MODIFIER_LETTER_LOW_TILDE = 0x02f7, // U+02F7\tMODIFIER LETTER LOW TILDE\n  U_MODIFIER_LETTER_RAISED_COLON = 0x02f8, // U+02F8\tMODIFIER LETTER RAISED COLON\n  U_MODIFIER_LETTER_BEGIN_HIGH_TONE = 0x02f9, // U+02F9\tMODIFIER LETTER BEGIN HIGH TONE\n  U_MODIFIER_LETTER_END_HIGH_TONE = 0x02fa, // U+02FA\tMODIFIER LETTER END HIGH TONE\n  U_MODIFIER_LETTER_BEGIN_LOW_TONE = 0x02fb, // U+02FB\tMODIFIER LETTER BEGIN LOW TONE\n  U_MODIFIER_LETTER_END_LOW_TONE = 0x02fc, // U+02FC\tMODIFIER LETTER END LOW TONE\n  U_MODIFIER_LETTER_SHELF = 0x02fd, // U+02FD\tMODIFIER LETTER SHELF\n  U_MODIFIER_LETTER_OPEN_SHELF = 0x02fe, // U+02FE\tMODIFIER LETTER OPEN SHELF\n  U_MODIFIER_LETTER_LOW_LEFT_ARROW = 0x02ff, // U+02FF\tMODIFIER LETTER LOW LEFT ARROW\n  U_GREEK_LOWER_NUMERAL_SIGN = 0x0375, // U+0375\tGREEK LOWER NUMERAL SIGN\n  U_GREEK_TONOS = 0x0384, // U+0384\tGREEK TONOS\n  U_GREEK_DIALYTIKA_TONOS = 0x0385, // U+0385\tGREEK DIALYTIKA TONOS\n  U_GREEK_KORONIS = 0x1fbd, // U+1FBD\tGREEK KORONIS\n  U_GREEK_PSILI = 0x1fbf, // U+1FBF\tGREEK PSILI\n  U_GREEK_PERISPOMENI = 0x1fc0, // U+1FC0\tGREEK PERISPOMENI\n  U_GREEK_DIALYTIKA_AND_PERISPOMENI = 0x1fc1, // U+1FC1\tGREEK DIALYTIKA AND PERISPOMENI\n  U_GREEK_PSILI_AND_VARIA = 0x1fcd, // U+1FCD\tGREEK PSILI AND VARIA\n  U_GREEK_PSILI_AND_OXIA = 0x1fce, // U+1FCE\tGREEK PSILI AND OXIA\n  U_GREEK_PSILI_AND_PERISPOMENI = 0x1fcf, // U+1FCF\tGREEK PSILI AND PERISPOMENI\n  U_GREEK_DASIA_AND_VARIA = 0x1fdd, // U+1FDD\tGREEK DASIA AND VARIA\n  U_GREEK_DASIA_AND_OXIA = 0x1fde, // U+1FDE\tGREEK DASIA AND OXIA\n  U_GREEK_DASIA_AND_PERISPOMENI = 0x1fdf, // U+1FDF\tGREEK DASIA AND PERISPOMENI\n  U_GREEK_DIALYTIKA_AND_VARIA = 0x1fed, // U+1FED\tGREEK DIALYTIKA AND VARIA\n  U_GREEK_DIALYTIKA_AND_OXIA = 0x1fee, // U+1FEE\tGREEK DIALYTIKA AND OXIA\n  U_GREEK_VARIA = 0x1fef, // U+1FEF\tGREEK VARIA\n  U_GREEK_OXIA = 0x1ffd, // U+1FFD\tGREEK OXIA\n  U_GREEK_DASIA = 0x1ffe, // U+1FFE\tGREEK DASIA\n\n  U_OVERLINE = 0x203e, // Unicode Character 'OVERLINE'\n\n  /**\n   * UTF-8 BOM\n   * Unicode Character 'ZERO WIDTH NO-BREAK SPACE' (U+FEFF)\n   * http://www.fileformat.info/info/unicode/char/feff/index.htm\n   */\n  UTF8_BOM = 65279\n}\n", "import { join } from \"path\"\nimport { blank } from \"../../fe/Blank\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { PS_LIBRARY_PROTOCOL } from \"../../fe/URI\"\nimport { posixPathFrom } from \"../fs/Path\"\nimport { Settings } from \"../settings/Settings\"\nimport { URI } from \"./URI\"\n\nexport const PSLIB_ROOT_URI = URI.from({\n  scheme: PS_LIBRARY_PROTOCOL,\n  path: \"\"\n})\n\nexport function nativePath2pslib(nativePath: string) {\n  const lp = Settings.libraryPath.value\n\n  if (blank(lp) || blank(nativePath) || !nativePath.startsWith(lp)) return\n\n  const path = \"/\" + posixPathFrom({ nativePath: lp }, { nativePath })\n\n  return URI.from({\n    scheme: PS_LIBRARY_PROTOCOL,\n    path\n  })\n}\n\nexport function pslib2nativePath(uri: URI): Maybe<string> {\n  if (uri.scheme !== PS_LIBRARY_PROTOCOL) {\n    throw new Error(\"invalid URI: \" + uri + \" (bad scheme)\")\n  }\n\n  const lp = Settings.libraryPath.value\n\n  if (blank(lp)) {\n    throw new Error(\"invalid URI: \" + uri + \" (no library set)\")\n  }\n\n  return join(lp, ...uri.path.split(\"/\"))\n}\n", "import { join, posix, sep } from \"path\"\nimport { blank, notBlank } from \"../../fe/Blank\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { toA } from \"../../fe/toA\"\nimport { PS_NETWORK_FILESYSTEM_PROTOCOL } from \"../../fe/URI\"\nimport { native2posix, nativePathIsReadableDirectory } from \"../fs/Path\"\nimport { isEquivalentHost } from \"../net/nslookup\"\nimport { isWin } from \"../Platform\"\nimport { equalsIgnoreCase, stripPrefix } from \"../String\"\nimport { Volume } from \"../volumes/Volume\"\nimport { volumes } from \"../volumes/Volumes\"\nimport { URI } from \"./URI\"\n\nexport function nativePath2psnet(\n  nativePath: string,\n  vol: Maybe<Volume>\n): Maybe<URI> {\n  if (blank(nativePath)) return\n\n  // Prefer the volume, if available:\n  if (\n    vol != null &&\n    vol.remote === true &&\n    notBlank(vol.remoteHost) &&\n    notBlank(vol.remoteShare)\n  ) {\n    return URI.from({\n      scheme: PS_NETWORK_FILESYSTEM_PROTOCOL,\n      authority: vol.remoteHost,\n      path: posix.join(\n        \"/\" + vol.remoteShare,\n        stripPrefix(native2posix(nativePath), native2posix(vol.mountpoint))\n      )\n    })\n  }\n\n  // If it's a UNC path, URI knows how to handle it:\n  if (nativePath.startsWith(\"\\\\\\\\\")) {\n    return URI.file(nativePath).with({ scheme: PS_NETWORK_FILESYSTEM_PROTOCOL })\n  }\n\n  // Give up:\n  return\n}\n\nexport async function psnet2nativePath(\n  uri: URI,\n  mountpoint?: string\n): PromiseMaybe<string> {\n  if (uri.scheme !== PS_NETWORK_FILESYSTEM_PROTOCOL) {\n    throw new Error(\"invalid URI: \" + uri + \" (bad scheme)\")\n  }\n\n  if (blank(uri.authority)) {\n    throw new Error(\"invalid URI: \" + uri + \" (missing authority)\")\n  }\n\n  const arr = uri.path.split(\"/\").slice(1) // < slice(1) to skip over the '' due to the absolute path\n  const share = arr[0]\n\n  if (blank(share)) {\n    throw new Error(\"invalid URI: \" + uri + \" (missing share)\")\n  }\n\n  if (isWin) {\n    return `\\\\\\\\${uri.authority}\\\\${arr.join(sep)}`\n  }\n\n  const path = arr.slice(1)\n\n  // If there's a mounted drive with this share, use that:\n  const vols = await volumes()\n\n  for (const vol of toA(vols)) {\n    if (!vol.remote) continue\n    if (\n      equalsIgnoreCase(vol.remoteShare, share) &&\n      (await isEquivalentHost(uri.authority, vol.remoteHost))\n    ) {\n      return join(vol.mountpoint, ...path)\n    }\n  }\n\n  if (await nativePathIsReadableDirectory(mountpoint)) {\n    return join(mountpoint!, ...path)\n  }\n\n  return\n}\n", "import { uniq } from \"../../fe/Array\"\nimport { eql } from \"../../fe/Eql\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { toS } from \"../../fe/toS\"\nimport {\n  PS_LOCAL_FILE_PROTOCOL,\n  PS_NETWORK_FILESYSTEM_PROTOCOL\n} from \"../../fe/URI\"\nimport { thenMap2Or } from \"../async/Promise\"\nimport { mkLogger } from \"../Logger\"\nimport { uri2nativePath } from \"./FileURI\"\nimport { toURI, URI } from \"./URI\"\n\nconst uriPrefixes = [\n  \"http:\",\n  \"https:\",\n  \"file:\",\n  PS_LOCAL_FILE_PROTOCOL,\n  PS_NETWORK_FILESYSTEM_PROTOCOL\n].map(ea => ea + \"//\")\n\nexport function isUri(s: string): boolean {\n  const l = toS(s).toLowerCase()\n  return uriPrefixes.some(ea => l.startsWith(ea))\n}\n\nconst logger = lazy(() => mkLogger(\"UriNormalization\"))\n\nexport function normalizeURI(uri: string): string {\n  try {\n    return URI.parse(uri).toString()\n  } catch (err) {\n    logger().warn(\"Failed to normalize invalid URI\", { uri, err })\n    return uri\n  }\n}\n\n//\n// URI UNICODE NORMALIZATION\n//\n\n// We don't store normalized unicode URIs, as this allows us to store the actual\n// filename characters.\n\n// We *do* compare URIs by normalizing them, so macOS (using NFD) and other\n// filesystems (using NFC) can be considered equivalent.\n\nexport function uriEqlSync(a: string, b: string) {\n  try {\n    if (a == null || b == null) return false\n    const au = URI.parse(a)\n    const bu = URI.parse(b)\n    return (\n      au.scheme === bu.scheme &&\n      au.authority === bu.authority &&\n      au.path.normalize() === bu.path.normalize()\n    )\n  } catch {\n    return false\n  }\n}\n\nexport async function uriIsEquivalent(\n  a: Maybe<string | URI>,\n  b: Maybe<string | URI>\n) {\n  try {\n    if (a == null || b == null) return false\n    if (eql(a, b)) return true\n    const aStr = a.toString()\n    const bStr = b.toString()\n    if (uriEqlSync(aStr, bStr)) return true\n    return await thenMap2Or(\n      uri2nativePath(aStr),\n      uri2nativePath(bStr),\n      (ap, bp) => ap.normalize() === bp.normalize(),\n      () => false\n    )\n  } catch {\n    return false\n  }\n}\n\nexport function uriEncodingVariants(uri: string | URI): string[] {\n  const u = toURI(uri)\n  return uniq([\n    u.toString(),\n    u.with({ path: u.path.normalize(\"NFC\") }).toString(),\n    u.with({ path: u.path.normalize(\"NFD\") }).toString()\n  ])\n}\n", "import { flatten, uniq } from \"../../fe/Array\"\nimport { blank } from \"../../fe/Blank\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { toA } from \"../../fe/toA\"\nimport {\n  PS_LIBRARY_PROTOCOL,\n  PS_LOCAL_FILE_PROTOCOL,\n  PS_NETWORK_FILESYSTEM_PROTOCOL\n} from \"../../fe/URI\"\nimport { firstDefinedLater } from \"../async/Later\"\nimport { thenCompact, thenMap, thenOrElse } from \"../async/Promise\"\nimport { mkLogger } from \"../Logger\"\nimport { Volume } from \"../volumes/Volume\"\nimport { volumeFor } from \"../volumes/Volumes\"\nimport { nativePath2psfile, psfile2nativePath } from \"./psfile\"\nimport { nativePath2pslib, pslib2nativePath } from \"./pslib\"\nimport { nativePath2psnet, psnet2nativePath } from \"./psnet\"\nimport { URI } from \"./URI\"\nimport { uriEncodingVariants } from \"./UriNormalization\"\n\nconst logger = lazy(() => mkLogger(\"FileURI\"))\n\nexport async function nativePath2uri(\n  nativePath: string,\n  volume?: Volume\n): Promise<URI> {\n  if (nativePath == null || blank(nativePath)) {\n    return logger().throw(\"empty nativePath passed to nativePath2uri()\", {\n      retriable: false\n    })\n  }\n\n  const vol = lazy(() => thenOrElse(volume, () => volumeFor(nativePath)))\n\n  return firstDefinedLater(\n    () => nativePath2pslib(nativePath),\n    async () => nativePath2psfile(nativePath, await vol()),\n    async () => nativePath2psnet(nativePath, await vol()),\n    () => URI.file(nativePath)\n  ) as any\n}\n\nexport async function nativePath2uris(nativePath: string): Promise<URI[]> {\n  const vol = await volumeFor(nativePath)\n  return thenCompact([\n    nativePath2pslib(nativePath),\n    nativePath2psfile(nativePath, vol),\n    nativePath2psnet(nativePath, vol),\n    URI.file(nativePath)\n  ])\n}\n\nexport async function nativePath2uriVariants(\n  nativePath: string\n): Promise<string[]> {\n  const arr = await nativePath2uris(nativePath)\n  return uniq(flatten(arr.map(uriEncodingVariants)))\n}\n\nexport async function uriVariants(\n  uri: string,\n  mountpoint?: string\n): Promise<string[]> {\n  const result = uriEncodingVariants(uri)\n  result.push(\n    ...toA(\n      await thenMap(uri2nativePath(uri, mountpoint), nativePath2uriVariants)\n    )\n  )\n  return uniq(result)\n}\n\nfunction toURI(uri: string | URI): Maybe<URI> {\n  try {\n    if (URI.isUri(uri)) return uri\n    return URI.parse(uri, true)\n  } catch (err) {\n    logger().warn(\"bad URI\", { uri, err })\n    return\n  }\n}\n\nexport async function uri2nativePath(\n  uri: string | URI,\n  mountpoint?: string\n): PromiseMaybe<string> {\n  if (blank(uri)) return\n  const u = toURI(uri)\n  if (u == null) return\n\n  switch (u.scheme) {\n    case \"file\":\n      return u.fsPath\n    case PS_LOCAL_FILE_PROTOCOL:\n      return psfile2nativePath(u, mountpoint)\n    case PS_NETWORK_FILESYSTEM_PROTOCOL:\n      return psnet2nativePath(u, mountpoint)\n    case PS_LIBRARY_PROTOCOL:\n      return pslib2nativePath(u)\n    default:\n      throw new Error(\"unsupported URI: \" + uri)\n  }\n}\n", "import { notBlank } from \"../../fe/Blank\"\nimport { secondMs } from \"../../fe/Date\"\nimport { toInt } from \"../../fe/Number\"\nimport { opt } from \"../../fe/Opt\"\nimport { SyncOrAsync } from \"../../fe/OptAsync\"\nimport { stdout } from \"../child/ChildProcess\"\nimport { isMac, isWin } from \"../Platform\"\nimport { PowerShell, pwshQuote } from \"../pwsh/PowerShell\"\nimport { SimpleFile } from \"./SimpleFile\"\n\nasync function hiddenWin(file: SimpleFile) {\n  const json = await PowerShell.instance().executeJsonToA(\n    [\n      \"Get-Item -Force -LiteralPath\",\n      pwshQuote(file.nativePath),\n      \"-ErrorAction SilentlyContinue\",\n      \"| Select-Object -Property Name, Mode\"\n    ].join(\" \")\n  )\n  return (\n    opt(json)\n      .flatMap(ea => ea[0])\n      .flatMap(ea => ea.Mode)\n      .filter(notBlank)\n      // See https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.management/get-childitem?view=powershell-5.1#examples\n      .flatMap((mode: string) => mode.includes(\"h\") || mode.includes(\"s\"))\n      .getOrElse(() => false)\n  )\n}\n\nasync function hiddenMac(file: SimpleFile) {\n  try {\n    const out = await stdout(\"stat\", [\"-f\", \"%f\", file.nativePath], {\n      timeout: 10 * secondMs\n    })\n    const flags = toInt(out)\n    if (flags != null) {\n      return (flags & 0x8000) > 0 // from /usr/include/sys/stat.h\n    } else {\n      return false\n    }\n  } catch (err) {\n    return false\n  }\n}\n\nexport function hidden(file: SimpleFile): SyncOrAsync<boolean> {\n  if (file.base.startsWith(\".\")) return true\n  return isWin ? hiddenWin(file) : isMac ? hiddenMac(file) : false\n}\n", "import { orElse } from \"../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../fe/MaybeTypes\"\nimport { keys } from \"../fe/Object\"\nimport { SyncOrAsync } from \"../fe/OptAsync\"\nimport { ContextualLogger } from \"./log/Logger\"\n\nexport interface BooleanThunk {\n  (): Maybe<boolean>\n}\n\n// TODO: SITS: COMBINE WITH PREDICATE\nexport interface BooleanLater {\n  (): Maybe<boolean> | PromiseMaybe<boolean>\n}\n\n// function log({\n//   logger,\n//   name,\n//   result\n// }: {\n//   logger: ContextualLogger\n//   name: string\n//   result: Maybe<boolean>\n// }) {\n//   const level = result == null ? \"warn\" : \"debug\"\n//   logger.log(\n//     level,\n//     darkGrey(name) + \": \" + (result === true ? green : red)(toS(result))\n//   )\n// }\n\nexport function orLogged(\n  predicates: { [key: string]: BooleanThunk }[],\n  name: string,\n  logger: ContextualLogger\n): boolean {\n  const results: BooleanValued = {}\n  try {\n    for (const predicate of predicates) {\n      for (const ea of keys(predicate)) {\n        const result = predicate[ea]()\n        results[ea] = orElse(result, false)\n        if (result === true) return result\n      }\n    }\n    return false\n  } finally {\n    logValues(logger, name, results)\n  }\n  //  return predicates.some(predicate =>\n  //   keys(predicate).some(name =>\n  //     isTrue(\n  //       tap(predicate[name](), result =>\n  //         log({\n  //           logger,\n  //           name,\n  //           result\n  //         })\n  //       )\n  //     )\n  //   )\n  // )\n}\n\nexport type AsyncPredicates = {\n  [key: string]: () => SyncOrAsync<boolean>\n}\n\nexport interface BooleanValued {\n  [key: string]: boolean\n}\n\nfunction logValues(logger: ContextualLogger, name: string, b: BooleanValued) {\n  const level = b == null ? \"warn\" : \"debug\"\n  logger.log(level, name, b)\n}\n\nexport async function orLoggedAsync(\n  predicates: AsyncPredicates[],\n  name: string,\n  logger: ContextualLogger\n): Promise<boolean> {\n  const results: BooleanValued = {}\n  try {\n    for (const predicate of predicates) {\n      for (const ea of keys(predicate)) {\n        const result = await predicate[ea]()\n        results[ea] = result\n        if (result) return result\n      }\n    }\n    return false\n  } finally {\n    logValues(logger, name, results)\n  }\n}\n", "import { getOrSet } from \"../fe/Map\"\nimport { map } from \"../fe/Maybe\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { mapGte0 } from \"./Number\"\n\n/**\n * Supports efficient lookup for 2-tuple matches\n */\nexport class SetSet {\n  private readonly store = new Map<string, Set<string>>()\n\n  add(elem1: string, elem2: string) {\n    getOrSet(this.store, elem1, () => new Set<string>()).add(elem2)\n  }\n\n  delete(elem1: string, elem2: string) {\n    map(this.store.get(elem1), set => {\n      set.delete(elem2)\n      if (set.size === 0) this.store.delete(elem1)\n    })\n  }\n\n  find(needle: string[]): Maybe<string[]> {\n    return mapGte0(\n      needle.findIndex((ea, idx) => this.store.get(ea)?.has(needle[idx + 1])),\n      idx => needle.slice(idx, idx + 2)\n    )\n  }\n\n  has(arr: string[]) {\n    return this.find(arr) != null\n  }\n}\n", "import { compactBlanks } from \"../../fe/Array\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { emitFileChanged, onClearCache } from \"../event/EventEmitter\"\nimport { mkLogger } from \"../Logger\"\nimport { Predicates } from \"../Predicates\"\nimport { Settings } from \"../settings/Settings\"\nimport { resolveSimpleFile } from \"./Path\"\nimport { SimpleFile } from \"./SimpleFile\"\n\nconst logger = lazy(() => mkLogger(\"NeverIgnoredPaths\"))\n\nconst listenForChanges = lazy(() => {\n  Settings.neverIgnored.addListener(() => {\n    NeverIgnored.clear()\n    emitFileChanged()\n    logger().info(\"Settings.neverIgnored changed\", Settings.neverIgnored.value)\n  })\n  Settings.scanPaths.addListener(() => {\n    NeverIgnored.clear()\n    emitFileChanged()\n  })\n  onClearCache(() => NeverIgnored.clear())\n})\n\nconst NeverIgnored = lazy(() => {\n  listenForChanges()\n  return new Set<string>(\n    compactBlanks([\n      ...Settings.scanPaths.values,\n      ...Settings.neverIgnored.values\n    ])\n  )\n})\n\nexport function pathIsNeverIgnored(nativePath: string): boolean {\n  return (\n    NeverIgnored().has(nativePath) ||\n    NeverIgnored().has(nativePath.toLowerCase())\n  )\n}\n\nexport function neverIgnore(...arr: (string | SimpleFile)[]) {\n  Settings.neverIgnored.push(...compactBlanks(arr).map(resolveSimpleFile))\n}\n\nexport function pathIsNeverIgnoredPredicate(\n  nativePath: string\n): Maybe<Predicates> {\n  return pathIsNeverIgnored(nativePath)\n    ? { pathIsNeverIgnored: () => false }\n    : undefined\n}\n", "import { join } from \"path\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { later } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { thenMap } from \"../async/Promise\"\nimport { onClearCache, onFileChanged } from \"../event/EventEmitter\"\nimport { FifoCacheAsync } from \"../FifoCache\"\nimport { mkLogger } from \"../Logger\"\nimport { MountpointsTtlMs } from \"../volumes/VolumeTtls\"\nimport { BaseFile } from \"./BaseFile\"\nimport { pathIsNeverIgnored } from \"./NeverIgnoredPaths\"\nimport { nativePathExists, pathnames } from \"./Path\"\nimport { SimpleFile } from \"./SimpleFile\"\n\n// We're making the dot optional (although that isn't part of the spec)\nconst nomediaRe = /^\\.?NoMedia$/i\n\nconst NoMedia = \"NoMedia\"\n\nfunction variants(s: string) {\n  return [s, s.toLowerCase(), s.toUpperCase()]\n}\n\nconst NoMediaNames = Object.freeze([\n  ...variants(\".\" + NoMedia),\n  ...variants(NoMedia)\n])\n\nexport function isNoMediaName(basename: string): boolean {\n  return nomediaRe.exec(basename) != null\n}\n\nconst cache = new FifoCacheAsync<Maybe<boolean>>({\n  maxSize: 1024,\n  timeoutMs: MountpointsTtlMs,\n  clearEveryMs: minuteMs\n})\n\nlater(() => onClearCache(() => cache.clear()))\nlater(() =>\n  onFileChanged(path => {\n    path == null ? cache.clear() : cache.deleteIf(key => key.startsWith(path))\n  })\n)\n\nconst logger = lazy(() => mkLogger(\"hasNoMedia()\"))\n\nexport async function hasNoMedia(sf: Maybe<SimpleFile>): PromiseMaybe<boolean> {\n  if (sf == null) return false\n\n  // Before checking the cache, do any simple tests say we are NoMedia?\n\n  if (pathIsNeverIgnored(sf.nativePath)) {\n    return logger().tap({ msg: sf + \" is never ignored\", result: false })\n  }\n\n  if (sf instanceof BaseFile) {\n    // Avoid instantiating tons of BaseFiles:\n    return hasNoMedia(await sf.directoryEntry())\n  }\n\n  // Are we an actual NoMedia file?\n\n  if (isNoMediaName(sf.base)) {\n    // this doesn't need to be cached, it's almost a no-op:\n    return logger().tap({ msg: sf + \" basename is NoMedia\", result: true })\n  }\n\n  // Are any of my parent directories NoMedia?\n\n  if (pathnames(sf.nativePath).some(isNoMediaName)) {\n    // this doesn't need to be cached, it's almost a no-op:\n    return logger().tap({ msg: sf + \" parent path is NoMedia\", result: true })\n  }\n\n  if (await sf.isDirectory()) {\n    const thisHasNoMedia = await cache.getOrSetAsync(\n      sf.nativePath,\n      async () => {\n        for (const ea of NoMediaNames) {\n          if (await nativePathExists(join(sf.nativePath, ea))) {\n            return logger().tap({\n              msg: sf + \" is a directory and has a noMedia child, \" + ea,\n              result: true\n            })\n          }\n        }\n        return false\n      }\n    )\n\n    if (thisHasNoMedia === true) return true\n  }\n  return sf.isRoot ? false : thenMap(sf.parent(), hasNoMedia)\n}\n", "import { count } from \"../../fe/Array\"\nimport { Settings } from \"../settings/Settings\"\n\n/**\n * Naive detection of symlink loops\n */\nexport function seemsRecursive(path: string[]): boolean {\n  const max = Settings.maxDuplicatePathElements.valueOrDefault\n  for (const ea of new Set(path)) {\n    if (count(path, el => el === ea) > max) return true\n  }\n  return false\n}\n", "import { entries, Valued } from \"../../fe/Object\"\nimport { flatMap } from \"../Array\"\nimport { darkGrey, green, red } from \"../Chalk\"\nimport { Filter } from \"../Filter\"\nimport { Logger } from \"../Logger\"\nimport { ellipsize } from \"../String\"\nimport { filter } from \"./Predicate\"\nimport { thenNot } from \"./Promise\"\n\nexport type AnyFilter<T> = Filter<T> | AsyncFilter<T>\n\nexport class AsyncFilter<T> {\n  constructor(readonly apply: (item: T) => Promise<boolean>) {}\n\n  static lift<T1>(f: (item: T1) => Promise<boolean>): AsyncFilter<T1> {\n    return new AsyncFilter(f)\n  }\n\n  static and<T1>(...filters: AnyFilter<T1>[]): AsyncFilter<T1> {\n    return new AsyncFilter(async (item: T1) => {\n      for (const f of filters) {\n        if (!(await f.apply(item))) return false\n      }\n      return true\n    })\n  }\n\n  static or<T1>(...filters: AnyFilter<T1>[]): AsyncFilter<T1> {\n    return new AsyncFilter(async (item: T1) => {\n      for (const f of filters) {\n        if (await f.apply(item)) return true\n      }\n      return false\n    })\n  }\n\n  static logged<T1>(\n    logger: Logger,\n    ...filters: { [key: string]: AnyFilter<T1> }[]\n  ) {\n    return flatMap(filters, ea =>\n      entries(ea).map(([key, value]) => value.asAsync().logged(logger, key))\n    )\n\n    // const tuples = flatten(filters.map(entries))\n    // return tuples.map(([k, v]) => v.asAsync().logged(logger, k))\n  }\n\n  static andLogged<T1>(\n    logger: Logger,\n    ...filters: { [key: string]: AnyFilter<T1> }[]\n  ): AsyncFilter<T1> {\n    return this.and(...this.logged(logger, ...filters))\n  }\n\n  static orLogged<T1>(\n    logger: Logger,\n    ...filters: Valued<AnyFilter<T1>>[]\n  ): AsyncFilter<T1> {\n    return this.or(...this.logged(logger, ...filters))\n  }\n\n  static async andExplain<T1>(\n    t: T1,\n    filters: Valued<AnyFilter<T1>>[]\n  ): Promise<{ accepted: string[]; rejected: string[] }> {\n    const accepted: string[] = []\n    const rejected: string[] = []\n    for (const filterObj of filters) {\n      for (const [name, ea] of entries(filterObj)) {\n        ;((await ea.apply(t)) ? accepted : rejected).push(name)\n      }\n    }\n    return {\n      accepted,\n      rejected\n    }\n  }\n\n  asAsync(): this {\n    return this\n  }\n\n  and(...that: this[]): this {\n    return AsyncFilter.and(this, ...that) as this\n  }\n\n  not(): this {\n    return new AsyncFilter((t: T) => thenNot(this.apply(t))) as this\n  }\n\n  or(that: this): this {\n    return new AsyncFilter(\n      async (item: T) =>\n        // don't need to await that.apply:\n        (await this.apply(item)) || (await that.apply(item))\n    ) as this\n  }\n\n  async filter(arr: T[]): Promise<T[]> {\n    return filter(arr, ea => this.apply(ea))\n  }\n\n  // SITS: this duplicates the Predicates.orLoggedAsync code: DRY. later?\n  logged(logger: Logger, description: string): AsyncFilter<T> {\n    const af = new AsyncFilter(async (item: T) => {\n      const result = await this.apply(item)\n      logger.log(\n        result ? \"debug\" : \"info\",\n        [\n          darkGrey(description),\n          result ? green(\"ACCEPT\") : red(\"REJECT\"),\n          ellipsize(item)\n        ].join(\" \")\n      )\n      return result\n    })\n    return af\n  }\n}\n", "import { secondMs } from \"../../fe/Date\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { toA } from \"../../fe/toA\"\nimport { AsyncFilter } from \"../async/AsyncFilter\"\nimport { stdout } from \"../child/ChildProcess\"\nimport { parseFixed } from \"../Fixed\"\nimport { mkLogger } from \"../Logger\"\nimport { isDocker, isLinux } from \"../Platform\"\nimport { pathnames } from \"./Path\"\nimport { SimpleFile } from \"./SimpleFile\"\n\nconst logger = mkLogger(\"Snap\")\n\n// Some snaps will mount the home directory into the snap, so we get assetfile dupes like\n// file:///home/mrm/snap/spotify/current/Pictures/2015/2015-12-29/IMG_20151229_160926.jpg and\n// file:///home/mrm/snap/spotify/13/Pictures/2016/2015-12-29/IMG_20151229_160926.jpg\n\nexport const ignorableSnapDir: AsyncFilter<SimpleFile> = AsyncFilter.lift(\n  async (file: SimpleFile) => {\n    // Snap is currently only available on linux:\n    if (!(await hasSnap())) return false\n    // Only call snaps() if a pathname is \"snap\":\n    const paths = pathnames(file.nativePath)\n    const idx = paths.indexOf(\"snap\")\n    if (idx < 0) return false\n    return toA(await snaps()).includes(pathnames[idx + 1])\n  }\n)\n\nexport const hasSnap = lazy(async () => {\n  // snap isn't on the alpine docker image:\n  if (!isLinux || isDocker()) return false\n\n  try {\n    await stdout(\"snap\", [\"--version\"], {\n      timeout: 10 * secondMs,\n      quiet: true,\n      maxRetries: 0\n    })\n    return true\n  } catch {\n    return false\n  }\n})\n\n/*\n\n$ snap list\nName              Version                 Rev   Tracking  Developer     Notes\nbitwarden         1.2.0                   4     stable    bitwarden     -\ncore              16-2.33.1               4917  stable    canonical     core\nffmpeg            4.0                     13    stable    snapcrafters  classic\ninkscape          0.92.3                  4019  stable    inkscape      -\nkde-frameworks-5  5.47.0                  27    stable    kde           -\nspotify           1.0.80.474.gef6b503e-7  16    stable    spotify       -\nvlc               3.0.3-1-3-gf09fd0d      365   stable    videolan      -\n\n*/\n\nexport const snaps = lazy(async () => {\n  if (!(await hasSnap())) return []\n  try {\n    // We don't use Version, but if we don't have the next column past \"Name\",\n    // the whole input will be considered a single column.\n    return await parseFixed(\n      [\"Name\", \"Version\"],\n      await stdout(\"snap\", [\"list\"], { timeout: 10 * secondMs })\n    ).map(ea => ea.Name as string)\n  } catch (err) {\n    logger.warn(\"snap failed\", err)\n    return []\n  }\n}, 30 * secondMs)\n", "import { compactBlanks, uniq } from \"../../fe/Array\"\nimport { blank } from \"../../fe/Blank\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { appData } from \"../AppData\"\nimport { thenMapOr } from \"../async/Promise\"\nimport { getEnv } from \"../Env\"\nimport { AsyncPredicates, orLogged, orLoggedAsync } from \"../LoggedThunks\"\nimport { mkLogger } from \"../Logger\"\nimport { isTest } from \"../NodeEnv\"\nimport { isLinux, isWin } from \"../Platform\"\nimport { Predicates } from \"../Predicates\"\nimport { SetSet } from \"../SetSet\"\nimport { mountpoints } from \"../volumes/Mountpoints\"\nimport { hidden } from \"./Hidden\"\nimport {\n  pathIsNeverIgnored,\n  pathIsNeverIgnoredPredicate\n} from \"./NeverIgnoredPaths\"\nimport { hasNoMedia } from \"./NoMedia\"\nimport { native2posix, pathnames } from \"./Path\"\nimport { PosixFile } from \"./PosixFile\"\nimport { seemsRecursive } from \"./SeemsRecursive\"\nimport { SimpleFile } from \"./SimpleFile\"\nimport { ignorableSnapDir } from \"./Snap\"\n\n/**\n * This is a steaming bag of whack-a-mole heuristics to prevent iterating\n * \"ignorable\" directories. These are OS or application directories which\n * frequently make up the bulk of files on many drives, but never include assets\n * that users want to include in their libraries.\n *\n * It's messy down here. Scroll down at your own peril.\n *\n * Also, because people access volumes with different OSes, we won't assume that\n * a given drive was used by the current OS, so \"C:\\\\etc\" on windows and\n * \"/Program Files/\" on mac should be considered ignorable directories, and be\n * skipped.\n */\nexport class Ignorable {\n  private readonly ignorableRootDirectories = new Set(\n    [\n      // See http://www.linfo.org/var.html\n      // https://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard\n      // http://www.pathname.com/fhs/\n\n      // bin and boot don't have many files, let them get scanned\n      // \"bin\", // Essential command binaries\n      // \"boot\", // Boot loader files\n      \"dev\", // Essential device files\n      \"etc\", // Host-specific system-wide configuration files\n      \"initrd\", // initial ramdisk\n      \"lib\", // Libraries essential for the binaries in /bin and /sbin.\n      \"lost+found\",\n      \"proc\", // Virtual filesystem providing process and kernel information as files.\n      // \"root\", // Home directory for the root user (might have something?)\n      \"sbin\", // Essential system binaries\n      \"sys\", // Contains information about devices, drivers, and some kernel features\n      \"tmp\", // tmp is tmp\n      // \"var\", < Some people mounted their docker volume to /var/photos:\n\n      \"System\", // mac and win\n\n      // windows\n      \"Dell\", // drivers\n      \"Intel\", // drivers\n      \"Microsoft\", // drivers\n      \"NVIDIA\", // surprisingly large driver (> 4gb!)\n      \"temp\",\n      // DON'T INCLUDE /Volumes here, as that causes all external drives to be\n      // rejected!\n      \"Windows.old\", // thanks, windows updater\n      \"Windows\"\n    ].map(s => s.toLowerCase().normalize())\n  ) // case insensitivity\n\n  /**\n   * All these directories are sufficiently nerdy that they uniquely identify a\n   * system or development directory, and don't need to be anchored to, say, / to\n   * be sufficiently constrained.\n   */\n  private readonly ignorableDirectories = new Set(\n    [\n      \"#snapshot\", // backup snapshots on synology\n      \"__MACOSX\", // resource fork\n      \"_includes\", // source tree\n      \"@eaDir\", // synology thumbs\n      \"@Recycle\", // qnap trash\n      \"@SynoResource\", // synology\n      \"#recycle\", // synology trash\n      \"$Recycle.Bin\", // windows trash\n      \"3rdParty\", // source\n      \"Application Data\", // win\n      \"Application Support\", // mac\n      \"Applications\", // mac\n      \"arangodb\", // their 3rdparty subdir is a menace\n      \"cache\",\n      \"caches\",\n      \"CacheClip\", // movie app cache dir\n      \"cmake\", // dev\n      \"com.apple.TimeMachine.localsnapshots\", // mac\n      \"cpan\", // hello old frenemy\n      \"DefinitelyTyped\", // roughly infinite subdirectories\n      \"Desktop DB\", // mac\n      \"Desktop DF\", // mac\n      \"Desktop.ini\", // mac\n      \"DisplayDriver\", // win\n      // \"Download\", // these might actually have something\n      // \"Downloads\",\n      \"ehthumbs.db\", // win\n      \"iMovie Cache\",\n      \"iTunes Cache\",\n      \"iTunes Media\", // music videos: see https://gitlab.com/mceachen/photostructure/issues/102\n      \"iTunes\", // music videos: see https://gitlab.com/mceachen/photostructure/issues/102\n      \"lost+found\", // posix\n      \"Network Trash Folder\",\n      \"node_modules\", // ugh, nothing good in there\n      \"pkgconfig\", // dev\n      \"pkgs\", // python\n      \"Program Files (x86)\", //win\n      \"Program Files\", // win\n      \"ProgramData\", // win\n      \"site-packages\", // python\n      \"spotifycache\", // muzak\n      \"SteamApps\", // win\n      \"System Volume Information\", // win\n      \"System32\", // win\n      \"temp\",\n      \"Temporary Items\", // win\n      \"test_suite\", // source\n      \"testutils\", // source\n      \"third_party\", // source\n      \"Thumbnails\", // iPhoto\n      \"Thumbs.db\", // win\n      \"tmp\",\n      \"Trash\", // xdg trash https://specifications.freedesktop.org/trash-spec/trashspec-1.0.html\n      \"Windows10Upgrade\",\n      \"Xcode.app\"\n    ].map(s => s.toLowerCase())\n  )\n\n  // These paths are all \"posix-ized\" before being applied\n  private readonly ignorableDirectoryPatterns = [\n    /.sparsebundle\\/bands(\\/|$)/i, // < mac time machine backups like \".../bob's mac.sparsebundle/bands/...\"\n    /\\/resources\\/media\\/face/i, // iPhoto face tiles\n    /\\/facetile[-_]/i, // iPhoto face tiles\n    /\\/.*?\\.photos?library\\/(?!(masters?|originals)\\/)/i, // iPhoto subdirectories except for Master, Masters, or Originals.\n    /\\/ImageMagick[\\d.-]*(\\/|$)/i,\n    /\\/Install OS X .+\\.app(\\/|$)/i,\n    /Previews\\.lrdata(\\/|$)/i, // lightroom\n    /\\/MinGW-.+(\\/|$)/i, // MSYS and variants\n    /\\/msys[\\d.-]*(\\/|$)/i, // msys or msys64\n    /\\/Python[\\d.-]*(amd64|x64)?(\\/|$)/i, // Python may not have a version\n    /\\/Ruby[\\d.-]+(amd64|x64)?(\\/|$)/i // Ruby directories always seem to have a version number\n  ]\n\n  private readonly systemDirs = uniq(\n    compactBlanks([\n      appData(),\n      getEnv(\"APPDATA\"),\n      getEnv(\"SYSTEMROOT\"),\n      getEnv(\"ProgramFiles\"),\n      getEnv(\"ProgramFiles(x86)\")\n    ]).map(ea => ea.toLowerCase().normalize())\n  )\n\n  // Some \"ignorable\" paths need more than just a single pathname to be sure it's\n  // ignorable. For example, just ignoring all folders named \"Library\" would not\n  // be safe.\n  private readonly ignorableSubdirs = new SetSet()\n  addIgnorableSubdirs(root: string, children: string[]) {\n    if (blank(root)) return\n    const l = root.toLowerCase().normalize()\n    compactBlanks(children).forEach(ea =>\n      this.ignorableSubdirs.add(l, ea.toLowerCase().normalize())\n    )\n  }\n\n  constructor(testing: boolean = isTest) {\n    if (isLinux) {\n      this.ignorableRootDirectories.add(\"run\")\n      this.ignorableRootDirectories.add(\"snap\")\n    }\n\n    this.addIgnorableSubdirs(\"nix\", [\"store\"])\n\n    const subdirs = [\n      \"bin\",\n      \"cygdrive\",\n      \"dev\",\n      \"etc\",\n      \"games\",\n      \"include\",\n      \"lib\",\n      \"lib32\",\n      \"local\",\n      \"locale\",\n      \"man\",\n      \"proc\",\n      \"sbin\",\n      \"share\",\n      \"src\",\n      \"tmp\",\n      \"usr\",\n      \"var\"\n    ]\n\n    this.addIgnorableSubdirs(\"usr\", subdirs)\n    this.addIgnorableSubdirs(\"cygwin\", subdirs)\n    this.addIgnorableSubdirs(\"cygwin64\", subdirs)\n    this.addIgnorableSubdirs(\"local\", subdirs)\n\n    // These can be found in backups:\n    this.addIgnorableSubdirs(\"Windows\", [\n      \"Boot\",\n      \"Containers\",\n      \"Cursors\",\n      \"Fonts\",\n      \"Help\",\n      \"Installer\",\n      \"Logs\",\n      \"Microsoft.NET\",\n      \"SoftwareDistribution\",\n      \"System\",\n      \"System32\",\n      \"SysWOW64\",\n      \"Temp\"\n    ])\n\n    this.addIgnorableSubdirs(\"lib\", [\n      \"firmware\",\n      \"modules\",\n      \"systemd\",\n      \"udev\",\n      \"x86_64-linux-gnu\"\n    ])\n    this.addIgnorableSubdirs(\"opt\", [\"google\", \"x11\", ...subdirs])\n\n    // git:\n    this.addIgnorableSubdirs(\"lfs\", [\"objects\"])\n\n    // https://www.tldp.org/LDP/sag/html/var-fs.html\n    this.addIgnorableSubdirs(\"var\", [\n      \"cache\",\n      \"crash\",\n      \"games\",\n      \"lib\",\n      \"local\",\n      \"lock\",\n      \"log\",\n      \"mail\",\n      \"run\",\n      \"snap\",\n      \"spool\",\n      \"tmp\"\n    ])\n\n    // linux backups:\n    this.addIgnorableSubdirs(\"dev\", [\n      \"block\",\n      \"bsg\",\n      \"bus\",\n      \"char\",\n      \"cpu\",\n      \"disk\",\n      \"dri\",\n      \"fd\",\n      \"hugepages\",\n      \"input\",\n      \"lightnvm\",\n      \"mapper\",\n      \"mqueue\",\n      \"net\",\n      \"pts\",\n      \"shm\",\n      \"snd\",\n      \"ubuntu-vg\",\n      \"usb\",\n      \"vfio\"\n    ])\n    this.addIgnorableSubdirs(\"proc\", [\n      \"acpi\",\n      \"asound\",\n      \"bus\",\n      \"driver\",\n      \"fs\",\n      \"ipmi\",\n      \"irq\",\n      \"net\",\n      \"scsi\",\n      \"self\",\n      \"sys\",\n      \"sysvipc\",\n      \"thread-self\",\n      \"tty\"\n    ])\n\n    // Mac Library folders:\n    this.addIgnorableSubdirs(\"library\", [\n      \"Application Support\",\n      \"Audio\",\n      \"Bundles\",\n      \"Caches\",\n      \"ColorPickers\",\n      \"ColorSync\",\n      \"Components\",\n      \"Compositions\",\n      \"Contextual Menu Items\",\n      \"CoreAnalytics\",\n      \"CoreMediaIO\",\n      \"Desktop Pictures\",\n      \"Developer\",\n      \"Dictionaries\",\n      \"DirectoryServices\",\n      \"Documentation\",\n      \"Extensions\",\n      \"Filesystems\",\n      \"Fonts\",\n      \"Frameworks\",\n      \"GPUBundles\",\n      \"Graphics\",\n      \"Image Capture\",\n      \"Input Methods\",\n      \"Internet Plug-Ins\",\n      \"iTunes\",\n      \"Java\",\n      \"Keyboard Layouts\",\n      \"Keychains\",\n      \"LaunchAgents\",\n      \"LaunchDaemons\",\n      \"Logs\",\n      \"Messages\",\n      \"MessageTracer\",\n      \"Modem Scripts\",\n      \"OpenDirectory\",\n      \"PDF Services\",\n      \"Perl\",\n      \"PreferencePanes\",\n      \"Preferences\",\n      \"Printers\",\n      \"PrivilegedHelperTools\",\n      \"Python\",\n      \"QuickLook\",\n      \"QuickTime\",\n      \"Receipts\",\n      \"Ruby\",\n      \"Sandbox\",\n      \"Screen Savers\",\n      \"ScriptingAdditions\",\n      \"Scripts\",\n      \"Security\",\n      \"Speech\",\n      \"Spotlight\",\n      \"StagedExtensions\",\n      \"StartupItems\",\n      \"SystemProfiler\",\n      \"Updates\",\n      \"User Pictures\",\n      \"Video\",\n      \"WebServer\",\n      \"Widgets\"\n    ])\n\n    // src trees:\n    this.addIgnorableSubdirs(\"src\", [\"main\", \"test\"]) // < maven\n    this.addIgnorableSubdirs(\"examples\", [\"bin\", \"conf\", \"src\"]) // docs\n    this.addIgnorableSubdirs(\"docs\", [\n      \"admin\",\n      \"content\",\n      \"general\",\n      \"generated\",\n      \"sql\"\n    ]) // docs\n    this.addIgnorableSubdirs(\"pkg\", [\n      \"acceptance\",\n      \"ccl\",\n      \"cli\",\n      \"cmd\",\n      \"server\",\n      \"sql\",\n      \"storage\",\n      \"ui\",\n      \"util\",\n      \"workload\"\n    ]) // cockroach\n\n    this.addIgnorableSubdirs(\"osv\", [\n      \"apps\",\n      \"arch\",\n      \"compiler\",\n      \"external\",\n      \"include\",\n      \"java\",\n      \"modules\",\n      \"musl\",\n      \"tests\"\n    ])\n\n    // Go installation has some ignorables:\n    this.addIgnorableSubdirs(\"go\", [\n      \"bin\",\n      \"blog\",\n      \"cmd\",\n      \"doc\",\n      \"lib\",\n      \"misc\",\n      \"pkg\",\n      \"src\",\n      \"test\",\n      \"vt\"\n    ])\n\n    // Perl\n    const perlDirs = [\"bin\", \"eg\", \"etc\", \"html\", \"lib\", \"site\"]\n\n    this.addIgnorableSubdirs(\"Perl\", perlDirs)\n    this.addIgnorableSubdirs(\"Perl64\", perlDirs)\n\n    // Android SDK:\n    this.addIgnorableSubdirs(\"sdk\", [\n      \"build-tools\",\n      \"emulator\",\n      \"extras\",\n      \"patcher\",\n      \"platforms\",\n      \"platform-tools\",\n      \"sources\",\n      \"tools\"\n    ])\n\n    // Seems safe? If you've got any transifex source, this is a huge chunk:\n    this.addIgnorableSubdirs(\"i18n\", [\n      \"chs\",\n      \"cht\",\n      \"deu\",\n      \"esn\",\n      \"fra\",\n      \"hun\",\n      \"ita\",\n      \"jpn\",\n      \"kor\",\n      \"ptb\",\n      \"rus\",\n      \"trk\"\n    ])\n\n    this.addIgnorableSubdirs(\"test\", [\"fixtures\"]) // no one will put their precious photos in \".../test/fixtures/...\". RIGHT?\n    this.addIgnorableSubdirs(\"data\", [\"$of\"]) // windows 7-10 backup directories\n    this.addIgnorableSubdirs(\"system\", [\"library\"]) // mac os system disk\n    this.addIgnorableSubdirs(\"contents\", [\n      \"frameworks\",\n      \"plugins\",\n      \"resources\",\n      \"sharedsupport\"\n    ]) // mac os app\n    this.addIgnorableSubdirs(\"pg\", [\"pgsql\"]) // PostgreSQL src\n\n    // Windows application data:\n    if (!testing) {\n      this.addIgnorableSubdirs(\"appdata\", [\"local\", \"locallow\", \"roaming\"])\n      this.addIgnorableSubdirs(getEnv(\"APPDATA\")!, [\n        \"local\",\n        \"locallow\",\n        \"roaming\"\n      ])\n    }\n\n    if (testing) {\n      // We want to be able to import example pictures directories that are from mktmpdir:\n      this.ignorableDirectories.delete(\"tmp\")\n      this.ignorableRootDirectories.delete(\"tmp\")\n      this.ignorableDirectories.delete(\"temp\")\n      this.ignorableRootDirectories.delete(\"temp\")\n      // gitlab on speedy:\n      this.ignorableRootDirectories.delete(\"var\")\n      this.ignorableSubdirs.delete(\"var\", \"lib\")\n      if (isWin) {\n        this.ignorableSubdirs.delete(\"cygwin64\", \"tmp\")\n      }\n    }\n  }\n\n  ignorablePathPredicates(nativePath: string): Predicates {\n    const neverIgnored = pathIsNeverIgnoredPredicate(nativePath)\n    if (neverIgnored != null) return neverIgnored\n\n    const lc = nativePath.toLowerCase().normalize()\n    const paths = compactBlanks(pathnames(lc))\n    return {\n      hiddenPosix: () => paths.some(ea => ea.startsWith(\".\")),\n      systemDir: () => this.systemDirs.some(ea => lc.startsWith(ea)),\n      ignorableRoot: () => this.ignorableRootDirectories.has(paths[0]),\n      ignorableDirectory: () =>\n        paths.some(ea => this.ignorableDirectories.has(ea)),\n      ignorablePath: () => this.ignorableSubdirs.has(paths),\n      ignorablePattern: () => {\n        const posixPath = native2posix(nativePath)\n        return this.ignorableDirectoryPatterns.some(ea => ea.test(posixPath))\n      }\n    }\n  }\n\n  ignorablePath(nativePath: string): boolean {\n    return orLogged(\n      [this.ignorablePathPredicates(nativePath)],\n      nativePath,\n      mkLogger(\"ignorablePath()\")\n    )\n  }\n}\n\nconst instance = lazy(() => new Ignorable())\n\nexport function ignorablePathPredicates(nativePath: string): AsyncPredicates {\n  return {\n    ...instance().ignorablePathPredicates(nativePath),\n    notExists: () => PosixFile.for(nativePath).notExists()\n  }\n}\n\nexport function ignorablePath(nativePath: string): boolean {\n  return instance().ignorablePath(nativePath)\n}\n\nexport function ignorableFile(file: SimpleFile): boolean {\n  return ignorablePath(file.nativePath)\n}\n\n/**\n * @return if accept is non-empty, the directory is ignorable.\n */\nexport function ignorableDirectoryPredicates(\n  file: SimpleFile\n): AsyncPredicates {\n  const lc = file.nativePath.toLowerCase().normalize()\n  if (pathIsNeverIgnored(file.nativePath) || pathIsNeverIgnored(lc)) {\n    return {\n      pathIsNeverIgnored: () => false\n    }\n  }\n  return {\n    ...ignorablePathPredicates(file.nativePath),\n    snapDirectory: async () => isLinux && (await ignorableSnapDir.apply(file)),\n    // hasNoMedia returns a PromiseMaybe:\n    noMedia: async () => true === (await hasNoMedia(file)),\n    hidden: () => hidden(file),\n    seemsRecursive: () => seemsRecursive(file.pathnames),\n    mountpoint: async () =>\n      thenMapOr(\n        mountpoints(),\n        arr => arr.includes(file.nativePath),\n        () => false\n      )\n  }\n}\n\nexport async function ignorablePredicates(\n  file: SimpleFile\n): Promise<AsyncPredicates> {\n  return (await file.isDirectory())\n    ? ignorableDirectoryPredicates(file)\n    : ignorablePathPredicates(file.nativePath)\n}\n\nexport async function ignorableDirectory(file: SimpleFile): Promise<boolean> {\n  return orLoggedAsync(\n    [ignorableDirectoryPredicates(file)],\n    file.nativePath,\n    mkLogger(\"ignorableDirectory()\")\n  )\n}\n", "import { minuteMs } from \"../fe/Date\"\nimport { lazy } from \"../fe/Lazy\"\nimport { onError } from \"./error/Error\"\nimport { FatalErrorFlag } from \"./error/ErrorTypes\"\nimport { PosixFile } from \"./fs/PosixFile\"\nimport { Settings } from \"./settings/Settings\"\n\nconst addSettingsListener = lazy(() => {\n  Settings.cacheDir.addListener(() => cacheDir.unset())\n})\n\nexport const cacheDir = lazy(() => {\n  try {\n    addSettingsListener()\n    const d = PosixFile.for(Settings.cacheDir.valueOrDefault)\n    void d.mkNoMedia_()\n    return d\n  } catch (err) {\n    onError(\"Failed to set up cacheDir\" + FatalErrorFlag, err)\n    throw err\n  }\n}, minuteMs)\n", "/**\n * Updated when Curators, AssetFile schema, or metadata changes warrant\n * re-updating all AssetFiles from files\n */\n// 8: v0.7.x\n// 9: v0.8.x: new image hashes, spread dominant colors\n// 10: v0.8.0: remove searchHash and rightHash\n// 11: v0.8.3: fix ImageId to prefix the tag. Support greyscale images.\nexport const AssetFileVersion = 11\n\n// 2: v0.8.x: new taggers\n// 3: v1.0.0: new people, album, and taggers\nexport const AssetVersion = 3\n", "import { Command } from \"commander\"\nimport { CommandPlugin } from \"../../core/cli/CLI\"\nimport { Pojo } from \"../../core/Object\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { isTrue } from \"../../fe/Boolean\"\nimport { clearCacheDirs } from \"../StatsDbDir\"\n\n/**\n * Used by sync and sync-file\n */\nexport const ForceArg: CommandPlugin = {\n  beforeParse: (cmd: Command) =>\n    cmd.option(\n      \"--force\",\n      \"Deletes prior cached directory metadata to force directory contents to be re-scanned\"\n    ),\n  afterParse: async (opts: Pojo) => {\n    if (isTrue(opts.force)) {\n      Settings.forceSync.tmpValue = true\n      await clearCacheDirs()\n    }\n  }\n}\n", "import { Command } from \"commander\"\nimport { CommandPlugin } from \"../../core/cli/CLI\"\nimport { Pojo } from \"../../core/Object\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { isTrue } from \"../../fe/Boolean\"\n\n/**\n * Used by sync and sync-file\n */\nexport const NoFilterArg: CommandPlugin = {\n  beforeParse: (cmd: Command) =>\n    cmd.option(\n      \"--no-filter,--noFilter\",\n      \"Disables import filters. All paths will try to be imported, even if they are too small or are missing tags.\"\n    ),\n  afterParse: async (opts: Pojo) => {\n    if (isTrue(opts.noFilter)) {\n      Settings.minAssetFileSizeBytes.tmpValue = 0\n      Settings.requireMakeModel.tmpValue = false\n      Settings.minImageDimension.tmpValue = 0\n      Settings.minVideoDimension.tmpValue = 0\n    }\n  }\n}\n", "import { Command } from \"commander\"\nimport { CommandPlugin } from \"../../core/cli/CLI\"\nimport { Pojo } from \"../../core/Object\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { isTrue } from \"../../fe/Boolean\"\n\n/**\n * Used by sync and sync-file\n */\nexport const RebuildArg: CommandPlugin = {\n  beforeParse: (cmd: Command) =>\n    cmd.option(\n      \"--rebuild\",\n      \"Rebuild your library by re-importing all your photos and videos (slow!)\"\n    ),\n  afterParse: async (opts: Pojo) => {\n    if (isTrue(opts.rebuild)) {\n      Settings.rebuild.tmpValue = true\n    }\n  }\n}\n", "import { Command } from \"commander\"\nimport { CommandPlugin } from \"../../core/cli/CLI\"\nimport { Pojo } from \"../../core/Object\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { isTrue } from \"../../fe/Boolean\"\n\n/**\n * Used by sync and sync-file\n */\nexport const SkipUpdateArg: CommandPlugin = {\n  beforeParse: (cmd: Command) =>\n    cmd.option(\n      \"--skip-updates,--skipUpdates\",\n      \"DANGEROUS: If you want to immediately import specific files or directories and skip any pending library maintenance tasks (like library rebuilds), use this argument. Note that asset aggregation may be incorrect after using this command if there are updates pending.\"\n    ),\n  afterParse: (opts: Pojo) => {\n    if (isTrue(opts.skipUpdates)) {\n      Settings.skipModelUpdates.tmpValue = true\n    }\n  }\n}\n", "import { BatchCluster, Task } from \"batch-cluster\"\nimport p from \"process\"\nimport { end, EndableRanks, ending } from \"../../core/async/Endable\"\nimport { rejected } from \"../../core/async/Promise\"\nimport { BatchClusterObserver } from \"../../core/BatchClusterObserver\"\nimport { spawn } from \"../../core/child/ChildProcess\"\nimport { nodeArgs, pathToService } from \"../../core/child/ChildService\"\nimport {\n  hasBad,\n  hasFail,\n  hasWarn,\n  HealthCheckResult\n} from \"../../core/child/HealthChecks\"\nimport { onError } from \"../../core/error/Error\"\nimport { FatalErrorRe, isRetriableError } from \"../../core/error/ErrorTypes\"\nimport { WrappedError } from \"../../core/error/WrappedError\"\nimport {\n  eventEmitter,\n  onRpcServerChange,\n  onVolumesChanged\n} from \"../../core/event/EventEmitter\"\nimport {\n  emitProgressEvt,\n  isProgressEvt,\n  onProgressEvt\n} from \"../../core/event/ProgressEvt\"\nimport { SimpleEventEmitter } from \"../../core/event/SimpleEventEmitter\"\nimport { neverIgnore } from \"../../core/fs/NeverIgnoredPaths\"\nimport { PosixFile } from \"../../core/fs/PosixFile\"\nimport { readdirCacheDir, ReadDirCacheName } from \"../../core/fs/Readdir\"\nimport { Chunker } from \"../../core/fs/StreamChunker\"\nimport { TmpfileCleanup } from \"../../core/fs/TmpfileCleanup\"\nimport { imgCacheDir, ImgCacheName } from \"../../core/img/ImgCache\"\nimport { MaxSyncFileTimeoutMs } from \"../../core/img/SyncFileTimeout\"\nimport { mkLogger } from \"../../core/Logger\"\nimport { isTest } from \"../../core/NodeEnv\"\nimport { mapGt0 } from \"../../core/Number\"\nimport { Try } from \"../../core/Object\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { CmdTimeoutMs, MountpointsTtlMs } from \"../../core/volumes/VolumeTtls\"\nimport { maxSyncFileJobs } from \"../../core/work/MaxCpus\"\nimport { filterInPlace, isNotEmpty } from \"../../fe/Array\"\nimport { retryOnReject } from \"../../fe/AsyncRetry\"\nimport { notBlank } from \"../../fe/Blank\"\nimport { minuteMs, secondMs } from \"../../fe/Date\"\nimport { delay } from \"../../fe/Delay\"\nimport { stringify } from \"../../fe/JSON\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, mapOr, orElse } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { throttle } from \"../../fe/Throttle\"\nimport { toA } from \"../../fe/toA\"\nimport { toS } from \"../../fe/toS\"\nimport { forceRebuildLibrary } from \"../ForceRebuildLibrary\"\nimport { healthChecks } from \"../HealthChecks\"\nimport { Library } from \"../Library\"\nimport { Progress } from \"../model/Progress\"\nimport { Service } from \"../Service\"\nimport { clearCacheDirs } from \"../StatsDbDir\"\nimport { ReadyStr, stdoutWrite } from \"../StdoutWrite\"\nimport { ImportResult } from \"../sync-file/ImportResult\"\nimport {\n  FileProcessor,\n  NativePathImportTask\n} from \"../sync-file/NativePathImportTask\"\nimport { UpdateCommand, UpdateTask } from \"../sync-file/UpdateTask\"\nimport { DirectoryTaggerOperation } from \"./DirectoryTaggerOperation\"\nimport { ModelDbUpdater } from \"./ModelDbUpdater\"\nimport { ProgressUpdater } from \"./ProgressUpdater\"\nimport { SyncRunner } from \"./SyncRunner\"\nimport { Syncs } from \"./Syncs\"\n\nexport interface SyncServiceOptions {\n  setupExecutor: boolean\n}\n\nconst logger = mkLogger(\"SyncService\")\n\nexport interface SyncServiceStatus {\n  libraryPath: Maybe<string>\n  rpcPort: Maybe<number>\n  ending: boolean\n  done: boolean\n  sync: Maybe<string>\n  progress: Maybe<Progress | Progress[]>\n  healthChecks: HealthCheckResult\n}\n\n/**\n * SyncService hosts the AllDrivesSync or DirectorySync instances, and feeds a\n * batch-cluster-managed set of sync-file processes (which do the actual work\n * of importing files into PhotoStructure)\n */\nexport class SyncService {\n  private readonly logger = mkLogger(\"SyncService\")\n  readonly service: Service\n  readonly exitWhenDone: boolean\n  private readonly progressUpdater = lazy(\n    () => new ProgressUpdater(() => this.sync())\n  )\n  private processCount = 0 // used for tmp file cleanups\n  private readonly imgFileCleanup: TmpfileCleanup\n\n  // Assigned by setup():\n  private syncFileCluster!: BatchClusterObserver<BatchCluster>\n\n  /**\n   * @param importPath if provided, will override the library settings for\n   * what drives or directories to import.\n   */\n  constructor(\n    private readonly importPaths: string[] = p.argv.slice(2),\n    readonly ee: SimpleEventEmitter = eventEmitter\n  ) {\n    filterInPlace(importPaths, notBlank)\n    neverIgnore(...importPaths)\n    this.exitWhenDone =\n      Settings.exitWhenDone.valueOrDefault || isNotEmpty(importPaths)\n    this.service = new Service({\n      name: \"sync\"\n    })\n\n    onRpcServerChange(() =>\n      // The sync process should restart if the server changes: this might be\n      // due to settings being changed.\n      // See https://gitlab.com/photostructure/photostructure/issues/143\n      this.service.exit({\n        reason: \"rpcServerChange\",\n        status: 0,\n        waitForJobs: false\n      })\n    )\n\n    this.setup().catch(err =>\n      onError(\"setup() failed\", new WrappedError({ cause: err, fatal: true }))\n    )\n\n    // sync is in charge of keeping the cache dir clean:\n    this.imgFileCleanup = new TmpfileCleanup(imgCacheDir, 5 * minuteMs, f =>\n      f.pathnames.includes(ImgCacheName)\n    )\n\n    // No need to hold on to the readdir cache cleaner-upper:\n    new TmpfileCleanup(\n      async () => PosixFile.for(await readdirCacheDir()),\n      Settings.readdirCacheSeconds.valueOrDefault * secondMs,\n      f => f.pathnames.includes(ReadDirCacheName)\n    )\n  }\n\n  async done(): Promise<boolean> {\n    const s = await this.sync()\n    return s == null || s.done()\n  }\n\n  private onProcessed() {\n    this.processCount++\n    if (this.processCount % 50 === 0) {\n      void this.imgFileCleanup.cleanup()\n    }\n  }\n\n  async status() {\n    try {\n      const s = await this.sync.prior()\n      const hc = await healthChecks()\n      if (hasWarn(hc) || hasBad(hc) || hasFail(hc)) {\n        this.logger.info(\n          \"status(): healthcheck is sad, let's clean up tmpfiles\",\n          hc\n        )\n        void this.imgFileCleanup.cleanup(this.imgFileCleanup.maxAgeMs / 2)\n      }\n\n      const sss: SyncServiceStatus = {\n        libraryPath: Settings.libraryPath.value,\n        rpcPort: Settings.rpcPort.value,\n        ending: ending(),\n        done: await this.done(),\n        sync: map(s, ea => ea.name),\n        healthChecks: hc,\n        progress: await s?.progress()\n      }\n      stdoutWrite(sss)\n    } catch (error) {\n      stdoutWrite({ error })\n    }\n    return\n  }\n\n  readonly processFile: FileProcessor = async (\n    nativePath: string\n  ): PromiseMaybe<ImportResult> => {\n    try {\n      return await this.enqueueTask(new NativePathImportTask(nativePath))\n    } catch (error) {\n      logger.warn(\"Failed to process \" + nativePath, error)\n      return { path: nativePath, error }\n    }\n  }\n\n  private readonly setup = lazy(async () => {\n    if (await rejected(this.service.ready)) {\n      this.logger.warn(\"setup(): service.ready was rejected, exitting.\")\n      return\n    }\n\n    neverIgnore(...toA(this.importPaths))\n\n    if (Settings.forceSync.valueOrDefault) {\n      this.logger.info(\"setup(): --force: clearing cache directories \")\n      await clearCacheDirs()\n    }\n\n    const library = Library.instanceRequired()\n    this.logger.info(\"setup(): library is at \" + library.rootDir)\n\n    await library.ready\n\n    if (Settings.rebuild.valueOrDefault) {\n      this.logger.info(\n        \"setup(): --rebuild: setting all assets to require updates...\"\n      )\n      await forceRebuildLibrary()\n    }\n\n    this.syncFileCluster = await this.mkSyncFileCluster()\n\n    await this.sync()\n\n    // Now we can set up the progress updater:\n    await this.progressUpdater()\n\n    // Only add this handler once we've got a sync to play with. This overrides\n    // the default status handler.\n    this.service.setInputHandler(\"--status\", () => this.status())\n    this.service.setInputHandler(\"--cancel-sync\", () => this.cancelSync())\n    p.on(\"SIGUSR1\", () => this.cancelSync())\n\n    if (isTest && isNotEmpty(this.importPaths)) {\n      onProgressEvt(ea => console.log(stringify(ea)))\n    }\n\n    const skipPreviews = false\n    eventEmitter.on(\"repairAsset\", ea =>\n      this.repairAsset(ea?.assetId, orElse(ea?.force, true), skipPreviews)\n    )\n\n    eventEmitter.on(\"repairAssetFile\", ea =>\n      this.repairAssetFile(ea?.assetFileId, orElse(ea?.force, true))\n    )\n\n    onVolumesChanged(() => this.maybeRestartSyncOnVolumeChange())\n  })\n\n  async enqueueUpdateTask(cmd: UpdateCommand) {\n    const start = Date.now()\n    const result = await this.enqueueTask(new UpdateTask(cmd))\n    if (isTest)\n      stdoutWrite({\n        ...cmd,\n        elapsedMs: Date.now() - start,\n        ...result\n      })\n    return result\n  }\n\n  private readonly taskDataChunkers = new Map<string, Chunker>()\n\n  private async enqueueTask<T>(task: Task<T>): PromiseMaybe<T> {\n    if (ending()) return\n    await this.setup()\n    const bc = await this.syncFileCluster?.t\n    if (bc == null) {\n      return this.logger.throw(\"syncFileCluster is undefined\")\n    }\n    return retryOnReject(\n      async () => {\n        if (ending()) return\n        const key = toS(task)\n        try {\n          this.taskDataChunkers.set(\n            key,\n            new Chunker(\"\\n\", ea => this.onTaskData(ea), true)\n          )\n          return await bc.enqueueTask(task)\n        } finally {\n          this.onProcessed()\n          this.taskDataChunkers.delete(key)\n        }\n      },\n      {\n        maxRetries: 2, // handle sync-file instances getting restarted due to high memory\n        errorIsRetriable: isRetriableError\n      }\n    )\n  }\n\n  async repairAsset(assetId: number, force: boolean, skipPreviews: boolean) {\n    this.logger.info(\"Asked to repair asset \", { assetId, force, skipPreviews })\n    return mapGt0(assetId, ea =>\n      this.enqueueUpdateTask({ updateAssetId: ea, force, skipPreviews })\n    )\n  }\n\n  async repairAssetFile(assetFileId: number, force: boolean) {\n    this.logger.info(\"Asked to repair assetFile\", { assetFileId })\n    return mapGt0(assetFileId, ea =>\n      this.enqueueUpdateTask({ updateAssetFileId: ea, force })\n    )\n  }\n\n  async repairAssetPreviews(assetId: number, force: boolean) {\n    this.logger.info(\"Asked to repair asset preview\", { assetId })\n    return mapGt0(assetId, ea =>\n      this.enqueueUpdateTask({ updateAssetPreviewId: ea, force })\n    )\n  }\n\n  async cancelSync() {\n    const s = await this.sync()\n    if (!s.done()) {\n      this.logger.info(\"cancelSync(): ending current sync...\")\n      await s.end()\n    } else {\n      this.logger.info(\"cancelSync(): No sync to end.\")\n    }\n  }\n\n  private readonly mkSyncFileCluster = lazy(async () => {\n    this.taskDataChunkers.clear()\n    const syncFile = await pathToService(\"sync-file\")\n    if (syncFile == null) {\n      return this.logger.throw(\"Could not find sync-file\")\n    }\n    this.logger.info(\"syncFileCluster(): sync-file found at \" + syncFile)\n\n    const maxProcAgeMillis = MaxSyncFileTimeoutMs * 2\n\n    const bc = new BatchCluster({\n      processFactory: () => {\n        this.logger.info(\"Spawning new sync-file\", {\n          execPath: process.execPath,\n          syncFile: syncFile.nativePath,\n          maxProcs: maxSyncFileJobs()\n        })\n        return spawn(\n          process.execPath,\n          [...nodeArgs(\"sync-file\"), syncFile.nativePath],\n          maxProcAgeMillis\n        )\n      },\n\n      maxProcs: maxSyncFileJobs() + 1,\n      // Shut down idle sync-files after a minute:\n      maxIdleMsPerProcess: 5 * minuteMs,\n      maxTasksPerProcess: Settings.maxTasksPerProcess.valueOrDefault,\n      // it shouldn't take longer than a second for node to spin up, but\n      // antivirus and slow external disks can cause huge latency:\n      spawnTimeoutMillis: CmdTimeoutMs,\n      taskTimeoutMillis: undefined, // we're handling this.\n      endGracefulWaitTimeMillis: minuteMs,\n      maxProcAgeMillis,\n      versionCommand: \"--version\",\n      pass: ReadyStr,\n      fail: FatalErrorRe,\n      exitCommand: \"--exit\",\n      cleanupChildProcs: false // We'll take care of it with the pid reaper.\n    })\n    // Use different Chunkers per task.\n    bc.on(\"taskData\", (data: string | Buffer, task) => {\n      if (data != null && task != null)\n        this.taskDataChunkers.get(toS(task))?.onChunk(data)\n    })\n    // sync file processing should end ASAP, while the db service is still\n    // around:\n    return new BatchClusterObserver(\"sync-file\", bc, EndableRanks.first)\n  })\n\n  private onTaskData(s: string) {\n    const json = orElse(\n      Try(() => JSON.parse(s)),\n      {}\n    )\n    if (isProgressEvt(json)) {\n      if (isTest) stdoutWrite(json)\n      emitProgressEvt(json)\n    }\n  }\n\n  private readonly currentWorkQueueLength = () =>\n    mapOr(\n      this.syncFileCluster,\n      ea => ea.t.busyProcs + ea.t.pendingTasks,\n      () => 0\n    )\n\n  private readonly setupStatsDb = lazy(() => {\n    return Library.instanceRequired().statsDb()\n  })\n\n  private readonly assetFileUpdater = (assetFileId: number) =>\n    this.repairAssetFile(assetFileId, false)\n\n  private readonly modelDbUpdater = lazy(async () => {\n    if (Settings.skipModelUpdates.valueOrDefault) {\n      this.logger.info(\"modelDbUpdater: skipUpdates is set.\")\n      return\n    }\n    const mdu = new ModelDbUpdater({\n      assetFileUpdater: this.assetFileUpdater,\n      assetUpdater: (assetId: number) => {\n        return this.repairAsset(assetId, false, true)\n      },\n      assetPreviewUpdater: (assetId: number) => {\n        return this.repairAssetPreviews(assetId, false)\n      },\n      currentWorkQueueLength: this.currentWorkQueueLength\n    })\n\n    // we want this to happen in the background, so we're not awaiting it:\n\n    void mdu.donePromise().then(async () => {\n      // allow mdu to be GC'ed:\n      this.logger.info(\"modelDbUpdater completed.\")\n      void this.sync.refresh()\n    })\n    mdu.donePromise().catch(err => {\n      onError(\"ModelDbUpdater failed\", err)\n      void this.sync.refresh()\n    })\n\n    return mdu\n  })\n\n  private readonly directoryTaggerOp = lazy(() => {\n    const dto = new DirectoryTaggerOperation()\n    void dto.donePromise().then(async () => {\n      // allow mdu to be GC'ed:\n      this.logger.info(\"directoryTaggerOp completed. Starting normal sync.\")\n      void this.sync.refresh()\n    })\n    return dto\n  })\n\n  async restartSync() {\n    await end(this.sync.clear(), minuteMs) // in case it's in the middle of a sync-file\n    return this.sync()\n  }\n\n  readonly maybeRestartSyncOnVolumeChange = throttle(async () => {\n    const s = await this.sync.prior()\n    if (s instanceof SyncRunner) {\n      void s.maybeSetupNextSync()\n    }\n  }, MountpointsTtlMs)\n\n  readonly sync = lazy(async () => {\n    await this.setupStatsDb()\n\n    {\n      const mdu = await this.modelDbUpdater()\n      if (mdu != null && !mdu.done()) {\n        return mdu\n      }\n    }\n\n    {\n      const dto = this.directoryTaggerOp()\n      if (!dto.done()) {\n        return dto\n      }\n    }\n\n    const result = isNotEmpty(this.importPaths)\n      ? Syncs.forPaths(\n          this.importPaths,\n          this.processFile,\n          this.assetFileUpdater,\n          this.currentWorkQueueLength\n        )\n      : new SyncRunner(\n          this.processFile,\n          this.assetFileUpdater,\n          this.currentWorkQueueLength\n        )\n\n    if (this.exitWhenDone) {\n      void delay(secondMs)\n        .then(() => map(result, ea => ea.donePromise()))\n        .then(() => delay(secondMs)) // let the final progress commit\n        .catch(err =>\n          this.service.exit({\n            reason: \"Error: \" + err,\n            status: 12,\n            waitForJobs: false\n          })\n        )\n        .then(() =>\n          this.service.exit({\n            reason: \"Finished\",\n            status: 0,\n            waitForJobs: true\n          })\n        )\n    }\n\n    return result\n  })\n}\n", "import { SpawnOptions } from \"child_process\"\nimport { cwd, execPath } from \"process\"\nimport { clearInterval } from \"timers\"\nimport { isNotEmpty } from \"../../fe/Array\"\nimport { blank, notBlank } from \"../../fe/Blank\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { orElse } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { pick } from \"../../fe/Object\"\nimport { isFunction } from \"../../fe/ObjectType\"\nimport { SyncOrAsync } from \"../../fe/OptAsync\"\nimport { toA } from \"../../fe/toA\"\nimport { toS } from \"../../fe/toS\"\nimport { firstAsync } from \"../Array\"\nimport { Deferred } from \"../async/Deferred\"\nimport {\n  addFirstEndable,\n  Endable,\n  EndableRanks,\n  ending\n} from \"../async/Endable\"\nimport { serially } from \"../async/Promises\"\nimport { setUnrefInterval } from \"../async/Timers\"\nimport { onError } from \"../error/Error\"\nimport {\n  DoNotSendErrorFlag,\n  HealthCheckErrorFlag,\n  isIgnorableError\n} from \"../error/ErrorTypes\"\nimport { BaseFile } from \"../fs/BaseFile\"\nimport { Logger, mkLogger } from \"../Logger\"\nimport { Pojo } from \"../Object\"\nimport { isPacked } from \"../Platform\"\nimport { ServiceName } from \"../ServiceNames\"\nimport { Settings } from \"../settings/Settings\"\nimport { ensureSuffix } from \"../String\"\nimport { CmdTimeoutMs } from \"../volumes/VolumeTtls\"\nimport { SpawnOptionsWithLocale } from \"./ChildEnv\"\nimport { spawn } from \"./ChildProcess\"\nimport { errors, fullhc, HealthCheckResult } from \"./HealthChecks\"\nimport {\n  WatchedChild,\n  WatchedChildListener,\n  WatchedChildOpts\n} from \"./WatchedChild\"\n\nexport const ChildServiceExitCommand = \"--exit\"\n\nconst logger = lazy(() => mkLogger(\"ChildService\"))\n/**\n * Find the path the given command.\n *\n * If we're running from mocha, we want callerDirname + cmdBase. If this is\n * running in packaged electron, the script will live in the asar bundle.\n */\nexport async function pathToService(\n  cmdBase: ServiceName\n): PromiseMaybe<BaseFile> {\n  const cmd = ensureSuffix(cmdBase, \".js\")\n  const root = BaseFile.projectRoot()\n  const currDir = BaseFile.for(cwd())\n  const dirs = isPacked\n    ? [\n        // Expected path for PhotoStructure for Servers:\n        root.join(\"bin\", cmd),\n        // Expected electron production path is in the root of app.asar:\n        root.join(\"app.asar\", cmd)\n      ]\n    : [\n        // library tests:\n        currDir.join(\"dist\", \"library\", cmd),\n        // desktop tests:\n        currDir.join(\"lib\", \"library\", cmd)\n      ]\n\n  // for running out of src/desktop:\n  dirs.push(currDir.join(\"dist\", \"app\", cmd))\n\n  const result = firstAsync(dirs, async ea =>\n    (await ea.isNonEmpty(101)) ? ea : undefined\n  )\n  return logger().tap({\n    msg: \"pathToService()\",\n    level: \"info\",\n    result,\n    meta: { cmd, isPacked, dirs: dirs.map(toS) }\n  })\n}\n\nexport interface ChildServiceOpts {\n  nodeArgs?: string[]\n  args?: string[]\n  onData?(obj: Pojo): void\n  healthy?: () => SyncOrAsync<Maybe<boolean>>\n  onPreRestart?: () => any\n  /** only for the test service: */\n  pathToService?: BaseFile\n}\n\nlet syncFileCount = 0\nexport function inspectPort(cmd: ServiceName): number {\n  switch (cmd) {\n    case \"web\":\n      return 9223\n    case \"sync\":\n      return 9224\n    case \"sync-file\":\n      return 9225 + (syncFileCount++ % 20)\n    default:\n      return 9222\n  }\n}\n\nexport function nodeArgs(cmd: ServiceName): string[] {\n  const args = []\n  if (Settings.inspect.valueOrDefault) {\n    args.push(\"--inspect=\" + inspectPort(cmd))\n  }\n  return args\n}\n\n/**\n * ChildService configures a WatchedChild for use by a PhotoStructure service,\n * like `web` or `sync`, and adds health checks.\n */\nexport class ChildService implements Endable {\n  static async mk(\n    cmd: ServiceName,\n    opts: Partial<WatchedChildOpts & WatchedChildListener> &\n      ChildServiceOpts &\n      Partial<SpawnOptions> = {}\n  ): PromiseMaybe<ChildService> {\n    const pathTo = orElse(opts.pathToService, await pathToService(cmd))\n    if (blank(pathTo)) throw new Error(\"Failed to find path to \" + cmd)\n    opts.nodeArgs = [...nodeArgs(cmd), ...toA(opts.nodeArgs)]\n    return new ChildService(cmd, pathTo, opts)\n  }\n  readonly name: string\n  restartCount = 0\n  private _lastStatus?: Deferred<HealthCheckResult>\n\n  private readonly logger: Logger\n  private readonly healthCheckTimer: NodeJS.Timer\n  readonly wc: WatchedChild\n  readonly spawnOpts: SpawnOptionsWithLocale\n\n  private constructor(\n    name: ServiceName,\n    readonly cmd: BaseFile,\n    readonly opts: Partial<WatchedChildOpts & WatchedChildListener> &\n      ChildServiceOpts &\n      Partial<SpawnOptionsWithLocale>\n  ) {\n    this.name = \"ChildService(\" + name + \")\"\n    this.logger = mkLogger(this.name)\n    const spawnArgs = [...toA(opts.nodeArgs), cmd.nativePath]\n    if (isNotEmpty(opts.args)) {\n      spawnArgs.push(...opts.args)\n    }\n    this.spawnOpts = pick(\n      this.opts,\n      \"argv0\",\n      \"cwd\",\n      \"detached\",\n      \"env\",\n      \"gid\",\n      \"shell\",\n      \"stdio\",\n      \"timeout\",\n      \"uid\",\n      \"windowsHide\",\n      \"windowsVerbatimArguments\",\n      \"forceCLocale\"\n    )\n    // We don't want to force the locale for photostructure services\n    this.spawnOpts.forceCLocale = false\n    const maxAgeMs = -1\n    this.wc = new WatchedChild({\n      name,\n      childFactory: async () => {\n        if (this.restartCount > 0 && this.opts.onPreRestart != null) {\n          await this.opts.onPreRestart()\n        }\n        this.restartCount++\n        return spawn(execPath, spawnArgs, maxAgeMs, this.spawnOpts)\n      },\n      // other things may rely on the child to get cleanup work done:\n      endableRank: EndableRanks.service,\n      onStdout: this.onStdout.bind(this),\n      onError: orElse<WatchedChildListener[\"onError\"]>(\n        this.opts.onError,\n        () => (ea: any) => !isIgnorableError(ea) // < restart on any error emitted to stderr or stdout\n      ),\n      ignoreStopErrors: false,\n      exitCommand: ChildServiceExitCommand,\n      ...opts\n    })\n    this.healthCheckTimer = setUnrefInterval(() => this.healthCheck(), minuteMs)\n\n    addFirstEndable(this)\n  }\n\n  get startMs() {\n    return this.wc.startMs\n  }\n\n  private async onStdout(data: string) {\n    if (blank(data)) return\n    try {\n      const obj = JSON.parse(data)\n      if (notBlank(obj.fatal)) {\n        void this.wc.onError(this.name + \".onStdout()\", obj.error)\n      } else if (obj.healthChecks != null) {\n        // Don't pass health checks on. We've got it.\n        const d = this._lastStatus\n        if (d != null && d.pending) {\n          d.resolve({ ...obj.healthChecks, ts: Date.now() })\n        }\n      } else if (null != this.opts.onData) {\n        this.opts.onData(obj)\n      }\n    } catch (err) {\n      // Pass it on:\n      console.log(data)\n      // Don't grump too much:\n      // this.logger.warn(\"invalid JSON: \" + err, data)\n      // this.wc.onError(\"onStdout()\", err)\n    }\n  }\n\n  start() {\n    return this.wc.start()\n  }\n\n  stop() {\n    return this.wc.stop()\n  }\n\n  restart(force?: boolean) {\n    return this.wc.restart(force)\n  }\n\n  get ended() {\n    return this.wc.ended\n  }\n\n  async end() {\n    clearInterval(this.healthCheckTimer)\n    if (!this.wc.ended) await this.write(\"--quit\")\n    return this.wc.end()\n  }\n\n  get pid() {\n    return this.wc.pid\n  }\n\n  get msSinceLastStart() {\n    return this.wc.msSinceLastStart\n  }\n\n  running() {\n    return this.wc.running()\n  }\n\n  notRunning() {\n    return this.wc.notRunning()\n  }\n\n  async write(toStdin: string, retries = 2): Promise<boolean> {\n    if (retries < 0) {\n      this.logger.warn(\"write(): no more retries\", { toStdin })\n      return false\n    }\n\n    // Don't check for ended, because end() uses this.\n    try {\n      const childProc = this.wc.proc\n      if (\n        childProc == null ||\n        childProc.stdin == null ||\n        !childProc.stdin.writable\n      ) {\n        this.logger.warn(\"write(): childProc isn't open, ignoring\", { toStdin })\n        return false\n      }\n      return childProc.stdin.write(ensureSuffix(toStdin, \"\\n\"))\n    } catch (err) {\n      this.logger.warn(\"write(): caught \" + err)\n      // The only reason for an error here is if the proc is gone.\n      // onError returns the result of restart--if that is successful,\n      // try again.\n      await this.wc.onError(\"onStdout()\", err)\n      return this.write(toStdin, retries - 1)\n    }\n  }\n\n  readonly healthCheck = serially(\"ChildService.healthCheck\", async () => {\n    if (ending() || this.ended) return\n    this.logger.debug(\"healthCheck(): running...\")\n    if (isFunction(this.opts.healthy)) {\n      const result = await this.opts.healthy()\n      if (result === false) {\n        await this.restart()\n        return\n      }\n    }\n\n    const d = (this._lastStatus = new Deferred<HealthCheckResult>(\n      this.name + \" healthCheck at \" + new Date()\n    ).setTimeout(CmdTimeoutMs))\n    d.promise.catch(err => {\n      onError(\"healthCheck for \" + this.name + \": failed\", err)\n      return this.restart()\n    })\n\n    const written = await this.write(\"--status\")\n    if (!written) {\n      d.resolve(fullhc({ fail: [\"write --status failed\"] }))\n    }\n\n    try {\n      const hc = await d.promise\n      const err = errors(hc)\n      if (isNotEmpty(err)) {\n        this.logger.warn(\n          \"healthCheck for \" +\n            this.name +\n            \": unhealthy\" +\n            DoNotSendErrorFlag +\n            HealthCheckErrorFlag +\n            \", restarting (\" +\n            err.join(\",\") +\n            \")\"\n        )\n        await this.restart()\n        return\n      } else {\n        this.logger.debug(\"healthCheck: all is well\", hc)\n        return hc\n      }\n    } catch (err) {\n      this.logger.warn(\"healthCheck: failed\", err)\n      // assume we already requested a restart.\n      return\n    }\n  })\n}\n", "import { compact, flatten, isNotEmpty, uniq } from \"../../fe/Array\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { toA } from \"../../fe/toA\"\n\nexport interface HealthCheckResult {\n  /**\n   * Descriptions of passing diagnostics\n   */\n  ok: string[]\n\n  /**\n   * Non-fatal problems that may become fatal if they worsen (like free disk or\n   * memory use)\n   */\n  warn: string[]\n\n  /**\n   * Non-fatal, but bad problems. If they persist, the system should be\n   * restarted.\n   */\n  bad: string[]\n\n  /**\n   * Fatal problems (like the library is missing, or RPC is broken). Expect the\n   * service to be restarted or the system to shut down if this is non-empty.\n   */\n  fail: string[]\n}\n\nexport function hasWarn(hc: Partial<HealthCheckResult>): boolean {\n  return (hc != null && isNotEmpty(hc.warn)) || hasBad(hc)\n}\n\nexport function hasBad(hc: Partial<HealthCheckResult>): boolean {\n  return (hc != null && isNotEmpty(hc.bad)) || hasFail(hc)\n}\n\nexport function hasFail(hc: Partial<HealthCheckResult>): boolean {\n  return hc != null && isNotEmpty(hc.fail)\n}\n\nexport function errors(hc: Partial<HealthCheckResult>): string[] {\n  return uniq([...toA(hc?.bad), ...toA(hc?.fail)])\n}\n\nexport function warnings(hc: Partial<HealthCheckResult>): string[] {\n  return uniq([...toA(hc.warn), ...toA(hc.bad), ...toA(hc.fail)])\n}\n\nexport function fullhc(hc: Partial<HealthCheckResult>): HealthCheckResult {\n  return {\n    ok: toA(hc.ok),\n    warn: toA(hc.warn),\n    bad: toA(hc.bad),\n    fail: toA(hc.fail)\n  }\n}\n\nexport function uniqhc(\n  ...arr: Maybe<Partial<HealthCheckResult>>[]\n): HealthCheckResult {\n  const carr = compact(arr)\n  return {\n    ok: uniq(flatten(carr.map(ea => ea.ok))),\n    warn: uniq(flatten(carr.map(ea => ea.warn))),\n    bad: uniq(flatten(carr.map(ea => ea.bad))),\n    fail: uniq(flatten(carr.map(ea => ea.fail)))\n  }\n}\n\nexport function concatHealthChecks(\n  ...arr: Partial<HealthCheckResult>[]\n): HealthCheckResult {\n  arr = compact(arr)\n  function mfcu( // obviously, map-flatten-compact-uniq\n    f: (t: Partial<HealthCheckResult>) => Maybe<string[]>\n  ): string[] {\n    return uniq(compact(flatten(arr.map(f))))\n  }\n\n  return {\n    ok: mfcu(ea => ea.ok),\n    warn: mfcu(ea => ea.warn),\n    bad: mfcu(ea => ea.bad),\n    fail: mfcu(ea => ea.fail)\n  }\n}\n", "import { unrefDelay } from \"../../fe/Delay\"\nimport { map, mapOr, orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { gt0 } from \"../../fe/Number\"\nimport { toA } from \"../../fe/toA\"\nimport { EndableRank, EndableRanks } from \"./Endable\"\nimport { EndableWrapper } from \"./EndableWrapper\"\nimport { setUnrefInterval } from \"./Timers\"\n\nexport class EndableInterval extends EndableWrapper {\n  private timer: Maybe<NodeJS.Timer>\n  constructor(opts: {\n    name: string\n    callback: (...args: any[]) => void\n    intervalMs: number\n    initialDelayMs?: number\n    rank?: EndableRank\n    args?: any[]\n    _isEnded?: () => boolean\n    endTimeoutMs?: number\n  }) {\n    super(\n      opts.name,\n      () => {\n        map(this.timer, clearInterval)\n        this.timer = undefined\n      },\n      orElse(opts.rank, EndableRanks.first),\n      () =>\n        mapOr(\n          opts._isEnded,\n          f => f(),\n          () => false\n        ),\n      opts.endTimeoutMs\n    )\n    void this.setup(opts)\n  }\n\n  private async setup(opts: ConstructorParameters<typeof EndableInterval>[0]) {\n    if (gt0(opts.initialDelayMs)) await unrefDelay(opts.initialDelayMs)\n    if (this.ended) return\n    this.timer = setUnrefInterval(\n      opts.callback,\n      Math.round(opts.intervalMs),\n      ...toA(opts.args)\n    )\n  }\n}\n", "import { isNotEmpty } from \"../../fe/Array\"\nimport { minuteMs, secondMs } from \"../../fe/Date\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { clamp } from \"../../fe/Number\"\nimport { MaybeSyncOrAsync, SyncOrAsync } from \"../../fe/OptAsync\"\nimport { EndableInterval } from \"../async/EndableInterval\"\nimport { Promises } from \"../async/Promises\"\nimport { untilTrue } from \"../async/until\"\nimport { BaseFile } from \"./BaseFile\"\nimport { isNoMediaName } from \"./NoMedia\"\nimport { PosixFile } from \"./PosixFile\"\n\nexport class TmpfileCleanup extends EndableInterval {\n  readonly mutex = new Promises()\n  lastCleanupFinishTs = 0\n\n  constructor(\n    readonly root: () => MaybeSyncOrAsync<PosixFile>,\n    readonly maxAgeMs: number,\n    readonly filter: (file: BaseFile) => SyncOrAsync<boolean>,\n    readonly scheduleCleanup = true\n  ) {\n    super({\n      name: \"TmpfileCleanup\",\n      intervalMs: clamp(10 * secondMs, 15 * minuteMs, maxAgeMs / 5),\n      callback: () => this.cleanup()\n    })\n  }\n\n  async cleanup(maxAgeMs = this.maxAgeMs): PromiseMaybe<BaseFile[]> {\n    return this.ended || Date.now() - this.lastCleanupFinishTs < 10 * secondMs\n      ? undefined\n      : this.mutex.maybeRun(\"cleanup\", () => this._cleanup(maxAgeMs))\n  }\n\n  private async _cleanup(maxAgeMs: number): Promise<BaseFile[]> {\n    const root = await this.root()\n    if (root == null) return []\n    const maxTs = Date.now() - maxAgeMs\n    const result: BaseFile[] = []\n    await root.clear().visitDescendants(async f => {\n      // don't use minStatMs! If main is keeping a logfile open for ages, don't\n      // delete it.\n      const statMs = await f.maxStatMs()\n      if (\n        (await f.isFile()) &&\n        statMs != null &&\n        // Don't erase the .NoMedia file in the tmp directory:\n        !(f.parent().eql(root) && isNoMediaName(f.base)) &&\n        (await this.filter(f)) &&\n        statMs < maxTs\n      ) {\n        result.push(f)\n        await f\n          .unlink()\n          .catch(err => this.logger.warn(\"Failed to unlink \" + f, err))\n      }\n    })\n    const fileCount = result.length\n    this.logger.info(\"Removed \" + fileCount + \" files.\")\n    await root.clear().visitDescendants(async f => {\n      f.clear()\n      if ((await f.isDirectory()) && !(await f.hasNoChildren())) {\n        // Did we just delete the children?\n        const childNames = await f.childDirectoryEntries()\n        if (isNotEmpty(childNames)) {\n          const childPaths = childNames.map(ea => ea.nativePath)\n          const allChildrenWereUnlinked = childPaths.every(ea =>\n            result.some(victim => victim.nativePath === ea)\n          )\n          if (allChildrenWereUnlinked) {\n            if (await untilTrue(() => f.rmdir(), { timeoutMs: 7 * secondMs })) {\n              result.push(f)\n            }\n          }\n        }\n      }\n      if ((await f.isDirectory()) && (await f.hasNoChildren())) {\n        result.push(f)\n        await f\n          .rmdir()\n          .catch(err => this.logger.warn(\"Failed to rmdir \" + f, err))\n      }\n      return\n    })\n    this.logger.info(\n      \"Pruned \" + (result.length - fileCount) + \" empty directories.\"\n    )\n    this.lastCleanupFinishTs = Date.now()\n    return result\n  }\n}\n", "import { FileTypeResult, fromBuffer } from \"file-type\"\nimport { stat } from \"fs-extra\"\nimport { extname } from \"path\"\nimport { notBlank } from \"../../fe/Blank\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { later } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { thenOpt } from \"../../fe/OptAsync\"\nimport { resolved } from \"../async/Promise\"\nimport { onClearCache, onFileChanged } from \"../event/EventEmitter\"\nimport { FifoCache } from \"../FifoCache\"\nimport { stripPrefix } from \"../String\"\nimport { exiftool } from \"../tags/ExifTags\"\nimport { readFilePart } from \"./ReadFilePart\"\n\nlater(() => {\n  onClearCache(() => cache.prior()?.clear())\n  onFileChanged(ea =>\n    ea == null ? cache.prior()?.clear() : cache.prior()?.delete(ea)\n  )\n})\n\nconst cache = lazy(\n  () => new FifoCache<PromiseMaybe<FileTypeResult>>(512, 3 * minuteMs)\n)\n\nexport async function readFileType(\n  nativePath: string\n): PromiseMaybe<FileTypeResult> {\n  // PERF: don't stat then read. Just hit it.\n  return cache().getOrSet(nativePath, async () => {\n    // We need to fetch at least 197 to work with AVCHD properly:\n    const { buffer } = await readFilePart(nativePath, 0, 248)\n    return thenOpt(fromBuffer(buffer))\n      .filter(ea => ea.mime !== \"image/tiff\")\n      .orElse(() =>\n        thenOpt(resolved(stat(nativePath)))\n          .filter(ea => ea)\n          .flatMap(() => exiftool().readRaw(nativePath, [\"-mimetype\"]))\n          .flatMap(t => t.MIMEType)\n          .filter(notBlank)\n          .map(\n            mime => ({ ext: extractExt(nativePath), mime } as FileTypeResult)\n          )\n          .get()\n      )\n      .get()\n  })\n}\n\nfunction extractExt(nativePath: string) {\n  return stripPrefix(extname(nativePath), \".\")\n}\n", "import { ExifTool, Tags, WriteTags } from \"exiftool-vendored\"\nimport { extname } from \"path\"\nimport { ExposureSettings } from \"../../fe/api/ExposureSettings\"\nimport { compactBlanks, isNotEmpty, uniq } from \"../../fe/Array\"\nimport { blank } from \"../../fe/Blank\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { later } from \"../../fe/Delay\"\nimport { Dimensions } from \"../../fe/Dimensions\"\nimport { errorToS } from \"../../fe/Error\"\nimport { Latch } from \"../../fe/Latch\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { keys, omit, values } from \"../../fe/Object\"\nimport { toS } from \"../../fe/toS\"\nimport { EndableRanks } from \"../async/Endable\"\nimport { firstDefinedLater } from \"../async/Later\"\nimport { thenCollectParallel, thenMap } from \"../async/Promise\"\nimport { time } from \"../async/PromiseTimer\"\nimport { thenOrTimeout } from \"../async/thenOrTimeout\"\nimport { BatchClusterObserver } from \"../BatchClusterObserver\"\nimport { thenElapsed } from \"../Elapsed\"\nimport { eqlAsync } from \"../Eql\"\nimport {\n  emitFileChanged,\n  onClearCache,\n  onFileChanged,\n  onFileCopied\n} from \"../event/EventEmitter\"\nimport { FifoCacheAsync } from \"../FifoCache\"\nimport { readFileType } from \"../fs/FileType\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { rawInfo } from \"../img/RawInfo\"\nimport { extractVideoFrame } from \"../img/Video\"\nimport { isVideoMimeType } from \"../img/VideoFilter\"\nimport { mkLogger } from \"../Logger\"\nimport { safeUUID } from \"../math/UUID\"\nimport { assignFields } from \"../Object\"\nimport { isWin } from \"../Platform\"\nimport { Settings } from \"../settings/Settings\"\nimport { CmdTimeoutMs } from \"../volumes/VolumeTtls\"\nimport { maxCpus } from \"../work/MaxCpus\"\nimport { parseBinaryField } from \"./BinaryTag\"\nimport { CapturedAt, extractCapturedAt } from \"./CapturedAt\"\nimport { extractDurationSec } from \"./Duration\"\nimport { extractExposureSettings } from \"./ExposureSettings\"\nimport { isExifExt, isVideoExt } from \"./FileExts\"\nimport { readJsonSidecar } from \"./JsonSidecar\"\nimport { extractLensMakeModel, LensInfo } from \"./LensMakeModel\"\nimport { make, model } from \"./MakeModel\"\nimport { isLibrawMimetype } from \"./Mimetypes\"\nimport { extractRotation } from \"./Orientation\"\nimport { extractSizeInfo, SizeInfo } from \"./SizeInfo\"\nimport { inferMakeAndModel } from \"./TagInference\"\nimport { extractTitleDescription } from \"./TitleDescription\"\nimport { TzInfo } from \"./TzInference\"\n\nconst logger = lazy(() => mkLogger(\"ExifTags\"))\n\nlet _addInstanceIdsToTags = false\n\nexport function addInstanceIdsToTags(b: boolean) {\n  _addInstanceIdsToTags = b\n}\n\nexport interface WithSidecars {\n  sidecars?: string[]\n}\n\ninterface TimedTags extends Tags {\n  exiftoolMs: number\n}\n\nexport interface OriginalTags {\n  originalMake: Tags[\"Make\"]\n  originalModel: Tags[\"Model\"]\n}\n\nexport interface ExifTags\n  extends TimedTags,\n    SizeInfo,\n    Partial<LensInfo>,\n    Partial<TzInfo>,\n    WithSidecars,\n    OriginalTags {\n  mimetype: string // guaranteed field\n  ImageHeight: number // assert that ImageHeight will be set\n  ImageWidth: number // assert that ImageWidth will be set\n  /**\n   * These are the dimensions of the image **after rotation**.\n   */\n  dimensions: Dimensions\n  /**\n   * These are the dimensions of the current image on disk (before any rotation)\n   */\n  fileDimensions: Dimensions\n  capturedAt: CapturedAt\n  duration?: number\n  exposureSettings?: ExposureSettings\n\n  title?: string\n  description?: string\n\n  /**\n   * stringified collection of errors and warnings\n   */\n  problems?: string[]\n}\n\nexport function setExifToolProcs(i: number) {\n  Settings.exiftoolProcsPerChild.tmpValue = i\n  return shutdownExiftool()\n}\n\nfunction maxProcs() {\n  return Settings.exiftoolProcsPerChild.value ?? (maxCpus() > 4 ? 3 : 2)\n}\n\nconst _exiftool = lazy(() => {\n  return new BatchClusterObserver(\n    \"ExifTool\",\n    new ExifTool({\n      logger: () => mkLogger(\"ExifTool\"),\n      maxProcs: maxProcs(),\n      // Shut down idle exiftool instances after a couple minutes:\n      maxIdleMsPerProcess: 5 * minuteMs,\n      maxTasksPerProcess: Settings.maxTasksPerProcess.valueOrDefault,\n      cleanupChildProcs: false // we'll handle it, thanks.\n    }),\n    // Other things may need tags to complete their work, so I'm a service:\n    EndableRanks.service,\n    true // < addExitHandler, to prevent exiftool zombies on Alpine\n  ).t\n})\n\nexport function exiftool() {\n  const et = _exiftool()\n  return et.ended ? _exiftool.refresh() : et\n}\n\nexport function exiftoolVersion() {\n  return thenOrTimeout(exiftool().version(), CmdTimeoutMs, () => {\n    throw new Error(\"ExifTool timed out\")\n  })\n}\n\n/**\n * If this process hasn't started exiftool, don't bother.\n */\nexport function exiftoolVersionMaybe() {\n  return map(_exiftool.prior(), et =>\n    et.ended\n      ? undefined\n      : thenOrTimeout(et.version(), CmdTimeoutMs, () => {\n          throw new Error(\"ExifTool timed out\")\n        })\n  )\n}\n\n// Primarily for tests:\nexport function shutdownExiftool(gracefully: boolean = false) {\n  return map(_exiftool.clear(), ea => ea.end(gracefully))\n}\n\nonFileCopied((srcNativePath: string, destNativePath: string) =>\n  thenMap(cachedTags(srcNativePath), tags => {\n    const dest = PosixFile.for(destNativePath)\n    return tagsCache.getOrSetAsync(dest.nativePath, () =>\n      Promise.resolve({\n        ...tags,\n        SourceFile: dest.nativePath,\n        FileName: dest.base,\n        Directory: dest.dir\n      })\n    )\n  })\n)\n\n/**\n * @throws on error\n */\nexport function extractBinaryTag(\n  tagname: string,\n  src: string,\n  dest: string\n): Promise<void> {\n  return exiftool().extractBinaryTag(tagname, src, dest)\n}\n\nconst tagsCache = new FifoCacheAsync<Maybe<ExifTags>>({\n  maxSize: 128,\n  timeoutMs: minuteMs\n})\n\n// Only exposed for tests\nexport const rawTagsCache = new FifoCacheAsync<Maybe<TimedTags>>({\n  maxSize: 128,\n  timeoutMs: minuteMs\n})\n\nexport function clearTagsCache() {\n  tagsCache.clear()\n  rawTagsCache.clear()\n}\n\nlater(() => onClearCache(clearTagsCache))\n\nonFileChanged(path => {\n  if (blank(path)) {\n    clearTagsCache()\n  } else {\n    tagsCache.deleteIf(key => key.startsWith(path))\n    rawTagsCache.deleteIf(key => key.startsWith(path))\n  }\n})\n\nconst IgnoredSidecarFields = [\n  \"Directory\",\n  \"FileAccessDate\",\n  \"FileInodeChangeDate\",\n  \"FileModifyDate\",\n  \"FileName\",\n  \"FilePermissions\",\n  \"FileSize\",\n  \"FileType\",\n  \"FileTypeExtension\",\n  \"MIMEType\",\n  \"RAFVersion\",\n  \"SourceFile\"\n]\n\nexport async function sidecarEql(a: PosixFile, b: PosixFile): Promise<boolean> {\n  const sidecarTags = (f: PosixFile) =>\n    thenMap(readRawTags(f, false), ea => omit(ea, ...IgnoredSidecarFields))\n\n  return (\n    (await eqlAsync(a.clear().sha(), b.clear().sha())) ||\n    (await eqlAsync(sidecarTags(a), sidecarTags(b)))\n  )\n}\n\n/**\n * Fetch the ExifTags for the given file. If a UID cannot be found, tag values\n * will be (hopefully safely) borrowed from directory siblings.\n */\nexport async function readTags(\n  pathOrFile: Maybe<string | PosixFile>\n): PromiseMaybe<ExifTags> {\n  if (pathOrFile == null) return\n  const f = PosixFile.for(pathOrFile)\n  if ((await f.isEmpty()) || (await f.isNotReadable())) return\n  return time(\"tags.readTags\", async () =>\n    thenMap(readRawTags(f), ea => parseTags(f, ea))\n  )\n}\n\nexport async function cachedTags(\n  pathOrFile: string | PosixFile\n): PromiseMaybe<ExifTags> {\n  return tagsCache.get(String(pathOrFile))\n}\n\n// Convenience methods:\n\nexport async function capturedAt(\n  pathOrFile: string | PosixFile\n): PromiseMaybe<CapturedAt> {\n  return thenMap(readTags(pathOrFile), t => t.capturedAt)\n}\n\nexport async function mimetype(\n  pathOrFile: string | PosixFile\n): PromiseMaybe<string> {\n  if (blank(pathOrFile)) return\n  const f = PosixFile.for(pathOrFile)\n  return firstDefinedLater(\n    () => thenMap(rawTagsCache.get(f.nativePath), ea => ea.MIMEType),\n    () => thenMap(cachedTags(f), ea => ea.MIMEType),\n    () =>\n      thenMap(readFileType(f.nativePath), ea =>\n        // don't trust FileType for image/tiffs:\n        ea.mime === \"image/tiff\" ? undefined : ea.mime\n      ),\n    // readFileType doesn't support all types, so we may have to use ExifTool, but only if it's a legit filetype.\n    () =>\n      isExifExt(f.ext)\n        ? thenMap(readRawTags(f, false), ea => ea.MIMEType)\n        : undefined\n  )\n}\n\nexport async function readRotation(\n  pathOrFile: string | PosixFile\n): PromiseMaybe<number> {\n  // We want to pick up rotation from a sidecar, if present:\n  return thenMap(readRawTags(pathOrFile, true), extractRotation)\n}\n\nexport async function isMimetype(\n  pathOrFile: string | PosixFile,\n  mimetypes: Set<string>\n): Promise<boolean> {\n  const mimeType = await mimetype(pathOrFile)\n  return logger().tap({\n    msg: \"isMimetype\",\n    meta: { path: toS(pathOrFile), mimeType },\n    result: mimeType != null && mimetypes.has(mimeType)\n  })\n}\n\nexport async function sizeInfo(\n  pathOrFile: string | PosixFile,\n  defaultTags?: Tags\n): PromiseMaybe<SizeInfo> {\n  const f = PosixFile.for(pathOrFile)\n\n  // defaultTags is set by tests and by videos after we extract a frame:\n  const t =\n    defaultTags == null || blank(defaultTags.ImageHeight)\n      ? await readRawTags(f)\n      : defaultTags\n  if (t == null) return\n\n  // If the video has a rotation value (or a sidecar with a rotation value), use\n  // that:\n  const rot = orElse(extractRotation(defaultTags), () => extractRotation(t))\n\n  // Only fetch raw information if it's a raw image mimetype:\n  const ri = isLibrawMimetype(t.MIMEType)\n    ? await rawInfo(f).catch(err => {\n        logger().warn(\"Failed to read raw info\", {\n          file: f.nativePath,\n          err: errorToS(err)\n        })\n        return undefined\n      })\n    : undefined\n\n  const si = extractSizeInfo(t, rot, ri)\n  if (si != null) return si\n\n  if (isVideoMimeType(t.MIMEType)) {\n    return thenMap(extractVideoFrame(f, t.MIMEType!), ea => sizeInfo(ea, t))\n  } else {\n    return\n  }\n}\n\n/**\n * ExifTool writes \"file.jpg_original\" files. Rename them to\n * \"file_original_06.jpg\" so the file extension isn't bogus.\n */\nexport async function moveOriginal(\n  src: PosixFile,\n  suffix = \"_original\"\n): PromiseMaybe<PosixFile> {\n  return src\n    .sibling(src.base + suffix)\n    .saveIfNewOrDelete(src.name + suffix + src.ext)\n}\n\nexport async function deleteAllTags(src: PosixFile) {\n  await exiftool().deleteAllTags(src.nativePath)\n  await src.sibling(src.base + \"_original\").unlink(\"trace\") // don't care if it's missing\n  return\n}\n\nexport function writeTags(\n  src: PosixFile,\n  tags: WriteTags,\n  srcMimeType: string\n): Promise<{ original?: PosixFile; dest: PosixFile }> {\n  return time(\"tags.writeTags\", async () => {\n    const sidecar = await src.sidecar()\n    const isVideo = isVideoMimeType(srcMimeType)\n    const useSidecar =\n      (isVideo && Settings.writeMetadataToSidecarsIfVideo.valueOrDefault) ||\n      (!isVideo && Settings.writeMetadataToSidecarsIfImage.valueOrDefault) ||\n      (await sidecar.exists())\n    const dest = useSidecar ? sidecar : src\n    await exiftool().write(\n      dest.nativePath,\n      tags,\n      Settings.overwriteOriginal.valueOrDefault\n        ? [\"-overwrite_original\"]\n        : undefined\n    )\n    const original = await moveOriginal(dest)\n    uniq([src.nativePath, dest.nativePath]).forEach(emitFileChanged)\n    src.clearThisAndParent() // < because the source tags should re-read the sidecar tags\n    dest.clearThisAndParent() // < this clears everything parent and down.\n    return { original, dest }\n  })\n}\n\n/**\n * Return the raw, unparsed tags for `bf`, and merge tags from any sidecars.\n */\nexport async function readRawTags(\n  f: string | PosixFile,\n  includeSidecars = true\n): PromiseMaybe<TimedTags & WithSidecars> {\n  const pf = PosixFile.for(f)\n  if (!(await pf.isFile())) return\n\n  return time(\"tags.readRawTags\", async () => {\n    const fileTags = await _readRawTags(pf.nativePath)\n    if (fileTags == null || !includeSidecars) return fileTags\n\n    const jsonTagsP = thenCollectParallel(pf.jsonSidecars(), readJsonSidecar)\n    const sidecarTagsP = thenCollectParallel(pf.sidecars(), ea =>\n      _readRawTags(ea.nativePath)\n    )\n\n    const result: TimedTags & WithSidecars = {\n      ...fileTags\n    }\n\n    for (const [sidecarTags, sidecar] of [\n      ...(await jsonTagsP),\n      ...(await sidecarTagsP)\n    ]) {\n      const safeTags = omit(sidecarTags, ...IgnoredSidecarFields)\n      if (isNotEmpty(values(safeTags))) {\n        ;(result.sidecars ??= []).push(sidecar.base)\n        assignFields(result, safeTags)\n        logger().debug(\"readRawTags() sidecar had values\", {\n          sidecar: sidecar.base,\n          safeTags\n        })\n      } else {\n        logger().debug(\"readRawTags() sidecar was empty\", {\n          sidecar: sidecar.base\n        })\n      }\n    }\n    return result\n  })\n}\n\n// Windows requires the first use of ExifTool to spin up completely before other\n// instances can.\nconst firstStarted = new Latch()\nconst firstFinished = new Latch()\n\nif (!isWin) {\n  void firstStarted.resolve()\n  void firstFinished.resolve()\n}\n\n/**\n * This doesn't handle sidecars. You want `readRawTags`.\n */\nasync function _readRawTags(nativePath: string) {\n  // If we have it *with* sidecars, return that:\n\n  return rawTagsCache.getOrSetAsync(nativePath, async () => {\n    logger().debug(\"_readRawTags(\" + nativePath + \") not cached, reading now.\")\n    // Are we the first?\n    const iAmFirst = firstStarted.pending\n    if (iAmFirst) {\n      void firstStarted.resolve()\n    } else {\n      await firstFinished.promise\n    }\n\n    // We need to read the whole file to get video duration. [] disables the\n    // default or [\"-fast\"]:\n    const args = isVideoExt(extname(nativePath)) ? [] : undefined\n\n    const result = await time(\"exiftool.read()\", () =>\n      thenOrTimeout(\n        thenElapsed(\n          exiftool()\n            .read(nativePath, args)\n            .catch(err => {\n              logger().info(\"Failed to read \" + nativePath, err)\n              return undefined\n            })\n        ),\n        CmdTimeoutMs\n      )\n    )\n    if (iAmFirst) {\n      void firstFinished.resolve()\n    }\n    return map(result, ea => {\n      logger().debug(\n        \"_readRawTags(\" + nativePath + \") in \" + ea.elapsedMs + \"ms\"\n      )\n      return map(ea.result, t => {\n        // PERF: no maps here as there are tons of fields.\n        for (const key of keys(t)) {\n          const v = t[key]\n          if (typeof v === \"string\") {\n            const bf = parseBinaryField(v)\n            if (bf != null) t[key] = bf as any\n          }\n        }\n        const problems = compactBlanks(\n          [t.Error, ...orElse(t.errors, []), t.Warning].map(toS)\n        )\n        if (isNotEmpty(problems)) {\n          t[\"problems\"] = problems\n        }\n        t[\"exiftoolMs\"] = ea.elapsedMs\n        if (_addInstanceIdsToTags) t[\"instance\"] = safeUUID()\n        return t as TimedTags\n      })\n    })\n  })\n}\n\n/**\n * NOT FOR PUBLIC CONSUMPTION only exposed for tests\n */\nexport async function parseTags(\n  f: PosixFile,\n  t: Maybe<TimedTags>\n): PromiseMaybe<ExifTags> {\n  if (t == null) return\n\n  const m = t.MIMEType\n  const nativePath = f.nativePath\n\n  if (blank(m)) {\n    logger().debug(\"No mimetype for \" + f)\n    return\n  }\n\n  const skipInference =\n    f.nativePath.startsWith(Settings.cacheDir.valueOrDefault) ||\n    f.pathnames.includes(\".photostructure\")\n\n  if (!skipInference) {\n    await inferMakeAndModel(f, t)\n  }\n\n  // const tzInfo = await inferTz(f, t)\n\n  const a = t as OriginalTags & TimedTags\n\n  // DON'T USE DeviceModel or DeviceManufacturer: those are from the ICC\n  // profile!\n\n  a.originalMake = t.Make\n  a.originalModel = t.Model\n\n  t.Make = make(t.Make)\n  t.Model = model(t.Make, t.Model)\n\n  const lensMakeModel = extractLensMakeModel(t)\n\n  const capturedAt_ = await extractCapturedAt(f, t, skipInference)\n  if (capturedAt_ == null) {\n    logger().info(\"No capturedAt for \" + f)\n    return\n  }\n  const exposureSettings = extractExposureSettings(t)\n\n  const si = await sizeInfo(f, t)\n  if (si == null) {\n    logger().info(\"No size info for \" + nativePath)\n    return\n  }\n\n  const duration = m.startsWith(\"video/\") ? extractDurationSec(t) : undefined\n\n  const obj = {\n    mimetype: m,\n    exposureSettings,\n    ...extractTitleDescription(a),\n    ...lensMakeModel,\n    ...si,\n    duration,\n    capturedAt: capturedAt_,\n    // ...tzInfo,\n    tz: t.tz\n  }\n\n  logger().debug(\"parsedTags\", {\n    nativePath,\n    ...obj,\n    // tzInfo\n    capturedAt: map(capturedAt_, ea => ({\n      date: ea.date,\n      src: ea.src\n    }))\n  })\n\n  return {\n    ...a,\n    ...obj // < needs to be after ...tags to override ImageHeight and ImageWidth\n  }\n}\n", "import os from \"os\"\nimport { notBlank } from \"../../fe/Blank\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { firstDefinedLater } from \"../async/Later\"\nimport { stdoutResult } from \"../child/ChildProcess\"\nimport { FatalErrorFlag } from \"../error/ErrorTypes\"\nimport { isElectron, isWin, platformName } from \"../Platform\"\nimport { CmdTimeoutMs } from \"../volumes/VolumeTtls\"\nimport { BaseFile } from \"./BaseFile\"\nimport { ProjectPath } from \"./ProjectPath\"\n\nexport async function pathTo(tool: string): PromiseMaybe<string> {\n  const cmd = isWin ? \"where\" : \"which\"\n  try {\n    const result = await stdoutResult(cmd, [tool], {\n      timeout: CmdTimeoutMs,\n      // Don't flip out if we're missing a command:\n      ignoreExitCode: true,\n      ignoreStderr: true\n    })\n\n    // trim() because `where` and `which` will return \"/usr/bin/tool\\n\"\n\n    // .split() shenanigans due to Windows' \"where\" returning *all* paths to\n    // binaries with that name.\n\n    return result.code === 0 && notBlank(result.result)\n      ? result.result.trim().split(\"\\n\")[0]?.trim()\n      : undefined\n  } catch {\n    return undefined\n  }\n}\n\nasync function pathIfExists(f: Maybe<BaseFile>) {\n  return f != null && (await f.exists()) ? f.nativePath : undefined\n}\n\n/**\n * @param tool \".exe\" is appended if the local platform is windows.\n * @throws if tool is not found\n */\nexport async function pathToTool(\n  tool: string,\n  libraryName?: string\n): Promise<string> {\n  const toolsDir = map(ProjectPath.Tools(), ea => BaseFile.for(ea))\n  if (isElectron && (toolsDir == null || (await toolsDir.isNotDirectory()))) {\n    // Electron builds always have a tools dir:\n    throw new Error(\"Cannot find project path for tools\" + FatalErrorFlag)\n  }\n\n  function forArch(arch: string) {\n    // tools dir won't exist on docker:\n    return toolsDir?.join(\n      platformName + \"-\" + arch,\n      orElse(libraryName, tool),\n      tool + (isWin ? \".exe\" : \"\")\n    )\n  }\n  return firstDefinedLater<string>(\n    // Prefer ours, if it's there:\n    () => pathIfExists(forArch(os.arch())),\n    // If we're 64-bit intel, try 32-bit intel?\n    () => (os.arch() === \"x64\" ? pathIfExists(forArch(\"ia32\")) : undefined),\n    // system-installed tool:\n    () => systemPathToTool(tool)\n  ) as any\n}\n\nasync function systemPathToTool(tool: string): Promise<string> {\n  return firstDefinedLater<string>(\n    // system-installed tool:\n    () => pathTo(tool),\n    // Used for docker's copy of dcraw:\n    () => pathIfExists(BaseFile.for(ProjectPath.Bin())?.join(tool)),\n    () => {\n      throw new Error(\"Cannot find path for \" + tool)\n    }\n  ) as any\n}\n\nexport const dcrawEmuNativePath = lazy(() => pathToTool(\"dcraw_emu\", \"libraw\"))\n\nexport const rawIdentifyNativePath = lazy(() =>\n  pathToTool(\"raw-identify\", \"libraw\")\n)\n\nexport const jpegtranNativePath = lazy(() => pathToTool(\"jpegtran\"))\n\nexport const sqliteNativePath = lazy(() => pathToTool(\"sqlite3\"))\n", "import { mapNotBlank } from \"../../fe/Blank\"\nimport { Dimensions } from \"../../fe/Dimensions\"\nimport { errorToS } from \"../../fe/Error\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { map2Numeric, toInt } from \"../../fe/Number\"\nimport { stdout } from \"../child/ChildProcess\"\nimport { onClearCache, onFileChanged } from \"../event/EventEmitter\"\nimport { FifoCache } from \"../FifoCache\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { StatTimeoutMs } from \"../fs/StatTimeout\"\nimport { rawIdentifyNativePath } from \"../fs/Tools\"\nimport { mkLogger } from \"../Logger\"\n\nexport type RawInfo = {\n  Filename: string\n  Make: string\n  Model: string\n  ImageSize: Dimensions\n}\n\nconst cache = new FifoCache<PromiseMaybe<RawInfo>>(512)\n\nonClearCache(() => cache.clear())\nonFileChanged(ea => (ea == null ? cache.clear() : cache.delete(ea)))\nconst logger = lazy(() => mkLogger(\"RawInfo\"))\n\nexport async function rawInfo(src: PosixFile): PromiseMaybe<RawInfo> {\n  return cache.getOrSet(src.nativePath, async () => {\n    try {\n      const cmd = await rawIdentifyNativePath()\n      // -u -f returns something that _isn't_ the rendered TIFF dimensions.\n      const s = await stdout(cmd, [\"-s\", src.nativePath], {\n        timeout: StatTimeoutMs\n      })\n      return mapNotBlank(s, parseRawInfoOutput)\n    } catch (err) {\n      logger().warn(\"raw-identify failed\", {\n        file: src.nativePath,\n        error: errorToS(err)\n      })\n      return\n    }\n  })\n}\n\nexport function parseRawInfoOutput(input: string) {\n  const [Filename, Make, Model, w, h] = input.split(\"\\t\")\n  return logger().tap({\n    msg: \"parseRawInfoOutput()\",\n    result: map2Numeric(toInt(w), toInt(h), (width, height) => ({\n      Filename,\n      Make,\n      Model,\n      ImageSize: { width, height }\n    })),\n    meta: { input }\n  })\n}\n", "import { Tags } from \"exiftool-vendored\"\nimport { totalmem } from \"os\"\nimport { compactBlanks } from \"../../fe/Array\"\nimport { isTrue } from \"../../fe/Boolean\"\nimport { secondMs } from \"../../fe/Date\"\nimport { later } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { clamp, gt0, gte, sigFigs } from \"../../fe/Number\"\nimport { gt } from \"../../fe/Primitive\"\nimport { GiB } from \"../../fe/Units\"\nimport { firstDefinedLater } from \"../async/Later\"\nimport { thenMap, thenOrElse } from \"../async/Promise\"\nimport { time } from \"../async/PromiseTimer\"\nimport { onClearCache } from \"../event/EventEmitter\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { PullProgressObserver } from \"../fs/ProgressObservers\"\nimport { mkLogger } from \"../Logger\"\nimport { lerp2d } from \"../math/Lerp\"\nimport { isProd } from \"../NodeEnv\"\nimport { mapGt0 } from \"../Number\"\nimport { Settings } from \"../settings/Settings\"\nimport { hasAnyIgnoreCase } from \"../String\"\nimport { extractBitrateKbps } from \"../tags/Bitrate\"\nimport { extractDurationSec } from \"../tags/Duration\"\nimport { deleteAllTags, readRawTags } from \"../tags/ExifTags\"\nimport { extractRotation } from \"../tags/Orientation\"\nimport { extractSizeInfo } from \"../tags/SizeInfo\"\nimport { maxCpus } from \"../work/MaxCpus\"\nimport {\n  checkFFmpegVersion,\n  ffmpegFrame,\n  ffmpegTranscode,\n  ffmpegValidVideo,\n  isFFmpegSupported\n} from \"./ffmpeg\"\nimport { dimensions } from \"./FileDimensions\"\nimport { cachedImgFile } from \"./ImgCache\"\nimport { rotateInPlace } from \"./jpegtran\"\nimport { transcodeTimeout } from \"./SyncFileTimeout\"\nimport { ToolDetails } from \"./ToolDetails\"\nimport { isVideoMimeType } from \"./VideoFilter\"\nimport { checkVlcInfo, isVlcSupported, vlcFrame, vlcTranscode } from \"./vlc\"\n\n// ffmpeg happily chows 8gb/RAM per transcode. Only run 2 if we've got enough grunt\nexport const maxConcurrentVideoImports = lazy(async () =>\n  totalmem() > 16 * GiB && maxCpus() > 5 && (await isFFmpegSupported()) ? 2 : 1\n)\n\nexport async function getVideoToolDetails(opts?: {\n  ignoreffmpeg: any\n  ignorevlc: any\n}): Promise<ToolDetails> {\n  return (await firstDefinedLater<ToolDetails>(\n    () =>\n      isTrue(opts?.ignoreffmpeg) && !isProd\n        ? undefined\n        : thenMap(checkFFmpegVersion(), v => ({\n            ok: true,\n            msg: \"FFmpeg \" + v\n          })),\n    () =>\n      isTrue(opts?.ignorevlc)\n        ? undefined\n        : thenMap(checkVlcInfo(), v => ({ ok: true, msg: \"VLC \" + v.version })),\n    () => ({ ok: false, msg: \"(no video tools were found)\" })\n  ))!\n}\n\nexport const isVideoSupported = lazy(\n  async () => (await getVideoToolDetails()).ok\n)\n\nlater(() => onClearCache(() => isVideoSupported.unset()))\n\n// These are \"high quality\" bitrates for a given video resolution.\nexport const bitrateKps = (pixels: number) =>\n  sigFigs(\n    lerp2d(\n      { x: 320 * 240, y: Settings.transcodeBitrateQVGA.valueOrDefault },\n      { x: 3840 * 2160, y: Settings.transcodeBitrateUHD.valueOrDefault },\n      pixels\n    ),\n    2\n  )\n\nfunction extractMaxBitrate(src: PosixFile, rawTags: Tags) {\n  const log = mkLogger(\"img/Video.dim(\" + src + \")\")\n  // These dimensions will be enforced by PosixFileFilters, before this. We need\n  // reasonable dimensions to give to VLC, though, so re-validating them here is\n  // excusable. Hopefully.\n  const minDim = Settings.minVideoDimension.valueOrDefault\n  const width = rawTags.ImageWidth\n  if (width != null && !gte(width, minDim)) {\n    return log.throw(\"invalid width: \" + width, { ignorable: true })\n  }\n  const height = rawTags.ImageHeight\n  if (height != null && !gte(height, minDim)) {\n    return log.throw(\"invalid height: \" + height, { ignorable: true })\n  }\n\n  const bitrateKbps = orElse(\n    extractBitrateKbps(rawTags),\n    Settings.transcodeBitrateUHD.valueOrDefault\n  )\n\n  // Don't let video bitrate exceed the encoded bitrate:\n  const videoBitrateKbps = mapGt0(width, w =>\n    mapGt0(height, h => clamp(0, bitrateKbps, bitrateKps(w * h)))\n  )\n\n  const result = { width, height, videoBitrateKbps }\n  log.debug(\"dim()\", { src, result })\n  return result\n}\n\nexport async function extractVideoFrame(\n  src: PosixFile,\n  mimetype: string,\n  forceImpl?: {\n    useFfmpeg?: boolean\n    useVlc?: boolean\n  }\n) {\n  if (!isVideoMimeType(mimetype)) return\n\n  const useFfmpeg = isTrue(forceImpl?.useVlc)\n    ? false\n    : isTrue(await thenOrElse(forceImpl?.useFfmpeg, () => isFFmpegSupported()))\n  const useVlc =\n    !useFfmpeg &&\n    isTrue(await thenOrElse(forceImpl?.useVlc, () => isVlcSupported()))\n  if (!useFfmpeg && !useVlc) return\n\n  const log = mkLogger(\"img/Video.extractVideoFrame(\" + src + \")\")\n\n  // We don't use BaseFile.applyIfEmpty here, because we want to verify the\n  // dimensions are reasonable:\n\n  const dest = await cachedImgFile(src, \"frame\", \".jpg\")\n  log.debug(\"extractVideoFrame\", { dest: dest.nativePath, mimetype })\n\n  const srcMtime = await src.mtimeMs()\n  if (srcMtime == null) {\n    return log.throw(\"null mtime\")\n  }\n\n  const rawTags = await readRawTags(src)\n  if (rawTags == null) {\n    return log.throw(\"no tags\")\n  }\n  const rot = extractRotation(rawTags)\n  log.debug(\"video orientation:\" + rot)\n\n  // Note that width and height may be missing from videos like AVCHD:\n  const srcDim = extractSizeInfo(rawTags, rot)?.dimensions\n\n  const destStat = await dest.stat()\n  // If the file doesn't exist, don't tease ExifTool:\n  const destDim = destStat == null ? undefined : await dimensions(dest)\n\n  if (\n    destStat != null &&\n    destStat.mtimeMs > srcMtime &&\n    destDim != null &&\n    (srcDim == null ||\n      (destDim.height === srcDim.height && destDim.width === srcDim.width))\n  ) {\n    log.debug(\"prior dest, \" + dest + \" seems reasonable\", { srcDim, destDim })\n    return dest\n  }\n  const duration = extractDurationSec(rawTags)\n  const startAtSec = Math.min(\n    duration ?? 0,\n    Settings.videoFrameAtSec.valueOrDefault\n  )\n  log.info(\"extracted metadata\", {\n    startAtSec,\n    duration\n  })\n\n  await dest.applyWip(async destWip => {\n    const args = {\n      src,\n      dest: destWip,\n      startAtSec,\n      ...srcDim\n    }\n\n    await (useFfmpeg ? ffmpegFrame(args) : vlcFrame(args))\n\n    await deleteAllTags(destWip)\n    // VLC doesn't auto-rotate. FFmpeg does.\n    if (useVlc && rot != null && rot !== 0) {\n      log.info(\"rotating in place...\" + destWip, { rot })\n      await rotateInPlace(destWip, rot)\n    }\n  })\n  return dest\n}\n\nexport async function isVideoTranscodingSupported() {\n  return (\n    Settings.transcodeVideos.valueOrDefault &&\n    ((await isFFmpegSupported()) || (await isVlcSupported()))\n  )\n}\n\nexport async function needsTranscoding(f: PosixFile) {\n  const log = mkLogger(\"needsTranscoding(\" + f + \")\")\n\n  if (!(await isVideoTranscodingSupported())) {\n    return log.tap({\n      msg: \"videoTranscodingSupported is false\",\n      result: false\n    })\n  }\n\n  const t = await readRawTags(f)\n  if (t == null) {\n    return log.tap({\n      msg: \"Cannot transcode files that exiftool can't read\",\n      result: false\n    })\n  }\n\n  const mimetype = t.MIMEType!\n\n  if (!isVideoMimeType(mimetype)) {\n    return log.tap({\n      msg: \"not transcoding (unsupported mimetype)\",\n      result: false,\n      meta: { mimetype }\n    })\n  }\n\n  const duration = extractDurationSec(t)\n\n  if (!gt(duration, Settings.minVideoDurationSec.valueOrDefault)) {\n    return log.tap({\n      msg: \"not transcoding (video duration is too short)\",\n      result: false,\n      meta: { duration }\n    })\n  }\n\n  const audioCodecs = compactBlanks([t.AudioFormat])\n  const isSafeAudioCodec = audioCodecs.some(ea =>\n    hasAnyIgnoreCase(Settings.doNotTranscodeAudioCodecs.values, ea)\n  )\n\n  const videoCodecs = compactBlanks([\n    t.VideoCodec,\n    t.CompressorID,\n    t.CompressorName\n  ])\n  const isSafeVideoCodec = videoCodecs.some(ea =>\n    hasAnyIgnoreCase(Settings.doNotTranscodeVideoCodecs.values, ea)\n  )\n\n  const isSafeMimetype = hasAnyIgnoreCase(\n    Settings.doNotTranscodeMimetypes.values,\n    mimetype\n  )\n\n  return log.tap({\n    msg: \"result\",\n    result: !(isSafeAudioCodec && isSafeVideoCodec && isSafeMimetype),\n    meta: {\n      mimetype,\n      isSafeMimetype,\n      audioCodecs,\n      isSafeAudioCodec,\n      videoCodecs,\n      isSafeVideoCodec\n    }\n  })\n}\n\nexport async function transcode(src: PosixFile, dest: PosixFile) {\n  if (false === (await needsTranscoding(src))) return\n\n  const size = await src.size()\n  if (!gt0(size)) {\n    throw new Error(\"transcode(): cannot read \" + src)\n  }\n\n  const rawTags = await readRawTags(src)\n  if (rawTags == null) {\n    throw new Error(\"Cannot transcode files that exiftool can't read\")\n  }\n\n  return time(\"video.transcode()\", async () => {\n    const durationSec = orElse(extractDurationSec(rawTags), 60)\n    const timeoutMs = transcodeTimeout({\n      bytes: size,\n      durationMs: durationSec * secondMs,\n      ext: src.ext\n    })\n    const args: any = {\n      src,\n      timeoutMs,\n      ...extractMaxBitrate(src, rawTags)\n    }\n    const expectedSize = guessExpectedSize(\n      size,\n      args.videoBitrateKbps,\n      durationSec\n    )\n\n    const minSizeBytes = expectedSize / 3\n\n    const _transcode = async (destWip: PosixFile) => {\n      const start = Date.now()\n\n      const obs = new PullProgressObserver(\n        { path: src.nativePath, op: \"Transcoding video\" },\n        expectedSize,\n        async () => {\n          const bySize = orElse(await dest.clear().size(), 0)\n          const byTime = ((Date.now() - start) / timeoutMs) * expectedSize\n          return Math.max(bySize, byTime)\n        }\n      )\n\n      args.dest = destWip\n\n      const result = await obs.observe(\n        (await isFFmpegSupported()) ? ffmpegTranscode(args) : vlcTranscode(args)\n      )\n      if (result.code !== 0) {\n        throw new Error(\"transcode failed with code \" + result.code)\n      }\n    }\n\n    return dest.applyIfEmpty_(destWip => _transcode(destWip), minSizeBytes)\n  })\n}\n\nexport function guessExpectedSize(\n  filesize: number,\n  videoBitrateKbps: Maybe<number>,\n  durationSec: Maybe<number>\n) {\n  return Math.min(\n    filesize,\n    // SITS: these constants are not really defensible\n    orElse(durationSec, 60) * orElse(videoBitrateKbps, 1000)\n  )\n}\n\n/**\n * @throws on errors\n */\nexport async function validVideo(src: PosixFile, mimetype: string) {\n  const log = mkLogger(\"img/Video.validVideo(\" + src + \")\")\n  const f = await extractVideoFrame(src, mimetype)\n  if (f == null) {\n    log.throw(\"Could not extract a video frame\")\n  }\n  if (await isFFmpegSupported()) {\n    return ffmpegValidVideo(src)\n  } else {\n    // TODO: implement vlcValidVideo()\n    return\n  }\n}\n", "export function lerp(v0: number, v1: number, t = 0.5): number {\n  // See https://en.wikipedia.org/wiki/Linear_interpolation#Programming_language_support\n  return (1 - t) * v0 + t * v1\n}\n\nexport interface Point {\n  x: number\n  y: number\n}\n\n/**\n * @return y for the given x, given the line defined p0 and p1\n */\nexport function lerp2d(p0: Point, p1: Point, x: number): number {\n  const dx = p1.x - p0.x\n  const xdx = x - p0.x\n  const t = xdx / dx\n  return lerp(p0.y, p1.y, t)\n}\n\nexport function lerp2d_(p0: Point, p1: Point, x: number): number {\n  // https://en.wikipedia.org/wiki/Linear_interpolation\n  return (p0.y * (p1.x - x) + p1.y * (x - p0.x)) / (p1.x - p0.x)\n}\n", "import { notBlank } from \"../../fe/Blank\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\n\nexport function isVideoMimeType(mimeType: Maybe<string>): boolean {\n  return (\n    notBlank(mimeType) &&\n    (mimeType.startsWith(\"video/\") ||\n      mimeType === \"application/mp4\" ||\n      mimeType === \"application/ogg\")\n  )\n}\n", "import { Tags } from \"exiftool-vendored\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { gt0 } from \"../../fe/Number\"\nimport { thenOpt } from \"../../fe/OptAsync\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { isVideoMimeType } from \"../img/VideoFilter\"\nimport { mimetype, readRawTags } from \"./ExifTags\"\n\nexport function extractDurationSec(t: Maybe<Tags>): Maybe<number> {\n  return map(t, ea =>\n    [ea.Duration, ea.MediaDuration, ea.TrackDuration].find(gt0)\n  )\n}\n\nexport async function duration(\n  pathOrFile: string | PosixFile\n): PromiseMaybe<number> {\n  const f = PosixFile.for(pathOrFile)\n  return thenOpt(mimetype(f))\n    .filter(isVideoMimeType)\n    .flatMap(() => readRawTags(f, false))\n    .flatMap(extractDurationSec)\n    .get()\n}\n", "import { map } from \"./Maybe\"\nimport { Maybe } from \"./MaybeTypes\"\nimport { isNumber, round } from \"./Number\"\n\nexport type Rotation = 0 | 90 | 180 | 270\n\nexport function isRotation(r: any): r is Rotation {\n  return isNumber(r) && [0, 90, 180, 270].includes(r)\n}\n\n/** @return if set, rotation, normalized to [0, 360) */\nexport function normalizeRotation(rotation: Maybe<number>): Maybe<Rotation> {\n  const r = map(rotation, ea => round(ea + Math.ceil(-ea / 360) * 360))\n  return isRotation(r) ? r : undefined\n}\n\n/**\n * @return true if the dimensions need to be flipped to respect the given\n * rotation\n */\nexport function flippable(rotation: Maybe<number>) {\n  const r = normalizeRotation(rotation)\n  return r === 90 || r === 270\n}\n", "import { Tags } from \"exiftool-vendored\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { normalizeRotation } from \"../../fe/Rotation\"\nimport { isVideoMimeType } from \"../img/VideoFilter\"\nimport { firstThunk } from \"../Object\"\n\n// const ExifOrientations = new Map([\n//   [\"Horizontal (normal)\", 1],\n//   [\"Mirror horizontal\", 2],\n//   [\"Rotate 180\", 3],\n//   [\"Mirror vertical\", 4],\n//   [\"Mirror horizontal and rotate 270 CW\", 5],\n//   [\"Rotate 90 CW\", 6],\n//   [\"Mirror horizontal and rotate 90 CW\", 7],\n//   [\"Rotate 270 CW\", 8]\n// ])\n\n// TODO: support https://github.com/recurser/exif-orientation-examples\n\nexport function extractRotation(tags: Maybe<Tags>): Maybe<number> {\n  return map(tags, ea =>\n    firstThunk(\n      () => orientationToRotation(ea.Orientation),\n      () => orientationToRotation(ea.CameraOrientation),\n      () => normalizeRotation(ea.Rotation) // < used by videos\n    )\n  )\n}\n\nconst ExifOrientationToRotation = new Map<string | number, number>([\n  [\"Horizontal (normal)\", 0],\n  [\"Rotate 90 CW\", 90],\n  [\"Rotate 180\", 180],\n  [\"Rotate 270 CW\", 270],\n  [1, 0],\n  [6, 90],\n  [3, 180],\n  [8, 270]\n])\n\n/**\n * @return clockwise rotation, or undefined if mirroring is involved or the\n * orientation string is undefined or unknown\n */\nexport function orientationToRotation(\n  orientation: Maybe<string | number>\n): Maybe<number> {\n  return map(orientation, ea => ExifOrientationToRotation.get(ea))\n}\n\nconst Rotation2ExifOrientation = new Map<number, number>([\n  [0, 1],\n  [90, 6],\n  [180, 3],\n  [270, 8]\n])\n\n/**\n * @param rotation clockwise rotation (0, 90, 180, 270)\n * @return if rotated is defined and a known value, return the ExifTool\n * Orientation string\n */\nexport function rotationToExifOrientation(\n  rotation: Maybe<number>\n): Maybe<number> {\n  return map(rotation, ea => Rotation2ExifOrientation.get(ea))\n}\n\nexport type ImageDimensions = Required<Pick<Tags, \"ImageHeight\" | \"ImageWidth\">>\n\nexport function rotationToWriteTag(rotation: number, mimetype: string) {\n  return map(normalizeRotation(rotation), nr =>\n    isVideoMimeType(mimetype)\n      ? { Rotation: nr as any }\n      : map(rotationToExifOrientation(nr), ea => ({\n          \"Orientation#\": ea\n        }))\n  )\n}\n", "import { Maybe } from \"./MaybeTypes\"\nimport { gt0 } from \"./Number\"\nimport { flippable } from \"./Rotation\"\nimport { megapixels, pixels2size } from \"./Units\"\n\nexport interface Dimensions {\n  width: number\n  height: number\n}\n\nexport function isDimensions(a: any): a is Dimensions {\n  return a != null && gt0(a.width) && gt0(a.height)\n}\n\nexport function dimToS(d: Dimensions) {\n  return `${d.width} \u00D7 ${d.height}`\n}\n\nexport function dimToSize(d: Dimensions) {\n  return pixels2size(d.width * d.height)\n}\n\nexport function flip(dim: Dimensions): Dimensions {\n  return { width: dim.height, height: dim.width }\n}\n\nexport function maybeFlip(\n  dim: Dimensions,\n  rotation: Maybe<number>\n): Dimensions {\n  return flippable(rotation) ? flip(dim) : dim\n}\n\nexport function maybeFlipInPlace(dim: Dimensions, rotation: Maybe<number>) {\n  if (flippable(rotation)) {\n    ;[dim.width, dim.height] = [dim.height, dim.width]\n  }\n}\n\nexport function isPortrait(dim: Dimensions): boolean {\n  return dim.width / dim.height < 1\n}\n\nexport function dmegapixels(dim: Dimensions) {\n  return megapixels(dim.width * dim.height)\n}\n", "import { Tags } from \"exiftool-vendored\"\nimport { Dimensions, isDimensions, maybeFlip } from \"../../fe/Dimensions\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { sigFigs } from \"../../fe/Number\"\nimport { first } from \"../Array\"\nimport { RawInfo } from \"../img/RawInfo\"\nimport { mkLogger } from \"../Logger\"\nimport { ImageDimensions } from \"./Orientation\"\n\nexport interface SizeInfo extends ImageDimensions {\n  dimensions: Dimensions\n  fileDimensions: Dimensions\n  aspectRatio: number\n  /**\n   * Degrees clockwise that the image should be rotated. 0 if the image is\n   * already in correct orientation. Undefined if `Orientation` involves\n   * mirroring (which should be extremely rare)\n   */\n  rotation: Maybe<number>\n}\n\nconst logger = lazy(() => mkLogger(\"SizeInfo\"))\n\nexport function extractSizeInfo(\n  tags: Partial<\n    ImageDimensions & Pick<Tags, \"MIMEType\" | \"ImageSize\" | \"FileName\">\n  >,\n  rotation: Maybe<number>,\n  rawInfo?: Maybe<Partial<RawInfo>>\n): Maybe<SizeInfo> {\n  const fileDimensions = first(\n    [\n      rawInfo?.ImageSize,\n      // DON'T pull in ExifImageWith/ExifImageHeight: those tags don't\n      // necessarily represent the actual image size.\n      { width: tags.ImageWidth, height: tags.ImageHeight }\n    ],\n    d => (isDimensions(d) ? d : undefined)\n  )\n\n  logger().debug(\"extractSizeInfo()\", {\n    filename: tags.FileName,\n    mimetype: tags.MIMEType,\n    rawInfo,\n    fileDimensions\n  })\n\n  // Sometimes this is \"11mm\" (for .svg)\n  if (fileDimensions == null) {\n    return\n  }\n  const dimensions = maybeFlip(fileDimensions, rotation)\n  const aspectRatio = sigFigs(dimensions.width / dimensions.height, 5)\n  return {\n    ImageHeight: dimensions.height,\n    ImageWidth: dimensions.width,\n    aspectRatio,\n    dimensions,\n    rotation,\n    fileDimensions\n  }\n}\n", "import { lerp2d } from \"../../core/math/Lerp\"\nimport { minuteMs, secondMs } from \"../../fe/Date\"\nimport { orElse } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { clamp } from \"../../fe/Number\"\nimport { GB, MB } from \"../../fe/Units\"\nimport { thenMap } from \"../async/Promise\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { mapGt0 } from \"../Number\"\nimport { Settings } from \"../settings/Settings\"\nimport { readRawTags } from \"../tags/ExifTags\"\nimport { extTypes, ExtTypes, isVideoExt } from \"../tags/FileExts\"\nimport { CmdTimeoutMs, MinIoRate } from \"../volumes/VolumeTtls\"\n\n// Handle general system churn/hiccups/external drive spinups:\nexport const MinSyncFileTimeoutMs = minuteMs\n\n// This number needs to be greater than the slowest computer's file processing\n// time under load.\n\n// TODO: LATER: make timeouts more accurate by using the current system's\n// processing times.\n\nexport const MaxSyncFileTimeoutMs = 15 * minuteMs\n\n// If it takes > 10x slower than realtime to transcode we've got issues.\nexport const DurationMultiplier = 10\n\n// Sync file time is going to be governed by\n\n// 1. DB insert time (normally less than a second, let's say 5 seconds)\n// 2. Metadata extraction (should be less than a second, worst-case, 30 seconds)\n// 3. Copy to library (assume 4-5mb/sec transfer speed for a slow nas, should\n//    typically be more like 20-50mb/s, though) + SHA, == MaxFileSize / 4mb\n// 4. Thumbnail generation (normally less than a second, can be 30 seconds for\n//    RAW images)\n// 5. Video transcoding (may a no-op, or only be remuxing, which is fast, or\n//    actual transcoding, which is ~1-10x longer than the actual duration of the\n//    video, and can be limited by disk I/O as well).\n\n// linux timings:\n//           ubu mac win\n//  7M .MTS:     30s\n// 18M .MTS: 23s 60s\n// 8M  .AVI: 4s\n// 30M .MOV: 18s 40s\n\n// These timings are all from the Raspberry Pi 4, the slowest supported CPU.\n\nconst ImagePoints = {\n  p0: { x: 0.8 * MB, y: 4 * secondMs },\n  p1: { x: 20 * MB, y: 12 * secondMs }\n}\n\nconst RawPoints = {\n  p0: { x: 11 * MB, y: 12 * secondMs },\n  p1: { x: 26 * MB, y: 24 * secondMs }\n}\n\nconst VideoPoints = {\n  p0: { x: 7 * MB, y: 45 * secondMs },\n  p1: { x: 32 * MB, y: 90 * secondMs }\n}\n\nexport function transcodeTimeoutForFile(file: PosixFile) {\n  return isVideoExt(file.ext)\n    ? thenMap(readMeta(file), transcodeTimeout)\n    : undefined\n}\n\nexport function transcodeTimeout(opts: FileTimeoutMeta): number {\n  return isVideoExt(opts.ext)\n    ? Math.max(\n        orElse(\n          mapGt0(opts.durationMs, d => d * DurationMultiplier),\n          0\n        ),\n        lerp2d(VideoPoints.p0, VideoPoints.p1, opts.bytes)\n      )\n    : 0\n}\n\nexport function syncFileTimeoutForFileMs(file: PosixFile) {\n  return thenMap(syncFileTimeoutForFile(file), ea => ea.result)\n}\n\nexport function syncFileTimeoutForFile(file: PosixFile) {\n  return thenMap(readMeta(file), syncFileTimeout)\n}\n\nfunction readMeta(file: PosixFile): PromiseMaybe<FileTimeoutMeta> {\n  return thenMap(file.size(), async bytes => ({\n    bytes,\n    ext: file.ext,\n    durationMs: isVideoExt(file.ext)\n      ? await thenMap(readRawTags(file), t =>\n          mapGt0(t.Duration, d => d * secondMs)\n        )\n      : undefined\n  }))\n}\n\nexport interface FileTimeoutMeta {\n  bytes: number\n  ext: string\n  durationMs?: number\n}\n\nexport function dcrawTimeout(bytes: Maybe<number>): number {\n  return lerp2d(\n    RawPoints.p0,\n    RawPoints.p1,\n    clamp(11 * MB, 100 * MB, orElse(bytes, 0))\n  )\n}\n\nexport function syncFileTimeout(meta: FileTimeoutMeta) {\n  // clamp to something reasonable:\n  const bytes = clamp(0.5 * MB, 64 * GB, meta.bytes)\n\n  // Time to sync is DB + tags + copy op + sha + thumbs + transcode.\n\n  // db time is constant. Should be ~10ms, but the system might be borked:\n  const dbMs = 5 * secondMs\n\n  // tag extraction time. Should be normally ~5-50ms, but we may need to fetch\n  // tags for sibling variants (5? 10?) over a slow LAN NAS.\n  const tagMs = CmdTimeoutMs\n\n  // Copy time will be directly proportional to the asset size. Assume 2mb/s for\n  // a really crappy NAS and a 100baseT network, and that we need to do it twice\n  // (once to copy, once to SHA-verify the copy):\n\n  const copyMs = 2 * bytes * MinIoRate\n\n  const lerpPoints = (p: typeof ImagePoints) =>\n    lerp2d(p.p0, p.p1, clamp(0.5 * MB, 50 * MB, bytes))\n\n  const thumbMs = lerpPoints(ImagePoints)\n\n  const types = extTypes(meta.ext)\n\n  const rawDecodeMs =\n    types?.includes(ExtTypes.RawImage) === true ? lerpPoints(RawPoints) : 0\n\n  const transcodeMs = transcodeTimeout(meta)\n  const validateMs = Settings.validateVideos.valueOrDefault ? transcodeMs : 0\n\n  const result = clamp(\n    MinSyncFileTimeoutMs,\n    MaxSyncFileTimeoutMs,\n    Math.round(\n      dbMs + tagMs + copyMs + thumbMs + rawDecodeMs + transcodeMs + validateMs\n    )\n  )\n\n  return {\n    result,\n    dbMs,\n    tagMs,\n    copyMs,\n    thumbMs,\n    rawDecodeMs,\n    transcodeMs,\n    validateMs\n  }\n}\n", "import { later } from \"../../fe/Delay\"\nimport { toA } from \"../../fe/toA\"\nimport { onClearCache, onFileCopied } from \"../event/EventEmitter\"\nimport { FifoCache } from \"../FifoCache\"\nimport { BaseFile } from \"./BaseFile\"\n\n// This is a set of paths that we just copied, so we know the contents are the\n// same.\n\nconst cache = new FifoCache<string[]>(256)\n\nlater(() => onClearCache(() => cache.clear()))\nlater(() =>\n  onFileCopied((src, dest) => {\n    cache.getOrSet(src, () => []).push(dest)\n    cache.getOrSet(dest, () => []).push(src)\n  })\n)\n\nexport function sameNativePaths(src: string | BaseFile): string[] {\n  return [src.toString(), ...toA(cache.get(src.toString()))]\n}\n\nexport function getOrSetByNativePath<P extends string | BaseFile, T>(\n  src: P,\n  onCacheMiss: (path: P) => T,\n  store: FifoCache<T>\n): T {\n  for (const ea of sameNativePaths(src)) {\n    const prior = store.get(ea)\n    if (prior != null) return prior\n  }\n  const result = onCacheMiss(src)\n  store.set(src.toString(), result)\n  return result\n}\n", "import { strEnum, StrEnumKeys } from \"../StrEnum\"\n\n// in order of goodness:\nexport const S = strEnum(\"plus\", \"lite\")\nexport type SubscriptionTier = StrEnumKeys<typeof S>\n", "import { mapNotBlank } from \"../../fe/Blank\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { version } from \"../Version\"\nimport { Settings } from \"./Settings\"\n\nconst README = `\nHello, and thank you for using PhotoStructure!\n\nThe files in this folder support your PhotoStructure Library, including\n\n  * a database with the filepaths to your photos and movies\n  * previews and thumbnails of your photos and movies\n  * content metadata about these assets, like ratings and sharing information\n  * albums that both you and PhotoStructure Curators have assembled\n\nMoving or deleting any files here will cause problems using your library.\n\nIf you have any questions, please visit <https://photostructure.com/support/>.\n\nSincerely,\n\nYour Friendly Neighborhood PhotoStructure, v${version}`\n\n/**\n * libraryDataDir was pulled out of Library so settings could be written into\n * .photostructure, rather than directly into the library root.\n */\nexport function libraryDataDir(\n  libraryRootPath: Maybe<string | PosixFile> = Settings.libraryPath.value\n): Maybe<PosixFile> {\n  return mapNotBlank(libraryRootPath, ea =>\n    // subdir is all lowercase to minimize case-(in)sensitive\n    // filesystem pain and suffering\n    PosixFile.for(ea).join(\".photostructure\")\n  )\n}\n\nexport function libraryOriginalsDir(\n  libraryRootPath: Maybe<string | PosixFile> = Settings.libraryPath.value\n): Maybe<PosixFile> {\n  return mapNotBlank(libraryRootPath, ea =>\n    PosixFile.for(ea).join(Settings.originalsDir.valueOrDefault)\n  )\n}\n\nexport function setupLibraryOriginalsDir(\n  libraryRootPath: Maybe<string | PosixFile> = Settings.libraryPath.value\n) {\n  return libraryOriginalsDir(libraryRootPath)?.mkdirp()\n}\n\nexport function libraryPreviewsDir(\n  libraryRootPath: Maybe<string | PosixFile> = Settings.libraryPath.value\n): Maybe<PosixFile> {\n  return mapNotBlank(libraryRootPath, ea =>\n    PosixFile.for(ea).join(Settings.previewsDir.valueOrDefault)\n  )\n}\n\n/**\n * @throws if there are issues\n */\nexport async function setupLibraryDataDir(\n  libraryRootPath: string | PosixFile\n): Promise<PosixFile> {\n  const dataDir = libraryDataDir(libraryRootPath)\n  if (dataDir == null) {\n    throw new Error(\"empty dataDir\")\n  }\n  if (null == (await dataDir.mkdirp())) {\n    throw new Error(\"Could not mkdirp \" + dataDir)\n  }\n  await dataDir.mkNoMedia()\n  const readmeFile = dataDir.join(\"README.txt\")\n  if ((await readmeFile.size()) !== README.length) {\n    await readmeFile.writeTxt_(README)\n  }\n  return dataDir\n}\n", "import { IncomingHttpHeaders, IncomingMessage } from \"http\"\nimport https = require(\"https\")\nimport { URL } from \"url\"\nimport { blank } from \"../../fe/Blank\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { AppName } from \"../AppName\"\nimport { WrappedError } from \"../error/WrappedError\"\nimport { within } from \"../Number\"\nimport { URI } from \"../uri/URI\"\nimport { version } from \"../Version\"\nimport { CmdTimeoutMs } from \"../volumes/VolumeTtls\"\n\nexport interface HttpsRequestOptions extends https.RequestOptions {\n  body?: string | Buffer\n}\n\nexport interface RequestResponse {\n  ok: boolean\n  headers: IncomingHttpHeaders\n  body: string\n  statusCode: Maybe<number>\n  statusMessage: string | undefined\n}\n\nexport async function request(\n  url: string | URI | URL,\n  options: HttpsRequestOptions = {}\n) {\n  if (options.headers == null) options.headers = {}\n  if (blank(options.headers[\"user-agent\"])) {\n    options.headers[\"user-agent\"] = AppName + \" v\" + version\n  }\n\n  return new Promise<RequestResponse>((resolve, reject) => {\n    const req = https.request(url.toString(), options)\n    req.setTimeout(orElse(options.timeout, CmdTimeoutMs), () => {\n      reject(\n        new WrappedError({\n          message: \"Timeout fetching <\" + url + \">\",\n          doNotSend: true,\n          retriable: true\n        })\n      )\n    })\n\n    req\n      .on(\"response\", (response: IncomingMessage) => {\n        const dataChunks: (Buffer | string)[] = []\n        response.setEncoding(\"utf8\")\n        response.on(\"data\", chunk => dataChunks.push(chunk))\n        response.on(\"end\", () => {\n          resolve({\n            ok: within(200, 399, response.statusCode),\n            headers: response.headers,\n            body: dataChunks.join(\"\"),\n            statusCode: response.statusCode,\n            statusMessage: response.statusMessage\n          })\n        })\n      })\n      .on(\"error\", e => {\n        reject(e)\n      })\n\n    map(options.body, ea => req.write(ea))\n    req.end()\n  })\n}\n\n// Just use https://nodejs.org/dist/latest-v14.x/docs/api/querystring.html#querystring_querystring_stringify_obj_sep_eq_options\n// export function urlencodedForm(obj: Pojo) {\n//   return entries(obj)\n//     .map(([k, v]) => encodeURIComponent(k) + \"=\" + encodeURIComponent(toS(v)))\n//     .join(\"&\")\n// }\n", "import { brotliDecompressSync } from \"zlib\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { d } from \"../math/b64\"\n\n// console.dir(\n//   require(\"zlib\")\n//     .gzipSync(\n//       Buffer.from(\n//         JSON.stringify({\n//           m: \"zlib\",\n//           p: \"brotliDecompressSync\",\n//           n: \"from\",\n//           v: \"base64\",\n//           a: \"toString\",\n//           l: \"utf8\"\n//         }),\n//         \"utf8\"\n//       )\n//     )\n//     .toString(\"base64\")\n// )\n\nexport const m = lazy<{\n  m: \"zlib\"\n  p: \"brotliDecompressSync\"\n  n: \"from\"\n  v: \"base64\"\n  a: \"toString\"\n  l: \"utf8\"\n}>(\n  () =>\n    JSON.parse(\n      d(\n        \"H4sIAAAAAAAAA6tWylWyUqrKyUxS0lEqADKTivJLcjJdUpPzcwuKUouLgyvzkoFSeUCptKL8XCCzDKQqsTjVzATISQRySvKDS4oy89KB3Bwgt7QkzUKpFgCQWYV5WQAAAA==\"\n      )\n    )!\n)\n\n/**\n * Decode and parse a brotli-compressed, base64 string\n */\nexport function j(s: string) {\n  return JSON.parse(\n    brotliDecompressSync(Buffer.from(s, \"base64\")).toString(\"utf8\")\n  )\n  // return JSON.parse( require(m().m)[m().p](Buffer[m().n](s, m().v))[m().a](m().l) )\n}\n", "import { cpus } from \"os\"\nimport { uniq } from \"../../fe/Array\"\nimport { mapNotBlank } from \"../../fe/Blank\"\nimport { secondMs } from \"../../fe/Date\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { toA } from \"../../fe/toA\"\nimport { thenFlatten } from \"../async/Promise\"\nimport { thenOrTimeout } from \"../async/thenOrTimeout\"\nimport { stdout } from \"../child/ChildProcess\"\nimport { readFileMaybe } from \"../fs/ReadFile\"\nimport { LibraryUIDStore } from \"../fs/UIDStore\"\nimport { mkLogger } from \"../Logger\"\nimport { macs } from \"../net/mac\"\nimport { isDocker, isLinux, isMac, isWin } from \"../Platform\"\nimport { PowerShell } from \"../pwsh/PowerShell\"\nimport { volumes } from \"../volumes/Volumes\"\nimport { j } from \"./BrotliDecode\"\nimport { S, sortUids, toUID } from \"./SystemIdSchemes\"\n\n// console.dir(\n//   require(\"zlib\")\n//     .brotliCompressSync(\n//       JSON.stringify({\n//         n: \"SystemIds\",\n//         c: \"cpuid\",\n//         i: \"ioreg\",\n//         ia: [\"-rd1\", \"-c\", \"IOPlatformExpertDevice\"],\n//         le: \"/etc/machine-id\",\n//         lv: \"/var/lib/dbus/machine-id\",\n//         w:\n//           \"Get-ItemProperty -Path hklm:\\\\SOFTWARE\\\\Microsoft\\\\Cryptography -Name MachineGuid | Select-Object -Property MachineGuid\"\n//       })\n//     )\n//     .toString(\"base64\")\n// )\n\n/**\n * licensing keys\n */\nexport const k = lazy<{\n  n: \"SystemIds\"\n  c: \"cpuid\"\n  i: \"ioreg\"\n  ia: [\"-rd1\", \"-c\", \"IOPlatformExpertDevice\"]\n  le: \"/etc/machine-id\"\n  lv: \"/var/lib/dbus/machine-id\"\n  w: \"Get-ItemProperty -Path hklm:\\\\SOFTWARE\\\\Microsoft\\\\Cryptography -Name MachineGuid | Select-Object -Property MachineGuid\"\n}>(() =>\n  j(\n    \"GwkBABwHdoyzjXCwzccdzUv9+g11VQzlNQjNotPVt0S2zHa8CLMs19auq91f4APvhhMIPZZ0m49e3qooFMQq6ej4jJBRUbv5BmSQzUeTCzW5mdaimgkX4ZqrHjPAjQ8XSSsp+cYQ79EXELnYMzlJwyYHVTq/nMkq900q5+mx2ayLgl3s6O7FgGooQh++7vpBI+Qpw3dCNqYDIfr6zPvUur259BmFMDQjV/hviADXURsBk2HJBesB\"\n  )\n)\n\nconst logger = lazy(() => mkLogger(k().n))\n\nasync function libraryId() {\n  return toUID(S.li, await LibraryUIDStore()?.read_())\n}\n\nfunction cpuModelId() {\n  return toUID(S.cm, cpus()[0].model)\n}\n\nfunction macAddressIds() {\n  return macs().map(ea => toUID(S.ma, ea))\n}\n\nasync function volumeIds() {\n  return toA(await volumes()).map(v => toUID(S.vl, v.uuid))\n}\n\nasync function linux_cpuid_() {\n  const out = await stdout(k().c, [\"-1\"], { timeout: 5 * secondMs })\n  return logger().tap({\n    msg: k().c,\n    result: out.match(/serial.*=\\s*([a-z0-9-]{12,})/i)?.[1]\n  })\n}\n\nasync function linux_hwid() {\n  try {\n    return mapNotBlank(await linux_cpuid_(), ea =>\n      // CPU IDs aren't unique across manufacturers, so add the model (which should be stable):\n      toUID(S.lc, ea + \":\" + cpus()[0].model)\n    )\n  } catch (err) {\n    logger().info(k().c + \" failed\", err)\n    return\n  }\n}\n\nasync function mac_hwid() {\n  try {\n    const id = await mac_IOPlatformUUID_()\n    return toUID(S.mp, id)\n  } catch (err) {\n    logger().info(\"ioreg failed\", err)\n    return\n  }\n}\n\nasync function mac_IOPlatformUUID_() {\n  const out = await stdout(k().i, k().ia, {\n    timeout: 5 * secondMs\n  })\n  //       \"IOPlatformUUID\" = \"XXX-XXX-XXX\"\n  const id = out.match(/uuid\" = \"([a-z0-9-]{12,})\"/i)?.[1]\n  return id\n}\n\nasync function win_machineGuid_() {\n  return (await PowerShell.instance().executeJson(k().w))?.MachineGuid\n}\nasync function win_hwid() {\n  const obj = await win_machineGuid_()\n  return toUID(S.wm, obj)\n}\n\nconst machineIds = lazy(async () => {\n  if (isDocker()) {\n    return []\n  }\n  // See https://github.com/denisbrodbeck/machineid#snippets\n  else if (isLinux) {\n    return [\n      toUID(S.lm, readFileMaybe(k().lv)),\n      toUID(S.lm, readFileMaybe(k().le)),\n      linux_hwid()\n    ]\n  } else if (isMac) {\n    return [mac_hwid()]\n  } else if (isWin) {\n    return [win_hwid()]\n  } else {\n    return []\n  }\n})\n\nexport async function sids() {\n  const arr = await Promise.all(\n    [libraryId, cpuModelId, volumeIds, macAddressIds, machineIds].map(\n      async ea => {\n        try {\n          // don't wait forever. TICK TOCK!\n          return await thenOrTimeout(ea(), 5 * secondMs)\n        } catch (err) {\n          return logger().warn(err)\n        }\n      }\n    )\n  )\n  return sortUids(uniq(await thenFlatten(arr)))\n}\n", "import { readFile } from \"fs/promises\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { mkLogger } from \"../Logger\"\n\nconst logger = lazy(() => mkLogger(\"ReadFile\"))\n\nexport async function readFileMaybe(nativePath: string): PromiseMaybe<Buffer> {\n  try {\n    const b = await readFile(nativePath)\n    return b\n  } catch (err) {\n    logger().info(\".readFileMaybe(\" + nativePath + \")\", err)\n    return\n  }\n}\n", "import { lazy } from \"../../fe/Lazy\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { MaybeSyncOrAsync } from \"../../fe/OptAsync\"\nimport { thenMap } from \"../async/Promise\"\nimport { mkLogger } from \"../Logger\"\nimport { WrappedError } from \"../error/WrappedError\"\nimport { PosixFile } from \"./PosixFile\"\n\nexport interface CreatedAt {\n  createdAt: number\n}\n\nexport class JsonFileStore<T extends CreatedAt> {\n  constructor(\n    readonly file: PosixFile,\n    readonly mkObject: () => MaybeSyncOrAsync<T>,\n    readonly onWrite?: (file: PosixFile, object: T) => any\n  ) {}\n\n  private readonly prior = lazy(() => this.file.readJson<T>(\"debug\"))\n\n  async read(): PromiseMaybe<T> {\n    const prior = await this.prior()\n    mkLogger(\"JsonFileStore\").debug(\"prior \" + this.file, prior)\n    if (prior != null) {\n      return prior\n    } else {\n      return thenMap(this.mkObject(), t => this.write(t))\n    }\n  }\n\n  async write(t: T): Promise<T> {\n    try {\n      await this.file.writeJSON_(t, { spaces: 2 })\n      await this.prior.set(Promise.resolve(t))\n      mkLogger(\"JsonFileStore\").info(\"wrote to \" + this.file, t)\n      if (this.onWrite != null) {\n        await this.onWrite(this.file, t)\n      }\n      return t\n    } catch (err) {\n      throw new WrappedError({\n        cause: err,\n        message: \"Failed to write to \" + this.file\n      })\n    }\n  }\n}\n", "import { later } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map } from \"../../fe/Maybe\"\nimport { thenMapOr } from \"../async/Promise\"\nimport { onClearCache } from \"../event/EventEmitter\"\nimport { TokenRadix } from \"../math/Radix\"\nimport { libraryDataDir } from \"../settings/LibraryDirs\"\nimport { Settings } from \"../settings/Settings\"\nimport { version } from \"../Version\"\nimport { WrappedError } from \"../error/WrappedError\"\nimport { CreatedAt, JsonFileStore } from \"./JsonFileStore\"\nimport { PosixFile } from \"./PosixFile\"\n\nexport interface UidFile extends CreatedAt {\n  uid: string\n  version: string\n  type: \"library\" | \"system\"\n}\n\nexport function mkuid() {\n  return TokenRadix.safeRandomUid(16, 4)\n\n  // Having a hostname prefix might help make UUIDs more glance-discriminatable.\n\n  // We really just want to see some ID that a user has a chance of recognizing.\n  // They won't know their MAC address or CPUID.\n\n  // * CPUID isn't available on all platforms.\n\n  // * remember that MAC addresses are changed by both macOS and Windows.\n\n  // return compactBlanks([\n  //   fsSafeHostname().substr(0, 6),\n  //   TokenRadix.safeRandomUid(16, 4)\n  // ]).join(\"-\")\n}\n\nexport class UIDStore extends JsonFileStore<UidFile> {\n  constructor(readonly rootDir: PosixFile, readonly type: UidFile[\"type\"]) {\n    // we hide it, because why not:\n    super(\n      rootDir.join(\".\" + type + \"-uid.json\"),\n      () => ({\n        uid: mkuid(),\n        version,\n        type: this.type,\n        createdAt: Date.now()\n      }),\n      f => f.hide()\n    )\n  }\n\n  readonly read_ = lazy(() =>\n    thenMapOr(\n      this.read(),\n      ea => ea.uid,\n      () => \"missing!\"\n    ).catch(cause => {\n      throw new WrappedError({\n        cause,\n        fatal: true,\n        message: \"Failed to read \" + this.rootDir\n      })\n    })\n  )\n}\n\n// /**\n//  * We store this so the system UID stays consistent even if the local hostname\n//  * changes\n//  */\n// export const SystemUIDStore = lazy(\n//   () => new UIDStore(PosixFile.for(userData()), \"system\")\n// )\n\nexport const LibraryUIDStore = lazy(() =>\n  map(libraryDataDir(), rootDir => new UIDStore(rootDir, \"library\"))\n)\n\nlater(() => {\n  onClearCache(() => {\n    // SystemUIDStore.unset()\n    LibraryUIDStore.unset()\n  })\n  Settings.libraryPath.addListener(() => LibraryUIDStore.unset())\n})\n", "import { networkInterfaces } from \"os\"\nimport { flatten, uniq } from \"../../fe/Array\"\nimport { notBlank } from \"../../fe/Blank\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { values } from \"../../fe/Object\"\nimport { toA } from \"../../fe/toA\"\n\n// ignore both \"00:00:00:00:00:00\" and \"ff:ff:ff:ff:ff:ff\":\n\nconst invalid = /^(?:[0:]+|[f:]+)$/i\n\nexport const macs = lazy(() =>\n  uniq(\n    flatten(\n      values(networkInterfaces()).map(arr => toA(arr).map(ea => ea.mac))\n    ).filter(ea => notBlank(ea) && invalid.exec(ea) == null)\n  )\n)\n", "import { sortBy, uniq } from \"../../fe/Array\"\nimport { blank } from \"../../fe/Blank\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { MaybeSyncOrAsync } from \"../../fe/OptAsync\"\nimport { strEnum, StrEnumKeys } from \"../../fe/StrEnum\"\nimport { toS } from \"../../fe/toS\"\nimport { shortStringSha } from \"../fs/Hash\"\nimport { mkLogger } from \"../Logger\"\nimport { Radix58 } from \"../math/Radix\"\nimport { j } from \"./BrotliDecode\"\n\n// console.dir(\n//   require(\"zlib\")\n//     .brotliCompressSync(\n//       JSON.stringify({\n//         cm: \"cpuModelUid\",\n//         cu: \"customerUid\",\n//         lc: \"linuxCpuUid\",\n//         li: \"libraryUid\",\n//         lm: \"linuxMachineUid\",\n//         ma: \"macAddressUid\",\n//         mp: \"macOsPlatformUid\",\n//         vl: \"volumeUid\",\n//         wm: \"windowsMachineUid\"\n//       })\n//     )\n//     .toString(\"base64\")\n// )\n\n/**\n * licensing keys\n */\nconst k = lazy<{\n  cm: \"cpuModelUid\"\n  cu: \"customerUid\"\n  lc: \"linuxCpuUid\"\n  li: \"libraryUid\"\n  lm: \"linuxMachineUid\"\n  ma: \"macAddressUid\"\n  mp: \"macOsPlatformUid\"\n  vl: \"volumeUid\"\n  wm: \"windowsMachineUid\"\n}>(() =>\n  j(\n    \"G7kAIIzUYs0Z7qRuS32pmsUk/UyD8OFBrsHUYemDqh3/zMuNBya1K0GYBazpDR8puUeR5pOPDwrAyLrH9L4GAhPQPWicizajRNayvHKU52siIpE9GddV7bjtHChhuc6wwPIkg/x4NH0P\"\n  )\n)\n\n// Sort order:\n\n// cu: \"customerUid\"\n// lc: \"linuxCpuUid\"\n// lm: \"linuxMachineUid\"\n// mp: \"macOsPlatformUid\"\n// wm: \"windowsMachineUid\"\n\n// li: \"libraryUid\"\n// cm: \"cpuModelUid\"\n\n// ma: \"macAddressUid\"\n// vl: \"volumeUid\"\n\n/**\n * System ID schemes, in order of importance\n */\nexport const S = strEnum(\"cu\", \"lc\", \"lm\", \"mp\", \"wm\", \"li\", \"cm\", \"ma\", \"vl\")\nexport type SchemePrefix = StrEnumKeys<typeof S>\n\nexport function sortUids(uids: string[]) {\n  return sortBy(uniq(uids.filter(isValidUid)), ea => [\n    S.indexOf(ea.split(\":\")[0]),\n    ea\n  ])\n}\n\nexport function prefix2scheme(prefix: SchemePrefix) {\n  return k()[prefix]\n}\n\nexport const UidLength = 15\n\nexport async function toUID(\n  pfx: SchemePrefix,\n  id: MaybeSyncOrAsync<string | Buffer>\n): PromiseMaybe<string> {\n  try {\n    const str = toS(await id)\n    return blank(str) || str.match(/^[\\s0:_\\/-]*$/) != null\n      ? undefined\n      : pfx + \":\" + shortStringSha(str.trim(), UidLength, Radix58)\n  } catch (err) {\n    mkLogger(\"toUID\").warn(\"failed\", { pfx, err })\n    return\n  }\n}\n\nconst uidRE = lazy(\n  () => new RegExp(`^(${S.values.join(\"|\")}):[0-9a-zA-Z]{${UidLength}}$`)\n)\n\nexport function isValidUid(s: string) {\n  return s != null && uidRE().exec(s) != null\n}\n", "import { License } from \"../../fe/api/License\";\nimport { S } from \"../../fe/api/Subscriptions\";\nimport { compact, uniq } from \"../../fe/Array\";\nimport { dayMs } from \"../../fe/Date\";\nimport { Maybe } from \"../../fe/MaybeTypes\";\nimport { cmp } from \"../../fe/Primitive\";\nimport { intersection } from \"../Array\";\nimport { within } from \"../Number\";\nimport { Pojo } from \"../Object\";\nimport { prefix2scheme } from \"./SystemIdSchemes\";\nimport { ParsedLicense, k } from \"./Licensing\";\n\nexport class L implements ParsedLicense {\n  readonly meta: Pojo;\n  /**\n   * @param s the actual license string\n   * @param _l the parsed License\n   */\n  constructor(\n    readonly s: string,\n    readonly _l: Maybe<License>,\n    readonly _sids: string[],\n    src: string\n  ) {\n    this.meta = { src };\n  }\n\n  get l() {\n    return this._l;\n  }\n\n  get ok() {\n    if (this._l == null)\n      return false;\n    const matchedUids = intersection(this._sids, this._l.uids);\n    const matchedSchemePrefixes = uniq(matchedUids.map(ea => ea.split(\":\")[0]));\n    const matchedSchemes = compact(\n      matchedSchemePrefixes.map(ea => prefix2scheme(ea as any))\n    );\n    const uidsOK = matchedSchemes.length >= this._l.mat;\n    const dateOK = within(\n      this._l.iat?.getTime(),\n      this._l.exp?.getTime() + dayMs,\n      Date.now()\n    );\n\n    this.meta[k().o] = dateOK;\n    this.meta[k().u] = uidsOK;\n    this.meta[k().m] = matchedSchemes;\n\n    // console.log(\"L.ok()\", {\n    //   dateOK,\n    //   uidsOK,\n    //   sids: this._sids,\n    //   l_uids: this._l.uids,\n    //   matchedSchemes,\n    //   matchedUids,\n    //   matchedSchemePrefixes\n    // })\n    return dateOK && uidsOK;\n  }\n\n  cmpVal() {\n    return [\n      this.ok,\n      -S.indexOf(this.l?.[k().T]),\n      this.l?.exp?.getTime() ?? 1,\n      this.meta.matchedSchemes // more is better\n    ];\n  }\n\n  /**\n   * @return 1 if this > b, -1 if this < b, 0 if this == b.\n   */\n  cmp(p: L) {\n    return cmp(this.cmpVal(), p.cmpVal());\n  }\n}\n", "import { lazy } from \"../../fe/Lazy\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { thenCollect } from \"../../fe/Promise\"\nimport { BaseFile } from \"../fs/BaseFile\"\nimport { shortStringSha } from \"../fs/Hash\"\nimport { mkLogger } from \"../Logger\"\nimport { libraryDataDir } from \"../settings/LibraryDirs\"\nimport { userData } from \"../UserData\"\nimport { L } from \"./L\"\nimport { k, m, vok } from \"./Licensing\"\n\nconst logger = lazy(() => mkLogger(\"writeLicense\"))\n\n/**\n * Write license\n * @param t paseto token (\"v2.public....\")\n */\nexport async function writeLicense(str: string) {\n  // This throws if validation fails\n  const pl = await vok(str, \"candidate\")\n  if (pl == null) {\n    return logger().error(\"!ok\", str)\n  }\n  // Only store the license if it's better than what we've got already for any\n  // given directory:\n  await saveIfBetter(pl, libraryDataDir()?.join(k().d))\n  await saveIfBetter(pl, BaseFile.for(userData()).join(k().d))\n\n  m.unset()\n}\n\nexport async function licensesInDirectory(dir: BaseFile): Promise<L[]> {\n  return (\n    await thenCollect(dir.childFiles(), async ea =>\n      vok((await ea.readFile())?.toString().trim(), ea.nativePath)\n    )\n  ).filter(ea => ea.ok && ea instanceof L) as L[]\n}\n\nexport async function saveIfBetter(pl: L, dir: Maybe<BaseFile>) {\n  if (dir == null) return\n  const prior = await licensesInDirectory(dir)\n  if (prior.some(ea => ea.cmp(pl) >= 0)) {\n    logger().info(\"saveIfBetter(): no-op for \" + dir)\n    return\n  } else {\n    const f = dir.join(shortStringSha(pl.s) + \".txt\")\n    return await f\n      .writeFile_(pl.s)\n      .then(() => {\n        logger().info(\"saveIfBetter(): wrote to \" + f)\n        return f\n      })\n      .catch(err => {\n        logger().error(\"saveIfBetter(): failed to save license to \" + dir, err)\n        return\n      })\n  }\n}\n", "import { isEmpty } from \"../../fe/Array\"\nimport { blank, notBlank } from \"../../fe/Blank\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { stringify } from \"../../fe/JSON\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { BaseFile } from \"../fs/BaseFile\"\nimport { shortFsStringSha } from \"../fs/Hash\"\nimport { mkLogger } from \"../Logger\"\nimport { request } from \"../net/Request\"\nimport { Settings } from \"../settings/Settings\"\nimport { userData } from \"../UserData\"\nimport { j } from \"./BrotliDecode\"\nimport { m } from \"./Licensing\"\nimport { sids } from \"./SystemIds\"\nimport { writeLicense } from \"./WriteLicense\"\n\nconst logger = lazy(() => mkLogger(k().l))\n\n// console.dir(\n//   require(\"zlib\")\n//     .brotliCompressSync(\n//       JSON.stringify({\n//         a: \"license\",\n//         e: \"email\",\n//         l: \"AutoRefreshLicense\",\n//         n: [\"plus\"], // non-free subscription tiers\n//         r: { method: \"POST\", headers: { \"content-type\": \"application/json\" } },\n//         s: \"autoRefreshLicense\",\n//         u: \"https://account.photostructure.com/license/refresh\"\n//       })\n//     )\n//     .toString(\"base64\")\n// )\n\nconst k = lazy<{\n  a: \"license\"\n  l: \"AutoRefreshLicense\"\n  n: [\"plus\"] // non-free subscription tiers\n  r: { method: \"POST\"; headers: { \"content-type\": \"application/json\" } }\n  s: \"autoRefreshLicense\"\n  u: \"https://account.photostructure.com/license/refresh\"\n}>(() =>\n  j(\n    \"G9YAwIzTFfOihHWPgG6m/h0h65IqCersIGkdlq6+6ra6+PjQ8mHlRTkDg6UJJqPJEIU6WaIUNodfF2xPB7iLWJDlIN8z6xhOKyn4qqHpZlh6qCZUoQghd4BVMkz3A0IIevFn+7UO7uM+VGJb/MeZXfHngpQWZzk=\"\n  )\n)\n\n/**\n * Automatically attempt to refresh the license in the background iff\n *\n * 1) autoRefreshLicense is true\n *\n * 2) there isn't a currently valid license\n *\n * 3) there is a prior license with a customer id hash (required by POST)\n *\n * 4) the license has expired\n *\n * 5) there hasn't been a license refresh for that license\n */\nexport const r = lazy(async () => {\n  const ctx = k().s + \": \"\n  try {\n    if (!Settings[k().s].valueOrDefault) {\n      return logger().debug(ctx + \"no-op (settings disabled)\")\n    }\n    // These all have a valid (but possibly expired) license:\n    const arr = (await m()).filter(ea => ea.l != null && notBlank(ea.s))\n    const now = new Date()\n    // We're actually checking the expiration time here, because .ok gives the\n    // expiration date a day of leeway:\n    const current = arr.find(ea => ea.ok && now < ea.l!.exp)\n    if (current != null) {\n      return logger().debug(ctx + \"no-op: \", current)\n    }\n    const dir = await BaseFile.for(userData()).join(k().s).mkdirp_()\n    for (const lic of arr) {\n      // skip over empty or unexpired licenses:\n      if (blank(lic.s) || lic.l == null || now < lic.l!.exp) continue\n      const c = lic.l.uids.find(ea => ea.startsWith(\"cu:\"))\n      if (c == null) {\n        logger().debug(ctx + \"skipping (no cu)\", lic)\n        continue\n      }\n      await dir\n        .join(shortFsStringSha(lic.s, 14) + \".txt\")\n        .applyIfEmpty_(async dest => {\n          await f(c)\n          await dest.writeJSON_({ l: lic.l, at: Date.now() })\n          logger().warn(ctx + \"requested\", lic)\n        })\n    }\n  } catch (err) {\n    logger().warn(ctx + \"failed\", err)\n  }\n}, 15 * minuteMs)\n\n/**\n * Fetch and store a new license. Should normally only be run via r()\n * (auto-refresh license)\n */\nasync function f(cuid: string) {\n  try {\n    const uids = await sids()\n    if (isEmpty(uids)) {\n      return logger().warn(\"no-op: empty sids\")\n    }\n    // Add the customer ids to the current system ids so\n    // account.photostructure.com knows our customer:\n    const body = stringify({ uids: [...uids, cuid] })\n    const req = {\n      // headers are included in k().r\n      ...k().r,\n      body\n    }\n    const response = await request(k().u, req)\n    logger().info(k().u, { req, response })\n    if (response.ok) {\n      // If this is successfull, w() (writeLicense) will automatically unset m()\n      // (readAllLicenses):\n      await writeLicense(JSON.parse(response.body)?.[k().a])\n    } else {\n      logger().warn(k().u, { req, response })\n    }\n  } catch (err) {\n    logger().warn(k().u, err)\n  }\n}\n", "import { V2 } from \"paseto\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { onError } from \"../error/Error\"\nimport { FatalErrorFlag } from \"../error/ErrorTypes\"\nimport { j } from \"./BrotliDecode\"\n\n// console.dir(\n//   require(\"zlib\")\n//     .brotliCompressSync(\n//       JSON.stringify({\n//         c: \"crypto\",\n//         m: \"createPublicKey\",\n//         o: {\n//           format: \"pem\",\n//           type: \"spki\",\n//           key:\n//             \"-----BEGIN PUBLIC KEY-----\\nMCowBQYDK2VwAyEA5XK+l4rxUbUfFOUkFN3S5kk0xpQo4zA3bGNY9SdL1XE=\\n-----END PUBLIC KEY-----\\n\"\n//         },\n//         w: \"verify\"\n//       })\n//   )\n//     .toString(\"base64\")\n// )\n\nexport const l = lazy<{\n  c: \"crypto\"\n  m: \"createPublicKey\"\n  o: {\n    format: \"pem\"\n    type: \"spki\"\n    key: \"-----BEGIN PUBLIC KEY-----\\nMCowBQYDK2VwAyEA5XK+l4rxUbUfFOUkFN3S5kk0xpQo4zA3bGNY9SdL1XE=\\n-----END PUBLIC KEY-----\\n\"\n  }\n  w: \"verify\"\n}>(\n  () =>\n    j(\n      \"G9AAICwK7KZhK2gx/dEjjDHuEVVxShG2PVDGAcBqBqP3binicrOwzdRXMfMKd00dlj6bnSYcBaK1S8KWhAGGv73Zu73eMMKnXGoKt4NsAefjf3tdIWcHCM4FdbL+J+haq7GA2/ps1jHled6Oe+3j+k+BBQbgzzJmnLDvnTnXr11NbkL3X+vvWdyYILH9urnb+EV39HOm4Y5Hcrfqyt5i5iCfpGaVUqOnNfYDdeWC8wV2OWE=\"\n    ) as any\n)\n\n/** PublicKey */\nexport const q = lazy(() => {\n  try {\n    const c = require(l().c)\n    return c[l().m](l().o)\n  } catch (err) {\n    onError(l().m + FatalErrorFlag, err)\n  }\n})\n\n/**\n * V2.verify the given token string\n */\nexport function V(s: string) {\n  return V2[l().w](s, l().o)\n}\n", "import { License } from \"../../fe/api/License\"\nimport { S } from \"../../fe/api/Subscriptions\"\nimport { compact, flatten, sortBy } from \"../../fe/Array\"\nimport { blank, mapNotBlank } from \"../../fe/Blank\"\nimport { isTrue } from \"../../fe/Boolean\"\nimport { later } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { thenOpt } from \"../../fe/OptAsync\"\nimport { thenCollect } from \"../../fe/Promise\"\nimport { ensurePrefix } from \"../../fe/String\"\nimport { toA } from \"../../fe/toA\"\nimport { toS } from \"../../fe/toS\"\nimport { mapAsync, thenMap } from \"../async/Promise\"\nimport { utcIsoToTs } from \"../date/Date\"\nimport { BaseFile } from \"../fs/BaseFile\"\nimport { mkLogger } from \"../Logger\"\nimport { Pojo } from \"../Object\"\nimport { libraryDataDir } from \"../settings/LibraryDirs\"\nimport { Settings } from \"../settings/Settings\"\nimport { userData } from \"../UserData\"\nimport { r } from \"./AutoRefreshLicense\"\nimport { j } from \"./BrotliDecode\"\nimport { L } from \"./L\"\nimport { V } from \"./Paseto\"\nimport { sids } from \"./SystemIds\"\n\n// prevent greps for \"*license*\" or \"*validate*\":\n\n// console.dir(\n//   require(\"zlib\")\n//     .brotliCompressSync(\n//       JSON.stringify({\n//         a: \"mat\",\n//         b: \"uids\",\n//         d: \"licenses\",\n//         e: \"Token verification failed: \",\n//         f: \"lite\",\n//         l: \"Licensing\",\n//         i: \"iat\",\n//         r: \"exp\",\n//         m: \"matchedSchemes\",\n//         n: \"set\",\n//         o: \"dateOK\",\n//         p: \"v2.public.\",\n//         R: \"autoRefreshLicense\",\n//         L: \"license\",\n//         T: \"tier\",\n//         t: \"trial\",\n//         u: \"uidsOK\",\n//         v: \"validate\"\n//       })\n//     )\n//     .toString(\"base64\")\n// )\n\n/**\n * licensing keys\n */\nexport const k = lazy<{\n  a: \"mat\"\n  b: \"uids\"\n  d: \"licenses\"\n  e: \"Token verification failed: \"\n  f: \"lite\"\n  l: \"Licensing\"\n  i: \"iat\"\n  r: \"exp\"\n  m: \"matchedSchemes\"\n  n: \"set\"\n  o: \"dateOK\"\n  p: \"v2.public.\"\n  R: \"autoRefreshLicense\"\n  L: \"license\"\n  T: \"tier\"\n  t: \"trial\"\n  u: \"uidsOK\"\n  v: \"validate\"\n}>(() =>\n  j(\n    \"GwwBABwHdkzj5qg5WDnubFuq7NaxSKjiobwK4iGSLDp98J87fqD679bWgnaVtCVBQAEFBJm7aiN4y7puJw8PPz+CHDoAhk5Fd0AhTjKYPbo8F5freFUJHhQHc2xp4qfyoqKKAmGb7IkFZwkajH7uJCR829lmguhEXw/iusqUQE4nk7LeJyad4wmdptoVln0otnUOO3UHnEyjrxtXUr7B\"\n  )\n)\n\nconst logger = lazy(() => mkLogger(k().l))\n\n// /**\n//  * Extract the footer from a token\n//  */\n// function extractFooter(t: string): Maybe<string> {\n//   return map(t.split(\".\")[3], b64decodeString)\n// }\n\n/**\n * Verify token, but don't validate against current system IDs\n */\nexport async function v_(str: Maybe<string>) {\n  const o = (await V(ensurePrefix(toS(str).trim(), k().p))) as Pojo\n  const iat = utcIsoToTs(o[k().i])\n  if (iat == null) {\n    throw new Error(\"bad \" + k().i + \": \" + o[k().i] + \" (\" + str + \")\")\n  }\n  const exp = utcIsoToTs(o[k().r])\n  if (exp == null) {\n    throw new Error(\"bad \" + k().r + \": \" + o[k().r] + \" (\" + str + \")\")\n  }\n\n  o[k().a] = o[k().a] >= 0 ? o[k().a] : 2\n  o[k().i] = new Date(iat)\n  o[k().r] = new Date(exp)\n  o[k().b] = toS(o.uids).split(\",\")\n  return o as License\n}\n\nexport interface ParsedLicense {\n  ok: boolean\n  /**\n   * the actual license string\n   */\n  s: string\n  l?: License\n  meta: Pojo\n}\n\n/**\n * Verify and validate the given stringified license\n */\nexport async function v(str: string, src: string): Promise<ParsedLicense | L> {\n  try {\n    return new L(str, await v_(str), await sids(), src)\n  } catch (err) {\n    return logger().tap({\n      msg: k().v,\n      result: {\n        s: str,\n        ok: false,\n        meta: { err }\n      }\n    })\n  }\n}\n\n/**\n * Only return an L if the license string validates and is currently good.\n */\nexport async function vok(str: Maybe<string>, src: string): PromiseMaybe<L> {\n  if (blank(str)) return\n  const ea = await v(str, src)\n  return isTrue(ea?.ok) && ea instanceof L ? ea : undefined\n}\n\n/**\n * Return all available licenses and metadata from either the PS_LICENSE\n * environment variable, or licenses stored on the filesystem.\n *\n * The first element will be the \"best\" license.\n */\nexport const m = lazy(async () => {\n  // Read from env, system, and library. Use the best one.\n  // We don't require any special naming convention. Just try to b64 decode everything:\n  const srcDirs = compact([\n    libraryDataDir()?.join(k().d),\n    BaseFile.for(userData()).join(k().d)\n  ])\n  // console.log(\"src dirs\", srcDirs.map(toS))\n  const files = flatten(await mapAsync(srcDirs, dir => dir.childFiles()))\n  // console.log(\n  //   \"src files\",\n  //   files.map(ea => ea.baseWithGrandparent)\n  // )\n  const raw = flatten(\n    await mapAsync(files, async src =>\n      mapNotBlank(\n        toA(await src.readLines())\n          .map(ea => ea.trim())\n          .join(\"\"),\n        ea => v(ea, src.nativePath)\n      )\n    )\n  )\n  await mapNotBlank(Settings[k().L].value, async ea =>\n    raw.push(await v(ea, \"Settings\"))\n  )\n\n  const result = sb(raw)\n\n  // autoRefreshLicense if necessary\n  later(r)\n\n  return logger().tap({\n    msg: k().d + \"()\",\n    result\n  })\n})\n\n/**\n * @return sort-by criteria\n */\nexport async function sb(arr: ParsedLicense[]) {\n  return sortBy(arr, ea => [\n    !ea.ok, // we want true first\n    S.indexOf(ea.l?.[k().T]),\n    -(ea.l?.exp?.getTime() ?? 1) // farther-out expiration is better\n  ])\n}\n\n/**\n * read files from dir and return the best license\n */\nexport async function d(f: BaseFile) {\n  return sb(\n    await thenCollect(f.childFiles(), async ea => {\n      const txt = (await ea.readFile())?.toString().trim()\n      return blank(txt) ? undefined : v(txt, ea.nativePath)\n    })\n  )\n}\n\nlater(\n  // Don't let .set() to be a thing:\n  () => (m[k().n] = (() => null) as any)\n)\n\n/**\n * @return the best license available\n */\nexport function b() {\n  return thenMap(m(), arr => (arr[0]?.ok ? arr[0] : undefined))\n}\n\n/**\n * @return the current subscription tier\n */\nexport async function t() {\n  return thenOpt(b())\n    .flatMap(ea => ea.l?.[k().T])\n    .getOrElse(() => k().f)\n}\n\n/**\n * @return true if the license is \"lite\"\n */\nexport async function l() {\n  try {\n    return (await t()) === k().f\n  } catch {\n    return true\n  }\n}\n", "import { minuteMs, secondMs } from \"../../fe/Date\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { isRotation } from \"../../fe/Rotation\"\nimport { thenMap } from \"../async/Promise\"\nimport { stdout, stdoutResult } from \"../child/ChildProcess\"\nimport { WrappedError } from \"../error/WrappedError\"\nimport { emitFileChanged } from \"../event/EventEmitter\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { jpegtranNativePath } from \"../fs/Tools\"\nimport { mkLogger } from \"../Logger\"\nimport { isWin } from \"../Platform\"\nimport { cachedImgFile } from \"./ImgCache\"\nimport { isIgnorableValidationError } from \"./ValidFile\"\n\nconst devnull = isWin ? \"NUL\" : \"/dev/null\"\n\nconst logger = lazy(() => mkLogger(\"jpegtran\"))\n\n/**\n * @throws if the jpeg is not valid.\n */\nexport async function validJpeg(src: PosixFile): Promise<void> {\n  const cmd = await jpegtranNativePath()\n  try {\n    await stdoutResult(cmd, [\"-outfile\", devnull, src.nativePath], {\n      timeout: 30 * secondMs,\n      isIgnorableError: isIgnorableValidationError\n    })\n  } catch (cause) {\n    throw new WrappedError({\n      cause,\n      doNotSend: true,\n      fatal: false,\n      retriable: false\n    })\n  }\n}\n\n/**\n * @throws if error\n */\nexport async function rotateInPlace(\n  src: PosixFile,\n  degrees: number\n): Promise<void> {\n  const dest = src.wip()\n  logger().info(\"rotateInPlace(\" + src + \")\", degrees)\n  await rotate(src, dest, degrees)\n  await dest.unwip_()\n  emitFileChanged(src.nativePath)\n  return\n}\n\n/**\n * @throws if error\n */\nexport async function rotate(\n  src: PosixFile,\n  dest: PosixFile,\n  degrees: number\n): Promise<void> {\n  const cmd = await jpegtranNativePath()\n  if (!isRotation(degrees)) {\n    throw new Error(\"refusing to rotate(\" + src + \", \" + degrees + \")\")\n  }\n  await stdout(\n    cmd,\n    [\n      \"-copy\",\n      \"all\",\n      \"-trim\",\n      \"-rotate\",\n      degrees.toFixed(0),\n      \"-outfile\",\n      dest.nativePath,\n      src.nativePath\n    ],\n    { timeout: minuteMs }\n  )\n  return\n}\n\nexport async function rotateToImgTmp(\n  src: PosixFile,\n  degrees: Maybe<number>\n): PromiseMaybe<PosixFile> {\n  if (degrees == null || degrees === 0) return src\n  return thenMap(cachedImgFile(src, \"r\" + degrees, src.ext), dest =>\n    dest.applyIfEmpty_(ea => rotate(src, ea, degrees))\n  )\n}\n", "import { Maybe } from \"../../fe/MaybeTypes\"\nimport { toInt } from \"../../fe/Number\"\n\nexport const BinaryFieldRE = /^\\(?Binary data (\\d+).*use -b option to extract\\)?$/i\n\nexport class BinaryField {\n  constructor(readonly binaryDataBytes: number) {}\n}\n\nexport function parseBinaryField<T>(v: T): Maybe<BinaryField> {\n  if (typeof v !== \"string\") return\n  const m = v.match(BinaryFieldRE)\n  return m == null\n    ? undefined\n    : new BinaryField(toInt(m[1], { defaultValue: 0 })!)\n}\n", "import { Maybe } from \"../../fe/MaybeTypes\"\nimport { toS } from \"../../fe/toS\"\nimport { isChrome, isFirefox } from \"../../fe/UserAgent\"\n\nconst sharpSupportedMimeTypes = [\n  \"image/gif\",\n  \"image/jpeg\",\n  \"image/pjpeg\",\n  \"image/png\",\n  \"image/tiff\",\n  \"image/webp\"\n]\n\nexport function isSharpMimetype(mimetype: Maybe<string>): boolean {\n  return sharpSupportedMimeTypes.includes(toS(mimetype).toLowerCase())\n}\n\nconst librawSupportedMimeTypes = new Set([\n  // TODO: add hasselblad, leaf, leica, phase one\n  // See https://www.dechifro.org/dcraw/#cameras\n  \"image/x-adobe-dng\",\n  \"image/x-canon-cr2\",\n  // \"image/x-canon-cr3\", // TODO: these aren't supported by libraw yet\n  \"image/x-canon-crw\",\n  \"image/x-epson-erf\",\n  \"image/x-fuji-raf\", // < both are found in the wild\n  \"image/x-fujifilm-raf\", // < both are found in the wild\n  \"image/x-kodak-dcr\",\n  \"image/x-kodak-k25\",\n  \"image/x-kodak-kdc\",\n  \"image/x-minolta-mrw\",\n  \"image/x-nikon-nef\",\n  \"image/x-nikon-nrw\",\n  \"image/x-olympus-orf\",\n  \"image/x-panasonic-raw\",\n  \"image/x-panasonic-rw2\",\n  \"image/x-pentax-pef\",\n  \"image/x-samsung-srw\",\n  \"image/x-sigma-x3f\",\n  \"image/x-sony-arw\",\n  \"image/x-sony-sr2\",\n  \"image/x-sony-srf\"\n])\n\nexport function isLibrawMimetype(mimetype: Maybe<string>): boolean {\n  return librawSupportedMimeTypes.has(toS(mimetype).toLowerCase())\n}\n\nconst reasonableBrowserMimetypes = [\n  \"image/gif\",\n  \"image/jpeg\",\n  \"image/pjpeg\",\n  \"image/png\",\n  \"image/webp\"\n]\n\nconst oldBrowserMimetypes = [\"image/gif\", \"image/jpeg\", \"image/png\"]\n\nexport function isMimetypeSupported(\n  mimetype: Maybe<string>,\n  userAgent: Maybe<string>\n) {\n  return (isChrome(userAgent) || isFirefox(userAgent)\n    ? reasonableBrowserMimetypes\n    : oldBrowserMimetypes\n  ).includes(toS(mimetype))\n}\n", "import { compact } from \"../../fe/Array\"\nimport { Dimensions, dmegapixels } from \"../../fe/Dimensions\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { gt0, lt, lte, toInt } from \"../../fe/Number\"\nimport { toS } from \"../../fe/toS\"\nimport { ExifTags } from \"../tags/ExifTags\"\n\nexport function tmegapixels(t: ExifTags) {\n  if (t.dimensions != null) return dmegapixels(t.dimensions)\n  if (gt0(t.Megapixels)) return t.Megapixels\n  return\n}\n\n/**\n * @return true if `lhs` is wholly contained by `rhs`.\n */\nexport function ltBoth(lhs: Dimensions, rhs: Dimensions) {\n  return lt(lhs.width, rhs.width) && lt(lhs.height, rhs.height)\n}\n\n/**\n * @return true if `lhs` is wholly contained by `rhs`.\n */\nexport function lteBoth(lhs: Dimensions, rhs: Dimensions) {\n  return lte(lhs.width, rhs.width) && lte(lhs.height, rhs.height)\n}\n\n/**\n * @return true if `lhs` is wholly contained by `rhs`.\n */\nexport function ltEither(lhs: Dimensions, rhs: Dimensions) {\n  return lt(lhs.width, rhs.width) || lt(lhs.height, rhs.height)\n}\n\nexport function parseDimensions(s: Maybe<string>): Maybe<Dimensions> {\n  const arr = compact(\n    toS(s)\n      .split(/[x\u00D7]/)\n      .map(ea => toInt(ea))\n  )\n  return arr.length === 2 ? { width: arr[0], height: arr[1] } : undefined\n}\n", "import { Dimensions } from \"../../fe/Dimensions\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { thenMap } from \"../async/Promise\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { sizeInfo } from \"../tags/ExifTags\"\n\nexport function dimensions(file: PosixFile): PromiseMaybe<Dimensions> {\n  return thenMap(sizeInfo(file.nativePath), ea => ({\n    width: ea.ImageWidth,\n    height: ea.ImageHeight\n  }))\n}\n", "import { notBlank } from \"../../fe/Blank\"\nimport { later } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { thenMap } from \"../../fe/Promise\"\nimport { stdoutResult } from \"../child/ChildProcess\"\nimport { onClearCache } from \"../event/EventEmitter\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { pathTo } from \"../fs/Tools\"\nimport { mkLogger } from \"../Logger\"\nimport { Settings } from \"../settings/Settings\"\nimport { CmdTimeoutMs } from \"../volumes/VolumeTtls\"\nimport { cachedImgFile } from \"./ImgCache\"\n\nconst logger = lazy(() => mkLogger(\"HeifConvert\"))\n\nlater(() => onClearCache(() => heifConvertPath.unset()))\n\nexport const heifConvertPath = lazy(async () =>\n  pathTo(Settings.heifConvertPath.valueOrDefault)\n)\n\nexport async function isHeifConvertSupported() {\n  const p = await heifConvertPath()\n  return logger().tap({\n    msg: \"isHeifConvertSupported()\",\n    result: notBlank(p),\n    meta: { heifConvertPath: p }\n  })\n}\n\n/**\n * Returns a file holding the binary stream associated to the given tag.\n * Orientation is copied from the src to the result.\n */\nexport async function heif2jpeg(src: PosixFile): PromiseMaybe<PosixFile> {\n  if (!(await isHeifConvertSupported())) return\n  return thenMap(cachedImgFile(src, \"heif\", \".jpeg\"), dest =>\n    dest.applyIfEmpty_(async tmp => {\n      try {\n        await stdoutResult(\n          Settings.heifConvertPath.valueOrDefault,\n          [\n            \"-q\",\n            String(Settings.jpegQuality.valueOrDefault),\n            src.nativePath,\n            tmp.nativePath\n          ],\n          {\n            timeout: CmdTimeoutMs\n          }\n        )\n      } catch (err) {\n        logger().warn(\n          \"heif2jpeg(): failed to convert \" +\n            src +\n            \" to \" +\n            tmp.nativePath +\n            \": \" +\n            err\n        )\n        return\n      }\n    })\n  )\n}\n", "import { lazy } from \"../../fe/Lazy\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { thenMap } from \"../../fe/Promise\"\nimport { stdout, stdoutResult } from \"../child/ChildProcess\"\nimport { BaseFile } from \"../fs/BaseFile\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { mkLogger } from \"../Logger\"\nimport { Settings } from \"../settings/Settings\"\nimport { CmdTimeoutMs, ShortCmdTimeoutMs } from \"../volumes/VolumeTtls\"\nimport { cachedImgFile } from \"./ImgCache\"\n\nconst logger = lazy(() => mkLogger(\"sips\"))\n\n// No one knows nor cares about the version: we just hope they're all compatible with eachother, ish.\n\nexport const sipsPath = lazy(async () => {\n  try {\n    return await stdout(\"command\", [\"-v\", \"sips\"], {\n      timeout: ShortCmdTimeoutMs\n    })\n  } catch (err) {\n    const f = BaseFile.for(\"/usr/bin/sips\")\n    if (await f.isExecutable()) {\n      return f.nativePath\n    } else {\n      logger().info(\"sips is missing from $PATH\", err)\n      return undefined\n    }\n  }\n})\n\n// sips -s format png oldpic.jpg --out newpic.png\n\nexport async function sips2jpeg(src: PosixFile): PromiseMaybe<PosixFile> {\n  return thenMap(cachedImgFile(src, \"heif\", \".jpeg\"), dest =>\n    dest.applyIfEmpty_(async tmp => {\n      try {\n        await stdoutResult(\n          \"sips\",\n          [\n            \"-s\",\n            \"format\",\n            \"jpeg\",\n            \"-s\",\n            \"formatOptions\",\n            String(Settings.jpegQuality.valueOrDefault),\n            src.nativePath,\n            \"--out\",\n            tmp.nativePath\n          ],\n          {\n            timeout: CmdTimeoutMs\n          }\n        )\n      } catch (err) {\n        logger().warn(\n          \"sips(): failed to convert \" +\n            src +\n            \" to \" +\n            tmp.nativePath +\n            \": \" +\n            err\n        )\n        return\n      }\n    })\n  )\n}\n", "import { blank, notBlank, notBlankOr } from \"../../fe/Blank\"\nimport { later } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { errorToHumanString } from \"../error/Error\"\nimport { onClearCache } from \"../event/EventEmitter\"\nimport { mkLogger } from \"../Logger\"\nimport { isMac } from \"../Platform\"\nimport { Settings } from \"../settings/Settings\"\nimport { heifConvertPath } from \"./HeifConvert\"\nimport { sipsPath } from \"./sips\"\nimport { ToolDetails } from \"./ToolDetails\"\n\nconst logger = lazy(() => mkLogger(\"Heif\"))\n\nexport const getHeifSupportDetails = lazy<Promise<ToolDetails>>(async () => {\n  try {\n    if (isMac) {\n      try {\n        const msg = await sipsPath()\n        if (!blank(msg)) {\n          return { ok: true, msg }\n        }\n      } catch (err) {\n        logger().error(\n          \"Failed to find the sips tool (either in PATH or /usr/bin).\",\n          err\n        )\n      }\n    }\n\n    const path = await heifConvertPath()\n\n    return {\n      ok: notBlank(path),\n      msg: notBlankOr(\n        path,\n        Settings.heifConvertPath.valueOrDefault + \": not installed\"\n      )!\n    }\n  } catch (err) {\n    return {\n      ok: false,\n      msg: errorToHumanString(err)\n    }\n  }\n})\n\nexport async function isHeifSupported() {\n  return (await getHeifSupportDetails()).ok\n}\n\nlater(() => onClearCache(() => getHeifSupportDetails.unset()))\n", "import { toS } from \"../../fe/toS\"\n\nconst HeifMimetypeRE = /^image\\/hei[fc]$/i\n\nexport function isHeifMimetype(mimetype: string) {\n  return HeifMimetypeRE.exec(toS(mimetype)) != null\n}\n", "import { EventEmitter } from \"events\"\nimport { isNotEmpty } from \"../../fe/Array\"\nimport { untilTrue } from \"../async/until\"\n\n/**\n * Safe .emit(): waits until there are listeners for the event before\n * submitting.\n *\n * @return true if the event is emitted as expected. false if the timeout\n * arrives before listeners are added\n */\nexport async function emitSafely(\n  to: EventEmitter,\n  event: string | symbol,\n  args: any,\n  timeoutMs = 1000\n): Promise<boolean> {\n  const ready = await untilTrue(() => isNotEmpty(to.listeners(event)), {\n    timeoutMs\n  })\n  if (ready) to.emit(event, args)\n  return ready\n}\n", "import _sharp = require(\"sharp\")\nimport { inspect } from \"util\"\nimport { Dimensions, dmegapixels, flip, isPortrait } from \"../../fe/Dimensions\"\nimport { ImageSizeName } from \"../../fe/ImageSizes\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { megapixels } from \"../../fe/Units\"\nimport { greatestBy } from \"../Array\"\nimport { Settings } from \"../settings/Settings\"\nimport { Fit, OutputSize, Reducer, Square } from \"./Reducers\"\n\n// https://www.bhphotovideo.com/FrameWork/charts/resolutionChartPopup.html\n// says 2240 x 1680, or 4 Megapixels, is \"Photo Quality\" 8x10 prints. That's\n// ~210 pixels per inch, which is fine for some continuous tone images, but\n// high-contrast line art should see 300 at least.\n\n// We want to render assets on a 5k display quickly.\n\n// If we can cheaply stream the original file, we don't need to save a\n// 5K UHD-resized version.\n\n// \"cheaply stream\" requires the following to be true:\n\n// * not RAW\n// * not enormous (> 20MP)\n\n// x2 image resolutions results in a 20MB, 318 file previews directory.\n// x3 image resolutions results in a 17MB, 210 file previews directory.\n\n// Possible resize strategies:\n\n// megapixel-based (.5MP, 1MP, 2MP, 3MP, ...)\n\n// file size based (2k, 8k, 32k, 128k, ...)\n\n// use popular display sizes, k-means grouping with 4 sizes\n\n// there are *many* display resolutions from 720p through 5k--we'll get it\n// wrong--so what are we trying to do here?\n\n// * We want to make the UI fast by reducing the bytes needed to render a page,\n//   so we want different sizes of previews.\n\n// * We want to minimize the work the browser and webserver need to do to per\n//   request, so if we're going to resize previews, it needs to be < 100ms of\n//   work per image.\n\n// * We want a previews directory that is only as large as it needs to be.\n\n// We could probably serve smaller image resizes on the fly if the source image\n// was small enough (< 2 MP)? But that won't save much disk space.\n\n// A page of several hundred thumbnails would crush the webserver's CPU if the\n// per-request expense is sufficiently high.\n\n// Each halving of width quarters the size of the image, of course, so size\n// drops geometrically.\n\n// https://docs.google.com/spreadsheets/d/18j8oBFwPu9lwQKk2RgpeDIZ5k2bpb5WF7rbHFQwP_4s/edit?usp=sharing\n\n// Display sizes:\n// 1136 \u00D7 640: iPhone SE\n// 1280 \u00D7 720: HD, cheap android phones\n// 1334 x 750: iPhone 6, iPhone 7\n// 1920 x 1080: FHD: TVs, iPhone 6 Plus, iPhone 7 Plus, Google Pixel, Nexus 5x, Chromebooks\n// 2048 x 1536: iPads, Nexus 9\n// 2436 x 1125: iPhone X\n// 2560 x 1440: QHD: Nexus 6P, Google Pixel XL, Samsung Note 5\n// 3120 x 1440: OnePlus 7 Pro\n// 2560 x 1600: 13\" Retina Macbook\n// 2880 x 1440: QHD+: Pixel 2 XL\n// 2732 x 2048: iPad Pro\n// 2880 x 1800: 15\" Retina Macbook\n// 3840 \u00D7 2160: UHD 4k monitor\n// 5120 \u00D7 2880: iMac 5k\n\n// Camera resolutions:\n// First(ish) camera with selfie cam: iPhone 4: front: VGA (480P) rear: 2592x1936\n\n// srcset only works with widths, so images fit to common native screen\n// resolutions will most likely not be the native resolution width, hence the\n// name\n\n// https://en.wikipedia.org/wiki/Graphics_display_resolution\n// https://en.wikipedia.org/wiki/Pixel#/media/File:Sensoraufl%C3%B6sungen.svg\n\nexport class ImageSize {\n  private static readonly _Sizes: ImageSize[] = []\n\n  static sq() {\n    return this._Sizes.filter(ea => ea.reducer === Square)\n  }\n  static largestSq() {\n    return greatestBy(this.sq(), ea => ea.megapixels())!\n  }\n  static fit() {\n    const arr = Settings.previewResolutions.valueOrDefault\n    return this._Sizes.filter(ea => ea.reducer === Fit && arr.includes(ea.name))\n  }\n  static largestFit() {\n    return greatestBy(this.fit(), ea => ea.megapixels())!\n  }\n\n  // Landscape fullscreen native resolution sizes:\n\n  // These images are fit to these boundaries without any cropping\n\n  // static readonly UHD5K = new ImageSize(\"uhd5k\", 5120, 5120, Fit)\n\n  // fit-* files are reduced in size until the entire image fits in the given\n  // dimensions. No cropping is done.\n\n  // Given that we always serve the original as a width, UHD and QHD isn't\n  // needed. FHD is only used to reduce network load.\n\n  // 5K UHD: (14.7 MP)\n  // UHD: (8.3 MP) ~1MiB\n  // FHD: (2 MP) ~500KiB\n  // FWXGA: (1.2 MP) ~300K\n  // HD: (.9 MP) ~100K\n  // SD: (.3 MP) 46K\n  // w240 (.1 MP) 13K\n\n  // These aren't rotational (as of 2020):\n  static readonly UHD8k = new ImageSize(\"uhd8k\", 7680, 4320, Fit, false)\n  static readonly UHD5k = new ImageSize(\"uhd5k\", 5120, 2880, Fit, false) // < 15 MP\n\n  // As of 2020, 4k displays are *normally* landscape.\n  static readonly UHD = new ImageSize(\"uhd4k\", 4096, 2160, Fit)\n\n  // Flagship smartphone screens. Rotational.\n  static readonly QHD = new ImageSize(\"qhd\", 3120, 1440, Fit)\n\n  // 1920x1080 is 1080p. fit to 1920x1920 to fill a 1080p display (most smartphones)\n  // Only one of these will be built, and it depends on the orientation of the image:\n  static readonly FHD = new ImageSize(\"fhd\", 1920, 1080, Fit)\n\n  // FWXGA is so close to FHD, just send them the fhd and save time and space.\n  // // 1366x768 (FWXGA) is (at least as of 2018) the most popular screen\n  // // resolution, according to\n  // // http://gs.statcounter.com/screen-resolution-stats/desktop/worldwide\n  // but 720 video is 720x1280, so this makes a better poster image:\n  static readonly HD = new ImageSize(\"hd\", 1280, 720, Fit)\n\n  // 720x480 is WVGA or 480p (aka \"EDTV\"). Presumably will be used if the window\n  // isn't full screen.\n  static readonly WVGA = new ImageSize(\"wvga\", 720, 480, Fit)\n\n  // old videos are 320x240, so 256 is slightly too big, and made the thumbnails horrible.\n  static readonly QVGA = new ImageSize(\"qvga\", 320, 240, Fit)\n\n  // 160x100 is the wonderfully descriptive QQVGA standard.\n  static readonly QQVGA = new ImageSize(\"qqvga\", 160, 120, Fit)\n\n  // Anything smaller is silly, sending 1k vs 2k is still just one TCP packet.\n  // Note that each additional file also makes scanning the previews directory\n  // slower.\n\n  // sq-* are constrained to a square:\n\n  // Typical file sizes:\n  // sq-w480: ~40-100k\n  // sq-w240: 10-30k\n  // sq-w120: 4-8k\n  // sq-w60: 1-3k\n\n  static readonly S480 = new ImageSize(\"s480\", 480, 480, Square)\n  static readonly S240 = new ImageSize(\"s240\", 240, 240, Square)\n  static readonly S120 = new ImageSize(\"s120\", 120, 120, Square)\n  static readonly S60 = new ImageSize(\"s60\", 60, 60, Square)\n\n  // See the note about about f80 being silly.\n\n  // static readonly S32 = new ImageSize(\"s32\", 32, 32, Square, \"s64\")\n\n  readonly max: Dimensions\n\n  private constructor(\n    readonly name: ImageSizeName,\n    readonly maxWidth: number,\n    readonly maxHeight: number,\n    readonly reducer: Reducer,\n    readonly rotational = true\n  ) {\n    this.max = { width: maxWidth, height: maxHeight }\n    ImageSize._Sizes.push(this)\n  }\n\n  [inspect.custom]() {\n    return {\n      ctor: \"ImageSize\",\n      name: this.name + \" (\" + this.reducer.name + \")\",\n      maxDim: this.maxWidth + \"\u00D7\" + this.maxHeight,\n      maxMP: this.megapixels()\n    }\n  }\n\n  get minDimension() {\n    return Math.min(this.maxWidth, this.maxHeight)\n  }\n\n  readonly megapixels = lazy(() => megapixels(this.maxWidth * this.maxHeight))\n\n  outputSize(inputSize: Dimensions): Maybe<OutputSize> {\n    return this.reducer.reduce(\n      this.rotational && isPortrait(inputSize) ? flip(this.max) : this.max,\n      inputSize\n    )\n  }\n\n  resize(outputSize: Dimensions, s: _sharp.Sharp): _sharp.Sharp {\n    // SITS: SHARP TYPINGS ARE CRAP\n    s = (s as any).resize({\n      ...outputSize,\n      fit: this.reducer.fit,\n      withoutEnlargement: true\n    })\n\n    return s\n  }\n\n  toJpeg({\n    path,\n    sh,\n    outputSize\n  }: {\n    path: string\n    sh: _sharp.Sharp\n    outputSize: Dimensions\n  }) {\n    // we don't need to add colorspace or metadata, as sRGB and tag stripping is\n    // on by default.\n\n    const mp = dmegapixels(outputSize)\n    if (mp < 2 || Settings.sharpen.valueOrDefault) {\n      sh = sh.sharpen()\n    }\n    return sh\n      .jpeg({\n        quality: Settings.jpegQuality.valueOrDefault,\n        progressive: Settings.progressive.valueOrDefault\n      })\n      .toFile(path)\n  }\n\n  toString() {\n    return this.name\n  }\n}\n", "import { Dimensions } from \"./Dimensions\"\n\nexport function fitInside(input: Dimensions, max: Dimensions) {\n  const inputAspectRatio = input.width / input.height\n  const maxAspectRatio = max.width / max.height\n\n  if (inputAspectRatio >= maxAspectRatio) {\n    // too wide, height takes aspect ratio into account.\n    const width = Math.min(max.width, input.width)\n    return {\n      width,\n      height: Math.ceil(width / inputAspectRatio)\n    }\n  } else {\n    // too tall, width takes aspect ratio\n    const height = Math.min(max.height, input.height)\n    return { width: Math.ceil(max.height * inputAspectRatio), height }\n  }\n}\n", "import { strEnum, StrEnumKeys } from \"./StrEnum\"\n\n// export const ReducerNames = strEnum(\"fit\", \"fill\", \"sq\")\nexport const ReducerNames = strEnum(\"fit\", \"sq\")\nexport type ReducerName = StrEnumKeys<typeof ReducerNames>\n", "import { ResizeOptions } from \"sharp\"\nimport { Dimensions, dimToS } from \"../../fe/Dimensions\"\nimport { fitInside } from \"../../fe/Fit\"\nimport { ReducerName, ReducerNames } from \"../../fe/ImageReducers\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { strEnum, StrEnumKeys } from \"../../fe/StrEnum\"\nimport { mkLogger } from \"../Logger\"\nimport { ltBoth, lteBoth } from \"./Dimensions\"\n\n// See http://sharp.pixelplumbing.com/en/stable/api-resize/ and\n// https://github.com/lovell/sharp/issues/1135\nexport const SharpFits = strEnum(\n  \"cover\",\n  \"contain\", // this adds background to fill the expected dim, instead of cropping\n  \"fill\",\n  \"inside\",\n  \"outside\"\n)\nexport type SharpFit = StrEnumKeys<typeof SharpFits>\n\nexport type OutputSize = ResizeOptions & Dimensions\n\nexport interface Reducer {\n  name: ReducerName\n  fit: SharpFit\n  reduce(max: Dimensions, input: Dimensions): Maybe<OutputSize>\n}\n\n/**\n * Reduce the smaller dimension and crop the larger dimension to fill the given\n * constraints. As this is the default behavior of sharp, the implementation is\n * the identity function.\n */\nexport namespace Square {\n  const logger = lazy(() => mkLogger(\"Reducers.Square\"))\n  export const name = ReducerNames.sq\n  export const fit = \"cover\"\n  export function reduce(\n    max: Dimensions,\n    input: Dimensions\n  ): Maybe<OutputSize> {\n    const result = !lteBoth(max, input)\n      ? undefined\n      : {\n          ...max,\n          fit: SharpFits.cover\n        }\n\n    return logger().tap({\n      msg: \"reduce()\",\n      result,\n      meta: {\n        max,\n        input\n      }\n    })\n  }\n}\n\n/**\n * Reduce `input` to match `aspectRatio`'s aspect ratio.\n */\nexport function fitInsideToAspectRatio(\n  input: Dimensions,\n  aspectRatio: number\n): Dimensions {\n  return input.width / input.height >= aspectRatio\n    ? {\n        width: Math.floor(input.height * aspectRatio),\n        height: input.height\n      }\n    : {\n        width: input.width,\n        height: Math.floor(input.width / aspectRatio)\n      }\n}\n\n/**\n * Reduce the entire image to fit given constraints\n */\nexport namespace Fit {\n  const logger = lazy(() => mkLogger(\"Reducers.Fit\"))\n\n  export const name = ReducerNames.fit\n  export const fit = \"inside\"\n  export function reduce(\n    max: Dimensions,\n    input: Dimensions\n  ): Maybe<OutputSize> {\n    // if input height < max AND input width < max, max is too big.\n    if (ltBoth(input, max)) {\n      logger().trace(\n        `reduce(): input ${dimToS(input)} is too small for ${dimToS(max)}`\n      )\n      return\n    }\n    return fitInside(input, max)\n  }\n}\n\n// /**\n//  * Reduce the entire image to fit given constraints\n//  */\n// export namespace Fill {\n//   const logger = lazy(() => mkLogger(\"Reducers.Fill\"))\n\n//   export const name = ReducerNames.fill\n//   export const fit = \"inside\"\n//   export function reduce(\n//     max: Dimensions,\n//     input: Dimensions\n//   ): Maybe<OutputSize> {\n//     // if input height < max AND input width < max, max is too big.\n//     if (ltEither(input, max)) {\n//       logger().debug(\"reduce(): input is too small for max\", { input, max })\n//       return\n//     }\n\n//     const inputAspectRatio = input.width / input.height\n//     const maxAspectRatio = max.width / max.height\n\n//     return inputAspectRatio >= maxAspectRatio\n//       ? {\n//           // wider, height takes aspect ratio into account.\n//           width: Math.floor((input.width * max.height) / input.height),\n//           height: max.height\n//         }\n//       : {\n//           // too tall, width takes aspect ratio\n//           width: max.width,\n//           height: Math.floor((input.height * max.width) / input.width)\n//         }\n//   }\n// }\n\n// Ensure all namespaces implement Reducer:\nexport const Reducers: Reducer[] = [Square, Fit]\n", "import { Readable } from \"stream\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { dmegapixels } from \"../../fe/Dimensions\"\nimport { MB } from \"../../fe/Units\"\nimport { thenMap } from \"../async/Promise\"\nimport { execFile } from \"../child/ChildProcess\"\nimport { cleanError } from \"../error/Error\"\nimport { DoNotSendErrorFlag, NonRetriableErrorFlag } from \"../error/ErrorTypes\"\nimport { emitSafely } from \"../event/EmitSafely\"\nimport { readFileType } from \"../fs/FileType\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { PullProgressObserver } from \"../fs/ProgressObservers\"\nimport { dcrawEmuNativePath } from \"../fs/Tools\"\nimport { mkLogger } from \"../Logger\"\nimport { Settings } from \"../settings/Settings\"\nimport { isLibrawMimetype } from \"../tags/Mimetypes\"\nimport { dimensions } from \"./FileDimensions\"\nimport { ImageSize } from \"./ImageSize\"\nimport { dcrawTimeout } from \"./SyncFileTimeout\"\n\nconst logger = mkLogger(\"libraw\")\n\nexport async function librawSupported(src: PosixFile): Promise<boolean> {\n  // THIS SHOULD NOT CALL mimetype(), because we may already be trying to\n  // service a readTags request for src.\n  try {\n    return isLibrawMimetype(\n      await thenMap(readFileType(src.nativePath), ea => ea.mime)\n    )\n  } catch (err) {\n    logger.warn(\"librawSupported(): failed to read filetype\", err)\n    return false\n  }\n}\n\nconst TiffOutput = [\"-T\"]\nconst WriteToStdout = [\"-Z\", \"-\"]\n// -o [0-6]  Output colorspace (raw,sRGB,...):\nconst Colorspace = [\"-o\", \"1\"]\n// disable auto-flip/auto-rotate, because dcraw doesn't always know what to\n// do. Sharp will flip for us:\nconst IgnoreOrientation = [\"-t\", \"0\", \"-j\"]\n\n// this is already time()d by sharpReadable\nexport async function dcraw_emu(src: PosixFile): Promise<Readable> {\n  const start = Date.now()\n\n  const srcDim = await dimensions(src)\n  if (srcDim == null) {\n    return logger.throw(\n      \"Cannot decode RAW \" +\n        src +\n        \": no EXIF dimensions.\" +\n        DoNotSendErrorFlag +\n        NonRetriableErrorFlag\n    )\n  }\n\n  const fitDim = ImageSize.largestFit().outputSize(srcDim)\n\n  const maybeHalfSize: string[] = []\n\n  if (fitDim != null && 4 * dmegapixels(fitDim) < dmegapixels(srcDim)) {\n    logger.debug(\"Large original source: using -h\")\n    maybeHalfSize.push(\"-h\")\n  }\n\n  const cmd = await dcrawEmuNativePath()\n  const args = [\n    ...TiffOutput,\n    ...WriteToStdout,\n    ...Colorspace,\n    ...maybeHalfSize,\n    ...IgnoreOrientation,\n    ...Settings.dcrawEmuArgs.values,\n    src.nativePath\n  ]\n  const timeout = 5 * minuteMs\n  const opts = {\n    encoding: \"buffer\",\n    timeout,\n    maxBuffer: 250 * MB\n  }\n  logger.debug(\"dcraw_emu()\", { cmd, args, opts })\n  const childProc = await execFile(cmd, args, timeout, opts)\n  const onErr = async (err: any) => {\n    if (\n      !(await emitSafely(\n        childProc.stdout!,\n        \"error\",\n        \"Problem from \" + src + \": \" + cleanError(err, src.nativePath)\n      ))\n    ) {\n      logger.error(\"No listeners for error when reading \" + src, err)\n    }\n    childProc.kill(\"SIGINT\")\n  }\n  childProc.on(\"error\", onErr)\n  childProc.stderr!.on(\"data\", onErr)\n\n  // The timeout is very pessimistic:\n  const expectedElapsedMs = dcrawTimeout(await src.size()) / 7\n\n  const obs = new PullProgressObserver(\n    { path: src.nativePath, op: \"Converting raw image\" },\n    expectedElapsedMs,\n    () => Date.now() - start\n  )\n\n  childProc.on(\"close\", () => obs.end())\n\n  return childProc.stdout!\n}\n", "import { Tags } from \"exiftool-vendored\"\nimport sharp = require(\"sharp\")\nimport { retryOnReject } from \"../../fe/AsyncRetry\"\nimport { blank } from \"../../fe/Blank\"\nimport { Dimensions, dmegapixels } from \"../../fe/Dimensions\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { LaterMaybe } from \"../async/Later\"\nimport { firstResolvedDefinedPromise, thenMap } from \"../async/Promise\"\nimport { time } from \"../async/PromiseTimer\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { mkLogger } from \"../Logger\"\nimport { isMac } from \"../Platform\"\nimport { Settings } from \"../settings/Settings\"\nimport { BinaryField } from \"../tags/BinaryTag\"\nimport { extractBinaryTag, readRawTags } from \"../tags/ExifTags\"\nimport { isLibrawMimetype, isSharpMimetype } from \"../tags/Mimetypes\"\nimport { extractRotation } from \"../tags/Orientation\"\nimport { extractSizeInfo } from \"../tags/SizeInfo\"\nimport { sharpThreadsPerJob } from \"../work/MaxCpus\"\nimport { ltBoth } from \"./Dimensions\"\nimport { dimensions } from \"./FileDimensions\"\nimport { isHeifSupported } from \"./Heif\"\nimport { heif2jpeg } from \"./HeifConvert\"\nimport { isHeifMimetype } from \"./HeifFilter\"\nimport { cachedImgFile, readableToFile } from \"./ImgCache\"\nimport { dcraw_emu } from \"./libraw\"\nimport { rawInfo } from \"./RawInfo\"\nimport { sips2jpeg } from \"./sips\"\nimport { extractVideoFrame, isVideoSupported } from \"./Video\"\nimport { isVideoMimeType } from \"./VideoFilter\"\n\nconst logger = mkLogger(\"SharpReadable\")\n\n/**\n * If the file is rotated (in camera or post), there aren't good assumptions to\n * be made regarding the embedded image, so we can't use it.\n *\n * If orientation of the original image is normal, and EXIF thumb aspect ratio\n * agrees with source image, EXIF thumb is valid. In all other jpeg cases, EXIF\n * thumb needs to be ignored. For raw and video, which are much less likely to\n * be edited, if both raw images are landscape, use the orientation.\n */\nexport async function imgFromExif(\n  src: PosixFile,\n  tags: Maybe<Tags>,\n  tag: keyof Tags,\n  minDim: Dimensions\n): PromiseMaybe<PosixFile> {\n  const val = tags?.[tag] as Maybe<BinaryField>\n  if (!(val instanceof BinaryField)) return\n\n  // JPEG can compress ~75%, but will never compress more than 90%:\n  const minBytes = minDim.width * minDim.height * 0.1\n  if (val.binaryDataBytes == null || val.binaryDataBytes < minBytes) {\n    logger.debug(\"imgFromExif(): rejecting (too small) \" + tag, {\n      minBytes,\n      val\n    })\n    return\n  }\n\n  const img = await extractImageForThumbs(src, tag)\n  const dim = await map(img, dimensions)\n\n  // if both dimensions are too small, don't return.\n  return logger.tap({\n    msg: \"imgFromExif()\",\n    meta: {\n      src: src.baseWithGrandparent,\n      tag,\n      dim,\n      minDim\n    },\n    result: dim != null && ltBoth(minDim, dim) ? img : undefined\n  })\n}\n\n// Sharp can cause RSS bloat with high-CPU-count machines. See\n// https://github.com/lovell/sharp/issues/955\nconst setupSharp = lazy(() => {\n  sharp.simd(Settings.enableSIMD.valueOrDefault)\n  sharp.cache(Settings.enableVipsCache.valueOrDefault)\n  sharp.concurrency(sharpThreadsPerJob())\n})\n\n/**\n * @throws if we can't get `src` into a format that sharp can read.\n */\nexport function sharpReadable(\n  src: PosixFile,\n  minDim?: Dimensions,\n  ignoreRotation = false\n): PromiseMaybe<PosixFile> {\n  return time(`img.sharpReadable${src.ext.toUpperCase()}`, () =>\n    _sharpReadable(src, minDim, ignoreRotation)\n  )\n}\n\nasync function _sharpReadable(\n  src: PosixFile,\n  minDim?: Dimensions,\n  ignoreRotation = false\n): PromiseMaybe<PosixFile> {\n  setupSharp()\n  const includeSidecars = !ignoreRotation\n  const t = await readRawTags(src, includeSidecars)\n  const mt = t?.MIMEType\n  if (t == null || blank(mt)) {\n    throw new Error(src + \" is not supported (missing mimetype)\")\n  }\n  if (isHeifMimetype(mt) && !(await isHeifSupported())) {\n    logger.warn(\"sharpReadable(): HEIF file, but heif support is missing\", {\n      src: src.nativePath,\n      mimetype: mt,\n      minDim\n    })\n    return\n  }\n  if (isVideoMimeType(mt) && !(await isVideoSupported())) {\n    logger.warn(\"sharpReadable(): video file, but video support is missing\", {\n      src: src.nativePath,\n      mimetype: mt,\n      minDim\n    })\n    return\n  }\n\n  const strategies: LaterMaybe<PosixFile>[] = []\n  // Don't include metadata thumbnails if:\n\n  // 1. the image is rotated, as metadata thumbnails are inconsistently oriented, or\n  // 2. src is a video, because some thumbnails are cutesy and add filmstrip borders\n  const rot = extractRotation(t)\n  const si = extractSizeInfo(\n    t,\n    rot,\n    isLibrawMimetype(mt) ? await rawInfo(src) : undefined\n  )\n  if (si != null) {\n    const dim = orElse(minDim, {\n      width: si.dimensions.width * 0.95,\n      height: si.dimensions.height * 0.95\n    })\n    const srcMegapixels = dmegapixels(dim)\n    // If this is a smaller original, don't bother with previews, just use the original.\n    if (\n      srcMegapixels > 15 &&\n      (ignoreRotation || rot == null || rot === 0) &&\n      !isVideoMimeType(mt)\n    ) {\n      const tagsToExtract = Settings.embeddedPreviews.valueOrDefault\n      if (minDim != null && dmegapixels(minDim) < 1) {\n        tagsToExtract.unshift(...Settings.embeddedThumbnails.values)\n      }\n      strategies.push(\n        ...tagsToExtract.map(ea => () => imgFromExif(src, t, ea as any, dim))\n      )\n    }\n  }\n\n  if (isHeifMimetype(mt)) {\n    if (isMac) {\n      strategies.push(() => sips2jpeg(src))\n    }\n    strategies.push(() => heif2jpeg(src))\n  }\n\n  if (isSharpMimetype(mt)) {\n    strategies.push(async () => src)\n  }\n\n  if (si != null && isLibrawMimetype(mt)) {\n    strategies.push(() => {\n      logger.info(\"sharpReadable() -> dcraw()\", {\n        src: src.nativePath,\n        minDim\n      })\n      return readableToFile({\n        src,\n        desc: \"dcraw\", // this becomes the basename!\n        suffix: \".tiff\",\n        f: () => dcraw_emu(src)\n      })\n    })\n  }\n\n  if (mt.startsWith(\"video/\")) {\n    strategies.push(() =>\n      retryOnReject(() => extractVideoFrame(src, mt), { maxRetries: 1 })\n    )\n  }\n\n  const errs: Error[] = []\n  const result = await firstResolvedDefinedPromise(strategies, err => {\n    logger.warn(\"strategy failed for \" + src + \": \" + err)\n    errs.push(err)\n  })\n  if (result == null) {\n    throw orElse(errs[0], new Error(\"Cannot read \" + src + \" (\" + mt + \")\"))\n  } else {\n    return result\n  }\n}\n\n/**\n * Returns a file holding the binary stream associated to the given tag.\n * Orientation is copied from the src to the result.\n */\nexport function extractImageForThumbs(\n  src: PosixFile,\n  tag: keyof Tags\n): PromiseMaybe<PosixFile> {\n  const suffix = tag.toLowerCase().endsWith(\"tiff\") ? \".tiff\" : \".jpg\"\n  return thenMap(cachedImgFile(src, tag, suffix), dest =>\n    dest.applyIfEmpty_(async tmp => {\n      try {\n        return await extractBinaryTag(tag, src.nativePath, tmp.nativePath)\n      } catch (err) {\n        logger.warn(\n          \"Failed to extract embedded \" +\n            tag +\n            \" from \" +\n            src.nativePath +\n            \": \" +\n            err\n        )\n        return\n      }\n    })\n  )\n}\n", "import { minuteMs } from \"../../fe/Date\"\nimport { later } from \"../../fe/Delay\"\nimport { errorToS } from \"../../fe/Error\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { opt } from \"../../fe/Opt\"\nimport { resolved } from \"../async/Promise\"\nimport { WrappedError } from \"../error/WrappedError\"\nimport { onClearCache, onFileChanged } from \"../event/EventEmitter\"\nimport { FifoCache } from \"../FifoCache\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { getOrSetByNativePath } from \"../fs/SameFiles\"\nimport { l } from \"../licensing/Licensing\"\nimport { mkLogger } from \"../Logger\"\nimport { joinPatterns } from \"../RegExp\"\nimport { Settings } from \"../settings/Settings\"\nimport { mimetype } from \"../tags/ExifTags\"\nimport { validJpeg } from \"./jpegtran\"\nimport { sharpReadable } from \"./SharpReadable\"\nimport { validVideo } from \"./Video\"\nimport { isVideoMimeType } from \"./VideoFilter\"\nimport sharp = require(\"sharp\")\n\nconst logger = lazy(() => mkLogger(\"ValidFile\"))\n\nconst cache = lazy(() => new FifoCache<Promise<void>>(1024, minuteMs))\n\nlater(() => onClearCache(() => cache.prior()?.clear()))\n\nlater(() =>\n  onFileChanged(path =>\n    opt(path)\n      .forEach(ea => {\n        cache.prior()?.delete(ea)\n      })\n      .orElse(() => {\n        cache.prior()?.clear()\n      })\n  )\n)\n\nconst validationErrorBlocklist = lazy(() =>\n  joinPatterns(Settings.validationErrorBlocklist.values, \"i\")\n)\n\nexport function isIgnorableValidationError(err: any) {\n  return logger().tap({\n    msg: \"isIgnorableValidationError\",\n    result: validationErrorBlocklist().exec(errorToS(err)) == null\n  })\n}\n\n/**\n * @return true if the file is valid, or false if the file is invalid.\n */\nexport async function isValidFile(fileOrPath: PosixFile | string) {\n  return resolved(validFile(fileOrPath))\n}\n\n/**\n * Try to validate the contents of an image or video are not corrupt\n * @throws on invalid file\n */\nexport async function validFile(fileOrPath: PosixFile | string): Promise<void> {\n  if (\n    // if we're \"lite\":\n    (await l()) ||\n    // or it's turned off:\n    (!Settings.validateJpegImages.valueOrDefault &&\n      !Settings.validateVideos.valueOrDefault)\n  ) {\n    logger().debug(\"no validation for \" + fileOrPath, {\n      validateJpegImages: Settings.validateJpegImages.valueOrDefault,\n      validateVideos: Settings.validateVideos.valueOrDefault\n    })\n    return\n  }\n  return getOrSetByNativePath(fileOrPath, _validFile, cache())\n}\n\nasync function _validFile(fileOrPath: PosixFile | string) {\n  const src = PosixFile.for(fileOrPath)\n  // Use the raw tags--if we're missing dimensions or something else, it still\n  // might be valid.\n  try {\n    const mt = await mimetype(src)\n    if (mt == null) {\n      throw new Error(\"Cannot validate, no mimetype\")\n    }\n    if (isVideoMimeType(mt)) {\n      if (Settings.validateVideos.valueOrDefault) {\n        logger().debug(\"validating \" + src)\n        await validVideo(src, mt)\n      }\n    } else if (mt.startsWith(\"image/\")) {\n      if (mt === \"image/jpeg\") {\n        if (Settings.validateJpegImages.valueOrDefault) {\n          return await validJpeg(src)\n        }\n      } else if (Settings.validateRawImages.valueOrDefault) {\n        const sr = await sharpReadable(src)\n        if (sr == null) {\n          throw new Error(\"Cannot read\")\n        }\n        await sharp(sr.nativePath, { failOnError: true }).tiff().toBuffer()\n      }\n    } else {\n      throw new Error(\"Unsupported mimetype, \" + mt)\n    }\n  } catch (cause) {\n    throw new WrappedError({\n      cause,\n      message: \"invalid file \" + src,\n      retriable: false,\n      doNotSend: true, // we expect these to happen.\n      ignorable: true // we expect these to happen.\n    })\n  }\n}\n", "import { compact } from \"../../fe/Array\"\nimport { notBlank } from \"../../fe/Blank\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { later } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { clamp, gt0, round, sigFigs } from \"../../fe/Number\"\nimport { opt } from \"../../fe/Opt\"\nimport { toS } from \"../../fe/toS\"\nimport { thenMapOr, thenOrElse } from \"../async/Promise\"\nimport { StdoutResult, stdoutResult } from \"../child/ChildProcess\"\nimport { onClearCache } from \"../event/EventEmitter\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { mkLogger } from \"../Logger\"\nimport { mapGte0f } from \"../Number\"\nimport { Settings } from \"../settings/Settings\"\nimport { CmdTimeoutMs } from \"../volumes/VolumeTtls\"\nimport { maxCpus } from \"../work/MaxCpus\"\nimport { syncFileTimeoutForFileMs } from \"./SyncFileTimeout\"\nimport { isIgnorableValidationError } from \"./ValidFile\"\n\nconst logger = lazy(() => mkLogger(\"ffmpeg\"))\n\n// If we're doing multiple video file imports, don't hammer the system too hard:\nconst ffmpegThreads = lazy(() => clamp(1, 8, round(maxCpus() / 2)))\n\n// This may be something reasonable, like \"ffmpeg version 3.2.1\", but if it's a\n// nightly build, \"ffmpeg version N-94833-g9d1e98afee\"\nconst versionRe = /ffmpeg version (\\S+)/i\n\nexport const ffmpegVersion = lazy(async () => {\n  try {\n    const result = await stdoutResult(\n      Settings.ffmpegPath.valueOrDefault,\n      [\"-version\"],\n      {\n        timeout: CmdTimeoutMs,\n        ignoreStderr: true,\n        isIgnorableError: () => true\n      }\n    )\n    const version: Maybe<string> = versionRe.exec(result.result)?.[1]\n    logger().info(\"ffmpegVersion\", {\n      version,\n      code: result.code,\n      stdout: result.result.split(\"\\n\", 1)[0]\n    })\n    return result.code === 0 && notBlank(version) ? version : undefined\n  } catch (err) {\n    return\n  }\n})\n\nexport const ffmpegVersionDescription = lazy(() =>\n  thenMapOr(\n    ffmpegVersion(),\n    ver => \"version \" + ver,\n    () => \"(not found)\"\n  )\n)\nlater(() => onClearCache(() => ffmpegVersion.unset()))\n\nexport async function checkFFmpegVersion() {\n  return thenOrElse(ffmpegVersion.prior(), () => ffmpegVersion.refresh())\n}\n\nexport async function isFFmpegSupported() {\n  // TODO: what versions do we *actually* require?\n  return (await ffmpegVersion()) != null\n}\n\n// Example errors:\n\n// [h264 @ 0x5642cf833640] left block unavailable for requested intra mode\n\n// [h264 @ 0x5642cf833640] error while decoding MB 0 16, bytestream 99553\n\n// [mov,mp4,m4a,3gp,3g2,mj2 @ 0x556e03cfb8c0] stream 0, offset 0x184ef: partial file\n\n// Invalid data found when processing input\n\n// Nothing was written into output file 0 (pipe:), because at least one of its streams received no packets.\n\n// Error: [mov,mp4,m4a,3gp,3g2,mj2 @ 0x560b7c7f59a0] Referenced QT chapter track not found\n\n/*\n-vframes number (output) Set the number of video frames to output. This is an\nalias for \"-frames:v\".\n\n-f fmt (input/output) Force input or output file format. The format is normally\nauto detected for input files and guessed from the file extension for output\nfiles, so this option is not needed in most cases.\n\npipe:[number] number is the number corresponding to the file descriptor of the\npipe (e.g. 0 for stdin, 1 for stdout, 2 for stderr). If number is not specified,\nby default the stdout file descriptor will be used for writing, stdin for\nreading.\n\n-ss position (input/output) When used as an input option (before -i), seeks in\nthis input file to position. Note that in most formats it is not possible to\nseek exactly, so ffmpeg will seek to the closest seek point before position.\nWhen transcoding and -accurate_seek is enabled (the default), this extra segment\nbetween the seek point and position will be decoded and discarded. When doing\nstream copy or when -noaccurate_seek is used, it will be preserved.\n\nWhen used as an output option (before an output url), decodes but discards input\nuntil the timestamps reach position.\n\nposition must be a time duration specification, see (ffmpeg-utils)the Time\nduration section in the ffmpeg-utils(1) manual.\n*/\nexport async function ffmpegFrame(args: {\n  src: PosixFile\n  dest: PosixFile\n  startAtSec?: number\n  width?: number\n  height?: number\n}) {\n  if ((await args.dest.exists()) && (await args.dest.isEmpty())) {\n    await args.dest.unlink()\n  }\n\n  return stdoutResult(\n    Settings.ffmpegPath.valueOrDefault,\n    compact([\n      \"-loglevel\",\n      \"error\",\n      \"-i\",\n      args.src.nativePath,\n      ...(mapGte0f(args.startAtSec, ea => [\"-ss\", ea.toFixed(1)]) ?? []),\n      \"-vframes\",\n      \"1\",\n      // This didn't seem to really help much, and made it slower.\n      // \"-q:v\", // require quality to be <= 2 (range between 1 and 31)\n      // \"2\",\n      // This seems to lead to distorted outputs?\n      // ...(args.width != null && args.height != null\n      //   ? [\"-s\", `${round(args.width)}x${round(args.height)}`]\n      //   : []),\n      \"-f\",\n      \"singlejpeg\",\n      \"-y\", // overwrite output files\n      args.dest.nativePath\n    ]),\n    {\n      timeout: minuteMs, // extracting a single frame should take less than a second.\n      isIgnorableError: isIgnorableValidationError\n    }\n  )\n}\n\nexport async function ffmpegTranscode(args: {\n  src: PosixFile\n  dest: PosixFile\n  width: Maybe<number>\n  height: Maybe<number>\n  videoBitrateKbps?: number\n  timeoutMs: number\n}) {\n  // https://trac.ffmpeg.org/wiki/Limiting%20the%20output%20bitrate\n  const bitrate = opt(args.videoBitrateKbps)\n    .filter(gt0)\n    .map(ea => sigFigs(ea, 2))\n    .map(m => [\n      \"-b:v\",\n      m + \"k\",\n      \"-maxrate\",\n      m + \"k\",\n      \"-bufsize\",\n      sigFigs(m / 2, 2) + \"k\"\n    ])\n    .getOrElse(() => [])\n\n  return stdoutResult(\n    Settings.ffmpegPath.valueOrDefault,\n    [\n      \"-loglevel\",\n      \"error\",\n      \"-threads\",\n      toS(ffmpegThreads()),\n      \"-i\",\n      args.src.nativePath,\n      ...Settings.ffmpegTranscodeArgs.values,\n      ...bitrate,\n\n      args.dest.nativePath\n    ],\n    {\n      timeout: args.timeoutMs,\n      isIgnorableError: isIgnorableValidationError\n    }\n  )\n}\n\n/**\n * @throws on errors\n */\nexport async function ffmpegValidVideo(src: PosixFile): Promise<StdoutResult> {\n  return logger().tap({\n    msg: \"ffmpegValidVideo\",\n    meta: { src: src.nativePath },\n    result: await stdoutResult(\n      Settings.ffmpegPath.valueOrDefault,\n      // `-v error` may also complains about minor encoding issues, so we have to\n      // pass the error messages through that RegExp.\n      [\n        \"-v\",\n        \"error\",\n        \"-nostats\",\n        \"-threads\",\n        toS(ffmpegThreads()),\n        \"-i\",\n        src.nativePath,\n        \"-f\",\n        \"null\",\n        \"-\"\n      ],\n      {\n        timeout: orElse(await syncFileTimeoutForFileMs(src), 2 * minuteMs),\n        isIgnorableError: isIgnorableValidationError,\n        ignoreExitCode: true,\n        quiet: false // < raise the error\n      }\n    )\n  })\n}\n", "import { join } from \"path\"\nimport { compact } from \"../../fe/Array\"\nimport { blank, mapNotBlank, notBlank } from \"../../fe/Blank\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { later } from \"../../fe/Delay\"\nimport { stringify } from \"../../fe/JSON\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { denull } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { gt0 } from \"../../fe/Number\"\nimport { tap } from \"../../fe/Object\"\nimport { opt } from \"../../fe/Opt\"\nimport { thenMap, thenMapOr, thenOrElse } from \"../async/Promise\"\nimport { stdoutResult } from \"../child/ChildProcess\"\nimport { getEnv } from \"../Env\"\nimport { NonRetriableErrorFlag } from \"../error/ErrorTypes\"\nimport { onClearCache } from \"../event/EventEmitter\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { mkLogger } from \"../Logger\"\nimport { mapGt0 } from \"../Number\"\nimport { isArm, isMac, isWin } from \"../Platform\"\nimport { PowerShell, pwshQuote } from \"../pwsh/PowerShell\"\nimport { Settings } from \"../settings/Settings\"\nimport { stripPrefix } from \"../String\"\nimport { CmdTimeoutMs } from \"../volumes/VolumeTtls\"\n\nconst logger = lazy(() => mkLogger(\"vlc\"))\n\nexport function vlcVersionDescription() {\n  return thenMapOr(\n    vlcInfo().catch(() => undefined),\n    vlc => \"version \" + vlc.version,\n    () => \"(not found)\"\n  )\n}\n\nconst VersionRe = /VLC (?:version|media player) ([0-9.]+)/i\n\nexport interface VLCInfo {\n  path?: string\n  version?: string\n}\n\n// See: https://superuser.com/questions/947116/how-do-i-use-vlc-command-line-in-windows-batch-line-without-showing-gui\n\nconst DefaultVlcArgs = [\n  \"--intf=dummy\", // don't render the interface\n  \"--vout=dummy\", // don't render the video\n  \"--aout=dummy\", // don't render the audio\n  \"--quiet\"\n]\n\nexport const vlcInfo = lazy<PromiseMaybe<VLCInfo>>(() => _vlcInfo())\n\nlater(() => onClearCache(() => vlcInfo.unset()))\n\nexport async function checkVlcInfo() {\n  return thenOrElse(vlcInfo.prior(), () => vlcInfo.refresh())\n}\n\nexport async function isVlcSupported() {\n  // 20200320: The raspbian/ARM port of VLC doesn't work correctly.\n  return (\n    !isArm &&\n    (await thenMapOr(\n      vlcInfo(),\n      ea => ea.version != null,\n      () => false\n    ))\n  )\n}\n\nexport function vlcPath() {\n  return thenMap(vlcInfo(), ea => (ea.version == null ? undefined : ea.path))\n}\n\nasync function versionPosix(path: string): PromiseMaybe<string> {\n  return thenMap(\n    stdoutResult(\n      path,\n      // VLC on linux and mac don't use `--dummy-quiet`.\n      [...DefaultVlcArgs, \"--version\"],\n      {\n        timeout: CmdTimeoutMs,\n        // VLC burps \"VLC media player 3.0.6 Vetinari (revision\n        // 3.0.6-0-g5803e85)\" to stderr. SRSLY WTH. STDERR.\n        ignoreStderr: true,\n        quiet: true,\n        isIgnorableError: () => true\n      }\n    ),\n    result =>\n      opt(result.result)\n        .filter(notBlank)\n        .map(ea => ea.trim())\n        .flatMap(ea => VersionRe.exec(ea))\n        .flatMap(ea => ea[1])\n        .get()\n  )\n}\n\nfunction versionWin(path: string): PromiseMaybe<string> {\n  // Windows VLC --version pops up a terminal no matter what options you give\n  // it. YAY\n  return thenMap(\n    PowerShell.instance()\n      .execute(\n        `(Get-Item -path ${pwshQuote(path)}).VersionInfo.FileVersion`,\n        ea => ea\n      )\n      .catch(err => {\n        logger().warn(\"Failed to run vlcInfoWin: \" + path + \": \" + err)\n        return undefined\n      }),\n    result => denull(result.trim())\n  )\n}\n\nasync function _vlcInfo(): PromiseMaybe<VLCInfo> {\n  const paths: (string | PosixFile)[] = []\n  function add(...arr: string[]) {\n    paths.push(PosixFile.for(join(...arr)))\n  }\n  if (!isWin || Settings.vlcPath.hasValue()) {\n    // only add the default path (which is just \"vlc\") on mac and linux, as\n    // powershell doesn't handle PATH resolution:\n    paths.push(Settings.vlcPath.valueOrDefault)\n  }\n  if (isMac) {\n    const subpath = \"/Applications/VLC.app/Contents/MacOS/VLC\"\n    mapNotBlank(getEnv(\"HOME\"), ea => add(ea + subpath))\n    add(subpath)\n  }\n  if (isWin) {\n    const subpath = [\"VideoLAN\", \"VLC\", \"vlc.exe\"]\n    mapNotBlank(getEnv(\"LOCALAPPDATA\"), ea => {\n      add(ea, \"Apps\", ...subpath)\n    })\n    mapNotBlank(getEnv(\"ProgramFiles\"), ea => {\n      add(ea, ...subpath)\n    })\n    mapNotBlank(getEnv(\"ProgramFiles(x86)\"), ea => {\n      add(ea, ...subpath)\n    })\n  }\n\n  for (const pathOrFile of paths) {\n    try {\n      if (\n        pathOrFile instanceof PosixFile &&\n        (await pathOrFile.clear().notExists())\n      ) {\n        continue\n      }\n      const path = pathOrFile.toString()\n      const version = await (isWin ? versionWin(path) : versionPosix(path))\n      if (blank(version)) {\n        logger().info(\"vlcInfo(): no VLC version found for \" + pathOrFile)\n        continue\n      } else {\n        return tap({ path, version }, result =>\n          logger().info(\"vlcInfo()\", result)\n        )\n      }\n    } catch (err) {\n      logger().warn(\"vlcInfo(): err:\" + err, { path: pathOrFile })\n    }\n  }\n  return\n}\n\n// https://wiki.videolan.org/How_to_create_thumbnails/\nexport async function vlcFrame(args: {\n  src: PosixFile\n  dest: PosixFile\n  startAtSec?: number\n  width?: number\n  height?: number\n}) {\n  const vlc = await vlcPath()\n  if (blank(vlc)) {\n    return logger().throw(\"vlcFrame(): empty vlcPath\", {\n      ...args,\n      ignorable: true\n    })\n  }\n  const format = stripPrefix(args.dest.ext, \".\").toLowerCase()\n  if (![\"png\", \"jpg\"].includes(format)) {\n    return logger().throw(\n      \"vlcFrame(): Invalid destination extension\" + NonRetriableErrorFlag,\n      { format, args }\n    )\n  }\n  const startTime = args.startAtSec ?? 0\n  const stopTime = startTime + 1\n  const result = await stdoutResult(\n    vlc,\n    compact([\n      // BEWARE! VLC NEEDS THIS ORDER OF ARGUMENTS TO WORK! SRSLYWTF\n      ...DefaultVlcArgs,\n      \"--avcodec-hw=none\", // https://forum.videolan.org/viewtopic.php?f=13&t=129067&p=486082&hilit=snapshot#p433025\n      \"--video-filter=scene\", // enable post-processing to make image quality better\n      \"--scene-format=\" + format,\n      \"--scene-replace\",\n      // Ratio of images to record. 3 means that one image out of three is\n      // recorded. This is ridiculously large so we only get one frame:\n      \"--scene-ratio=500\",\n\n      // VLC doesn't quite do dimensions correctly, but as of 20191205, it's\n      // better than what we have otherwise, so this is commented out.\n      // map(args.width, ea => \"--scene-width=\" + ea),\n      // map(args.height, ea => \"--scene-height=\" + ea),\n\n      \"--scene-path=\" + args.dest.dir,\n      \"--scene-prefix=\" + args.dest.name,\n      \"--start-time=\" + startTime.toFixed(1), // this makes the poster image match the start of the video.\n      \"--stop-time=\" + stopTime.toFixed(1),\n      args.src.nativePath,\n      \"vlc://quit\"\n    ]),\n    {\n      timeout: minuteMs,\n      ignoreStderr: true\n    }\n  )\n  // console.log(\"vlcFrame()\", { result })\n  // if (gt0(result.pid)) {\n  //   if (!(await until(() => pidNotExists(result.pid), 7 * secondMs))) {\n  //     await kill(result.pid, true)\n  //   }\n  // }\n  args.dest.clear()\n  if (gt0(result.code)) {\n    throw new Error(\"vlc failed: \" + stringify(result))\n  }\n  return result\n}\n\nexport async function vlcTranscode(args: {\n  src: PosixFile\n  dest: PosixFile\n  width: Maybe<number>\n  height: Maybe<number>\n  videoBitrateKbps?: number\n  timeoutMs: number\n}) {\n  const vlc = await vlcPath()\n  if (blank(vlc)) {\n    throw new Error(\n      \"vlc.transcode(): VLC is not installed, cannot transcode \" + args.src\n    )\n  }\n\n  // Enable debug logging within VLC, restart, then run a convert job. These\n  // options will be in the log.\n\n  // mp4 is the most compatible format, according to https://en.wikipedia.org/wiki/HTML5_video\n\n  // AAC encoding seems to be required for audio playback across different\n  // source video formats.\n\n  // $ ffmpeg -hide_banner -f lavfi -i nullsrc -c:v libx264 -preset faster -f mp4 -\n\n  // options: cabac=1 ref=2 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=4 psy=1\n  // psy_rd=1.00:0.00 mixed_ref=0 me_range=16 chroma_me=1 trellis=1 8x8dct=1\n  // cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=0 threads=6\n  // lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0\n  // bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1\n  // b_bias=0 direct=1 weightb=1 open_gop=0 weightp=1 keyint=250 keyint_min=25\n  // scenecut=40 intra_refresh=0 rc_lookahead=20 rc=crf mbtree=1 crf=23.0\n  // qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n\n  // mrm@i3:~$ ffmpeg -hide_banner -f lavfi -i nullsrc -c:v libx264 -preset slow\n  // -f mp4 -\n\n  // options: cabac=1 ref=5 deblock=1:0:0 analyse=0x3:0x113 me=umh subme=8 psy=1\n  // psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1\n  // cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=6\n  // lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0\n  // bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=2\n  // b_bias=0 direct=3 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25\n  // scenecut=40 intra_refresh=0 rc_lookahead=50 rc=crf mbtree=1 crf=23.0\n  // qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n\n  const tcOpts = compact([\n    \"vcodec=h264\",\n    mapGt0(args.videoBitrateKbps, ea => \"vb=\" + ea),\n    mapGt0(args.width, w => \"width=\" + Math.floor(w)),\n    mapGt0(args.height, h => \"height=\" + Math.floor(h)),\n    // These are the \"faster\" options that differ from the \"slower\" presets:\n    \"venc=x264{ref=2:me=hex:mixed_ref=0:chroma_qp_offset=0:b_adapt=1:direct=1:weightp=1:rc_lookahead=20}\",\n    // https://support.plex.tv/articles/200250347-transcoder/\n    // \"faster encoding\": (basically the same speed as hq)\n    // \"venc=x264{subme=0:me_range=4:rc_lookahead=10:me=dia:no_chroma_me:8x8dct=0:partitions=none}\",\n    // \"hq encoding\":\n    // \"venc=x264{subme=0:me_range=4:rc_lookahead=10:me=hex:8x8dct=0:partitions=none}\",\n    // \"make my cpu hurt\":\n    // \"venc=x264{subme=0:me_range=4:rc_lookahead=10:me=hex:8x8dct=1}\",\n    \"acodec=mp4a\",\n    \"ab=128\",\n    \"channels=2\",\n    \"samplerate=44100\",\n    \"scodec=none\",\n    \"deinterlace\"\n  ]).join(\",\")\n\n  const stdOpts = [\n    \"access=file{overwrite}\",\n    \"mux=mp4\",\n    \"dst=\" + args.dest.base\n  ].join(\",\")\n\n  return stdoutResult(\n    vlc,\n    [\n      ...DefaultVlcArgs,\n      \"--no-repeat\",\n      \"--no-loop\",\n      args.src.fileuri(),\n      `--sout=#transcode{${tcOpts}}:standard{${stdOpts}}`,\n      \"vlc://quit\"\n    ],\n    {\n      cwd: args.dest.dir,\n      timeout: args.timeoutMs,\n      ignoreStderr: true\n    }\n  )\n}\n", "import { Tags } from \"exiftool-vendored\"\nimport { Info } from \"luxon\"\nimport { compact, compactBlanks, sortBy } from \"../../fe/Array\"\nimport { secondMs } from \"../../fe/Date\"\nimport { stringify } from \"../../fe/JSON\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { toA } from \"../../fe/toA\"\nimport { toS } from \"../../fe/toS\"\nimport { anyDefined, firstNonEmptyThunk, greatestBy, max } from \"../Array\"\nimport { firstDefinedLater } from \"../async/Later\"\nimport { thenMap } from \"../async/Promise\"\nimport {\n  Dated,\n  datedToISO,\n  datedToLocal,\n  datedToMillis,\n  datedToOffsetMinutes,\n  datedToPrecisionMs,\n  extractDateFromPath,\n  hasSeconds,\n  hasTime,\n  hasZone,\n  mapValidDate,\n  parseDated,\n  setZone,\n  toExifDateTime,\n  validDate\n} from \"../date/FuzzyDate\"\nimport { containedByNativePath } from \"../fs/Path\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { ifLog } from \"../log/LogFilter\"\nimport { LogLevels } from \"../log/LogLevel\"\nimport { mkLogger } from \"../Logger\"\nimport { firstThunk } from \"../Object\"\nimport { Settings } from \"../settings/Settings\"\nimport {\n  bname,\n  extractStatBname,\n  inferCapturedAtFromSiblings,\n  nearestSiblingTzOffset\n} from \"./TagInference\"\n\nconst logger = lazy(() => mkLogger(\"CapturedAt\"))\n\nexport function capturedAtSrcFromTags(src: string): boolean {\n  return toS(src).toLowerCase().startsWith(\"tags\")\n}\n\nexport class CapturedAt {\n  constructor(\n    readonly nativePath: string,\n    readonly date: Dated,\n    readonly src: string,\n    readonly mtime: Date,\n    readonly precisionMs?: number\n  ) {}\n\n  spread(p: Partial<CapturedAt>): CapturedAt {\n    const o = { ...this, ...p }\n    return new CapturedAt(o.nativePath, o.date, o.src, o.mtime)\n  }\n\n  readonly toISOString = lazy(() => datedToISO(this.date))\n\n  toLocal() {\n    // TODO: SITS: EFFICIENCY: cache DateTime instead of ISO\n    return datedToLocal(this.date)\n  }\n\n  toOffset() {\n    return datedToOffsetMinutes(this.date)\n  }\n\n  get isFromTags() {\n    return capturedAtSrcFromTags(this.src)\n  }\n\n  toPrecisionMs() {\n    return orElse(this.precisionMs, () => datedToPrecisionMs(this.date))\n  }\n\n  toString() {\n    return stringify({\n      nativePath: this.nativePath,\n      date: this.toISOString(),\n      src: this.src,\n      mtime: this.mtime\n    })\n  }\n\n  hasTz() {\n    return hasZone(this.date)\n  }\n\n  hasTime() {\n    return hasTime(this.date)\n  }\n}\n\nexport function bestCapturedAt(arr: CapturedAt[]): CapturedAt {\n  // Always take the value from the newest file (in case the date was updated).\n  // Prefer tags, then paths, then stat.\n  const byMtime = sortBy(arr, ea => -ea.mtime.getTime())\n  return firstThunk(\n    () => byMtime.find(ea => ea.src.startsWith(\"tags\")),\n    () => byMtime.find(ea => ea.src.startsWith(\"bname+stat\")),\n    () => byMtime.find(ea => ea.src.startsWith(\"bname\")),\n    () => byMtime.find(ea => ea.src.startsWith(\"siblings\")),\n    () => byMtime.find(ea => ea.src.startsWith(\"path\")),\n    () => arr[0]\n  )!\n}\n\nexport function capturedAtTags(arr: CapturedAt[]): CapturedAt[] {\n  arr = sortBy(toA(arr), ea => -ea.mtime)\n  return firstNonEmptyThunk(\n    () => arr.filter(ea => ea.src.startsWith(\"tags\")),\n    () => arr.filter(ea => ea.src.startsWith(\"bname+stat\")),\n    () => arr.filter(ea => ea.src.startsWith(\"bname\")),\n    () => arr.filter(ea => ea.src.startsWith(\"siblings\")),\n    () => arr.filter(ea => ea.src.startsWith(\"path\")),\n    () => arr.filter(ea => ea.src.startsWith(\"stat\")).slice(1, 1),\n    () => []\n  )!\n}\n\nexport function hasSubSecCapturedAt(t: Maybe<Tags>): boolean {\n  return (\n    t != null &&\n    anyDefined([\n      t.SubSecTime,\n      t.SubSecTimeDigitized,\n      t.SubSecTimeOriginal,\n      t.SubSecCreateDate,\n      t.SubSecDateTimeOriginal\n    ])\n  )\n}\n\nasync function addTimeZone(\n  f: PosixFile,\n  tags: Maybe<Tags>,\n  d: Maybe<Dated> | PromiseMaybe<Dated>,\n  skipInference: boolean\n): PromiseMaybe<Dated> {\n  const dated = await d\n  if (!validDate(dated)) return\n  if (hasZone(dated)) return dated\n\n  if (tags != null && tags.tz != null && Info.isValidIANAZone(tags.tz)) {\n    return setZone(dated, tags.tz)\n  } else {\n    return skipInference ? dated : addTzFromSibs(f, dated)\n  }\n}\n\nexport async function addTzFromSibs(\n  f: PosixFile,\n  d: Maybe<Dated>\n): PromiseMaybe<Dated> {\n  if (!validDate(d)) return\n  if (hasZone(d)) return d\n  const sibTz = await nearestSiblingTzOffset(f)\n  if (sibTz != null) {\n    const wtz = toExifDateTime(d, sibTz)\n    if (validDate(wtz)) return wtz\n  }\n  return d\n}\n\nfunction cannotUseDateFromPath(f: PosixFile, skipInference: boolean): boolean {\n  return (\n    f == null ||\n    skipInference ||\n    !Settings.usePathsToInferDates.valueOrDefault ||\n    (!Settings.useLibraryPathsToInferDates.valueOrDefault &&\n      containedByNativePath(f.nativePath, Settings.libraryPath.value))\n  )\n}\n\n/**\n * @param skipInference if the file is a temporary scratch file (like a screenshot from a\n * video or a raw image capture), and more expensive extraction heuristics\n * should be skipped.\n */\n// no deps on posixfile because posixfile depends on tag parsing\nexport async function extractCapturedAt(\n  f: PosixFile,\n  tags: Maybe<Tags>,\n  skipInference: boolean\n): Promise<Maybe<CapturedAt>> {\n  const mtime = await f.mtime()\n\n  const from = async (\n    src: string,\n    result:\n      | Maybe<{ src: string; date: Dated; precisionMs?: number }>\n      | PromiseMaybe<{ src: string; date: Dated; precisionMs?: number }>\n  ) => {\n    return thenMap(result, r =>\n      thenMap(\n        addTimeZone(f, tags, r.date, skipInference),\n        d =>\n          new CapturedAt(\n            f.nativePath,\n            d,\n            compactBlanks([src, r.src]).join(\":\"),\n            mtime!,\n            r.precisionMs\n          )\n      )\n    )\n  }\n\n  return firstDefinedLater<CapturedAt>(\n    () => from(\"tags\", capturedAtFromTags(tags)),\n    () => from(\"bname+stat\", extractStatBname(f)),\n    () =>\n      skipInference\n        ? undefined\n        : from(\"siblings\", inferCapturedAtFromSiblings(f)),\n    () =>\n      skipInference || !Settings.usePathsToInferDates.valueOrDefault\n        ? undefined\n        : from(\n            \"bname\",\n            map(parseDated(bname(f)), date => ({\n              date,\n              src: \"\", // it'll be \"bname\"\n              precisionMs: max([datedToPrecisionMs(date), secondMs])\n            }))\n          ),\n    () =>\n      cannotUseDateFromPath(f, skipInference)\n        ? undefined\n        : from(\n            \"path\",\n            map(extractDateFromPath(f.pathnamesWithoutDrive), date => ({\n              src: \"\",\n              date\n            }))\n          ),\n    () =>\n      !Settings.useStatToInferDates.valueOrDefault\n        ? undefined\n        : from(\n            \"stat\",\n            thenMap(f.minStatDate(), date => ({ src: \"\", date }))\n          )\n  )\n}\n\nconst CapturedAtTags = [\n  // By the specification, DateTimeOriginal should be the time of the\n  // shutter actuation, and CreateDate should be the time that the file\n  // was written to the memory card (but not all mfrs follow the spec)\n  // http://u88.n24.queensu.ca/exiftool/forum/index.php?topic=2568.0\n\n  // <https://exiftool.org/TagNames/EXIF.html>\n\n  // First \"*original*\"\n  \"SubSecDateTimeOriginal\", // (fractional seconds for DateTimeOriginal)\n  \"SubSecCreateDate\",\n  \"SubSecTimeDigitized\", // (fractional seconds for CreateDate)\n  \"SubSecMediaCreateDate\",\n\n  \"DateTimeOriginal\", // (date/time when original image was taken)\n\n  // Then \"*create*\"\n  \"OriginalCreateDateTime\",\n\n  \"CreateDate\", // (called DateTimeDigitized by the EXIF spec)\n  \"DateTimeCreated\",\n  \"DateCreated\", // XMP tag\n  \"DateTimeDigitized\",\n  \"MediaCreateDate\",\n\n  \"DateTime\",\n\n  // Then *modify*\n  \"SubSecTime\", // (fractional seconds for ModifyDate)\n  \"ModifyDate\", // (called DateTime by the EXIF spec)\n\n  // Lightroom:\n  // \"HistoryWhen\", // This is when history records happen, NOT when the file was captured!\n\n  // Google Takeout (not really reliable, though)\n  \"photoTakenTime\"\n\n  // This is the Google Photos upload time. That's not something we want, so\n  // it's commented out. DON'T ADD IT BACK, FUTURE ME!\n  // \"creationTime\"\n]\n\nfunction extractDate(\n  t: Tags,\n  src: keyof Tags\n): Maybe<{ date: Dated; src: string }> {\n  return mapValidDate(t[src] as any, date => ({\n    src,\n    date\n  }))\n}\n\nexport function capturedAtFromTags(\n  maybeTags: Maybe<Tags>\n): Maybe<{ date: Dated; src: string }> {\n  if (maybeTags == null) return\n\n  const rawArr = compact(\n    CapturedAtTags.map(src => ({\n      date: maybeTags[src],\n      src,\n      ts: map(datedToMillis(maybeTags[src]), ea => Math.floor(ea / 1000))\n    }))\n  )\n\n  const validArr = rawArr.filter(ea => validDate(ea.date) && ea.ts != null)\n\n  ifLog(LogLevels.debug, () => {\n    logger().debug(\"capturedAtFromTags()\", { rawArr, validArr })\n  })\n  // Let's look at all these tags, and get the earliest, highest-resolution\n  // time. We ! the flags because false < true.\n\n  return firstThunk<{ date: Dated; src: string }>(\n    () =>\n      greatestBy(validArr, ea =>\n        map(datedToLocal(ea.ts!), lts => [\n          -Math.floor(lts / 1e8),\n          hasTime(ea.date) ? 1 : 0,\n          hasSeconds(ea.date) ? 1 : 0,\n          hasZone(ea.date) ? 1 : 0,\n          -CapturedAtTags.indexOf(ea.src) // for determinism\n        ])\n      ),\n\n    // This definitionally doesn't have the correct TZ:\n    () => extractDate(maybeTags, \"DateTimeUTC\"),\n\n    // Honestly we'd rather use any metadata to fetch the captured-at\n    // instead of the heuristics we use as a backstop, so n though GPS\n    // acquisition time isn't really the captured-at, it's probably within a\n    // minute, which is close enough:\n    () => extractDate(maybeTags, \"GPSDateTime\")\n  )\n}\n", "import { ExifDate, ExifDateTime, ExifTime } from \"exiftool-vendored\"\nimport { DateObject, DateTime, Info, Zone } from \"luxon\"\nimport { compact, isEmpty, sort, startsWith, uniq } from \"../../fe/Array\"\nimport { blank, mapNotBlank, notBlank } from \"../../fe/Blank\"\nimport { dayMs, hourMs } from \"../../fe/Date\"\nimport { later } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { allDefined, map, mapOr, orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport {\n  clamp,\n  gt0,\n  isNumber,\n  lte,\n  mapNumeric,\n  round,\n  times,\n  toFloat,\n  toInt\n} from \"../../fe/Number\"\nimport { opt } from \"../../fe/Opt\"\nimport { gt, gte } from \"../../fe/Primitive\"\nimport { toS } from \"../../fe/toS\"\nimport { anyNotDefined, first } from \"../Array\"\nimport { onClearCache } from \"../event/EventEmitter\"\nimport { mkLogger } from \"../Logger\"\nimport { within } from \"../Number\"\nimport { firstThunk, firstTrueThunk } from \"../Object\"\nimport { Settings } from \"../settings/Settings\"\nimport { hasAnyIgnoreCase, isString, leftPad, pad2 } from \"../String\"\nimport { zoneSeemsLegit } from \"../Timezone\"\nimport { millisToLocalSuffix, tsToLocal } from \"./Date\"\nimport { DateInterval } from \"./DateInterval\"\n\nfunction pad(n?: number, minLength: number = 2): string {\n  return n == null ? \"\" : leftPad(n, minLength, \"0\")\n}\n\nexport function validDate(d: any): d is Dated {\n  if (d == null || typeof d === \"string\" || d === 0) return false\n  const ts = datedToMillis(d)\n  if (ts == null || ts === 0) return false\n  if (!validYMD(getYear(d), getMonth(d), getDay(d))) return false\n  return hasTime(d)\n    ? mapOr(\n        toDateTime(d),\n        ea => ea.isValid,\n        () => false\n      )\n    : true\n}\n\nexport function mapValidDate<D extends Dated, T>(\n  obj: Maybe<D>,\n  f: (date: D) => T\n): Maybe<T> {\n  return validDate(obj) ? f(obj) : undefined\n}\n\nconst minYear = lazy(() => Settings.minValidYear.valueOrDefault, hourMs)\nconst maxYear = lazy(() => new Date(Date.now() + dayMs).getFullYear(), hourMs)\nconst maxMonth = lazy(() => new Date(Date.now() + dayMs).getMonth() + 1, hourMs)\n\nlater(() =>\n  onClearCache(() => {\n    minYear.unset()\n    maxYear.unset()\n    maxMonth.unset()\n  })\n)\n\nexport function validYear(year: Maybe<number>) {\n  return within(minYear(), maxYear(), year)\n}\n\nexport function validMonth(month: Maybe<number>, year?: number) {\n  return gte(year, maxYear()) && gt(month, maxMonth())\n    ? false\n    : within(1, 12, month)\n}\n\n/**\n * @return true iff the given month and day values are valid for the given year\n */\nexport function validDay(\n  year: Maybe<number>,\n  month: Maybe<number>,\n  day: Maybe<number>\n) {\n  // If Date doesn't change the day, that month and day exist for that year.\n  return day != null && DateTime.fromObject({ year, month, day }).isValid\n}\n\nexport function validYMD(year?: number, month?: number, day?: number) {\n  return (\n    validYear(year) &&\n    (month == null ||\n      (validMonth(month, year) && (day == null || validDay(year, month, day))))\n  )\n}\n\nexport class FuzzyDate {\n  constructor(\n    readonly year: number,\n    readonly month?: number,\n    readonly day?: number\n  ) {}\n\n  static for(year: number, month?: number, day?: number): Maybe<FuzzyDate> {\n    return validYMD(year, month, day!)\n      ? new FuzzyDate(year, month, day)\n      : undefined\n  }\n\n  static localToday() {\n    return toFuzzyDate(new Date())!\n  }\n\n  toString() {\n    return compact([this.year, this.month, this.day])\n      .map(ea => pad(ea))\n      .join(\"-\")\n  }\n\n  toISOString() {\n    return this.toString()\n  }\n\n  toDateTime() {\n    return DateTime.fromObject(this)\n  }\n}\n\nexport interface ToFuzzyDate {\n  (s: string): Maybe<FuzzyDate>\n}\n\nclass Parser {\n  constructor(\n    readonly monthsToMonth: Map<string, number>,\n    readonly re: RegExp,\n    readonly yearIndex: number,\n    readonly monthIndex?: number,\n    readonly dayIndex?: number\n  ) {}\n  apply(input: string): FuzzyDate | undefined {\n    const ymd = this.re.exec(input)\n    if (ymd != null) {\n      const year = parseInt(ymd[this.yearIndex], 10)\n      const month = this.month(ymd)\n      const day =\n        this.dayIndex == null ? undefined : parseInt(ymd[this.dayIndex], 10)\n      return FuzzyDate.for(year, month, day)\n    } else {\n      return\n    }\n  }\n\n  private month(result: RegExpExecArray): Maybe<number> {\n    if (this.monthIndex == null) {\n      return\n    }\n    const m = result[this.monthIndex].toLowerCase()\n    if (this.monthsToMonth.has(m)) {\n      return this.monthsToMonth.get(m)\n    } else {\n      return toInt(m)\n    }\n  }\n}\n\nconst yearRE = \"((?:19|20)[0-9]{2})\" // 1975, 2014\nconst monthRE = \"(1[0-2]|0[1-9])\"\nconst monthishRE = \"(1[0-2]|0?[1-9])\"\nconst dayRE = \"([1-3][0-9]|0[1-9])\"\nconst dayishRE = \"([1-3][0-9]|0?[1-9])\"\nconst hourRE = \"(1[0-9]|2[0-3]|0[0-9])\"\n\nconst d59 = \"([0-5][0-9])\"\nconst minuteRE = d59 // 1, 01, ... 59\nconst secondRE = d59\n\nconst seps = \"([-\\\\.\\\\,:_/ |])\"\nconst optSeps = seps + \"?\"\n\nconst subsecRE = \"(?:(\\\\.[0-9]+))?\"\n\n// Timezones are [-13:00, +13:00], \"Z\", or \"UTC\"\nconst timezoneRE = \"(?:(Z|UTC)|(?:([+-])([01][0-9]):?([0-5][0-9])))\"\n\nconst tzRE = new RegExp(\"\\\\d\\\\d\\\\s*\" + timezoneRE, \"i\")\n\nexport function isoToOffsetMinutes(iso: string): Maybe<number> {\n  // we slice(1) because extractTzOffsetMinutes expects [zulu, sign, offsethour,\n  // offsetminutes]:\n  return map(tzRE.exec(iso), ea => extractTzOffsetMinutes(ea.slice(1)))\n}\n\n/**\n * @param arr must be [zulu, sign, offsethour, offsetminutes]\n */\nfunction extractTzOffsetMinutes(\n  arr: string[],\n  defaultTzOffsetMinutes?: number\n): Maybe<number> {\n  if (isEmpty(arr)) return defaultTzOffsetMinutes\n  const [zulu, sign] = arr.splice(0, 2)\n  const [offsetHour, offsetMin] = arr.splice(0, 2).map(ea => toInt(ea))\n  if (hasAnyIgnoreCase([\"z\", \"utc\"], zulu)) return 0\n  if (anyNotDefined([sign, offsetHour, offsetMin]))\n    return defaultTzOffsetMinutes\n  return (sign === \"-\" ? -1 : 1) * (offsetHour! * 60 + offsetMin!)\n}\n\nexport function dateTimeBetween(a: DateTime, b: DateTime): DateTime {\n  return a.until(b).divideEqually(2)[0].end\n}\n\nexport function agoMs(dated: Maybe<Dated>): Maybe<number> {\n  return mapNumeric(datedToMillis(dated), ea => Date.now() - ea)\n}\n\nexport function parseDateTime(str: string): Maybe<ExifDateTime> {\n  return mapNotBlank(str, s =>\n    firstTrueThunk(\n      [() => ExifDateTime.fromEXIF(s), () => parseExifDateTime(s)],\n      d => validDate(d)\n    )\n  )\n}\n\nconst logger = lazy(() => mkLogger(\"FuzzyDate\"))\n\n/**\n * Parses ISO, EXIF, and macOS screenshot (!!) formatted dates.\n */\nexport function parseDated(\n  s: string,\n  allowJsDateParsing = false\n): Maybe<Dated> {\n  if (blank(s)) return\n  for (const { desc, f } of [\n    { desc: \"DateInterval.fromISO\", f: () => DateInterval.fromISO(s) }, // must be first\n    { desc: \"parseDateTime\", f: () => parseDateTime(s) },\n    {\n      desc: \"DateTime.fromFormat(macOS)\",\n      f: () => DateTime.fromFormat(s, \"y-M-d 'at' H.m.s\")\n    }, // macOS screenshots\n    {\n      desc: \"DateTime.fromFormat(gnome)\",\n      f: () => DateTime.fromFormat(s, \"y-M-d H-m-s\")\n    }, // gnome screenshots.\n    // (Windows doesn't timestamp screenshots, BOOOOO)\n    {\n      desc: \"DateTime.fromFormat(yMMdd_HHmmss)\",\n      f: () => DateTime.fromFormat(s, \"yMMdd_HHmmss\")\n    }, // IMG_20190604_142556\n    { desc: \"ExifDate.fromEXIF\", f: () => ExifDate.fromEXIF(s) },\n    { desc: \"fuzzyDate.parseYMD\", f: () => fuzzyDate().parseYMD(s) },\n    {\n      desc: \"new Date()\",\n      f: () => (allowJsDateParsing ? new Date(s) : undefined)\n    } // js Date's constructor is astoundingly lax\n  ]) {\n    const result = f()\n    if (validDate(result)) {\n      const tzoffsetMinutes = isoToOffsetMinutes(s)\n      if (tzoffsetMinutes != null) {\n        result[\"tzoffsetMinutes\"] = tzoffsetMinutes\n      }\n      return logger().tap({\n        msg: \"parseDated()\",\n        result,\n        meta: {\n          s,\n          desc,\n          tzoffsetMinutes\n        }\n      })\n    }\n  }\n  return\n}\n\nexport class FuzzyDateParser {\n  private readonly monthsToMonth: Map<string, number> = new Map()\n  private readonly ymdPatterns: Parser[] = []\n  private readonly ymPatterns: Parser[] = []\n  private readonly yPatterns: Parser[] = []\n\n  constructor(readonly locale?: string) {\n    this.setup()\n  }\n\n  parseYMD(input: string): Maybe<FuzzyDate> {\n    return first(this.ymdPatterns, p => p.apply(input))\n  }\n\n  private addParser(\n    re: string,\n    yearIndex: number,\n    monthIndex?: number,\n    dayIndex?: number\n  ) {\n    const p = new Parser(\n      this.monthsToMonth,\n      // new RegExp(\"[\\\\b|_ /:]\" + re + \"[\\\\b|_ /:]\", \"i\"),\n      new RegExp(re + \"(?:$|[^\\\\d])\", \"i\"),\n      yearIndex,\n      monthIndex,\n      dayIndex\n    )\n    if (dayIndex != null && monthIndex != null) {\n      this.ymdPatterns.push(p)\n    } else if (\n      Settings.fuzzyYearParsing.valueOrDefault &&\n      dayIndex == null &&\n      monthIndex != null\n    ) {\n      this.ymPatterns.push(p)\n    } else if (\n      Settings.fuzzyYearParsing.valueOrDefault &&\n      dayIndex == null &&\n      monthIndex == null\n    ) {\n      this.yPatterns.push(p)\n    }\n  }\n\n  private setup() {\n    // #DADJOKES FTW\n    const flavorsOfTheMonth = [\"short\", \"long\"] as (\"short\" | \"long\")[]\n    for (const locale of uniq([this.locale, \"en-US\"])) {\n      for (const flavorOfTheMonth of flavorsOfTheMonth) {\n        const dtf = new Intl.DateTimeFormat(locale, {\n          month: flavorOfTheMonth\n        })\n        times(12, m => {\n          const monthName = dtf.format(new Date(2017, m))\n          this.monthsToMonth.set(monthName.toLowerCase(), m + 1)\n        })\n      }\n    }\n\n    const allMonths = \"(\" + sort([...this.monthsToMonth.keys()]).join(\"|\") + \")\"\n    // Very conservative/restrictive patterns to guard against mmddyy or ddmmyy:\n\n    // ISO 8601: 1999-11-11 (the \\\\2 ensures consistent seps). Seps are required\n    // if month and day aren't padded:\n    this.addParser(yearRE + seps + monthishRE + \"\\\\2\" + dayishRE, 1, 3, 4)\n\n    // If month and day are padded, seps are optional:\n    this.addParser(yearRE + optSeps + monthRE + \"\\\\2\" + dayRE, 1, 3, 4)\n\n    // 2011:Feb:06\n    this.addParser(yearRE + optSeps + allMonths + \"\\\\2\" + dayishRE, 1, 3, 4)\n\n    // August 6, 1994\n    this.addParser(allMonths + optSeps + dayishRE + \",?\\\\2\" + yearRE, 4, 1, 3)\n\n    // 6 August 1994\n    this.addParser(dayishRE + optSeps + allMonths + \",?\\\\2\" + yearRE, 4, 3, 1)\n\n    // The following are only year + month (no date):\n    if (Settings.fuzzyDateParsing.valueOrDefault) {\n      // August 1994\n      this.addParser(allMonths + seps + yearRE, 3, 1)\n\n      // 2001 AUG\n      this.addParser(yearRE + seps + allMonths, 1, 3)\n    }\n\n    this.addParser(yearRE, 1)\n  }\n\n  extractDateFromPath(path: string[]): Maybe<FuzzyDate> {\n    if (!Settings.usePathsToInferDates.valueOrDefault) return\n\n    // https://en.wikipedia.org/wiki/Design_rule_for_Camera_File_system\n    ignorableSubpaths.forEach(ea => {\n      if (startsWith(path, ea)) {\n        path.splice(0, ea.length)\n      }\n    })\n    path = path.filter(\n      // If it's a camera-provided serial number, ignore that part of the path.\n      ea => notBlank(ea) && path[0].match(ignorableDCF) == null\n    )\n    // Don't modify path!\n    const reversePath = [...path].reverse()\n\n    return firstThunk(\n      // First try to find a YMD in one of the path elements individually:\n      () => first(reversePath, ea => this.parseYMD(ea)),\n      // Then try to find YMD by joining the paths:\n      () => this.parseYMD(reversePath.slice(0, 4).join(\" \")),\n      () => this.parseYMD(path.slice(0, 4).join(\" \")),\n      ...(!Settings.fuzzyDateParsing.valueOrDefault\n        ? []\n        : [\n            () =>\n              first(this.ymPatterns, parser =>\n                first(reversePath, ea => parser.apply(ea))\n              ),\n            () =>\n              first(this.ymPatterns, parser => parser.apply(path.join(\" \"))),\n            () =>\n              first(this.yPatterns, parser =>\n                first(reversePath.slice(1), ea => parser.apply(ea))\n              )\n          ])\n    )\n  }\n}\n\nconst ignorableDCF = /^((DCIM)|(DSC[_0F]?|IMG[-_]|GOPRO|MOV[-_]|MVI[-_]|P_?)\\d+)$/i\n\nconst fuzzyDateSettingsListener = lazy(() => {\n  Settings.fuzzyDateParsing.addListener(() => fuzzyDate.unset())\n  Settings.fuzzyYearParsing.addListener(() => fuzzyDate.unset())\n  Settings.usePathsToInferDates.addListener(() => fuzzyDate.unset())\n})\n\nconst fuzzyDate = lazy(() => {\n  fuzzyDateSettingsListener()\n  return new FuzzyDateParser(undefined)\n})\n\nconst ignorableSubpaths: string[][] = []\n\nexport function addIgnorableSubpath(subpath: string[]) {\n  ignorableSubpaths.push(subpath)\n}\n\n// Only for tests\nexport function clearIgnorableSubpaths() {\n  ignorableSubpaths.length = 0\n}\n\nexport function extractDateFromPath(path: string[]): Maybe<FuzzyDate> {\n  return fuzzyDate().extractDateFromPath(path)\n}\n\nexport function parseYMD(s: string): Maybe<FuzzyDate> {\n  return fuzzyDate().parseYMD(s)\n}\n\n// can't IDate because IMarried HUR HUR LOL DADJOKES FTW\nexport type Dated =\n  | FuzzyDate\n  | ExifDate\n  | ExifDateTime\n  | Date\n  | DateInterval\n  | DateTime\n  | DateObject\n// we don't include luxon.Interval here because our DateInterval supports\n// slots and index.\n\nexport function isDated(d: any): d is Dated {\n  // My proudest moment in coding:\n\n  // oh wait this is all just garbage bailing wire and duct tape nm.\n  return (\n    d != null &&\n    (d instanceof FuzzyDate ||\n      d instanceof ExifDate ||\n      d instanceof ExifDateTime ||\n      d instanceof Date ||\n      d instanceof DateInterval ||\n      d instanceof DateTime ||\n      allDefined([d.year, d.month, d.day]))\n  )\n}\n\nexport function getYear(d: Dated): Maybe<number> {\n  return map(d, ea => (ea instanceof Date ? ea.getFullYear() : ea.year))\n}\n\n/**\n * @return 1-12, like normal humans\n */\nexport function getMonth(d: Dated): Maybe<number> {\n  return map(d, ea => (ea instanceof Date ? ea.getMonth() + 1 : ea.month))\n}\n\nexport function getDay(d: Dated): Maybe<number> {\n  return map(d, ea => (ea instanceof Date ? ea.getDate() : ea.day))\n}\n\nexport function getHour(d: Dated): Maybe<number> {\n  return hasTime(d) ? (d instanceof Date ? d.getHours() : d.hour) : undefined\n}\n\nexport function getMinute(d: Dated): Maybe<number> {\n  return hasTime(d)\n    ? d instanceof Date\n      ? d.getMinutes()\n      : d.minute\n    : undefined\n}\n\nexport function getSecond(d: Dated): Maybe<number> {\n  return hasTime(d)\n    ? d instanceof Date\n      ? d.getSeconds()\n      : d.second\n    : undefined\n}\n\nexport function getMillisecond(d: Dated): Maybe<number> {\n  return hasTime(d)\n    ? d instanceof Date\n      ? d.getMilliseconds()\n      : d.millisecond\n    : undefined\n}\n\nexport function hasSeconds(d: Dated): boolean {\n  return (\n    hasTime(d) &&\n    (gt0(getMinute(d)) || gt0(getSecond(d)) || gt0(getMillisecond(d)))\n  )\n}\n\n/**\n * \".###\" or \".#####\" from the milliseconds in `d`.\n */\nexport function getSecMs(d: Dated): Maybe<string> {\n  return map(getSecond(d), sec => {\n    const ms = orElse(getMillisecond(d), 0)\n    let s = (sec + ms / 1000).toString()\n    if (sec < 10) s = \"0\" + s\n    if (ms === 0) s = s + \".\"\n    while (s.length < 6) {\n      s = s + \"0\"\n    }\n    return s\n  })\n}\n\nexport function zoneOffsetToName(\n  offsetMinutes: Maybe<number>,\n  includeUTCPrefix = true\n): Maybe<string> {\n  if (offsetMinutes == null) return\n  if (offsetMinutes === 0) return includeUTCPrefix ? \"UTC\" : \"\"\n  const sign = offsetMinutes < 0 ? \"-\" : \"+\"\n  // Round to nearest :15 minute:\n  const rounded = round(offsetMinutes / 15) * 15\n  const abs = Math.abs(rounded)\n  const hours = Math.floor(abs / 60)\n  const minutes = Math.floor(Math.abs(abs % 60))\n  return `${includeUTCPrefix ? \"UTC\" : \"\"}${sign}${pad(hours)}:${pad(minutes)}`\n}\n\nexport function hasZone(d: Dated): boolean {\n  if (d instanceof ExifDateTime) {\n    return d.hasZone && zoneSeemsLegit(d.tzoffsetMinutes)\n  } else if (d instanceof DateTime) {\n    return d.zone != null && d.zone.type !== \"local\"\n  } else {\n    return false\n  }\n}\n\n// Used for creating DateTime. \"UTC\", or something like \"UTC+07:30\"\nexport function getZoneName(d: Dated): Maybe<string> {\n  if (d instanceof DateTime) {\n    return map(d.zone, ea => ea.name)\n  } else if (d instanceof ExifDateTime) {\n    return d.zone\n  } else {\n    // `Date`s don't retain the timezone offset of the source date.\n    return\n  }\n}\n\nexport function parseExifDateTime(\n  input: string,\n  re: RegExp = ymd_hmsRegExp\n): Maybe<ExifDateTime> {\n  const m = re.exec(input)\n  if (m == null) {\n    return\n  }\n  const tokens = [...m.slice(1)]\n  const [year, month, day, hour, minute, second] = tokens\n    .splice(0, 6)\n    .map(ea => toInt(ea))\n\n  if (year == null || month == null || day == null) {\n    return\n  }\n  if (\n    !Settings.fuzzyDateParsing.valueOrDefault &&\n    (hour == null || minute == null)\n  ) {\n    return\n  }\n\n  const millisecond = clamp(\n    0,\n    999,\n    toFloat(tokens.shift(), { defaultValue: 0 })! * 1000\n  )\n  const offset = extractTzOffsetMinutes(tokens)\n  const zone = zoneOffsetToName(offset)\n  const dt = DateTime.fromObject({\n    year,\n    month,\n    day,\n    hour,\n    minute,\n    second,\n    millisecond,\n    zone\n  })\n  return dt.isValid ? toExifDateTime(dt, zone) : undefined\n}\n\nconst sep = `[-:_ ]?`\n\nconst ymd_hmsRegExp = new RegExp(\n  [yearRE, monthRE, dayRE, hourRE, minuteRE, secondRE, subsecRE].join(sep) +\n    timezoneRE +\n    \"?\", // < timezone isn't required\n  \"i\" // < \"T\" separator\n)\n\n/**\n * If you don't care about timezone offsets (you're just wanting `.isValid`,\n * right?), otherwise, use `toExifDateTime`.\n */\nexport function toDateTime(d: Maybe<Dated>): Maybe<DateTime> {\n  if (d instanceof DateTime) return d\n  if (d instanceof ExifDateTime) return d.toDateTime()\n  if (d instanceof DateInterval) return d.middle.toDateTime()\n  if (d instanceof Date) return DateTime.fromJSDate(d)\n  return\n}\n\n/**\n * DateTime doesn't retain timezone offsets being \"set\" or \"unset\", so we prefer\n * ExifDateTime.\n *\n * @param zoneName set the zoneName.\n */\nexport function toExifDateTime(\n  d: Maybe<Dated>,\n  zoneName?: string\n): Maybe<ExifDateTime> {\n  if (d == null || !hasTime(d)) return\n  if (d instanceof DateTime) {\n    return ExifDateTime.fromDateTime(d)\n  }\n  const ts = datedToMillis(d)\n  if (ts == null) return\n  // If zoneName is non-blank, use it.\n  const zoneWithDefault = !blank(zoneName)\n    ? zoneName\n    : hasZone(d)\n    ? getZoneName(d)\n    : undefined\n\n  const offset = mapNotBlank(zoneWithDefault, ea => zoneToOffset(ts, ea))\n  if (zoneName != null && offset == null) {\n    return\n  }\n  const result = map(getYear(d), year =>\n    map(getMonth(d), month =>\n      map(getDay(d), day =>\n        map(\n          getHour(d),\n          hour =>\n            new ExifDateTime(\n              year,\n              month,\n              day,\n              hour,\n              orElse(getMinute(d), 0),\n              orElse(getSecond(d), 0),\n              getMillisecond(d),\n              offset,\n              (d as any).rawValue\n            )\n        )\n      )\n    )\n  )\n  return validDate(result) ? result : undefined\n}\n\nexport function toDate(d: Maybe<Dated>): Maybe<Date> {\n  if (d == null) return\n  if (typeof d === \"number\") {\n    return new Date(d)\n  }\n  if (d instanceof Date) {\n    return d\n  }\n  if (d instanceof DateTime) {\n    return d.toJSDate()\n  }\n  if (null != d[\"toDate\"]) {\n    return d[\"toDate\"]()\n  }\n  if (gt0(d.year) && gt0(d.month) && gt0(d.day)) {\n    // NOTE: new Date() only requires year and month.\n    // Day defaults to 1 if undefined.\n    // This Date will be noon in the current timezone.\n    return new Date(d.year, orElse(d.month, 1) - 1, d.day, 12) // pick middle of the day\n  }\n  const s = toS(d)\n  if (notBlank(s)) return map(fromISO(s) as any, toDate)\n  return\n}\n\nexport function datedToMillis(\n  d: Maybe<Dated | number | string>\n): Maybe<number> {\n  if (d == null || isString(d)) return // invalid tag from ExifTool\n  if (isNumber(d)) return d\n  if (d instanceof Date) return d.getTime()\n  if (d instanceof DateTime) return d.toMillis()\n  return map(toDate(d), ea => ea.getTime())\n}\n\nexport function datedToLocal(d: Maybe<Dated | number | string>): Maybe<number> {\n  if (d == null || isString(d)) return // invalid tag from ExifTool\n  if (isNumber(d)) return tsToLocal(d)\n  if (d instanceof ExifDateTime || d instanceof DateTime) return dtToLocal(d)\n  if (d instanceof Date) return tsToLocal(d.getTime())\n  return map(datedToMillis(d), tsToLocal)\n}\n\nexport function dtToLocal(d: ExifDateTime | DateTime): Maybe<number> {\n  return (\n    parseInt(\n      [d.year, d.month, d.day, d.hour, d.minute, d.second]\n        .map(ea => pad2(ea))\n        .join(\"\") + \"00\"\n    ) + millisToLocalSuffix(d.millisecond ?? 0)\n  )\n}\n\nexport function datedToOffsetMinutes(d: Maybe<Dated>): Maybe<number> {\n  return map(d, ea =>\n    ea instanceof ExifDateTime\n      ? ea.tzoffsetMinutes\n      : ea instanceof DateTime\n      ? ea.offset\n      : undefined\n  )\n}\n\nexport function datedToPrecisionMs(d: Maybe<Dated>): Maybe<number> {\n  return map(d, ea =>\n    ea instanceof DateTime || ea instanceof ExifDateTime || ea instanceof Date\n      ? 0\n      : ea instanceof ExifDate\n      ? dayMs\n      : ea instanceof DateInterval\n      ? ea.intervalMs\n      : undefined\n  )\n}\n\nexport function datedToISO(\n  d: Dated | number,\n  includeOffset = true\n): Maybe<string> {\n  if (d == null) return\n  if (d instanceof DateInterval) return d.toString(includeOffset)\n  const fd = isNumber(d) ? new Date(d) : d\n  if (!hasTime(fd)) return datedToYMD(fd)\n  return map(toExifDateTime(fd), edt => edt.toISOString({ includeOffset }))\n}\n\nexport function fromISO(\n  iso: string,\n  defaultZone?: Maybe<string>\n): Maybe<ExifDateTime | ExifDate | ExifTime> {\n  return typeof iso !== \"string\" || blank(iso)\n    ? undefined\n    : // We use ExifDateTime because it supports unset timezones:\n      opt<ExifDateTime | ExifDate | ExifTime>(\n        ExifDateTime.fromISO(iso, defaultZone)\n      )\n        .orElse(() => ExifDate.fromISO(iso))\n        .orElse(() => ExifTime.fromEXIF(iso))\n        .get()\n}\n\nexport function datedToYMD(d: Dated, separator = \"-\"): string {\n  return compact([getYear(d), getMonth(d), getDay(d)])\n    .map(ea => pad(ea))\n    .join(separator)\n}\n\nexport function toFuzzyDate(d: Maybe<Dated>): Maybe<FuzzyDate> {\n  return map(d, ea =>\n    map(getYear(ea), y => new FuzzyDate(y, getMonth(ea), getDay(ea)))\n  )\n}\n\nexport function sameDay(dis: Maybe<Dated>, dat: Maybe<Dated>): boolean {\n  return lte(diffMillis(dis, dat), dayMs)\n}\n\nexport function diffMillis(a: Maybe<Dated>, b: Maybe<Dated>): Maybe<number> {\n  const [aMs, bMs] = [a, b].map(datedToMillis)\n  return aMs == null || bMs == null ? undefined : aMs - bMs\n}\n\nexport function closeTo(\n  a: Maybe<Dated>,\n  b: Maybe<Dated>,\n  maxDiffMs: number\n): boolean {\n  return mapOr(\n    diffMillis(a, b),\n    ea => Math.abs(ea) < maxDiffMs,\n    () => false\n  )\n}\n\nexport function gtDate(a: Maybe<Dated>, b: Maybe<Dated>): boolean {\n  const aMs = datedToMillis(a)\n  const bMs = datedToMillis(b)\n  return aMs == null || bMs == null ? false : aMs > bMs\n}\n\n/**\n * @param index must be [0, splits]\n * @param splits must be >= 1\n */\nexport function dateBetween(\n  a: Maybe<Dated>,\n  b: Maybe<Dated>,\n  index = 1,\n  splits = 1\n): Maybe<Dated> {\n  if (datedToMillis(a) == null || datedToMillis(b) == null) return\n  const [start, end] = [a, b].map(d => datedToMillis(d)!).sort()\n  const diff = end - start\n  const delta = diff / (splits + 1)\n  const zoneA = getZoneName(a!)\n  const zoneB = getZoneName(b!)\n  const zone = zoneA === zoneB ? zoneA : undefined\n  const result = DateTime.fromMillis(start + delta * index, { zone })\n  return [a, b].some(ea => !hasTime(ea)) ? toFuzzyDate(result) : result\n}\n\n/**\n * @return true iff time resolution is available\n */\nexport function hasTime(d: Maybe<Dated>): d is Date | ExifDateTime | DateTime {\n  return d instanceof Date || d instanceof ExifDateTime || d instanceof DateTime\n}\n\n/**\n * @param ts timestamp\n */\nexport function zoneToOffset(\n  ts: number,\n  zone: number | string | Zone\n): Maybe<number> {\n  const z = Info.normalizeZone(zone)\n  return z.isValid ? (z as any).offset(ts) : undefined\n}\n\nexport function setZone(\n  edt: Maybe<Dated>,\n  zone: string\n): Maybe<DateTime | ExifDateTime> {\n  if (edt instanceof DateTime) {\n    return edt.setZone(zone, { keepLocalTime: true })\n  }\n  return toExifDateTime(edt, zone)\n}\n", "import { DateTime } from \"luxon\"\nimport { hourMs } from \"../fe/Date\"\nimport { lazy } from \"../fe/Lazy\"\nimport { Maybe } from \"../fe/MaybeTypes\"\n\n// Pacific/Kiritimati is +14:00 TIL\n// https://en.wikipedia.org/wiki/List_of_tz_database_time_zones\nexport const MaxTzOffsetHours = 14\n\nexport const localTzOffsetMinutes = lazy(() => DateTime.local().offset, hourMs)\n\nexport function zoneSeemsLegit(tzoffsetMinutes: Maybe<number>): boolean {\n  if (tzoffsetMinutes == null) return false\n  if (Math.abs(tzoffsetMinutes) > MaxTzOffsetHours * 60) return false\n\n  // Don't accept a zero-offset tz unless local is UTC:\n  return tzoffsetMinutes === 0 ? localTzOffsetMinutes() === 0 : true\n}\n", "import { ExifDateTime } from \"exiftool-vendored\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { clamp, toInt } from \"../../fe/Number\"\nimport { toS } from \"../../fe/toS\"\nimport {\n  Dated,\n  datedToISO,\n  getDay,\n  getMonth,\n  getYear,\n  hasTime,\n  toExifDateTime,\n  validDate\n} from \"./FuzzyDate\"\n\n// See https://en.wikipedia.org/wiki/ISO_8601#Time_intervals\nconst re = /^(.+?)(?:--|\\/)(.+?)(?:(?:\\/)(\\d+)\\/(\\d+))?$/\nexport class DateInterval {\n  static fromISO(s: string): Maybe<DateInterval> {\n    s = toS(s).trim()\n    const m = re.exec(s)\n    if (m == null) {\n      return\n    }\n    const start = ExifDateTime.fromISO(m[1])\n    const end = ExifDateTime.fromISO(m[2])\n    const index = toInt(m[3])\n    const slots = toInt(m[4])\n    return this.for(start, end, index, slots)\n  }\n\n  static for(\n    start: Maybe<Dated>,\n    end: Maybe<Dated>,\n    index = 0,\n    splits = 1\n  ): Maybe<DateInterval> {\n    if (!validDate(start) || !validDate(end)) return\n    const startEDT = toExifDateTime(start)\n    const endEDT = toExifDateTime(end)\n    if (startEDT == null || endEDT == null) return\n    splits = clamp(1, 1000, toInt(splits, { defaultValue: 1 })!)\n    index = clamp(0, splits - 1, toInt(index, { defaultValue: 0 })!)\n    const middle = map(\n      startEDT\n        .toDateTime()\n        .until(endEDT.toDateTime())\n        .divideEqually(splits + 1)[index],\n      d => d.end\n    )\n    if (middle == null) return\n    // console.log(\"DateInterval.for\", {\n    //   start: datedToISO(start),\n    //   middle: datedToISO(middle),\n    //   end: datedToISO(end),\n    //   index,\n    //   splits,\n    //   startMiddleMs: fmtDuration(middle.toMillis() - start.toMillis()),\n    //   middleEndMs: fmtDuration(end.toMillis() - middle.toMillis()),\n    //   startEndMs: fmtDuration(end.toMillis() - start.toMillis())\n    // })\n    return new DateInterval(\n      startEDT,\n      toExifDateTime(middle, orElse(startEDT.zone, endEDT.zone))!,\n      endEDT,\n      index,\n      splits\n    )\n  }\n\n  readonly year: number\n  readonly month: number\n  readonly day: number\n\n  private constructor(\n    readonly start: ExifDateTime,\n    readonly middle: ExifDateTime,\n    readonly end: ExifDateTime,\n    readonly index = 0,\n    readonly splits = 1\n  ) {\n    this.year = getYear(this.middle)!\n    this.month = getMonth(this.middle)!\n    this.day = getDay(this.middle)!\n  }\n\n  get intervalMs() {\n    return this.end.toDate().getTime() - this.start.toDate().getTime()\n  }\n\n  interval() {\n    return this.start.toDateTime().until(this.end.toDateTime())\n  }\n\n  toDate() {\n    return this.middle.toDate()\n  }\n\n  get zone() {\n    return orElse(this.start.zone, this.end.zone)\n  }\n\n  get hasTimes() {\n    return hasTime(this.start) && hasTime(this.end)\n  }\n\n  /**\n   * This only complies with the ISO standard if the index and slots are 1.\n   */\n  toString(includeOffset = true): string {\n    return (\n      `${datedToISO(this.start, includeOffset)}/${datedToISO(\n        this.end,\n        includeOffset\n      )}` +\n      (this.index === 0 && this.splits === 1\n        ? \"\"\n        : `/${this.index}/${this.splits}`)\n    )\n  }\n\n  readonly toISOString = this.toString.bind(this)\n\n  includes(d: Maybe<Dated>): boolean {\n    if (d == null) return false\n    const edt = toExifDateTime(d)\n    if (edt != null) {\n      return this.interval().contains(edt.toDateTime())\n    } else {\n      return (\n        this.year === getYear(d) &&\n        this.month === getMonth(d) &&\n        this.day === getDay(d)\n      )\n    }\n  }\n}\n", "import { defined } from \"../fe/Maybe\"\nimport { AsyncFilter } from \"./async/AsyncFilter\"\n\nexport abstract class Filter<T> {\n  static lift<T1>(f: (item: T1) => boolean): Filter<T1> {\n    return new (class extends Filter<T1> {\n      apply(item: T1): boolean {\n        return f(item)\n      }\n    })()\n  }\n\n  abstract apply(item: T): boolean\n\n  and(that: Filter<T>): Filter<T> {\n    return Filter.lift((item: T) => this.apply(item) && that.apply(item))\n  }\n\n  or(that: Filter<T>): Filter<T> {\n    return Filter.lift((item: T) => this.apply(item) || that.apply(item))\n  }\n\n  filter(array: Array<T>): Array<T> {\n    return array.filter(ea => this.apply(ea))\n  }\n\n  asAsync(): AsyncFilter<T> {\n    return AsyncFilter.lift((item: T) => Promise.resolve(this.apply(item)))\n  }\n}\n\n/**\n * Filter out undefined and null references\n */\nexport const definedFilter = Filter.lift<any>(defined)\n\nexport const trueFilter = Filter.lift<any>(() => true)\n", "import { Filter } from \"../Filter\"\nimport { ExtType, ExtTypes, isExtType } from \"../tags/FileExts\"\nimport { pathnames } from \"./Path\"\nimport { SimpleFile } from \"./SimpleFile\"\n\n/**\n * case-insensitive basename matching\n */\nexport function excludedPathFilter<T extends SimpleFile>(\n  excludedBasenames: string[]\n): Filter<T> {\n  const s = new Set(excludedBasenames.map(ea => ea.toLowerCase()))\n  return Filter.lift((file: T) =>\n    pathnames(file.nativePath).every(ea => !s.has(ea.toLowerCase()))\n  )\n}\n\n/**\n * @param includedExtensions case-insensitive file extensions.\n * Note these must be prefixed with a '.'\n */\nexport function extFilter<T extends SimpleFile>(extType: ExtType): Filter<T> {\n  return Filter.lift((file: T) => isExtType(file?.ext, extType))\n}\n\nexport const browserExtFilter = extFilter(ExtTypes.SupportedByCurrentBrowser)\nexport const videoExtFilter = extFilter(ExtTypes.Video)\nexport const exifExtFilter = extFilter(ExtTypes.AssetFile)\n", "import { ExifDateTime, Tags } from \"exiftool-vendored\"\nimport { compact, flatten, isEmpty, isNotEmpty, sortBy } from \"../../fe/Array\"\nimport { blank, notBlank } from \"../../fe/Blank\"\nimport { dayMs, minuteMs } from \"../../fe/Date\"\nimport { later } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { opt } from \"../../fe/Opt\"\nimport { toA } from \"../../fe/toA\"\nimport { toS } from \"../../fe/toS\"\nimport { allNotBlank, first, firstAsync, flatZip, zip } from \"../Array\"\nimport { thenMap } from \"../async/Promise\"\nimport { DateInterval } from \"../date/DateInterval\"\nimport {\n  Dated,\n  datedToMillis,\n  diffMillis,\n  getZoneName,\n  hasZone,\n  parseDateTime,\n  parseYMD,\n  sameDay\n} from \"../date/FuzzyDate\"\nimport { onClearCache } from \"../event/EventEmitter\"\nimport { FifoCache } from \"../FifoCache\"\nimport { extFilter } from \"../fs/BaseFileFilters\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { SimpleFile } from \"../fs/SimpleFile\"\nimport { mkLogger } from \"../Logger\"\nimport { isString } from \"../String\"\nimport { diceCoeff } from \"../StringSimilarity\"\nimport { MaxTzOffsetHours } from \"../Timezone\"\nimport { capturedAtFromTags } from \"./CapturedAt\"\nimport { readRawTags } from \"./ExifTags\"\nimport { ExtTypes, isSidecarExt } from \"./FileExts\"\n\nconst logger = lazy(() => mkLogger(\"TagInference\"))\n\n/**\n * HEY GUESS WHAT HERE ARE SOME HEURISTICS OO BOY OO BOY WHAT COULD\n * POSSIBLY GO WRONG, AMIRITE?\n *\n * Unfortunately, many smartphones don't encode the make and model into their\n * video headers (like the Google Pixel!). They are stinky, stinky poopy\n * pants, but we can try to clean up their mess. With a different stinky poopy\n * mess.\n *\n * Also unfortunately, `jpegtrans` from days of yore (2000s) didn't copy\n * tags to rotated images--so the image rotation was lossless, but the\n * resulting file lost its tags (like Make, Model, and capture time).\n *\n * If there are other files in the directory, and they have a consistent make\n * and model, assume the video shares the same make and model.\n */\nexport async function inferMakeAndModel(\n  f: PosixFile,\n  tags: Tags\n): Promise<void> {\n  if (notBlank(tags.Make) && notBlank(tags.Model)) {\n    return\n  }\n\n  if (\n    blank(tags.Make) &&\n    (toS(tags.HandlerDescription) + toS((tags as any).CompressorName)).includes(\n      \"GoPro\"\n    )\n  ) {\n    tags.Make = \"GoPro\"\n    // TODO: more heuristics for GoPros?\n    return\n  }\n\n  // If a nearby file in the current directory have the same make and\n  // model, or a filename has the same prefix as our file, use that.\n  const fbname = bname(f)\n  const sibs = await nearestSiblings(f)\n  if (sibs == null) return\n  const nearestN = compact(flatten(zip(sibs.younger, sibs.older)))\n    .slice(0, 50)\n    // Only look at closely-named files:\n    .filter(ea => diceCoeff(bname(ea), fbname) > 0.7)\n    // If we don't find something in two handfuls, give up:\n    .slice(0, 10)\n\n  logger().info(\n    \"inferMakeAndModel(\" + f + \"): looking at nearby siblings\",\n    nearestN.map(ea => ea.base)\n  )\n\n  for (const sibling of nearestN) {\n    const t = await readRawTags(sibling)\n    if (t != null && allNotBlank(t.Make, t.Model)) {\n      logger().info(\"inferMakeAndModel(\" + f + \")\", {\n        sibling: sibling.base,\n        Make: t.Make,\n        Model: t.Model\n      })\n      tags.Make = t.Make\n      tags.Model = t.Model\n      return\n    }\n  }\n}\n\nexport async function inferCapturedAtFromSiblings(\n  file: PosixFile\n): PromiseMaybe<{ date: Dated; src: string }> {\n  return thenMap(\n    beforeAfterCapturedAt(file),\n    ({ before, after, index, slots }) => {\n      if (!sameDay(before.date, after.date)) {\n        // This \"same day\" heuristic means we don't apply this general heuristic\n        // when the siblings are really different.\n        logger().debug(\n          \"inferCapturedAtFromSiblings(): rejecting, not same day\",\n          {\n            file: file.nativePath,\n            before: toS(before),\n            after: toS(after)\n          }\n        )\n        return\n      }\n      // `sameDay` will only be true if before and after are valid:\n      return map(\n        DateInterval.for(before.date, after.date, index, slots),\n        date => ({\n          date,\n          src: `before:${before.src},after:${after.src}`\n        })\n      )\n    }\n  )\n}\n\nasync function firstWithCapturedAt(\n  arr: Maybe<PosixFile[]>,\n  maxChecked = 7\n): PromiseMaybe<{ date: Dated; src: string; index: number }> {\n  return firstAsync(toA(arr).slice(0, maxChecked), (sib, index) =>\n    thenMap(readRawTags(sib), t =>\n      thenMap(capturedAtFromTags(t), ea => ({ ...ea, index }))\n    )\n  )\n}\n\nasync function firstWithCapturedAtTzOffset(\n  arr: PosixFile[],\n  maxChecked = 7\n): PromiseMaybe<{ zoneName: string; index: number }> {\n  return firstAsync(arr.slice(0, maxChecked), (sib, index) =>\n    thenMap(readRawTags(sib), t =>\n      thenMap(capturedAtFromTags(t), d =>\n        opt(d)\n          .filter(ea => hasZone(ea.date))\n          .flatMap(ea => getZoneName(ea.date))\n          .map(zoneName => ({ zoneName, index }))\n          .get()\n      )\n    )\n  )\n}\n\nexport type BeforeAfterResult = PromiseMaybe<{\n  before: { date: Dated; src: string }\n  after: { date: Dated; src: string }\n  index: number\n  slots: number\n}>\n\nlater(() => onClearCache(() => bacaCache.prior()?.clear()))\n\nconst bacaCache = lazy(() => new FifoCache<BeforeAfterResult>(1024))\n\nfunction beforeAfterCapturedAt(file: PosixFile): BeforeAfterResult {\n  return bacaCache().getOrSet(file.nativePath, async () => {\n    const sibs = await nearestSiblings(file)\n    const before = await firstWithCapturedAt(sibs?.younger)\n    const after = await firstWithCapturedAt(sibs?.older)\n    return before == null || after == null\n      ? undefined\n      : {\n          before,\n          after,\n          index: before.index,\n          slots: before.index + after.index + 1\n        }\n  })\n}\n\nlater(() => onClearCache(() => bnameCache.prior()?.clear()))\n\nconst bnameCache = lazy(() => new FifoCache<string>(2048, minuteMs))\n\n/**\n * Pull out the basename, remove prefixes like \"IMG_\", \"VID_\", and \"MOV_\", strip\n * any count suffixes, then downcase.\n */\nexport function bname(f: SimpleFile | string): string {\n  let name = isString(f) ? f : f.name\n  return bnameCache().getOrSet(name, () => {\n    map(/(?:burst)(.{8,})$/i.exec(name), m => (name = m[1]))\n\n    // https://en.wikipedia.org/wiki/Design_rule_for_Camera_File_system\n    map(\n      /^(?:(?:dsc[0f]?|img|mov|mvi|mvimg|vid|gpfr|gopro?|gp|gf|p)(?:[-_ ])?)(\\S.+)$/i.exec(\n        name\n      ),\n      m => (name = m[1])\n    )\n\n    return (\n      name\n        // macOS, when you copy-paste-paste, you get\n        // img.jpg\n        // img copy.jpg\n        // img copy 2.jpg\n        // img copy 3.jpg\n\n        // Windows, when you copy-paste-paste, you get\n        // img.jpg\n        // img - Copy.jpg\n        // img - Copy (2).jpg\n        // img - Copy (3).jpg\n        .replace(/\\s*-?\\s*copy( \\(?\\d+\\)?)?\\s*$/i, \"\")\n\n        // Ubuntu when you copy-paste-paste-paste, you get\n        // img.jpg\n        // img (copy).jpg\n        // img (another copy).jpg\n        // img (3rd copy).jpg\n        // img (4th copy).jpg\n        .replace(/\\s*\\((another |\\d+[a-z]{2} )?copy\\)\\s*$/i, \"\")\n\n        // left trim \"_1234\" or \" base\"\n        .replace(/^[-\\s_0]+/, \"\")\n        // right trim off any count suffix, like \"filename-12\":\n        .replace(/[\\s-_][\\d\\s]{0,2}$/, \"\")\n        .replace(/_cover$/i, \"\")\n\n        .toLowerCase()\n        .normalize()\n    )\n  })\n}\n\nconst pathsWithExif = extFilter(ExtTypes.AssetFile)\n\ntype NearestSiblings = { younger: PosixFile[]; older: PosixFile[] }\n\n/**\n * Return `{younger: PosixFile[], older: PosixFile[]}`, ordered by basename\n * similarity to `f`.\n *\n * Both `younger` and `older` will be truncated after `maxLength` entries, to\n * prevent large directories from causing exiftool to visit every entry in large\n * directories.\n */\nexport async function nearestSiblings(\n  f: PosixFile,\n  maxLength = 7\n): PromiseMaybe<NearestSiblings> {\n  const dirents = await f\n    .parent()\n    .childDirectoryEntries(\n      ea =>\n        ea.isFile() &&\n        !ea.name.startsWith(\".\") &&\n        !isSidecarExt(ea.ext) &&\n        pathsWithExif.apply(ea)\n    )\n  if (dirents == null) {\n    logger().info(\"nearestSiblings(): can't readdir parent, \" + f.parent())\n    return\n  }\n  const times = await f.statTimes()\n  if (isEmpty(times)) {\n    logger().info(\"nearestSiblings(): statTimes() missing from \" + f)\n    return\n  }\n\n  const sorted = sortBy(dirents, ea => bname(ea))\n  const myIndex = sorted.findIndex(ea => ea.base === f.base)\n  if (myIndex < 0) {\n    logger().warn(\"nearestSiblings(): can't find self in siblings: \" + f)\n    return\n  }\n\n  const [youngerDE, olderDE] = [\n    sorted.slice(myIndex - maxLength * 2, myIndex),\n    sorted.slice(myIndex + 1, myIndex + 1 + maxLength * 2)\n  ]\n\n  const younger: PosixFile[] = []\n  const older: PosixFile[] = []\n\n  while (isNotEmpty(youngerDE) && younger.length < maxLength) {\n    const ea = PosixFile.forDirectoryEntry(youngerDE.pop()!)\n    if (await nearSibling(f, ea)) {\n      younger.push(ea)\n    }\n  }\n  while (isNotEmpty(olderDE) && older.length < maxLength) {\n    const ea = PosixFile.forDirectoryEntry(olderDE.shift()!)\n    if (await nearSibling(f, ea)) {\n      older.push(ea)\n    }\n  }\n\n  return {\n    younger,\n    older\n  }\n\n  // return logger().tap({\n  //   msg: \"nearestSiblings(\" + f + \")\",\n  //   result: {\n  //     younger,\n  //     older\n  //   },\n  //   meta: {\n  //     sorted,\n  //     myIndex,\n  //     maxLength\n  //   }\n  // })\n}\n\nfunction nearSibling(a: PosixFile, b: PosixFile, maxDiffMs = 2 * dayMs) {\n  const diffMs = diffMillis(parseYMD(a.base), parseYMD(b.base))\n  if (diffMs != null && Math.abs(diffMs) > maxDiffMs) return false\n  return a.contemporary(b, maxDiffMs)\n}\n\nexport async function nearestSiblingTzOffset(\n  f: PosixFile\n): PromiseMaybe<string> {\n  const sibs = await nearestSiblings(f)\n  const zipped = flatZip(toA(sibs?.younger), toA(sibs?.older)).slice(0, 10)\n  return logger().tap({\n    msg: \"nearestSiblingTzOffset(\" + f + \")\",\n    result: await thenMap(\n      firstWithCapturedAtTzOffset(zipped),\n      ea => ea.zoneName\n    ),\n    meta: {\n      zipped\n    }\n  })\n}\n\n/**\n * If the basename encodes a date and time, and it matches any file stat time,\n * use that.\n */\nexport async function extractStatBname(\n  f: PosixFile\n): PromiseMaybe<{ src: string; date: ExifDateTime }> {\n  const fromName = parseDateTime(bname(f))\n  const fromNameMs = map(fromName, datedToMillis)\n\n  if (fromName == null || fromNameMs == null) {\n    logger().debug(\"extractStatBname() bname isn't dated\", {\n      bname: bname(f),\n      fromName,\n      fromNameMs\n    })\n    return\n  }\n\n  const stat = await f.stat()\n  if (stat == null) {\n    logger().debug(\"extractStatBname() no stat\", { fromName, fromNameMs })\n    return\n  }\n\n  return logger().tap({\n    msg: \"extractStatBname()\",\n    result: first([\"birthtimeMs\", \"aTimeMs\", \"mtimeMs\", \"ctimeMs\"], src =>\n      Math.abs(stat[src] - fromNameMs) < MaxTzOffsetHours\n        ? { src, date: fromName }\n        : undefined\n    ),\n    meta: { fromName, fromNameMs, stat }\n  })\n}\n", "import { Tags } from \"exiftool-vendored\"\nimport { ExposureSettings } from \"../../fe/api/ExposureSettings\"\nimport { firstNotBlank } from \"../../fe/Blank\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { reqValuedOrElse } from \"../../fe/Object\"\nimport { mkLogger } from \"../Logger\"\nimport { firstNonZero } from \"../Number\"\n\nconst logger = mkLogger(\"ExposureSettings\")\n\nexport function extractExposureSettings(t: Tags): Maybe<ExposureSettings> {\n  const exposureSettings = {\n    focalLength: t.FocalLength,\n    iso: firstNonZero(t.ISO, t.ISOSpeed, t.SonyISO),\n    aperture: firstNonZero(\n      t.FNumber,\n      t.Fnumber,\n      t.ApertureValue,\n      t.SonyFNumber\n    ),\n    shutterSpeed: firstNotBlank(\n      t.ExposureTime,\n      t.ShutterSpeed,\n      t.SonyExposureTime\n    )\n  }\n  logger.debug(\"extracted from \" + t.FileName, { exposureSettings })\n  return reqValuedOrElse(exposureSettings)\n}\n", "import { sum } from \"../../fe/Array\"\nimport { map2 } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { absdiff, clamp, toInt } from \"../../fe/Number\"\nimport { zip } from \"../Array\"\nimport { avg } from \"./Vector\"\n\nexport interface Dimension {\n  min: number\n  max: number\n}\nexport interface ValuedDimension extends Dimension {\n  value: number\n}\n\nexport interface BitMixArgs {\n  dims: ValuedDimension[]\n  bitDepth: number\n}\n\nexport function concatBits(arr: number[], bitsPerValue: number): number {\n  const max = Math.pow(2, bitsPerValue)\n  return arr.reduce(\n    (acc, i) => acc * max + clamp(0, max, toInt(i, { defaultValue: 0 })!),\n    0\n  )\n}\n\nexport function splitBits(n: number, bitsPerValue: number): number[] {\n  const max = Math.pow(2, bitsPerValue)\n  const result: number[] = []\n  while (n > 0) {\n    result.unshift(n % max)\n    n = Math.floor(n / max)\n  }\n  return result\n}\n\nexport function diffConcattedBits(\n  a: Maybe<number>,\n  b: Maybe<number>,\n  bitsPerValue: number\n): Maybe<number> {\n  return map2(a, b, (ea1, ea2) =>\n    sum(\n      zip(splitBits(ea1, bitsPerValue), splitBits(ea2, bitsPerValue)),\n      ([i, j]) => absdiff(i, j)!\n    )\n  )\n}\n\nexport function bitZip(a: BitMixArgs): number {\n  a.dims.forEach(dim => (dim.value = clamp(dim.min, dim.max, dim.value)))\n\n  let result = 0\n\n  for (let bit = 0; bit < a.bitDepth; bit++) {\n    result *= 2 // < no bit twiddling, we may be > 32 bits!\n    const dIdx = bit % a.dims.length\n    const d = a.dims[dIdx]\n    const mid = avg([d.min, d.max])!\n    if (d.value > mid) {\n      result += 1 // < no bit twiddling, we may be > 32 bits!\n      d.min = mid\n    } else {\n      d.max = mid\n    }\n  }\n  return result\n}\n\nexport interface BitUnmixArgs {\n  dims: Dimension[]\n  bitDepth: number\n}\n\nexport function bitUnzip(n: number, a: BitUnmixArgs): Maybe<number[]> {\n  if (a.bitDepth > 52 || a.bitDepth < 0) return\n  const setBits = bitsSet(n)\n  for (let bit = 0; bit < a.bitDepth; bit++) {\n    const dIdx = bit % a.dims.length\n    const d = a.dims[dIdx]\n    const mid = avg([d.min, d.max])!\n    if (setBits.includes(a.bitDepth - bit - 1)) {\n      d.min = mid\n    } else {\n      d.max = mid\n    }\n  }\n  return a.dims.map(d => avg([d.min, d.max])!)\n}\n\n// Supports > 32 bit numbers\nexport function bitsSet(n: number): number[] {\n  return n\n    .toString(2)\n    .split(\"\")\n    .reverse()\n    .map((ea, idx) => (ea === \"1\" ? idx : -1))\n    .filter(ea => ea !== -1)\n}\n\n/**\n * Number of set bits in `x`\n * @see https://stackoverflow.com/questions/109023/how-to-count-the-number-of-set-bits-in-a-32-bit-integer#109117\n */\nexport function pop(x: number): number {\n  x = x - ((x >> 1) & 0x55555555)\n  x = (x & 0x33333333) + ((x >> 2) & 0x33333333)\n  x = (x + (x >> 4)) & 0x0f0f0f0f\n  x = x + (x >> 8)\n  x = x + (x >> 16)\n  return x & 0x0000003f\n}\n\nexport function bits<T>(arr: T[], f: (t: T, index: number) => boolean): number {\n  return sum(arr, (ea, index) =>\n    f(ea, index) ? Math.pow(2, arr.length - index - 1) : 0\n  )\n}\n", "import { map } from \"../fe/Maybe\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { isNumber } from \"../fe/Number\"\nimport { bitUnzip, bitZip } from \"./math/Bits\"\nimport { GeoRadix } from \"./math/Radix\"\nimport { within } from \"./Number\"\n\n// See https://en.wikipedia.org/wiki/Geographic_coordinate_system\n// and https://en.wikipedia.org/wiki/Decimal_degrees\n// https://www.movable-type.co.uk/scripts/geohash.html\n\nexport interface GeoLocation {\n  lat: number\n  lon: number\n}\n\nconst DefaultBitDepth = 30\n\nfunction toNearestBitDepth(bitDepth: number) {\n  return Math.floor(bitDepth / 5) * 5\n}\n\nexport function validLat(latitude: Maybe<number>): boolean {\n  return isNumber(latitude) && latitude !== 0 && within(-90, 90, latitude)\n}\n\nexport function validLon(longitude: Maybe<number>): boolean {\n  return isNumber(longitude) && longitude !== 0 && within(-180, 180, longitude)\n}\n\nexport function validLatLon(\n  latitude: Maybe<number>,\n  longitude: Maybe<number>\n): boolean {\n  return validLat(latitude) && validLon(longitude)\n}\n\nexport function locationToGeohash(\n  loc?: Maybe<Partial<GeoLocation>>,\n  bitDepth = DefaultBitDepth\n): Maybe<string> {\n  return geohash(loc?.lat, loc?.lon, bitDepth)\n}\n\nexport function geohash(\n  latitude?: number,\n  longitude?: number,\n  bitDepth = DefaultBitDepth\n): Maybe<string> {\n  return map(\n    geohashNumeric(latitude, longitude, toNearestBitDepth(bitDepth)),\n    i => GeoRadix.encode(i)\n  )\n}\n\nexport function geohashNumericShort(latitude?: number, longitude?: number) {\n  return geohashNumeric(latitude, longitude, 30)\n}\n\nexport function geohashNumeric(\n  latitude?: number,\n  longitude?: number,\n  bitDepth = DefaultBitDepth\n): Maybe<number> {\n  return !validLatLon(latitude, longitude)\n    ? undefined\n    : bitZip({\n        // The geohash spec does bitmixing oddly, requiring this to be lon, lat :(\n        dims: [\n          {\n            min: -180,\n            value: longitude!,\n            max: 180\n          },\n          {\n            min: -90,\n            value: latitude!,\n            max: 90\n          }\n        ],\n        bitDepth: toNearestBitDepth(bitDepth)\n      })\n}\n\nexport function ungeohash(\n  geohashString: string,\n  bitDepth: number = DefaultBitDepth\n): Maybe<[number, number]> {\n  return map(GeoRadix.decode(geohashString), ea => ungeohash_num(ea, bitDepth))\n}\n\n/**\n * @return [latitude, longitude]\n */\nexport function ungeohash_num(\n  geohashNum: number,\n  bitDepth: number = DefaultBitDepth\n): [number, number] {\n  return map(\n    bitUnzip(geohashNum, {\n      dims: [\n        {\n          min: -180,\n          max: 180\n        },\n        {\n          min: -90,\n          max: 90\n        }\n      ],\n      bitDepth: toNearestBitDepth(bitDepth)\n    }),\n    arr => arr.reverse()\n  ) as any\n}\n\nexport function geoHashToLocation(\n  geohashNum: number,\n  bitDepth: number = DefaultBitDepth\n): GeoLocation {\n  const [lat, lon] = ungeohash_num(geohashNum, bitDepth)\n  return { lat, lon }\n}\n\nconst EarthDiaMeters = 12742000\n\nexport function geohashDistanceMeters(\n  geohash1: Maybe<number>,\n  geohash2: Maybe<number>\n): Maybe<number> {\n  if (geohash1 == null || geohash2 == null) return\n  if (geohash1 === geohash2) return 0\n  return distanceMeters(\n    geoHashToLocation(geohash1),\n    geoHashToLocation(geohash2)\n  )\n}\n\n// http://www.movable-type.co.uk/scripts/latlong.html\nexport function distanceMeters(a: GeoLocation, b: GeoLocation) {\n  const phi1 = (a.lat * Math.PI) / 180 // \u03C6, \u03BB in radians\n  const phi2 = (b.lat * Math.PI) / 180\n  const deltaPhi = ((b.lat - a.lat) * Math.PI) / 180\n  const deltaLambda = ((b.lon - a.lon) * Math.PI) / 180\n  const c =\n    Math.sin(deltaPhi / 2) * Math.sin(deltaPhi / 2) +\n    Math.cos(phi1) *\n      Math.cos(phi2) *\n      Math.sin(deltaLambda / 2) *\n      Math.sin(deltaLambda / 2)\n  const d = Math.atan2(Math.sqrt(c), Math.sqrt(1 - c))\n  return EarthDiaMeters * d\n}\n", "import { Tags } from \"exiftool-vendored\"\nimport { compactBlanks, mapNotEmpty } from \"../../fe/Array\"\nimport { ifNotBlank } from \"../../fe/Blank\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { isNumber, mapInt } from \"../../fe/Number\"\nimport { compactValues } from \"../../fe/Object\"\nimport { thenMap } from \"../../fe/Promise\"\nimport { toA } from \"../../fe/toA\"\nimport { first } from \"../Array\"\nimport { isTrue } from \"../../fe/Boolean\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { mapValidDate } from \"../date/FuzzyDate\"\nimport { validLat, validLon } from \"../GeoHash\"\n\nexport type JsonSidecarTags = Pick<\n  Tags,\n  \"Title\" | \"Description\" | \"GPSLatitude\" | \"GPSLongitude\" | \"GPSAltitude\"\n> & {\n  /**\n   * This is when the photo was uploaded to Google Photos:\n   */\n  creationTime?: Date\n  /**\n   * This is the time the photo was last modified within Google Photos:\n   */\n  modificationTime?: Date\n  /**\n   * This isn't remotely correct. I'm expecting 2019:01:08 17:28:44.740313\n   * (local, UTC-10:00) but I get something like Jan 9, 2019, 3:14:38 AM UTC\n   * (expecting 3:28:44 UTC)\n   */\n  photoTakenTime?: Date\n  imageViews?: number\n  peopleNames?: string[]\n  favorited?: boolean\n}\n\n/*\n\n{\n  \"title\": \"title from JSON!\",\n  \"description\": \"Description from JSON, hurray.\",\n  \"imageViews\": \"0\",\n  \"creationTime\": {\n    \"timestamp\": \"1547019276\",\n    \"formatted\": \"Jan 9, 2019, 7:34:36 AM UTC\"\n  },\n  \"modificationTime\": {\n    \"timestamp\": \"1555097007\",\n    \"formatted\": \"Apr 12, 2019, 7:23:27 PM UTC\"\n  },\n  \"favorited\": true,\n  \"people\": [{\n    \"name\": \"John Doe\"\n  }, {\n    \"name\": \"Jane Doe\"\n  }],\n  \"geoData\": {\n    \"latitude\": 20.927258333333334,\n    \"longitude\": -156.69559722222223,\n    \"altitude\": 34.0,\n    \"latitudeSpan\": 0.0,\n    \"longitudeSpan\": 0.0\n  },\n  \"geoDataExif\": {\n    \"latitude\": 20.927258333333334,\n    \"longitude\": -156.69559722222223,\n    \"altitude\": 34.0,\n    \"latitudeSpan\": 0.0,\n    \"longitudeSpan\": 0.0\n  },\n  \"photoTakenTime\": {\n    \"timestamp\": \"1547003678\",\n    \"formatted\": \"Jan 9, 2019, 3:14:38 AM UTC\"\n  }\n}\n\n*/\n\nfunction parseTimestamp(ea: Maybe<{ timestamp?: string }>): Maybe<Date> {\n  return mapInt(ea?.timestamp, ts => mapValidDate(new Date(ts * 1000), d => d))\n}\n\n/**\n * JSON sidecar from Google Takeouts.\n */\nexport async function readJsonSidecar(\n  jsonFile: PosixFile\n): PromiseMaybe<JsonSidecarTags> {\n  return thenMap(jsonFile.readJson<any>(\"info\"), j => {\n    return compactValues({\n      Title: ifNotBlank(j.title),\n      Description: ifNotBlank(j.description),\n      GPSLatitude: first([j?.geoData?.latitude, j?.geoData?.latitude], lat =>\n        validLat(lat) ? lat : undefined\n      ),\n      GPSLongitude: first([j?.geoData?.longitude, j?.geoData?.longitude], lon =>\n        validLon(lon) ? lon : undefined\n      ),\n      GPSAltitude: first([j?.geoData?.altitude, j?.geoData?.altitude], alt =>\n        isNumber(alt) ? alt : undefined\n      ),\n      favorited: j.favorited == null ? undefined : isTrue(j.favorited),\n      peopleNames: mapNotEmpty(\n        [...toA(j.people), ...toA(j.person)],\n        (arr: any[]) => compactBlanks(arr.map(ea => ea.name))\n      ),\n      creationTime: parseTimestamp(j.creationTime),\n      modificationTime: parseTimestamp(j.modificationTime),\n      photoTakenTime: parseTimestamp(j.photoTakenTime),\n      imageViews: mapInt(j.imageViews, i => i)\n    })\n  })\n}\n", "import { blank, mapNotBlank } from \"../../fe/Blank\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, mapOr } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { Valued } from \"../../fe/Object\"\nimport { escapeRegExp } from \"../RegExp\"\nimport { stripQuotes } from \"../String\"\n\n// HEURISTICS AHOY!\n\nfunction replaceAll(s: string, re: RegExp, replacement = \"\"): string {\n  const str = s.replace(re, replacement)\n  return str === s ? s : replaceAll(str, re, replacement)\n}\n\nconst CamelCasedCos = [\n  \"BenQ\",\n  \"GoPro\",\n  \"HTC\",\n  \"LG\",\n  \"NEC\",\n  \"OnePlus\",\n  \"Sony\",\n  \"TrueHDR\"\n]\nconst Lower2Camel = new Map(CamelCasedCos.map(ea => [ea.toLowerCase(), ea]))\n\nexport function companyCased(str: string): string {\n  const s = str.trim()\n  const m = Lower2Camel.get(s.toLowerCase())\n  return m != null\n    ? m\n    : s.length < 4\n    ? s\n    : s.toLowerCase().replace(/(?:^|\\s|-)\\S/g, c => c.toUpperCase())\n}\n\ntype NamedPattern = [RegExp, string]\n\nclass Constants {\n  readonly ignorables = [\n    \"ag\",\n    \"camera\",\n    \"co\",\n    \"company\",\n    \"computer\",\n    \"corp\",\n    \"corporation\",\n    \"digital\",\n    \"elec\",\n    \"electric\",\n    \"electronics\",\n    \"fototechnic\",\n    \"global\",\n    \"gmbh\",\n    \"group\",\n    \"imaging\",\n    \"inc\",\n    \"international\",\n    \"ltd\",\n    \"optical\",\n    \"photo\",\n    \"products\",\n    \"technologies\",\n    \"technology\",\n    \"techwin\"\n  ].join(\"|\")\n\n  readonly ignorableSep = \"[\\\\s\\\\.,_-]*\"\n\n  readonly IgnorableMakePatterns = new RegExp(\n    `${this.ignorableSep}(?:${this.ignorables})${this.ignorableSep}$`,\n    \"i\"\n  )\n\n  readonly IgnorableModelPatterns = [\n    // Some camera models (like Motorola's Droid X) end in a hex serial number. We don't need that:\n    /[0-9a-f]{24,}$/i,\n    // Some camera models have a version number (!!):\n    /\\(v\\d+.\\d+\\)\\w?$/i,\n    // Some digital cameras are less sure of themselves, and need to reassert there digital camera-ness:\n    /digital camera$/i\n  ]\n\n  // TODO: https://www.gazelle.com/thehorn/2013/06/10/how-to-identify-your-samsung-galaxy-smartphone/\n\n  readonly samsungPatterns: NamedPattern[] = [\n    [/^PL150 /, \"PL150\"],\n    [\n      /^SCH-I545|SHV-E300|SGH-I337|SGH-M919|SPH-L720|SCH-R970|SGH-N045|GT-I950/i,\n      \"Galaxy S4\"\n    ],\n    [/^SGH-i537|GT-I9295/, \"Galaxy S4 Active\"],\n    [/^GT-S50\\S+|SM-G90/, \"Galaxy S5\"],\n    [/^SM-G870A/, \"Galaxy S5 Active\"],\n    [/^SM-A30\\S+/, \"Galaxy A3\"],\n    [/^SM-A530/, \"Galaxy A8\"],\n    [/^SM-A700\\S+/, \"Galaxy A7\"],\n    [/^SM-A730/, \"Galaxy A8+\"],\n    [/^SM-G920\\S+/, \"Galaxy S6\"],\n    [/^SM-G925\\S+/, \"Galaxy S6 Edge\"],\n    [/^SM-G928/, \"Galaxy S6 Edge+\"],\n    [/^SM-G930\\S+/, \"Galaxy S7\"],\n    [/^SM-G935\\S+/, \"Galaxy S7 Edge\"],\n    [/^SM-G950/, \"Galaxy S8\"],\n    [/^SM-G955/, \"Galaxy S8+\"],\n    [/^SM-G960/, \"Galaxy S9\"],\n    [/^SM-G965/, \"Galaxy S9+\"],\n    [/^SM-G970/, \"Galaxy S10e\"],\n    [/^SM-G973|SM-G977|SC-03|SCV41/, \"Galaxy S10\"],\n    [/^SM-G975|SC-04|SC-05|SCV42/, \"Galaxy S10+\"],\n    [/^SM-G98[01]/, \"Galaxy S20\"],\n    [/^SM-G98[56]/, \"Galaxy S20+\"],\n    [/^SM-G988/, \"Galaxy S20 Ultra\"],\n    [/^SM-J510\\S+/, \"Galaxy J5\"],\n    [/^SM-N900/, \"Galaxy Note 3\"],\n    [/^SM-N910/, \"Galaxy Note 4\"],\n    [/^SM-N920/, \"Galaxy Note 5\"],\n    [/^SM-N930/, \"Galaxy Note 7\"],\n    [/^SM-N950/, \"Galaxy Note 8\"]\n  ]\n\n  readonly lgPatterns: NamedPattern[] = [\n    // https://en.wikipedia.org/wiki/LG_G2#Model_variants\n    [/LG-D80[01235]|LS98|VS98|L-01F/, \"G2\"],\n    [/D85|F400|LS990|US990|VS985/, \"G3\"],\n    [/H81\\d|F500|LS991|US991|VS986/, \"G4\"],\n    [/H850|H858|VS987|H820|LS992|H830|US992|H860N/, \"G5\"],\n    [/H87[0123]|LS993|AS993|US997|VS998/, \"G6\"],\n    [/^(LM-)?G71/i, \"G7\"] // LM-G710N\n  ]\n\n  readonly onePlusPatterns: NamedPattern[] = [\n    // https://en.wikipedia.org/wiki/LG_G2#Model_variants\n    [/A0001/, \"One\"],\n    [/A100\\d/, \"X\"],\n    [/A20\\d\\d/, \"2\"],\n    [/A30\\d\\d/, \"3(T)\"],\n    [/A40\\d\\d/, \"4\"],\n    [/A500\\d/, \"5\"],\n    [/A501\\d/, \"5T\"],\n    [/A600\\d/, \"6\"],\n    [/A601\\d/, \"6T\"],\n    [/GM190\\d/, \"7\"],\n    [/GM19[12]\\d/, \"7 Pro\"],\n    [/HD190\\d/, \"7T\"],\n    [/HD19[12]\\d/, \"7T Pro\"]\n  ]\n\n  readonly CommonNamesByMake: Valued<NamedPattern[]> = {\n    Samsung: this.samsungPatterns,\n    LG: this.lgPatterns,\n    OnePlus: this.onePlusPatterns\n  }\n}\n\nconst i = lazy(() => new Constants())\n\nexport function make(rawMake?: string): Maybe<string> {\n  return mapNotBlank(rawMake, s => {\n    s = stripQuotes(s)\n    s = replaceAll(s, i().IgnorableMakePatterns)\n    s = s.replace(/\\s+app on Apple iDevice$/i, \"\")\n    s = s.replace(/\\bLGE\\b/, \"LG\")\n    s = companyCased(s)\n    return s\n  })\n}\n\n// < Digimax U-CA 5, Kenox U-CA 5 / Kenox U-CA 50 >\n\nconst AncientSamsungModel = /<(.+?)[,/].+>/\n\nexport function model(\n  cleanMake?: string,\n  rawModel?: string\n): string | undefined {\n  if (blank(cleanMake) || blank(rawModel)) {\n    return\n  }\n  // Some Canon will put quotes around the make and model (!!)\n  let m = stripQuotes(rawModel)\n\n  if (cleanMake === \"Samsung\") {\n    const match = AncientSamsungModel.exec(m)\n    if (match != null) {\n      m = match[1]\n    }\n  }\n\n  const commonName = map(\n    i().CommonNamesByMake[cleanMake],\n    (arr: NamedPattern[]) => arr.find(([re]) => m!.match(re) != null)\n  )\n\n  if (commonName != null) {\n    return commonName[1].trim()\n  }\n\n  if (cleanMake === \"Sony\") {\n    m = m\n      .replace(/^(DSLR-A|SLT-A|ILCA-|ILCE-)/, \"\u03B1\")\n      .replace(/7CL/i, \"7c\") // ILCE-7CL is the \u03B17c\n      .replace(/M2$/, \" II\")\n      .replace(/M3$/, \" III\")\n      .replace(/M4$/, \" IV\")\n      .replace(/M5$/, \" V\")\n      .replace(/M6$/, \" VI\")\n      .replace(/M7$/, \" VII\")\n      .replace(/M8$/, \" VIII\")\n      .replace(/M9$/, \" IX\")\n      .replace(/M10$/, \" X\")\n      .replace(/M11$/, \" XI\")\n  }\n\n  if (cleanMake === \"Olympus\") {\n    // Handle \"E-M5MarkIII\"\n    m = mapOr(\n      /^(.+?\\d)mark(i.+?)$/i.exec(m),\n      match => `${match[1]} Mark ${match[2]}`,\n      () => m\n    )\n  }\n\n  if (cleanMake === \"Canon\") {\n    // Handle \"EOS DIGITAL REBEL\"\n    m = m.replace(/( DIGITAL)/i, \"\").replace(/EOS REBEL/i, \"EOS Rebel\") // as per Canon's website\n  }\n\n  for (const re of i().IgnorableModelPatterns) {\n    m = replaceAll(m!, re).trim()\n  }\n\n  // If the make prefixes the model, remove that:\n  m = m.replace(new RegExp(`^${escapeRegExp(cleanMake)}\\\\s+`, \"i\"), \"\")\n  // Even if it's \"HP\":\n  if (\n    cleanMake!.match(/^HP|Hewlett.Packard$/i) != null &&\n    m.match(/^hp\\b/i) != null\n  ) {\n    // Remove \"HP\" prefix:\n    m = m.slice(2).trim()\n  }\n  return m\n}\n", "import { compact, compactBlanks } from \"../../fe/Array\"\nimport { blank, notBlank } from \"../../fe/Blank\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map2, mapOr } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { sigFigs, toFloat } from \"../../fe/Number\"\nimport { toS } from \"../../fe/toS\"\nimport { first } from \"../Array\"\nimport { mkLogger } from \"../Logger\"\nimport { Settings } from \"../settings/Settings\"\nimport { stripPrefixIgnoreCase } from \"../String\"\nimport { make } from \"./MakeModel\"\n\nconst UnknownRE = /\\b(n\\/a|unknown)\\b/i\n\nfunction _compact(arr: Maybe<string>[]): string[] {\n  return arr.filter(ea => {\n    return notBlank(ea) && UnknownRE.exec(ea) == null\n  }) as string[]\n}\n\nexport interface LensInfo {\n  lensMake: string\n  lensModel: string\n  lensInfo?: string\n}\n\nconst logger = lazy(() => mkLogger(\"LensMakeModel\"))\n\nexport function extractLensMakeModel(t: {\n  Make?: string\n  LensType?: string\n  LensID?: string\n  LensSpec?: string\n  LensInfo?: string\n  LensMake?: string\n  LensModel?: string\n}): Maybe<LensInfo> {\n  const lensMake = make(t.LensMake)\n  const Make = make(t.Make)\n  const makes = _compact([lensMake, t.LensMake, Make, t.Make])\n\n  const cleanUpModel = (model: string) => {\n    model = cleanBogusPrecision(model)\n    return makes.reduce(\n      (prev, curr) => stripPrefixIgnoreCase(prev, curr).trim(),\n      model\n    )\n  }\n\n  // \"LensID\" can be quite descriptive, like \"Olympus M.Zuiko Digital ED\n  // 12-100mm F4.0 IS Pro\", but it's also sometimes \"Unknown 7-21mm\"\n\n  // \"LensModel\" is typically shorter than \"LensID\", but still has some branding\n\n  // \"LensInfo\" is typically perfect for short: \"4-6mm f/1.8-2.4\" but sometimes is \"24-105mm f/?\"\n\n  // \"Lens\" doesn't include aperture: \"28.0 - 135.0 mm\"\n\n  // \"LensType\" is a grab bag of random: \"E-Mount, T-Mount, Other Lens or no\n  // lens\", \"n/a\", \"G VR\", \"Canon EF 50mm f/1.4 USM or Other Lens\". I don't think it should be used.\n\n  const lensInfo = first(\n    [t.LensInfo, t.LensSpec, t.LensModel, t.LensID],\n    justLengthAndAperture\n  )\n\n  const lensModels = compact([t.LensID, t.LensModel, t.LensSpec, t.LensInfo])\n\n  logger().debug(\"extractLensMakeModel\", { lensMake, lensInfo, lensModels })\n\n  for (const lensModel of lensModels) {\n    const hasLengthAndAperture = justLengthAndAperture(lensModel) != null\n    logger().debug(\"extractLensMakeModel\", { lensModel, hasLengthAndAperture })\n\n    if (!hasLengthAndAperture) continue\n    if (notBlank(lensMake)) {\n      return {\n        lensMake,\n        lensModel: cleanUpModel(lensModel),\n        lensInfo\n      }\n    }\n\n    if (lensModel.toLowerCase().includes(\"nikkor\")) {\n      return {\n        lensMake: \"Nikon\",\n        lensModel: cleanUpModel(lensModel),\n        lensInfo\n      }\n    }\n    for (const mfg of compactBlanks([\n      lensMake,\n      Make,\n      ...Settings.lensMakes.values\n    ])) {\n      if (lensModel.toLowerCase().includes(mfg.toLowerCase())) {\n        makes.unshift(mfg)\n        return {\n          lensMake: mfg,\n          lensModel: cleanUpModel(lensModel),\n          lensInfo\n        }\n      }\n    }\n  }\n\n  return\n}\n\nexport function justLengthAndAperture(s: Maybe<string>): Maybe<string> {\n  if (blank(s) || toS(s).toLowerCase().includes(\"unknown\")) return\n  const model = normalizeLensModel(\n    s.replace(/\\b(AF-S|DG|Digital|DI|DX|E|ED|HSM|LM|OIS|Pro|R|XF)\\b/gi, \"\")\n  )\n  const length = /[\\d.-]+mm/.exec(model)?.[0]\n  const aperture = /f\\/[\\d.-]+/.exec(model)?.[0]\n  if (length === \"0mm\" || aperture === \"f/0\") return\n  return map2(length, aperture, (l, a) => `${l} ${a}`)\n}\n\nexport function cleanBogusPrecision(s: string, significant = 3): string {\n  return s.replace(/\\d+\\.\\d+/g, m =>\n    mapOr(toFloat(m), ea => String(sigFigs(ea, significant)), m)\n  )\n}\n\nexport function normalizeLensModel(model: string): string {\n  return cleanBogusPrecision(model)\n    .replace(/(\\d) - (\\d)/g, (_, m1, m2) => `${m1}-${m2}`)\n    .replace(/(\\d)\\s+mm\\b/, (_, m1) => m1 + \"mm\")\n    .replace(/\\s+f\\/?(\\d)/i, (_, m1) => \" f/\" + m1)\n}\n", "import { Tags } from \"exiftool-vendored\"\nimport { uniq } from \"../../fe/Array\"\nimport { mapNotBlank, notBlank } from \"../../fe/Blank\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { compactValues } from \"../../fe/Object\"\nimport { toS } from \"../../fe/toS\"\nimport { OriginalTags } from \"./ExifTags\"\n\nexport function extractTitleDescription(t: Tags & OriginalTags) {\n  // from <https://exiftool.org/forum/index.php?topic=1464.msg6370#msg6370>\n\n  // Olympus sometimes adds OLYMPUS DIGITAL CAMERA as the ImageDescription, but\n  // also includes that string as the \"CameraID\". In any event, if the title or\n  // description matches the camera id, or \"OLYMPUS DIGITAL CAMERA\", it's not\n  // valid, and we should look elsewhere for the title or description.\n\n  const not = uniq([\n    \"OLYMPUS DIGITAL CAMERA\",\n    t.originalMake,\n    t.originalModel,\n    t.Model,\n    t.Make,\n    t.CameraID\n  ]).map(ea => mapNotBlank(ea, s => s.trim().toLowerCase().normalize()))\n\n  const first = (...fieldNames: (keyof Tags)[]): Maybe<string> => {\n    for (const fieldName of fieldNames) {\n      const s = toS(t[fieldName]).trim()\n      if (notBlank(s) && !not.includes(s.toLowerCase().normalize())) {\n        return s\n      }\n    }\n    return\n  }\n\n  return compactValues({\n    title: first(\"XPTitle\", \"Title\", \"ObjectName\"),\n    description: first(\n      \"XPSubject\",\n      \"Description\",\n      \"ImageDescription\",\n      \"Caption-Abstract\"\n    )\n  })\n}\n", "import { close, open, read, stat } from \"fs-extra\"\nimport { orElse } from \"../../fe/Maybe\"\nimport { thenMap } from \"../async/Promise\"\nimport { mapGte0 } from \"../Number\"\n\n/**\n * @param position where to begin reading from in the file\n * @param length the number of bytes to read\n */\nexport async function readFilePart(\n  nativePath: string,\n  position: number = 0,\n  length?: number\n) {\n  let fd = -1\n  try {\n    const bufLen = await orElse<number>(\n      length,\n      () => thenMap(stat(nativePath), ea => ea.size - position) as any\n    )\n    const b = Buffer.alloc(bufLen)\n    fd = await open(nativePath, \"r\")\n    return await read(fd, b, 0, bufLen, position)\n  } finally {\n    await mapGte0(fd, close)\n  }\n}\n", "import { Readable } from \"stream\"\nimport { Dimensions } from \"../../fe/Dimensions\"\nimport { stringify } from \"../../fe/JSON\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { thenMap } from \"../async/Promise\"\nimport { cacheDir } from \"../CacheDir\"\nimport { onError } from \"../error/Error\"\nimport { FatalErrorFlag } from \"../error/ErrorTypes\"\nimport { WrappedError } from \"../error/WrappedError\"\nimport { readFileType } from \"../fs/FileType\"\nimport { shortFsStringSha } from \"../fs/Hash\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { mkLogger } from \"../Logger\"\nimport { isProd } from \"../NodeEnv\"\nimport { ensurePrefix, splitEvery } from \"../String\"\nimport { readRawTags } from \"../tags/ExifTags\"\nimport { isMimetypeSupported } from \"../tags/Mimetypes\"\nimport { extractRotation } from \"../tags/Orientation\"\nimport { extractSizeInfo } from \"../tags/SizeInfo\"\nimport { sharpReadable } from \"./SharpReadable\"\n\nconst sharp = require(\"sharp\")\n\nconst logger = lazy(() => mkLogger(\"ImgCache\"))\n\nexport const ImgCacheName = \"imgcache\"\n// NOTE: sync service is in charge of cleaning cacheDir. See `setup()`.\n\n/**\n * @throws if imgCacheDir cannot be created.\n */\nexport async function imgCacheDir() {\n  return cacheDir()\n    .join(ImgCacheName)\n    .mkdirp_()\n    .catch(err => {\n      onError(\"Failed to create imgCache directory\" + FatalErrorFlag, err)\n      return undefined\n    })\n}\n\nexport async function emptyImgCacheDir() {\n  if (isProd) throw new Error(\"emptyImgCacheDir is for tests\")\n  await thenMap(imgCacheDir(), d =>\n    thenMap(d.children(), arr => Promise.all(arr.map(ea => ea.rmrf())))\n  )\n}\n\n/**\n * @throws on error\n */\nexport async function cachedImgFile(\n  src: PosixFile,\n  desc: string,\n  ext: string\n): Promise<PosixFile> {\n  const stat = await src.stat()\n  if (stat == null) {\n    throw new Error(`cachedImgFile(${src}): unreadable`)\n  }\n  const dir = await imgCacheDir()\n  if (dir == null) throw new Error(\"imgcache dir is missing\")\n\n  // SHA for large files over a NAS is expensive. This assumes a file with the\n  // same size, mimetype, and basename is the same:\n\n  const ft = await readFileType(src.nativePath)\n  if (ft == null) throw new Error(\"Cannot read filetype for \" + src)\n\n  // Truncated to 24 to hopefully avoid max path issues on windows: (linux\n  // kernel has to truncate to 15 chars (64 bits) to avoid collisions, so 24 at\n  // base32 (120 bits) should be fine). we could probably get away with\n  // dropping all the files directly into the imgtmp dir because they have to be\n  // cleaned up, but having 2-deep directories (1024 * 1024) should cover at\n  // least an hour of processing:\n\n  const sha = shortFsStringSha(\n    stringify({\n      basename: src.base.toLowerCase(),\n      mimetype: ft.mime,\n      size: stat.size\n    })\n  )\n\n  ext = ensurePrefix(ext, \".\")\n\n  const result = dir.join(...splitEvery(sha.slice(0, 24), 2, 3), desc + ext)\n  if (null == (await result.parent().mkdirp())) {\n    throw new Error(\"Cannot make dest dir, \" + result.parent())\n  }\n  logger().debug(\"cachedImgFile(\" + src.baseWithGrandparent + \")\", {\n    desc,\n    ext,\n    result\n  })\n  return result\n}\n\n/**\n * Only applies the readable thunk if the tmpfile doesn't already exist.\n *\n * @throws if f() has issues generating a readable, or the readable has errors\n * during stream.\n */\nexport async function readableToFile({\n  src,\n  desc,\n  suffix,\n  f\n}: {\n  src: PosixFile\n  desc: string\n  suffix: string\n  f: () => PromiseMaybe<Readable>\n}): PromiseMaybe<PosixFile> {\n  try {\n    return await thenMap(cachedImgFile(src, desc, suffix), dest =>\n      dest.applyIfEmpty_(async tmp =>\n        thenMap(f(), readable => tmp.writeStream_(readable))\n      )\n    )\n  } catch (cause) {\n    throw new WrappedError({ cause, message: \"readableToFile() failed\" })\n  }\n}\n\n/** Only applies the thunk if the tmpfile doesn't already exist */\nexport async function withImgCache(\n  src: PosixFile,\n  desc: string,\n  ext: string,\n  applyIfEmpty: (dest: PosixFile) => Promise<any>\n): PromiseMaybe<PosixFile> {\n  try {\n    return await thenMap(cachedImgFile(src, desc, ext), dest =>\n      dest.applyIfEmpty_(applyIfEmpty)\n    )\n  } catch (err) {\n    logger().warn(\"readableToFile(\" + src + \"): \" + err)\n    throw err\n  }\n}\n\nexport async function prepFileForBrowser(\n  file: PosixFile,\n  info: { userAgent?: string } & Dimensions\n) {\n  if (await file.notExists()) return\n  const t = await readRawTags(file, true) // < we want the sidecar rotation\n  const mt = t?.MIMEType\n  const rot = orElse(extractRotation(t), 0)\n  const sizeInfo = map(t, ea => extractSizeInfo(ea, rot))\n  const minDim = orElse(sizeInfo?.dimensions, info)\n  if (minDim == null) {\n    logger().warn(\"prepFileForBrowser(): no file dimensions\", {\n      file,\n      si: sizeInfo,\n      info\n    })\n    return\n  }\n  const croppedDim = { width: minDim.width - 32, height: minDim.height - 32 }\n\n  if (isMimetypeSupported(mt, info.userAgent) && rot === 0) {\n    return file\n  }\n  logger().info(\"prepFileForBrowser(): non-browser-supported mimetype\", {\n    file,\n    mt,\n    info\n  })\n\n  return withImgCache(file, \"web-\" + rot, \".jpg\", async dest =>\n    thenMap(sharpReadable(file, croppedDim), async sr =>\n      sharp(sr.nativePath).rotate(rot).toFile(dest.nativePath)\n    )\n  )\n}\n", "import { isSqliteBusyError } from \"../../core/error/ErrorTypes\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { delay } from \"../../fe/Delay\"\nimport { SyncOrAsync } from \"../../fe/OptAsync\"\nimport { randomInt } from \"../../fe/Random\"\n\n/**\n * @param f MUST BE IDEMPOTENT\n */\nexport async function handleDbRetries<T>(\n  f: () => SyncOrAsync<T>,\n  onRetry?: () => any\n): Promise<T> {\n  const start = Date.now()\n  let retries = 0\n  const timeoutAt = start + Settings.maxBusyDbMs.valueOrDefault\n  while (Date.now() < timeoutAt) {\n    try {\n      return await f()\n    } catch (err) {\n      if (!isSqliteBusyError(err) || Date.now() >= timeoutAt) {\n        throw err\n      } else {\n        onRetry?.()\n        // give the other process time to unlock:\n        await delay(randomInt(500, 1500) * ++retries)\n      }\n    }\n  }\n  throw new Error(\n    \"handleDbRetries(): timeout after \" +\n      Settings.maxBusyDbMs.valueOrDefault +\n      \"ms\"\n  )\n}\n\nexport function handleDbRetriesSync<T>(f: () => T, maxErrors = 25): T {\n  let lastError: Error\n  for (let retry = 0; retry < maxErrors; retry++) {\n    try {\n      return f()\n    } catch (err) {\n      lastError = err\n      if (!isSqliteBusyError(err)) {\n        throw err\n      }\n    }\n  }\n  throw lastError!\n}\n", "import { lazy } from \"../../fe/Lazy\"\nimport { mkLogger } from \"../Logger\"\nimport { Broadcaster } from \"./Broadcaster\"\n\nconst logger = lazy(() => mkLogger(\"Broadcaster\"))\n\nnamespace NoOpBroadcasterImpl {\n  export const broadcast = async (event: string, args?: any) => {\n    logger().warn(\"broadcast sent to no-op\", { event, args })\n    return false\n  }\n}\n\nexport const NoOpBroadcaster: Broadcaster = NoOpBroadcasterImpl\n", "import { Event } from \"../event/SimpleEventEmitter\"\nimport { NoOpBroadcaster } from \"./NoOpBroadcaster\"\n\n/**\n * Broadcast allows for events from the web service to be sent to all db\n * clients. Note that this means the main process won't receive this event.\n */\nexport interface Broadcaster {\n  broadcast(event: Event, args?: any): any\n}\n\nlet defaultBroadcaster: Broadcaster = NoOpBroadcaster\n\nexport function setBroadcaster(b: Broadcaster) {\n  defaultBroadcaster = b\n}\n\nexport function setBroadcasterIfUnset(b: Broadcaster) {\n  if (defaultBroadcaster === NoOpBroadcaster) defaultBroadcaster = b\n}\n\nexport function broadcast(event: Event, args?: any) {\n  defaultBroadcaster.broadcast(event, args)\n}\n", "import { FSWatcher, watch } from \"fs-extra\"\nimport { hostname } from \"os\"\nimport { pid } from \"process\"\nimport { leastBy, partition } from \"../core/Array\"\nimport { EndableRanks, ending } from \"../core/async/Endable\"\nimport { EndableWrapper } from \"../core/async/EndableWrapper\"\nimport { memoizeAsync } from \"../core/async/MemoizedAsyncFunc\"\nimport { thenCompact } from \"../core/async/Promise\"\nimport { setUnrefInterval } from \"../core/async/Timers\"\nimport { eqlAsyncPicked } from \"../core/Eql\"\nimport {\n  DoNotSendErrorFlag,\n  FatalErrorFlag,\n  NonRetriableErrorFlag\n} from \"../core/error/ErrorTypes\"\nimport { onClearCache } from \"../core/event/EventEmitter\"\nimport { shortFsStringSha } from \"../core/fs/Hash\"\nimport { CreatedAt } from \"../core/fs/JsonFileStore\"\nimport { PosixFile } from \"../core/fs/PosixFile\"\nimport { mkLogger } from \"../core/Logger\"\nimport { existingPids } from \"../core/Ps\"\nimport {\n  isMainService,\n  isSyncFileService,\n  isWebService,\n  ServiceName,\n  serviceName,\n  serviceNameIndex\n} from \"../core/ServiceNames\"\nimport { libraryDataDir } from \"../core/settings/LibraryDirs\"\nimport { Settings } from \"../core/settings/Settings\"\nimport { CmdTimeoutMs } from \"../core/volumes/VolumeTtls\"\nimport { isEmpty, isNotEmpty } from \"../fe/Array\"\nimport { thenOrTimeout } from \"../fe/AsyncRetry\"\nimport { hourMs, secondMs } from \"../fe/Date\"\nimport { lazy } from \"../fe/Lazy\"\nimport { map, mapOr, orElse } from \"../fe/Maybe\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { randomInt } from \"../fe/Random\"\nimport { toA } from \"../fe/toA\"\n\nexport interface OpenedByJson extends CreatedAt {\n  hostname: string\n  systemUID: string\n  pid: number\n  serviceName: ServiceName\n  createdAt: number\n  updatedAt: number\n  file?: PosixFile\n}\n\nexport const maybeRemovePriorLocks = lazy(async () => {\n  if (Settings.forceOpen.valueOrDefault) {\n    const ldd = libraryDataDir()\n    if (ldd != null) {\n      await thenOrTimeout(\n        async () =>\n          Promise.all(toA(await openedByFiles(ldd)).map(ea => ea.unlink())),\n        7 * secondMs\n      )\n    }\n  }\n})\n\nexport const StaleMs = hourMs // allow the disk to go to sleep\n\n/**\n * @param ldd library data dir\n */\nfunction openedByDir(ldd: Maybe<PosixFile>) {\n  return map(ldd, ea => ea.join(\"opened-by\"))\n}\n\n// only exposed for tests\nexport function openedByFiles(ldd: Maybe<PosixFile>) {\n  const dir = openedByDir(ldd)\n  // clear to make sure the children are current:\n  return dir?.clear().children(ea => ea.ext === \".json\")\n}\n\nexport async function isLockOwner() {\n  return mapOr(\n    libraryDataDir(),\n    async ldd =>\n      eqlAsyncPicked(\n        currentLibraryLockOwner(ldd),\n        expectedJson(),\n        \"hostname\",\n        \"pid\"\n      ),\n    async () => false\n  )\n}\n\nexport const expectedJson = lazy(async () => ({\n  hostname: hostname(),\n  pid\n}))\n\nexport const currentLibraryLockOwner = memoizeAsync(\n  (ldd: PosixFile) => _currentLibraryLockOwner(ldd),\n  {\n    maxSize: 3,\n    timeoutMs: CmdTimeoutMs,\n    // random retry to avoid concurrent lock checks:\n    clearEveryMs: randomInt(7 * secondMs, CmdTimeoutMs)\n  }\n)\n\nasync function _currentLibraryLockOwner(ldd: PosixFile) {\n  await maybeRemovePriorLocks()\n  const cleanupFiles = !isSyncFileService()\n  const l = mkLogger(\"currentLibraryLockOwner(\" + ldd + \")\")\n  const thisHostname = hostname()\n  const children = await openedByFiles(ldd)\n  if (isEmpty(children)) {\n    l.warn(\"no opened-by files found.\")\n    return\n  }\n  const jsons = await thenCompact(\n    children.map(async file => {\n      const json = await file.readJson<OpenedByJson>()\n      if (\n        cleanupFiles &&\n        json == null &&\n        true !== (await file.modifiedCloseTo(Date.now(), CmdTimeoutMs))\n      ) {\n        l.warn(\"unlinking old empty json file: \" + file)\n        await file.unlink(\"debug\")\n        return\n      } else {\n        return { file, ...json } as OpenedByJson\n      }\n    })\n  )\n\n  l.debug(\"read\", { jsons })\n\n  const minUpdatedAt = Date.now() - StaleMs\n\n  const [freshJsons, staleJsons] = partition(\n    jsons,\n    ea => ea.updatedAt > minUpdatedAt\n  )\n  if (cleanupFiles && isNotEmpty(staleJsons)) {\n    l.debug(\"Unlinking expired opened-by files:\", {\n      minUpdatedAt,\n      staleJsons\n    })\n    await Promise.all(staleJsons.map(ea => ea.file?.unlink(\"debug\")))\n  }\n\n  const [localJsons, externalJsons] = partition(\n    freshJsons,\n    ea => ea.hostname === thisHostname\n  )\n\n  const localPids = localJsons.map(ea => ea.pid)\n\n  // if we can't list current pids, assume they're all alive:\n  const alivePids = orElse(await existingPids(localPids), localPids)\n\n  const [aliveLocalJsons, zombieLocalJsons] = partition(localJsons, ea =>\n    alivePids.includes(ea.pid)\n  )\n\n  if (cleanupFiles && isNotEmpty(zombieLocalJsons)) {\n    l.debug(\"Unlinking zombie opened-by files:\", zombieLocalJsons)\n    await Promise.all(zombieLocalJsons.map(ea => ea.file?.unlink()))\n  }\n\n  const validJsons = [...aliveLocalJsons, ...externalJsons]\n  if (isEmpty(validJsons)) {\n    l.debug(\"No valid opened-by files.\")\n    return\n  }\n\n  const earliestJson = leastBy(validJsons, ea => ea.createdAt)!\n  const winningHostJsons = validJsons.filter(\n    ea => ea.systemUID === earliestJson.systemUID\n  )\n\n  const result = leastBy(winningHostJsons, ea => [\n    serviceNameIndex(ea.serviceName),\n    orElse(ea.createdAt, () => Date.now()) // tiebreak with earliest\n  ])\n  return l.tap({ msg: \"currentLibraryLockOwner\", level: \"info\", result })\n}\n\nonClearCache(() => currentLibraryLockOwner.clear())\n\n/**\n * Consumers should access this through Library.instance().openedBy().\n *\n * Libraries cannot be opened by separate hosts concurrently due to SQLite\n * needing to be on a local filesystem.\n *\n * Only one process on a given host should run \"database janitor\" tasks, like\n * periodic vacuuming, copying back to the library, and finalizing the library\n * copy on shutdown.\n *\n * The janitor process is the \"best\" process sorting by `[service name\n * hierarchy, pid]`.\n */\nexport class OpenedByIO extends EndableWrapper {\n  private readonly createdAt = Date.now()\n  readonly dir: PosixFile\n  private timer: Maybe<NodeJS.Timer>\n  private readonly watchers: FSWatcher[] = []\n  readonly intervalMs = StaleMs / 4\n\n  /**\n   * @param ldd library data dir\n   */\n  constructor(readonly ldd: PosixFile) {\n    super(\"OpenedByIO()\", () => this.onEnd(), EndableRanks.postdb)\n    this.dir = ldd.join(\"opened-by\")\n\n    // Release the lock only after the db is closed.\n    this.timer = setUnrefInterval(() => this.write_(), this.intervalMs)\n  }\n\n  clear() {\n    this.file.unset()\n    this.json.unset()\n    this.lockOwner.unset()\n    this.write_.unset()\n  }\n\n  refresh_() {\n    this.clear()\n    return this.write_()\n  }\n\n  private async onEnd() {\n    this.watchers.forEach(ea => ea.close())\n    this.watchers.length = 0\n    map(this.timer, clearInterval)\n    this.timer = undefined\n    await this.file().unlink()\n  }\n\n  async deleteAllLocks(includeMe = false) {\n    if (includeMe) {\n      await this.dir.rmrf()\n    } else {\n      await this.dir.visitDescendants(ea =>\n        ea.eql(this.file()) ? undefined : ea.unlink()\n      )\n    }\n  }\n\n  readonly file = lazy(() =>\n    this.dir.join(shortFsStringSha(hostname(), 7) + \"-\" + pid + \".json\")\n  )\n\n  // lazy for testing:\n  readonly json = lazy(\n    async () => ({\n      serviceName: serviceName(),\n      createdAt: this.createdAt,\n      updatedAt: Date.now(),\n      ...(await expectedJson())\n    }),\n    this.intervalMs / 2\n  )\n\n  readonly write_ = lazy(async () => {\n    const json = await this.json()\n    await this.file().writeJSON_(json)\n    currentLibraryLockOwner.clear()\n  }, this.intervalMs / 2)\n\n  // CAREFUL! Most functions rely on setup() (like this.isLockOwner())\n  readonly setup = lazy(async () => {\n    await this.write_()\n    if (isMainService()) {\n      for (const f of this.file().selfAndParents(4)) {\n        try {\n          // This may fail for UNC or remote filesystems:\n          const w = watch(\n            f.nativePath,\n            { persistent: false, recursive: false },\n            () => this.lockOwner.refresh()\n          ).on(\"error\", err => {\n            this.logger.warn(\"watch().on(error):\", err)\n            return this.lockOwner.refresh()\n          })\n          this.watchers.push(w)\n        } catch (err) {\n          this.logger.warn(\"Failed to set up watch\", { f: f.nativePath, err })\n        }\n      }\n    }\n  })\n\n  readonly lockOwner = lazy(async () => {\n    if (ending()) return\n    await this.setup()\n    return currentLibraryLockOwner(this.ldd)\n  }, 7 * secondMs)\n\n  async isLockOwner(): Promise<boolean> {\n    // lockOwner runs this.setup:\n    return eqlAsyncPicked(this.lockOwner(), expectedJson(), \"hostname\", \"pid\")\n  }\n\n  async throwIfUnavailable(from: any) {\n    this.logger.debug(\"throwIfAvailable()\", { from })\n\n    const lo = await this.lockOwner()\n    this.logger.debug(\"throwIfAvailable()\", { from, lockOwner: lo })\n\n    if (lo == null) return\n\n    const json = await this.json()\n    this.logger.debug(\"throwIfAvailable()\", { from, json })\n\n    if (lo != null && lo.hostname !== json.hostname) {\n      this.logger.warn(\"library is unavailable\", { lockOwner: lo, json })\n      throw new Error(\n        `Library is already opened by ${lo.hostname} (${lo.serviceName}:${lo.pid}) ${from}` +\n          // web service shouldn't crap out if they're just trying to change the\n          // library path:\n          (isWebService() ? \"\" : FatalErrorFlag) +\n          DoNotSendErrorFlag +\n          NonRetriableErrorFlag\n      )\n    }\n  }\n}\n", "import net from \"net\"\nimport { end } from \"../../core/async/Endable\"\nimport { thenOrTimeout } from \"../../core/async/thenOrTimeout\"\nimport { HealthCheckResult } from \"../../core/child/HealthChecks\"\nimport { mkLogger } from \"../../core/Logger\"\nimport { Client } from \"../../core/rpc/Client\"\nimport { isRpcServer } from \"../../core/ServiceNames\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { Volume } from \"../../core/volumes/Volume\"\nimport { notBlank } from \"../../fe/Blank\"\nimport { minuteMs, secondMs } from \"../../fe/Date\"\nimport { Latch } from \"../../fe/Latch\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\n\nconst logger = mkLogger(\"RpcClient\")\n\nfunction connect(port: number): Promise<net.Socket> {\n  const l = new Latch()\n  const socket = new net.Socket()\n  socket.on(\"error\", err => l.reject(err))\n  socket.connect(port, \"localhost\", () => {\n    logger.debug(\"Connected to \" + port)\n    void l.resolve()\n  })\n  return l.then(() => socket)\n}\n\nexport interface RpcClient {\n  request(method: \"libraryPath\"): Promise<string>\n  request(method: \"isVacuuming\"): Promise<boolean>\n  request(method: \"healthChecks\"): Promise<HealthCheckResult>\n  request(method: \"mountpoints\"): PromiseMaybe<string[]>\n  request(method: \"volumes\"): PromiseMaybe<Volume[]>\n}\n\nexport const rpcClient = lazy<Maybe<RpcClient & Client>>(() => {\n  if (isRpcServer()) return\n  const port = Settings.rpcPort.valueOrDefault\n  logger.debug(\"Creating new RPC client to \" + port)\n  const c = new Client(\"db@localhost:\" + port, () => connect(port))\n  // TODO: always start with a ping? (to verify the socket and send our service\n  // info to the server)\n  c.addChangeListener(() => rpcClientReady.unset())\n  return c\n})\n\n/**\n * This has an aggressive timeout to prevent hanging\n */\nexport const rpcClientReady = lazy(async () => {\n  try {\n    if (isRpcServer()) return false\n    const pong = await thenOrTimeout(\n      map(rpcClient(), ea => ea.ping()),\n      secondMs\n    )\n    return notBlank(pong)\n  } catch (err) {\n    logger.warn(\"rpcClientReady(): ping failed\", err)\n    return false\n  }\n}, minuteMs)\n\nexport function rpcClientEnd() {\n  return end(rpcClient.clear())\n}\n", "import { pid } from \"process\"\nimport { Duplex } from \"stream\"\nimport { blank, notBlank } from \"../../fe/Blank\"\nimport { minuteMs, secondMs } from \"../../fe/Date\"\nimport { stringify } from \"../../fe/JSON\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { gt } from \"../../fe/Number\"\nimport { EndableRanks, ending } from \"../async/Endable\"\nimport { EndableWrapper } from \"../async/EndableWrapper\"\nimport { Later } from \"../async/Later\"\nimport { thenMap } from \"../async/Promise\"\nimport { PromiseTimer } from \"../async/PromiseTimer\"\nimport { RetriableErrorFlag } from \"../error/ErrorTypes\"\nimport { eventEmitter } from \"../event/EventEmitter\"\nimport { Event } from \"../event/SimpleEventEmitter\"\nimport { onDataChunked } from \"../fs/StreamChunker\"\nimport { endStream } from \"../fs/Streams\"\nimport { Rate } from \"../math/Rate\"\nimport { isTest } from \"../NodeEnv\"\nimport { serviceName } from \"../ServiceNames\"\nimport { uid } from \"../UID\"\nimport { RequestResponse } from \"./RequestResponse\"\n\nconst DefaultRequestTTL = (isTest ? 7 : 30) * secondMs\nconst DefaultDelayBetweenRetries = isTest ? 500 : 5 * secondMs\n\nexport interface ClientOpts {\n  requestTTL: number\n  retriesPerRequest: number\n  delayBetweenRetries: number\n  maxPendingRequests: number\n}\n\nconst DefaultOpts: ClientOpts = {\n  requestTTL: DefaultRequestTTL,\n  retriesPerRequest: 5, // enough time for web to restart\n  delayBetweenRetries: DefaultDelayBetweenRetries,\n  maxPendingRequests: 10\n}\n\n// Ensures requests go to the correct client:\nlet instanceCount = 0\n\n/**\n * `Client`s make requests to `Server`s. RPC uses [JSON Lines](http://jsonlines.org/)\n */\nexport class Client extends EndableWrapper {\n  private sid?: string\n  readonly mkStreamRate = new Rate(minuteMs)\n  private readonly pending = new Map<string, RequestResponse<any>>()\n  readonly times = new PromiseTimer()\n  readonly opts: ClientOpts\n  readonly changeListeners: (() => any)[] = [() => this.mkStreamRate.onEvent()]\n\n  constructor(\n    name: string,\n    readonly streamFactory: Later<Duplex>,\n    opts: Partial<ClientOpts> = {}\n  ) {\n    super(\n      \"rpc.Client(\" + name + \"#\" + instanceCount++ + \")\",\n      () => this.onEnd(),\n      EndableRanks.first\n    )\n    this.opts = { ...DefaultOpts, ...opts }\n    // Open the stream eagerly so we can receive RPC events.\n    void this.stream()\n  }\n\n  private onEnd() {\n    this.logger.info(\"end()\", {\n      ending: ending(),\n      timings: this.times.report(),\n      pendingSize: this.pending.size\n    })\n    this.pending.clear()\n    return this.close()\n  }\n\n  addChangeListener(listener: () => any) {\n    this.changeListeners.push(listener)\n  }\n\n  get flapping() {\n    return this.logger.tap({\n      level: isTest ? \"debug\" : \"trace\",\n      msg: \"flapping()\",\n      result:\n        // If we just failed, assume it'll take a bit for the service to get restored:\n        this.mkStreamRate.msSinceLastEvent < this.opts.delayBetweenRetries ||\n        // we should only rarely need to reconnect:\n        gt(this.mkStreamRate.eventsPerMinute, 3),\n      meta: {\n        msSinceLastStream: this.mkStreamRate.msSinceLastEvent,\n        mkStreamRatePerMin: this.mkStreamRate.eventsPerMinute\n      }\n    })\n  }\n\n  readonly stream = lazy<PromiseMaybe<Duplex>>(async () => {\n    try {\n      if (this.flapping) {\n        return this.onError(\n          \"stream() is restarting too frequently (epm: \" +\n            this.mkStreamRate.eventsPerMinute +\n            \")\"\n        )\n      }\n      const d = await this.streamFactory()\n      if (d == null) {\n        return this.onError(\"streamFactory() returned null\")\n      }\n      this.changeListeners.forEach(ea => ea())\n      d.on(\"end\", (err: any) => this.onFinish(\"on(end)\", err))\n      d.on(\"close\", (err: any) => this.onFinish(\"on(close)\", err))\n      d.on(\"error\", err => this.onError(\"stream error\", err))\n      void onDataChunked(d, \"\\n\", buf => this.onData(buf))\n      return d\n    } catch (err) {\n      return this.onError(\"streamFactory rejection\", err)\n    }\n  })\n\n  readonly ping = lazy(\n    () => this.request(\"ping\", { serviceName: serviceName(), pid }),\n    250\n  )\n\n  /**\n   * Ask the server to broadcast this event on our behalf:\n   */\n  broadcast(event: Event, args: any) {\n    return this.request(\"broadcast\", { event, args })\n  }\n\n  sendRecentLogs() {\n    return this.request(\"sendRecentLogs\")\n  }\n\n  /**\n   * @return true if we aren't ended, and don't have too many pending\n   * requests, and we don't have too many recent errors\n   */\n  async ready(): Promise<boolean> {\n    if (this.ended) {\n      this.logger.debug(\"ready(): false (ended)\")\n      return false\n    }\n    return null != (await this.stream())\n  }\n\n  /**\n   * Handles submission retries\n   */\n  async request(method: string, params?: any): Promise<any> {\n    if (this.ended) {\n      if (ending()) return\n      else throw new Error(\"client is ending\")\n    }\n    if (blank(method)) {\n      throw new Error(\"method cannot be blank\")\n    }\n    return this.submit(method, params)\n    // return await retryOnReject(() => this.submit(method, params), {\n    //   maxRetries: this.opts.retriesPerRequest,\n    //   onRetryWaitUntil: retryCount =>\n    //     unrefDelay(this.opts.delayBetweenRetries * retryCount).then(() =>\n    //       until(() => this.ready(), this.opts.requestTTL)\n    //     ),\n    //   errorIsRetriable: err => isRetriableError(err)\n    // })\n  }\n\n  private async submit(method: string, params?: any) {\n    const s = await this.stream()\n    if (s == null) {\n      return this.onError(\"submit(\" + method + \"): stream is closed\")\n    }\n    const id = uid()\n    const rr = new RequestResponse(id, method, params, this.times)\n    rr.setTimeout(this.opts.requestTTL)\n    this.pending.set(id, rr)\n    rr.d.finally(() => this.pending.delete(id))\n    this.logger.log(isTest ? \"debug\" : \"trace\", \"sending request\", {\n      id,\n      method,\n      params\n    })\n    s.write(\n      stringify({\n        id,\n        method,\n        params\n      }) + \"\\n\"\n    )\n    return rr.response\n  }\n\n  /**\n   * This only shuts down the current connection. A new connection will be made\n   * when necessary.\n   */\n  close() {\n    this.logger.info(\"close()\", { ended: this.ended })\n    return thenMap(this.stream.clear(), endStream)\n  }\n\n  private onData(req: string) {\n    if (blank(req)) {\n      return\n    }\n    try {\n      this.logger.log(isTest ? \"debug\" : \"trace\", \"onData()\", { req })\n      const resp = JSON.parse(req)\n      if (blank(resp.sid)) {\n        throw new Error(\"response is missing server id\")\n      }\n      if (this.sid !== resp.sid) {\n        if (this.sid != null) {\n          this.logger.info(\"server id changed\", {\n            priorSid: this.sid,\n            newSid: resp.sid\n          })\n          eventEmitter.emit(\"rpcServerChange\")\n        }\n        this.sid = resp.sid\n        if (ending()) return // end ASAP.\n      }\n      if (resp.id == null) {\n        if (notBlank(resp.event)) {\n          // Support broadcasting events from the db server (this is how\n          // pause/resume works, and opening a file from the browser)\n          this.logger.trace(\"re-broadcasting event\", resp)\n          eventEmitter.emit(resp.event, resp.args)\n          return\n        } else {\n          throw new Error(\"missing request id from response\")\n        }\n      }\n      const rr = this.pending.get(resp.id)\n      this.pending.delete(resp.id)\n      if (rr == null) {\n        this.logger.warn(\"unknown or stale request ID\", {\n          resp,\n          pendingIds: [...this.pending.keys()]\n        })\n      } else {\n        if (resp.error != null) {\n          rr.reject(resp.error)\n          this.logger.warn(\"Rejected\", { resp, rr })\n        } else {\n          rr.resolve(resp.result)\n          this.logger.debug(\"Resolved\", resp.result)\n        }\n        // Note that we don't delete rr from this.pending, so we can get\n        // error rate for free\n      }\n    } catch (err) {\n      this.logger.warn(\"invalid input: \" + req, err)\n    }\n    return\n  }\n\n  private async onError(source: string, err?: any) {\n    this.logger.warn(\n      source + \" onError(): \" + map(err, ea => orElse(ea.stack, ea))\n    )\n    return this.restart()\n  }\n\n  async restart(): PromiseMaybe<Duplex> {\n    this.logger.info(\"restart()\", {\n      ended: this.ended,\n      flapping: this.flapping\n    })\n\n    await this.close()\n\n    if (this.ended || ending()) {\n      this.logger.warn(\"restart(): Ending. Rejecting new connection.\")\n      return\n    }\n\n    if (this.flapping) {\n      this.logger.warn(\n        \"restart(): Too many recent errors, we'll try reconnecting again in a bit\",\n        { errPerMin: this.mkStreamRate.eventsPerMinute }\n      )\n      return\n    }\n\n    const stream = await this.stream()\n\n    if (null != stream) {\n      const pending = [...this.pending.values()]\n      this.pending.clear()\n      this.logger.info(\n        \"restart(): got a new socket, resubmitting \" +\n          pending.length +\n          \" jobs now.\"\n      )\n      pending.forEach(rr => rr.reject(\"restarting\" + RetriableErrorFlag))\n      return stream\n    } else {\n      this.logger.warn(\"restart(): stream() returned null\")\n      return\n    }\n  }\n\n  private onFinish(source: string, error: any) {\n    if (this.ended) return\n    // the close event may give us `false` (!?)\n    const restarting = error == null || error === false\n    this.logger.info(\"onFinish\", { source, error, restarting })\n    return restarting ? this.restart() : this.onError(source, error)\n  }\n}\n", "import { hostname } from \"os\"\nimport { pid } from \"process\"\nimport { lazy } from \"../fe/Lazy\"\nimport { shortStringSha } from \"./fs/Hash\"\nimport { GeoRadix } from \"./math/Radix\"\n\nlet i = 0\n\nconst uidPrefix = lazy(\n  () => shortStringSha(hostname() + String.fromCharCode(31) + pid) + \"-\"\n)\n\n/**\n * Create a short unique-ish ID from the hostname, PID and a counter.\n *\n * DOES NOT comply with UUID standards because STANDARDS ARE FOR THE WEAK and\n * javascript doesn't have threads because JAVASCRIPT IS FOR THE WEAK wait wut\n *\n * Note that the uid must be filename-safe, as it is used by FsLock.\n */\nexport function uid(): string {\n  return uidPrefix() + GeoRadix.encode(++i)\n}\n", "import { inspect } from \"util\"\nimport { map } from \"../../fe/Maybe\"\nimport { Deferred } from \"../async/Deferred\"\nimport { PromiseTimer } from \"../async/PromiseTimer\"\n\n// const logger = lazy(() => mkLogger(\"RequestResponse\"))\n\n/**\n * Holds the request context, an ID, and a deferred that receives the RPC\n * response.\n */\nexport class RequestResponse<T> {\n  readonly name: string\n  readonly start = Date.now()\n  readonly d: Deferred<T>\n\n  constructor(\n    readonly id: string,\n    readonly method: string,\n    readonly params: T,\n    readonly timer: PromiseTimer\n  ) {\n    this.name = \"rpc.RequestResponse(\" + method + \")#\" + id\n    this.d = new Deferred<T>(this.name)\n  }\n\n  [inspect.custom]() {\n    return {\n      ctor: \"RequestResponse\",\n      id: this.id,\n      method: this.method,\n      params: this.params,\n      response: this.d\n    }\n  }\n\n  get pending(): boolean {\n    return this.d.pending\n  }\n\n  setTimeout(timeoutMs: number) {\n    this.d.setTimeout(timeoutMs)\n  }\n\n  resolve(resp: T) {\n    if (this.d.pending) {\n      this.d.resolve(resp)\n      map(this.d.settledMs, ea => this.timer.push(this.method, ea))\n    }\n  }\n\n  reject(reason?: any) {\n    return this.d.reject(reason)\n  }\n\n  get rejected(): boolean {\n    return this.d.rejected\n  }\n\n  get response(): Promise<T> {\n    return this.d.promise\n  }\n}\n", "import { onVacuuming } from \"../../core/event/EventEmitter\"\nimport { mkLogger } from \"../../core/Logger\"\nimport { broadcast } from \"../../core/rpc/Broadcaster\"\nimport { isTrue } from \"../../fe/Boolean\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { thenMap } from \"../../fe/Promise\"\nimport { isLockOwner } from \"../OpenedBy\"\nimport { rpcClient } from \"../rpc/RpcClient\"\nimport { Db } from \"./Db\"\n\nlet _vacuuming: Maybe<boolean>\n\nconst logger = lazy(() => mkLogger(\"Vacuum\"))\n\nexport function isVacuuming(db?: Db) {\n  return db == null || db.schema === \"models\"\n    ? isTrue(_vacuuming)\n    : // no stats db vacuuming:\n      false\n}\n\nconst setVacuuming = async (value: boolean) => {\n  if (typeof value !== \"boolean\") {\n    logger().throw(\"invalid setVacuuming argument\", { value })\n  }\n  logger().debug(\"setVacuuming()\", { value })\n  _vacuuming = value\n}\n\nonVacuuming(setVacuuming)\n\nexport async function checkRemoteVacuuming() {\n  return thenMap(rpcClient()?.request(\"isVacuuming\"), value => {\n    logger().info(\"checkRemoteVacuuming() received RPC value\", { value })\n    return map(value, setVacuuming)\n  })\n}\n\nexport async function withVacuumEvent<T>(f: () => Promise<T>): PromiseMaybe<T> {\n  if (!(await isLockOwner())) {\n    logger().info(\"withVacuumEvent(): no-op, I'm not the lock owner.\")\n    return\n  }\n  logger().info(\"db vacuum starting...\")\n  try {\n    _vacuuming = true\n    broadcast(\"vacuuming\", true)\n    return await f()\n  } finally {\n    _vacuuming = false\n    broadcast(\"vacuuming\", false)\n    logger().info(\"db vacuum finished.\")\n  }\n}\n", "import { Database } from \"better-sqlite3\"\nimport { untilTrue } from \"../../core/async/until\"\nimport {\n  isSqliteBusyError,\n  isSqliteDisconnectedError\n} from \"../../core/error/ErrorTypes\"\nimport { mkLogger } from \"../../core/Logger\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { retryOnReject } from \"../../fe/AsyncRetry\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { delay } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { randomInt } from \"../../fe/Random\"\nimport { Db } from \"./Db\"\nimport { handleDbRetries } from \"./DbRetries\"\nimport { isVacuuming } from \"./Vacuum\"\n\nconst logger = lazy(() => mkLogger(\"Transactions\"))\n\nconst MaxVacuumingTimeMs = minuteMs\nconst MaxRetries = 10\n\nlet _expectErrors = false\n\nexport async function tx<T>(\n  db: Db,\n  f: (database: Database) => T,\n  expectErrors: boolean = false,\n  iAmTheVacuumNow: boolean = false\n): Promise<T> {\n  if (db.db == null) throw new Error(\"tx(): null db\")\n  try {\n    if (expectErrors) _expectErrors = true\n\n    if (!iAmTheVacuumNow && isVacuuming(db)) {\n      if (\n        null ==\n        (await untilTrue(() => !isVacuuming(db), {\n          timeoutMs: MaxVacuumingTimeMs\n        }))\n      ) {\n        logger().throw(\"Timeout while waiting for external vacuum to complete\")\n      }\n    }\n\n    return await retryOnReject(\n      async () => {\n        return db.inTransaction\n          ? f(db.db!) // < no nested transactions or savepoints\n          : handleDbRetries(\n              () =>\n                db\n                  .db!.transaction(() => f(db.db!))\n                  // deferred to allow reads to not need write locks:\n                  .deferred(),\n              db.onRetry\n            )\n      },\n      {\n        maxRetries: MaxRetries,\n        errorIsRetriable: async err => {\n          if (expectErrors || _expectErrors) return false\n          logger().warn(\"errorIsRetriable()\", err)\n          if (isSqliteBusyError(err) || isSqliteDisconnectedError(err)) {\n            // Immediately close the db so the next access will re-open it:\n            db.closeDb()\n            logger().warn(\"Trying to reopen the db \" + db.dbfile)\n            return true\n          }\n          return false\n        },\n        timeoutMs: Settings.maxBusyDbMs.valueOrDefault / 10,\n        onRetryWaitUntil: retryCount => {\n          const delayMs = randomInt(\n            10,\n            Settings.maxBusyDbMs.valueOrDefault / (MaxRetries - retryCount)\n          )\n          logger().warn(\"onRetryWaitUntil()\", { retryCount, delayMs })\n          return delay(delayMs)\n        }\n      }\n    )\n  } catch (err) {\n    if (expectErrors || _expectErrors) {\n      return undefined as any\n    } else {\n      logger().warn(\"tx(): raised\", err)\n      throw err\n    }\n  } finally {\n    if (expectErrors) _expectErrors = false\n  }\n}\n", "import { DateTime, DateTimeFormatOptions } from \"luxon\"\nimport { blank, mapNotBlank, notBlank } from \"../../fe/Blank\"\nimport { dayMs, secondMs } from \"../../fe/Date\"\nimport { getOrSet } from \"../../fe/Map\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { mapNumeric } from \"../../fe/Number\"\nimport { opt } from \"../../fe/Opt\"\nimport { firstThunk } from \"../Object\"\nimport { isString } from \"../String\"\nimport { closeTo, dateTimeToLocal, isRecentMs } from \"./Date\"\nimport { DateInterval } from \"./DateInterval\"\nimport { Dated, datedToMillis, mapValidDate, validDate } from \"./FuzzyDate\"\n\nexport function recent(d: Maybe<Date | number>, delta = 5 * secondMs): boolean {\n  return isRecentMs(\n    map(d, ea => datedToMillis(ea)),\n    delta\n  )\n}\n\nexport function fmtDateTime(\n  dateTime?: DateTime,\n  locale?: string,\n  // Don't use FULL, because the friendly human offset name isn't known.\n  opts: DateTimeFormatOptions = DateTime.DATETIME_MED\n) {\n  return mapValidDate(dateTime, dt => {\n    mapNotBlank(locale, ea => (dt = dt.setLocale(ea)))\n    return dt.toLocaleString(opts)\n  })\n}\n\nconst BadMsRE = /(\\.\\d\\d\\d)\\d+/\n\nexport function isoToDateTime(iso: Maybe<string>): Maybe<DateTime> {\n  if (blank(iso)) return\n  return opt(\n    DateTime.fromISO(\n      iso.replace(BadMsRE, (_, m) => m),\n      { setZone: true }\n    )\n  )\n    .filter(ea => ea.isValid)\n    .orElse(() => map(DateInterval.fromISO(iso), ea => ea.middle.toDateTime()))\n    .get()\n}\n\nconst locale2dtf = new Map<string, Intl.DateTimeFormat>()\n\nexport function fmtDateShort(d: number | Dated, locale = \"en-US\"): string {\n  return getOrSet(\n    locale2dtf,\n    locale,\n    () =>\n      new Intl.DateTimeFormat(locale, {\n        weekday: \"long\",\n        year: \"numeric\",\n        month: \"long\",\n        day: \"numeric\",\n        hour: \"numeric\",\n        minute: \"numeric\"\n      })\n  ).format(datedToMillis(d))\n}\n\nexport function fmtDateIso(\n  isoDate: string,\n  locale?: string,\n  // Don't use FULL, because the friendly human offset name isn't known.\n  opts: DateTimeFormatOptions = DateTime.DATETIME_MED\n): string {\n  return opt(DateTime.fromISO(isoDate, { setZone: true }))\n    .filter(validDate)\n    .orElse(() =>\n      map(DateInterval.fromISO(isoDate), ea => ea.middle.toDateTime())\n    )\n    .map(ea => fmtDateTime(ea, locale, opts))\n    .getOrElse(() => isoDate)!\n}\n\n/**\n * @returns `yMMddHHmmssCC`, where CC is centiseconds, or millis / 10, so max js\n * int, 9007 19 92 54 74 09 91, is not overwhelmed\n */\nexport function isoToLocal(iso: Maybe<string>): Maybe<number> {\n  return map(isoToDateTime(iso), dateTimeToLocal)\n}\n\nconst ymdIsoRE = /^\\d{1,4}-\\d{2}-\\d{2}$/\n\nexport function isoToPrecisionMs(iso: Maybe<string>): Maybe<number> {\n  return mapNotBlank(iso, s =>\n    firstThunk(\n      () => map(DateInterval.fromISO(s), ea => ea.intervalMs),\n      () =>\n        opt(s.match(ymdIsoRE))\n          .flatMap(() => DateTime.fromISO(s))\n          .filter(validDate)\n          .map(() => dayMs)\n          .get(),\n      () =>\n        opt(DateTime.fromISO(s))\n          .filter(validDate)\n          .map(() => 0)\n          .get()\n    )\n  )\n}\n\nexport function parseJsonDate(\n  d: Maybe<string | { formatted: string; timestamp: number }>\n) {\n  if (d == null) return\n  if (isString(d)) return isoToDateTime(d)?.toJSDate()\n  const ts = d?.timestamp\n  const fmt = d?.formatted\n  const tsDate = mapNumeric(ts, ea => new Date(ea * secondMs))\n  if (notBlank(fmt)) {\n    const fmtDate = new Date(fmt)\n    if (!closeTo(tsDate, fmtDate, secondMs)) return\n  }\n  return tsDate\n}\n", "import { map2Or } from \"../Maybe\"\nimport { Maybe } from \"../MaybeTypes\"\nimport { gt, gt0, gte0 } from \"../Number\"\n\nexport interface ID {\n  id: number\n  v: number\n}\n\nexport type IDish = ID | number | { assetId: number } | { tagId: number }\n\n/**\n * @returns numeric id\n */\nexport function id2id(id: IDish): Maybe<number> {\n  const a = id as any\n  return a == null\n    ? undefined\n    : gt0(a)\n    ? a\n    : gt(a.id, -20) // < we use small negative numbers as sentinels\n    ? a.id\n    : gt0(a.assetId)\n    ? a.assetId\n    : gte0(a.tagId)\n    ? a.tagId\n    : undefined\n}\n\n/**\n * An ID is \"equal\" to a number if the number equals the `id`.\n *\n * If both are numbers, or both are instances of ID, use `eql`.\n */\nexport function idEql(a: IDish, b: IDish): boolean {\n  return map2Or(\n    id2id(a),\n    id2id(b),\n    (i, j) => i === j,\n    () => false\n  )\n}\n", "import { id2id, IDish } from \"./api/ID\"\nimport { compact } from \"./Array\"\nimport { ReducerName, ReducerNames } from \"./ImageReducers\"\nimport { SqWidths } from \"./ImageSizes\"\nimport { stringify } from \"./JSON\"\nimport { map, orElse } from \"./Maybe\"\nimport { StringValued } from \"./Object\"\nimport { ThumbSize } from \"./ThumbSizes\"\nimport { toS } from \"./toS\"\n\nexport class AssetUrls {\n  private static pageImageCount = 0\n\n  static onNewPage() {\n    this.pageImageCount = 0\n  }\n\n  readonly assetId: number\n  readonly query: string = \"\"\n\n  /**\n   * id === asset id\n   */\n  constructor(id: IDish, query: string = \"\") {\n    this.query = query\n    this.assetId = id2id(id)!\n    if (this.assetId == null) {\n      throw new Error(\"internal error: null asset id \" + stringify({ id }))\n    }\n  }\n\n  get unset() {\n    // Is this a placeholder asset thumbnail (to make streams line up)?\n    return this.assetId == null || this.assetId <= 0\n  }\n\n  assetUrl() {\n    return this.unset ? \"\" : `/asset/${this.assetId}${this.query}`\n  }\n\n  linkAttrs() {\n    return this.unset\n      ? {}\n      : {\n          href: this.assetUrl()\n        }\n  }\n\n  /**\n   * Sends a resized preview\n   */\n  imgLink(reducerName: ReducerName, width: number) {\n    // Must match ImgRouter:\n    return `/img/${this.assetId}/${reducerName}/${width}${this.query}`\n  }\n  /**\n   * Sends the full \"shown\" asset\n   */\n  imgActualLink(assetFileId?: number) {\n    // Must match ImgActualRouter:\n    return `/img/${compact([this.assetId, assetFileId]).join(\"/\")}/actual${\n      this.query\n    }`\n  }\n\n  videoLink(assetFileId: number) {\n    return `/video/${this.assetId}-${assetFileId}${this.query}`\n  }\n\n  sqImgAttrs(lazyLoad?: boolean, ts: ThumbSize = \"m\") {\n    return {\n      ...this.imgAttrs(\"sq\", SqWidths, lazyLoad),\n      // This is only directionally accurate. It's the max size expected for the\n      // given thumb size.\n      sizes: ts === \"s\" ? \"80px\" : ts === \"m\" ? \"160px\" : \"320px\"\n    }\n  }\n\n  imgAttrs(\n    reducer: ReducerName,\n    widths: number[],\n    lazyLoad?: boolean,\n    af?: { assetFileId: number; width: number }\n  ) {\n    if (this.unset) {\n      return { src: \"/images/clear-64.png\" }\n    }\n    const width = Math.min(...widths)\n    const attrs: StringValued = { width: toS(width) }\n    const src = this.imgLink(reducer, width)\n    AssetUrls.pageImageCount++\n    lazyLoad = orElse(lazyLoad, () => AssetUrls.pageImageCount > 72)\n\n    if (lazyLoad) {\n      attrs.src = \"/images/clear-64.png\"\n      attrs[\"data-src\"] = src\n    } else {\n      attrs.src = src\n    }\n\n    // TODO: safari and safari mobile doesn't support lazy loading.\n    // attrs.loading = lazyLoad ? \"lazy\" : \"eager\"\n\n    if (reducer === ReducerNames.sq) {\n      // attrs.sizes is set in the frontend based on the current thumbnail size.\n      attrs.height = toS(width)\n    }\n    const srcSetArr = widths.map(w => mkSrcSet(this.imgLink(reducer, w), w))\n    map(af, ea => srcSetArr.push(mkSrcSet(this.imgActualLink(), ea.width)))\n    attrs[(lazyLoad ? \"data-\" : \"\") + \"srcSet\"] = srcSetArr.join(\",\")\n    return attrs\n  }\n}\n\nfunction mkSrcSet(url: string, width: number) {\n  return url + \" \" + width + \"w\"\n}\n", "import { sort } from \"../Array\"\nimport { stringify } from \"../JSON\"\nimport { mapNumeric } from \"../Number\"\nimport { Valued } from \"../Object\"\nimport { isString } from \"../String\"\nimport { assembleUri } from \"../URI\"\nimport { AssetId } from \"./Asset\"\n\nexport const ThumbsPerSample = 128\n\nexport const BeforeAfterStreamLimit = 8 // NOTE: must match gallery-grid SCSS (which expects)\n\n// Returned from /api/tag/:tagId.json\n\nexport interface ApiTag {\n  tagId: number // root is 0\n  tagPath: string[]\n  description?: string\n  displayPath: string[]\n  assetCount: number\n  assetFileCount: number\n  releasedAt?: number // millis timestamp, used for sorting albums\n}\n\nexport interface TagAssetsCriteria {\n  tagId: number\n  capturedAtLt?: number // millis timestamp\n  capturedAtGt?: number\n  limit: number\n}\n\n// Returned from /api/t/:tagId/assets?capturedAtLt=456\nexport interface TagAssets {\n  tagId: number\n  assetIds: AssetId[] // may be paged, not prng'ed\n  // TODO: prevAssets?: TagAssetsCriteria // /api/tag/:tagId/assets.json?capturedAtGt=123\n  nextAssets?: TagAssetsCriteria // /api/tag/:tagId/assets.json?capturedAtLt=123\n}\n\nexport function nextAssetsUrl(tagId: number, crit: TagAssetsCriteria): string {\n  const params: Valued<string> = {}\n  mapNumeric(crit.capturedAtLt, lt => (params.capturedAtLt = lt.toString()))\n  mapNumeric(crit.capturedAtGt, gt => (params.capturedAtGt = gt.toString()))\n  mapNumeric(crit.limit, limit => (params.limit = limit.toString()))\n  // we don't call it \"/api/tag/$tagId\" because it's ambiguous with the tag-path\n  // endpoint:\n  return assembleUri(`/api/t/${tagId}/assets`, params)\n}\n\nexport interface ChildTagCriteria {\n  tagId: number\n  seed: number\n  limit?: number\n  offset?: number\n}\n\nexport type ChildTag = ApiTag & TagAssets\n\n// Returned from /api/t/:tagId/child-tags?seed=123&offset=0\nexport interface ChildTags {\n  tagId: number\n  childTagCount: number\n  childTags: ChildTag[]\n  nextChildTags?: ChildTagCriteria\n}\n\nexport function nextChildTagsUrl(\n  tagId: number,\n  crit: ChildTagCriteria\n): string {\n  const params: Valued<string> = {}\n  mapNumeric(crit.seed, ea => (params.seed = ea.toString()))\n  mapNumeric(crit.limit, ea => (params.limit = ea.toString()))\n  mapNumeric(crit.offset, ea => (params.offset = ea.toString()))\n  // we don't call it \"/api/tag/$tagId\" because it's ambiguous with the tag-path\n  // endpoint:\n  return assembleUri(`/api/t/${tagId}/child-tags`, params)\n}\n\n// Returned from /api/tag/:tagId.json\nexport interface ApiTagGallery extends ApiTag, TagAssets, ChildTags {\n  emptyLibrary?: boolean\n  startingUp?: boolean\n}\n\nexport const TagGalleryProps: (keyof ApiTagGallery)[] = [\n  \"tagId\",\n  \"tagPath\",\n  \"assetCount\",\n  \"assetIds\",\n  \"nextAssets\",\n  \"childTags\",\n  \"nextChildTags\"\n]\n\nexport interface TagGalleryContext {\n  seed: number\n  tagIds: number[]\n}\n\nexport function ctxToS(ctx: TagGalleryContext): string {\n  return stringify({ seed: ctx.seed, tagIds: sort([...ctx.tagIds]) })\n}\n\nexport interface TagRef {\n  name: string\n  displayName?: string\n  ordinal?: number\n  description?: string\n  releasedAt?: number // millis timestamp\n}\n\nexport type TagPath = (string | TagRef)[]\n\nexport const TagRoots = Object.freeze({\n  When: \"When\",\n  Who: \"Who\",\n  Where: \"Where\",\n  What: \"What\",\n  Camera: \"Camera\",\n  Lens: \"Lens\",\n  Albums: \"Albums\",\n  Keywords: \"Keywords\",\n  Type: \"Type\",\n  FS: \"fs\"\n})\n\nexport const NotInfoPanelTags = [\n  TagRoots.When,\n  TagRoots.Camera,\n  TagRoots.Lens,\n  TagRoots.Type,\n  TagRoots.FS\n]\n\nexport function isInfoTag(rootNameOrTag: string | ApiTag) {\n  if (rootNameOrTag == null) return false\n  const root = isString(rootNameOrTag)\n    ? rootNameOrTag\n    : rootNameOrTag.tagPath?.[0]\n  return !NotInfoPanelTags.includes(root)\n}\n", "import { Dated, getDay, getMonth, getYear } from \"../../core/date/FuzzyDate\"\nimport { onClearCache } from \"../../core/event/EventEmitter\"\nimport { PosixFile } from \"../../core/fs/PosixFile\"\nimport { locale } from \"../../core/Locale\"\nimport { mapGt0, within } from \"../../core/Number\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { stripSuffix } from \"../../core/String\"\nimport { bestCapturedAt, CapturedAt } from \"../../core/tags/CapturedAt\"\nimport { readTags } from \"../../core/tags/ExifTags\"\nimport { TagPath, TagRef, TagRoots } from \"../../fe/api/Tag\"\nimport { isEmpty, range } from \"../../fe/Array\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { thenMap } from \"../../fe/Promise\"\nimport { toS } from \"../../fe/toS\"\n\nconst dtf = lazy(\n  async () =>\n    new Intl.DateTimeFormat(await locale(), {\n      month: \"short\"\n    })\n)\n\nconst months = lazy(async () => {\n  const f = await dtf()\n  // There are rendering bugs (!!) for 1998-4-1, 2003-4-1, 1998-11-1, 2003-11-1,\n  // ... so we just capture the month names once for a known-correct year.\n  return range(0, 12, i => f.format(new Date(2016, i, 1))).map(ea =>\n    // Some locales (like en-CA) end with period:\n    stripSuffix(ea, \".\")\n  )\n})\n\nonClearCache(() => {\n  dtf.unset()\n  months.unset()\n})\n\nexport function yearToOrdinal(year: number): number {\n  // Y10K COME AT ME BRO\n  return 10000 - year\n}\n\nexport function monthToOrdinal(oneIndexedMonth: number): number {\n  return 13 - oneIndexedMonth\n}\n\nexport function ordinalToMonth(monthTagOrdinal: number): number {\n  return 13 - monthTagOrdinal\n}\n\nexport function dayToOrdinal(oneIndexedMonth: number): number {\n  return 33 - oneIndexedMonth\n}\n\nexport function yearTagRef(year: number): Maybe<TagRef> {\n  return mapGt0(year, ea => ({ name: toS(ea), ordinal: yearToOrdinal(ea) }))\n}\n\nexport async function monthTagRef(\n  oneIndexedMonth: Maybe<number>\n): PromiseMaybe<TagRef> {\n  if (!within(1, 12, oneIndexedMonth)) return\n  return map((await months())[oneIndexedMonth - 1], monthName =>\n    // ordinal makes months order in reverse chron:\n    ({\n      name: String(oneIndexedMonth),\n      displayName: monthName,\n      ordinal: monthToOrdinal(oneIndexedMonth)\n    })\n  )\n}\n\nexport function dayTagRef(day: Maybe<number>): Maybe<TagRef> {\n  return mapGt0(day, ea => ({ name: toS(ea), ordinal: dayToOrdinal(ea) }))\n}\n\nexport async function dateTag(date: Maybe<Dated>): PromiseMaybe<TagPath> {\n  const s = toS(Settings.tagYMD.valueOrDefault).toLowerCase()\n\n  if (date == null || s === \"\" || s === \"off\" || s.startsWith(\"disable\")) return // date tagging is disabled\n\n  // i18n happens in a layer above this:\n  const result: TagPath = [TagRoots.When]\n\n  if (s.startsWith(\"y\")) {\n    const y = map(getYear(date), yearTagRef)\n    if (y == null) return\n    result.push(y)\n  }\n  if (s.startsWith(\"ym\")) {\n    const m = await map(getMonth(date), monthTagRef)\n    if (m == null) return result // just take the year.\n    result.push(m)\n  }\n  if (s.startsWith(\"ymd\")) {\n    const m = map(getDay(date), dayTagRef)\n    if (m == null) return result // just take the month.\n    result.push(m)\n  }\n  return result\n}\n\nexport async function dateTagFile(\n  file: PosixFile,\n  capturedAts: CapturedAt[]\n): PromiseMaybe<TagPath> {\n  if (Settings.tagYMD.valueOrDefault === \"\") return\n\n  const arr = [...capturedAts]\n\n  if (isEmpty(capturedAts)) {\n    await thenMap(readTags(file), t => arr.push(t.capturedAt))\n  }\n  const best = bestCapturedAt(arr)\n\n  if (\n    best == null ||\n    (best.src.startsWith(\"stat\") && !Settings.tagDateFromStat.valueOrDefault)\n  ) {\n    return\n  }\n\n  return dateTag(best.date)\n}\n", "import { TagPath, TagRoots } from \"../../fe/api/Tag\"\nimport {\n  compactBlanks,\n  mapNotEmpty,\n  notEmptyOr,\n  sortBy,\n  uniq\n} from \"../../fe/Array\"\nimport { blank, mapNotBlankOr } from \"../../fe/Blank\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Defined, map } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { toA } from \"../../fe/toA\"\nimport { mkLogger } from \"../Logger\"\nimport { escapeRegExp, matchQuotes } from \"../RegExp\"\nimport { Settings } from \"../settings/Settings\"\nimport { spliceCapture } from \"../String\"\n\nconst logger = lazy(() => mkLogger(\"Names\"))\n\n// const cleanupRE = /^,?\\s*(\\S.+?)\\s*,?$/\n\n// function cleanup(s: string) {\n//   return spliceCapture(s.trim(), cleanupRE)?.captured\n// }\n\n// function cleanupName(given: string, family: string) {\n//   return {\n//     given: cleanup(given),\n//     family: cleanup(family)\n//   }\n// }\n\nfunction escRE(s: string) {\n  return matchQuotes(escapeRegExp(s))\n}\n\nfunction familyNameREs() {\n  return Settings.tagNamesSurnames.values.map(\n    ea => new RegExp(\"\\\\b(\" + escRE(ea) + \")\\\\b\", \"i\")\n  )\n}\n\nfunction givenNameREs() {\n  return Settings.tagNamesGiven.values.map(\n    ea => new RegExp(\"\\\\b(\" + escRE(ea) + \")\\\\b\", \"i\")\n  )\n}\n\nfunction familyNamePrefixeREs() {\n  return mapNotEmpty(\n    compactBlanks(Settings.tagNamesSurnamePrefixes.values),\n    arr =>\n      sortBy(arr, ea => -ea.length).map(\n        ea => new RegExp(`\\\\b(${escRE(ea)}\\\\s+\\\\S+)`, \"i\")\n      )\n  )\n}\n\nfunction givenNameSurroundREs() {\n  const arr = compactBlanks(Settings.tagNamesGivenSurrounds.values)\n  for (const ea of arr) {\n    if (ea.length !== 2) {\n      logger().warn(\n        \"Settings.tagNamesFamilySurrounds has an invalid value:\",\n        ea\n      )\n    }\n  }\n  return arr.map(\n    ea =>\n      new RegExp(\n        `(${escapeRegExp(ea.charAt(0))}\\\\s*[^${escapeRegExp(\n          ea.charAt(0)\n        )}]+\\\\s*${escapeRegExp(ea.charAt(1))})`,\n        \"i\"\n      )\n  )\n}\n\nfunction familyNameSurroundREs() {\n  const arr = compactBlanks(Settings.tagNamesFamilySurrounds.values)\n  for (const ea of arr) {\n    if (ea.length !== 2) {\n      logger().warn(\n        \"Settings.tagNamesFamilySurrounds has an invalid value:\",\n        ea\n      )\n    }\n  }\n  return arr.map(\n    ea =>\n      new RegExp(\n        `${escapeRegExp(ea.charAt(0))}\\\\s*([^${escapeRegExp(\n          ea.charAt(0)\n        )}]*)\\\\s*${escapeRegExp(ea.charAt(1))}`,\n        \"i\"\n      )\n  )\n}\n\nconst lifespanRE = /(\\(\\s*\\d+\\s*-\\s*(?:[\\d\\?]{1,4})?\\s*\\)?)/\n\nconst modifierRE = /(,?\\s*(?:jr\\.?|junior|sr.?|senior|i+\\.?))$/i\n\nconst uppercaseWordsRE = /\\b([A-Z\u2018\u2019']+(?:[-A-Z\u2018\u2019']{2}))\\b/\n\n/**\n * Parse the given name into familyNames, givenNames, an optional modifier and\n * optional lifespan.\n */\nexport function parseName(compoundName: string) {\n  if (blank(compoundName)) return\n\n  let s = compoundName.trim()\n\n  const lifespan = map(spliceCapture(s, lifespanRE), r => {\n    s = r.unmatched.trim()\n    // normalize whitespace:\n    return r.captured.replace(/\\s+/g, \"\")\n  })\n\n  // Strip off Bob Smith, jr.\n  const modifier = map(spliceCapture(s, modifierRE), r => {\n    s = r.unmatched.trim()\n    return r.captured.trim()\n  })\n\n  const givenNames: string[] = []\n  const givenNameEnds: string[] = []\n  const familyNames: string[] = []\n\n  for (const re of givenNameREs()) {\n    const r = spliceCapture(s, re)\n    if (r != null) {\n      givenNames.push(r.captured)\n      s = r.unmatched.trim()\n    }\n  }\n\n  for (const re of givenNameSurroundREs()) {\n    let r\n    do {\n      r = spliceCapture(s, re)\n      if (r != null) {\n        givenNameEnds.push(r.captured)\n        s = r.unmatched.trim()\n      }\n    } while (r != null)\n  }\n\n  let minFamilyNameIndex: Maybe<number>\n\n  function onCapture(r: Defined<ReturnType<typeof spliceCapture>>) {\n    if (minFamilyNameIndex == null || minFamilyNameIndex > r.matchedIndex) {\n      minFamilyNameIndex = r.matchedIndex\n    }\n  }\n\n  if (Settings.tagNamesCapitalizedAsFamily.valueOrDefault) {\n    let r\n    do {\n      r = spliceCapture(s, uppercaseWordsRE)\n      if (r != null) {\n        onCapture(r)\n        familyNames.push(r.captured)\n        s = r.unmatched.trim()\n      }\n    } while (r != null)\n  }\n\n  for (const re of familyNameSurroundREs()) {\n    let r\n    do {\n      r = spliceCapture(s, re)\n      if (r != null) {\n        onCapture(r)\n        familyNames.push(r.captured)\n        s = r.unmatched.trim()\n      }\n    } while (r != null)\n  }\n\n  // if (Settings.tagNamesParentheticalSurnames.valueOrDefault) {\n  //   let r\n  //   do {\n  //     r = spliceCapture(s, parenNameRE)\n  //     if (r != null) {\n  //       onCapture(r)\n  //       familyNames.push(r.captured)\n  //       s = r.remnants.trim()\n  //     }\n  //   } while (r != null)\n  // }\n\n  if (Settings.tagNamesLexical.valueOrDefault) {\n    const commaIndex = s.indexOf(\",\")\n    if (commaIndex >= 0) {\n      minFamilyNameIndex = undefined\n      familyNames.push(s.substring(0, commaIndex).trim())\n      givenNames.push(s.substring(commaIndex + 1).trim())\n      s = \"\"\n    }\n  }\n\n  for (const re of familyNameREs()) {\n    const r = spliceCapture(s, re)\n    if (r != null) {\n      onCapture(r)\n      familyNames.push(r.captured)\n      s = r.unmatched.trim()\n    }\n  }\n\n  for (const re of toA(familyNamePrefixeREs())) {\n    const r = spliceCapture(s, re)\n    if (r != null) {\n      onCapture(r)\n      familyNames.push(r.captured)\n      s = r.unmatched.trim()\n    }\n  }\n\n  if (minFamilyNameIndex != null && s.length > minFamilyNameIndex) {\n    // Everything to the right is a family name.\n    mapNotEmpty(\n      compactBlanks(s.substr(minFamilyNameIndex).split(/\\s+/)),\n      arr => {\n        familyNames.push(...arr)\n        s = s.substr(0, minFamilyNameIndex)\n      }\n    )\n  }\n\n  // OK, by this time we're either looking at an empty string, or [first]\n  // [middle] [last] (we may have pulled off either family names or given names,\n  // so everything is optional)\n\n  const names = compactBlanks(s.split(/\\s+/))\n\n  const givenNameCount = givenNames.length\n  const familyNameCount = familyNames.length\n\n  if (names.length > 0) {\n    // So, we've got leftovers. Where should they go?\n    // If we don't have a family name, and we don't have a given name:\n    if (givenNameCount === 0 && familyNameCount > 0) {\n      // We have a family name. Assume the remainder are given names?\n      givenNames.push(...names)\n    } else if (\n      familyNameCount === 0 &&\n      givenNameCount > 0 &&\n      names.length === 1\n    ) {\n      familyNames.push(...names)\n    } else {\n      if (names.length === 1) {\n        // Assume one name is a given name\n        givenNames.push(...names)\n      } else {\n        // names.length > 1. Last or first name is family name, the remainder is given names.\n        const western = Settings.tagNamesOrder.valueOrDefault === \"western\"\n\n        familyNames.push(western ? names.pop()! : names.shift()!)\n        givenNames.push(...names)\n      }\n    }\n  }\n\n  return {\n    givenNames: uniq(compactBlanks([...givenNames, ...givenNameEnds])),\n    modifier,\n    lifespan,\n    familyNames: uniq(compactBlanks(familyNames))\n  }\n}\n\nfunction join(arr: Maybe<string>[]) {\n  return compactBlanks(arr).join(\" \")\n}\n\nexport function renderNameTag(name: string): TagPath[] {\n  if (blank(name)) {\n    return []\n  } else if (Settings.tagNamesFormatter.valueOrDefault === \"family/given\") {\n    const r = parseName(name)\n    if (r == null) {\n      return []\n    } else {\n      const given = join([\n        join(r.givenNames) +\n          // we don't want to add a space after the modifier:\n          mapNotBlankOr(\n            r.modifier,\n            ea => (ea.startsWith(\",\") ? ea : \" \" + ea.trim()),\n            \"\"\n          ),\n        r.lifespan\n      ])\n      const familyNames = compactBlanks(\n        notEmptyOr(r.familyNames, [\n          Settings.tagNamesDefaultFamily.valueOrDefault\n        ])\n      )\n      return familyNames.map(fam => [TagRoots.Who, fam, given])\n    }\n  } else {\n    return [[TagRoots.Who, name.trim()]]\n  }\n}\n", "import { mapAsync } from \"../../core/async/Promise\"\nimport { PosixFile } from \"../../core/fs/PosixFile\"\nimport { l } from \"../../core/licensing/Licensing\"\nimport { mkLogger } from \"../../core/Logger\"\nimport { valpath } from \"../../core/Object\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { hasAnyIgnoreCase } from \"../../core/String\"\nimport { readRawTags } from \"../../core/tags/ExifTags\"\nimport { readJsonSidecar } from \"../../core/tags/JsonSidecar\"\nimport { renderNameTag } from \"../../core/tags/Names\"\nimport { TagPath, TagRoots } from \"../../fe/api/Tag\"\nimport { flatten, isNotEmpty, uniq } from \"../../fe/Array\"\nimport { blank } from \"../../fe/Blank\"\nimport { map } from \"../../fe/Maybe\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { toA } from \"../../fe/toA\"\nimport { tagRefToS } from \"./Taggers\"\n\nconst logger = mkLogger(\"WhoTagger\")\n\nexport async function whoTagFiles(files: PosixFile[]): PromiseMaybe<TagPath[]> {\n  if (await l()) return\n  // Don't bother to read tags, just read JSON payloads:\n  const names: string[] = []\n\n  if (Settings.tagJsonFaces.valueOrDefault) {\n    const jsonSidecars = flatten(await mapAsync(files, f => f.jsonSidecars()))\n    await mapAsync(jsonSidecars, async f => {\n      const tags = await readJsonSidecar(f)\n      map(tags?.peopleNames, arr => names.push(...arr))\n    })\n  }\n\n  if (Settings.tagFaceRegions.valueOrDefault) {\n    await mapAsync(files, async f => {\n      const tags = await readRawTags(f, true) // include sidecars\n      // Expect something like\n      // {\n      //   \"Area\": {\n      //     \"H\": 0.0653789,\n      //     \"Unit\": \"normalized\",\n      //     \"W\": 0.0318743,\n      //     \"X\": 0.214086,\n      //     \"Y\": 0.178058\n      //   },\n      //   \"Name\": \"First Last\",\n      //   \"Type\": \"Face\"\n      // }\n      for (const region of toA(tags?.RegionInfo?.RegionList)) {\n        if (region[\"Type\"] === \"Face\") {\n          names.push(region[\"Name\"])\n        }\n      }\n    })\n  }\n\n  if (isNotEmpty(Settings.tagWhoNames.values)) {\n    await mapAsync(files, async f => {\n      const tags = await readRawTags(f, true) // include sidecars\n      for (const field of Settings.tagWhoNames.values) {\n        names.push(...toA(valpath(tags, field)))\n      }\n    })\n  }\n\n  const result = uniq(flatten(uniq(names).map(nameTag)))\n\n  return logger.tap({\n    msg: \"whoTagFiles()\",\n    level: \"info\",\n    result,\n    meta: { names, files: files.map(ea => ea.nativePath) }\n  })\n}\n\nexport function isWhoTag(t: TagPath): boolean {\n  return isWhoRoot(tagRefToS(t[0]))\n}\n\nexport function isWhoRoot(s: string) {\n  return (\n    !blank(s) &&\n    hasAnyIgnoreCase([TagRoots.Who, ...Settings.tagWhoSynonyms.values], s)\n  )\n}\n\nexport function nameTag(s: string | string[]) {\n  if (blank(s)) return\n  if (Array.isArray(s)) {\n    if (isWhoRoot(s[0])) {\n      s.shift()\n    }\n    return s.length === 0\n      ? undefined // < weird: just a \"Who\":\n      : s.length === 1\n      ? renderNameTag(s[0]) // < \"Who/First Last\"\n      : [[TagRoots.Who, ...s]] // < \"Who/Person/Name\": retain the specified hierarchy\n  } else {\n    return renderNameTag(s)\n  }\n}\n", "import { l } from \"../../core/licensing/Licensing\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { TagPath, TagRef, TagRoots } from \"../../fe/api/Tag\"\nimport { compact, filterInPlace, isEmpty, last, uniqBy } from \"../../fe/Array\"\nimport { notBlank } from \"../../fe/Blank\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { toA } from \"../../fe/toA\"\nimport { toS } from \"../../fe/toS\"\nimport { isWhoTag } from \"./WhoTagger\"\n\n// ASCII unit separator. We're using an ASCII-separated path, rather than a\n// JSON-encoded path, to make \"getDescendants\" by path easier.\nexport const TagSep = String.fromCharCode(31)\n\nexport const Library = \"Library\"\n\nexport const Roots: TagRef[] = [\n  { name: TagRoots.When, ordinal: 1 }, //  icon: \"event\"\n  { name: TagRoots.Albums, ordinal: 2 }, //\n  { name: TagRoots.FS, ordinal: 3 }, // filesystem\n  { name: TagRoots.Who, ordinal: 4 },\n  // { name: Where, ordinal: 3, icon: explore},\n  // { name: What, ordinal: 4, icon: nature},\n  { name: TagRoots.Camera, ordinal: 5 }, // icon: photo_camera\n  { name: TagRoots.Lens, ordinal: 6 },\n  { name: TagRoots.Keywords, ordinal: 7 },\n  { name: TagRoots.Type, ordinal: 8 }\n]\n\n// export const WhereSynonyms = new CISet([\n//   \"country\",\n//   \"el pa\u00EDs\",\n//   \"emplacement\",\n//   \"endroit\",\n//   \"gps\",\n//   \"les pays\",\n//   \"location\",\n//   \"ort\",\n//   \"pays\",\n//   \"place\",\n//   \"places\",\n//   \"platz\",\n//   \"posici\u00F3n\",\n//   \"region\",\n//   \"r\u00E9gion\",\n//   \"site\",\n//   \"sitio\",\n//   \"st\u00E4tte\",\n//   \"ubicaci\u00F3n\",\n//   \"where\"\n// ])\n\n// export const WhatSynonyms = new CISet([\n//   \"article\",\n//   \"articles\",\n//   \"item\",\n//   \"items\",\n//   \"le sujet\",\n//   \"mati\u00E8re\",\n//   \"object\",\n//   \"objects\",\n//   \"objet\",\n//   \"objets\",\n//   \"subject\",\n//   \"subjects\",\n//   \"subjekt\",\n//   \"sujet\",\n//   \"sujeta\",\n//   \"sujeto\",\n//   \"what\"\n// ])\n\nexport function tagRefToS(tagref: Maybe<string | TagRef>): string {\n  return map(tagref, ea => orElse(ea[\"name\"], toS(ea)))\n}\n\nexport function tagPathToStringArray(path: TagPath): string[] {\n  return path.map(tagRefToS)\n}\n\nexport function joinTagPath(tp: TagPath, _sep = TagSep): string {\n  return tagPathToStringArray(tp).join(_sep) + (_sep === TagSep ? _sep : \"\")\n}\n\nexport function joinedTagPathBasename(path: string) {\n  return last(splitTagPath(path))\n}\n\nexport function splitTagPath(path: string, _sep = TagSep): string[] {\n  // filter(notBlank) removes the empty final path element due to suffixing with\n  // TagSep:\n  return toS(path).split(_sep).filter(notBlank)\n}\n\nexport function normalizeTagPath(path: string): string {\n  return joinTagPath(splitTagPath(path))\n}\n\nexport function uniqTagPaths(arr: Maybe<Maybe<TagPath>[]>) {\n  return uniqBy(toA(arr), t => (isEmpty(t) ? undefined : joinTagPath(t)))\n}\n\nfunction tagPathToLowerStr(path: TagPath): string {\n  return tagPathToStringArray(path).join(TagSep).toLowerCase() // case insensitive\n}\n\nexport function tagPathEql(a: TagPath, b: TagPath): boolean {\n  return a != null && b != null && tagPathToLowerStr(a) === tagPathToLowerStr(b)\n}\n\n/**\n * @return elements in `a` that are not in `b`\n */\nexport function tagDiff(\n  a: Maybe<Maybe<TagPath>[]>,\n  b: Maybe<Maybe<TagPath>[]>\n): TagPath[] {\n  const bPaths = new Set(compact(b).map(tag => tagPathToLowerStr(tag)))\n  return compact(a).filter(tag => !bPaths.has(tagPathToLowerStr(tag)))\n}\n\nexport function tagPathsInclude(needle: TagPath, haystack: TagPath[]) {\n  const s = tagPathToLowerStr(needle)\n  return haystack.some(ea => s === tagPathToLowerStr(ea))\n}\n\n/**\n * Determine which TagPaths need to be added and removed to make `before` become\n * `after`.\n */\nexport async function tagDeltas(\n  before: Maybe<Maybe<TagPath>[]>,\n  after: Maybe<Maybe<TagPath>[]>\n): Promise<{ add: TagPath[]; remove: TagPath[] }> {\n  const add = tagDiff(after, before)\n  const remove = tagDiff(before, after)\n\n  const excludedRootTags = Settings.excludedRootTags.valueOrDefault\n\n  filterInPlace(add, tagPath => {\n    const bad = excludedRootTags.includes(tagRefToS(tagPath[0]).toLowerCase())\n    if (bad && !tagPathsInclude(tagPath, remove)) {\n      remove.push(tagPath)\n      console.log(\"removing bad tag\", tagPath)\n    }\n    return !bad\n  })\n\n  if (await l()) {\n    // TODO: THIS IS A HORRIBLE HACK. Replace this with a \"source\" field in the\n    // AssetTag table!\n\n    // We're going to remove all Who tags from the removal list, which will\n    // retain prior Who tags.\n    filterInPlace(remove, tag => !isWhoTag(tag))\n  }\n\n  return {\n    add,\n    remove\n  }\n}\n", "import sharp = require(\"sharp\")\nimport { inspect } from \"util\"\nimport { compact, diff, isNotEmpty } from \"../../fe/Array\"\nimport { isTrue } from \"../../fe/Boolean\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { Dimensions, dimToS } from \"../../fe/Dimensions\"\nimport { errorToS } from \"../../fe/Error\"\nimport { stringify } from \"../../fe/JSON\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { pick } from \"../../fe/Object\"\nimport { thenCollect } from \"../../fe/Promise\"\nimport { leastBy } from \"../Array\"\nimport { time } from \"../async/PromiseTimer\"\nimport { WrappedError } from \"../error/WrappedError\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { PushProgressObserver } from \"../fs/ProgressObservers\"\nimport { Logger, mkLogger } from \"../Logger\"\nimport { Try } from \"../Object\"\nimport { Settings } from \"../settings/Settings\"\nimport { TTLSet } from \"../TTLSet\"\nimport { SortableAssetFile, sortAssetFiles } from \"./AssetFileSorter\"\nimport { AssetPreviewInfo, AssetPreviews } from \"./AssetPreviews\"\nimport { equivalentFitSizes, fitSizes } from \"./FitSizes\"\nimport { isHeifMimetype } from \"./HeifFilter\"\nimport { ImageSize } from \"./ImageSize\"\nimport { sharpClone } from \"./Sharp\"\nimport { maybeApplyColorspace } from \"./SharpColorspace\"\nimport { sharpReadable } from \"./SharpReadable\"\nimport { validFile } from \"./ValidFile\"\n\nexport interface PreviewAssetFile extends SortableAssetFile {\n  id?: number\n  assetId?: number\n  uri: string\n  mimetype: string\n  rotation?: number\n}\n\nexport class AssetPreviewBuilder {\n  private readonly logger: Logger\n  private badShas = new TTLSet<string>(2 * minuteMs)\n  constructor(\n    readonly ap: AssetPreviews,\n    readonly assetFiles: PreviewAssetFile[]\n  ) {\n    this.logger = mkLogger(\"AssetPreviewBuilder(\" + ap.assetId + \")\")\n  }\n\n  [inspect.custom]() {\n    return {\n      ctor: \"AssetPreviewBuilder\",\n      assetId: this.ap.assetId,\n      assetFiles: this.assetFiles\n    }\n  }\n\n  /**\n   * The caller is assumed to have a per-asset advisory lock to prevent\n   * concurrent runs for the same asset.\n   */\n  build_(opts: {\n    force?: boolean\n    validate?: boolean\n  }): Promise<AssetPreviewInfo> {\n    return time(\"img.AssetPreviewBuilder.build()\", async () => {\n      const arr = compact(await sortAssetFiles(await this.assetFiles))\n      this.logger.info(\n        \"build_(): asset file candidates:\",\n        arr.map(ea => ea.uri).reverse()\n      )\n      while (isNotEmpty(arr)) {\n        const best = arr.pop()!\n        const pf = await PosixFile.forUri(best.uri)\n        if (pf == null) continue\n        const sha = await pf.sha()\n        if (sha == null || this.badShas.has(sha)) continue\n        try {\n          const result = await this._build(pf, best, opts)\n          return result\n        } catch (err) {\n          this.badShas.add(sha)\n          this.logger.warn(\"Failed to set shown file to \" + best, errorToS(err))\n        }\n      }\n      return this.logger.throw(\n        \"none of the files are valid\",\n        { ignorable: true, retriable: false } // < don't send this to Sentry\n      )\n    })\n  }\n\n  private async _build(\n    pf: PosixFile,\n    best: PreviewAssetFile,\n    opts: { force?: boolean; validate?: boolean }\n  ) {\n    this.logger.info(\"_build(\" + pf + \")\", { uri: best.uri })\n\n    if (isTrue(opts.validate)) {\n      await validFile(pf)\n    }\n\n    const filesize = await pf.size()\n    const mtime = await pf.thisOrSidecareMaxMtimeMs()\n    this.logger.debug(\"_build\", { filesize, mtime, best })\n    if (filesize == null || mtime == null) {\n      return this.logger.throw(\"build(): missing stat info for best file\", {\n        ignorable: true,\n        best\n      })\n    }\n\n    if (\n      best.width == null ||\n      best.height == null ||\n      best.mimetype == null ||\n      best.sha == null\n    ) {\n      return this.logger.throw(\n        \"IE build(): missing fields for best file \" + pf,\n        { ignorable: true, best }\n      )\n    }\n\n    const fits = fitSizes(best as Dimensions, best.rotation, best.mimetype)\n\n    const info: AssetPreviewInfo = {\n      assetFileId: best.id,\n      ...(pick(\n        best,\n        \"assetId\",\n        \"uri\",\n        \"width\",\n        \"height\",\n        \"mimetype\",\n        \"sha\",\n        \"rotation\"\n      ) as any), // we validated this above, but TS doesn't get it.\n      path: pf.nativePath,\n      mtime,\n      filesize,\n      fitSizes: fits.map(([, ea]) => ea.name).join(\",\")\n    }\n\n    // Is the prior preview sufficient?\n    if (opts.force !== true && !Settings.forceSync.valueOrDefault) {\n      // Make sure we fetch the latest json with .refresh():\n      const priorInfo = await this.ap.readInfo.refresh()\n      if (priorInfo != null) {\n        if (priorInfo.assetId !== info.assetId) {\n          throw new Error(\n            \"IE build(): Mismatched asset IDs for \" +\n              best +\n              \": \" +\n              stringify({ priorInfo, info })\n          )\n        }\n        const priorFits = priorInfo.fitSizes.split(\",\")\n        const currFits = info.fitSizes.split(\",\")\n\n        if (\n          priorInfo.sha != null &&\n          priorInfo.sha === info.sha &&\n          priorInfo.rotation === info.rotation &&\n          equivalentFitSizes(priorFits, currFits)\n        ) {\n          // This is a no-op as far as the previews are concerned, but in order to\n          // be deterministic, we should change the metadata to make it point to\n          // (possibly) the library version.\n\n          // Are there previews that were orphaned?\n          const leftovers = diff(priorFits, currFits)\n          if (isNotEmpty(leftovers)) {\n            this.logger.info(\n              \"build(): removing previews that aren't required anymore.\",\n              { leftovers }\n            )\n            for (const fitname of leftovers) {\n              const fitsize = fits.find(([, ea]) => ea.name === fitname)\n              if (fitsize == null) {\n                this.logger.warn(\n                  \"build(): Failed to clean up: missing fit size\",\n                  { fitsize, fits }\n                )\n              } else {\n                const victim = this.ap.fileForWidth(\n                  fitsize[1].reducer.name,\n                  fitsize[0].width\n                )\n                this.logger.debug(\n                  \"build(): unlinking unwanted preview \" + victim,\n                  { fitsize }\n                )\n                await victim.unlink(\"warn\")\n              }\n            }\n          }\n\n          this.logger.debug(\n            \"build(): SHA and rotation match, and previews exist.\",\n            {\n              info,\n              priorInfo\n            }\n          )\n          await this.ap.writeInfo(info)\n          return info\n        }\n      }\n    }\n\n    // By rebuilding all sizes we ensure all the previews are from the same\n    // source (especially noticeable with assets are rotated!)\n\n    const pe = new PushProgressObserver(\n      { path: pf.nativePath, op: \"Building previews for\" },\n      ImageSize.sq().length + ImageSize.fit().length\n    )\n\n    this.logger.debug(\"Rebuilding all previews from \" + best.uri, {\n      assetId: best.assetId,\n      best,\n      info\n    })\n\n    if (null == (await this.ap.parent.mkdirp())) {\n      throw new Error(\n        \"build(): Failed to create previews directory, \" +\n          this.ap.parent +\n          \" for \" +\n          best\n      )\n    }\n\n    // It'd be easier to remove these files now, but it means there aren't\n    // previews available while we rebuild them, and that makes the UI 404.\n    // We'll delete them after we finish rebuilding the previews.\n    const priorExistingFiles = await this.ap.existingFiles()\n\n    const origSharpFile = await sharpReadable(pf, ImageSize.largestFit().max)\n    if (origSharpFile == null) {\n      throw new WrappedError({\n        message:\n          \"AssetPreviewBuilder.build(): \" +\n          best.uri +\n          \", \" +\n          pf.nativePath +\n          \", is not readable by sharp.\",\n        retriable: false\n      })\n    }\n\n    const origSharp = await maybeApplyColorspace(\n      pf,\n      sharp(origSharpFile.nativePath)\n    )\n\n    // videos are auto-rotated by Video.extractVideoFrame\n    if (\n      best.mimetype.startsWith(\"image/\") &&\n      !isHeifMimetype(best.mimetype) &&\n      best.rotation != null &&\n      best.rotation !== 0\n    ) {\n      origSharp.rotate(best.rotation) // we don't use auto-rotate.\n      this.logger.debug(\"build(): rotating \" + best.rotation + \"\u00B0\")\n    }\n\n    if (origSharpFile.name.toLowerCase().includes(\"thumbnail\")) {\n      // JPEG thumbnails are regularly \"letterboxed\". Delete that:\n      Try(() => origSharp.trim(1))\n    }\n\n    const files: PosixFile[] = []\n    let sqDim: Maybe<Dimensions> // = origDim\n    let sqSharp: Maybe<sharp.Sharp> // = origSharp\n\n    // Pick the smallest fit size that's larger than the largest square:\n    const lsq = ImageSize.largestSq()\n    const bestFitNameForSq = leastBy(fits, ([outputSize, fit]) =>\n      map(lsq.outputSize(outputSize), () => fit.megapixels())\n    )?.[1].name\n\n    const origDim = pick(best, \"width\", \"height\") as Dimensions\n    {\n      let fitSharp = origSharp.clone()\n      let fitDim = origDim\n\n      for (const [outputSize, fit] of fits) {\n        const start = Date.now()\n        const inputDim = fitDim\n        const dest = this.ap\n          .fileForWidth(fit.reducer.name, outputSize.width)\n          .wip()\n        fitSharp = fit.resize(outputSize, fitSharp)\n        fitDim = outputSize\n\n        if (fit.name === bestFitNameForSq) {\n          sqSharp = fitSharp.clone()\n          sqDim = outputSize\n        }\n\n        await fit.toJpeg({\n          path: dest.nativePath,\n          sh: fitSharp,\n          outputSize\n        })\n        pe.onProgress()\n\n        this.logger.debug(\n          \"resize(\" +\n            fit.name +\n            \") \" +\n            dimToS(inputDim) +\n            \" -> \" +\n            dimToS(outputSize) +\n            \" in \" +\n            (Date.now() - start) +\n            \" ms\"\n        )\n        files.push(dest)\n      }\n    }\n\n    // sq\n    {\n      if (sqSharp == null) {\n        this.logger.debug(\"square resize(): resorting to \", {\n          origDim,\n          bestFitNameForSq\n        })\n        sqSharp = origSharp\n        sqDim = origDim\n      } else {\n        this.logger.debug(\"square resize(): using to \", {\n          sqDim,\n          bestFitNameForSq\n        })\n      }\n\n      let positioned = false\n\n      // We do square resizing synchronously to ensure the crop is consistent:\n\n      for (const sq of ImageSize.sq()) {\n        const start = Date.now()\n        const inputDim = sqDim!\n        const outputSize = sq.outputSize(orElse(sqDim, origDim))\n        if (outputSize == null) {\n          this.logger.debug(\"skipping square output for \" + sq.max)\n          continue\n        }\n\n        // Positioning the crop takes time, even if it's a no-op, so only do it if\n        // the input isn't square already.\n        if (!positioned) {\n          outputSize.position = Settings.squareThumbStrategy.valueOrDefault\n          positioned = true\n        }\n\n        this.logger.debug(\"Applying \", { outputSize })\n\n        const dest = this.ap\n          .fileForWidth(sq.reducer.name, outputSize.width)\n          .wip()\n\n        sq.resize(outputSize, sqSharp!)\n        if (outputSize.position != null) {\n          // Deep-cloning sharp if we've prevents \"attention\" from cropping to different\n          // regions at different square sizes:\n          this.logger.debug(\"Cloning square crop to make position consistent\", {\n            outputSize\n          })\n          sqSharp = await sharpClone(sqSharp)\n        }\n        sqDim = outputSize\n        await sq.toJpeg({\n          path: dest.nativePath,\n          sh: sqSharp,\n          outputSize\n        })\n        pe.onProgress()\n        files.push(dest)\n        this.logger.debug(\n          \"resize(\" +\n            sq.name +\n            \") \" +\n            dimToS(inputDim) +\n            \" -> \" +\n            dimToS(outputSize) +\n            \" in \" +\n            (Date.now() - start) +\n            \" ms\"\n        )\n      }\n    }\n\n    try {\n      // Be sure to unlink THEN unwip, so we don't unlink just-unwipped files!\n      await Promise.all(priorExistingFiles.map(ea => ea.unlink()))\n      await Promise.all(files.map(ea => ea.unwip_()))\n      await this.ap.writeInfo(info)\n      this.logger.debug(\"Previews unwipped and info written\", { info })\n    } catch (err) {\n      await thenCollect(files, ea => ea.unlink())\n      throw new WrappedError({\n        cause: err,\n        fatal: false,\n        message: \"Failed to create previews from \" + pf\n      })\n    }\n    return info\n  }\n}\n", "import { compact, mapNotEmpty, sortBy, uniq } from \"../../fe/Array\"\nimport { blank } from \"../../fe/Blank\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { Dimensions } from \"../../fe/Dimensions\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { map2Numeric, mapNumeric } from \"../../fe/Number\"\nimport { reqValuedOrElse, values } from \"../../fe/Object\"\nimport { Primitive } from \"../../fe/Primitive\"\nimport {\n  PS_LIBRARY_PROTOCOL,\n  PS_LOCAL_FILE_PROTOCOL,\n  PS_NETWORK_FILESYSTEM_PROTOCOL\n} from \"../../fe/URI\"\nimport { countFromName, parsePosixPath } from \"../fs/Path\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { mkLogger } from \"../Logger\"\nimport { Settings } from \"../settings/Settings\"\nimport { isSupportedByCurrentBrowserExt } from \"../tags/FileExts\"\nimport { URI } from \"../uri/URI\"\nimport { AssetFileBase } from \"./AssetFileBase\"\nimport { dimensions } from \"./FileDimensions\"\n\nconst logger = lazy(() => mkLogger(\"AssetFileSorter\"))\n\n// We prefer pslib, then psfile, then file, then psnet, but we're popping,\n// so we want psnet < file < psfile < pslib:\nconst UriSchemeOrder = [\n  PS_NETWORK_FILESYSTEM_PROTOCOL,\n  \"file\",\n  PS_LOCAL_FILE_PROTOCOL,\n  PS_LIBRARY_PROTOCOL\n]\n\nexport type SortableAssetFile = Pick<\n  AssetFileBase,\n  \"uri\" | \"mtime\" | \"fileSize\" | \"sha\" | \"width\" | \"height\"\n>\n\n/**\n * Rough comparable number such that substantively larger resolution files are\n * considered \"better\"\n */\nexport function dim2sort(d: Partial<Dimensions>): Maybe<number> {\n  return map(d, ea =>\n    map2Numeric(ea.width, ea.height, (w, h) => sortScale(w * h))\n  )\n}\n\nexport function sortScale(i: number) {\n  // 1/6 is the strongest fractional exponent such that ImageSize values are\n  // still distinct.\n  return Math.round(\n    Math.pow(i, Settings.variantSortCriteriaPower.valueOrDefault)\n  )\n}\n\nexport function mtime2sort(ms: number): number {\n  return Math.round(ms / (2 * minuteMs))\n}\n\nexport async function file2sortableAssetFile(\n  f: PosixFile\n): PromiseMaybe<SortableAssetFile> {\n  return reqValuedOrElse({\n    uri: await f.uri(),\n    mtime: await f.thisOrSidecareMaxMtimeMs(),\n    fileSize: await f.size(),\n    sha: await f.sha(),\n    ...(await dimensions(f))\n  })\n}\n\n/**\n * A pleasing melange of heuristics to pick the \"best\" file from a set of files\n * to show to the user.\n *\n * Sorted by oldest/worst first. pop() to \"pick\" to best.\n *\n * It's assumed that all the files are of the same image, so metadata isn't used\n * to discriminate.\n *\n * Files that are missing, less than a KB, or have no URI will be removed from\n * the returned array.\n */\nexport function sortAssetFiles<T extends SortableAssetFile>(\n  files: T[]\n): Maybe<T[]> {\n  // For each uniq SHA, pretend everyone has the youngest mtime. This lets\n  // scheme win over mtime for the same SHA.\n  for (const sha of uniq(files.map(ea => ea.sha))) {\n    const sameSha = files.filter(ea => ea.sha === sha)\n    const maxMtime = Math.max(...compact(sameSha.map(ea => ea.mtime)))\n    sameSha.forEach(ea => (ea.mtime = maxMtime))\n  }\n\n  const withCrit = compact(\n    files.map(f =>\n      map(assetFileSortCriteriaPojo(f), pojo =>\n        map(pojoToCriteria(pojo), crit => ({ f, crit, pojo }))\n      )\n    )\n  )\n  const byCrit = sortBy(withCrit, ({ crit }) => crit)\n  return mapNotEmpty(byCrit, arr => arr.map(ea => ea.f))\n}\n\nexport function assetFileSortCriteriaPojo(af: SortableAssetFile) {\n  const resolution = dim2sort(af)\n\n  const parsedURI = URI.parse(af.uri)\n\n  if (blank(parsedURI.scheme) || blank(parsedURI.path) || af.mtime == null) {\n    logger().debug(\"assetFileSortCriteriaPojo(): skipping\", {\n      af,\n      parsedURI\n    })\n    return\n  }\n\n  const schemeIdx = UriSchemeOrder.indexOf(parsedURI.scheme)\n  if (schemeIdx === -1) {\n    logger().debug(\"assetFileSortCriteriaPojo(): skipping\", {\n      af,\n      schemeIdx,\n      parsedURI\n    })\n    return\n  }\n\n  const parsedFile = parsePosixPath(parsedURI.path)\n\n  // 2-minute-resolution, plus the scheme index to resolve close ties\n  const isCover = parsedFile.base.toLowerCase().includes(\"cover\")\n  const isBrowserSupported = isSupportedByCurrentBrowserExt(parsedFile.ext)\n  const count = orElse(countFromName(parsedFile.name), 0)\n\n  // Note that we don't fetch tags here, as that is done for only the winning\n  // file by AssetPreviewBuilder.\n  const mtime = mtime2sort(af.mtime)\n  const fileSize = mapNumeric(af.fileSize, sortScale)\n  const fields = {\n    resolution,\n    mtime,\n    schemeIdx,\n    fileSize,\n    isCover,\n    count,\n    isBrowserSupported\n  }\n  const result: any = {}\n  for (const field of Settings.variantSortCriteria.values) {\n    map(fields[field], ea => (result[field] = ea))\n  }\n  result.uri = af.uri // < just to make sorting deterministic\n  return result\n}\n\nfunction pojoToCriteria(pojo: any): Maybe<Primitive[]> {\n  const v = values(pojo)\n  if (v.some(ea => ea == null)) {\n    logger().debug(\"pojoToCriteria(): skipping\", { pojo })\n    return\n  } else {\n    return v as Primitive[]\n  }\n}\n", "import { compactBlanks, includesAll } from \"../../fe/Array\"\nimport { Dimensions, dmegapixels } from \"../../fe/Dimensions\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { gt0 } from \"../../fe/Number\"\nimport { ImageSize } from \"./ImageSize\"\nimport { OutputSize } from \"./Reducers\"\n\n/**\n * @param dim MUST BE FLIPPED BY CALLER\n */\nexport function fitSizes(\n  dim: Dimensions,\n  rotation: Maybe<number>,\n  mimetype: string\n): [OutputSize, ImageSize][] {\n  const sizes = ImageSize.fit()\n  const dim2fitSizes = sizes\n    .map(ea => [ea.outputSize(dim), ea])\n    .filter(([dims]) => dims != null) as [OutputSize, ImageSize][]\n\n  let smallestDim = dim\n\n  function keep(d: Dimensions, idx: number) {\n    const rezRatio = dmegapixels(smallestDim) / dmegapixels(d)\n    // If we can't stream the original to the browser, keep the biggest preview:\n    const avoidActual =\n      idx === 0 && (mimetype !== \"image/jpeg\" || gt0(rotation))\n    const result =\n      avoidActual ||\n      rezRatio > 3 ||\n      dmegapixels(d) - dmegapixels(smallestDim) > 2.5\n\n    if (result) smallestDim = d\n    return result\n  }\n\n  return dim2fitSizes.filter(([dims], idx) => keep(dims, idx))\n}\n\nfunction old2new(s: string) {\n  // Unfortunately, prior v0.3.8 encoded wvga as qhd, and wvgap as qhdp.\n  // As of v0.6.0, portrait sizes went away.\n  if (s === \"qhd\") return \"wvga\"\n  if (s === \"uhd\") return \"uhd4k\"\n  return s\n}\n\nexport function equivalentFitSizes(\n  oldArr: string[],\n  newArr: string[]\n): boolean {\n  return includesAll(\n    compactBlanks(oldArr).map(old2new),\n    compactBlanks(newArr).map(old2new)\n  )\n}\n", "import sharp from \"sharp\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { mkLogger } from \"../Logger\"\n\n// SITS: why isn't this exported in the typing?\nexport interface OutputInfo {\n  format: string\n  size: number\n  width: number\n  height: number\n  channels: number\n}\n\nconst logger = lazy(() => mkLogger(\"Sharp\"))\n\nexport async function sharpClone(s: sharp.Sharp): Promise<sharp.Sharp> {\n  try {\n    const { data, info } = await s.raw().toBuffer({ resolveWithObject: true })\n    return sharpFromRawBuffer(data, info)\n  } catch (err) {\n    logger().info(\"Failed to buffer-clone sharp\", err)\n    return s.clone()\n  }\n}\n\nexport function sharpFromRawBuffer(\n  b: Buffer,\n  info: Pick<OutputInfo, \"width\" | \"height\" | \"channels\">\n) {\n  return sharp(b, {\n    raw: info as any\n  })\n}\n\n// > require(\"sharp\").format\n// { ...\n// heif: {\n//   id: 'heif',\n//   input: { file: false, buffer: false, stream: false },\n//   output: { file: false, buffer: false, stream: false }\n// },\n// ... }\n\n// export const isSharpHeifEnabled = lazy(\n//   () => true === sharp.format?.[\"heif\"]?.input?.file\n// )\n", "import sharp = require(\"sharp\")\nimport { blank } from \"../../fe/Blank\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { keys, StringValued } from \"../../fe/Object\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { ProjectPath } from \"../fs/ProjectPath\"\nimport { mkLogger } from \"../Logger\"\nimport { Settings } from \"../settings/Settings\"\nimport { readRawTags } from \"../tags/ExifTags\"\n\nconst profile2filename = lazy(async () => {\n  const root = PosixFile.for(ProjectPath.ICC())\n  const result: StringValued = {}\n  for (const mapping of Settings.iccProfileMappings.valueOrDefault) {\n    const [key, basename] = mapping.split(\":\")\n    const icc = root.join(basename)\n    if (await icc.isNonEmptyFile()) {\n      result[key] = icc.nativePath\n    } else {\n      mkLogger(\"SharpColorspace\").warn(\n        \" iccProfileMappings has an invalid ICC profile filename: \" + basename\n      )\n    }\n  }\n  return Object.freeze(result)\n})\n\nexport async function maybeApplyColorspace(pf: PosixFile, s: sharp.Sharp) {\n  const readSidecars = false\n  const t = await readRawTags(pf, readSidecars)\n  const v = t?.ProfileDescription\n  if (!blank(v)) {\n    const m = await profile2filename()\n    for (const k of keys(m)) {\n      if (v.includes(k)) {\n        return s.withMetadata({ icc: m[k] } as any) // SITS: TYPING\n      }\n    }\n  }\n  return s.toColorspace(\"srgb\")\n}\n", "import { Downloadable } from \"../../fe/api/Asset\"\nimport { AssetUrls } from \"../../fe/AssetUrls\"\nimport { Dimensions, dimToS, dimToSize } from \"../../fe/Dimensions\"\nimport { ReducerName, ReducerNames } from \"../../fe/ImageReducers\"\nimport { map2 } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { gt0, toInt } from \"../../fe/Number\"\nimport { SizeDescription } from \"../../fe/Units\"\nimport { thenMap } from \"../async/Promise\"\nimport { extname } from \"../fs/Path\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { mkLogger } from \"../Logger\"\nimport { extractInt } from \"../Number\"\nimport { stripSuffix } from \"../String\"\nimport { dimensions } from \"./FileDimensions\"\n\nexport interface PreviewInfo {\n  file: PosixFile\n  assetId: number\n  reducer?: ReducerName\n  width?: number\n}\n\nconst epilog = mkLogger(\"extractPreviewInfo\")\n\nexport function extractPreviewInfo(\n  previewsRoot: PosixFile,\n  file: PosixFile\n): Maybe<PreviewInfo> {\n  const arr = file.posixPathFrom(previewsRoot).replace(/\\//g, \"\").split(\"-\")\n  const assetId = toInt(arr[0])\n  const s = arr[1]\n  const reducer = ReducerNames.validOrElse(s, undefined)\n  const width = extractInt(arr[2])\n  if (!gt0(assetId)) {\n    epilog.warn(\"Failed to extract preview info\", {\n      file,\n      previewsRoot,\n      arr,\n      assetId,\n      reducer,\n      width\n    })\n    return\n  } else {\n    return { file, assetId, reducer, width }\n  }\n}\n\nexport async function previewToDownloadable(\n  basename: string,\n  pi: PreviewInfo\n): PromiseMaybe<Downloadable> {\n  return map2(pi.assetId, pi.width, (assetId, width) =>\n    thenMap(dimensions(pi.file), d => {\n      const size = dimToSize(d)\n      const name = stripSuffix(basename, extname(basename))\n      return {\n        size,\n        basename: `${name}-${size}${pi.file.ext}`,\n        title: mkDownloadableTitle(pi.file, size, \"image\", d),\n        description: `Download ${size}`,\n        details: `(${dimToS(d)} ${pi.file.ext})`,\n        href: new AssetUrls(assetId).imgLink(ReducerNames.fit, width)\n      }\n    })\n  )\n}\n\nexport function mkDownloadableTitle(\n  f: PosixFile,\n  s: SizeDescription,\n  imageOrVideo: string,\n  d: Dimensions\n): string {\n  return `Download ${s} ${f.ext} ${imageOrVideo} (${dimToS(d)})`\n}\n", "import { ID, id2id } from \"../../fe/api/ID\"\nimport { compact, sort } from \"../../fe/Array\"\nimport { AssetUrls } from \"../../fe/AssetUrls\"\nimport { ReducerName, ReducerNames } from \"../../fe/ImageReducers\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { StringValued } from \"../../fe/Object\"\nimport { greatestBy, leastBy } from \"../Array\"\nimport { AdvisoryLockProvider } from \"../async/AdvisoryLockProvider\"\nimport { sortByAsync, thenOrElse } from \"../async/Promise\"\nimport { PromiseTimer } from \"../async/PromiseTimer\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { Logger, mkLogger } from \"../Logger\"\nimport { leftPad, splitEvery } from \"../String\"\nimport { extractPreviewInfo, PreviewInfo } from \"./PreviewInfo\"\n\nexport const previewTimers = new PromiseTimer()\n\nexport interface AssetPreviewInfo {\n  assetId: number\n  assetFileId: number\n  uri: string\n  path: string\n  mimetype: string\n  width: number\n  height: number\n  /**\n   * If filesize and maxStatMs matches, we can assume this metadata is still correct:\n   */\n  mtime: number\n  filesize: number\n  sha: string\n  rotation?: number\n  fitSizes: string\n}\n\nexport class AssetPreviews {\n  readonly logger: Logger\n  readonly assetId: number\n  readonly parent: PosixFile\n  readonly basename: string\n  readonly urls: AssetUrls\n\n  constructor(\n    readonly previewsRoot: PosixFile,\n    id: number | ID,\n    readonly alp: AdvisoryLockProvider\n  ) {\n    this.logger = mkLogger(\"AssetPreviews(assetId:\" + id2id(id) + \")\")\n    this.assetId = id2id(id)!\n    this.urls = new AssetUrls(id)\n    // To simplify debugging, we use the base-10 (rather, than, say, geohash\n    // radix encoded) ID in the path.\n\n    // MacOS finder and Windows Explorer crashes with folders > 1000, so that\n    // (ish) should be considered the largest allowable number of items in a\n    // given directory. dir_stat reads in chunks of 32k, so smaller than that is\n    // better.\n\n    // FAT and FAT32 maximum number of files on disk: 65,517\n\n    // As there will be ~10 files per image, we can have ~100 assets per\n    // directory\n\n    // See discussion:\n    // https://docs.google.com/document/d/1UzrntF9-gQhvmvKgecMI3Em623hsMP5iKBdkPHR5mC0/edit#heading=h.kyfjnq6c2j4i\n\n    // If we pad to 8 digits and split every 3 (assuming 99 million is an upper\n    // bound, which is ridiculously large), we get /000/000/01-fit-w480.jpg\n\n    // We could make this leftPad(5 or 8 or 11) based on the size of assetId,\n    // but let's just make this simple and only support assetIds < 100 million.\n    const paddedId = leftPad(this.assetId, 8, \"0\")\n    const assetPath = splitEvery(paddedId, 3)\n    // NOTE: make sure the \"-\" stays here, or else removeAll may remove other\n    // asset's files!\n    this.basename = assetPath.pop() + \"-\"\n    this.parent = previewsRoot.join(...assetPath)\n  }\n\n  existingFiles() {\n    return thenOrElse(\n      this.parent.childFiles(ea => ea.base.startsWith(this.basename)),\n      () => []\n    )\n  }\n\n  existingJpgs() {\n    return thenOrElse(\n      this.parent.childFiles(\n        ea => ea.base.startsWith(this.basename) && ea.ext === \".jpg\"\n      ),\n      () => []\n    )\n  }\n\n  // Sorted by size ascending\n  async previews(): Promise<PreviewInfo[]> {\n    const arr = await this.existingFiles()\n    return sortByAsync(\n      compact(arr.map(ea => extractPreviewInfo(this.previewsRoot, ea))),\n      ea => ea?.file.size()\n    )\n  }\n\n  async deleteAll() {\n    this.parent.clear()\n    const arr = await this.existingFiles()\n    if (arr.length > 30) {\n      throw new Error(\"INTERNAL ERROR (yikes, > 30 existing files?!)\")\n    }\n    await Promise.all(arr.map(ea => ea.unlink()))\n    return arr\n  }\n\n  file(suffix: string): PosixFile {\n    return this.parent.join(this.basename + suffix)\n  }\n\n  mp4(): PosixFile {\n    return this.file(\"video.mp4\")\n  }\n\n  infoJson(): PosixFile {\n    return this.file(\"info.json\")\n  }\n\n  readonly readInfo = lazy<PromiseMaybe<AssetPreviewInfo>>(() =>\n    // PERF: don't stat then read--just try to read.\n    this.infoJson().readJson(\"debug\")\n  )\n\n  writeInfo(info: AssetPreviewInfo) {\n    this.readInfo.unset()\n    // pretty-print (it's only ~150 vs ~160 bytes) for easier debugging\n    return this.infoJson().writeJsonMaybe(info, { spaces: 2 })\n  }\n\n  fileForWidth(reducer: ReducerName, width: number): PosixFile {\n    return this.file(reducer + \"-w\" + width + \".jpg\")\n  }\n\n  filesForReducer(reducer: ReducerName): Promise<PosixFile[]> {\n    const prefix = this.basename + reducer + \"-\"\n    return this.existingFiles().then(arr =>\n      arr.filter(ea => ea.base.startsWith(prefix))\n    )\n  }\n\n  async smallestFileForReducer(reducer: ReducerName): PromiseMaybe<PosixFile> {\n    return leastBy(await this.filesForReducer(reducer), f =>\n      orElse(\n        map(extractPreviewInfo(this.previewsRoot, f), ea => ea.width),\n        0\n      )\n    )\n  }\n\n  async largestFileForReducer(reducer: ReducerName): PromiseMaybe<PosixFile> {\n    return greatestBy(await this.filesForReducer(reducer), f =>\n      orElse(\n        map(extractPreviewInfo(this.previewsRoot, f), ea => ea.width),\n        0\n      )\n    )\n  }\n\n  async widths(reducer: ReducerName): Promise<number[]> {\n    const files = await this.filesForReducer(reducer)\n    return sort(\n      compact(\n        files.map(f =>\n          map(extractPreviewInfo(this.previewsRoot, f), ea => ea.width)\n        )\n      )\n    )\n  }\n\n  async posterLink(): Promise<string> {\n    const widths = await this.widths(ReducerNames.fit)\n    return this.urls.imgLink(ReducerNames.fit, Math.max(...widths))\n  }\n\n  /**\n   * @param stat if true, always look at the filesystem\n   */\n  async imgAttrs(\n    reducer: ReducerName,\n    stat = false,\n    skipFs = true\n  ): Promise<StringValued> {\n    if (!stat && reducer === ReducerNames.sq) {\n      return this.urls.sqImgAttrs(skipFs)\n    } else {\n      const info =\n        reducer === ReducerNames.fit ? await this.readInfo() : undefined\n      return this.urls.imgAttrs(\n        reducer,\n        await this.widths(reducer),\n        skipFs,\n        info\n      )\n    }\n  }\n}\n", "import { PosixFile } from \"../../core/fs/PosixFile\"\nimport { ID, id2id, idEql } from \"../../fe/api/ID\"\nimport { isNumber } from \"../../fe/Number\"\nimport { toS } from \"../../fe/toS\"\nimport { AdvisoryLockProvider } from \"../async/AdvisoryLockProvider\"\nimport { FifoCache } from \"../FifoCache\"\nimport { AssetPreviewBuilder, PreviewAssetFile } from \"./AssetPreviewBuilder\"\nimport { AssetPreviews } from \"./AssetPreviews\"\n\nexport class Previews {\n  private readonly id2ap = new FifoCache<AssetPreviews>(512)\n  constructor(readonly root: PosixFile, readonly alp: AdvisoryLockProvider) {}\n\n  async build_(opts: {\n    assetId: number\n    assetFiles: PreviewAssetFile[]\n    force?: boolean\n    validate?: boolean\n  }) {\n    return this.apb(opts.assetId, opts.assetFiles).build_(opts)\n  }\n\n  apb(assetId: number, assetFiles: PreviewAssetFile[]): AssetPreviewBuilder {\n    return new AssetPreviewBuilder(this.ap(assetId), assetFiles)\n  }\n\n  ap(assetId: number | ID) {\n    // TODO: SITS: YUCKOS CACHE INVALIDATION\n    const key = toS(id2id(assetId))\n    const prior = this.id2ap.get(key)\n    if (prior != null && idEql(assetId, prior.assetId)) {\n      return prior\n    } else {\n      const ap = new AssetPreviews(this.root, assetId, this.alp)\n      if (isNumber(assetId)) {\n        // Don't cache the result.\n        return ap\n      } else {\n        this.id2ap.set(key, ap)\n        return ap\n      }\n    }\n  }\n\n  clearAssetId(assetId: number) {\n    this.id2ap.delete(toS(assetId))\n  }\n}\n", "import toml from \"@iarna/toml\"\nimport { compact, flatten, isNotEmpty, mapNotEmpty, sort } from \"../../fe/Array\"\nimport { firstNotBlank, mapNotBlank } from \"../../fe/Blank\"\nimport { isTrue } from \"../../fe/Boolean\"\nimport { later } from \"../../fe/Delay\"\nimport { errorToVerbose } from \"../../fe/Error\"\nimport { stringify } from \"../../fe/JSON\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { entries, pick, values } from \"../../fe/Object\"\nimport { toS } from \"../../fe/toS\"\nimport { first } from \"../Array\"\nimport { thenMap, thenNot, thenOrElse } from \"../async/Promise\"\nimport { eqlAsync } from \"../Eql\"\nimport {\n  emitClearCache,\n  emitSettingsChanged,\n  onClearCache\n} from \"../event/EventEmitter\"\nimport { BaseFile } from \"../fs/BaseFile\"\nimport { splitLines } from \"../fs/CRLF\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { mkLogger } from \"../Logger\"\nimport { Pojo } from \"../Object\"\nimport { baseVersion } from \"../PhotoStructureVersion\"\nimport { picturesDir } from \"../PicturesDir\"\nimport { capitalize, dumbquote, padding, wrap } from \"../String\"\nimport { camel2snake } from \"../StringCase\"\nimport { userData } from \"../UserData\"\nimport { version } from \"../Version\"\nimport { ShortCmdTimeoutMs } from \"../volumes/VolumeTtls\"\nimport { libraryDataDir, setupLibraryDataDir } from \"./LibraryDirs\"\nimport { LibraryCategories, Setting, SystemCategories } from \"./Setting\"\nimport {\n  persistedLibrarySettings,\n  persistedSystemSettings,\n  Settings\n} from \"./Settings\"\n\nconst logger = mkLogger(\"SettingsIO\")\n\nconst Filename = \"settings.toml\"\n\nexport function systemSettingsFile() {\n  return PosixFile.for(userData()).join(Filename)\n}\n\nexport function librarySettingsFile(libraryPath?: Maybe<string>) {\n  return first([libraryPath, Settings.libraryPath.value], lp =>\n    mapNotBlank(lp, ea => map(libraryDataDir(ea), f => f.join(Filename)))\n  )\n}\n\nasync function migrateScanMyPictures() {\n  if (isTrue(Settings.scanMyPictures.value)) {\n    Settings.scanMyPictures.value = false\n    Settings.scanPaths.push(await picturesDir())\n  }\n}\n\n// Called by Service.setup:\nexport async function readSystemSettings(\n  settingsFile: BaseFile = systemSettingsFile()\n) {\n  const settings = await thenOrElse(importFileSettings(settingsFile), () => [])\n  await migrateScanMyPictures()\n  libraryHasSettings.unset()\n  return settings\n}\n\nexport async function envOrSavedLibraryPath() {\n  return Settings.libraryPath.value ?? savedLibraryPath()\n}\n\nexport function savedLibraryPath(): PromiseMaybe<string> {\n  return thenMap(\n    read(systemSettingsFile()),\n    ea => ea[Settings.libraryPath.name] as string\n  )\n}\n\nexport async function systemSettingsVersion(): PromiseMaybe<string> {\n  return readSettingsVersion(systemSettingsFile())\n}\n\nexport async function librarySettingsVersion(\n  libraryPath?: Maybe<string>\n): PromiseMaybe<string> {\n  return map(librarySettingsFile(libraryPath), ea => readSettingsVersion(ea))\n}\n\nexport const libraryHasSettings = lazy(\n  () => _libraryHasSettings(),\n  ShortCmdTimeoutMs\n)\nlater(() => {\n  onClearCache(() => libraryHasSettings.unset())\n  Settings.libraryPath.addListener(() => libraryHasSettings.unset())\n})\n\n// This needs to be sync for WebService and MenuItems:\nexport function _libraryHasSettings(libraryPath?: string): boolean {\n  const lsf = librarySettingsFile(libraryPath)\n  return logger.tap({\n    msg: \"_libraryHasSettings\",\n    result: orElse(lsf?.clear().existsSync(), false),\n    level: \"info\",\n    meta: {\n      libraryPath,\n      settings: Settings.libraryPath.value,\n      librarySettingsFile: lsf?.nativePath\n    }\n  })\n}\n\nconst versionRegExp = /^# PhotoStructure v(\\d+\\.\\d+\\.\\d+(?:-\\S+)?)$/i\n\nasync function readSettingsVersion(file: BaseFile): PromiseMaybe<string> {\n  return thenMap(file.firstMatchingLine(versionRegExp), m => m[1])\n}\n\nconst wrapComments = { maxLineLen: 78, prefix: \"# \" }\n\nasync function maybeWriteToml(file: BaseFile, settings: Setting<any>[]) {\n  const wip = await file.clear().isNonEmpty()\n  const dest = wip ? await file.wip() : file\n  await writeToml(dest, settings, file)\n  logger.info(\"maybeWriteFile(): wrote settings\", {\n    dest,\n    file,\n    nonDefaults: settings\n      .filter(ea => ea.hasValue())\n      .map(ea => ({\n        name: ea.name,\n        value: ea.value\n      }))\n  })\n\n  if (wip) {\n    if (await thenNot(eqlAsync(read(dest), read(file)))) {\n      logger.info(\"Archiving prior, different contents\", { dest, file })\n      await file.renameYMDHMS_(\"old\")\n    }\n    await dest.unwip_()\n  }\n}\n\n/**\n * Used by SettingIO.spec (to let the persisted system and library versions be\n * consistent)\n */\nexport const versionForSettings = lazy(() => version)\n\nasync function writeToml(\n  file: BaseFile,\n  settings: Setting<any>[],\n  src: BaseFile\n): Promise<void> {\n  const priorValues = orElse(await read(src), {})\n  const lines = flatten(\n    [\n      \"\",\n      \"Hello!\",\n      \"\",\n      `These are ${settings[0].categoryType} settings for PhotoStructure.`,\n      \"\",\n      \" - Please shut down PhotoStructure before editing this file.\",\n      \"\",\n      \" - PhotoStructure has TWO settings files!\",\n      \"\",\n      \" - Most settings have reasonable defaults, which are provided after the\",\n      `   description. Remove the \"#\" from the beginning of the line to override`,\n      \"   the default.\",\n      \"\",\n      \" - See <https://photostructure.com/getting-started/advanced-settings/>\",\n      \"   for more details\",\n      \"\",\n      \"Thanks for using PhotoStructure! Visit <https://photostructure.com/support> or email <support@photostructure.com> if you find any bugs or have any questions, ideas, or feedback. We'd love to hear from you.\",\n      \"\",\n      \"-- \",\n      \"\",\n      // DON'T EDIT THIS! WE USE IT TO CHECK THE VERSION! See `versionRegExp`\n      \"PhotoStructure v\" + versionForSettings()\n    ].map(s => wrap(s, wrapComments))\n  )\n\n  lines.push(\"\", \"\")\n\n  let priorCat = \"\"\n  settings.forEach(setting => {\n    const cat = `${capitalize(\n      setting.categoryType\n    )}.${setting.category.toLowerCase()}`\n\n    if (cat !== priorCat) {\n      priorCat = cat\n      lines.push(\n        \"\",\n        padding(\"#\", 78),\n        \"#\",\n        \"# Settings for \" + cat + \":\",\n        \"#\",\n        \"\",\n        \"\"\n      )\n    }\n\n    const border = \"# +\" + padding(\"-\", setting.name.length + 4) + \"+\"\n\n    const extra = entries({\n      env: setting.key,\n      ...mapNotEmpty(setting.opts.envAliases, ea => ({\n        \"env aliases\": ea\n      })),\n      ...setting.addToJSON()\n    })\n      .map(([k, v]) => `${k}: ${stringify(v)}`)\n      .join(\", \")\n\n    lines.push(\n      ...wrap(\n        [\n          border,\n          \"|  \" + setting.name + \"  |\",\n          border,\n          \"\",\n          `${setting.opts.description.replace(/\\n/g, \"\\n\\n\")}`,\n          `(${extra})`,\n          \"\"\n        ].join(\"\\n\"),\n        wrapComments\n      )\n    )\n\n    const prior = priorValues[setting.name]\n    const o = {}\n    const v = setting.valueToPersist(prior)\n    if (v != null) {\n      o[setting.name] = v\n      lines.push(...stringifyToml(o))\n    } else {\n      o[setting.name] = setting.exampleValue\n      lines.push(...stringifyToml(o).map(ea => \"# \" + ea))\n    }\n    lines.push(\"\", \"\")\n  })\n\n  await file.writeTxt_(\n    \"\\n\" + lines.map(ea => ea.trimRight()).join(\"\\n\") + \"\\n\\n\"\n  )\n  emitSettingsChanged()\n}\n\nexport function stringifyToml(obj: Pojo) {\n  return splitLines(\n    ...entries(obj).map(\n      ([k, v]) =>\n        // We add 2 spaces here to make long array values wrap:\n        k + \" = \" + stringify(v, undefined, 2)\n    )\n  )\n}\n\nexport async function writeSystemSettings(\n  dest: BaseFile = systemSettingsFile()\n) {\n  return maybeWriteToml(dest, persistedSystemSettings())\n}\n\nexport async function readLibrarySettings(libraryPath?: string) {\n  return map(librarySettingsFile(libraryPath), ea => importFileSettings(ea))\n}\n\n/**\n * @throws if there are errors\n */\nexport async function writeLibrarySettings(libraryPath?: string) {\n  await setupLibraryDataDir(\n    firstNotBlank(libraryPath, Settings.libraryPath.value)!\n  )\n  const file = librarySettingsFile(libraryPath)\n  logger.warn(\"writeLibrarySettings(\" + file + \")\")\n  await map(file, f => maybeWriteToml(f, persistedLibrarySettings()))\n  libraryHasSettings.unset()\n  return file\n}\n\nasync function read(file: BaseFile): PromiseMaybe<toml.JsonMap> {\n  return thenMap(file.readFile(), buf =>\n    logger.tap({\n      msg: `read(${file})`,\n      result: toml.parse(dumbquote(buf.toString()))\n    })\n  )\n}\n\nasync function importFileSettings(f: BaseFile): PromiseMaybe<Setting<any>[]> {\n  const log = mkLogger(\"SettingsIO.importFileSettings(\" + f.nativePath + \")\")\n  try {\n    const tomlMap = await read(f)\n    if (tomlMap == null) {\n      if (await f.isNonEmpty()) throw new Error(\"Failed to read \" + f)\n      else return []\n    }\n    const settings = new Map<string, Setting<any>>(\n      entries(Settings)\n        .filter(([, v]) => v instanceof Setting && !v.transient)\n        .map(([k, v]) => [k.toLowerCase(), v])\n    )\n    const imported = compact(\n      entries(tomlMap).map(([key, value]) => {\n        const s = settings.get(toS(key).toLowerCase())\n        if (s == null) {\n          log.warn(\"Failed to import (no setting with this name)\", {\n            key\n          })\n        } else {\n          s.importFromFile(value)\n        }\n        return s\n      })\n    )\n    log.info(\"loaded\", {\n      tomlMap,\n      imported: imported.map(s => pick(s, \"name\", \"value\", \"persist\"))\n    })\n    return imported\n  } catch (err) {\n    log.error(\"Cannot read\" + errorToVerbose(err))\n    return\n  }\n}\n\nconst UnclearableSettings = lazy(\n  () =>\n    new Set(\n      [\n        Settings.logLevel,\n        Settings.httpPort,\n        Settings.rpcPort,\n        Settings.license\n      ].map(ea => ea.key)\n    )\n)\n\n/**\n * Force all in-memory settings to default values.\n */\nexport function clearSettings() {\n  values(Settings)\n    // don't reset LOG, NODE_ENV, or random ports!\n    .filter(ea => !UnclearableSettings().has(ea.key))\n    .forEach(ea => ea.unset())\n  emitClearCache()\n  emitSettingsChanged()\n}\n\n/**\n * Force all in-memory Settings to default values, and delete both system and\n * library settings.\n *\n * Probably only useful for tests.\n */\nexport async function nukeSettings() {\n  await systemSettingsFile().unlink(\"debug\")\n  await map(librarySettingsFile(), ea => ea.unlink(\"debug\"))\n  clearSettings()\n  return\n}\n\nexport async function writeEnv(\n  file: BaseFile,\n  settings: Setting<any>[]\n): Promise<void> {\n  const lines = flatten(\n    [\n      \"\",\n      `Welcome to PhotoStructure! These are the settings for version ${baseVersion()}.`,\n      \"\",\n      \"Please see <https://photostructure.com/environment-variables> for more information about using environment variables with PhotoStructure.\",\n      \"\",\n      `PLEASE NOTE: PhotoStructure does not read the contents of this \"defaults.env\" (or any \".env\" variant).`,\n      \"\",\n      `The following settings categories are stored in the system settings.toml:`,\n      \"\",\n      ...sort([...SystemCategories]).map(ea => \"* System.\" + ea),\n      \"\",\n      `The following settings categories are stored in the library settings.toml:`,\n      \"\",\n      ...sort([...LibraryCategories]).map(ea => \"* Library.\" + ea),\n      \"\",\n      \"Please visit <https://forum.photostructure.com> if you find anything that may be a bug or have any questions, ideas, or feedback. We'd love to hear from you!\",\n      \"\"\n    ].map(s => wrap(s, wrapComments))\n  )\n\n  lines.push(\"\", \"\")\n\n  let priorCat = \"\"\n  settings.forEach(setting => {\n    const cat = `${capitalize(\n      setting.categoryType\n    )}.${setting.category.toLowerCase()}`\n\n    if (cat !== priorCat) {\n      priorCat = cat\n      lines.push(\n        \"\",\n        padding(\"#\", 78),\n        \"#\",\n        \"# Settings for \" + cat + \":\",\n        \"#\",\n        \"\",\n        \"\"\n      )\n    }\n\n    const name = setting.name\n    const border = \"# +\" + padding(\"-\", name.length + 4) + \"+\"\n\n    const extra: any = { ...setting.addToJSON() }\n    mapNotEmpty(setting.opts.envAliases, aliases => (extra.aliases = aliases))\n\n    const extraLines = entries(extra).map(\n      ([k, v]) => `${capitalize(camel2snake(k)).replace(/_/g, \" \")}: ${v}`\n    )\n\n    if (isNotEmpty(extraLines)) extraLines.push(\"\")\n\n    lines.push(\n      ...wrap(\n        [\n          // `Category: ${capitalize(setting.categoryType)}.${setting.category}`,\n          // \"\",\n          border,\n          `|  ${name}  |`,\n          border,\n          \"\",\n          setting.opts.description.replace(/\\n/g, \"\\n\\n\"),\n          \"\",\n          ...extraLines\n        ].join(\"\\n\"),\n        wrapComments\n      )\n    )\n\n    lines.push(`# ${setting.key}=${stringify(toS(setting.envValueOrDefault))}`)\n    lines.push(\"\", \"\")\n  })\n\n  await file.writeTxt_(lines.map(ea => ea.trimRight()).join(\"\\n\"))\n}\n", "import net = require(\"net\")\nimport { pid } from \"process\"\nimport { filterInPlace } from \"../../fe/Array\"\nimport { blank, mapNotBlank } from \"../../fe/Blank\"\nimport { secondMs } from \"../../fe/Date\"\nimport { stringify } from \"../../fe/JSON\"\nimport { Latch } from \"../../fe/Latch\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { orElse } from \"../../fe/Maybe\"\nimport { entries, keys } from \"../../fe/Object\"\nimport { SyncOrAsync } from \"../../fe/OptAsync\"\nimport { throttle } from \"../../fe/Throttle\"\nimport { toS } from \"../../fe/toS\"\nimport { addFirstEndable, Endable, ending } from \"../async/Endable\"\nimport { time } from \"../async/PromiseTimer\"\nimport { untilTrue } from \"../async/until\"\nimport { elapsedAsync } from \"../Elapsed\"\nimport { onError } from \"../error/Error\"\nimport { FatalErrorFlag } from \"../error/ErrorTypes\"\nimport { eventEmitter, onPause, onResume } from \"../event/EventEmitter\"\nimport { onDataChunked } from \"../fs/StreamChunker\"\nimport { closeStream, endStream, remoteDesc } from \"../fs/Streams\"\nimport { ms2level } from \"../log/Logger\"\nimport { mkLogger } from \"../Logger\"\nimport { Radix58 } from \"../math/Radix\"\nimport { mapGt0 } from \"../Number\"\nimport { Pojo } from \"../Object\"\nimport { serviceName } from \"../ServiceNames\"\nimport { Settings } from \"../settings/Settings\"\nimport { Broadcaster, setBroadcaster } from \"./Broadcaster\"\n\nconst logger = mkLogger(\"rpc.Server\")\n\nexport interface Handler {\n  (args: {\n    id: string\n    method: string\n    params: any\n    conn: ClientConnection\n  }): SyncOrAsync<any>\n}\n\nexport interface SimpleHandler {\n  (params: any): SyncOrAsync<any>\n}\n\nexport interface SimpleHandlers {\n  [methodName: string]: SimpleHandler\n}\n\nconst pong: Handler = ({\n  params,\n  conn\n}: {\n  id: string\n  method: string\n  params: any\n  conn: ClientConnection\n}) => {\n  // This actually sets the connection servicename (as it isn't established on\n  // connect):\n  mapNotBlank(params.serviceName, ea => {\n    if (blank(conn.serviceName)) {\n      conn.serviceName = ea\n    }\n  })\n  mapGt0(params.pid, ea => {\n    if (blank(conn.pid)) {\n      conn.pid = ea\n    }\n  })\n  return `pong to ${conn.serviceName}@${\n    conn.pid\n  } from ${serviceName()}@${pid} at ${new Date()}`\n}\n\nexport class ClientConnection {\n  constructor(readonly socket: net.Socket) {}\n  serviceName?: string // < set by `ping`\n  pid?: number // < set by `ping`\n\n  toString() {\n    return blank(this.serviceName)\n      ? remoteDesc(this.socket)\n      : `${this.serviceName}:${this.pid}`\n  }\n}\n\n/**\n * Servers handle duplex streams from a server, deserializing requests from\n * sockets, sending the request to one of a given set of Handlers, and\n * serializing the response to the socket.\n *\n * RPC encoded with [JSON Lines](http://jsonlines.org/). Responses always\n * include a \"sid\" field that identifies the server.\n */\nexport class Server implements Endable, Broadcaster {\n  readonly name: string\n  private _ended = false\n  private server?: net.Server\n  private readonly _ready = new Latch()\n  private readonly connections: ClientConnection[] = []\n  private readonly onPause = () => this.broadcast(\"pause\")\n  private readonly onResume = () => this.broadcast(\"resume\")\n  readonly handlers = new Map<string, Handler>()\n  readonly sid = lazy(() => Radix58.randomChars(12))\n\n  /**\n   * Caller must call `.start` after adding handlers.\n   */\n  constructor(readonly port: number, readonly unref: boolean = true) {\n    this.name = \"Server:\" + port\n    this.addHandler(\"ping\", pong)\n    this.addSimpleHandler(\"broadcast\", ea => {\n      eventEmitter.emit(ea.event, ea.args)\n      return this.broadcast(ea.event, ea.args)\n    })\n    onPause(this.onPause)\n    onResume(this.onResume)\n    addFirstEndable(this)\n    setBroadcaster(this)\n  }\n\n  get connectionCount() {\n    return this.connections.length\n  }\n\n  async serialize(pojo: Pojo): Promise<string> {\n    return stringify({ sid: this.sid(), ...pojo }) + \"\\n\"\n  }\n\n  addHandler(method: string, handler: Handler) {\n    const prior = this.handlers.get(method)\n    if (prior != null) {\n      logger.warn(\"addHandler(): overwriting\", {\n        method,\n        prior,\n        newHandler: handler\n      })\n    }\n    this.handlers.set(method, handler)\n  }\n\n  addSimpleHandler(method: string, handler: SimpleHandler) {\n    this.addHandler(method, ({ params }) => handler(params))\n  }\n\n  addSimpleHandlers(handlers: SimpleHandlers) {\n    entries(handlers).forEach(([k, v]) => this.addSimpleHandler(k, v))\n  }\n\n  readonly start = throttle(async () => {\n    if (this.ended) return\n    logger.debug(\"start(\" + this.port + \")\")\n    this.server = net.createServer(this.onConnect.bind(this))\n    this.server.on(\"listening\", () => {\n      logger.info(\"listening on \" + this.port)\n      void this._ready.resolve()\n    })\n    this.server.on(\"error\", async err => {\n      logger.warn(\"error, rejecting ready\")\n      void this._ready.reject()\n      await this.onError(\"createServer\" + FatalErrorFlag, err)\n    })\n    this.server.listen(\n      this.port,\n      Settings.exposeNetworkWithoutAuth.valueOrDefault ? undefined : \"127.0.0.1\"\n    )\n    if (this.unref) {\n      this.server.unref()\n    }\n    return this._ready.promise\n  }, 5000)\n\n  get ended() {\n    return this._ended || ending()\n  }\n\n  get ready(): Promise<void> {\n    return this._ready.promise\n  }\n\n  closeAllConnections() {\n    const p = this.connections.map(ea => endStream(ea.socket))\n    this.connections.length = 0\n    return Promise.all(p)\n  }\n\n  /**\n   * Send an event that will be emitted to the default eventEmitter for all\n   * connected clients:\n   */\n  broadcast(event: string, args?: any): Promise<boolean> {\n    return this.sendAll({ event, args })\n  }\n\n  private async sendAll(\n    pojo: Pojo,\n    method: \"write\" | \"end\" = \"write\"\n  ): Promise<boolean> {\n    const msg = await this.serialize(pojo)\n    const sockets = [...this.connections]\n    let todo = sockets.length\n    logger.debug(\"sendAll()\", { pojo, method })\n    for (const ea of sockets) {\n      try {\n        if (ea.socket.writableEnded) {\n          todo--\n        } else {\n          ea.socket[method](msg, () => todo--)\n        }\n      } catch {\n        todo--\n      }\n    }\n    return untilTrue(() => todo <= 0, { timeoutMs: secondMs })\n  }\n\n  // lazy to only run once:\n  readonly end = lazy(async () => {\n    this._ended = true\n    eventEmitter.removeListener(\"pause\", this.onPause)\n    eventEmitter.removeListener(\"resume\", this.onResume)\n    await this.closeAllConnections()\n    await closeStream(this.server)\n  })\n\n  private onConnect(socket: net.Socket): void {\n    logger.info(\"Connection from \" + remoteDesc(socket))\n    if (this.unref) {\n      socket.unref()\n    }\n    const conn = new ClientConnection(socket)\n    this.connections.push(conn)\n    socket.on(\"end\", () => {\n      logger.info(\"Closing connection from \" + remoteDesc(socket))\n      filterInPlace(this.connections, ea => ea.socket !== socket)\n    })\n    socket.on(\"error\", async err => {\n      logger.warn(\"on error from \" + remoteDesc(socket) + \": \" + err)\n      await this.onError(\"socket\", err)\n      socket.end()\n    })\n    try {\n      void onDataChunked(socket, \"\\n\", ea => this.onRequest(ea, conn))\n    } catch (err) {\n      logger.warn(\"Caught error from \" + remoteDesc(socket) + \": \" + err)\n      socket.end()\n    }\n  }\n\n  private async onRequest(line: string, conn: ClientConnection) {\n    logger.debug(\"onRequest()\", line)\n    if (blank(line)) {\n      return\n    }\n    let id: string = \"missing\"\n    let method: string = \"missing\"\n    try {\n      const req = JSON.parse(line) as any\n      mapNotBlank(req.id, ea => (id = ea))\n      mapNotBlank(req.method, ea => (method = ea))\n      // `return await` so the catch handles the promise:\n      return await time(\"rpc.\" + method, () =>\n        this.handle(id, method, req.params, conn)\n      )\n    } catch (error) {\n      logger.warn(\"invalid request\", { line, error })\n      conn.socket.write(\n        await this.serialize({\n          id,\n          error: orElse(error.message, () => toS(error))\n        })\n      )\n    }\n  }\n\n  private async handle(\n    id: string,\n    method: string,\n    params: any,\n    conn: ClientConnection\n  ) {\n    const handler = this.handlers.get(method)\n    if (handler == null) {\n      logger.warn(\"bad handler request\", {\n        method,\n        params,\n        supported: keys(this.handlers)\n      })\n      // this.onLine() will catch this error and return an invalid request\n      // response:\n      throw new Error(\"No handler for \" + method)\n    }\n    const { elapsedMs, result } = await elapsedAsync(() =>\n      handler({ id, method, params, conn })\n    )\n    logger.log(ms2level(elapsedMs, secondMs), \"handle()\", {\n      method,\n      conn: toS(conn),\n      elapsedMs,\n      id,\n      params,\n      result\n    })\n    conn.socket.write(await this.serialize({ id, result }))\n    return\n  }\n\n  private async onError(source: string, err?: any) {\n    if (!this.ended) onError(source, err)\n  }\n}\n", "import { emitClearCache, emitPause, emitResume } from \"../event/EventEmitter\"\n\n/*\n## Design for pause/resume ##\n\nPhotoStructure's \"system of record\" for pause/resume state is the MainService.\n\nWhen the user picks \"pause\" or \"resume\" from the system tray, \"--pause\" or\n\"--resume\" is written to the web and sync processes.\n\nWhen the web service pauses or resumes, it broadcasts that setting to all\ncurrently-connected RPC clients via core/rpc/Server, which should also take care\nof the sync-file processes.\n\nIt's not awesome that there are two ways that services share pause/resume state\n(via stdin and vi dbrpc), but it means the main service doesn't have to maintain\na socket connection to the web service, in addition to the stdin/stdout/stderr\npipes to the web service. Also, currently, the RPC socket is only set up when\nthe library path is set.\n\nThe previous design had a lazy-with-TTL to fetch \"remotePaused\" state, but that\nrequired sync and sync-file to continuously poll for paused state, which also\nwasn't awesome.\n*/\n\nlet paused = false\n\nexport function isPaused(): boolean {\n  return paused\n}\n\nexport function pause(): void {\n  if (!paused) {\n    paused = true // < no infinite loops (if emitPause() calls pause())\n    emitPause()\n  }\n}\n\nexport function resume(): void {\n  if (paused) {\n    paused = false // < no infinite loops (if emitResume() calls resume())\n    emitClearCache()\n    emitResume()\n  }\n}\n", "import { env } from \"process\"\nimport {\n  concatHealthChecks,\n  HealthCheckResult\n} from \"../core/child/HealthChecks\"\nimport { errorToHumanString, onError } from \"../core/error/Error\"\nimport { FatalErrorFlag, HealthCheckErrorFlag } from \"../core/error/ErrorTypes\"\nimport { WrappedError } from \"../core/error/WrappedError\"\nimport {\n  onNonFatal,\n  onSettingsChanged,\n  onVolumesChanged\n} from \"../core/event/EventEmitter\"\nimport { BaseFile } from \"../core/fs/BaseFile\"\nimport { ProjectPath } from \"../core/fs/ProjectPath\"\nimport { mkLogger } from \"../core/Logger\"\nimport { isWin } from \"../core/Platform\"\nimport { PowerShell } from \"../core/pwsh/PowerShell\"\nimport { libraryOriginalsDir } from \"../core/settings/LibraryDirs\"\nimport { Settings } from \"../core/settings/Settings\"\nimport { libraryHasSettings } from \"../core/settings/SettingsIO\"\nimport { exiftoolVersionMaybe } from \"../core/tags/ExifTags\"\nimport { Volume } from \"../core/volumes/Volume\"\nimport { bestVolume, volumes } from \"../core/volumes/Volumes\"\nimport { CmdTimeoutMs } from \"../core/volumes/VolumeTtls\"\nimport { isEmpty, isNotEmpty } from \"../fe/Array\"\nimport { blank, notBlank } from \"../fe/Blank\"\nimport { hourMs, minuteMs, secondMs } from \"../fe/Date\"\nimport { later } from \"../fe/Delay\"\nimport { errorToVerbose } from \"../fe/Error\"\nimport { lazy } from \"../fe/Lazy\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { SyncOrAsync } from \"../fe/OptAsync\"\nimport { randomChars } from \"../fe/Random\"\nimport { toA } from \"../fe/toA\"\nimport { fmtBytes, GB } from \"../fe/Units\"\nimport { syncSettingsCheck } from \"./HealthChecks\"\nimport { Library } from \"./Library\"\nimport { Heartbeat } from \"./model/Heartbeat\"\nimport { healthChecksArePaused } from \"./PauseHealthChecks\"\n\nconst logger = mkLogger(\"LibraryHealthChecks\")\n\nexport const libraryHealthChecks = lazy<Promise<Partial<HealthCheckResult>>>(\n  () => _libraryHealthChecks(),\n  15 * secondMs\n)\n\nfunction clear() {\n  checkOriginalsDirIsWritable.unset()\n  libraryHealthChecks.unset()\n}\n\nfunction refresh() {\n  clear()\n  return libraryHealthChecks.refresh()\n}\n\nlater(() => {\n  Settings.libraryPath.addListener(clear)\n  onVolumesChanged(refresh)\n  onSettingsChanged(refresh)\n  onNonFatal(clear)\n})\n\nasync function _libraryHealthChecks(): Promise<Partial<HealthCheckResult>> {\n  if (healthChecksArePaused()) {\n    return { ok: [\"Library health checks are paused\"] }\n  }\n\n  if (!Settings.libraryPath.hasValue() && !libraryHasSettings()) {\n    return { ok: [\"Library isn't set up yet\"] }\n  }\n\n  const l = Library.instance()\n  if (l == null) {\n    // If we don't have a library path set, there's nothing to check\n    return libraryHasSettings()\n      ? { fail: [\"Missing library at \" + Settings.libraryPath.value] }\n      : {}\n  }\n\n  if (l.isPendingSetup) {\n    // redo healthchecks as soon as the library is ready:\n    void l.ready.then(() => libraryHealthChecks.unset())\n    const elapsedMs = Date.now() - l.start\n    if (elapsedMs < CmdTimeoutMs) {\n      return { ok: [\"Library is setting up...\"] }\n    } else if (elapsedMs < 3 * minuteMs) {\n      return { warn: [\"Library is taking a long time to set up...\"] }\n    } else {\n      return { fail: [\"Library took too long time to set up.\"] }\n    }\n  } else {\n    try {\n      await l.ready\n    } catch (err) {\n      return { fail: [\"Library setup failed: \" + errorToHumanString(err)] }\n    }\n  }\n\n  // This remaining of this function can assume we have a library that has been\n  // set up.\n\n  const ok: string[] = []\n  const warn: string[] = []\n  const bad: string[] = []\n  const fail: string[] = []\n  const errors: Error[] = []\n\n  const trap = async <T>(f: () => SyncOrAsync<T>) => {\n    try {\n      return await f()\n    } catch (err) {\n      errors.push(err)\n      logger.warn(\n        \"trap(): failed to run \" + f.name + \": \" + errorToVerbose(err)\n      )\n      fail.push(errorToHumanString(err))\n      return undefined\n    }\n  }\n\n  await trap(() => l.openedBy().throwIfUnavailable(\"(library health check)\"))\n\n  if (Settings.healthCheckExiftool.valueOrDefault) {\n    await trap(() => exiftoolVersionMaybe())\n  }\n\n  if (Settings.healthCheckLibraryIsWritable.valueOrDefault) {\n    // Make sure we can copy assets to the library\n    await trap(() =>\n      checkOriginalsDirIsWritable().catch(err => {\n        throw new WrappedError({\n          cause: err,\n          message: \"Cannot write to \" + libraryOriginalsDir(),\n          fatal: true\n        })\n      })\n    )\n  }\n\n  if (isWin) {\n    try {\n      const version = await PowerShell.instance().version()\n      if (blank(version)) {\n        fail.push(\"PowerShell isn't working (can't get version).\")\n      }\n    } catch (err) {\n      errors.push(err)\n      fail.push(`PowerShell isn't working (${errorToHumanString(err)}).`)\n    }\n  }\n\n  // Pause if the system drive is getting low.\n\n  if (\n    Settings.healthCheckFreeSpace.valueOrDefault ||\n    Settings.healthCheckVolumes.valueOrDefault\n  ) {\n    const vols: Maybe<Volume[]> = await trap(() => volumes())\n\n    // Make sure we can get current volumes:\n    if (isEmpty(vols)) {\n      fail.push(\"Failed to scan system volumes.\" + FatalErrorFlag)\n    } else if (Settings.healthCheckFreeSpace.valueOrDefault) {\n      for (const reqFile of await l.requiredFiles()) {\n        try {\n          const file = await reqFile.file()\n          if (file == null) continue\n          file.clear()\n          if (reqFile.isDir && !(await file.isDirectory())) {\n            fail.push(`${reqFile.desc}, ${file}, is missing` + FatalErrorFlag)\n          } else if (isNotEmpty(vols)) {\n            const vol = bestVolume(vols, file.nativePath)\n            logger.debug(\"checkDir()\", {\n              dir: file.nativePath,\n              desc: reqFile.desc,\n              bestVolume: vol,\n              vols: vols.map(ea => ea.mountpoint)\n            })\n            if (vol == null) {\n              if (file.isUNC) {\n                warn.push(\n                  `${reqFile.desc}, ${file}: cannot be monitored for sufficient free space. Consider using a mapped network drive instead.`\n                )\n              } else {\n                fail.push(\n                  `${reqFile.desc}, ${file}, doesn't seem to have a mountpoint (?!)`\n                )\n              }\n            } else if (\n              vol.available <\n              Settings.minDiskFreeGb.valueOrDefault * GB\n            ) {\n              // If disk available is low, we should pause sync, but it's not a\n              // fatal error for the webservice.\n              warn.push(\n                `Only ${fmtBytes(vol.available)} are available on ${\n                  vol.mountpoint\n                }.`\n              )\n            }\n          }\n        } catch (err) {\n          errors.push(err)\n          fail.push(\n            \"Failed to check \" + reqFile.desc + \": \" + errorToHumanString(err)\n          )\n        }\n      }\n    }\n  }\n\n  if (isEmpty(fail) && isEmpty(warn)) {\n    ok.push(\"Library and support directories are OK\")\n  }\n  if (notBlank(env.TEST_FAIL)) {\n    fail.unshift(...env.TEST_FAIL.split(\",\"))\n  }\n  if (notBlank(env.TEST_WARN)) {\n    warn.unshift(...env.TEST_WARN.split(\",\"))\n  }\n\n  if (Settings.healthCheckDb.valueOrDefault) {\n    await trap(() => Heartbeat.assertPing())\n  }\n\n  // If we found issues, we should consider shutting down. Adding a\n  // HealthCheckErrorFlag here prevents this onError from calling healthChecks\n  // again.\n  fail.map(ea => onError(ea + HealthCheckErrorFlag))\n\n  // concat does uniq and compact for us:\n  return concatHealthChecks({ ok, warn, bad, fail }, syncSettingsCheck())\n}\n\nconst checkOriginalsDirIsWritable = lazy(\n  async () => copyExampleImageToLibraryDir(libraryOriginalsDir()),\n  hourMs\n)\n\nexport async function copyExampleImageToLibraryDir(\n  rootDir: Maybe<BaseFile | string>\n): Promise<void> {\n  if (rootDir == null) {\n    return logger.throw(\"copyExampleImageToLibraryDir(): undefined rootDir\")\n  }\n  const src = toA(\n    await BaseFile.for(ProjectPath.Public()).join(\"images\").children()\n  ).find(ea => ea.name.startsWith(\"splash\")) // really just any file will do.\n  if (src == null) {\n    return logger.throw(\n      \"copyExampleImageToLibraryDir(): missing validation image\"\n    )\n  }\n  rootDir = BaseFile.for(rootDir)\n  const destDir = rootDir.join(\".tmp-\" + randomChars(6))\n  const dest = destDir.join(\"write-test\" + src.ext)\n  try {\n    await src.copyFile_(dest)\n    const srcSha = await src.sha()\n    const destSha = await dest.sha()\n    if (srcSha !== destSha) {\n      return logger.throw(\n        \"Failed to copy sample file to library. Is \" + rootDir + \" writable?\",\n        { ignorable: true }\n      )\n    }\n    logger.debug(`Library root directory, ${rootDir}, is writable`)\n  } finally {\n    await destDir.rmrf(\"debug\")\n  }\n}\n", "import { memoryUsage } from \"process\"\nimport { sigFigs } from \"../fe/Number\"\nimport { MB } from \"../fe/Units\"\nimport { sum } from \"./math/Vector\"\n\nexport function memoryUsageBytes() {\n  const mem = memoryUsage()\n  // These are sometimes not defined. We don't want to return NaN.\n  return sum([mem.external, mem.heapUsed, mem.arrayBuffers])\n}\n\nexport function memoryUsageMb() {\n  return sigFigs(memoryUsageBytes() / MB, 2)\n}\n\nexport function memoryUsageRssBytes() {\n  return memoryUsage().rss\n}\n\nexport function memoryUsageRssMb() {\n  return sigFigs(memoryUsageRssBytes() / MB, 2)\n}\n", "import { EndableRanks, ending } from \"../core/async/Endable\"\nimport { EndableWrapper } from \"../core/async/EndableWrapper\"\nimport { thenNot } from \"../core/async/Promise\"\nimport {\n  concatHealthChecks,\n  fullhc,\n  hasWarn,\n  HealthCheckResult\n} from \"../core/child/HealthChecks\"\nimport { onError } from \"../core/error/Error\"\nimport { HealthCheckErrorFlag } from \"../core/error/ErrorTypes\"\nimport { mkLogger } from \"../core/Logger\"\nimport { memoryUsageBytes, memoryUsageRssBytes } from \"../core/Memory\"\nimport { isTest } from \"../core/NodeEnv\"\nimport { serviceName } from \"../core/ServiceNames\"\nimport { Settings } from \"../core/settings/Settings\"\nimport { isPaused } from \"../core/work/WorkPlanner\"\nimport { isEmpty, isNotEmpty } from \"../fe/Array\"\nimport { notBlankOr } from \"../fe/Blank\"\nimport { errorToS } from \"../fe/Error\"\nimport { stringify } from \"../fe/JSON\"\nimport { lazy } from \"../fe/Lazy\"\nimport { gt0 } from \"../fe/Number\"\nimport { fmtBytes, MB } from \"../fe/Units\"\nimport { libraryHealthChecks } from \"./LibraryHealthChecks\"\n\nexport function memoryUsageIsHigh() {\n  return Settings.maxMemoryMb.valueOrDefault < memoryUsageBytes() / MB\n}\n\nconst memOnExit = lazy(\n  () =>\n    new EndableWrapper(\n      \"memoryCheck on exit\",\n      () => {\n        const l = mkLogger(\"PromiseTimer\")\n        const mc = memoryCheck()\n        l.log(hasWarn(mc) ? \"warn\" : \"info\", \"memory use on exit:\", mc)\n      },\n      EndableRanks.service\n    )\n)\n\nexport function memoryCheck(): Partial<HealthCheckResult> {\n  memOnExit()\n  const ok: string[] = []\n  const warn: string[] = []\n  const bad: string[] = []\n\n  function check(bytesUsed: number, maxMb: number, desc: string) {\n    if (!gt0(bytesUsed)) {\n      return onError(\n        \"memoryCheck(): invalid bytesUsed. \" +\n          stringify({ bytesUsed, desc }) +\n          HealthCheckErrorFlag\n      )\n    }\n    const mbUsed = bytesUsed / MB\n    const info = `used by ${serviceName()} (${fmtBytes(bytesUsed, 2)})`\n\n    if (mbUsed >= maxMb) {\n      bad.push(`${desc} ${info} is high`)\n    } else if (mbUsed >= maxMb * 0.8) {\n      warn.push(`${desc} ${info} is high`)\n    } else {\n      ok.push(`${desc} ${info} is OK`)\n    }\n    return\n  }\n\n  check(memoryUsageBytes(), Settings.maxMemoryMb.valueOrDefault, \"Used memory\")\n  check(\n    memoryUsageRssBytes(),\n    Settings.maxRssMemoryMb.valueOrDefault,\n    \"RSS memory\"\n  )\n  return {\n    ok,\n    warn,\n    bad\n  }\n}\n\n/**\n * This is applied by libraryHealthChecks, because it should show up in the\n * about box health checks.\n */\nexport function syncSettingsCheck(): Partial<HealthCheckResult> {\n  if (\n    !isTest &&\n    !Settings.scanAllDrives.valueOrDefault &&\n    isEmpty(Settings.scanPaths.values)\n  ) {\n    return {\n      warn: [`Nothing to scan: scanAllDrives is false and scanPaths is empty.`]\n    }\n  } else {\n    return {}\n  }\n}\n// Don't lazy this. libraryHealthChecks is already memoized, and memoryCheck is cheap.\nexport async function healthChecks() {\n  try {\n    // Don't spin everything up if we're not set up yet:\n    return concatHealthChecks(await libraryHealthChecks(), memoryCheck())\n  } catch (err) {\n    return fullhc({\n      fail: [notBlankOr(errorToS(err), \"healthChecks failed\")]\n    })\n  }\n}\n\n/**\n * @return true if we're paused\n */\n// Not lazy because of isPaused\nexport async function doNotRun() {\n  if (isPaused() || ending()) return true\n  const hc = await healthChecks() //Assumes this is lazy/cached\n  return (\n    hc == null ||\n    isNotEmpty(hc.fail) ||\n    isNotEmpty(hc.bad) ||\n    isNotEmpty(hc.warn)\n  )\n}\n\n/**\n * @return true if operations may run. False if we can't fetch healthchecks, or\n * there are warn or fail messages, or OK is empty.\n */\nexport function runvalve() {\n  return thenNot(doNotRun())\n}\n", "import { Knex } from \"knex\"\nimport { inspect } from \"util\"\nimport { Logger, mkLogger } from \"../../core/Logger\"\nimport { isProd } from \"../../core/NodeEnv\"\nimport { Constructor } from \"../../core/Object\"\nimport { includes } from \"../../fe/Array\"\nimport { notBlank } from \"../../fe/Blank\"\nimport { boolToInt, isTrue } from \"../../fe/Boolean\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { mapFields, pick } from \"../../fe/Object\"\nimport { SyncOrAsync } from \"../../fe/OptAsync\"\nimport { isPrimitive } from \"../../fe/Primitive\"\nimport { thenMap } from \"../../fe/Promise\"\nimport { toS } from \"../../fe/toS\"\nimport { Db } from \"../db/Db\"\nimport { DbRequest } from \"../db/DbRequest\"\nimport { DbValue, DbValued } from \"../db/DbValued\"\nimport { knex } from \"../db/Knex\"\nimport { PartialPojo } from \"../db/PartialPojo\"\nimport { Schema } from \"../db/Schema\"\nimport { tx } from \"../db/Transactions\"\nimport { modelDb } from \"./ModelDb\"\nimport { ModelInterface } from \"./ModelInterface\"\nimport { assignFromJSON, fromJSON } from \"./ModelJson\"\nimport { ModelOps } from \"./ModelOps\"\nimport { TableName } from \"./TableName\"\n\nexport interface ModelClass<M extends Model> extends Constructor<M> {\n  db: () => Db\n  dbl: DbRequest\n  // NOTE TO FUTURE ME: .ops() can't be a getter, as I need to capture the\n  // <this> for typing. :(\n  ops(): ModelOps<M>\n  fromJSON(json: M | PartialPojo<M>): M\n  toJSON(json: M | PartialPojo<M>): DbValued\n  // TODO: remove these methods and make everything go through .ops()?\n  query(): Knex.QueryBuilder\n  queryBy(constraint: PartialPojo<M>): Knex.QueryBuilder\n  queryOneBy(constraint: PartialPojo<M>): Knex.QueryBuilder\n\n  tableName: TableName\n  schema: Schema\n  $ctor: string\n  uniqueColumnName: string\n  booleanFields?: string[]\n}\n\nexport class Model implements ModelInterface {\n  static readonly tableName: TableName\n  static readonly schema: Schema = \"models\"\n  static readonly db = modelDb\n  static readonly uniqueColumnName: string\n  static readonly booleanFields?: string[]\n\n  static get $ctor() {\n    return this.schema + \".\" + this.tableName\n  }\n\n  private static _logger: Logger\n  static logger() {\n    if (this._logger == null) this._logger = mkLogger(this.tableName)\n    return this._logger\n  }\n\n  static query() {\n    return knex(this.tableName)\n  }\n\n  static queryBy<M extends Model>(\n    this: ModelClass<M>,\n    constraint: PartialPojo<M>\n  ) {\n    return this.query().where(constraint)\n  }\n\n  static queryOneBy<M extends Model>(\n    this: ModelClass<M>,\n    constraint: PartialPojo<M>\n  ) {\n    return this.queryBy(constraint)\n  }\n\n  protected static _ops: ModelOps<Model>\n\n  static ops<M extends Model>(this: Constructor<M>): ModelOps<M> {\n    if (this[\"_ops\"] == null) {\n      this[\"_ops\"] = new ModelOps(this as any, this[\"db\"])\n    }\n    return this[\"_ops\"]\n  }\n\n  static get dbl(): DbRequest {\n    return this.ops().dbl\n  }\n\n  static async txOp<M extends Model, T>(\n    this: ModelClass<M>,\n    f: (ops: ModelOps<M>) => SyncOrAsync<T>\n  ): Promise<T> {\n    return tx(this.db(), () => f(this.ops()))\n  }\n\n  static async tx<M extends Model, T>(\n    this: ModelClass<M>,\n    f: (db: DbRequest) => T,\n    expectErrors: boolean = false\n  ): Promise<T> {\n    return tx(this.db(), () => f(this.dbl), expectErrors)\n  }\n\n  static rows(): Promise<number> {\n    return this.ops().rows()\n  }\n\n  static truncate() {\n    if (isProd) {\n      throw new Error(\"rejecting attempt to truncate in prod\")\n    }\n    return this.dbl.run(\"DELETE FROM \" + this.tableName)\n  }\n\n  $ops() {\n    return this.class().ops()\n  }\n\n  id?: number\n\n  // Can't be a getter because getters can't have args and we need to give it\n  // the this:\n  class<M extends Model>(this: M): ModelClass<M> {\n    return this.constructor as any\n  }\n\n  $pk(): string {\n    return toS(this.id)\n  }\n\n  $ucn(): DbValue {\n    return this[this.class().uniqueColumnName]\n  }\n\n  $tableName(): string {\n    return this.class().tableName\n  }\n\n  $uid(): string {\n    return `${this.$tableName()}(${orElse(\n      this.id,\n      this[this.class().uniqueColumnName]\n    )})`\n  }\n\n  protected logger(): Logger {\n    return mkLogger(toS(this.valueOf()))\n  }\n\n  [inspect.custom]() {\n    return this.$toShallowJSON()\n  }\n\n  toString(): string {\n    return this.$uid()\n  }\n\n  // We have to return Object to follow es5\n  // eslint-disable-next-line @typescript-eslint/ban-types\n  valueOf(): Object {\n    return this.$uid()\n  }\n\n  /**\n   * Supports both db and rpc JSON representations\n   */\n  static fromJSON<M extends Model>(\n    this: Constructor<M>,\n    pojo: M | PartialPojo<M>\n  ): M {\n    return fromJSON(this as ModelClass<M>, pojo)\n  }\n\n  static toJSON<M extends Model>(\n    this: ModelClass<M>,\n    m: M | PartialPojo<M>\n  ): DbValued {\n    return this.fromJSON(m).toJSON()\n  }\n\n  $toShallowJSON() {\n    return this.$_toJSON(isTrue)\n  }\n\n  $toDbJSON(colNames?: string[]): Record<keyof this, DbValue> {\n    const result = this.$_toJSON(boolToInt, false)\n    return notBlank(colNames) ? pick(result, ...colNames) : (result as any)\n  }\n\n  // used for RPC (millis dates to reduce unnecessary parsing work)\n  toJSON(): PartialPojo<this> {\n    // the m.valueOf removes circular reference errors.\n    // we want date in millis to make date parsing simpler.\n    return this.$_toJSON(isTrue)\n  }\n\n  $_toJSON(encodeBool: (b: any) => any, includeCtor = true): PartialPojo<this> {\n    const mc = this.class()\n    return mapFields(\n      this,\n      (key, value) => {\n        if (value == null || !isPrimitive(value)) {\n          return\n        }\n        if (includes(mc.booleanFields, key)) {\n          return [key, encodeBool(value)]\n        }\n        return [key, value]\n      },\n      includeCtor ? { $ctor: mc.$ctor } : {}\n    ) as any\n  }\n\n  upsert(pojo?: PartialPojo<this>) {\n    if (pojo != null) assignFromJSON(this, pojo)\n    return this.class().ops().upsertOne(this)\n  }\n\n  $beforeUpsert() {\n    // no-op, but Timestamped does something interesting.\n  }\n\n  async reload() {\n    return thenMap(this.class().ops().findById(this.id!), ea =>\n      assignFromJSON(this, ea)\n    )\n  }\n\n  delete() {\n    return map(this.id, ea => this.class().ops().delete([ea]))\n  }\n}\n", "import _k, { Knex } from \"knex\"\nimport { thenMap } from \"../../core/async/Promise\"\nimport { map } from \"../../fe/Maybe\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { values } from \"../../fe/Object\"\n\nexport const knex = _k({ client: \"sqlite3\", useNullAsDefault: true })\n\nexport async function firstMigratedAt(k: Knex): PromiseMaybe<Date> {\n  return thenMap(k(\"migrations\").min(\"migration_time\").first(), d =>\n    map(values(d as any)[0], ea => new Date(ea as any))\n  )\n}\n", "import { BaseFile } from \"../../core/fs/BaseFile\"\nimport { Schema } from \"./Schema\"\n\nexport const SqliteExt = \".sqlite3\"\n\nexport function pathToDb<T extends BaseFile>(dataDir: T, schema: Schema): T {\n  return dataDir.join(schema, \"db\" + SqliteExt)\n}\n", "import { isFalse } from \"../../fe/Boolean\"\nimport { libraryDataDir } from \"../../core/settings/LibraryDirs\"\nimport { map } from \"../../fe/Maybe\"\nimport { Db } from \"../db/Db\"\nimport { pathToDb } from \"../db/DbPath\"\n\nlet _modelDb: Db\n\n// fat arrows to always keep binding:\nexport const modelDb = () => _modelDb\n\nexport function setModelDb(db: Db) {\n  _modelDb = db\n}\n\nexport function libraryModelDbFile() {\n  return map(libraryDataDir(), ldd => pathToDb(ldd, \"models\"))\n}\n\n/**\n * @return only returns a value if we are running a local primary db replica\n */\nexport function localModelDbPath() {\n  return isFalse(_modelDb?.datadir.eql(libraryModelDbFile()))\n    ? _modelDb.dbfile\n    : undefined\n}\n", "import { isTrue } from \"../../fe/Boolean\"\nimport { mkLogger } from \"../../core/Logger\"\nimport { stripPrefix } from \"../../core/String\"\nimport { includes, uniq } from \"../../fe/Array\"\nimport { notBlank } from \"../../fe/Blank\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { keys } from \"../../fe/Object\"\nimport { opt } from \"../../fe/Opt\"\nimport { Model, ModelClass } from \"./Model\"\n\nconst ctor2class = new Map<string, ModelClass<any>>()\n\nexport function addModelClass(mc: ModelClass<any>) {\n  ctor2class.set(mc.$ctor, mc)\n}\n\n// const objectKeys = keys(new Object())\n\nconst kvpresent = ([k, v]: any[]) => k != null && v != null\n\n/**\n * Supports both db and rpc JSON representations\n */\nexport function fromJSON<M extends Model>(caller: ModelClass<M>, json: any): M {\n  if (json == null) {\n    throw new Error(\"json is null\")\n  }\n  if (\n    caller != null &&\n    notBlank(caller.$ctor) &&\n    !ctor2class.has(caller.$ctor)\n  ) {\n    addModelClass(caller)\n  }\n  if (json instanceof caller) {\n    return json as M\n  }\n\n  const mc = opt(json[\"$ctor\"])\n    .flatMap(ea => ctor2class.get(ea))\n    .getOrElse(() => caller)\n  if (json instanceof mc) return json\n  const m = new mc()\n  if (json == null) return m\n  return assignFromJSON(\n    m,\n    json,\n    uniq([caller.tableName + \".\", mc.tableName + \".\"])\n  )\n}\n\nexport function assignFromJSON<M extends Model>(\n  m: M,\n  json: any,\n  stripPrefixes: string[] = []\n): M {\n  const mc = m.class()\n  const entries = keys(json)\n    .filter(key => key !== \"$ctor\")\n    .filter(key => json[key] != null)\n    .map(key => {\n      const value = json[key]\n      stripPrefixes.forEach(ea => (key = stripPrefix(key, ea)))\n      if (includes(mc.booleanFields, key)) {\n        return [key, isTrue(value)]\n      }\n      return [key, value]\n    })\n    .filter(kvpresent)\n  entries.forEach(([k, v]) => (m[k] = v))\n  return m\n}\n\nexport function toJSON(\n  m: Maybe<Model | Model[]>,\n  mc: ModelClass<any>,\n  key: string\n): any | any[] {\n  if (m == null) return\n  if (Array.isArray(m))\n    return m.map((ea, idx) => toJSON(ea, mc, `${key}[${idx}]`))\n  if (typeof m.toJSON === \"function\") return m.toJSON()\n  mkLogger(\"ModelJSON.toJSON()\").warn(\"Failed\", { m, key, mc: mc.$ctor })\n  return undefined\n}\n", "import { datedToMillis, isDated } from \"../../core/date/FuzzyDate\"\nimport { includes } from \"../../fe/Array\"\nimport { entries, mapFields } from \"../../fe/Object\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\n\n// SQLite can only store numbers or strings, but let's also take booleans to\n// simplify constructors\nexport type DbValue = number | string | boolean | Date\n\nexport interface DbValued {\n  [key: string]: Maybe<DbValue>\n}\n\nexport function isDbValue(obj: any): obj is DbValue {\n  return obj === null || includes([\"number\", \"string\"], typeof obj)\n}\n\nexport function isDbValued(obj: any): obj is DbValued {\n  return obj != null && Array.isArray(obj)\n    ? obj.every(isDbValued)\n    : entries(obj).every(([, value]) => isDbValue(value))\n}\n\nexport function toDbValued(obj: any): DbValued {\n  return mapFields(obj, (key, value) => {\n    if (key.startsWith(\"$\")) return\n    if (typeof value === \"boolean\") return [key, value ? 1 : 0]\n    if (isDbValue(value)) return [key, value]\n    if (isDated(value)) return [key, datedToMillis(value)]\n    return\n  }) as DbValued\n}\n", "import { Knex } from \"knex\"\nimport { zip } from \"../../core/Array\"\nimport { escapeRegExp } from \"../../core/RegExp\"\nimport { isString } from \"../../core/String\"\nimport { flatten } from \"../../fe/Array\"\nimport { notBlank } from \"../../fe/Blank\"\nimport { stringify } from \"../../fe/JSON\"\nimport { keys, omit } from \"../../fe/Object\"\nimport { isFunction } from \"../../fe/ObjectType\"\nimport { toS } from \"../../fe/toS\"\nimport { DbValued, isDbValued } from \"./DbValued\"\n\nexport function isSqlQuery(obj: any): obj is SqlQuery {\n  return (\n    obj != null &&\n    isString(obj.sql) &&\n    (obj.bindings == null || isDbValued(obj.bindings))\n  )\n}\n\nexport interface SqlQuery {\n  sql: string\n  bindings?: Knex.Value[] | DbValued\n}\n\nexport type Queryish = string | Knex.QueryBuilder<any, any> | SqlQuery\n\nexport function toSqlQuery(sql: Queryish): SqlQuery {\n  if (sql == null) throw new Error(\"null sql\")\n  if (isSqlQuery(sql)) return sql\n  if (isString(sql)) {\n    return { sql }\n  } else if (isFunction(sql[\"toSQL\"])) {\n    return (omit(sql.toSQL(), \"__knexQueryUid\") as any) as SqlQuery\n  } else {\n    throw new Error(\"not queryish: \" + stringify(sql))\n  }\n}\n\nexport function sqlQueryToS(sq: SqlQuery) {\n  if (sq.bindings == null) return sq.sql\n  else if (Array.isArray(sq.bindings)) {\n    return (\n      flatten(\n        zip(\n          sq.sql.split(\"?\"),\n          sq.bindings.map(ea => stringify(ea))\n        )\n      )\n        // .map(ea => ea.trim())\n        .join(\"\")\n    )\n  } else {\n    let result = sq.sql\n    for (const key of keys(sq.bindings)) {\n      result = result.replace(\n        new RegExp(\"[@:$]\" + escapeRegExp(key), \"gi\"),\n        toS(sq.bindings[key])\n      )\n    }\n    return result\n  }\n}\n\nexport function isQueryBuilder(q: Queryish): q is Knex.QueryBuilder {\n  return isFunction(q[\"where\"]) && isFunction(q[\"limit\"])\n}\n\n/**\n * Assume a \"heredoc\" with 1 or more queries.\n *\n * - Comment lines that start with `--` will be removed\n * - Individual queries are separated by a semicolon at the end of a line\n *\n */\nexport function prepQueries(s: string) {\n  return s\n    .replace(/\\s*--.*?\\n/g, \"\")\n    .split(\";\")\n    .map(q => q.replace(/\\s+/g, \" \").trim())\n    .filter(notBlank)\n}\n", "import { Database, RunResult, Statement } from \"better-sqlite3\"\nimport { Knex } from \"knex\"\nimport { ending } from \"../../core/async/Endable\"\nimport { mkElapsed } from \"../../core/async/PromiseTimer\"\nimport { FifoCache } from \"../../core/FifoCache\"\nimport { mkLogger } from \"../../core/Logger\"\nimport { isTest } from \"../../core/NodeEnv\"\nimport { flatten, isNotEmpty } from \"../../fe/Array\"\nimport { blank } from \"../../fe/Blank\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { mapOr } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { ellipsize, replaceAll } from \"../../fe/String\"\nimport { TableName } from \"../model/TableName\"\nimport { Db } from \"./Db\"\nimport { DbValue, DbValued } from \"./DbValued\"\nimport { knex } from \"./Knex\"\nimport { Queryish, SqlQuery, toSqlQuery } from \"./SqlQuery\"\nimport { tx } from \"./Transactions\"\n\n// SQLite max params is 100 and max variables is 1000.\n\n// This limit is just to prevent memory bloat. It can be larger than SQLite\n// batch size. It's small in test to prove we do windowing correctly:\nexport const MaxBatchSize = isTest ? 25 : 1000\n\nconst logger = lazy(() => mkLogger(\"DbRequest\"))\n\nexport class DbRequest {\n  private readonly cachedStatements = new FifoCache<Statement>(256)\n  constructor(readonly db: () => Db, private readonly tableName?: TableName) {}\n\n  qb() {\n    return knex(this.tableName)\n  }\n\n  private prep(\n    db: Database,\n    q: Queryish,\n    pluck = false\n  ): { sq: SqlQuery; stmt: Statement } {\n    const sq = toSqlQuery(q)\n    // console.log(\"DbRequest\", sq)\n    try {\n      const stmt = this.cachedStatements.getOrSet(\n        (pluck === true ? \"pluck:\" : \"\") + sq.sql,\n        () => {\n          const result = db.prepare(sq.sql)\n          return pluck === true ? result.pluck() : result\n        }\n      )\n      if (!stmt.database.open) {\n        this.cachedStatements.clear()\n        return this.prep(db, q, pluck)\n      } else {\n        return {\n          sq,\n          stmt\n        }\n      }\n    } catch (error) {\n      return logger().throw(\"prep() failed\", {\n        error,\n        sqlQuery: sq,\n        retriable: false\n      })\n    }\n  }\n\n  // private caller() {\n  //   return stack().filter(\n  //     ea =>\n  //       ea.match(\n  //         /DbRequest|transactions|dbRetries|asyncRetry|ModelOps|Promise/i\n  //       ) == null\n  //   )\n  // }\n\n  private async wrap({\n    q,\n    pluck,\n    m\n  }: {\n    q: Queryish\n    pluck?: boolean\n    m: \"run\" | \"get\" | \"all\"\n  }) {\n    try {\n      // HEY FUTURE ME: don't put the catch /in/ the tx: that can prevent errors\n      // from being retried correctly.\n      return await tx(this.db(), db => {\n        const { sq, stmt } = this.prep(db, q, pluck)\n        // if (Settings.logSql.valueOrDefault)\n        //   logger().log(\n        //     defaultLogLevel(),\n        //     m + \"(): \" + sqlQueryToS(sq),\n        //     this.caller()\n        //   )\n        const meth = stmt[m].bind(stmt) as any\n        // PERF: INLINED FROM mapOr\n        return sq.bindings == null ? meth() : meth(sq.bindings)\n      })\n    } catch (err) {\n      if (String(err.message).includes(\"AdvisoryLock\")) {\n        // expect errors from AdvisoryLock!\n        throw err\n      } else {\n        logger().throw(err, { method: m, ...toSqlQuery(q) })\n      }\n    }\n  }\n\n  run(q: Queryish): Promise<RunResult> {\n    return this.wrap({ q, m: \"run\" })\n  }\n\n  async runScript(lines: string[], ignorable: string = \"\") {\n    const e = mkElapsed(\"runScript()\")\n    // Don't block anything with a big transaction boundary:\n    for (const sql of lines) {\n      if (blank(sql) || sql.trim().startsWith(\"--\")) continue\n      await this.run({ sql })\n      // Only fetch the first part of the query (so temp tables don't pollute\n      // the times):\n      const msg = replaceAll(ellipsize(sql, 60), ignorable, \"\")\n      e.elapsed(msg)\n    }\n  }\n\n  mapRun(queries: Queryish[]): Promise<RunResult[]> {\n    return tx(this.db(), db =>\n      queries.map(q => {\n        const { sq, stmt } = this.prep(db, q)\n        return mapOr(\n          sq.bindings,\n          b => stmt.run(b),\n          () => stmt.run()\n        )\n      })\n    )\n  }\n\n  runf(f: (q: Knex.QueryBuilder) => Knex.QueryBuilder): Promise<RunResult> {\n    return this.wrap({ q: f(this.qb()), m: \"run\" })\n  }\n\n  updateOrIgnore(\n    f: (q: Knex.QueryBuilder) => Knex.QueryBuilder\n  ): Promise<RunResult> {\n    const q = toSqlQuery(f(this.qb()))\n    q.sql = q.sql.replace(/update /i, \"UPDATE OR IGNORE \")\n    return this.wrap({ q, m: \"run\" })\n  }\n\n  first(q: Queryish): Promise<DbValued> {\n    return this.wrap({ q, m: \"get\" })\n  }\n\n  firstf(f: (q: Knex.QueryBuilder) => Knex.QueryBuilder): Promise<DbValued> {\n    return this.wrap({ q: f(this.qb()), m: \"get\" })\n  }\n\n  mapAll(queries: Queryish[]): Promise<DbValued[]> {\n    return tx(this.db(), db =>\n      flatten(\n        queries.map(q => {\n          const { sq, stmt } = this.prep(db, q)\n          return mapOr(\n            sq.bindings,\n            b => stmt.all(b),\n            () => stmt.all()\n          )\n        })\n      )\n    )\n  }\n\n  all(q: Queryish): Promise<DbValued[]> {\n    return this.wrap({ q, m: \"all\" })\n  }\n\n  allf(f: (q: Knex.QueryBuilder) => Knex.QueryBuilder): Promise<DbValued[]> {\n    return this.wrap({ q: f(this.qb()), m: \"all\" })\n  }\n\n  async batched<T>(opts: {\n    onResults: (ids: T[]) => any\n    qb: (q: Knex.QueryBuilder, prior: Maybe<T[]>) => Knex.QueryBuilder\n  }) {\n    let prior: Maybe<T[]>\n    do {\n      prior = await this.wrap({\n        q: opts.qb(this.qb(), prior).limit(MaxBatchSize),\n        m: \"all\"\n      })\n      if (isNotEmpty(prior)) {\n        await opts.onResults(prior)\n      }\n    } while (isNotEmpty(prior) && !ending())\n  }\n\n  pluckFirst<T = DbValue>(q: Queryish): Promise<T> {\n    return this.wrap({ q, pluck: true, m: \"get\" })\n  }\n\n  pluckFirstf<T extends DbValue = DbValue>(\n    f: (q: Knex.QueryBuilder) => Knex.QueryBuilder\n  ): Promise<T> {\n    return this.wrap({ q: f(this.qb()), pluck: true, m: \"get\" })\n  }\n\n  pluckAll<T = DbValue>(q: Queryish): Promise<T[]> {\n    return this.wrap({ q, pluck: true, m: \"all\" })\n  }\n\n  pluckAllf<T = DbValue>(\n    f: (q: Knex.QueryBuilder) => Knex.QueryBuilder\n  ): Promise<T[]> {\n    return this.wrap({ q: f(this.qb()), pluck: true, m: \"all\" })\n  }\n\n  async pluckBatched<T extends number | string>(opts: {\n    onResults: (ids: T[]) => any\n    qb: (q: Knex.QueryBuilder, prior: Maybe<T[]>) => Knex.QueryBuilder\n  }) {\n    let prior: Maybe<T[]>\n    do {\n      prior = await this.wrap({\n        q: opts.qb(this.qb(), prior).limit(MaxBatchSize),\n        pluck: true,\n        m: \"all\"\n      })\n      if (isNotEmpty(prior)) {\n        await opts.onResults(prior)\n      }\n    } while (isNotEmpty(prior))\n  }\n}\n", "import { RunResult } from \"better-sqlite3\"\nimport { Knex } from \"knex\"\nimport { batches } from \"../../core/Array\"\nimport {\n  thenCollectBatched,\n  thenCompact,\n  thenOrElse\n} from \"../../core/async/Promise\"\nimport { NonRetriableErrorFlag } from \"../../core/error/ErrorTypes\"\nimport { Logger, mkLogger } from \"../../core/Logger\"\nimport { mapGt0Or } from \"../../core/Number\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { flatten, isNotEmpty, mapNotEmpty, sortBy } from \"../../fe/Array\"\nimport { blank } from \"../../fe/Blank\"\nimport { stringify } from \"../../fe/JSON\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { mapOr, orElse } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { gt0, toInt } from \"../../fe/Number\"\nimport { keys, pick } from \"../../fe/Object\"\nimport { MaybeSyncOrAsync } from \"../../fe/OptAsync\"\nimport { thenCollect, thenMap } from \"../../fe/Promise\"\nimport { toA } from \"../../fe/toA\"\nimport { Db } from \"../db/Db\"\nimport { DbRequest } from \"../db/DbRequest\"\nimport { handleDbRetriesSync } from \"../db/DbRetries\"\nimport { DbValue, toDbValued } from \"../db/DbValued\"\nimport { PartialPojo } from \"../db/PartialPojo\"\nimport { Queryish } from \"../db/SqlQuery\"\nimport { tx } from \"../db/Transactions\"\nimport { Model, ModelClass } from \"./Model\"\nimport { addModelClass, assignFromJSON } from \"./ModelJson\"\nimport { TableName } from \"./TableName\"\n\nexport class ModelOps<M extends Model> {\n  readonly dbl: DbRequest\n  readonly logger: Logger\n\n  constructor(readonly model: ModelClass<M>, readonly db: () => Db) {\n    this.logger = mkLogger(`ModelOps(${model.tableName})`)\n    addModelClass(model)\n    this.dbl = new DbRequest(this.db, model.tableName)\n  }\n\n  get dbOpen(): boolean {\n    return mapOr(\n      this.db(),\n      ea => ea.open,\n      () => false\n    )\n  }\n\n  readonly columnNames = lazy<Promise<string[]>>(() =>\n    handleDbRetriesSync(() =>\n      this.db()\n        .pragma(`table_info(${this.tableName})`)\n        .map((ea: any) => ea.name)\n    )\n  )\n\n  private get tableName(): TableName {\n    return this.model.tableName\n  }\n\n  query() {\n    return this.model.query()\n  }\n\n  async toDbValued(obj: PartialPojo<M> | M) {\n    const m = this.model.fromJSON(obj)\n    const dbv = toDbValued(m)\n    return pick(dbv, ...(await this.columnNames()))\n  }\n\n  private run(qb: Queryish) {\n    return this.dbl.run(qb)\n  }\n\n  fromJSON(pojo: Maybe<any>): PromiseMaybe<M> {\n    return thenMap(pojo, ea => this.model.fromJSON(ea))\n  }\n\n  async fromJSONs(pojos: MaybeSyncOrAsync<any[]>): Promise<M[]> {\n    const arr = await thenCompact(pojos)\n    const result = arr.map(ea => this.model.fromJSON(ea as any))\n    return result\n  }\n\n  first(qb: Knex.QueryBuilder): PromiseMaybe<M> {\n    return this.fromJSON(this.dbl.first(qb))\n  }\n\n  firstf(f: (qb: Knex.QueryBuilder) => Knex.QueryBuilder): PromiseMaybe<M> {\n    return this.first(f(this.query()))\n  }\n\n  all(qb: Queryish = this.query()): Promise<M[]> {\n    return this.fromJSONs(this.dbl.all(qb))\n  }\n\n  allf(f: (qb: Knex.QueryBuilder) => Knex.QueryBuilder): Promise<M[]> {\n    return this.all(f(this.query()))\n  }\n\n  findOne(qb: Knex.QueryBuilder): PromiseMaybe<M> {\n    return this.fromJSON(this.dbl.first(qb))\n  }\n\n  findOneBy(constraint: PartialPojo<M>): PromiseMaybe<M> {\n    return this.findOne(this.model.query().where(constraint))\n  }\n\n  findById(id: number, constraint?: PartialPojo<M>): PromiseMaybe<M> {\n    return this.findOneBy({ ...constraint, id } as any)\n  }\n\n  async findByIds(ids: number[]): Promise<M[]> {\n    const results = await tx(this.db(), async () =>\n      thenCollect(\n        batches(\n          toA(ids).filter(gt0),\n          Settings.dbBatchSelectSize.valueOrDefault\n        ),\n        arr => this.dbl.all(this.query().whereIn(\"id\", arr))\n      )\n    )\n    return sortBy(await this.fromJSONs(flatten(results)), ea =>\n      ids.indexOf(ea.id!)\n    )\n  }\n\n  findBy(constraint: PartialPojo<M>): Promise<M[]> {\n    return this.all(this.model.queryBy(constraint))\n  }\n\n  findWhereIn<K extends keyof M>(column: K, values: M[K][]): Promise<M[]> {\n    return this.all(this.model.query().whereIn(column, values))\n  }\n\n  rows(qb?: Knex.QueryBuilder): Promise<number> {\n    return this.count(orElse(qb, () => this.model.query()))\n  }\n\n  /**\n   * Count the rows in the given query,\n   */\n  count(qb: Knex.QueryBuilder): Promise<number> {\n    return thenOrElse(\n      this.dbl.pluckFirst(qb.count()) as Promise<number>,\n      () => 0\n    )\n  }\n\n  countf(f: (qb: Knex.QueryBuilder) => Knex.QueryBuilder): Promise<number> {\n    return this.count(f(this.query()))\n  }\n\n  async insert(arr: (M | PartialPojo<M>)[]): Promise<M[]> {\n    return tx(this.model.db(), () => thenCollect(arr, ea => this.insertOne(ea)))\n  }\n\n  async upsertOne(t: M | PartialPojo<M>) {\n    return this.modelSupportsUpsert\n      ? (await this.upsert([t]))![0]\n      : t.id == null\n      ? this.insertOne(t)\n      : this.updateOne(t)\n  }\n\n  async insertOne(t: M | PartialPojo<M>): Promise<M> {\n    if (t.id != null) {\n      throw new Error(\n        \"insert called for \" + stringify(t) + NonRetriableErrorFlag\n      )\n    }\n    const m = this.model.fromJSON(t)\n    m.$beforeUpsert()\n    const dbJson = m.$toDbJSON(await this.columnNames())\n    const runInfo = await this.dbl.runf(q => q.insert(dbJson))\n    const result = (await mapGt0Or(\n      toInt(runInfo.lastInsertRowid),\n      id => this.findById(id),\n      () => {\n        this.logger.throw(\"internal error: lastInsertedRowId was non-numeric\", {\n          runInfo\n        })\n      }\n    ))!\n    if (t instanceof this.model) {\n      assignFromJSON(t, result)\n    }\n    return result\n  }\n\n  async updateOne(t: M | PartialPojo<M>): Promise<M> {\n    if (t.id == null) {\n      throw new Error(\n        \"update called for \" + stringify(t) + NonRetriableErrorFlag\n      )\n    }\n    const m = this.model.fromJSON(t)\n    m.$beforeUpsert()\n    const dbJson = m.$toDbJSON(await this.columnNames())\n    await this.dbl.runf(q => q.where({ id: t.id }).update(dbJson))\n    return m\n  }\n\n  /**\n   * unique column name (not ID)\n   */\n  get ucn(): string {\n    return this.model.uniqueColumnName\n  }\n\n  get ucnFieldNames(): string[] {\n    return orElse(this.ucn, \"id\").split(\",\")\n  }\n\n  get modelSupportsUpsert() {\n    return this.ucn != null && this.ucn !== \"id\"\n  }\n\n  get ucnConstraint(): string {\n    return `(${this.ucn})`\n  }\n\n  onConflictClause(cols: string[]) {\n    const immutableCols = [...this.ucn.split(\",\"), \"id\", \"createdAt\"]\n    const doUpdate = cols\n      .filter(ea => !immutableCols.includes(ea))\n      .sort()\n      .map(ea => `${ea}=excluded.${ea}`)\n      .join(\",\")\n    // https://sqlite.org/lang_UPSERT.html\n    const onConflictArr = [\"ON CONFLICT\", this.ucnConstraint]\n    if (blank(doUpdate)) {\n      onConflictArr.push(\"DO NOTHING\")\n    } else {\n      onConflictArr.push(\"DO UPDATE SET\", doUpdate)\n    }\n    return onConflictArr.join(\" \")\n  }\n\n  private async upsertDbJson(jsons: Record<keyof M, DbValue>[]) {\n    const insert = this.query().insert(jsons).toSQL()\n    const setKeys = new Set<string>()\n    for (const json of jsons) {\n      for (const key of keys(json)) {\n        setKeys.add(key)\n      }\n    }\n    const upsert = {\n      sql: `${insert.sql} ${this.onConflictClause([...setKeys.values()])}`,\n      bindings: insert.bindings as Knex.Value[]\n    }\n    // NOTE: lastInsertRowid DOES NOT WORK HERE, as the ID will be from a\n    // prior insert if the ON CONFLICT clause runs.\n    await this.run(upsert)\n  }\n\n  private pickModelUcn(m: Model): PartialPojo<M> {\n    return pick(m, ...(this.ucnFieldNames as any)) as any\n  }\n\n  async reload(arr: M[]): Promise<M[]> {\n    // TODO: PERFORMANCE: would it be faster to do one joined orWhere?\n    await thenCollect(arr, async m =>\n      thenMap(this.findOneBy(this.pickModelUcn(m)), dbModel =>\n        assignFromJSON(m, dbModel)\n      )\n    )\n    return arr\n  }\n\n  async upsert(arr: (M | PartialPojo<M>)[], skipReturn = false): Promise<M[]> {\n    if (this.modelSupportsUpsert) {\n      const cols = await this.columnNames()\n      const result = await tx(this.db(), async () =>\n        thenCollectBatched(\n          toA(arr),\n          Settings.dbBatchUpsertSize.valueOrDefault,\n          async batchArr => {\n            const models = batchArr.map(ea => this.model.fromJSON(ea))\n            models.forEach(ea => ea.$beforeUpsert())\n            await this.upsertDbJson(models.map(ea => ea.$toDbJSON(cols)))\n            return models\n          }\n        )\n      )\n      return skipReturn ? result : this.reload(result)\n    } else {\n      return tx(this.db(), () => thenCollect(arr, ea => this.upsertOne(ea)))\n    }\n  }\n\n  async delete(ids: number[]): PromiseMaybe<RunResult> {\n    return mapNotEmpty(ids.filter(gt0), arr =>\n      this.run(this.model.query().delete().whereIn(\"id\", arr))\n    )\n  }\n\n  /**\n   * @param q the query will have an .orderBy(\"id\", \"asc\") added.\n   */\n  async batched(opts: {\n    onResults: (arr: M[]) => any\n    qb: (q: Knex.QueryBuilder) => Knex.QueryBuilder\n  }) {\n    const limit = Settings.dbBatchSelectSize.valueOrDefault\n    let prior: Maybe<M[]>\n    let maxId: Maybe<number>\n    do {\n      prior = await this.allf(q => {\n        q = opts.qb(q)\n        if (maxId != null) q = q.andWhere(\"id\", \">\", maxId)\n        return q.orderBy(\"id\", \"asc\").limit(limit)\n      })\n      if (isNotEmpty(prior)) {\n        maxId = Math.max(...prior.map(ea => ea.id!))\n        await opts.onResults(prior)\n      }\n    } while (isNotEmpty(prior))\n  }\n}\n", "import { mapGt0, mapGt0Or } from \"../../core/Number\"\nimport { ID } from \"../../fe/api/ID\"\nimport { mapNotEmpty } from \"../../fe/Array\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { gt0, numericOr } from \"../../fe/Number\"\nimport { toA } from \"../../fe/toA\"\nimport { Model } from \"./Model\"\n\nexport class TimestampedModel extends Model {\n  static touch(ids: number[]) {\n    return mapNotEmpty(toA(ids).filter(gt0), arr =>\n      this.dbl.runf(q => q.whereIn(\"id\", arr).update(\"updatedAt\", Date.now()))\n    )\n  }\n\n  createdAt?: number\n  updatedAt?: number\n\n  toID() {\n    if (\"updateCount\" in this) {\n      ;(this as any)[\"updateCount\"] = mapGt0Or(this[\"updateCount\"], ea => ea, 1)\n    }\n    return toID(this)\n  }\n\n  get createdAtDate() {\n    return mapGt0(this.createdAt, ea => new Date(ea))\n  }\n\n  get updatedAtDate() {\n    return mapGt0(this.updatedAt, ea => new Date(ea))\n  }\n\n  $beforeUpsert() {\n    if (this.createdAt == null) {\n      this.createdAt = Date.now()\n    }\n    this.updatedAt = Date.now()\n    if (\"updateCount\" in this) {\n      const obj = this as any\n      obj.updateCount = mapGt0Or(obj.updateCount, ea => ea + 1, 1)\n    }\n  }\n}\n\nexport interface UpdatedId {\n  id?: number\n  updatedAt?: number\n}\n\nexport function toID(obj: Maybe<UpdatedId>): Maybe<ID> {\n  return map(obj, ea => ({\n    id: ea.id!,\n    v: numericOr(ea[\"updateCount\"], 0)\n  }))\n}\n", "import { WrappedError } from \"../../core/error/WrappedError\"\nimport { secondMs } from \"../../fe/Date\"\nimport { TimestampedModel } from \"./TimestampedModel\"\n\nexport class Heartbeat extends TimestampedModel {\n  static readonly tableName = \"Heartbeat\"\n  static readonly uniqueColumnName = \"name\"\n\n  name?: string\n\n  static ping(name: string = \"ping\") {\n    return Heartbeat.ops().upsertOne({ name })\n  }\n\n  static async assertPing(name?: string) {\n    const start = Date.now()\n    try {\n      if (Heartbeat.db() == null) throw new Error(\"db is undefined\")\n      const heartbeat = await this.ping(name)\n      this.logger().debug(\"assertPing()\", {\n        heartbeat\n      })\n      if (Math.abs(start - heartbeat.updatedAt!) > 20 * secondMs) {\n        throw new Error(\"Heartbeat.updatedAt wasn't updated\")\n      }\n    } catch (err) {\n      throw new WrappedError({\n        cause: err,\n        message: \"Failed to write to the library database\"\n      })\n    }\n  }\n}\n", "import { minuteMs } from \"../fe/Date\"\n\nlet pauseHealthChecksUntil = 0\n\nexport function pauseHealthChecks(forMs: number = 2 * minuteMs) {\n  pauseHealthChecksUntil = Date.now() + forMs\n}\n\nexport function resumeHealthChecks() {\n  pauseHealthChecksUntil = 0\n}\n\nexport function healthChecksArePaused() {\n  return Date.now() <= pauseHealthChecksUntil\n}\n", "import { mkLogger } from \"../../core/Logger\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { mountpoints } from \"../../core/volumes/Mountpoints\"\nimport { volumes } from \"../../core/volumes/Volumes\"\nimport { isPaused } from \"../../core/work/WorkPlanner\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { isVacuuming } from \"../db/Vacuum\"\nimport { libraryHealthChecks } from \"../LibraryHealthChecks\"\n\nconst logger = lazy(() => mkLogger(\"RpcServiceHandlers\"))\n\nexport const RpcServiceHandlers = lazy(() => ({\n  libraryPath: () => Settings.libraryPath.value,\n  healthChecks: () => libraryHealthChecks(),\n  isVacuuming: () =>\n    logger().tap({ msg: \"isVacuuming\", result: isVacuuming() }),\n  mountpoints: () => mountpoints(),\n  volumes: () => volumes(),\n  paused: () => isPaused()\n}))\n", "import { mkLogger } from \"../../core/Logger\"\nimport { Server } from \"../../core/rpc/Server\"\nimport { isRpcServer } from \"../../core/ServiceNames\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { RpcServiceHandlers } from \"./RpcServiceHandlers\"\n\nconst logger = lazy(() => mkLogger(\"RpcServer\"))\nexport const rpcServer = lazy(async () => {\n  if (!(await isRpcServer())) return\n  logger().info(\"Setting up RPC...\")\n  const port = Settings.rpcPort.valueOrDefault\n  const unref = true\n  const s = new Server(port, unref)\n  s.addSimpleHandlers(RpcServiceHandlers())\n  await s.start()\n\n  logger().info(\"RPC service serving port \" + s.port)\n  return s\n})\n", "import { thenMap, thenMapOr } from \"../core/async/Promise\"\nimport { Broadcaster } from \"../core/rpc/Broadcaster\"\nimport { rpcClient } from \"./rpc/RpcClient\"\nimport { rpcServer } from \"./rpc/RpcServer\"\nimport { Event } from \"../core/event/SimpleEventEmitter\"\n\nexport const BroadcasterImpl: Broadcaster = {\n  broadcast: (event: Event, args?: any) =>\n    thenMapOr(\n      rpcServer(),\n      ea => ea.broadcast(event, args),\n      () => thenMap(rpcClient(), ea => ea.broadcast(event, args))\n    )\n}\n", "import { AdvisoryLockProvider } from \"../../core/async/AdvisoryLockProvider\"\nimport { untilTrue } from \"../../core/async/until\"\nimport { nowish } from \"../../core/date/Date\"\nimport { elapsedAsync } from \"../../core/Elapsed\"\nimport { uid } from \"../../core/UID\"\nimport { minuteMs, secondMs } from \"../../fe/Date\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { SyncOrAsync } from \"../../fe/OptAsync\"\nimport { randomInt } from \"../../fe/Random\"\nimport { AdvisoryLockStats } from \"../AdvisoryLockStats\"\nimport { Model } from \"./Model\"\n\nexport const CurrentLockHoldersSql = `\nSELECT\n  al1.name,\n  al1.lockId\nFROM\n  AdvisoryLock AS al1\n  LEFT OUTER JOIN AdvisoryLock AS al2 ON al1.name = al2.name\n  AND al1.createdAt > al2.createdAt\nWHERE\n  al2.createdAt IS NULL\n`.replace(/\\s+/, \" \")\n\nexport class AdvisoryLock extends Model {\n  static readonly tableName = \"AdvisoryLock\"\n  static readonly uniqueColumnName = \"name,lockId\"\n\n  name?: string\n  lockId?: string\n  createdAt?: number\n  acquired?: number\n\n  static vacuum(staleMs = 30 * minuteMs) {\n    return this.dbl.runf(q =>\n      q.where(\"createdAt\", \"<=\", Date.now() - staleMs).delete()\n    )\n  }\n\n  static async currentAcquiredLocks(): Promise<string[]> {\n    return this.dbl.pluckAllf(q =>\n      q.select(\"name\").where({ acquired: 1 })\n    ) as any\n  }\n\n  static async allLocks(): Promise<string[]> {\n    return this.dbl.pluckAllf(q => q.select(\"name\")) as any\n  }\n\n  static async withLocks<T>({\n    lockNames,\n    f,\n    timeoutMs\n  }: {\n    lockNames: string[]\n    f: (lockId: string) => SyncOrAsync<T>\n    timeoutMs: number\n  }): Promise<Partial<AdvisoryLockStats<T>>> {\n    const start = Date.now()\n    const stats: Partial<AdvisoryLockStats<T>> = {}\n    const lockId = uid()\n    this.logger().debug(\"withLocks()\", { lockNames, lockId })\n    const lockPojos = (stats.locks = lockNames.map(name => ({\n      name,\n      lockId,\n      acquired: 0, // insert as un-acquired\n      createdAt: Date.now()\n    })))\n    await this.tx(db => db.runf(q => q.insert(lockPojos)))\n    const warn = lazy(() => this.logger().warn(\"long wait time for\", lockNames))\n    try {\n      const acquired = await untilTrue(\n        async () => {\n          const expectErrors = true\n          // atomically set all acquired to true, or fail all atomically:\n          const result = await this.tx(\n            db => db.runf(q => q.where({ lockId }).update({ acquired: 1 })),\n            expectErrors\n          )\n          if (result == null && !nowish(start, 5 * secondMs)) warn()\n          return result != null\n        },\n        { timeoutMs, timeBetweenMs: randomInt(5, 500) }\n      )\n      this.logger().info(\"withLocks()\", { lockNames, acquired })\n\n      if (acquired) {\n        stats.acquireMs = Date.now() - start\n        const r = await elapsedAsync(async () => f(lockId))\n        stats.result = r.result\n        stats.runMs = r.elapsedMs\n      }\n    } finally {\n      const r = await elapsedAsync(() =>\n        AdvisoryLock.tx(db => db.runf(q => q.where({ lockId }).delete()))\n      )\n      stats.releaseMs = r.elapsedMs\n      stats.released = true\n    }\n    return stats\n  }\n}\n\nexport const withAdvisoryLocks = <T>(\n  lockNames: string[],\n  f: () => Promise<T>\n): Promise<T> =>\n  AdvisoryLock.withLocks({ lockNames, f, timeoutMs: minuteMs }).then(\n    r => r.result!\n  )\n\nexport const DbAdvisoryLockProvider: AdvisoryLockProvider = {\n  withAdvisoryLocks\n}\n", "import { range, stepRange } from \"../../fe/Array\"\nimport { mapFinite } from \"../../fe/Number\"\nimport { concat, greatestIndex, leastIndex } from \"../Array\"\nimport { Average } from \"./Average\"\nimport { mode, sum } from \"./Vector\"\n\nexport function vecXvec(a: number[], b: number[]): number[] {\n  return a.map((v, idx) => v * b[idx])\n}\n\nexport function matXvec(matrix: number[][], vector: number[]): number[] {\n  return matrix.map((row, rowIdx) => {\n    if (row.length !== vector.length) {\n      throw new Error(\"misshaped matrix on row \" + rowIdx)\n    }\n    return sum(row.map((col, colIdx) => col * vector[colIdx]))\n  })\n}\n\nexport interface Index2d {\n  col: number\n  row: number\n}\n\n/**\n * @param to is exclusive, like slice\n */\nexport function slice(m: number[][], from: Index2d, to: Index2d): number[][] {\n  const rowFrom = Math.max(0, from.row)\n  const rowTo = Math.min(m.length, to.row) // range is exclusive\n  const colFrom = Math.max(0, from.col)\n  const colTo = Math.min(m[0].length, to.col)\n  return range(rowFrom, rowTo, row => m[row].slice(colFrom, colTo))\n}\n\nexport function index1D(dim: Index2d, row: number, col: number) {\n  return row * dim.col + col\n}\n\n/**\n * Returns the index values for a 1d matrix that correspond with the given\n * from and to.\n * @param dim holds the number of rows and columns in the 2d matrix\n * @param from inclusive\n * @param to exclusive\n */\nexport function submatrixForEach(\n  dim: Index2d,\n  from: Index2d,\n  to: Index2d,\n  f: (i: number) => any\n): void {\n  const rowFrom = Math.floor(Math.max(0, from.row))\n  const rowTo = Math.ceil(Math.min(dim.row, to.row)) // range is exclusive\n  const colFrom = Math.floor(Math.max(0, from.col))\n  const colTo = Math.ceil(Math.min(dim.col, to.col))\n  for (let row = rowFrom; row < rowTo; row++) {\n    for (let col = colFrom; col < colTo; col++) {\n      f(row * dim.col + col)\n    }\n  }\n}\n\nexport function submatrixMagnitude(\n  m: number[],\n  dim: Index2d,\n  from: Index2d,\n  to: Index2d\n): number {\n  let agg = 0\n  submatrixForEach(dim, from, to, i => mapFinite(m[i], v => (agg += v * v)))\n  return Math.sqrt(agg)\n}\n\nexport function submatrixStdDev(\n  m: number[],\n  dim: Index2d,\n  from: Index2d,\n  to: Index2d\n): number {\n  const a = new Average()\n  submatrixForEach(dim, from, to, i => mapFinite(m[i], v => a.push(v)))\n  return a.stdDev!\n}\n\nexport function submatrixMode(\n  m: number[],\n  dim: Index2d,\n  from: Index2d,\n  to: Index2d\n): number {\n  const arr: number[] = []\n  submatrixForEach(dim, from, to, i => mapFinite(m[i], v => arr.push(v)))\n  return mode(arr)!\n}\n\n/**\n * Returns the quarter submatrix with the largest magnitude, in quadrant order:\n *\n * 1 | 0\n * - + -\n * 2 | 3\n */\nexport function leastMagQuarter(m: number[], dim: Index2d): number {\n  const c = dim.col\n  const r = dim.row\n  const quarterMagnitudes = [\n    submatrixMagnitude(m, dim, { col: c / 2, row: 0 }, { col: c, row: r / 2 }),\n    submatrixMagnitude(m, dim, { col: 0, row: 0 }, { col: c / 2, row: r / 2 }),\n    submatrixMagnitude(m, dim, { col: 0, row: r / 2 }, { col: c / 2, row: r }),\n    submatrixMagnitude(m, dim, { col: c / 2, row: r / 2 }, { col: c, row: r })\n  ]\n  return leastIndex(quarterMagnitudes)\n}\n\nexport function leastVariantQuarter(m: number[], dim: Index2d): number {\n  const c = dim.col\n  const r = dim.row\n  return leastIndex([\n    submatrixStdDev(m, dim, { col: c / 2, row: 0 }, { col: c, row: r / 2 }),\n    submatrixStdDev(m, dim, { col: 0, row: 0 }, { col: c / 2, row: r / 2 }),\n    submatrixStdDev(m, dim, { col: 0, row: r / 2 }, { col: c / 2, row: r }),\n    submatrixStdDev(m, dim, { col: c / 2, row: r / 2 }, { col: c, row: r })\n  ])\n}\n\n/**\n * Returns the quarter submatrix with the largest magnitude, in quadrant order:\n *\n *   0\n * 1 + 3\n *   2\n */\nexport function greatestHalf(m: number[], dim: Index2d): number {\n  const c = dim.col\n  const r = dim.row\n  const quarterMagnitudes = [\n    submatrixMode(m, dim, { col: 0, row: 0 }, { col: c, row: r / 2 }),\n    submatrixMode(m, dim, { col: 0, row: 0 }, { col: c / 2, row: r }),\n    submatrixMode(m, dim, { col: 0, row: r / 2 }, { col: c, row: r }),\n    submatrixMode(m, dim, { col: c / 2, row: 0 }, { col: c, row: r })\n  ]\n  return greatestIndex(quarterMagnitudes)\n}\n\nexport function submatrixCollect(\n  dim: Index2d,\n  from: Index2d,\n  to: Index2d\n): number[] {\n  const r: number[] = []\n  submatrixForEach(dim, from, to, i => r.push(i))\n  return r\n}\n\n/**\n * Reduce to dimXdim matrix, using the mode of surrounding values in the\n * matrix\n */\nexport function modeReduce(\n  m: number[],\n  fromDim: Index2d,\n  toDim: Index2d\n): number[] {\n  const colDelta = Math.floor(fromDim.col / toDim.col)\n  const rowDelta = Math.floor(fromDim.row / toDim.row)\n  const avg = new Average(Math.ceil(colDelta * rowDelta))\n  return concat(\n    ...stepRange(0, fromDim.row, rowDelta, rowStart =>\n      stepRange(0, fromDim.col, colDelta, colStart => {\n        avg.clear()\n        const from = { col: colStart, row: rowStart }\n        const to = { col: colStart + colDelta, row: rowStart + rowDelta }\n        submatrixForEach(fromDim, from, to, i =>\n          mapFinite(m[i], ea => avg.push(ea))\n        )\n        return avg.sampleMode\n      })\n    )\n  )\n}\n", "import { map } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { clamp, round } from \"../../fe/Number\"\nimport { toS } from \"../../fe/toS\"\nimport { leastBy } from \"../Array\"\nimport { bitUnzip, bitZip } from \"../math/Bits\"\nimport { matXvec, vecXvec } from \"../math/Matrix\"\nimport { leftPad } from \"../String\"\n\n// From http://www.brucelindbloom.com\nconst srgb2xyz = [\n  [0.4124564, 0.3575761, 0.1804375],\n  [0.2126729, 0.7151522, 0.072175],\n  [0.0193339, 0.119192, 0.9503041]\n]\nconst xyz2srgb = [\n  [3.2404542, -1.5371385, -0.4985314],\n  [-0.969266, 1.8760108, 0.041556],\n  [0.0556434, -0.2040259, 1.0572252]\n]\n\nexport type Triplet = [number, number, number]\n\nexport function rgbhex2triplet(rgbHex: string): Maybe<Triplet> {\n  return map(\n    toS(rgbHex).match(/^#?([0-9a-f]{2})([0-9a-f]{2})([0-9a-f]{2})$/i),\n    m => [m[1], m[2], m[3]].map(ea => parseInt(ea, 16)) as Triplet\n  )\n}\n\nexport function rgbhex2Lab(rgbHex: string): Maybe<Triplet> {\n  return map(rgbhex2triplet(rgbHex), rgb2lab)\n}\n\nexport function rgbhex2Labhash(\n  rgbHex: string,\n  bitDepth: number\n): Maybe<number> {\n  return map(rgbhex2triplet(rgbHex), ea => labhash(rgb2lab(ea), bitDepth))\n}\n\nexport function lab2rgbhex(lab: Triplet): string {\n  return `#${lab2rgb(lab)\n    .map(ea => leftPad(ea.toString(16), 2, \"0\"))\n    .join(\"\")}`\n}\n\n/**\n * Convert from flattened RGB triplets to flattened L*a*b* triplets\n */\nexport function rgb2labs(rgb: Buffer): number[] {\n  const lab: number[] = []\n  for (let i = 0; i < rgb.length; i += 3) {\n    lab.push(...rgb2lab([rgb[i], rgb[i + 1], rgb[i + 2]]))\n  }\n  return lab\n}\n\n/**\n * where rgb values are [0,255]\n */\nexport function rgb2lab(rgb: Triplet): Triplet {\n  return xyz2lab(rgb2xyz(rgb))\n}\n\nexport function lab2rgb(lab: Triplet): Triplet {\n  return clampRGB(xyz2rgb(lab2xyz(lab)))\n}\n\nexport function clampRGB(rgb: Triplet): Triplet {\n  return (\n    // the [0], [1], [2] allows rgb to be a Buffer.slice:\n    [rgb[0], rgb[1], rgb[2]]\n      // clamp values to expected reasonable [0, 255] range:\n      .map(ea => clamp(0, 255, ea)) as Triplet\n  )\n}\n\nexport function clampLab(lab: Triplet): Triplet {\n  return [\n    clamp(0, 100, lab[0]),\n    clamp(-100, 100, lab[1]),\n    // -108 seems to be wrong, but RGB(0,0,255) ->\n    // L*a*b*(32.297,79.188,-107.860) according to\n    // http://www.easyrgb.com/en/convert.php#inputFORM and\n    // http://colormine.org/convert/rgb-to-lab\n    clamp(-108, 100, lab[2])\n  ]\n}\n\nexport function rgb2xyz(rgb: Triplet): Triplet {\n  // See http://www.brucelindbloom.com/index.html?Eqn_RGB_XYZ_Matrix.html\n  const srgb = clampRGB(rgb)\n    .map(ea => ea / 255)\n    .map(ea =>\n      ea > 0.04045 ? Math.pow((ea + 0.055) / 1.055, 2.4) : ea / 12.92\n    )\n  return matXvec(srgb2xyz, srgb) as any // because TS doesn't support tuples well\n}\n\n// https://en.wikipedia.org/wiki/Lab_color_space#CIELAB\n\nconst RefWhite = {\n  X: 0.95047,\n  Y: 1,\n  Z: 1.08883\n}\n\n// http://www.brucelindbloom.com/index.html?Eqn_XYZ_to_Lab.html\n\nconst epsilon = 216 / 24389 // 0.00885\nconst kappa = 24389 / 27 // 903.3\n\nexport function xyz2lab(xyz: Triplet): Triplet {\n  const [fx, fy, fz] = vecXvec(xyz, [\n    1 / RefWhite.X,\n    1 / RefWhite.Y,\n    1 / RefWhite.Z\n  ]).map(t => (t > epsilon ? Math.pow(t, 1 / 3) : (kappa * t + 16) / 116))\n\n  return [116 * fy - 16, 500 * (fx - fy), 200 * (fy - fz)]\n}\n\nexport function lab2xyz(lab: Triplet): Triplet {\n  // the [0], [1], [2] allows lab to be a Buffer.slice:\n  const [l, a, b] = clampLab(lab)\n  const fy = (l + 16) / 116\n  const fx = a / 500 + fy\n  const fz = fy - b / 200\n\n  const fx3 = fx * fx * fx\n  const fz3 = fz * fz * fz\n\n  const xr = fx3 > epsilon ? fx3 : (116.0 * fx - 16.0) / kappa\n  const yr = l > 8 ? Math.pow(fy, 3.0) : l / kappa\n  const zr = fz3 > epsilon ? fz3 : (116.0 * fz - 16.0) / kappa\n\n  return [xr * RefWhite.X, yr * RefWhite.Y, zr * RefWhite.Z]\n}\n\nexport function xyz2rgb(xyz: Triplet): Triplet {\n  return matXvec(xyz2srgb, xyz).map(v => {\n    const sign = v < 0 ? -1 : 1\n    const l = v * sign\n    return round(\n      255 *\n        sign *\n        (l <= 0.0031308 ? 12.92 * l : 1.055 * Math.pow(l, 1 / 2.4) - 0.055)\n    )\n  }) as any // < boooo TS tuples\n}\n\nexport function labhash(lab: Triplet, bitDepth: number): Maybe<number> {\n  return bitZip({\n    dims: [\n      { value: lab[0], min: 0, max: 100 },\n      { value: lab[1], min: -80, max: 80 },\n      { value: lab[2], min: -80, max: 80 }\n    ],\n    bitDepth\n  })\n}\n\nexport function unlabhash(hash: number, bitDepth: number): Maybe<Triplet> {\n  return bitUnzip(hash, {\n    dims: [\n      { min: 0, max: 100 },\n      { min: -80, max: 80 },\n      { min: -80, max: 80 }\n    ],\n    bitDepth\n  }) as any\n}\n\nexport function cie76_delta_e(lab1: Triplet, lab2: Triplet): number {\n  return Math.sqrt(\n    (lab2[0] - lab1[0]) ** 2 +\n      (lab2[1] - lab1[1]) ** 2 +\n      (lab2[2] - lab1[2]) ** 2\n  )\n}\n\ntype Lab = {\n  L: number\n  a: number\n  b: number\n}\n\n/**\n * @see https://en.wikipedia.org/wiki/Color_difference#CIE94\n * @return the perceptual difference. <= 2 is not perceptable.\n */\n\nexport function cie94_delta_e(a: Triplet, b: Triplet) {\n  return d94({ L: a[0], a: a[1], b: a[2] }, { L: b[0], a: b[1], b: b[2] })\n}\n\nfunction d94(lab1: Lab, lab2: Lab) {\n  const _Kl = 1.0\n  const _K1 = 0.045\n  const _K2 = 0.015\n\n  const dL = lab1.L - lab2.L\n  const dA = lab1.a - lab2.a\n  const dB = lab1.b - lab2.b\n  const c1 = Math.sqrt(lab1.a * lab1.a + lab1.b * lab1.b)\n  const c2 = Math.sqrt(lab2.a * lab2.a + lab2.b * lab2.b)\n  const dC = c1 - c2\n\n  let deltaH = dA * dA + dB * dB - dC * dC\n  deltaH = deltaH < 0 ? 0 : Math.sqrt(deltaH)\n\n  return Math.sqrt(\n    (dL / _Kl) ** 2 +\n      (dC / (1.0 + _K1 * c1)) ** 2 +\n      (deltaH / (1.0 + _K2 * c1)) ** 2\n  )\n}\n\nexport function diffCIE94rgb(rgb1: Triplet, rgb2: Triplet): number {\n  return cie94_delta_e(rgb2lab(rgb1), rgb2lab(rgb2))\n}\n\nexport function closestLab(haystack: Triplet[], needle: Triplet) {\n  return leastBy(haystack, ea => cie94_delta_e(ea, needle))\n}\n\nexport const MinCie = 2 // barely perceptable\nexport const MaxCie = 50 // very perceptable\n\n/**\n * Use `diffCIE94` to return a correlation value between 1 (imperceptible\n * difference) and 0 (largest possible difference)).\n */\nexport function diffCIE94Corr(\n  lab1: Maybe<Triplet>,\n  lab2: Maybe<Triplet>\n): number {\n  if (lab1 == null || lab2 == null) return 1\n  return clamp(0, MaxCie, cie94_delta_e(lab1, lab2) - MinCie) / MaxCie\n}\n\nexport function rgbhex2hsv(rgb: string): Triplet {\n  let rDiff\n  let gDiff\n  let bDiff\n  let h = 0\n  let s = 0\n\n  const [r, g, b] = rgbhex2triplet(rgb)!.map(ea => ea / 255)\n  const v = Math.max(r, g, b)\n  const diff = v - Math.min(r, g, b)\n  const diffC = (c: number) => (v - c) / 6 / diff + 1 / 2\n\n  if (diff !== 0) {\n    s = diff / v\n    rDiff = diffC(r)\n    gDiff = diffC(g)\n    bDiff = diffC(b)\n\n    if (r === v) {\n      h = bDiff - gDiff\n    } else if (g === v) {\n      h = 1 / 3 + rDiff - bDiff\n    } else if (b === v) {\n      h = 2 / 3 + gDiff - rDiff\n    }\n\n    if (h < 0) {\n      h += 1\n    } else if (h > 1) {\n      h -= 1\n    }\n  }\n\n  return [h * 360, s * 100, v * 100]\n}\n", "import sharp = require(\"sharp\")\nimport { flatten, stepRange, uniq } from \"../../fe/Array\"\nimport { notBlank } from \"../../fe/Blank\"\nimport { secondMs } from \"../../fe/Date\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { times } from \"../../fe/Number\"\nimport { lt } from \"../../fe/Primitive\"\nimport { MB } from \"../../fe/Units\"\nimport { time } from \"../async/PromiseTimer\"\nimport { elapsedAsync } from \"../Elapsed\"\nimport {\n  onClearCache,\n  onFileChanged,\n  onFileCopied\n} from \"../event/EventEmitter\"\nimport { FifoCache } from \"../FifoCache\"\nimport { PosixFile } from \"../fs/PosixFile\"\nimport { ms2level } from \"../log/Logger\"\nimport { mkLogger } from \"../Logger\"\nimport { b64encode } from \"../math/b64\"\nimport { avg, mode, modes } from \"../math/Vector\"\nimport { Settings } from \"../settings/Settings\"\nimport { labhash, rgb2lab, Triplet } from \"./Colorspace\"\nimport { dimensions } from \"./FileDimensions\"\nimport { imgCacheDir } from \"./ImgCache\"\nimport { sharpReadable } from \"./SharpReadable\"\n\n// How many bits per color for N modes?\n\n// 6 bits shared across 3 channels means 2 bits (4 values) per channel, 4 ** 3 =\n// 64 colors, but ends up only being ~21 colors in practice due to the\n// non-uniform L*a*b* colorspace\n\n// Total possible uniq labhashes\n// for 6: 40\n// for 7: 70\n// for 8: 107\n// for 9: 172\n// for 10: 292\n// for 11: 460\n// for 12: 589\n\n// But in practice, photos only have a subset of the full colorspace:\n\n// for 8, ~35 colors.\n// for 9, ~38 colors.\n// for 10, ~49 colors\n// for 11, ~47 colors (! worse than 10)\n// for 12, ~80 colors\n// for 15, ~95 colors (still ample collisions)\n\nexport const ModeBits = 12 // 12 = 4 bits per L*, a*, and b channels\n\n// with ModeBits = 12\n// with 5: labModesCorr: { k: 18, avg: 0.931, min: 0.69, max: 1, sd: 0.09 }\n// with 6: labModesCorr: { k: 18, avg: 0.942, min: 0.72, max: 1, sd: 0.08 }\n// with 7: labModesCorr: { k: 18, avg: 0.946, min: 0.74, max: 1, sd: 0.08 }\n\n// with ModeBits = 15\n// with 5: labModesCorr: { k: 18, avg: 0.962, min: 0.79, max: 1, sd: 0.06 }\n// with 6: labModesCorr: { k: 18, avg: 0.959, min: 0.79, max: 1, sd: 0.05 }\n// with 7: labModesCorr: { k: 18, avg: 0.954, min: 0.79, max: 1, sd: 0.06 }\n\n// 15 ModeBits means the modes are taken up with fairly similar colors (and\n// makes library preview-similarity tests fail). 12 seems to be a reasonable\n// compromize between accuracy and posterization.\n\n// SearchHash only looks at lightness, and needs to be < 52 bits. 7x7 is 49:\n\n// export const SearchHashDim = 5\n// export const SearchHashBits = SearchHashDim * SearchHashDim * 3\n// export const MaxSearchHash = 2 ** SearchHashBits\n\nexport const ModeCount = 7 // lucky. TODO: Make sure this matches the AssetFile.modeN fields\n\n/**\n * How many bits-wide values can be bit-concatted into a single value?\n */\nexport function maxPerBits(bits: number): number {\n  // We don't want to overflow Javascript numbers, hence the 52:\n  return Math.floor(52 / bits)\n}\n\nconst logger = mkLogger(\"ImageHash\")\n\nconst instanceCacheMaxSize = 250\n\nconst cache = new FifoCache<PromiseMaybe<ImageHash>>(instanceCacheMaxSize)\n\nonClearCache(() => cache.clear())\nonFileChanged(path => (notBlank(path) ? cache.delete(path) : cache.clear()))\n\nonFileCopied((srcNativePath: string, destNativePath: string) =>\n  map(cache.get(srcNativePath), result => {\n    return cache.getOrSet(destNativePath, () => result)\n  })\n)\n\nexport interface ImageHash {\n  /**\n   * b64 8x8 L*a*b* triplet ahash, rotation invariant\n   */\n  meanHash: string\n\n  /**\n   * Top N most dominant colors in labhash:\n   */\n  modes: number[]\n}\n\n// If this is 4, SyncService tests fail to validate against preview images:\nexport const HashDim = 8\n// larger values don't seem to impact accuracy:\n// meanHamm 3: { k: 18, avg: 0.962, min: 0.86, max: 1, sd: 0.05 }\n// meanHamm 4: { k: 18, avg: 0.968, min: 0.89, max: 1, sd: 0.04 }\n// meanHamm 5: { k: 18, avg: 0.963, min: 0.87, max: 1, sd: 0.03 },\n// meanHamm 6: { k: 18, avg: 0.958, min: 0.88, max: 1, sd: 0.04 },\n// meanHamm 7: { k: 18, avg: 0.945, min: 0.86, max: 1, sd: 0.04 }\n// meanHamm 8: { k: 18, avg: 0.959, min: 0.85, max: 1, sd: 0.04 },\n\n// Most EXIF thumbprints are 120x160, so less than that should be fine.\n// NOTE: smaller dimensions (like 48) cause panoramas to fail tests.\nexport const ModeDim = {\n  width: 96,\n  height: 96\n}\n\nfunction bitsToB64(m: number[]): string {\n  return b64encode(BigInt(\"0b0\" + m.map(ea => (ea === 1 ? 1 : 0)).join(\"\")))\n}\n\nfunction rgb2labs(rgb: Buffer): [number[], number[], number[]] {\n  const lab: [number[], number[], number[]] = [[], [], []]\n  for (let i = 0; i < rgb.length; i += 3) {\n    const v = rgb2lab([rgb[i], rgb[i + 1], rgb[i + 2]])\n    lab[0].push(v[0])\n    lab[1].push(v[1])\n    lab[2].push(v[2])\n  }\n  return lab\n}\n\n/**\n * @param labs [[L* values], [a* values], [b* values]]\n */\nfunction labsAreGreyscale(labs: Triplet[]) {\n  const thresh = Settings.greyscaleColorThreshold.valueOrDefault\n  for (const ea of labs) {\n    if (Math.abs(ea[1]) > thresh || Math.abs(ea[2]) > thresh) return false\n  }\n  return true\n}\n\n// function computeRotation({\n//   labs,\n//   isGreyscale\n// }: {\n//   labs: [number[], number[], number[]]\n//   isGreyscale: boolean\n// }) {\n//   const m = labs[0].map((l, idx) =>\n//     Math.round(isGreyscale ? l : l * 10 + labs[1][idx] - labs[2][idx])\n//   )\n//   return normalizeRotation(\n//     Settings.imageHashRotation.valueOrDefault ===\n//       \"brightness-submatrix-magnitude\"\n//       ? // the +180 makes most photos not need rotation\n//         leastMagQuarter(labs[0], { col: HashDim, row: HashDim }) * 90 + 180\n//       : leastVariantQuarter(m, { col: HashDim, row: HashDim }) * 90\n//   )!\n// }\n\nfunction middle(arr: number[]) {\n  return 1 < 2 ? avg(arr)! : avg([avg(arr), mode(arr)])!\n}\n\nasync function _imageHash(file: PosixFile): Promise<Maybe<ImageHash>> {\n  const l = mkLogger(\"ImageHash(\" + file + \")\")\n  // const e = mkElapsed(\"ImageHash\")\n  try {\n    const ignoreRotation = true\n    const readable = await sharpReadable(file, ModeDim, ignoreRotation)\n    if (readable == null) {\n      l.warn(\"Cannot build readable stream\")\n      return\n    }\n    // e.elapsed(\"sharpReadable\")\n\n    const fileDim = await dimensions(file)\n    if (fileDim == null) {\n      l.warn(\"Can't extract dimensions\")\n      return\n    }\n    // e.elapsed(\"dimensions\")\n\n    let s1 = sharp(readable.nativePath)\n      // PNGs and TIFFs can have an alpha channel. We don't want that.\n      .removeAlpha()\n\n    if (\n      readable.isDescendantOf(await imgCacheDir()) &&\n      lt(await readable.size(), 2 * MB)\n    ) {\n      // EXIF preview images sometimes have black borders. Trim that (but only\n      // if it's a thumb: trim() is slow!)\n      s1 = s1.trim(4)\n    }\n\n    // We have to do the RGB to L*a*b* conversion because raw() doesn't work:\n    // https://github.com/lovell/sharp/issues/681\n    // .toColorspace(\"srgb\")\n    s1 = s1.resize({\n      ...ModeDim,\n      // fill gets .95/.92 matched hamm\n      // cover gets ~.8 matched hamm\n      // contain gets .97/.88 matched hamm (worse than fill)\n      // default fit gets .84/.87 matched hamm (worse than fill)\n      fit: sharp.fit.fill, // < Ignore the aspect ratio of the input and stretch to both provided dimensions\n      // kernel: \"lanczos3\",\n      // lanczos3 gets the best ImageHash.spec scores.\n      // mitchell, lanczos2 gets lower scores than lanczos3\n      // nearest fails tests!\n      kernel: sharp.kernel.lanczos3,\n      fastShrinkOnLoad: true, // < slightly better scores with true\n      withoutEnlargement: true\n    })\n\n    // NOTE: DON'T NORMALIZE s1, it mucks up what the actual dominant colors are!\n\n    // if (!ignoreRotation) {\n    //   // Sharp doesn't do rotation correctly with raw images, so we have to be\n    //   // explicit with the rotation:\n    //   await thenMap(readRotation(file), r => (s1 = s1.rotate(r)))\n    // }\n\n    // await s1\n    //   .clone()\n    //   .jpeg()\n    //   .toFile(\"/tmp/image-hash-\" + file.base + \"-\" + ModeDim.width + \"w.jpg\")\n\n    const { data: rgb1, info: rgbInfo } = await s1\n      .raw()\n      .toBuffer({ resolveWithObject: true })\n    // e.elapsed(\"big resize done\")\n\n    const bigLAB = stepRange(0, rgb1.length, 3, i =>\n      rgb2lab([rgb1[i], rgb1[i + 1], rgb1[i + 2]])\n    )\n    const isGreyscale = labsAreGreyscale(bigLAB)\n\n    let labModes = modes(\n      bigLAB.map(ea => labhash(ea, ModeBits)!),\n      ModeCount\n    )\n\n    if (!isGreyscale && Settings.includeSharpDominantColor.valueOrDefault) {\n      const stats = await time(\n        `img.imageHash.stats ${file.ext.toUpperCase()}`,\n        () => s1.stats()\n      )\n      const dominant = labhash(\n        rgb2lab([stats.dominant.r, stats.dominant.g, stats.dominant.b]),\n        ModeBits\n      )\n      labModes = uniq([dominant, ...labModes]).slice(0, ModeCount)\n    }\n\n    // e.elapsed(\"Dominant colors\")\n\n    const s2 = sharp(rgb1, {\n      raw: { ...rgbInfo, channels: 3 }\n    }).resize({\n      width: HashDim,\n      height: HashDim\n    })\n\n    // DON'T: .toColorspace(\"srgb\"), because we already forced the colorspace, no need to do it twice.\n\n    // await s2\n    //   .clone()\n    //   .jpeg()\n    //   .toFile(\"/tmp/image-hash-\" + file.base + \"-\" + HashDim + \"w.jpg\")\n\n    const { data: rgb2 } = await s2.raw().toBuffer({ resolveWithObject: true })\n\n    // e.elapsed(\"small resize done\")\n\n    // [[L* values], [a* values], [b* values]]:\n\n    const lab2 = rgb2labs(rgb2)\n\n    // Halfway-normalize the l channel to make hash somewhat invariant to\n    // brightness adjustments & computational imagery.\n\n    // (Unfortunately, this breaks almost as many images as it fixes, so it's commented out):\n\n    // if (1 < 0)\n    //   lab2[0] = normalize({\n    //     x: lab2[0],\n    //     normMin: 0,\n    //     normMax: 100,\n    //     strength: 0.5\n    //   })\n\n    // [L* mean, a* mean, b* mean]:\n    const labMeans = isGreyscale\n      ? [middle(lab2[0]), 0, 0]\n      : times(3, channel => middle(lab2[channel])!)\n\n    // e.elapsed(\"means\")\n\n    // const degrees = rotationInvariant\n    //   ? computeRotation({ labs: lab2, isGreyscale })\n    //   : 0\n\n    // const meanBits0 =\n    //   degrees === 0\n    //     ? undefined\n    //     : (isGreyscale ? [lab2[0]] : lab2).map((m, i) => {\n    //         const mean = labMeans[i]\n    //         return m.map(ea => (ea >= mean ? 1 : 0))\n    //       })\n\n    const rotLab2 = isGreyscale ? [lab2[0]] : lab2\n    // .map(m => rotateSquareMatrix(m, degrees) )\n\n    // bits are set whose pixels exceed the mean for their L*a*b* component:\n    const meanBits = rotLab2.map((m, i) => {\n      const mean = labMeans[i]\n      return m.map(ea => (ea >= mean ? 1 : 0))\n    })\n    // console.log(\"meanBits\", {\n    //   degrees,\n    //   meanL: labMeans[0],\n    //   L: rotLab2[0],\n    //   means: meanBits[0]\n    // })\n    if (isGreyscale) {\n      const zeros = times(HashDim * HashDim, () => 0) as 0[]\n      meanBits.push(zeros, zeros)\n      // meanBits0?.push(zeros, zeros)\n    }\n    // e.elapsed(\"meanBits\")\n\n    // We don't care that it's all L* bits, and then all a* bits, ..., because\n    // position doesn't matter to hamming distance.\n    // const meanHash0 = map(meanBits0, ea => bitsToB64(flatten(ea)))\n    const meanHash = bitsToB64(flatten(meanBits))\n\n    // console.log(\"imageHash meanbits for \" + meanHash, {\n    //   lengths: meanBits.map(ea => ea.length),\n    //   bits: flatten(meanBits).join(\"\"),\n    //   l: BigInt(\"0b0\" + meanBits[0].join(\"\")),\n    //   b10: BigInt(\"0b0\" + flatten(meanBits).join(\"\"))\n    // })\n    // e.elapsed(\"meanHash\")\n\n    return {\n      meanHash,\n      // meanHash0,\n      isGreyscale,\n      // degrees,\n      modes: labModes\n    } as any\n  } catch (err) {\n    l.warn(\"Failed to imageHash(\" + file.nativePath + \")\", err)\n    return undefined\n  }\n}\n\n/**\n * Image fingerprint to find duplicate images (so strive for no false\n * positives).\n *\n * Should match 90/180/270 degree rotations.\n *\n * May match against global exposure changes.\n *\n * Does not need to match cropping or free rotations.\n *\n * Moving the pixels to L*a*b* means we can pick bin to perceptual ranges.\n */\nexport async function imageHash(file: PosixFile): Promise<Maybe<ImageHash>> {\n  return cache.getOrSet(file.nativePath, () =>\n    elapsedAsync(() =>\n      time(`img.imageHash${file.ext.toUpperCase()}`, () => _imageHash(file))\n    ).then(({ elapsedMs, result }) => {\n      return logger.tap({\n        level: ms2level(elapsedMs, 4 * secondMs),\n        msg: \"imageHash()\",\n        result,\n        meta: {\n          file: file.nativePath,\n          elapsedMs\n        }\n      })\n    })\n  )\n}\n", "import { Database } from \"better-sqlite3\"\nimport { batches, greatestBy } from \"../../core/Array\"\nimport { isoToLocal, isoToPrecisionMs } from \"../../core/date/ExtendedDate\"\nimport { isoToOffsetMinutes } from \"../../core/date/FuzzyDate\"\nimport { labhash, Triplet, unlabhash } from \"../../core/img/Colorspace\"\nimport { ModeBits, ModeCount } from \"../../core/img/ImageHash\"\nimport { mkLogger } from \"../../core/Logger\"\nimport { splitBits } from \"../../core/math/Bits\"\nimport { mapGt0 } from \"../../core/Number\"\nimport { escapeRegExp } from \"../../core/RegExp\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport {\n  readSystemSettings,\n  writeSystemSettings\n} from \"../../core/settings/SettingsIO\"\nimport {\n  ensureSuffix,\n  isString,\n  stripPrefixIgnoreCase\n} from \"../../core/String\"\nimport { normalizeURI } from \"../../core/uri/UriNormalization\"\nimport {\n  compact,\n  isEmpty,\n  isNotEmpty,\n  sortBy,\n  sortByInPlace\n} from \"../../fe/Array\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { gt0, times, toInt } from \"../../fe/Number\"\nimport { opt } from \"../../fe/Opt\"\nimport { toS } from \"../../fe/toS\"\nimport { PS_NETWORK_FILESYSTEM_PROTOCOL } from \"../../fe/URI\"\nimport {\n  joinedTagPathBasename,\n  joinTagPath,\n  normalizeTagPath,\n  splitTagPath,\n  TagSep\n} from \"../curators/Taggers\"\n\nconst logger = lazy(() => mkLogger(\"Migrations\"))\n\nconst psnetRe = new RegExp(\n  `^(${escapeRegExp(PS_NETWORK_FILESYSTEM_PROTOCOL)}://.*?/)(.*)$`\n)\n\n// exported for tests\nexport const lowercase_psnet_function = (s: any) =>\n  opt(s)\n    .filter(isString)\n    .flatMap(ea => psnetRe.exec(ea))\n    .map(m => m[1].toLowerCase() + m[2])\n    .getOrElse(() => s)\n\nfunction splitLabs(labModes: number, bits = ModeBits): Triplet[] {\n  return splitBits(labModes, bits).map(ea => unlabhash(ea, bits)) as Triplet[]\n}\n\nexport function plucklabmodeb6(labModes: number, index: number): Maybe<number> {\n  return mapGt0(labModes, () =>\n    map(splitLabs(labModes, 6)[index], ea => labhash(ea, ModeBits))\n  )\n}\n\nexport function tag_path_suffix(path: string): string {\n  return path.endsWith(TagSep) ? path : path + TagSep\n}\n\nfunction mergeTags(db: Database, tagIds: number[]) {\n  if (isEmpty(tagIds)) {\n    logger().warn(\"mergeTags(): empty tagIds\", { tagIds })\n  }\n  function run(sql: string) {\n    return db.prepare(sql).run()\n  }\n\n  const idPaths = new Map(\n    db\n      .prepare(\n        \"SELECT id, _path FROM Tag WHERE id IN (\" + tagIds.join(\",\") + \")\"\n      )\n      .all()\n      .map(({ id, _path }) => [id, _path] as [number, string])\n  )\n  const arr = sortBy(\n    tagIds.map(id => {\n      const path = idPaths.get(id)!\n      return { id, path, base: joinedTagPathBasename(path)! }\n    }),\n    ea => [ea.base, ea.path]\n  )\n\n  // Capitalized should win:\n  arr.reverse()\n\n  logger().info(\"mergeTags()\", { arr })\n  const winner = arr[0]!\n  const winnerId = winner.id\n  if (isEmpty(arr) || !gt0(winnerId)) {\n    logger().warn(\"mergeTags(): empty array, or missing winner\", {\n      arr,\n      winner,\n      winnerId\n    })\n    return\n  }\n  const losers = arr.slice(1)\n\n  if (isNotEmpty(losers)) {\n    const loserIds = losers.map(ea => ea.id).join(\",\")\n    run(\n      `UPDATE OR IGNORE AssetTag SET tagId = ${winnerId} WHERE tagId in (${loserIds})`\n    )\n    run(\n      `UPDATE OR IGNORE Tag SET parentId = ${winnerId} WHERE parentId in (${loserIds})`\n    )\n    run(\n      `UPDATE OR IGNORE Tag SET parentId = ${winnerId} WHERE parentId in (${loserIds})`\n    )\n    run(`DELETE FROM AssetTag WHERE tagId in (${loserIds})`)\n    run(`DELETE FROM Tag WHERE id in (${loserIds})`)\n  }\n\n  const winnerPath = db\n    .prepare(\"select _path from Tag where id = :id\")\n    .get({ id: winnerId })._path as string\n\n  const newTagPrefix = splitTagPath(winnerPath)\n\n  const children = db\n    .prepare(\n      \"SELECT id, _path FROM Tag WHERE id = :winnerId OR _path LIKE :like COLLATE NOCASE\"\n    )\n    .all({\n      winnerId,\n      like: ensureSuffix(winnerPath, TagSep) + \"%\",\n      winnerPath\n    })\n\n  for (const ea of children) {\n    const newPath = joinTagPath([\n      ...newTagPrefix,\n      ...splitTagPath(stripPrefixIgnoreCase(ea._path, winnerPath))\n    ])\n    if (ea._path !== newPath) {\n      logger().info(\"mergeTags(): repairing tag path\", { ea, newPath })\n      db.prepare(\n        // the OR IGNORE should not be needed:\n        \"UPDATE OR IGNORE Tag SET _path = :path, updatedAt = :updatedAt WHERE id = :id\"\n      ).run({\n        id: ea.id,\n        updatedAt: Date.now(),\n        path: newPath\n      })\n    }\n  }\n\n  return logger().tap({\n    msg: \"mergeTags()\",\n    level: \"info\",\n    result: { winner, losers },\n    meta: { tagIds, winnerPath }\n  })\n}\n\nexport function dedupeTags(db: Database) {\n  const rows = db\n    .prepare(\n      [\n        \"SELECT\",\n        \"rtrim(_path, char(31)) as path,\",\n        \"count(*) AS cnt,\",\n        \"group_concat(id) AS ids\",\n        \"FROM Tag\",\n        \"GROUP BY path\",\n        \"COLLATE NOCASE\",\n        \"HAVING cnt > 1\"\n      ].join(\" \")\n    )\n    .all() as { path: string; cnt: number; ids: number[] }[]\n\n  for (const row of rows) {\n    row.ids = compact(\n      toS(row.ids)\n        .split(\",\")\n        .map(ea => toInt(ea))\n    )\n  }\n\n  // longest paths first:\n  sortByInPlace(rows, ea => ea.path).reverse()\n\n  return logger().tap({\n    msg: \"dedupeTags()\",\n    result: rows.map(ea => mergeTags(db, ea.ids)),\n    meta: { rows }\n  })\n}\n\n/**\n * The functions exported in this namespace may be used by migrations that share\n * the same name as the function. \"Applying\" that migration will run that\n * function.\n *\n * !!!REMEMBER TO APPLY db.transaction!!! `db.transaction(() => something)()`\n */\nexport const Migrations = {\n  lowercase_psnet_hostname: (db: Database) => {\n    db.function(\n      \"lowercase_psnet_hostname\",\n      { deterministic: true },\n      lowercase_psnet_function\n    )\n    db.transaction(() => {\n      db.exec(\"DROP INDEX IF EXISTS assetfile_uri_udx\")\n      db.exec(\"UPDATE AssetFile SET uri = lowercase_psnet_hostname(uri)\")\n      db.exec(\"CREATE UNIQUE INDEX assetfile_uri_udx ON AssetFile(uri)\")\n    })()\n  },\n\n  force_stable_channel: async () => {\n    try {\n      // This migration should only be applied by a stable version release, or all\n      // alpha or beta users will downgrade to the prior stable version.\n      await readSystemSettings()\n      const priorValue = Settings.updateChannel.value\n      if (priorValue !== \"stable\") {\n        Settings.updateChannel.value = \"stable\"\n        await writeSystemSettings()\n        logger().info(\"force_stable_channel(): reset updateChannel\", {\n          priorValue\n        })\n      }\n    } catch (err) {\n      logger().error(\"force_stable_channel(): failed: \" + err)\n    }\n  },\n\n  numeric_captured_at: (db: Database) => {\n    db.function(\"isoToLocal\", { deterministic: true }, isoToLocal)\n    db.function(\n      \"isoToOffsetMinutes\",\n      { deterministic: true },\n      isoToOffsetMinutes\n    )\n    db.function(\"isoToPrecisionMs\", { deterministic: true }, isoToPrecisionMs)\n    db.transaction(() => {\n      db.exec(\"ALTER TABLE AssetFile ADD COLUMN capturedAtLocal bigint\")\n      db.exec(\"ALTER TABLE AssetFile ADD COLUMN capturedAtOffset integer\")\n      db.exec(\"ALTER TABLE AssetFile ADD COLUMN capturedAtPrecisionMs integer\")\n      db.exec(\n        \"UPDATE AssetFile SET capturedAtLocal = isoToLocal(capturedAtISO)\"\n      )\n      db.exec(\n        \"UPDATE AssetFile SET capturedAtOffset = isoToOffsetMinutes(capturedAtISO)\"\n      )\n      db.exec(\n        \"UPDATE AssetFile SET capturedAtPrecisionMs = isoToPrecisionMs(capturedAtISO)\"\n      )\n      db.exec(\"DROP INDEX asset_captured_at_geohash_idx\")\n      db.exec(\"DROP INDEX assetfile_exifuid_idx\")\n      db.exec(\n        \"CREATE INDEX assetfile_capturedAtLocal_idx ON AssetFile(capturedAtLocal)\"\n      )\n    })()\n  },\n\n  spread_modes: (db: Database) => {\n    db.function(\"plucklabmodeb6\", { deterministic: true }, plucklabmodeb6)\n\n    db.transaction(() => {\n      times(ModeCount, i =>\n        db.exec(\"ALTER TABLE AssetFile ADD COLUMN \" + `mode${i} integer`)\n      )\n      db.exec(\n        \"UPDATE AssetFile SET \" +\n          times(\n            ModeCount,\n            i => `mode${i} = plucklabmodeb6(mode8b6, ${i})`\n          ).join(\", \")\n      )\n    })()\n  },\n\n  normalize_asset_file_uris: (db: Database) => {\n    db.function(\"normalizeURI\", { deterministic: true }, normalizeURI)\n    db.transaction(() => {\n      const rows = db\n        .prepare(\n          \"SELECT normalizeURI(uri) AS nuri, count(*) AS cnt, GROUP_CONCAT(id) AS ids FROM AssetFile GROUP BY nuri HAVING cnt > 1\"\n        )\n        .all()\n      const loserIds = []\n      for (const row of rows) {\n        const ids = toS(row.ids).split(\",\")\n        const afs = db\n          .prepare(\n            \"SELECT id, shown, version, updatedAt FROM AssetFile WHERE id in (\" +\n              ids.join(\",\") +\n              \")\"\n          )\n          .all()\n        const winner = greatestBy(afs, ea => [\n          ea.shown,\n          ea.version,\n          ea.updatedAt\n        ])\n        const losers = afs.filter(ea => ea.id !== winner.id)\n        loserIds.push(...losers.map(ea => ea.id))\n      }\n      for (const ids of batches(loserIds, 256)) {\n        db.exec(\"DELETE FROM AssetFile WHERE id in (\" + ids.join(\",\") + \")\")\n      }\n      db.exec(\"UPDATE AssetFile SET uri = normalizeURI(uri)\")\n    })()\n  },\n\n  dedupe_tag_paths: (db: Database) => {\n    db.transaction(() => dedupeTags(db))()\n  },\n\n  suffix_tag_paths: (db: Database) => {\n    db.function(\"tag_path_suffix\", { deterministic: true }, tag_path_suffix)\n    return db.transaction(() => {\n      dedupeTags(db)\n      db.exec(\"UPDATE Tag SET _path = tag_path_suffix(_path)\")\n    })()\n  },\n\n  // fixes tags with empty interstitial paths (like `aaa//bbb/ccc/`)\n  normalize_tag_paths: (db: Database) => {\n    const badTags = db\n      .prepare(\n        \"SELECT id, _path FROM Tag WHERE _path LIKE '%' || char(31) || char(31) || '%'\"\n      )\n      .all()\n    logger().info(\"normalize_tag_paths():\", { badTags })\n    for (const tag of badTags) {\n      const correctPath = normalizeTagPath(tag._path)\n      mergeTags(\n        db,\n        compact([\n          tag.id,\n          ...db\n            .prepare(\"SELECT id FROM Tag WHERE _path = ?\")\n            .pluck()\n            .all(correctPath)\n        ])\n      )\n    }\n  },\n\n  drop_tc_tables: (db: Database) => {\n    const re = /^(ct|taf|tag_counts)_[a-z0-9]{6}$/i\n    const tables = db\n      .prepare(\"SELECT name FROM sqlite_master WHERE type='table'\")\n      .pluck()\n      .all()\n    const victims = tables.filter(ea => re.exec(ea) != null)\n    logger().info(\"drop_tc_tables()\", { tables, victims })\n    for (const ea of victims) {\n      db.exec(\"DROP TABLE \" + ea)\n    }\n  }\n}\n", "import { Database, Statement } from \"better-sqlite3\"\nimport { thenOrTimeout } from \"../../core/async/thenOrTimeout\"\nimport { WrappedError } from \"../../core/error/WrappedError\"\nimport { emitMigration } from \"../../core/event/EventEmitter\"\nimport { BaseFile } from \"../../core/fs/BaseFile\"\nimport { Logger, mkLogger } from \"../../core/Logger\"\nimport { isPacked } from \"../../core/Platform\"\nimport { gitDate } from \"../../core/Version\"\nimport { compactBlanks, isEmpty, isNotEmpty } from \"../../fe/Array\"\nimport { blank } from \"../../fe/Blank\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { errorToVerbose } from \"../../fe/Error\"\nimport { stringify } from \"../../fe/JSON\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map } from \"../../fe/Maybe\"\nimport { toInt } from \"../../fe/Number\"\nimport { isFunction } from \"../../fe/ObjectType\"\nimport { toS } from \"../../fe/toS\"\nimport { Migrations } from \"./Migrations\"\n\nconst CreateMigration = `\nCREATE TABLE IF NOT EXISTS migrations (\n  id integer NOT NULL PRIMARY KEY, \n  name varchar(255) NOT NULL, \n  migration_time integer NOT NULL \n)\n`\n\n// MAGICK NAMING CONVENTIONS:\n\n// \"_nofk\" migrations are applied with foreign keys disabled.\n\nfunction isDisabledForeignKeysMigration(migrationFile: BaseFile) {\n  return migrationFile.name.includes(\"_nofk\")\n}\n\nexport class Migration {\n  private readonly logger: Logger\n  private readonly addMigrationStmt: Statement\n  constructor(\n    private readonly migrationsDir: BaseFile,\n    private db: Database,\n    dbFile: BaseFile\n  ) {\n    this.logger = mkLogger(\n      \"Migration(\" +\n        stringify({\n          schema: migrationsDir.base,\n          db: dbFile.nativePath\n        }) +\n        \")\"\n    )\n    db.exec(CreateMigration)\n    this.addMigrationStmt = db.prepare(\n      \"INSERT INTO migrations (name, migration_time) VALUES (?, ?)\"\n    )\n  }\n\n  readonly fsMigrations = lazy(() =>\n    this.migrationsDir.children(f => f.ext === \".sql\")\n  )\n\n  readonly migrationsInDatabase = lazy(() =>\n    this.db.prepare(\"SELECT name from migrations\").pluck().all()\n  )\n\n  readonly assertKnownMigrations = lazy(() => {\n    // No need to check if we're in dev and not packed up:\n    if (!isPacked) return\n\n    // If any migrations are from after this version was built, the library is\n    // from a newer version.\n    const unknownMigrations = this.migrationsInDatabase().filter(\n      migrationName => {\n        const [y, m, d] = [\n          migrationName.slice(0, 4),\n          migrationName.slice(4, 6),\n          migrationName.slice(6, 8)\n        ].map(s => toInt(s)!)\n        const migrationDate = new Date(y, m - 1, d)\n        this.logger.debug(\"migration filter\", {\n          migrationName,\n          migrationDate,\n          gitDate\n        })\n        // We're OK with any migration that was created before this version was\n        // created. We create 3 days of slop in dev and test because we may not\n        // have committed the new migration (and assume we're committing at least\n        // once every couple days)\n        return gitDate.getTime() < migrationDate.getTime()\n      }\n    )\n\n    if (isNotEmpty(unknownMigrations)) {\n      throw new WrappedError({\n        fatal: true,\n        doNotSend: true,\n        message:\n          \"PhotoStructure is not forward-compatible with newer libraries. Please upgrade to open this library\",\n        cause: new Error(\"Unknown migrations: \" + unknownMigrations.join(\",\"))\n      })\n    }\n  })\n\n  async apply(onBeforeMigrate?: (migrationFile: BaseFile) => Promise<any>) {\n    this.assertKnownMigrations()\n\n    const migrationFiles = await this.fsMigrations()\n    if (migrationFiles == null) {\n      throw new Error(\"no migration files found for \" + this.migrationsDir)\n    }\n    const appliedMigrations: string[] = []\n    const migrationsInDatabase = this.migrationsInDatabase()\n\n    for (const migrationFile of migrationFiles) {\n      if (migrationsInDatabase.includes(migrationFile.name)) {\n        this.logger.debug(\"latest(): already applied \" + migrationFile.base)\n      } else {\n        await map(onBeforeMigrate, ea => ea(migrationFile))\n        await thenOrTimeout(\n          this.applyMigration(migrationFile),\n          5 * minuteMs,\n          () => {\n            throw new WrappedError({\n              fatal: true,\n              ignorable: false,\n              message: \"Migration \" + migrationFile.name + \" timed out.\"\n            })\n          }\n        )\n        appliedMigrations.push(migrationFile.base)\n      }\n    }\n    this.logger.info(\"up to latest!\", { appliedMigrations })\n    return appliedMigrations\n  }\n\n  //\n  // Migrations that name-collide with a function in the Migrations namespace\n  // assume to be a javascript-based migration, rather than a SQL migration.\n  //\n\n  async applyMigration(f: BaseFile) {\n    // the splash screen shows migration progress:\n    emitMigration(f.name)\n\n    try {\n      const start = Date.now()\n      const contents = (await f.readLines())!.filter(\n        ea => blank(ea) || ea.trim().startsWith(\"--\")\n      )\n      const m = Migrations[f.name.replace(/^[\\d_-]+/, \"\")]\n      const codeMigration = isFunction(m)\n      if (isEmpty(contents) && codeMigration) {\n        throw new WrappedError({\n          message: \"empty migration \" + f.name,\n          fatal: true\n        })\n      }\n      if (codeMigration) {\n        await m.bind(Migrations)(this.db)\n      } else {\n        await this.applySqlMigration(f)\n      }\n      this.logger.debug(\"applyMigration() completed\", {\n        elapsedMs: Date.now() - start,\n        codeMigration,\n        migration: f.baseWithParent\n      })\n      return this.db.transaction(() => {\n        this.addMigrationStmt.run(f.name, Date.now())\n      })()\n    } catch (err) {\n      return this.logger.throw(\n        \"Failed to apply migration \" + f.baseWithParent,\n        errorToVerbose(err)\n      )\n    }\n  }\n\n  private async applySqlMigration(f: BaseFile) {\n    const disableForeignKeys = isDisabledForeignKeysMigration(f)\n    try {\n      const sql = toS(await f.readFile())\n      if (blank(sql)) {\n        this.logger.error(\"Empty migration: \" + f)\n        return\n      }\n      if (disableForeignKeys) {\n        // See https://sqlite.org/lang_altertable.html\n        this.db.pragma(\"foreign_keys = OFF\")\n      }\n\n      // We don't run these inside a transaction, because SQLite doesn't respect\n      // boundaries:\n\n      // split DDL into statements to highlight what part was bad:\n      for (const ea of compactBlanks(sql.split(\";\"))) {\n        try {\n          this.db.exec(ea)\n        } catch (cause) {\n          throw new WrappedError({\n            cause,\n            fatal: true,\n            message: `Failed to apply: ${ea}`\n          })\n        }\n      }\n      if (disableForeignKeys) {\n        const result = this.db.pragma(\"foreign_key_check\")\n        if (isNotEmpty(result)) {\n          this.logger.error(\"foreign_key_check failed\", result)\n          throw new Error(\n            \"Foreign key checks failed during migration \" + f.name\n          )\n        }\n      }\n    } finally {\n      if (disableForeignKeys) {\n        this.db.pragma(\"foreign_keys = ON\")\n      }\n    }\n  }\n}\n", "import { Database } from \"better-sqlite3\"\nimport { sep } from \"path\"\nimport { maybeSizeSync } from \"../../core/fs/Stat\"\nimport { defaultLogLevel } from \"../../core/log/LogFilter\"\nimport { mkLogger } from \"../../core/Logger\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { maxCpus } from \"../../core/work/MaxCpus\"\nimport { map } from \"../../fe/Maybe\"\nimport { clamp } from \"../../fe/Number\"\nimport { KiB, MiB } from \"../../fe/Units\"\nimport { handleDbRetriesSync } from \"./DbRetries\"\n\nimport bs = require(\"better-sqlite3\")\n\nexport function mkdb(\n  nativePath: string,\n  timeoutMs = Settings.dbTimeoutMs.valueOrDefault\n): Database {\n  let verbose: any\n  if (Settings.logSql.valueOrDefault) {\n    const logger = mkLogger(\n      \"SQLite(\" + nativePath.split(sep).slice(-2).join(sep) + \")\"\n    )\n    const ll = defaultLogLevel()\n    verbose = (sql: string) => logger.log(ll, sql.replace(/\\s{2,}/g, \" \"))\n  }\n  map(maybeSizeSync(nativePath), dbFileSize => {\n    Settings.dbCacheSizeMb.tmpValue = Math.max(\n      Settings.dbCacheSizeMb.valueOrDefault,\n      Math.ceil((1.1 * dbFileSize) / MiB)\n    )\n    mkLogger(\n      \"mkdb(\" + nativePath + \")\"\n    ).info(\n      \"Dynamically setting dbCacheSize to \" + Settings.dbCacheSizeMb.value,\n      { dbFileSize }\n    )\n  })\n  return setPragmas(\n    new bs(nativePath, {\n      fileMustExist: false,\n      readonly: false,\n      timeout: timeoutMs,\n      verbose\n    })\n  )\n}\n\nexport function setPragmas(db: Database): Database {\n  const pragmas = [\n    // List of PRAGMAs: https://sqlite.org/pragma.html#toc\n    // https://wiki.mozilla.org/Performance/Avoid_SQLite_In_Your_Next_Firefox_Feature\n\n    'encoding = \"UTF-8\"',\n\n    // https://sqlite.org/pragma.html#pragma_threads\n\n    // This limit sets an upper bound on the number of auxiliary threads that a\n    // prepared statement is allowed to launch to assist with a query.\n    \"threads = \" + clamp(1, 4, maxCpus()),\n\n    // Doesn't default to ON. WTH.\n    \"foreign_keys = ON\",\n\n    // increased to reduce IO waits:\n    \"page_size = \" + 16 * KiB,\n\n    // https://sqlite.org/pragma.html#pragma_trusted_schema\n\n    // There are advantages to turning it off, and most applications will be\n    // unaffected if it is turned off. For that reason, all applications are\n    // encouraged to switch this setting off on every database connection as soon\n    // as that connection is opened.\n    \"trusted_schema = 0\",\n\n    // https://sqlite.org/pragma.html#pragma_cache_size\n\n    // If the argument N is negative, then the number of cache pages is adjusted\n    // to be a number of pages that would use approximately abs(N*1024) bytes of\n    // memory based on the current page size.\n\n    \"cache_size = -\" + (Settings.dbCacheSizeMb.valueOrDefault * MiB) / 1024,\n\n    // setting this to EXCLUSIVE prevents concurrent read /or/ write access.\n    \"locking_mode = NORMAL\",\n\n    // to improve performance and support concurrent writers:\n    \"journal_mode = WAL\",\n\n    // patience before giving up:\n    \"busy_timeout = \" + Settings.dbTimeoutMs.valueOrDefault,\n\n    // https://sqlite.org/pragma.html#pragma_synchronous\n\n    // Windows (the worst for File IO) drops latency from ~17ms to ~5ms for\n    // upserts if `synchronous = OFF`, but that doesn't end up being substantive\n    // to processing rate, and OFF means library DBs can be corrupt from power\n    // cuts, so let's just use NORMAL and be safe (and a bit slower)\n\n    // With no dbrpc, synchronous = NORMAL made updates sometimes not \"stick\",\n    // causing Heartbeat to not get updated.\n\n    // With FULL, inserts on linux are 10-20x slower.\n    \"synchronous = NORMAL\",\n\n    // https://stackoverflow.com/a/8586390/1268016\n    // this allows tag path LIKE clauses to use the index:\n    // DON'T SET THIS ON! Tags are case-insensitive!\n    // \"case_sensitive_like = ON\",\n\n    // https://sqlite.org/pragma.html#pragma_auto_vacuum\n    // We'll handle vacuuming by SqliteJanitor (and only by `main`)\n    \"auto_vacuum = NONE\"\n  ]\n\n  handleDbRetriesSync(() => {\n    for (const pragma of pragmas) {\n      db.pragma(pragma)\n    }\n  })\n  return db\n}\n", "import { stat, statSync } from \"fs-extra\"\nimport { notBlank } from \"../../fe/Blank\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { opt } from \"../../fe/Opt\"\n\nexport function maybeSizeSync(nativePath: Maybe<string>): Maybe<number> {\n  try {\n    return opt(nativePath)\n      .filter(notBlank)\n      .flatMap(statSync)\n      .flatMap(ea => Number(ea.size))\n      .get()\n  } catch {\n    return\n  }\n}\n\nexport function mtimeMs(nativePath: string): PromiseMaybe<number> {\n  return stat(nativePath)\n    .then(ea => ea.mtimeMs)\n    .catch(() => undefined)\n}\n", "// No need for the -shm file:  The WAL-index or \"shm\" file is used to\n// coordinate access to the database by multiple clients, and as a cache to\n// help clients quickly locate frames within the wal file.\n\n// See https://sqlite.org/walformat.html#the_wal_index_file_format\n\n// Because the shm file is not involved in recovery, the shm file does not\n// need to be machine byte-order independent. Hence, numeric values in the shm\n// file are written in the native byte order of the host computer, rather than\n// being converted into a specific cross-platform byte order as is done with\n// the main database file and the wal file.\n\n// The -journal file may be needed if it is \"hot\": Before reading from a\n// database file, SQLite always checks to see if that database file has a hot\n// journal. If the file does have a hot journal, then the journal is rolled\n// back before the file is read. In this way, we ensure that the database file\n// is in a consistent state before it is read.\n\n// See https://sqlite.org/lockingv3.html\n\nexport const SqliteSuffixes = [\"-wal\", \"-journal\"]\n", "import { BaseFile } from \"../../core/fs/BaseFile\"\nimport { mkLogger } from \"../../core/Logger\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { SqliteSuffixes } from \"./SqliteSuffixes\"\n\nconst logger = lazy(() => mkLogger(\"SQLiteFiles\"))\n\n/**\n * @return an empty array if dbfile doesn't exist\n */\nexport function sqliteFiles(dbfile: BaseFile): BaseFile[] {\n  return [\n    dbfile,\n    ...SqliteSuffixes.map(ea => dbfile.sibling(dbfile.base + ea))\n  ].filter(ea => ea.clear().existsSync())\n}\n\n/**\n * Assumes the database is open if there is a -wal or -journal sibling file that\n * has been touched recently\n *\n * (we expect recent updates because healthchecks touch the Heartbeat table)\n */\nexport async function isDbOpen(dbfile: BaseFile, recentMs = 2 * minuteMs) {\n  if (await dbfile.clear().isEmpty()) return false\n  for (const suff of SqliteSuffixes) {\n    const f = dbfile.sibling(dbfile.base + suff)\n    const ms = await f.clear().maxStatMs()\n    if (ms != null && Date.now() - ms < recentMs) {\n      logger().debug(\"isDbOpen(\" + dbfile + \"): \" + f + \" is too recent\", {\n        lastTouchedAgoMs: Date.now() - ms\n      })\n      return true\n    }\n  }\n  return false\n}\n", "import { Database } from \"better-sqlite3\"\nimport { BaseFile } from \"../../core/fs/BaseFile\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { toS } from \"../../fe/toS\"\nimport { mkdb } from \"./MkDb\"\n\nexport function withDbSync<T>(\n  dbfile: BaseFile | string,\n  f: (db: Database) => T,\n  timeoutMs = Settings.dbTimeoutMs.valueOrDefault\n): T {\n  const d = mkdb(toS(dbfile), timeoutMs)\n  try {\n    return f(d)\n  } finally {\n    d.close()\n  }\n}\n\nexport async function withDb<T>(\n  dbfile: BaseFile | string,\n  f: (db: Database) => Promise<T>,\n  timeoutMs = Settings.dbTimeoutMs.valueOrDefault\n): Promise<T> {\n  const d = mkdb(toS(dbfile), timeoutMs)\n  try {\n    return await f(d)\n  } finally {\n    d.close()\n  }\n}\n", "import { Database } from \"better-sqlite3\"\nimport { execFile, stdout } from \"../../core/child/ChildProcess\"\nimport { filestamp } from \"../../core/date/Date\"\nimport { elapsedAsync } from \"../../core/Elapsed\"\nimport { onError } from \"../../core/error/Error\"\nimport { FatalErrorFlag } from \"../../core/error/ErrorTypes\"\nimport { WrappedError } from \"../../core/error/WrappedError\"\nimport { BaseFile } from \"../../core/fs/BaseFile\"\nimport { PushProgressObserver } from \"../../core/fs/ProgressObservers\"\nimport { sqliteNativePath } from \"../../core/fs/Tools\"\nimport { mkLogger } from \"../../core/Logger\"\nimport { CmdTimeoutMs } from \"../../core/volumes/VolumeTtls\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { eql } from \"../../fe/Eql\"\nimport { stringify } from \"../../fe/JSON\"\nimport { Latch } from \"../../fe/Latch\"\nimport { thenCollect, thenMap } from \"../../fe/Promise\"\nimport { toA } from \"../../fe/toA\"\nimport { toS } from \"../../fe/toS\"\nimport { MB } from \"../../fe/Units\"\nimport { DbValue } from \"./DbValued\"\nimport { sqliteFiles } from \"./SQLiteFiles\"\nimport { withDb, withDbSync } from \"./WithDb\"\n\nimport bs = require(\"better-sqlite3\")\n\nconst logger = mkLogger(\"SQLite\")\n\nexport async function sqliteVersion() {\n  return thenMap(sqliteNativePath(), async path => {\n    const fullToolVersion = await stdout(path, [\"-version\"], {\n      timeout: CmdTimeoutMs\n    })\n    // expected: \"3.31.1 2020-01-27 19:55:54 3bfa9cc97da1059852...16eaa837bb4d6\"\n    const toolVersion = fullToolVersion.split(/\\s+/, 1)[0]\n    const db = new bs(\":memory:\", { fileMustExist: false })\n    const libraryVersion = db.prepare(\"select sqlite_version()\").pluck().get()\n    db.close()\n    return { libraryVersion, toolVersion, fullToolVersion }\n  })\n}\n\nexport async function sqlite({\n  dbFile,\n  sql,\n  args\n}: {\n  dbFile: BaseFile\n  sql: string\n  args?: string[]\n}): Promise<string> {\n  const path = await sqliteNativePath()\n  const r = await elapsedAsync(() =>\n    // backups can take a while (hopefully never longer than a minute!)\n    stdout(path, [...toA(args), dbFile.nativePath, sql], {\n      timeout: 1 * minuteMs\n    })\n  )\n  logger.debug(\n    \"sqlite(\" + sql + \") on \" + dbFile + \" in \" + r.elapsedMs + \"ms\",\n    r.result\n  )\n  return r.result\n}\n\nexport async function backupDbFile_(srcDb: BaseFile, destDb: BaseFile) {\n  try {\n    await destDb.parent().mkdirp_()\n    const obs = new PushProgressObserver(\n      { path: toS(srcDb), op: \"Backing up\" },\n      100\n    )\n    await withDb(\n      srcDb,\n      db =>\n        db.backup(toS(destDb), {\n          progress({ totalPages: t, remainingPages: r }) {\n            obs.onProgress(((t - r) / t) * 100)\n            return 100\n          }\n        }),\n      CmdTimeoutMs\n    )\n  } catch (err) {\n    throw new WrappedError({\n      cause: err,\n      fatal: true,\n      message: `Could not back up db ${srcDb} -> ${destDb}`\n    })\n  }\n}\n\nconst OK = [{ integrity_check: \"ok\" }]\n\nexport function verifyDb_(db: Database): true {\n  try {\n    const r = db.pragma(\"integrity_check\")\n    if (eql(r, OK)) {\n      logger.info(\"verifyDb(\" + db.name + \"): OK\")\n      return true\n    } else {\n      throw new Error(stringify(r))\n    }\n  } catch (cause) {\n    throw new WrappedError({\n      cause,\n      fatal: true,\n      retriable: false,\n      message: \"verifyDb(\" + db.name + \") failed\"\n    })\n  }\n}\n\nexport function verifyDb(db: Database): boolean {\n  try {\n    return verifyDb_(db)\n  } catch {\n    return false\n  }\n}\n\n/**\n * @return string with errors\n */\nexport function verifyDbFile_(dbFile: BaseFile | string): true {\n  return withDbSync(dbFile, verifyDb_, CmdTimeoutMs)\n}\n\nconst OptimizePragmas = [\n  // https://sqlite.org/pragma.html#pragma_wal_checkpoint\n  \"wal_checkpoint(RESTART)\",\n  // We're going to do FULL VACUUM. It pauses the world, but it means the db\n  // isn't fragmented (as what happens with auto_vacuum). See\n  // https://sqlite.org/pragma.html#pragma_incremental_vacuum\n  // https://sqlite.org/pragma.html#pragma_optimize\n  \"optimize\"\n]\nexport function optimizeDb(db: Database) {\n  logger.warn(\"optimizeDb() starting...\", db.name)\n  for (const pragma of OptimizePragmas) {\n    db.pragma(pragma)\n  }\n  logger.warn(\"optimizeDb() finished.\")\n}\n\n/**\n * Dump and restore to srcDb-new, then move src to ./invalid/, and rename the\n * new db to srcDb.\n *\n * The final db will have passed verification.\n *\n * @return where srcDb was moved to\n */\nexport async function repairDbFile_(\n  srcDb: BaseFile,\n  op: \"dump\" | \"recover\" = \"recover\",\n  fatal = true\n) {\n  const destDir = await srcDb.parent().join(op).mkdirpSync_()\n  const dest = destDir.join(srcDb.base)\n  logger.info(`repairDbFile_(${srcDb} -> ${dest})`)\n  try {\n    const cmd = await sqliteNativePath()\n    const size = 3 * MB + (await srcDb.size())! * 1.25\n    const maxBuffer = 10 * size\n    const obs = new PushProgressObserver(\n      { path: toS(srcDb), op: \"Repairing db\" },\n      size\n    )\n    const l = new Latch()\n\n    const dump = execFile(cmd, [srcDb.nativePath, \".\" + op], 5 * minuteMs, {\n      encoding: \"buffer\",\n      maxBuffer\n    })\n    dump.stdout!.on(\"error\", cause =>\n      onError(\n        \"sqlite \" + op + \" failed for \" + srcDb,\n        new WrappedError({ cause, fatal })\n      )\n    )\n    const load = execFile(cmd, [dest.nativePath], 5 * minuteMs, {\n      encoding: \"buffer\",\n      maxBuffer\n    })\n    load.on(\"exit\", () => l.resolve())\n    dump.stdout!.on(\"end\", () => {\n      load.stdin!.end(\n        OptimizePragmas.map(ea => \"PRAGMA \" + ea + \";\").join(\"\\n\")\n      )\n    })\n    dump.stdout!.on(\"data\", buf => {\n      const len = (buf as string | Buffer).length\n      obs.incrProgress(len)\n      load.stdin!.write(buf)\n    })\n\n    await l\n\n    await verifyDbFile_(dest)\n    logger.info(`repairDbFile_(): ${dest} is valid, finishing repair.`)\n    const result = await thenCollect(sqliteFiles(srcDb), ea =>\n      ea.renameYMDHMS_(\"needed-repair\")\n    )\n    await thenCollect(sqliteFiles(dest), ea => ea.mv_(srcDb.parent()))\n\n    return result.find(ea => ea.ext === \".db\" || ea.ext.startsWith(\".sqlite\"))!\n  } catch (err) {\n    return logger.throw(\n      \"failed to recover DB via dump and restore. Please see <https://photostructure.com/faq/restore-db-from-backup/> \" +\n        FatalErrorFlag,\n      err\n    )\n  }\n}\n\nexport function escStr(s: DbValue): string {\n  return `'${toS(s).replace(/'/g, \"''\")}'`\n}\n\nexport async function makeVersionBackup_(srcDbFile: BaseFile) {\n  if (await srcDbFile.notExists()) return\n  const destDir = await srcDbFile.parent().join(\"version-backup\").mkdirp()\n  const prior = await destDir?.childWithSameContents(srcDbFile)\n  if (destDir == null || prior != null) return prior\n  const dest = destDir.join(filestamp() + \"-\" + srcDbFile.base)\n  await backupDbCold_(srcDbFile, dest)\n  return dest\n}\n\n/**\n * SQLite's db backup tries to acquired filesystem locks when it backs up. This\n * won't work if the db is on a remote filesystem.\n *\n * If you don't care about running a \"hot\" backup, this implementation is simpler.\n */\nexport async function backupDbCold_(srcDbFile: BaseFile, destDir: BaseFile) {\n  logger.info(\"coldDbBackup(): copying \" + srcDbFile + \" to \" + destDir)\n  const auxFiles = sqliteFiles(srcDbFile).filter(ea => !ea.eql(srcDbFile))\n  await srcDbFile.copyFile_(destDir)\n  // thenCollect to prevent race condition errors with mkdirp on parent():\n  await thenCollect(auxFiles, ea => ea.copyFile_(destDir)).catch(err =>\n    logger.warn(\"Failed to copy aux db files\", err)\n  )\n}\n", "import sqlite from \"better-sqlite3\"\nimport { EndableRanks } from \"../../core/async/Endable\"\nimport { EndableWrapper } from \"../../core/async/EndableWrapper\"\nimport { FatalErrorFlag } from \"../../core/error/ErrorTypes\"\nimport { WrappedError } from \"../../core/error/WrappedError\"\nimport { BaseFile } from \"../../core/fs/BaseFile\"\nimport { ProjectPath } from \"../../core/fs/ProjectPath\"\nimport { libraryDataDir } from \"../../core/settings/LibraryDirs\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { pathToDb } from \"./DbPath\"\nimport { handleDbRetries } from \"./DbRetries\"\nimport { Migration } from \"./Migration\"\nimport { mkdb } from \"./MkDb\"\nimport { Schema } from \"./Schema\"\nimport {\n  makeVersionBackup_,\n  optimizeDb,\n  repairDbFile_,\n  verifyDb\n} from \"./SQLite\"\nimport { withVacuumEvent } from \"./Vacuum\"\n\n/**\n * Manages a SQLite database connection. If the connection closes (due to\n * external vacuuming), it will be automatically re-opened.\n */\nexport class Db extends EndableWrapper {\n  private _db: Maybe<sqlite.Database>\n  readonly endTimeoutMs = minuteMs\n\n  /**\n   * @param _dataDir if not given, use `libraryDataDir()`\n   */\n  constructor(\n    readonly schema: Schema,\n    readonly _dataDir?: Maybe<BaseFile>,\n    readonly _onMigration: () => any = () => undefined\n  ) {\n    super(\"Db(\" + schema + \")\", () => this.closeDb(), EndableRanks.db)\n  }\n\n  get datadir() {\n    return orElse(this._dataDir, libraryDataDir())!\n  }\n\n  get dbfile() {\n    return pathToDb(this.datadir, this.schema)\n  }\n\n  get open() {\n    return this._db != null && this._db.open\n  }\n\n  get inTransaction() {\n    return this.open && true === this._db?.inTransaction\n  }\n\n  prepare(source: string) {\n    return this.db!.prepare(source)\n  }\n\n  pragma(source: string, options?: sqlite.PragmaOptions): any {\n    return this.db!.pragma(source, options)\n  }\n\n  get db() {\n    const priorWasNull = this._db == null\n    if (!this.open) {\n      this.logger.info(\"setting up new db connection to \" + this.dbfile, {\n        priorWasNull\n      })\n      try {\n        this.dbfile.parent().mkdirpSync_()\n        this._db = mkdb(this.dbfile.nativePath)\n        const integrity: string = this._db.pragma(\"quick_check\", {\n          simple: true\n        })\n        if (integrity !== \"ok\") {\n          throw new Error(\n            \"Quick integrity check failed: \" + integrity + FatalErrorFlag\n          )\n        }\n      } catch (cause) {\n        throw new WrappedError({\n          cause,\n          fatal: true,\n          message: \"Failed to set up \" + this.dbfile\n        })\n      }\n    }\n    return this._db!\n  }\n\n  readonly migrate = lazy(async () => {\n    const file = this.dbfile\n    if (this.db == null || file == null) {\n      throw new Error(\"Cannot migrate database: missing db\")\n    }\n    await this.maybeRepair()\n\n    // We only need to back up the db once per \"migration batch\":\n    const onBeforeMigrate = lazy(async () => {\n      this._onMigration()\n      return makeVersionBackup_(file)\n    })\n    const migration = new Migration(\n      BaseFile.for(ProjectPath.Migrations()).join(this.schema),\n      this.db,\n      file\n    )\n    const appliedMigrations = await migration.apply(onBeforeMigrate)\n    return { appliedMigrations, migration }\n  })\n\n  closeDb() {\n    try {\n      if (true === this._db?.open) {\n        this.logger.info(\"closing db\", this._db)\n        this._db?.close()\n      }\n    } catch (err) {\n      this.logger.warn(\"closeDb(): .close() failed\", err)\n    }\n    this._db = undefined\n  }\n\n  async maybeRepair() {\n    let dbIsHealthy = true\n    try {\n      // If the db is really toast, this may throw.\n      dbIsHealthy = verifyDb(this.db)\n    } catch {\n      dbIsHealthy = false\n    }\n    if (!dbIsHealthy) {\n      this.logger.warn(\n        \"maybeRepair(): database failed validation. Trying to restore with dump/load.\"\n      )\n      await this.repair_()\n    }\n  }\n\n  async vacuum() {\n    await withVacuumEvent(() => this._vacuum())\n  }\n\n  readonly onRetry = lazy(\n    () => this.closeDb(),\n    Settings.maxBusyDbMs.valueOrDefault / 4\n  )\n\n  private async _vacuum() {\n    try {\n      await handleDbRetries(() => {\n        optimizeDb(this.db)\n        this.db.exec(\"VACUUM\")\n      }, this.onRetry)\n    } catch (err) {\n      this.logger.warn(\n        \"vacuum(): vacuum failed, trying to recover by dump-load\",\n        err\n      )\n      await this.repair_()\n    }\n  }\n\n  private async repair_() {\n    this.logger.warn(\"repair_(): Attemping restore of \" + this.dbfile)\n    this.closeDb()\n    await withVacuumEvent(() => repairDbFile_(this.dbfile))\n    this.logger.info(\"repair_(): Database restoration was successful!\")\n  }\n}\n", "import { compact } from \"../../fe/Array\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { times } from \"../../fe/Number\"\nimport { toA } from \"../../fe/toA\"\nimport { greatestBy } from \"../Array\"\nimport { thenMap, thenOrElse } from \"../async/Promise\"\nimport { filestampUTC } from \"../date/Date\"\nimport { max } from \"../math/Vector\"\nimport { groupBy } from \"../MultiMap\"\nimport { BaseFile } from \"./BaseFile\"\nimport { SimpleFile } from \"./SimpleFile\"\n\nexport class HanoiFile {\n  constructor(\n    readonly seq: number,\n    readonly set: number,\n    readonly name: string,\n    readonly stamp: string = filestampUTC()\n  ) {}\n\n  valueOf(): string {\n    return this.toFilename()\n  }\n\n  toFilename(): string {\n    return [this.stamp, \"seq\" + this.seq, \"set\" + this.set, this.name].join(\"-\")\n  }\n\n  toFile(root: BaseFile): BaseFile {\n    return root.join(this.toFilename())\n  }\n\n  private static readonly parseRe = /([-\\d]{8,})-seq(\\d+)-set(\\d+)-(.+)$/\n\n  static fromFile(f: SimpleFile): Maybe<HanoiFile> {\n    return this.fromBasename(f.base)\n  }\n\n  static fromBasename(base: string): Maybe<HanoiFile> {\n    return map(\n      this.parseRe.exec(base),\n      r =>\n        new HanoiFile(\n          parseInt(r[2], 10), // safe because the re only takes digits\n          parseInt(r[3], 10), // safe because the re only takes digits\n          r[4],\n          r[1]\n        )\n    )\n  }\n}\n\n/**\n * Implements a Tower of Hanoi backup rotation scheme.\n * Naming convention: YYYYMMDD-HHMMSS-seqNNN-setNNN-${base}\n *\n * @export\n * @class Hanoi\n * @see https://en.wikipedia.org/wiki/Backup_rotation_scheme#Tower_of_Hanoi\n */\nexport class Hanoi {\n  static async for(dir: BaseFile, sets: number) {\n    return new Hanoi(dir, sets, orElse(await Hanoi.maxSeq(dir), -1))\n  }\n\n  static async maxSeq(dir: BaseFile) {\n    return max([\n      ...toA(\n        await thenMap(dir.childNames(), arr =>\n          arr.map(ea => HanoiFile.fromBasename(ea)?.seq)\n        )\n      )\n    ])\n  }\n\n  private constructor(\n    readonly dir: BaseFile,\n    readonly sets: number,\n    private seq: number\n  ) {}\n\n  readonly mods = lazy(() => times(this.sets, i => Math.pow(2, i)).reverse())\n\n  private set(seq: number): number {\n    return this.sets - this.mods().findIndex(m => seq % m === 0)\n  }\n\n  next(name: string): HanoiFile {\n    // preincrement to not overwrite the first backup on construction:\n    const seq = ++this.seq\n    return new HanoiFile(seq, this.set(seq), name)\n  }\n\n  async hanoiFiles(): Promise<HanoiFile[]> {\n    const childNames = await this.dir.clear().childNames()\n    return compact(childNames?.map(ea => HanoiFile.fromBasename(ea)))\n  }\n\n  /**\n   * Return files whose seq is the largest value for its set\n   */\n  async validHanoiFiles(files?: HanoiFile[]): Promise<HanoiFile[]> {\n    // only return BaseFiles that are parsable as HanoiFiles:\n    const arr = await thenOrElse(files, () => this.hanoiFiles())\n    const bySet = groupBy(arr, ea => ea.set)\n    const valid: HanoiFile[] = []\n    for (const set of bySet.keys()) {\n      map(\n        greatestBy(bySet.get(set)!, ea => ea.seq),\n        keep => valid.push(keep)\n      )\n    }\n    return valid\n  }\n\n  /**\n   * Return files whose seq is less than the largest value for its set\n   */\n  async staleHanoiFiles(files?: HanoiFile[]): Promise<HanoiFile[]> {\n    // only return BaseFiles that are parsable as HanoiFiles:\n    const arr = await thenOrElse(files, () => this.hanoiFiles())\n    const valid = await this.validHanoiFiles(files)\n    const validSeqs = valid.map(ea => ea.seq)\n    return arr.filter(ea => !validSeqs.includes(ea.seq))\n  }\n\n  async staleFiles(): Promise<BaseFile[]> {\n    return this.staleHanoiFiles().then(files =>\n      files.map(ea => ea.toFile(this.dir))\n    )\n  }\n}\n", "import { stdout } from \"process\"\n\nexport function stdoutEnded() {\n  return stdout == null || stdout.destroyed || stdout.writableEnded\n}\n\nexport function consoleLog(msg: string, ...optionalParams: any[]) {\n  if (stdoutEnded()) return\n  console.log(msg, ...optionalParams)\n}\n", "import { EndableRanks } from \"../../core/async/Endable\"\nimport { EndableInterval } from \"../../core/async/EndableInterval\"\nimport { Later } from \"../../core/async/Later\"\nimport { Promises } from \"../../core/async/Promises\"\nimport { filestampUTC } from \"../../core/date/Date\"\nimport { BaseFile } from \"../../core/fs/BaseFile\"\nimport { Hanoi } from \"../../core/fs/Hanoi\"\nimport { isSingleSpecTests } from \"../../core/NodeEnv\"\nimport { isMainService } from \"../../core/ServiceNames\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { consoleLog } from \"../../core/Stdout\"\nimport { hourMs, minuteMs } from \"../../fe/Date\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Db } from \"./Db\"\nimport { backupDbCold_, backupDbFile_, verifyDbFile_ } from \"./SQLite\"\nimport { sqliteFiles } from \"./SQLiteFiles\"\n\n/**\n * Shouldn't be so frequent that it overwhelms the network to the NAS, but\n * shouldn't be so long such that data loss due to system crashes are painful.\n *\n * For reference, a 100k asset models db takes 6-10 seconds (!!) to transfer\n * over wifi from a cheap NAS over CIFS to a windows 10 box.\n */\nexport const DefaultBackupFrequencyMs = 1 * hourMs\nexport const DefaultRetentionCount = 32\n\nexport function stamp(date: Date = new Date()): string {\n  return \".\" + filestampUTC(date) + \"-\"\n}\n\nexport class DbBackup extends EndableInterval {\n  readonly endTimeoutMs = minuteMs\n  private readonly mutex = new Promises()\n\n  /**\n   * Creates an instance of DbBackup.\n   * @param {BaseFile} srcDbFile the db to backup\n   * @param {BaseFile} backupsDir where to store backups\n   * @param {BaseFile} replaceDir where to move the db on shutdown\n   * @memberof DbBackup\n   */\n  constructor(\n    readonly db: Db,\n    readonly isLockOwner: Later<boolean>,\n    readonly srcDbFile: BaseFile,\n    readonly backupsDir: BaseFile,\n    readonly replaceDir?: BaseFile,\n    readonly beforeBackup: () => any = () => undefined,\n    readonly onBackupFinished: () => any = () => undefined\n  ) {\n    super({\n      name: \"DbBackup(\" + srcDbFile + \")\",\n      callback: () => this.backup(),\n      intervalMs: Settings.dbBackupIntervalMinutes.valueOrDefault * minuteMs,\n      rank: EndableRanks.predb\n    })\n    if (!isSingleSpecTests()) {\n      this.onEnds.push(async () => {\n        await this.mutex.serial(\"DbBackup.end()\", async () => {\n          if (isMainService())\n            consoleLog(\"Verifying & backing up \" + db.dbfile + \"...\")\n          await this._backup(true)\n          if (isMainService())\n            consoleLog(\n              \"PhotoStructure library db has been backed up to \" +\n                backupsDir +\n                \".\"\n            )\n        })\n      })\n    }\n  }\n\n  private backup() {\n    return this.mutex.maybeRun(\"DbBackup.backup()\", () => this._backup())\n  }\n\n  private readonly hanoi = lazy(() =>\n    Hanoi.for(this.backupsDir, Settings.dbBackupsCount.valueOrDefault)\n  )\n\n  private async _backup(ended = this.ended) {\n    if (!(await this.isLockOwner())) {\n      this.logger.info(\"backup(): not lock owner, no-op.\")\n      return\n    }\n    if (!ended && !this.db.open) {\n      this.logger.warn(\"backup(): db is already closed.\", this.db.name)\n      return\n    }\n\n    if (await this.srcDbFile.clear().isEmpty()) {\n      this.logger.warn(\"backup(): db is missing.\", this.srcDbFile.nativePath)\n      return\n    }\n    try {\n      this.logger.info(\"backup(): beforeBackup...\", {\n        srcDb: this.srcDbFile.nativePath,\n        backupsDir: this.backupsDir.nativePath\n      })\n\n      await this.beforeBackup()\n\n      if (ended && this.db.open) {\n        this.logger.info(\"backup(): closing db before backup...\")\n        await this.db.closeDb()\n      }\n\n      // We want the \"hot\" backup to be a local destination, because SQLite's\n      // backup doesn't work on remote filesystems.\n\n      const localDestDbFile = this.srcDbFile\n        .parent()\n        .join(\"backup\", this.srcDbFile.base)\n\n      this.logger.info(\"backup(): starting backup to \" + localDestDbFile)\n      await backupDbFile_(this.srcDbFile, localDestDbFile)\n\n      this.logger.info(\"backup(): backup taken. Verifying \" + localDestDbFile)\n      await verifyDbFile_(localDestDbFile)\n\n      if (this.replaceDir != null) {\n        // This backup is \"cold\" as it may be to a remote filesystem.\n        this.logger.info(\"backup(): Copying to \" + this.replaceDir)\n        await backupDbCold_(localDestDbFile, this.replaceDir)\n      }\n\n      const dbFiles = await sqliteFiles(localDestDbFile)\n      const hanoi = await this.hanoi()\n      const hf = hanoi.next(\"\")\n      const hanoiPrefix = hf.toFilename()\n      this.logger.info(\n        \"backup(): Rotating files to \" + this.backupsDir.join(hanoiPrefix)\n      )\n      for (const dbFile of dbFiles) {\n        await dbFile.mv_(this.backupsDir.join(hanoiPrefix + dbFile.base), {\n          overwrite: true\n        })\n      }\n      for (const f of await hanoi.staleFiles()) {\n        this.logger.info(\"backup(): removing stale backup \" + f)\n        await f.unlink()\n      }\n      this.logger.info(\"backup(): finished successfully\")\n      await this.onBackupFinished()\n    } catch (cause) {\n      this.logger.throw(cause, {\n        from: \"DbBackup._backup() failed\",\n        fatal: true,\n        srcDb: this.srcDbFile.nativePath\n      })\n    }\n  }\n}\n", "import { cacheDir } from \"../core/CacheDir\"\nimport { lazy } from \"../fe/Lazy\"\n\nexport const localDbDir = lazy(async () => {\n  const localDb = cacheDir().join(\"local-db\")\n  await localDb.join(\"README.txt\").writeTxt_(`\nThis folder is only used when your library is on a remote filesystem.\n\nYou will corrupt your library if you remove this directory while PhotoStructure is\nrunning.\n\nIf you have any questions, please visit <https://photostructure.com/support/>.`)\n  return localDb\n})\n", "import { randomInt } from \"./Random\"\n\nexport const primesPerBin = 4\nexport const primeBins = 8\n\nexport const SeedCount = primesPerBin ** primeBins\n\nexport function prngSeed(): number {\n  return randomInt(0, SeedCount)\n}\n", "import { sortBy } from \"../../fe/Array\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { sigFigs } from \"../../fe/Number\"\nimport { primeBins, primesPerBin, SeedCount } from \"../../fe/PRNG\"\nimport { numericSha } from \"../fs/Hash\"\nimport { memoize } from \"../MemoizedFunc\"\nimport { encodeDigits } from \"./Radix\"\n\n// TODO: This whole thing is SITS, because we should be able to just give the\n// random function in SQLite a seed\n\n// but we can't\n\n// because everything is terrible\n\n// The score for a given row is (ax^2 + bx)(cx + d)\n\n// X^2 is required for reasonable diff distribution between X_ks.\n\n// Related: https://en.wikipedia.org/wiki/Linear_congruential_generator\n\nexport function prngOrderByClause(\n  seed: number,\n  idColumn: string,\n  max: number\n): string {\n  const [a, b, c, d, e] = factors(seed)\n  const x = idColumn\n  const i = `(${a}*${x}*${x}+${b}*${x})%${max}`\n  const j = `(${c}*${x}+${d})%${max}`\n  return `((${i})*(${j})+${e})%${max}`\n}\n\nexport function prng(seed: number, x: number, max: number): number {\n  const [a, b, c, d, e] = factors(seed)\n  const y1 = (a * x * x + b * x) % max\n  const y2 = (c * x + d) % max\n  return Math.round((y1 * y2 + e) % max)\n}\n\n// https://primes.utm.edu/curios/index.php?start=5&stop=5\nexport const primes = [\n  [353868013, 472882027, 479001599, 517294153],\n  [1012573, 1230587, 1355297, 1572751],\n  [756065159, 812182027, 899809343, 989450477],\n  [3959297, 4514113, 4823201, 5133127],\n  [573259391, 666101999, 694847533, 746151647],\n  [2275327, 2770513, 3073703, 3511973],\n  [173313197, 182557181, 203457869, 222230231],\n  [6054613, 6189107, 7752103, 9852103]\n]\n\n// 20200902: Adding a static intercept didn't help the quality of the PRNG.\n\nexport const primeInt = [\n  1012573,\n  1101689,\n  1183811,\n  1196089,\n  1230587,\n  1355297,\n  1419641,\n  1483733,\n  1572751,\n  2275327,\n  2770513,\n  3010349,\n  3073703,\n  3118691,\n  3174823,\n  3511973,\n  3959297,\n  4514113,\n  4690451,\n  4823201,\n  5133127,\n  5375327,\n  6019889,\n  6054613,\n  6189107,\n  7752103,\n  7752103,\n  9852103\n]\n\nexport function primeSeeds(seed: number) {\n  const indexes = encodeDigits(primesPerBin, seed, primeBins)\n  return indexes.map((ea, idx) => primes[idx][ea])\n}\n\nexport const factors = memoize(\n  (seed: number) => {\n    const [a, b, c, d, e, f, g, h] = primeSeeds(seed % SeedCount)\n    const result = [a / b, c / d, e / f, g / h].map(ea => sigFigs(ea, 7))\n    result.push(primeInt[seed % primeInt.length])\n    return result\n  },\n  { maxSize: 128, ttlMs: minuteMs }\n)\n\nexport function stableIndexShuffle<T>(arr: T[], seed = 1): T[] {\n  return sortBy(arr, (_, idx) => prng(seed, idx, arr.length))\n}\n\nexport function stableContentShuffle<T>(arr: T[], seed = 1): T[] {\n  return sortBy(arr, ea => numericSha(String(ea) + seed))\n}\n", "import { map } from \"./Maybe\"\nimport { assembleUri } from \"./URI\"\n\nexport class TagUrls {\n  /**\n   * id === tag id\n   */\n  constructor(readonly id: number) {}\n\n  nextAssetBatch(capturedAtLt?: Date) {\n    const q: any = {}\n    map(capturedAtLt, ea => (q.capturedAtLt = ea.getTime()))\n    return assembleUri(`/tag-gallery/${this.id}`, q)\n  }\n}\n", "import { compact, isEmpty } from \"../../fe/Array\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { id } from \"../../fe/Number\"\nimport { Asset } from \"./Asset\"\nimport { Model } from \"./Model\"\nimport { TableName } from \"./TableName\"\nimport { Tag } from \"./Tag\"\n\nexport class AssetTag extends Model {\n  static tableName: TableName = \"AssetTag\"\n  static readonly uniqueColumnName = \"assetId,tagId\"\n\n  $pk() {\n    return [\n      orElse(this.assetId, () => map(this.asset, ea => ea.id)),\n      orElse(this.tagId, () => map(this.tag, ea => ea.id))\n    ].join(\":\")\n  }\n\n  asset!: Asset\n  assetId!: number\n\n  tag!: Tag\n  tagId!: number\n\n  static addTagsToAsset(assetId: number, tagIds: number[]) {\n    const safeAssetId = id(assetId)\n    if (safeAssetId == null) {\n      this.logger().warn(\"addTagsToAsset(): got null assetId\")\n      return\n    }\n    const safeTagIds = compact(tagIds.map(id))\n    if (isEmpty(safeTagIds)) {\n      this.logger().warn(\"addTagsToAsset(): no tagIds\", { assetId, tagIds })\n      return\n    }\n    const sql =\n      \"INSERT OR IGNORE INTO AssetTag(assetId,tagId) VALUES \" +\n      safeTagIds.map(tagId => `(${safeAssetId},${tagId})`).join(\",\")\n    return this.dbl.run(sql)\n  }\n\n  static removeTagsFromAsset(assetId: number, tagIds: number[]) {\n    tagIds = compact(tagIds)\n    const q = this.query()\n      .whereIn(\"tagId\", tagIds)\n      .andWhere({ assetId })\n      .delete()\n    return this.dbl.run(q)\n  }\n\n  // static countDirectAssets(t: Tag, b?: BatchDbRequest) {\n  //   return AssetTag.ops().count(\n  //     AssetTag.query()\n  //       .count(\"assetId as count\")\n  //       .where({ tagId: t.id }),\n  //     b\n  //   )\n  // }\n\n  // static countAssets(t: Tag, b?: BatchDbRequest) {\n  //   return AssetTag.ops().count(\n  //     AssetTag.query()\n  //       .countDistinct(\"assetId as count\")\n  //       .join(\"Tag as t\", \"t.id\", \"AssetTag.tagId\")\n  //       .where(\"t._path\", \"like\", t._path + \"%\"),\n  //     b\n  //   )\n  // }\n}\n", "import {\n  diceCoeff,\n  greatestBy,\n  retainFirstN,\n  retainLastN\n} from \"../../core/Array\"\nimport { mkLogger } from \"../../core/Logger\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { ApiAssetStream } from \"../../fe/api/Asset\"\nimport { ID } from \"../../fe/api/ID\"\nimport { pushUniqBy, sortByInPlace } from \"../../fe/Array\"\nimport { gtOrElse, times } from \"../../fe/Number\"\nimport { cmp } from \"../../fe/Primitive\"\nimport { thenCollect } from \"../../fe/Promise\"\nimport { toA } from \"../../fe/toA\"\nimport { Asset } from \"./Asset\"\nimport { Tag } from \"./Tag\"\n\nexport const cmpAssetAsc = (a: Asset, b: Asset) =>\n  cmp([a.capturedAtLocal, a.id!], [b.capturedAtLocal, b.id!])\n\nexport const cmpAssetDesc = (a: Asset, b: Asset) =>\n  cmp([b.capturedAtLocal, b.id!], [a.capturedAtLocal, a.id!])\n\nfunction briefAsset(a: Asset) {\n  return { id: a.id, at: a.capturedAtLocal }\n}\n\nexport class TaggedAssetStream {\n  readonly logger = () => mkLogger(\"TaggedAssetStream(\" + this.toString() + \")\")\n\n  constructor(\n    readonly tags: Tag[],\n    readonly before: Asset[],\n    readonly after: Asset[],\n    readonly limit: number\n  ) {\n    this.logger().info(\"new\", this.toJSON())\n  }\n\n  vacuum() {\n    sortByInPlace(this.before, (a: Asset) => [-a.capturedAtLocal, -a.id!])\n    retainFirstN(this.before, this.limit)\n    sortByInPlace(this.after, (a: Asset) => [-a.capturedAtLocal, -a.id!])\n    retainLastN(this.after, this.limit)\n  }\n\n  toString() {\n    return this.tags.map(ea => ea.path.join(\"/\")).join(\",\")\n  }\n\n  valueOf() {\n    return this.toString()\n  }\n\n  get length() {\n    return toA(this.before).length + toA(this.after).length\n  }\n\n  leftPad(ids: ID[]): ID[] {\n    return [\n      ...times(this.limit - ids.length, ea => ({ id: -(ea + 1), v: 0 })),\n      ...ids\n    ]\n  }\n\n  rightPad(ids: ID[]): ID[] {\n    return [\n      ...ids,\n      ...times(this.limit - ids.length, ea => ({\n        id: -(ea + this.limit + 1),\n        v: 0\n      }))\n    ]\n  }\n\n  toJSON() {\n    return {\n      tags: this.tags.map(tag => tag.toString()),\n      assetIdsAfter: this.after.map(briefAsset),\n      assetIdsBefore: this.before.map(briefAsset)\n    }\n  }\n\n  mergeWith(tas: TaggedAssetStream) {\n    // this.logger().info(\"mergeWith()\", {\n    //   tas: tas.toJSON(),\n    //   beforeIds: this.before.map(briefAsset),\n    //   afterIds: this.after.map(briefAsset)\n    // })\n\n    pushUniqBy(this.tags, tas.tags, ea => ea.path)\n\n    // These are the thumbnails to the right of the current asset:\n    pushUniqBy(this.before, tas.before, ea => ea.id!)\n\n    // These are the thumbnails to the left of the current asset:\n    pushUniqBy(this.after, tas.after, ea => ea.id!)\n    this.logger().debug(\"mergeWith() complete\", {\n      tas: tas.toJSON(),\n      tags: this.tags.map(ea => ea.path),\n      beforeIds: this.before.map(briefAsset),\n      afterIds: this.after.map(briefAsset)\n    })\n  }\n\n  async toApi(): Promise<ApiAssetStream> {\n    this.vacuum()\n    return this.logger().tap({\n      msg: \"toApi()\",\n      result: {\n        tags: await thenCollect(this.tags, ea => ea.toApiTag()),\n        assetIdsAfter: this.leftPad(this.after.map(ea => ea.toID()!)),\n        assetIdsBefore: this.rightPad(this.before.map(ea => ea.toID()!))\n      }\n    })\n  }\n\n  streamCoeff(tas: TaggedAssetStream) {\n    return this.logger().tap({\n      msg: \"streamCoeff\",\n      meta: {\n        this: this.tags.map(ea => ea.path),\n        tas: tas.tags.map(ea => ea.path)\n      },\n      result: diceCoeff(\n        [...this.before, ...this.after],\n        [...tas.before, ...tas.after],\n        ea => ea.id!\n      )\n    })\n  }\n}\n\nexport function coalesceStreams(\n  streams: TaggedAssetStream[]\n): TaggedAssetStream[] {\n  const minStreamCorr = Settings.minStreamCorrPct.valueOrDefault / 100\n  const result: TaggedAssetStream[] = []\n  const prefilter = streams.filter(ea => ea.length > 5)\n  for (const stream of prefilter) {\n    const nearest = greatestBy(result, ea =>\n      gtOrElse(ea.streamCoeff(stream), minStreamCorr)\n    )\n    if (nearest == null) {\n      result.push(stream)\n    } else {\n      nearest.mergeWith(stream)\n    }\n  }\n  return result\n}\n", "import { Knex } from \"knex\"\nimport { ancestry } from \"../../core/Array\"\nimport { thenMap } from \"../../core/async/Promise\"\nimport { onClearCache } from \"../../core/event/EventEmitter\"\nimport { FifoCache } from \"../../core/FifoCache\"\nimport { prngOrderByClause } from \"../../core/math/PRNG\"\nimport { mapGt0, mapGte0 } from \"../../core/Number\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { hasAnyIgnoreCase } from \"../../core/String\"\nimport { AssetId, PathTag } from \"../../fe/api/Asset\"\nimport {\n  ApiTag,\n  BeforeAfterStreamLimit,\n  ChildTagCriteria,\n  TagAssetsCriteria,\n  TagPath,\n  TagRoots,\n  ThumbsPerSample\n} from \"../../fe/api/Tag\"\nimport { isEmpty } from \"../../fe/Array\"\nimport { blank, notBlank } from \"../../fe/Blank\"\nimport { minuteMs, secondMs } from \"../../fe/Date\"\nimport { lazy, MemoizedThunk } from \"../../fe/Lazy\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { gt0 } from \"../../fe/Number\"\nimport { isObject } from \"../../fe/ObjectType\"\nimport { MaybeSyncOrAsync } from \"../../fe/OptAsync\"\nimport { cmp } from \"../../fe/Primitive\"\nimport { thenCollect } from \"../../fe/Promise\"\nimport { compressWhitespace } from \"../../fe/String\"\nimport { TagUrls } from \"../../fe/TagUrls\"\nimport { fmt, plur } from \"../../fe/Units\"\nimport { joinTagPath, Roots, splitTagPath, TagSep } from \"../curators/Taggers\"\nimport { knex } from \"../db/Knex\"\nimport { PartialPojo } from \"../db/PartialPojo\"\nimport { Asset } from \"./Asset\"\nimport { AssetTag } from \"./AssetTag\"\nimport { TableName } from \"./TableName\"\nimport { TaggedAssetStream } from \"./TaggedAssetStream\"\nimport { TimestampedModel } from \"./TimestampedModel\"\n\nfunction orderBy(builder: Knex.QueryBuilder) {\n  return builder.orderByRaw(\"COALESCE(ordinal, _path) COLLATE NOCASE\")\n}\n\nonClearCache(() => Tag.clear())\n\nasync function cacheTag(o: MaybeSyncOrAsync<Tag>): PromiseMaybe<Tag> {\n  const t = await o\n  if (t != null) Tag.cacheTag(t)\n  return t\n}\n\nexport class Tag extends TimestampedModel {\n  static tableName: TableName = \"Tag\"\n  static readonly uniqueColumnName = \"_path\"\n\n  // Tags are immutable, so this expedites .findByPath, .findOrCreate,\n  // .getParent, and .getAncestors.\n  private static readonly recentTagsByPath = new FifoCache<PromiseMaybe<Tag>>(\n    256\n  )\n  private static readonly tagById = new FifoCache<PromiseMaybe<Tag>>(\n    256,\n    minuteMs\n  )\n  static readonly cmp = (a: Tag, b: Tag) =>\n    cmp(\n      [orElse(a.ordinal, Number.MAX_SAFE_INTEGER), ...a.path],\n      [orElse(b.ordinal, Number.MAX_SAFE_INTEGER), ...b.path]\n    )\n\n  static clear() {\n    this.root.unset()\n    this.roots.unset()\n    this._upsertDefaultRoots.unset()\n    this.recentTagsByPath.clear()\n    this.tagById.clear()\n    // this._selfAndAncestorIds.clear()\n  }\n\n  static cacheTags(arr: Tag[]) {\n    return arr.map(ea => this.cacheTag(ea))\n  }\n\n  static cacheTag(tag: Maybe<Tag>): Maybe<Tag> {\n    if (tag != null) this.recentTagsByPath.set(tag._path, Promise.resolve(tag))\n    if (tag?.id != null) this.tagById.set(tag.id, Promise.resolve(tag))\n    return tag\n  }\n\n  static readonly root = lazy(async () => {\n    const root = new Tag()\n    root.id = 0\n    // root.name = \"\" // DON'T SET .name, it's always derived from _path.\n    root._path = TagSep\n    root.parentId = undefined\n    root.children = (await Tag.roots()).filter(\n      ea => !hasAnyIgnoreCase(Settings.hiddenHomeTags.valueOrDefault, ea.name)\n    )\n    root.ancestors = []\n    root.assetCount = await Asset.shownAssetCounts()\n    root.upsert = () => {\n      throw new Error(\"upsert not supported on root\")\n    }\n    return root\n  }, 7 * secondMs) // so Tag.roots() gets refreshed\n\n  private static readonly _upsertDefaultRoots = lazy(() =>\n    Tag.ops().upsert(\n      Roots.map(\n        ea =>\n          ({\n            _path: joinTagPath([ea.name]),\n            ordinal: ea.ordinal\n          } as PartialPojo<Tag>)\n      )\n    )\n  )\n\n  // afterUpsert will only clear this if new root tags are added\n  static readonly roots = lazy<Promise<Tag[]>>(async () => {\n    await Tag._upsertDefaultRoots()\n\n    const tags = await Tag.ops().all(orderBy(Tag.query().whereNull(\"parentId\")))\n\n    tags.forEach(ea => {\n      ea.parentId = undefined\n      ea.ancestors = []\n      Tag.cacheTag(ea)\n    })\n\n    return tags\n  })\n\n  static newTag(tagPath: TagPath): Tag {\n    const t = new Tag()\n    t._path = joinTagPath(tagPath)\n    const d = tagPath[tagPath.length - 1] as any\n    if (d != null && isObject(d)) {\n      map(d.displayName, ea => (t._displayName = ea))\n      map(d.ordinal, ea => (t.ordinal = ea))\n      map(d.description, ea => (t.description = ea))\n      map(d.releasedAt, ea => (t.releasedAt = ea))\n    }\n    return t\n  }\n\n  static findByIdOrPath(tagId: Maybe<number>, tagPath: string[]) {\n    return tagId === 0\n      ? Tag.root()\n      : gt0(tagId)\n      ? this.findById(tagId)\n      : this.findByPath(tagPath)\n  }\n\n  static findById(tagId: number) {\n    return tagId === 0\n      ? Tag.root()\n      : Tag.tagById.getOrSet(tagId, () => cacheTag(this.ops().findById(tagId)))\n  }\n\n  static async findByPath(tagPath: TagPath): PromiseMaybe<Tag> {\n    const _path = joinTagPath(tagPath)\n    return blank(_path)\n      ? Tag.root()\n      : Tag.recentTagsByPath.getOrSet(_path, () =>\n          thenMap(\n            // LIKE gives us case insensitivity:\n            this.ops().firstf(q => q.where(\"_path\", \"like\", _path)),\n            ea => Tag.cacheTag(ea)\n          )\n        )\n  }\n\n  static getPagedAssets(tagId: number, crit: TagAssetsCriteria) {\n    const t = new Tag()\n    t.id = tagId\n    return t.getPagedAssetIds(crit)\n  }\n\n  static async findOrCreate(tagPath: TagPath): Promise<Tag> {\n    if (isEmpty(tagPath)) {\n      throw new Error(\"empty tagPath\")\n    }\n    const path = joinTagPath(tagPath, \"/\")\n    const prior = (await this.findByPath(tagPath)) as Tag\n    this.logger().debug(\"_findOrCreate(\" + path + \")\", { prior })\n    if (prior != null) {\n      return prior\n    }\n\n    const newTag = this.newTag(tagPath)\n    const parent =\n      newTag.depth <= 1\n        ? undefined\n        : await this.findOrCreate(tagPath.slice(0, -1))\n    map(parent, p => (newTag.parentId = p.id!))\n    const result = (await cacheTag(this.ops().upsertOne(newTag)))!\n    this.logger().debug(\"_findOrCreate(\" + path + \") upserted\", {\n      newTag,\n      result,\n      parent\n    })\n    return result\n  }\n\n  id?: number\n  parentId?: number\n  ordinal?: number\n\n  // The _path is required and must be unique. It's used for navigation.\n  _path!: string\n\n  // \"_displayName\" is optional, and used when the \"canonical\" name differs from\n  // the \"display\" name.\n\n  // \"_displayName\" allows for more friendly tag names in the UI (for\n  // month name localization or to replace the \"volsha\" in filesystem paths with the label\n  // of the device).\n\n  _displayName?: string\n  description?: string\n  releasedAt?: number\n  assetCount?: number\n  assetFileCount?: number\n\n  parent?: Tag\n  root?: Tag\n  children?: Tag[]\n  ancestors?: Tag[]\n  assets?: Asset[]\n\n  /**\n   * Holds the last-fetched related assets from `getRelatedAssets`\n   */\n  relatedAssets?: Asset[]\n  nextBatchUrl?: string\n\n  clear() {\n    this.parent = undefined\n    this.root = undefined\n    this.children = undefined\n    this.ancestors = undefined\n    this.assets = undefined\n    this.relatedAssets = undefined\n    this.ancestorIds.unset()\n    this.descendantIds.unset()\n    return this\n  }\n\n  readonly urls = lazy(() => new TagUrls(this.id!))\n\n  siblingPath(name: string) {\n    return joinTagPath([...this.parentPath, name])\n  }\n\n  async changeName(name: string) {\n    return this.changePath(this.siblingPath(name))\n  }\n\n  maybeUpsertDisplayName(displayName: Maybe<string>) {\n    return blank(displayName) || displayName === this._displayName\n      ? undefined\n      : this.upsert({ _displayName: displayName } as any)\n  }\n\n  async changePath(newPath: string, finallyClear = true) {\n    const priorPath = this._path\n\n    // If a sibling already exists, they win.\n    const existingSibling = await Tag.findByPath(splitTagPath(newPath))\n\n    this.logger().info(\"changePath(): \", {\n      priorPath,\n      newPath,\n      existingSibling\n    })\n\n    try {\n      if (existingSibling == null) {\n        await Tag.tx(async () => {\n          await Tag.dbl.runf(q =>\n            q.where(\"_path\", \"LIKE\", priorPath + \"%\").update({\n              updatedAt: Date.now(),\n              _path: knex.raw(\"REPLACE(_path, ?, ?)\", [priorPath, newPath])\n            })\n          )\n        })\n        this._path = newPath\n      } else {\n        // OH NOES. I'm about to get deleted. Give my children to existingSibling.\n        newPath = existingSibling._path // < deal with case insensitivity\n        this.logger().info(\"changePath(): replacing with sibling\", newPath)\n\n        // Make sure my assets are still tagged:\n        await AssetTag.dbl.updateOrIgnore(q =>\n          q.where({ tagId: this.id }).update({ tagId: existingSibling.id })\n        )\n        await AssetTag.dbl.runf(q => q.where({ tagId: this.id }).delete())\n\n        // TODO: make this one big batch command instead of doing it in node:\n        await thenCollect(this.getChildren(), ea =>\n          ea.changePath(joinTagPath([...existingSibling.path, ea.name]), false)\n        )\n\n        // At this point my child tags will have been either deleted, if they were duplicated by `existingSibling`, or they need to be re-parented:\n        await Tag.dbl.runf(q =>\n          q\n            .where({ parentId: this.id })\n            .update({ parentId: existingSibling.id })\n        )\n        await this.delete()\n      }\n    } finally {\n      if (finallyClear) Tag.clear()\n    }\n  }\n\n  get name(): string {\n    const p = this.path\n    return p[p.length - 1]\n  }\n\n  get path(): string[] {\n    return splitTagPath(this._path)\n  }\n\n  get displayName() {\n    return notBlank(this._displayName) ? this._displayName : this.name\n  }\n\n  readonly displayPath: MemoizedThunk<Promise<string[]>> = lazy(async () => {\n    const p = await this.getParent()\n    return [...(p == null ? [] : await p?.displayPath()), this.displayName]\n  })\n\n  get isRoot(): boolean {\n    return this.id === 0\n  }\n\n  get depth(): number {\n    return this.path.length\n  }\n\n  get parentPath(): string[] {\n    return this.path.slice(0, -1)\n  }\n\n  get sortBy() {\n    return [\n      this.ordinal == null ? 2 ** 51 : this.ordinal,\n      this.path.map(ea => ea.toLowerCase())\n    ]\n  }\n\n  $childrenQuery() {\n    return orderBy(Tag.query().where({ parentId: this.id }))\n  }\n\n  $assetsQuery() {\n    return Asset.query()\n      .columns(\"Asset.*\")\n      .join(\"AssetTag\", \"AssetTag.assetId\", \"Asset.id\")\n      .where({ tagId: this.id! })\n      .andWhere(\"Asset.shown\", 1)\n      .andWhere(\"Asset.hidden\", 0)\n      .andWhere(\"Asset.excluded\", 0)\n  }\n\n  setAncestors(a: Tag[]) {\n    this.ancestors = a\n    this.parent = a[a.length - 1]\n    map(this.parent, p => p.setAncestors(a.slice(0, -1)))\n  }\n\n  async toApiPathElements(): Promise<PathTag[]> {\n    return thenCollect(this.getAncestorsAndSelf(), ea => ({\n      tagPath: ea.path,\n      displayName: ea.displayName\n    }))\n  }\n\n  async toApiTag(): Promise<ApiTag> {\n    return {\n      tagId: this.id!,\n      tagPath: this.path,\n      displayPath: await this.displayPath(),\n      description: this.description,\n      assetCount: this.assetCount!,\n      assetFileCount: this.assetFileCount!\n    }\n  }\n\n  toStringId() {\n    return \"Tag(\" + this.path.join(\"/\") + \")\"\n  }\n\n  async getParent() {\n    if (this.isRoot) return undefined\n    if (this.parentId != null && this.parent == null) {\n      return (this.parent = await Tag.findById(this.parentId))\n    } else {\n      return this.parent\n    }\n  }\n\n  async getPagedChildren(crit: ChildTagCriteria) {\n    if (this.id === 0) {\n      const begin = orElse(crit.offset, 0)\n      const end = begin + orElse(crit.limit, this.children!.length)\n      return [...this.children!].slice(begin, end)\n    }\n    const q = this.$childrenQuery()\n    mapGt0(crit.offset, offset => {\n      void q.offset(offset)\n    })\n    mapGt0(crit.limit, limit => void q.limit(limit))\n    const result = await Tag.ops().all(q)\n    for (const ea of result) Tag.cacheTag(ea)\n    return result\n  }\n\n  readonly descendantIds = lazy(async () => {\n    return Tag.dbl.pluckAll({\n      sql: compressWhitespace(\n        \"WITH RECURSIVE descendants(id) AS (\",\n        \"  VALUES (:tagId)\",\n        \"  UNION\",\n        \"  SELECT Tag.id\",\n        \"  FROM Tag, descendants\",\n        \"  WHERE Tag.parentId = descendants.id\",\n        \")\",\n        \"SELECT id \",\n        \"FROM descendants\",\n        \"WHERE id <> :tagId\"\n      ),\n      bindings: { tagId: this.id }\n    })\n  }, 7 * secondMs)\n\n  async getDescendants() {\n    return Tag.ops().all({\n      sql: compressWhitespace(\n        \"WITH RECURSIVE descendants(id) AS (\",\n        \"  VALUES (:tagId)\",\n        \"  UNION\",\n        \"  SELECT Tag.id\",\n        \"  FROM Tag, descendants\",\n        \"  WHERE Tag.parentId = descendants.id\",\n        \")\",\n        \"SELECT Tag.*\",\n        \"FROM Tag\",\n        \"WHERE Tag.id IN descendants\",\n        \"  AND Tag.id <> :tagId\"\n      ),\n      bindings: { tagId: this.id }\n    })\n  }\n\n  async getChildrenCount() {\n    return this.children != null\n      ? this.children.length\n      : (Tag.dbl.pluckFirstf(q =>\n          (this.isRoot\n            ? q.whereNull(\"parentId\")\n            : q.where({ parentId: this.id })\n          ).count()\n        ) as Promise<number>)\n  }\n\n  async getChildren() {\n    this.children = await Tag.ops().all(this.$childrenQuery())\n    this.children.forEach(childTag => {\n      childTag.parent = this\n    })\n    return this.children\n  }\n\n  link(): string {\n    return \"/tag/\" + this.path.map(encodeURIComponent).join(\"/\")\n  }\n\n  get rootName() {\n    return this.path[0]\n  }\n\n  get ancestorsAndSelf() {\n    return [...this.ancestors!, this]\n  }\n\n  /**\n   * @return nearest parent last\n   */\n  async getAncestors() {\n    if (this.ancestors == null) {\n      const ancestorPaths = ancestry(this.parentPath).map(ea => joinTagPath(ea))\n      const cachedAncestors = await Promise.all(\n        ancestorPaths.map(ea => Tag.recentTagsByPath.get(ea))\n      )\n      if (cachedAncestors.every(ea => ea != null)) {\n        return (this.ancestors = cachedAncestors as Tag[])\n      }\n      const q = Tag.query().whereIn(\"_path\", ancestorPaths).orderBy(\"_path\")\n      this.ancestors = await Tag.ops().all(q)\n      Tag.cacheTags(this.ancestors)\n\n      this.parent = orElse(\n        this.parent,\n        this.ancestors[this.ancestors.length - 1]\n      )\n    }\n    return this.ancestors\n  }\n\n  async getAncestorsAndSelf() {\n    return [...(await this.getAncestors()), this]\n  }\n\n  /**\n   * Doesn't cache ancestors.\n   * @return nearest parent last\n   */\n  async _getAncestors() {\n    if (this.parentId === 0 || this.parentId == null) return []\n    return Tag.ops().all({\n      sql: compressWhitespace(\n        [\n          \"WITH RECURSIVE ancestors(id) AS (\",\n          \"  VALUES (:tagId)\",\n          \"  UNION\",\n          \"  SELECT Tag.parentId\",\n          \"  FROM Tag, ancestors\",\n          \"  WHERE Tag.id = ancestors.id\",\n          \")\",\n          \"SELECT Tag.*\",\n          \"FROM Tag\",\n          \"WHERE Tag.id IN ancestors\",\n          \"  AND Tag.id <> :tagId\",\n          \"ORDER BY Tag._path DESC\"\n        ].join(\" \")\n      ),\n      bindings: { tagId: this.id }\n    })\n  }\n\n  readonly ancestorIds = lazy(async () => {\n    if (this.parentId === 0 || this.parentId == null) return []\n    return Tag.dbl.pluckAll({\n      sql: compressWhitespace(\n        [\n          \"WITH RECURSIVE ancestors(id) AS (\",\n          \"  VALUES (:tagId)\",\n          \"  UNION\",\n          \"  SELECT Tag.parentId\",\n          \"  FROM Tag, ancestors\",\n          \"  WHERE Tag.id = ancestors.id\",\n          \")\",\n          \"SELECT id\",\n          \"FROM Tag\",\n          \"WHERE Tag.id in ancestors\",\n          \"  AND Tag.id <> :tagId\",\n          \"ORDER BY _path DESC\"\n        ].join(\" \")\n      ),\n      bindings: { tagId: this.id }\n    })\n  })\n\n  getPagedAssetIds(crit: TagAssetsCriteria): Promise<AssetId[]> {\n    let q = this.$assetsQuery().select(\n      \"Asset.id as assetId\",\n      \"Asset.capturedAtLocal as capturedAtLocal\"\n    )\n\n    let sortDirection = \"desc\"\n\n    mapGte0(crit.capturedAtLt, lt => {\n      q = q.where(\"capturedAtLocal\", \"<\", lt)\n    })\n    mapGte0(crit.capturedAtGt, gt => {\n      q = q.where(\"capturedAtLocal\", \">\", gt)\n      sortDirection = \"asc\"\n    })\n    mapGte0(crit.limit, limit => {\n      q = q.limit(limit)\n    })\n    q = q.orderBy(\"capturedAtLocal\", sortDirection)\n    return (Asset.dbl.all(q) as any) as Promise<AssetId[]>\n  }\n\n  getAssets() {\n    // reverse chron:\n    const q: any = this.$assetsQuery().orderBy(\"capturedAtLocal\", \"desc\")\n    return Asset.ops().all(q)\n  }\n\n  async assetCountDesc(assets?: Asset[]) {\n    const assetCount = this.assetCount\n    return (\n      (assetCount == null ||\n      assets == null ||\n      assets.length === assetCount ||\n      assets.length === 0\n        ? \"\"\n        : fmt(assets.length) + \" of \") + plur(assetCount!, \"asset\")\n    )\n  }\n\n  // readonly counts = lazy(async () => {\n  //   return this.id === 0\n  //     ? Tag.dbl.first({\n  //         sql: compressWhitespace(\n  //           \"SELECT\",\n  //           \"  count(DISTINCT Asset.id) AS assetCount,\",\n  //           \"  count(DISTINCT AssetFile.id) as assetFileCount\",\n  //           \"FROM\",\n  //           \"  Asset\",\n  //           \"  JOIN AssetFile ON AssetFile.assetId = Asset.id\",\n  //           \"WHERE\",\n  //           \"  Asset.shown = 1\",\n  //           \"  AND Asset.excluded = 0\",\n  //           \"  AND Asset.hidden = 0\"\n  //         )\n  //       })\n  //     : Tag.dbl.first({\n  //         sql: compressWhitespace(\n  //           \"WITH RECURSIVE descendants(id) AS (\",\n  //           \"  VALUES (:tagId)\",\n  //           \"  UNION\",\n  //           \"  SELECT Tag.id\",\n  //           \"  FROM Tag, descendants\",\n  //           \"  WHERE Tag.parentId = descendants.id\",\n  //           \")\",\n  //           \"SELECT sum(assetCount) as assetCount, sum(assetFileCount) as assetFileCount\",\n  //           \"FROM descendants\",\n  //           \"JOIN Tag ON Tag.id = descendants.id\"\n  //         ),\n  //         bindings: { tagId: this.id }\n  //       })\n  // }, 7 * secondMs)\n\n  // /**\n  //  * Includes all inherited counts from descendant tags\n  //  */\n  // async getAssetCount() {\n  //   return (await this.counts())?.assetCount as number\n  // }\n\n  // /**\n  //  * Includes all inherited counts from descendant tags\n  //  */\n  // async getAssetFileCount() {\n  //   return (await this.counts())?.assetFileCount as number\n  // }\n\n  $assetStreamQuery(asset: Asset, limit: number, op: \"<\" | \"=\" | \">\") {\n    let qb =\n      this.path[0] === TagRoots.When\n        ? Asset.shownUnhidden()\n        : this.$assetsQuery()\n    qb = qb\n      .distinct()\n      .where(\"capturedAtLocal\", op, asset.capturedAtLocal)\n      .andWhereNot(\"Asset.id\", asset.id)\n      .limit(op === \"=\" ? limit * 2 : limit) // in case both sides of the stream are all from the same time (!!!)\n\n    if (op === \"=\") {\n      return qb.orderByRaw(`ABS(Asset.id-${asset.id})`)\n    } else {\n      return qb.orderBy([\n        { column: \"capturedAtLocal\", order: op === \">\" ? \"asc\" : \"desc\" },\n        \"Asset.id\"\n      ])\n    }\n  }\n\n  async getAssetStream(\n    asset: Asset,\n    limit: number\n  ): Promise<TaggedAssetStream> {\n    limit = gt0(limit) ? limit : BeforeAfterStreamLimit\n    const [before, same, after] = await thenCollect([\"<\", \"=\", \">\"], op =>\n      Asset.ops().all(this.$assetStreamQuery(asset, limit, op as any))\n    )\n    for (const ea of same) {\n      if (ea.id! < asset.id!) {\n        before.push(ea)\n      } else {\n        after.push(ea)\n      }\n    }\n    return new TaggedAssetStream([this], before, after.reverse(), limit)\n  }\n\n  async getRelatedAssetIds(seed: number, limit: number = ThumbsPerSample) {\n    const max = Math.max(256, await assetCount())\n    const results = ((await AssetTag.dbl.allf(q =>\n      q\n        .select(\n          \"Asset.id as assetId\",\n          \"Asset.capturedAtLocal as capturedAtLocal\"\n        )\n        .distinct()\n        .join(\"Asset\", \"Asset.id\", \"AssetTag.assetId\")\n        .join(\"Tag\", \"Tag.id\", \"AssetTag.tagId\")\n        // TODO: is this faster?\n        // .whereIn(\"AssetTag.assetId\", await this.selfAndDescendantIds(txn))\n        .where(\"_path\", \"like\", this._path + \"%\")\n        .andWhere(\"Asset.shown\", 1)\n        .andWhere(\"Asset.excluded\", 0)\n        .andWhere(\"Asset.hidden\", 0)\n        .orderByRaw(\n          prngOrderByClause(seed + orElse(this.id, 0), \"Asset.id\", max)\n        )\n        .limit(limit)\n    )) as unknown) as AssetId[]\n\n    this.logger().debug(\n      this.path + \": Found \" + results.length + \" related assets\",\n      results\n    )\n    return results\n  }\n\n  get attrs(): Record<string, string> {\n    return { href: this.link(), title: this.name }\n  }\n}\n\nconst assetCount = lazy(\n  () => Asset.dbl.pluckFirstf<number>(q => q.count()),\n  minuteMs\n)\n", "import { mkLogger } from \"../../core/Logger\"\nimport { mapGt0 } from \"../../core/Number\"\nimport { TagRoots } from \"../../fe/api/Tag\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { thenCollect } from \"../../fe/Promise\"\nimport { monthTagRef, ordinalToMonth } from \"../curators/DateTagger\"\nimport { Tag } from \"./Tag\"\n\n//\n// UUUUUGHHHHH!\n//\n// THIS WHOLE CLASS IS A TERRIBLE HACK. FUTURE ME PLEASE DELETE THIS CODE.\n//\n// When tags should be represented numerically in the database, and *only in the\n// frontend* should the display value rendered, according to the browser locale.\n//\n\nconst whenQuery = `'${TagRoots.When}' || char(31)`\nconst yearQuery = whenQuery + ` || '%' || char(31)`\nconst monthQuery = yearQuery + ` || '%' || char(31)`\nconst dayQuery = monthQuery + ` || '%' || char(31)`\n\nconst logger = lazy(() => mkLogger(\"DateTagNormalizer\"))\n\nexport async function getMonthTags() {\n  return Tag.ops().allf(\n    q =>\n      q\n        .whereNotNull(\"ordinal\")\n        .andWhereRaw(\n          \"_path LIKE \" + monthQuery + \" AND _path NOT LIKE \" + dayQuery\n        )\n        .limit(200 * 12) // 200 years of month tags. We can fetch all 2400 into RAM, no need to batch.\n  )\n}\n\nexport async function normalizeDateTags() {\n  await Tag.tx(async () => thenCollect(getMonthTags(), normalizeMonthTag))\n}\n\nexport async function normalizeMonthTag(tag: Tag) {\n  const tagRef = await mapGt0(tag.ordinal, ord =>\n    monthTagRef(ordinalToMonth(ord))\n  )\n  if (tagRef == null) {\n    logger().warn(\"failed to fix tag (no monthTagRef)\", { t: tag })\n  } else if (tagRef.name !== tag.name) {\n    logger().info(\"Fixing month name\", { tagRef, tag })\n    await tag.changeName(tagRef.name)\n  }\n  await tag.maybeUpsertDisplayName(tagRef?.displayName)\n}\n", "import { hostname } from \"os\"\nimport { pid } from \"process\"\nimport { LaterMaybe } from \"../../core/async/Later\"\nimport { stack } from \"../../core/error/Error\"\nimport { maxCpus } from \"../../core/work/MaxCpus\"\nimport { ProgressState, SyncStatus } from \"../../fe/api/ProgressState\"\nimport { compactBlanks } from \"../../fe/Array\"\nimport { mapNotBlank } from \"../../fe/Blank\"\nimport { dayMs, secondMs } from \"../../fe/Date\"\nimport { stringify } from \"../../fe/JSON\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { fromEntries } from \"../../fe/Object\"\nimport { thenCollect } from \"../../fe/Promise\"\nimport { compressWhitespace } from \"../../fe/String\"\nimport { toA } from \"../../fe/toA\"\nimport { assignFromJSON } from \"./ModelJson\"\nimport { Operation, OperationNames } from \"./Operation\"\nimport { ProgressMeta, ProgressMetaName } from \"./ProgressMeta\"\nimport { TableName } from \"./TableName\"\nimport { TimestampedModel } from \"./TimestampedModel\"\n\nexport interface ProgressPojo extends ProgressState {\n  id: number\n  uri: string\n  completedAt?: number\n}\n\n// Slower progress rate if we don't have free CPUs:\nexport const ProgressRateMs = lazy(() => secondMs * (maxCpus() <= 3 ? 3 : 1.5))\n\nexport interface ProgressTimes {\n  uri: string\n  lastUpdatedAt: number\n  lastCompletedAt: Maybe<number>\n  lastStartedAt: number\n}\n\n// Yeah, I'm not transcribing this into knex.\nconst StartTimeQuery = compressWhitespace(`\nSELECT\n  p1.uri as uri,\n  p1.lastUpdatedAt as lastUpdatedAt,\n  p1.lastCompletedAt as lastCompletedAt,\n  min(p2.createdAt) AS lastStartedAt\nFROM\n  (\n    SELECT\n      uri,\n      max(updatedAt) AS lastUpdatedAt,\n      max(completedAt) AS lastCompletedAt\n    FROM\n      Progress\n    WHERE\n      createdAt > :minCreatedAt\n    GROUP BY\n      uri\n  ) AS p1\n  JOIN Progress AS p2\n    ON \n      p2.uri = p1.uri AND \n      p2.createdAt > :minCreatedAt AND\n      (p2.createdAt > ifnull(p1.lastCompletedAt, 0) OR p2.completedAt = lastCompletedAt)\nGROUP BY\n  1,2,3\n`)\n\nconst ProgressMetaQuery = compressWhitespace(`\nSELECT\n  *\nFROM\n  ProgressMeta\nWHERE\n  id IN (\n    SELECT\n      max(pm.id)\n    FROM\n      ProgressMeta pm\n      JOIN Progress p ON pm.progressId = p.id\n      AND p.createdAt > :minCreatedAt\n    WHERE\n      p.uri = :uri\n      AND p.hostname = :hostname\n    GROUP BY\n      p.uri,\n      pm.name\n  )\n`)\n\n/**\n * Holds per-volume information rendered to the UI by progress-panel. We delete\n * records older than 90 days, so we expect max ~ new sync job every hour: 2,160\n * rows (so we only bother with an index on updatedAt to help performance of\n * ProgressRouter)\n */\nexport class Progress\n  extends TimestampedModel\n  implements Omit<ProgressPojo, \"id\"> {\n  static tableName: TableName = \"Progress\"\n  uri!: string\n  hostname!: string\n  pid!: number\n  volume!: string\n  state?: SyncStatus\n  hed?: string\n  dekJSON?: string\n  completePct?: number\n  incompletePct?: number\n  scanningPct?: number\n  completedAt?: number\n\n  // 45 days because we only look back 30 days for last-started-at times\n  static async vacuum(staleMs = 90 * dayMs) {\n    // CAUTION! KNEX .delete() DOESN'T SUPPORT INNER JOINS!\n    // https://github.com/knex/knex/issues/2543#issuecomment-375958986\n    await ProgressMeta.dbl.runf(q =>\n      q\n        .whereIn(\"progressId\", q2 =>\n          q2\n            .table(\"Progress\")\n            .select(\"id\")\n            .where(\"createdAt\", \"<=\", Date.now() - staleMs)\n        )\n        .delete()\n    )\n    await this.dbl.runf(q =>\n      q.where(\"createdAt\", \"<=\", Date.now() - staleMs).delete()\n    )\n  }\n\n  static async minCreatedAt() {\n    const op = await Operation.getFirstPendingOp({\n      name: OperationNames.forceRestartSync\n    })\n    return Progress.logger().tap({\n      msg: \"minCreatedAt\",\n      level: \"info\",\n      result: orElse(op?.createdAt, 0),\n      meta: { op }\n    })\n  } // don't cache this! Operations can be completed!\n\n  static async times(): Promise<ProgressTimes[]> {\n    const minCreatedAt = await this.minCreatedAt()\n    return this.dbl.all({\n      sql: StartTimeQuery,\n      bindings: { minCreatedAt }\n    }) as any\n  }\n\n  static async saveSyncState(sync: {\n    progress: LaterMaybe<Progress | Progress[]>\n  }) {\n    return thenCollect(toA(await sync.progress()), ea => {\n      if (ea.state === \"done\" && ea.completedAt == null) {\n        this.logger().warn(\n          \"caller saved done sync state without setting completedAt\",\n          stack()\n        )\n        ea.completedAt = Date.now()\n      }\n      if (ea.id == null) {\n        return this.logger().throw(\n          sync[\"name\"] + \" returned an unsaved Progress\",\n          ea\n        )\n      }\n      return ea.upsert()\n    })\n  }\n\n  static async insertNew(uri: string, volume: string) {\n    return this.ops().insertOne({\n      uri,\n      volume,\n      pid,\n      hostname: hostname()\n    })\n  }\n\n  // TODO: save recent asset ids to the db in this table, instead of requiring a\n  // query?\n\n  toSyncState(): ProgressPojo {\n    return {\n      id: this.id!,\n      uri: this.uri,\n      volume: this.volume,\n      state: this.state,\n      hed: this.hed,\n      dek: this.dek,\n      completePct: this.completePct,\n      incompletePct: this.incompletePct,\n      scanningPct: this.scanningPct\n    }\n  }\n\n  get dek(): string[] {\n    return orElse(\n      mapNotBlank(this.dekJSON, () => compactBlanks(JSON.parse(this.dekJSON!))),\n      () => []\n    )\n  }\n\n  set dek(arr: string[]) {\n    this.dekJSON = stringify(compactBlanks(arr))\n  }\n\n  assignFromPojo(pojo: Omit<ProgressState, \"volume\" | \"uri\">) {\n    return assignFromJSON(this, pojo)\n  }\n\n  getThisMeta() {\n    return ProgressMeta.ops().allf(q =>\n      q.where({ progressId: this.id! }).orderBy(\"createdAt\")\n    )\n  }\n\n  async getMeta() {\n    return ProgressMeta.ops().all({\n      sql: ProgressMetaQuery,\n      bindings: {\n        minCreatedAt: await Progress.minCreatedAt(),\n        uri: this.uri,\n        hostname: this.hostname\n      }\n    })\n  }\n\n  setMeta(name: ProgressMetaName, value: string) {\n    return ProgressMeta.ops().upsertOne({ progressId: this.id, name, value })\n  }\n\n  async getMetaAsRecord(): Promise<Record<ProgressMetaName, string>> {\n    return fromEntries((await this.getMeta()).map(ea => [ea.name, ea.value]))\n  }\n}\n", "import { Knex } from \"knex\"\nimport { ending } from \"../../core/async/Endable\"\nimport { identity } from \"../../core/Object\"\nimport { blank } from \"../../fe/Blank\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { strEnum, StrEnumKeys } from \"../../fe/StrEnum\"\nimport { PartialPojo } from \"../db/PartialPojo\"\nimport { TimestampedModel } from \"./TimestampedModel\"\n\n// TODO: rebuild, rebuild-assets (just rebuilds assets), sync-asset, ...\nexport const OperationNames = strEnum(\n  \"rebuildLibrary\",\n  \"forceRestartSync\",\n  \"enqueueAssetFileUpdates\",\n  \"enqueueAssetUpdates\",\n  \"applyNewTagger\"\n)\nexport type OperationName = StrEnumKeys<typeof OperationNames>\n\nexport class Operation extends TimestampedModel {\n  static readonly tableName = \"Operation\"\n  static readonly uniqueColumnName = \"id\"\n  name!: OperationName\n  value?: string\n  version?: number\n  completedAt?: number\n\n  static incomplete() {\n    return this.ops().allf(q =>\n      q.whereIn(\"id\", q2 =>\n        q2.table(Operation.tableName).min(\"id\").whereNull(\"completedAt\")\n      )\n    )\n  }\n\n  static async getFirstPendingOp(pojo?: PartialPojo<Operation>) {\n    return this.logger().tap({\n      msg: \"getFirstPendingOp\",\n      level: \"info\",\n      result: await this.ops().firstf(q => {\n        // We want the earliest incomplete op (order by id desc)\n        const result = q.whereNull(\"completedAt\").orderBy(\"createdAt\", \"asc\")\n        return pojo != null ? result.andWhere(pojo) : result\n      }),\n      meta: { pojo }\n    })\n  }\n\n  static markOpCompleted(query: Pick<Operation, \"name\" | \"value\" | \"version\">) {\n    if (blank(query?.name))\n      return this.logger().throw(\"markOpCompleted(): bad query\", { query })\n    return this.dbl.runf(q =>\n      q\n        .whereNull(\"completedAt\")\n        .andWhere(query)\n        .update({ completedAt: Date.now() })\n    )\n  }\n\n  static async applyOnce<T>(\n    attrs: Pick<Operation, \"name\" | \"value\" | \"version\">,\n    f: (op: Operation) => Promise<T>,\n    qb: (qb: Knex.QueryBuilder) => Knex.QueryBuilder = identity\n  ): PromiseMaybe<T> {\n    const prior = await this.ops().firstf(q =>\n      qb(q.whereNotNull(\"completedAt\").andWhere(attrs))\n    )\n    if (prior != null) {\n      this.logger().info(\"applyOnce(): already done\", { prior })\n      return\n    }\n    const op = await this.ops().insertOne(attrs)\n    const result = await f(op)\n    if (!ending()) {\n      await op.upsert({ completedAt: Date.now() })\n    }\n    return result\n  }\n}\n", "import { strEnum, StrEnumKeys } from \"../../fe/StrEnum\"\nimport { TimestampedModel } from \"./TimestampedModel\"\n\nexport const ProgressMetaNames = strEnum(\n  \"lastScannedDirectory\",\n  \"scannedDirectoryCount\",\n  \"completedDirectoryScan\",\n  \"enqueuedStaleFiles\",\n  \"processedImageCount\",\n  \"processedVideoCount\"\n)\nexport type ProgressMetaName = StrEnumKeys<typeof ProgressMetaNames>\n\nexport class ProgressMeta extends TimestampedModel {\n  static readonly tableName = \"ProgressMeta\"\n  static readonly uniqueColumnName = \"progressId,name\"\n  name!: ProgressMetaName\n  value!: string\n}\n", "import { Knex } from \"knex\"\nimport { sep } from \"path\"\nimport { thenMap, thenMapOr, thenNot } from \"../../core/async/Promise\"\nimport { localToDateTime } from \"../../core/date/Date\"\nimport { fmtDateTime } from \"../../core/date/ExtendedDate\"\nimport { onError } from \"../../core/error/Error\"\nimport { PosixFile } from \"../../core/fs/PosixFile\"\nimport { expensiveFileFilter } from \"../../core/fs/PosixFileFilters\"\nimport { geohashNumericShort } from \"../../core/GeoHash\"\nimport { AssetFileBase } from \"../../core/img/AssetFileBase\"\nimport { PreviewAssetFile } from \"../../core/img/AssetPreviewBuilder\"\nimport { ImageHash, imageHash, ModeCount } from \"../../core/img/ImageHash\"\nimport {\n  mkDownloadableTitle,\n  previewToDownloadable\n} from \"../../core/img/PreviewInfo\"\nimport { Previews } from \"../../core/img/Previews\"\nimport { isVideoMimeType } from \"../../core/img/VideoFilter\"\nimport { assignFields, eqlSubset, identity } from \"../../core/Object\"\nimport { AssetFileVersion } from \"../../core/PhotoStructureVersions\"\nimport { escapeRegExp } from \"../../core/RegExp\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { stripSuffix, wbrPath } from \"../../core/String\"\nimport { CapturedAt } from \"../../core/tags/CapturedAt\"\nimport { readTags } from \"../../core/tags/ExifTags\"\nimport { cameraId, imageId, lensId } from \"../../core/tags/ExifUid\"\nimport { uri2nativePath } from \"../../core/uri/FileURI\"\nimport { URI } from \"../../core/uri/URI\"\nimport { uriIsEquivalent } from \"../../core/uri/UriNormalization\"\nimport { mountpoints } from \"../../core/volumes/Mountpoints\"\nimport {\n  ApiAssetFile,\n  AssetFilePathInfo,\n  Downloadable\n} from \"../../fe/api/Asset\"\nimport { ExposureSettings } from \"../../fe/api/ExposureSettings\"\nimport { compact, isEmpty, sort, sum, uniq, uniqBy } from \"../../fe/Array\"\nimport { blank, notBlank } from \"../../fe/Blank\"\nimport { isTrue } from \"../../fe/Boolean\"\nimport { secondMs } from \"../../fe/Date\"\nimport { dimToS } from \"../../fe/Dimensions\"\nimport { fmtDuration } from \"../../fe/fmtDuration\"\nimport { ReducerNames } from \"../../fe/ImageReducers\"\nimport { stringify } from \"../../fe/JSON\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, mapOr, orElse } from \"../../fe/Maybe\"\nimport { Maybe, MaybePromiseMaybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { gt0, round, times, toFloat } from \"../../fe/Number\"\nimport {\n  compactValues,\n  isReqValued,\n  mapFields,\n  omit,\n  reqValuedOrElse\n} from \"../../fe/Object\"\nimport { thenOpt } from \"../../fe/OptAsync\"\nimport { gte } from \"../../fe/Primitive\"\nimport { toS } from \"../../fe/toS\"\nimport { uriToTagPath } from \"../curators/FilePathTagger\"\nimport { knex } from \"../db/Knex\"\nimport { PartialPojo } from \"../db/PartialPojo\"\nimport { Asset } from \"./Asset\"\nimport { TableName } from \"./TableName\"\nimport { Tag } from \"./Tag\"\nimport { TimestampedModel } from \"./TimestampedModel\"\n\nexport class AssetFile\n  extends TimestampedModel\n  implements\n    Partial<ExposureSettings>,\n    ImageHash,\n    AssetFileBase,\n    PreviewAssetFile {\n  /**\n   * Most recent 64 assetURIs, mapped to their asset id. Given we need at most\n   * 32 per progress bar, and there may be the end of one progress and the start\n   * of another, 64 should do it.\n   */\n  // static readonly uri2assetId = new BoundedMap<string, number>(\n  //   5 * minuteMs,\n  //   64,\n  //   true\n  // )\n  // static clear() {\n  //   this.uri2assetId.clear()\n  // }\n  static async recentAssetIdsByUriRoot(\n    uriRoot: Maybe<string>,\n    ttlMs: number,\n    limit = 64\n  ): Promise<number[]> {\n    const since = Date.now() - ttlMs\n    let q = this.query()\n      .distinct(\"AssetFile.assetId\")\n      .join(\"Asset\", \"Asset.id\", \"AssetFile.assetId\")\n      .where(\"AssetFile.updatedAt\", \">\", since)\n      .andWhere(\"Asset.shown\", 1)\n      .andWhere(\"Asset.hidden\", 0)\n\n    if (notBlank(uriRoot)) {\n      q = q.andWhere(\"AssetFile.uri\", \"like\", uriRoot + \"%\")\n    }\n\n    q = q.orderBy(\"AssetFile.updatedAt\", \"desc\").limit(limit)\n\n    this.logger().debug(\"recentAssetIdsByUriRoot\", q.toSQL())\n    return this.dbl.pluckAll(q) as Promise<number[]>\n  }\n\n  static assetCountByMimetype(\n    uriRoot?: string\n  ): Promise<{ mimetype: string; count: number }[]> {\n    let q = this.query()\n      .select(knex.raw(\"mimetype, count(*) as count\"))\n      .join(\"Asset\", \"Asset.id\", \"AssetFile.assetId\")\n      .where(\"Asset.shown\", 1)\n      .andWhere(\"Asset.hidden\", 0)\n      .andWhere(\"Asset.excluded\", 0)\n    if (notBlank(uriRoot)) {\n      q = q.andWhere(\"uri\", \"like\", uriRoot + \"%\")\n    }\n    q = q.groupBy(\"mimetype\").orderBy(\"mimetype\")\n    return this.dbl.all(q) as any\n  }\n\n  /**\n   * Aggregate by \"image/\" and \"video/\"\n   */\n  static async assetCountByMimetypeRoot(\n    uriRoot?: string\n  ): Promise<{ mimetypeRoot: string; count: number }[]> {\n    const agg = await this.assetCountByMimetype(uriRoot)\n    const roots = sort(uniq(agg.map(ea => ea.mimetype.split(\"/\")[0])))\n    return roots.map(mimetypeRoot => ({\n      mimetypeRoot,\n      count: sum(agg, ea =>\n        ea.mimetype.startsWith(mimetypeRoot + \"/\") ? ea.count : 0\n      )\n    }))\n  }\n\n  static children(\n    uriParent: string,\n    q?: (qb: Knex.QueryBuilder) => Knex.QueryBuilder\n  ) {\n    const qb = this.query()\n      // the uri like allows the index to be used:\n      .where(\"uri\", \"like\", uriParent + \"/%\")\n      .andWhere(\"uri\", \"regexp\", `^${escapeRegExp(uriParent)}/[^/]+$}`)\n    return this.ops().all(\n      mapOr(\n        q,\n        ea => ea(qb),\n        () => qb\n      )\n    )\n  }\n\n  static tableName: TableName = \"AssetFile\"\n  static readonly uniqueColumnName = \"uri\"\n  static readonly booleanFields = [\"shown\"]\n\n  assetId?: number\n  asset?: Asset\n\n  /** shown is true iff it's the Asset's preview source */\n  shown!: number | boolean\n\n  uri!: string\n  mountpoint?: string // not set for pslib: URIs\n\n  mtime!: number\n  fileSize!: number\n  mimetype!: string\n  sha!: string\n\n  /**\n   * deci-second resolution in YYYYMMddHHmmssSS\n   */\n  capturedAtLocal!: number\n  capturedAtOffset?: number\n  capturedAtPrecisionMs?: number\n  capturedAtSrc!: string\n\n  get capturedAtDateTime() {\n    return localToDateTime(this.capturedAtLocal, this.capturedAtOffset)\n  }\n\n  capturedAtLocale(locale?: string) {\n    return fmtDateTime(this.capturedAtDateTime, locale)\n  }\n\n  focalLength?: string // 35 mm\n  aperture?: number // 4.8\n  shutterSpeed?: string // 1/100 (does this need to be cleaned up?)\n  iso?: number // 100\n  /** in seconds. Only set for videos. */\n  durationMs?: number\n  fps?: number\n\n  width!: number\n  height!: number\n  rotation?: number\n\n  make?: string\n  model?: string\n  cameraId?: string\n  imageId?: string\n  lensId?: string\n  geohash?: number\n\n  /**\n   * Not-null because all images must be rasterizable to be imported.\n   */\n  meanHash!: ImageHash[\"meanHash\"]\n\n  // rightHash!: ImageHash[\"rightHash\"]\n\n  mode0!: number\n  mode1!: number\n  mode2!: number\n  mode3!: number\n  mode4!: number\n  mode5!: number\n  mode6!: number\n\n  // searchHash!: ImageHash[\"searchHash\"]\n\n  version!: number\n  updateCount?: number\n\n  // transient\n  deleted?: boolean\n\n  // afterUpsert() {\n  //   map(this.assetId, assetId =>\n  //     map(this.uri, uri => AssetFile.uri2assetId.set(uri, assetId))\n  //   )\n  // }\n\n  private static outdatedQuery(_mountpoints: Maybe<string[]>) {\n    const qb = this.query()\n      .where(\"version\", \"<\", AssetFileVersion)\n      .orderBy(\"id\")\n    return isEmpty(_mountpoints)\n      ? qb\n      : qb.andWhere(q =>\n          q.whereIn(\"mountpoint\", _mountpoints).orWhereNull(\"mountpoint\")\n        )\n  }\n\n  static async nextOutdated(\n    q: (qb: Knex.QueryBuilder) => Knex.QueryBuilder = identity\n  ) {\n    return this.ops().findOne(q(this.outdatedQuery(await mountpoints())))\n  }\n\n  static async outdatedCount(\n    q: (qb: Knex.QueryBuilder) => Knex.QueryBuilder = identity\n  ): Promise<number> {\n    const qb = this.outdatedQuery(await mountpoints())\n    return this.dbl.pluckFirst(q(qb.count(\"id\"))) as any // SITS TYPING\n  }\n\n  static async setShown(assetId?: number, assetFileId?: number) {\n    this.logger().info(\"setShown()\", { assetId, assetFileId })\n    if (!gt0(assetId) || !gt0(assetFileId)) {\n      throw new Error(\n        \"setShown(): invalid IDs: \" + stringify({ assetId, assetFileId })\n      )\n    }\n\n    // Avoid fighting the unique constraint:\n    await this.dbl.runf(q => q.update(\"shown\", 0).where(\"assetId\", assetId))\n\n    const sql = [\n      \"UPDATE AssetFile\",\n      \"SET shown = CASE id WHEN $assetFileId THEN 1 ELSE 0 END,\",\n      \"updatedAt = $updatedAt\",\n      \"WHERE assetId = $assetId\"\n    ].join(\" \")\n\n    const bindings = { assetId, assetFileId, updatedAt: Date.now() }\n    return this.dbl.run({ sql, bindings })\n  }\n\n  static async findByAsset(\n    assetConstraints: Pick<Partial<Asset>, keyof Asset>,\n    assetFileConstraints?: Maybe<Pick<Partial<AssetFile>, keyof AssetFile>>\n  ) {\n    const q = this.query().select(\"AssetFile.*\")\n\n    void map(compactValues(assetConstraints), ea =>\n      q\n        .join(\"Asset\", \"Asset.id\", \"AssetFile.assetId\")\n        .where(mapFields(ea, (k, v) => [\"Asset.\" + k, v]))\n    )\n\n    void map(compactValues(assetFileConstraints), ea =>\n      q.where(mapFields(ea, (k, v) => [\"AssetFile.\" + k, v]))\n    )\n\n    return this.ops().all(q)\n  }\n\n  get modes() {\n    return compact(times(ModeCount, i => this[\"mode\" + i]))\n  }\n\n  set modes(arr: number[]) {\n    times(ModeCount, i => (this[\"mode\" + i] = arr[i]))\n  }\n\n  async matchesFile(file?: PosixFile): Promise<boolean> {\n    if (\n      this.version == null ||\n      this.version < AssetFileVersion ||\n      Settings.forceSync.valueOrDefault\n    ) {\n      return false\n    }\n\n    const ff = await this.fileFields(file)\n    return eqlSubset(ff, this)\n  }\n\n  fileFields(file?: PosixFile) {\n    return thenOpt(file)\n      .orElse(() => this.posixFile())\n      .filter(ea => ea.exists())\n      .flatMap(async f => ({\n        uri: await f.uri(), // TODO: SITS: is this necessary? why?\n        fileSize: await f.size(),\n        mtime: await f.thisOrSidecareMaxMtimeMs()\n      }))\n      .filter(isReqValued)\n      .get() as PromiseMaybe<Pick<AssetFile, \"uri\" | \"fileSize\" | \"mtime\">>\n  }\n\n  isVersionUpToDate() {\n    return gte(this.version, AssetFileVersion)\n  }\n\n  async siblingCount(): Promise<number> {\n    return AssetFile.dbl.pluckFirstf<number>(q =>\n      q.count().where({ assetId: this.assetId }).andWhereNot({ id: this.id })\n    )\n  }\n\n  async upsertIfNeeded(): PromiseMaybe<this> {\n    const forced = Settings.forceSync.valueOrDefault\n    if ((await this.matchesFile()) && gt0(this.id) && !forced) {\n      return this.upsert() // < update the updatedAt\n    }\n    if (await this.isFileDeleted()) {\n      this.deleted = true\n      await this.delete()\n      return\n    }\n    if (await this.notExists()) return\n    return thenMap(this.updateFromFile(), () => this.upsert())\n  }\n\n  async maybeUpdateStats(file?: Maybe<PosixFile>) {\n    return thenMap(this.fileFields(file), ea => assignFields(this, ea))\n  }\n\n  /**\n   * NOTE: DOES NOT UPSERT. See `updateIfNeeded()`.\n   */\n  async updateFromFile(file?: PosixFile): PromiseMaybe<this> {\n    const start = Date.now()\n    const l = this.logger().addContext(\".updateFromFile()\")\n    l.debug(\"before\", this)\n    if (this.id != null && (await this.matchesFile(file))) {\n      l.info(\n        \"updateFromFile() no-op: up-to-date version and file stat matches since last update\"\n      )\n      return\n    }\n    if (file != null) {\n      await this.setFile(file)\n    }\n    if (file == null) {\n      file = await this.posixFile()\n    }\n\n    if (file == null || (await file.notExists())) {\n      l.info(\"no-op, \" + file + \" is missing\")\n      return\n    }\n\n    if (this.mountpoint == null) {\n      await thenMap(file.mountpoint(), ea => (this.mountpoint = ea.nativePath))\n    }\n\n    if (null == (await this.maybeUpdateStats(file))) {\n      l.info(\"maybeUpdateStats() failed\", {\n        id: this.id,\n        uri: this.uri\n      })\n      return\n    }\n\n    const shaP = file.sha()\n\n    // TODO: why doesn't this work?\n    // const sibling = await AssetFile.op((op, q) =>\n    //   op.first(q.where({ sha, version: AssetFileVersion }))\n    // )\n    // if (sibling != null) {\n    //   return this.updateFromShaSibling(sibling)\n    // }\n\n    // Don't unset any metadata we already have.\n    const af: PartialPojo<this> = {}\n\n    const t = await readTags(file)\n    if (t == null) {\n      l.error(\"missing tags for \" + file)\n      return\n    }\n    if (blank(t.MIMEType)) {\n      l.error(\"missing MIMEType for \" + file)\n      return\n    }\n    af.mimetype = t.MIMEType\n\n    const c = t.capturedAt\n    const capturedAtLocal = c.toLocal()\n    if (capturedAtLocal == null) {\n      return l.throw(\"bad CapturedAt\", c)\n    }\n    af.capturedAtLocal = capturedAtLocal\n    af.capturedAtOffset = c.toOffset()\n    af.capturedAtPrecisionMs = c.toPrecisionMs()\n    af.capturedAtSrc = c.src\n\n    map(t.exposureSettings, exp => {\n      af.focalLength = exp.focalLength\n      af.aperture = exp.aperture\n      af.shutterSpeed = exp.shutterSpeed\n      af.iso = exp.iso\n    })\n\n    const dims = t.dimensions\n    af.width = dims.width\n    af.height = dims.height\n    af.rotation = t.rotation\n    af.make = t.Make\n    af.model = t.Model\n    af.cameraId = cameraId(t)\n    af.imageId = map(imageId(t), toS)\n    af.lensId = lensId(t)\n    af.geohash = geohashNumericShort(t.GPSLatitude, t.GPSLongitude)\n    af.durationMs = map(t.duration, ea => Math.round(ea * 1000))\n    af.fps = map(toFloat(t.VideoFrameRate), round)\n\n    af.sha = await shaP\n    if (af.sha == null) {\n      l.info(\"maybeUpdateStats() failed, no SHA\", {\n        id: this.id,\n        uri: this.uri\n      })\n      return\n    }\n\n    if (\n      Settings.useImageHashes.valueOrDefault ||\n      Settings.strictDeduping.valueOrDefault\n    ) {\n      await thenMap(imageHash(file), ea => {\n        af.meanHash = ea.meanHash\n        // af.rightHash = ea.rightHash\n        // af.searchHash = ea.searchHash\n        af.modes = ea.modes\n      })\n    }\n\n    assignFields(this, af)\n\n    // This prevents previously-set values from being unset:\n    // for (const k of keys(af)) {\n    //   const v = af[k]\n    //   if (v != null || Settings.forceSync.valueOrDefault) {\n    //     this[k] = v\n    //   }\n    // }\n\n    this.version = AssetFileVersion\n    const elapsed = Date.now() - start\n    l.log(\n      elapsed > secondMs ? \"info\" : \"debug\",\n      \"after (\" + elapsed + \"ms)\",\n      this\n    )\n    return this\n  }\n\n  async updateFromShaSibling(sibling: AssetFile) {\n    this.logger().debug(\"updateFromShaSibling\", sibling)\n    if (this.isVersionUpToDate()) return this\n    if (\n      sibling.sha == null ||\n      !sibling.isVersionUpToDate() ||\n      (this.sha != null && sibling.sha !== this.sha)\n    ) {\n      return this.logger().throw(\"updateFromShaSibling(): invalid sibling\", {\n        this: this,\n        sibling\n      })\n    }\n    assignFields(\n      this,\n      omit(\n        sibling,\n        \"id\",\n        \"posixFile\",\n        \"asset\",\n        \"shown\",\n        \"uri\",\n        \"mtime\",\n        \"fileSize\",\n        \"mountpoint\",\n        \"createdAt\",\n        \"updatedAt\"\n      )\n    )\n    return this\n  }\n\n  async getAsset() {\n    if (this.assetId == null || this.asset != null) return this.asset\n    return (this.asset = await Asset.ops().findById(this.assetId))\n  }\n\n  async exists(): Promise<boolean> {\n    return thenMapOr(\n      this.posixFile(),\n      ea => ea.exists(),\n      () => false\n    )\n  }\n\n  /**\n   * True if the file is not currently present\n   */\n  async notExists(): Promise<boolean> {\n    return thenNot(this.exists())\n  }\n\n  /**\n   * True if the volume is currently mounted and this file is missing.\n   */\n  async isFileDeleted(): Promise<boolean> {\n    return thenMapOr(\n      this.posixFile(),\n      pf => pf.isDeleted(this.uri!),\n      () => false // If we're not sure, don't mark as deleted.\n    )\n  }\n\n  /**\n   * Does this file exist and rejected by the currently-configured\n   * expensiveFileFilter?\n   */\n  async isFiltered(): Promise<boolean> {\n    return (\n      thenOpt(this.posixFile())\n        // only validate existing files:\n        .filter(f => f.exists())\n        .flatMap(f => expensiveFileFilter().apply(f))\n        // we want not-accepted:\n        .map(ea => !ea)\n        // default to false (not filtered)\n        .getOrElse(() => false)\n    )\n  }\n\n  async hasNoMedia(): Promise<boolean> {\n    return thenMapOr(\n      this.posixFile(),\n      f => f.hasNoMedia(),\n      () => false\n    )\n  }\n\n  async setFile(file: PosixFile) {\n    const uri = await file.uri()\n    if (uri == null) {\n      return this.logger().throw(\"setFile(): no URI for \" + file)\n    }\n    const mountpoint = await file.mountpoint()\n    if (mountpoint == null) {\n      return this.logger().throw(\"setFile(): no mountpoint for \" + file)\n    }\n\n    if (this.uri != null) {\n      // Verify the prior URI is equivalent:\n      if (!(await uriIsEquivalent(uri, this.uri))) {\n        return this.logger().throw(\n          \"setFile(): cannot reassign non-equivalent URI\",\n          { prior: this.uri, new: uri, file: file.nativePath }\n        )\n      }\n    }\n\n    const voluri = await file.uriObject()\n    if (voluri == null) {\n      this.logger().error(\"setFile(): cannot determine voluri\", file)\n      throw new Error(\"no URI for \" + file)\n    }\n\n    this.uri = uri\n    this.mountpoint = mountpoint.nativePath\n\n    void this.posixFile.set(Promise.resolve(file))\n    return uri\n  }\n\n  readonly posixFile = lazy(() => PosixFile.forUri(this.uri, this.mountpoint))\n\n  nativePath() {\n    return thenMap(this.posixFile(), ea => ea.nativePath)\n  }\n\n  toCapturedAt(): MaybePromiseMaybe<CapturedAt> {\n    return map(\n      localToDateTime(this.capturedAtLocal, this.capturedAtOffset),\n      date =>\n        thenMap(\n          this.posixFile(),\n          pf =>\n            new CapturedAt(\n              pf.nativePath,\n              date,\n              this.capturedAtSrc as any,\n              new Date(this.mtime),\n              this.capturedAtPrecisionMs\n            )\n        )\n    )\n  }\n\n  async downloadables(\n    previews: Previews,\n    shownSha?: string\n  ): Promise<Downloadable[]> {\n    try {\n      const f = await this.posixFile()\n      if (f == null) return []\n\n      const ap = previews.ap(this.assetId!)\n\n      // If we can't get dimensions, the file is missing\n\n      const result: Downloadable[] = []\n      if (await f.isNonEmpty()) {\n        result.push({\n          href: `/dl/${this.assetId}/${this.id}`,\n          size: \"original\",\n          title: mkDownloadableTitle(\n            f,\n            \"original\",\n            this.isVideo ? \"video\" : \"image\",\n            { width: this.width, height: this.height }\n          ),\n          basename: f.base,\n          description: \"Download original\",\n          details: `(${dimToS(this)} ${f.ext})`\n        })\n      }\n\n      if (this.isVideo) return result\n\n      const shown = isTrue(this.shown) || this.sha === shownSha\n\n      if (!shown) return result\n\n      const arr = compact(\n        await Promise.all(\n          [...(await ap.previews())]\n            .reverse()\n            .filter(ea => ea.reducer === ReducerNames.fit)\n            .map(ea => previewToDownloadable(f.base, ea))\n        )\n      )\n\n      result.push(\n        ...uniqBy(\n          arr,\n          // arr.filter(ea => [\"large\", \"small\"].includes(ea.size)),\n          ea => ea.size\n        )\n      )\n      return result\n    } catch (err) {\n      onError(\"AssetFile.downloadables failed\", err, { context: this })\n      return []\n    }\n  }\n\n  async pathInfo(): PromiseMaybe<AssetFilePathInfo> {\n    try {\n      const u = URI.parse(this.uri)\n      const nativePath = await uri2nativePath(u, this.mountpoint)\n      if (nativePath == null) {\n        this.logger().warn(\"pathInfo(): failed to build nativePath\", {\n          uri: this.uri\n        })\n        return\n      }\n\n      // fsPath will not have the mountpoint/authority name\n      const fsPath = u.fsPath\n\n      const mountpointParent = stripSuffix(nativePath, fsPath).split(sep)\n      const mountpointName = mountpointParent.pop()\n      const pathAfterMountpointParent = fsPath.split(sep)\n\n      // for pslib://, it'll be the path from the library.\n\n      // for psfile://, it'll be the path from the mountpoint.\n\n      const tagPath = uriToTagPath(u)\n      const tag = await Tag.findByPath(tagPath)\n      if (tag == null) {\n        this.logger().warn(\"pathInfo(): failed to find existing Tag\", {\n          tagPath\n        })\n        return\n      }\n\n      const pathElements = await tag.toApiPathElements()\n\n      this.logger().info(\"pathInfo()\", {\n        uri: this.uri,\n        fsPath,\n        nativePath,\n        mountpointParent,\n        pathAfterMountpointParent,\n        mountpointName,\n        tag_path: tag.path,\n        pathElements\n      })\n\n      // The first tag element is \"File\": we don't need that.\n      pathElements.shift()\n\n      // The next element will be the volsha or \"Library\": call it the actual\n      // path's basename. This will be blank if the mountpoint is \"/\".\n      if (blank(mountpointName)) {\n        pathElements.shift()\n      } else {\n        pathElements[0].displayName = mountpointName\n      }\n\n      // assume the tag's pathElements matches up with pathAfterMountpointParent:\n\n      pathAfterMountpointParent.splice(0, pathElements.length)\n\n      const result = {\n        nativePath,\n        nativePathPrefixWbr: wbrPath(mountpointParent.join(sep) + sep),\n        pathElements,\n        nativePathSuffix: pathAfterMountpointParent.join(sep),\n        pathSep: sep,\n        exists: await this.exists()\n      }\n      this.logger().info(\"pathInfo()\", { result })\n      return result\n    } catch (err) {\n      this.logger().warn(\"pathInfo(): failed\", err)\n      return\n    }\n  }\n\n  async toApi(\n    previews: Previews,\n    shownSha?: string\n  ): PromiseMaybe<ApiAssetFile> {\n    return thenMap(this.pathInfo(), async pi =>\n      reqValuedOrElse({\n        assetId: this.assetId,\n        assetFileId: this.id,\n        ...pi,\n        mimetype: this.mimetype,\n        shown: isTrue(this.shown),\n        width: this.width,\n        height: this.height,\n        rotation: orElse(this.rotation, 0),\n        fileSize: this.fileSize,\n        mtime: this.mtime,\n        downloadables: await this.downloadables(previews, shownSha),\n        createdAtLocale: fmtMillis(this.createdAt!),\n        updatedAtLocale: fmtMillis(this.updatedAt!)\n      })\n    )\n  }\n\n  get isVideo(): boolean {\n    return isVideoMimeType(this.mimetype)\n  }\n}\n\nfunction fmtMillis(ms: Maybe<number>): Maybe<string> {\n  return map(ms, ea => fmtDuration(Date.now() - ea, 1) + \" ago\")\n}\n", "import { Tags } from \"exiftool-vendored\"\nimport { compact, includes } from \"../../fe/Array\"\nimport { blank } from \"../../fe/Blank\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { gte, toInt } from \"../../fe/Number\"\nimport { Valued } from \"../../fe/Object\"\nimport { toS } from \"../../fe/toS\"\nimport { allNotBlank } from \"../Array\"\nimport { AnyFilter, AsyncFilter } from \"../async/AsyncFilter\"\nimport { thenMapOr, thenNot } from \"../async/Promise\"\nimport { isHeifSupported } from \"../img/Heif\"\nimport { isHeifMimetype } from \"../img/HeifFilter\"\nimport { isVideoSupported } from \"../img/Video\"\nimport { isVideoMimeType } from \"../img/VideoFilter\"\nimport { mkLogger } from \"../Logger\"\nimport { within } from \"../Number\"\nimport { Settings } from \"../settings/Settings\"\nimport { extractDurationSec } from \"../tags/Duration\"\nimport { mimetype, readRawTags, sizeInfo } from \"../tags/ExifTags\"\nimport { isLibrawMimetype, isSharpMimetype } from \"../tags/Mimetypes\"\nimport { excludedPathFilter, exifExtFilter } from \"./BaseFileFilters\"\nimport { ignorablePath } from \"./Ignorable\"\nimport { hasNoMedia } from \"./NoMedia\"\nimport { PosixFile } from \"./PosixFile\"\nimport { SimpleFile } from \"./SimpleFile\"\n\nexport const onlyFiles = AsyncFilter.lift((file: PosixFile) => file.isFile())\n\nexport const onlyReadable = AsyncFilter.lift((item: PosixFile) => {\n  return item.isReadable()\n})\n\nfunction mkTagFilter(f: (tags: Tags) => boolean): AsyncFilter<PosixFile> {\n  return AsyncFilter.lift(async (file: PosixFile) =>\n    thenMapOr(readRawTags(file, false), f, () => false)\n  )\n}\n\nexport function requiredTagsFilter(\n  requiredExifTags: (keyof Tags)[]\n): AsyncFilter<PosixFile> {\n  return mkTagFilter((t: Tags) =>\n    allNotBlank(...requiredExifTags.map(ea => t[ea]))\n  )\n}\n\nexport const minDimensionsFilter = AsyncFilter.lift(async (f: PosixFile) => {\n  const m = await mimetype(f)\n  if (m == null || (!m.startsWith(\"image/\") && !m.startsWith(\"video/\")))\n    return false\n  const min = m.startsWith(\"video/\")\n    ? Settings.minVideoDimension.valueOrDefault\n    : Settings.minImageDimension.valueOrDefault\n  return thenMapOr(\n    sizeInfo(f),\n    dim => gte(dim.ImageWidth, min) && gte(dim.ImageHeight, min),\n    () => false\n  )\n})\n\nexport const minVideoDurationFilter = AsyncFilter.lift(async (f: PosixFile) => {\n  const m = await mimetype(f)\n  if (m == null) return false\n  if (!m.startsWith(\"video/\")) return true\n  const t = await readRawTags(f, false)\n  if (t == null) return false\n  return gte(extractDurationSec(t), Settings.minVideoDurationSec.valueOrDefault)\n})\n\nexport const hasMimeType = requiredTagsFilter([\"MIMEType\"])\nexport const hasMakeAndModel = requiredTagsFilter([\"Make\", \"Model\"])\n\n// A rating of -1 is considered \"rejected\"\nexport const notRejected = mkTagFilter(\n  (t: Tags) => toInt(t.Rating, { defaultValue: 0 })! >= 0\n)\n\nexport const hasBrowserImgMimetype = mkTagFilter((t: Tags) =>\n  includes([\"image/jpeg\", \"image/png\"], toS(t.MIMEType))\n)\n\nexport const imageFilter = mkTagFilter((t: Tags) => {\n  return toS(t.MIMEType).startsWith(\"image/\")\n})\n\nexport const videoFilter = mkTagFilter((t: Tags) => {\n  return toS(t.MIMEType).startsWith(\"video/\")\n})\n\nconst imageHasMakeAndModel = imageFilter.and(hasMakeAndModel).or(videoFilter)\n\nasync function supportedMimeType(mime: Maybe<string>) {\n  return (\n    !blank(mime) &&\n    (isSharpMimetype(mime) ||\n      isLibrawMimetype(mime) ||\n      (isVideoMimeType(mime) && (await isVideoSupported())) ||\n      (isHeifMimetype(mime) && (await isHeifSupported())))\n  )\n}\n\nexport const supportedMimeTypeFilter = AsyncFilter.lift(\n  async (file: SimpleFile) =>\n    thenMapOr(mimetype(file.nativePath), supportedMimeType, () => false)\n)\n\nexport const notHiddenCheap = AsyncFilter.lift(\n  async (file: SimpleFile) => !ignorablePath(file.nativePath)\n)\n\nexport const noMediaFilter = AsyncFilter.lift(async (file: SimpleFile) =>\n  thenNot(hasNoMedia(file))\n)\n\n// Skip over files that are < 50kb or > 1 gb, assuming that > 1 gb files are\n// downloaded movies. (1 gb is 10-20 minutes of FHD video, or > 5 minutes of\n// UHD video). kb = 1e3, mb = 1e6, gb = 1e9\n\n// If we're copying a file from a NAS to an external drive, we might be looking\n// at ~5-10mb/s. Transferring 1.5gb @ 5 mb/s is 5 minutes.\n\n// TODO: if we make asset import timeouts based on filesize, we can make this\n// limit much larger.\n\n// (Note that a 1600x1200 JPEG at 50% quality is ~150k, so 50k should be very\n// conservative.)\nexport const fileSizeFilter = AsyncFilter.lift(async (file: SimpleFile) =>\n  thenMapOr(\n    file.size(),\n    size =>\n      within(\n        Settings.minAssetFileSizeBytes.valueOrDefault,\n        Settings.maxAssetFileSizeBytes.valueOrDefault,\n        size\n      ),\n    () => false\n  )\n)\n\nexport const noStatFileFilter = AsyncFilter.andLogged<SimpleFile>(\n  mkLogger(\"fileFilterNoStat\"),\n  { exifExtFilter },\n  { notHiddenCheap }\n)\n\nexport const cheapFileFilter = AsyncFilter.andLogged<SimpleFile>(\n  mkLogger(\"fileFilterCheap\"),\n  { exifExtFilter },\n  { notHiddenCheap },\n  { noMediaFilter },\n  { fileSizeFilter }\n)\n\nexport const expensiveFileFilters = lazy<Valued<AnyFilter<PosixFile>>[]>(\n  () =>\n    compact([\n      { exifExtFilter }, // don't even bother if the suffix is not promising\n      { fileSizeFilter },\n      { notHiddenCheap },\n      { noMediaFilter },\n      { hasMimeType },\n      { supportedMimeTypeFilter },\n      Settings.requireMakeModel.valueOrDefault\n        ? { imageHasMakeAndModel }\n        : undefined,\n      { notRejected },\n      { minDimensionsFilter },\n      Settings.minVideoDurationSec.valueOrDefault > 0\n        ? { minVideoDurationFilter }\n        : undefined\n    ]) as any\n)\n\nexport const expensiveFileFilter = lazy(() =>\n  AsyncFilter.andLogged(\n    mkLogger(\"fileFilterExpensive\"),\n    ...expensiveFileFilters()\n  )\n)\n\nexport const extless = AsyncFilter.lift(async (file: PosixFile) =>\n  blank(file.ext)\n)\n\nexport const onlyDirectories = AsyncFilter.lift(async (file: PosixFile) =>\n  file.isDirectory()\n)\n\nexport function excludeDirnameFilter(excludedNames: string[]) {\n  return AsyncFilter.and(\n    excludedPathFilter<PosixFile>(excludedNames),\n    onlyDirectories\n  )\n}\n", "import { Tags } from \"exiftool-vendored\"\nimport { ExposureSettings } from \"../../fe/api/ExposureSettings\"\nimport { notBlank } from \"../../fe/Blank\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { approximates, isNumber, toFixed } from \"../../fe/Number\"\nimport { mapFields } from \"../../fe/Object\"\nimport { firstDefinedThunk } from \"../../fe/Thunk\"\nimport { toS } from \"../../fe/toS\"\nimport { geohash } from \"../GeoHash\"\nimport { extractFloat, extractFraction } from \"../Number\"\nimport { Pojo } from \"../Object\"\nimport { Settings } from \"../settings/Settings\"\nimport { extractLensMakeModel } from \"./LensMakeModel\"\n\nexport const zeroesRe = /^[\\s0]*$/\n\n/**\n * Ignore values that are blank or like \"000000000000\":\n */\nfunction zeroish(o: any) {\n  return o == null || isNumber(o) ? o === 0 : zeroesRe.exec(toS(o)) != null\n}\n\nexport function compactZeroes<T extends Pojo>(o: T) {\n  return mapFields(o, (k, v) => (zeroish(v) ? undefined : [k, v]))\n}\n\nexport function present(o: any) {\n  return o != null && notBlank(o) && !zeroish(o)\n}\n\nfunction whyDefinedNotApproximate({\n  a,\n  b,\n  field,\n  desc,\n  parser\n}: {\n  a: Partial<ExposureSettings>\n  b: Partial<ExposureSettings>\n  field: keyof ExposureSettings\n  desc: string\n  parser: (a: any) => Maybe<number>\n}): Maybe<string> {\n  const i = parser(a[field])\n  const j = parser(b[field])\n  const ratioGte = Settings.minExposureSettingsCoeffPct.valueOrDefault / 100\n  return i == null || j == null || approximates(i, j, ratioGte)\n    ? undefined\n    : \"Different \" + desc + \": \" + a[field] + \" \u2260 \" + b[field]\n}\n\n/**\n * @return a message with a mismatch if both a and b have a defined field but\n * they don't match.\n */\nexport function whyExposureSettingsNotSimilar(\n  a: Maybe<Partial<ExposureSettings>>,\n  b: Maybe<Partial<ExposureSettings>>\n): Maybe<string> {\n  if (a == null || b == null) return\n  return firstDefinedThunk([\n    () =>\n      whyDefinedNotApproximate({\n        a,\n        b,\n        field: \"focalLength\",\n        desc: \"focal length\",\n        parser: extractFloat\n      }),\n    () =>\n      whyDefinedNotApproximate({\n        a,\n        b,\n        field: \"aperture\",\n        desc: \"aperture\",\n        parser: extractFloat\n      }),\n    () =>\n      whyDefinedNotApproximate({\n        a,\n        b,\n        field: \"shutterSpeed\",\n        desc: \"shutter speed\",\n        parser: extractFraction\n      }),\n    () =>\n      whyDefinedNotApproximate({\n        a,\n        b,\n        field: \"iso\",\n        desc: \"ISO\",\n        parser: extractFloat\n      })\n  ])\n}\n\nexport function firstTagWithName(\n  t: Tags,\n  tagNames: (keyof Tags)[]\n): Maybe<string> {\n  for (const ea of tagNames) {\n    const v = t[ea]\n    if (notBlank(v)) return ea + \":\" + toS(v).trim()\n  }\n  return\n}\n\nexport function cameraId(t: Tags): Maybe<string> {\n  return firstTagWithName(t, [\n    \"SerialNumber\",\n    \"CameraSerialNumber\",\n    \"BodySerialNumber\",\n    \"InternalSerialNumber\"\n  ])\n}\n\nexport function lensId(t: Tags) {\n  {\n    const id = firstTagWithName(t, [\"LensSerialNumber\", \"LensID\"])\n    if (id != null) return id\n  }\n  return map(\n    extractLensMakeModel(t),\n    ({ lensMake, lensModel }) =>\n      `${lensMake.toLowerCase()}/${lensModel.toLowerCase()}`\n  )\n}\n\nexport function imageId(t: Tags): Maybe<string | number> {\n  return firstTagWithName(t, [\n    // DON'T: \"ImageUniqueID\", // set by picasa and lightroom. Frequently different for the same image.\n    \"BurstUUID\", // these seem to be really long, like type 4 UUIDs.\n    \"ImageNumber\", // these don't seem to ever be > 100000\n    \"ShutterCount\",\n    \"RunTimeValue\"\n  ])\n}\n\nexport function uidGeoHash(\n  lat: Maybe<number>,\n  lon: Maybe<number>\n): Maybe<string> {\n  // Note that 52 bits gives ~.5m resolution. Unfortunately, some cameras (like\n  // Google Pixels) will add slightly different GPS values to JPG/RAW pairs, so we\n  // downsample the geohash here.\n\n  // https://en.wikipedia.org/wiki/Decimal_degrees says 4 decimals get me to ~10m.\n  // Good enough.\n  return geohash(toFixed(lat, 4), toFixed(lon, 4))\n}\n", "import { compact, isEmpty } from \"./Array\"\nimport { dayMs, hourMs, minuteMs, secondMs, weekMs, yearMs } from \"./Date\"\nimport { mapOr } from \"./Maybe\"\nimport { gte0, isNumber } from \"./Number\"\nimport { plur } from \"./Units\"\n\nconst Units = [\n  { ms: yearMs, s: \"year\", p: \"years\" },\n  { ms: 30.4 * dayMs, s: \"month\", p: \"months\" },\n  { ms: weekMs, s: \"week\", p: \"weeks\" },\n  { ms: dayMs, s: \"day\", p: \"days\" },\n  { ms: hourMs, s: \"hour\", p: \"hours\" },\n  { ms: minuteMs, s: \"minute\", p: \"minutes\" },\n  { ms: secondMs, s: \"second\", p: \"seconds\" }\n]\n\nexport function fmtDuration(\n  ms: number,\n  units: number = 2,\n  suffix?: { singular: string; plural: string }\n): string {\n  if (!gte0(ms)) {\n    return !isNumber(ms) ? \"\" : \"-\" + fmtDuration(Math.abs(ms), units)\n  }\n  const largestUnitIndex = Units.findIndex(ea => ea.ms <= ms)\n  if (largestUnitIndex === -1) return \"\"\n  let remaining = ms\n  const result = compact(\n    Units.slice(largestUnitIndex, largestUnitIndex + units).map(unit => {\n      if (unit.ms > remaining) {\n        return\n      } else {\n        const i = Math.floor(remaining / unit.ms)\n        remaining -= i * unit.ms\n        return { i, s: plur(i, unit.s, unit.p) }\n      }\n    })\n  )\n  if (isEmpty(result)) return \"\"\n  return (\n    result.map(ea => ea.s).join(\", \") +\n    mapOr(\n      suffix,\n      ea => \" \" + (result[result.length - 1].i !== 1 ? ea.singular : ea.plural),\n      \"\"\n    )\n  )\n}\n", "import { mkLogger } from \"../../core/Logger\"\nimport { toURI, URI } from \"../../core/uri/URI\"\nimport { TagPath, TagRoots } from \"../../fe/api/Tag\"\nimport { compactBlanks } from \"../../fe/Array\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { PS_LIBRARY_PROTOCOL } from \"../../fe/URI\"\nimport { Asset } from \"../model/Asset\"\nimport { AssetFile } from \"../model/AssetFile\"\nimport { Library } from \"./Taggers\"\n\nconst logger = lazy(() => mkLogger(\"FilePathTagger\"))\n\nexport function tagAssetPaths(uris: string[]): TagPath[] {\n  const result: TagPath[] = []\n  for (const uri of uris) {\n    try {\n      result.push(uriToTagPath(uri))\n    } catch (err) {\n      logger().warn(\"Failed to parse asset file URI\", { uri })\n    }\n  }\n  return result\n}\n\nexport function uriToTagPath(u: URI | string): TagPath {\n  const uri = toURI(u)\n  const authority = uri.scheme === PS_LIBRARY_PROTOCOL ? Library : uri.authority\n  // don't include the pathname:\n  const path = uri.path.split(\"/\").slice(0, -1)\n  return compactBlanks([TagRoots.FS, authority, ...path])\n}\n\nexport async function addFilesTagsToAsset(assetId: number) {\n  return AssetFile.tx(async () => {\n    const uris = await AssetFile.dbl.pluckAllf<string>(q =>\n      q.select(\"uri\").where({ assetId })\n    )\n    return addFileUriTagsToAsset(assetId, uris)\n  })\n}\n\nexport async function addFileUriTagsToAsset(assetId: number, uris: string[]) {\n  return Asset.addTags(assetId, uris.map(uriToTagPath))\n}\n", "import { time } from \"../../core/async/PromiseTimer\"\nimport { thenElapsed } from \"../../core/Elapsed\"\nimport { mkLogger } from \"../../core/Logger\"\nimport { isProd, start } from \"../../core/NodeEnv\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { volsha } from \"../../core/uri/psfile\"\nimport { volumes } from \"../../core/volumes/Volumes\"\nimport { TagRoots } from \"../../fe/api/Tag\"\nimport { isEmpty, range } from \"../../fe/Array\"\nimport { notBlank, notBlankOr } from \"../../fe/Blank\"\nimport { minuteMs, secondMs } from \"../../fe/Date\"\nimport { eql } from \"../../fe/Eql\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { clamp } from \"../../fe/Number\"\nimport { randomChars } from \"../../fe/Random\"\nimport { Library } from \"../curators/Taggers\"\nimport { DbRequest } from \"../db/DbRequest\"\nimport { knex } from \"../db/Knex\"\nimport { prepQueries } from \"../db/SqlQuery\"\nimport { AssetFile } from \"./AssetFile\"\nimport { modelDb } from \"./ModelDb\"\nimport { Tag } from \"./Tag\"\n\nconst logger = lazy(() => mkLogger(\"TagSql\"))\n\nlet lastMax: number\n\nconst dbr = lazy(() => new DbRequest(modelDb, \"Tag\"))\n\nexport const runTagMaintenance = lazy(async () => {\n  if (isProd && Date.now() - start < 20 * secondMs) return // don't wait for this to finish just to start!\n  await updateTagMountpoints()\n\n  const newMax = await dbr().pluckFirst<number>({\n    sql: \"SELECT MAX(rowid) FROM AssetTag\"\n  })\n  logger().info(\"updateTagCounts()\", { newMax, lastMax })\n  if (newMax === lastMax) return\n  lastMax = newMax\n  await time(\"db.updateTagCounts\", () => updateTagCounts())\n}, 7 * secondMs)\n\nexport function updateTagCountSql(rnd = randomChars(6)) {\n  // closure tree table\n  const ct = `temp.ct_${rnd}`\n  // tag asset file table\n  const taf = `temp.taf_${rnd}`\n  // tag counts table\n  const tc = `temp.tag_counts_${rnd}`\n\n  return prepQueries(`\nCREATE TABLE ${ct} AS\nSELECT\n  DISTINCT t.id AS parentId,\n  kid.id AS childId\nFROM\n  Tag t\n  JOIN Tag kid ON kid._path LIKE (t._path || '%');\n\nCREATE INDEX ${ct}_idx ON ${ct.replace(/^temp\\./, \"\")}(parentId, childId);\n\nCREATE TABLE ${taf} AS\nSELECT\n  DISTINCT AssetTag.tagId as tagId,\n  Asset.id AS assetId,\n  AssetFile.id AS assetFileId\nFROM\n  AssetTag\n  JOIN Asset ON AssetTag.assetId = Asset.id\n  JOIN AssetFile ON AssetFile.assetId = Asset.id\nWHERE\n  Asset.hidden = 0\n  AND Asset.excluded = 0\n  AND Asset.shown = 1;\n\nCREATE INDEX ${taf}_idx ON ${taf.replace(\n    /^temp\\./,\n    \"\"\n  )}(tagId, assetId, assetFileId);\n\nCREATE TABLE ${tc} AS\nSELECT\n  parentId AS tagId,\n  count(DISTINCT assetId) AS ac,\n  count(DISTINCT assetFileId) AS afc\nFROM\n  ${ct}\n  JOIN ${taf} ON childId = tagId\nGROUP BY\n  1;\n\nCREATE INDEX ${tc}_idx ON ${tc.replace(/^temp\\./, \"\")}(tagId, ac, afc);\n\n-- Update used tags:\n\nUPDATE Tag SET \n  assetCount = NULL,\n  assetFileCount = NULL;\n\nUPDATE Tag\nSET\n  assetCount = ac,\n  assetFileCount = afc\nFROM ${tc}\nWHERE tagId = id;\n\n-- Clean up:\n\nDROP INDEX IF EXISTS ${ct}_idx;\nDROP INDEX IF EXISTS ${taf}_idx;\nDROP INDEX IF EXISTS ${tc}_idx;\nDROP TABLE ${ct};\nDROP TABLE ${taf};\nDROP TABLE ${tc};\n`)\n}\n\nasync function updateTagCounts() {\n  if (dbr().db() == null)\n    logger().throw(\"updateTagCounts(): modelDb is unset\", { retriable: false })\n\n  try {\n    const rnd = randomChars(6)\n    const ignorable = \"_\" + rnd\n    const r = await thenElapsed(\n      dbr().runScript(updateTagCountSql(rnd), ignorable)\n    )\n    const newTTL = clamp(7 * secondMs, 5 * minuteMs, r.elapsedMs * 20)\n    logger().info(\"Updated tag counts\", { elapsedMs: r.elapsedMs, newTTL })\n    runTagMaintenance.setTTL(newTTL)\n    await vacuumOrphanTags()\n  } catch (err) {\n    logger().warn(\"Failed to update tag counts\", err)\n  }\n}\n\nasync function vacuumOrphanTags(minCreatedAt = Date.now() - 10 * minuteMs) {\n  let prior = [-1]\n  for (const _ of range(0, 5)) {\n    const curr = await vacuumLeafTags(minCreatedAt)\n    if (isEmpty(curr) || eql(prior, curr)) return\n    prior = curr\n  }\n}\n\nasync function vacuumLeafTags(minCreatedAt: number) {\n  const candidates = await Tag.dbl.pluckAllf<number>(\n    q =>\n      q\n        .select(\"Tag.id\")\n        .leftOuterJoin(\"AssetTag\", \"AssetTag.tagId\", \"Tag.id\")\n        .leftOuterJoin(knex.raw(\"Tag AS child ON child.parentId = Tag.id\"))\n        .whereNull(\"AssetTag.assetId\")\n        .andWhere(q2 => q2.whereNull(\"child.id\"))\n        .andWhere(q2 => q2.whereNull(\"Tag.assetCount\"))\n        .andWhere(\"Tag.createdAt\", \"<\", minCreatedAt)\n        .orderBy(\"Tag._path\", \"asc\") // leaves first\n  )\n  logger().debug(\"vacuumLeafTags()\", { candidates })\n  for (const ea of candidates) {\n    try {\n      await Tag.dbl.runf(q => q.where({ id: ea }).delete())\n    } catch (err) {\n      logger().info(\"vacuumLeafTags(): failed to delete\", { tagId: ea, err })\n    }\n  }\n  logger().info(\"vacuumLeafTags() complete.\", { candidates })\n  return candidates\n}\n\nexport async function updateTagMountpoints() {\n  const log = mkLogger(\"updateTagMountpoints()\")\n  const fileRoot = await Tag.findByPath([TagRoots.FS])\n  if (fileRoot == null) {\n    log.info(\"No root filesystem tag\")\n    return\n  }\n\n  await fileRoot.maybeUpsertDisplayName(\n    Settings.tagDisplayNameFS.valueOrDefault\n  )\n\n  const vols = await volumes()\n  if (vols == null) {\n    log.warn(\"no-op: volumes() returned null\")\n    return\n  }\n\n  for (const t of await fileRoot.getChildren()) {\n    if (t.name === Library) {\n      if (t.ordinal !== 1) await t.upsert({ ordinal: 1 })\n      continue\n    }\n\n    let displayName\n    const v = vols.find(ea => notBlank(ea.uuid) && volsha(ea.uuid) === t.name)\n    if (v != null) {\n      displayName = notBlankOr(v.label, v.mountpoint)\n    } else {\n      displayName = await AssetFile.dbl.pluckFirstf<string>(q =>\n        q\n          .select(\"mountpoint\")\n          .where(\"uri\", \"LIKE\", \"psfile://\" + t.name + \"/%\")\n          .limit(1)\n      )\n    }\n    if (displayName != null) {\n      await t.maybeUpsertDisplayName(displayName)\n      log.info(\"updated tag\", { id: t.id, path: t.path, displayName })\n      Tag.clear()\n    } else {\n      log.debug(\"cannot update tag: no current volume.\", {\n        id: t.id,\n        path: t.path\n      })\n    }\n  }\n}\n", "import { Deferred } from \"../../core/async/Deferred\"\nimport { addDbEndable, Endable, ending } from \"../../core/async/Endable\"\nimport { Later } from \"../../core/async/Later\"\nimport { thenMap } from \"../../core/async/Promise\"\nimport { BaseFile } from \"../../core/fs/BaseFile\"\nimport { PosixFile } from \"../../core/fs/PosixFile\"\nimport { Logger, mkLogger } from \"../../core/Logger\"\nimport { isTest } from \"../../core/NodeEnv\"\nimport { isMainService } from \"../../core/ServiceNames\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { volumeFor } from \"../../core/volumes/Volumes\"\nimport { minuteMs } from \"../../fe/Date\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { Db } from \"../db/Db\"\nimport { DbBackup } from \"../db/DbBackup\"\nimport { pathToDb } from \"../db/DbPath\"\nimport { tx } from \"../db/Transactions\"\nimport { localDbDir as localDbDirImpl } from \"../LocalDbDir\"\nimport { statsDbDir } from \"../StatsDbDir\"\nimport { AdvisoryLock } from \"./AdvisoryLock\"\nimport { normalizeDateTags } from \"./DateTagNormalizer\"\nimport { modelDb, setModelDb } from \"./ModelDb\"\nimport { Progress } from \"./Progress\"\nimport { runTagMaintenance } from \"./TagSql\"\n\n// DO NOT REQUIRE ANY MODELS HERE (no circular deps, plz!) (well, except\n// Advisory Lock? And... Progress?)\n\n/**\n * Responsible for setting up the db, janitorial services, and backup service\n */\nexport class ModelDbJanitor implements Endable {\n  private readonly logger: Logger\n  readonly name: string\n  readonly endTimeoutMs = minuteMs // this should be *really* pessimistic.\n\n  readonly db: Deferred<Db>\n  readonly srcDbFile: BaseFile\n  localDbReplica: Maybe<BaseFile>\n  readonly backupDir: BaseFile\n  /**\n   * Only set if this process owns the model lock (this.backupAndMigrate()\n   * returns true)\n   */\n  readonly backup: Deferred<Maybe<DbBackup>>\n\n  static async for(\n    dataDir: PosixFile,\n    isLockOwner: Later<boolean>,\n    localDbDir: Later<PosixFile> = localDbDirImpl\n  ) {\n    const ea = new ModelDbJanitor(dataDir, isLockOwner, localDbDir)\n    await ea.setup()\n    return ea\n  }\n\n  private constructor(\n    readonly dataDir: PosixFile,\n    readonly isLockOwner: Later<boolean>,\n    private readonly localDbDir: Later<PosixFile>\n  ) {\n    this.name = \"ModelDbJanitor(\" + dataDir + \")\"\n    this.logger = mkLogger(this.name)\n    this.db = new Deferred(this.name + \".db\")\n    this.backup = new Deferred(this.name + \".backup\")\n    this.srcDbFile = pathToDb(this.dataDir, \"models\")\n    this.backupDir = this.srcDbFile.parent().join(\"backup\")\n    addDbEndable(this)\n    void this.setup()\n  }\n\n  get ended() {\n    return this.end.prior() != null\n  }\n\n  // Used for switching library paths and by integration tests.\n  readonly end = lazy(() => map(this.backup.value, ea => ea.end()))\n\n  readonly setup = lazy(async () => {\n    try {\n      await this._setup()\n      this.logger.info(\"ModelDb reading from \" + this.db.value?.dbfile)\n    } catch (err) {\n      this.db.reject(err)\n      this.backup.reject(err)\n      // Propagate the error to prevent startup:\n      this.logger.throw(err, {\n        fatal: true,\n        from: \"ModelDbJanitor.setup\"\n      })\n    }\n  })\n\n  /**\n   * Called only after all migrations have been applied:\n   */\n  private readonly beforeBackup = async () => {\n    if (ending()) return\n\n    if (!isTest && isMainService()) {\n      await tx(modelDb(), async () => {\n        await AdvisoryLock.vacuum()\n        await Progress.vacuum()\n        await runTagMaintenance()\n        // TODO: clean up deletable assets, tags, asset files, and file shas\n      })\n    } else {\n      // we're the web and we're just testing the library to see that it can be\n      // opened. We see db-is-closed issues when this is run by the webservice.\n    }\n  }\n\n  private readonly onBackupFinished = async () => {\n    if (ending()) return\n  }\n\n  private readonly onMigration = lazy(async () => {\n    this.logger.info(\n      \"onMigration: removing prior stats db to clear prior work queues\"\n    )\n    const createIfMissing = false\n    await thenMap(statsDbDir(createIfMissing), ea => ea.rmrf(\"info\"))\n  })\n\n  // This is a fat arrow to pass into DbBackup\n  private readonly backupAndMigrate = async () =>\n    isMainService() || (await this.isLockOwner())\n\n  private async _setup() {\n    // We need to wait for the lock, or db can't run migrations.\n\n    // Always run from a local primary if library is remote:\n\n    const useLocalDbReplica =\n      Settings.forceLocalDbReplica.valueOrDefault ||\n      true ===\n        (await thenMap(volumeFor(this.srcDbFile.nativePath), vol => vol.remote))\n\n    if (useLocalDbReplica) {\n      const localDataDir = await this.localDbDir()\n      this.localDbReplica = pathToDb(localDataDir, \"models\")\n      this.logger.info(\"Library on remote drive. Using local db replica.\", {\n        src: this.srcDbFile.nativePath,\n        local: this.localDbReplica\n      })\n      // Don't overwrite the db unless we're the primary lock owner!\n      if (await this.backupAndMigrate()) {\n        this.logger.info(\"Setting up local model db replica....\")\n\n        // Remove the prior library, if any exists:\n        await this.localDbReplica.parent().rmrf(\"info\")\n\n        // Don't bother copying if we're just getting started:\n        if (await this.srcDbFile.clear().exists()) {\n          // We only copy the db, not the .WAL file, to avoid corruption due to\n          // half-written databases.\n          await this.srcDbFile.copyFile_(this.localDbReplica)\n          await this.localDbReplica.chmod(0o644)\n        }\n        this.logger.info(\n          \"Local model db replica set up at \" + this.localDbReplica\n        )\n      }\n      return this._finishSetup(localDataDir, this.srcDbFile.parent())\n    } else {\n      return this._finishSetup(this.dataDir)\n    }\n  }\n\n  /**\n   * @param primaryDbDir is where we read and write to.\n   * @param replaceDbDir if set, is the actual library data directory. This is\n   * only set if the library is on a remote drive.\n   */\n  private async _finishSetup(primaryDbDir: BaseFile, replaceDbDir?: BaseFile) {\n    const backupDir = await this.backupDir.mkdirp()\n    if (backupDir == null) {\n      throw new Error(\"Failed to create models DB backup dir \" + this.backupDir)\n    }\n    const db = new Db(\"models\", primaryDbDir, this.onMigration)\n    const backupAndMigrate = await this.backupAndMigrate()\n    if (backupAndMigrate) {\n      await db.migrate()\n      this.backup.resolve(\n        new DbBackup(\n          db,\n          this.backupAndMigrate,\n          db.dbfile!,\n          backupDir,\n          replaceDbDir,\n          this.beforeBackup,\n          this.onBackupFinished\n        )\n      )\n    } else {\n      this.backup.resolve(undefined)\n    }\n\n    setModelDb(db)\n    this.db.resolve(db)\n\n    if (backupAndMigrate) {\n      await normalizeDateTags()\n      await runTagMaintenance()\n    }\n\n    this.logger.info(\"Finished setup\", {\n      primaryDbDir,\n      replaceDbDir,\n      backupDir\n    })\n    return\n  }\n}\n", "import { isRpcClient } from \"../../core/ServiceNames\"\nimport { setRpcMountpointsImpl } from \"../../core/volumes/Mountpoints\"\nimport { setRpcVolumesImpl } from \"../../core/volumes/Volumes\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map } from \"../../fe/Maybe\"\nimport { rpcClient, rpcClientReady } from \"./RpcClient\"\n\nexport const setupVolumeRpc = lazy(() => {\n  setRpcMountpointsImpl(isRpcClient() ? rpcMountpoints : undefined)\n  setRpcVolumesImpl(isRpcClient() ? rpcVolumes : undefined)\n})\n\nconst rpcMountpoints = async () => {\n  return (await rpcClientReady())\n    ? map(rpcClient(), ea => ea.request(\"mountpoints\"))\n    : undefined\n}\n\nconst rpcVolumes = async () => {\n  return (await rpcClientReady())\n    ? map(rpcClient(), ea => ea.request(\"volumes\"))\n    : undefined\n}\n", "import { Db } from \"../db/Db\"\n\nlet db: Db\n\nexport function statsDb() {\n  return db\n}\n\nexport function setStatsDb(newDb: Db) {\n  db = newDb\n}\n", "import { EndableRanks } from \"../../core/async/Endable\"\nimport { EndableInterval } from \"../../core/async/EndableInterval\"\nimport { PosixFile } from \"../../core/fs/PosixFile\"\nimport { isTest } from \"../../core/NodeEnv\"\nimport { isStatsDbMigrator } from \"../../core/ServiceNames\"\nimport { minuteMs, secondMs } from \"../../fe/Date\"\nimport { Db } from \"../db/Db\"\nimport { setStatsDb } from \"./StatsDb\"\n\nexport async function statsDbJanitor(dbDir: PosixFile) {\n  const db = new Db(\"stats\", dbDir)\n  // stats are only opened by sync:\n  if (isStatsDbMigrator()) {\n    await db.migrate()\n    new EndableInterval({\n      name: \"statsDbJanitor vacuum\",\n      callback: () => db.vacuum(),\n      intervalMs: isTest ? 20 * secondMs : 5 * minuteMs,\n      rank: EndableRanks.service\n    })\n  }\n  setStatsDb(db)\n  return db\n}\n", "import { filter } from \"../../core/async/Predicate\"\nimport { emitFileChanged } from \"../../core/event/EventEmitter\"\nimport { PosixFile } from \"../../core/fs/PosixFile\"\nimport { FuzzyDate, toFuzzyDate } from \"../../core/date/FuzzyDate\"\nimport { l } from \"../../core/licensing/Licensing\"\nimport { Logger, mkLogger } from \"../../core/Logger\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { readTags, sidecarEql } from \"../../core/tags/ExifTags\"\nimport { isNotEmpty } from \"../../fe/Array\"\nimport { map, orElse } from \"../../fe/Maybe\"\n\nexport function directoryForDate(d: FuzzyDate): string[] {\n  return d\n    .toDateTime()\n    .toFormat(Settings.assetSubdirectoryDatestampFormat.valueOrDefault)\n    .split(\"/\")\n}\n\n/**\n * Stores all found asset files in date-prefixed folder hierarchies.\n */\nexport class AssetFileRepository {\n  private readonly logger: Logger = mkLogger(\"AssetFileRepository\")\n\n  constructor(readonly root: PosixFile, readonly copyAssets: () => boolean) {}\n\n  directoryForDate(d: FuzzyDate): PosixFile {\n    return this.root.join(...directoryForDate(d))\n  }\n\n  /**\n   * @throws if there are any errors\n   */\n  async importFile(file: PosixFile): Promise<PosixFile> {\n    const copyAssets = this.copyAssets()\n    this.logger.debug(\"importFile()\", { file, copyAssets })\n\n    if (!copyAssets || (await l())) return file\n\n    if (await file.isDescendantOf(this.root)) {\n      this.logger.debug(\"no-op: \" + file + \" already contained by \" + this.root)\n      // And we don't need to worry about the sidecar, either.\n      return file\n    }\n\n    this.logger.debug(\"importing \" + file)\n\n    const t = await readTags(file)\n    if (t == null) {\n      throw new Error(file.nativePath + \" has no tags (so, no createdAt)\")\n    }\n    const d = map(t.capturedAt, ea => toFuzzyDate(ea.date))\n    if (d == null) {\n      throw new Error(file.nativePath + \" has no capturedAt\")\n    }\n    if (d.year == null || d.month == null || d.day == null) {\n      this.logger.warn(\n        \"Insufficient capturedAt precision to copy \" + file + \" into library.\",\n        {\n          capturedAt: t.capturedAt\n        }\n      )\n      return file\n    }\n    // Does a file in that subdirectory already have the same filesize and SHA?\n    const destParent = this.directoryForDate(d)\n    if ((await destParent.mkdirp()) == null) {\n      throw new Error(\n        \"Cannot create destination directory, \" +\n          destParent.nativePath +\n          \" for \" +\n          file.nativePath\n      )\n    }\n    const children = await destParent.children()\n    const thisSize = await file.size()\n\n    const editsWithSameSize = await filter(children, sibling =>\n      sibling.size().then(size => size === thisSize)\n    )\n    const thisSha = await file.sha()\n    if (editsWithSameSize.length > 0) {\n      const editsWithSameSha = await filter(editsWithSameSize, sibling =>\n        sibling.sha().then(sha => sha === thisSha)\n      )\n      if (editsWithSameSha.length > 0) {\n        const same = editsWithSameSha[0]!\n        this.logger.info(file + \" matches \" + same)\n        return this.handleSidecars(file, same)\n      }\n    }\n    const dest = await destParent.join(file.base).ensureNew_()\n    this.logger.info(\"Copying...\", {\n      src: file.nativePath,\n      dest: dest.nativePath\n    })\n    await file.copyFile_(dest)\n    return this.handleSidecars(file, dest)\n  }\n\n  private async handleSidecars(\n    src: PosixFile,\n    dest: PosixFile\n  ): Promise<PosixFile> {\n    const sidecars = orElse(await src.sidecars(), [])\n    for (const srcSidecar of sidecars) {\n      await this.handleSidecar(srcSidecar, dest)\n    }\n    // The sidecar might have metadata we should use:\n    if (isNotEmpty(sidecars)) emitFileChanged(dest.nativePath)\n    return dest\n  }\n\n  private async handleSidecar(srcSidecar: PosixFile, dest: PosixFile) {\n    for (const destSidecar of orElse(await dest.sidecars(), [])) {\n      if (await sidecarEql(srcSidecar, destSidecar)) {\n        this.logger.info(\"handleSidecar(): metadata already exists.\", {\n          srcSidecar,\n          destSidecar,\n          dest\n        })\n        // TODO: touch to the same mtime?\n        return\n      }\n    }\n    const copyTo = await dest\n      .parent()\n      .join(dest.name + srcSidecar.ext)\n      .ensureNew_({ emptyIsNew: true })\n    return srcSidecar.copyFile_(copyTo)\n  }\n}\n", "import { end, Endable, EndableRanks, ending } from \"../core/async/Endable\"\nimport { EndableWrapper } from \"../core/async/EndableWrapper\"\nimport { thenMap } from \"../core/async/Promise\"\nimport { cacheDir } from \"../core/CacheDir\"\nimport { onError } from \"../core/error/Error\"\nimport { DoNotSendErrorFlag, FatalErrorFlag } from \"../core/error/ErrorTypes\"\nimport { BaseFile } from \"../core/fs/BaseFile\"\nimport { nativePathIsReadableDirectory, resolve } from \"../core/fs/Path\"\nimport { PosixFile } from \"../core/fs/PosixFile\"\nimport { imgCacheDir } from \"../core/img/ImgCache\"\nimport { Previews } from \"../core/img/Previews\"\nimport { setBroadcasterIfUnset } from \"../core/rpc/Broadcaster\"\nimport {\n  isRpcClient,\n  isStatsDbClient,\n  isWebService,\n  isWelcomeService,\n  serviceName\n} from \"../core/ServiceNames\"\nimport {\n  libraryDataDir,\n  libraryOriginalsDir,\n  setupLibraryDataDir\n} from \"../core/settings/LibraryDirs\"\nimport { Settings } from \"../core/settings/Settings\"\nimport {\n  libraryHasSettings,\n  readLibrarySettings\n} from \"../core/settings/SettingsIO\"\nimport { CmdTimeoutMs } from \"../core/volumes/VolumeTtls\"\nimport { mapNotBlank } from \"../fe/Blank\"\nimport { isTrue } from \"../fe/Boolean\"\nimport { minuteMs } from \"../fe/Date\"\nimport { Latch } from \"../fe/Latch\"\nimport { lazy } from \"../fe/Lazy\"\nimport { map } from \"../fe/Maybe\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { tap } from \"../fe/Object\"\nimport { BroadcasterImpl } from \"./BroadcasterImpl\"\nimport { checkRemoteVacuuming } from \"./db/Vacuum\"\nimport { DescribedFile } from \"./DescribedFile\"\nimport { DbAdvisoryLockProvider } from \"./model/AdvisoryLock\"\nimport { ModelDbJanitor } from \"./model/ModelDbJanitor\"\nimport { OpenedByIO } from \"./OpenedBy\"\nimport { rpcClientReady } from \"./rpc/RpcClient\"\nimport { setupVolumeRpc } from \"./rpc/RpcSetup\"\nimport { statsDbJanitor } from \"./stats/StatsDbJanitor\"\nimport { statsDbDir } from \"./StatsDbDir\"\nimport { AssetFileRepository } from \"./sync-file/AssetFileRepository\"\n\n// DON'T DO THIS! LibrarySettings will take care of this.\n// Settings.libraryPath.addListener(() => Library.onLibraryPathChange())\n\n/**\n * Given a library root directory, provides paths and factory methods for\n * library services, like the SeenFileFilter, Previews, and database setup.\n *\n * Note that a given process only supports a single library, so this should\n * be a singleton. Most likely the singleton will be managed by a singleton\n * instance of `Service`.\n */\nexport class Library extends EndableWrapper implements Endable {\n  readonly start = Date.now()\n  static priorInstance: Maybe<Library>\n\n  static libraryPathChanged() {\n    const currentLibraryPath = map(Settings.libraryPath.value, resolve)\n    const priorLibraryPath = map(\n      this.priorInstance,\n      ea => ea.rootDir.nativePath\n    )\n    return currentLibraryPath !== priorLibraryPath\n  }\n\n  // This must not be async to ensure only one instance is currently live:\n  static instance() {\n    const pathChanged = this.libraryPathChanged()\n    const priorLibraryEnded = isTrue(this.priorInstance?.ended)\n    let priorEnd: Maybe<Promise<any>>\n    if (pathChanged || priorLibraryEnded) {\n      // don't wait for the end:\n      priorEnd = end(this.priorInstance, minuteMs)\n      this.priorInstance = undefined\n    }\n    if (this.priorInstance == null && libraryHasSettings()) {\n      this.priorInstance = mapNotBlank(Settings.libraryPath.value, path =>\n        tap(new Library(path), async ea => {\n          await priorEnd // < make sure RPC is shut down before we start the next\n          return ea.setup()\n        })\n      )\n    }\n    return this.priorInstance\n  }\n\n  static instanceRequired() {\n    const l = Library.instance()\n    if (l == null) {\n      throw new Error(\"Library is undefined\" + FatalErrorFlag)\n    } else {\n      return l\n    }\n  }\n\n  private readonly _ready = new Latch()\n  readonly rootDir: PosixFile\n  readonly dataDir: PosixFile\n\n  private constructor(rootDir: string | BaseFile) {\n    super(`Library(${rootDir})`, () => this.onEnd(), EndableRanks.predb)\n    this.rootDir = PosixFile.for(rootDir)\n    this.dataDir = libraryDataDir(this.rootDir)!\n    this.logger.info(\"new()\")\n  }\n\n  get isPendingSetup() {\n    return this._ready.pending\n  }\n\n  // Called by Library.instance() to allow new Library() to be called by tests\n  // without causing side effects:\n  private readonly setup = lazy(async () => {\n    const throwIfEnding = () => {\n      if (this.ended || ending()) throw new Error()\n    }\n    try {\n      this.logger.debug(\"setup() started\")\n\n      // THIS MUST BE BEFORE WE LOCK OR SET UP THE DB!\n      if (!libraryHasSettings()) {\n        if (!isWelcomeService()) {\n          throw new Error(\n            \"Cannot run \" +\n              serviceName() +\n              \" without a library\" +\n              FatalErrorFlag +\n              DoNotSendErrorFlag\n          )\n        }\n        this.logger.warn(\"Library settings don't exist yet. Skipping setup.\")\n        return\n      }\n\n      // THIS NEEDS TO BE FIRST. We don't want to do anything else if the\n      // library is locked.\n      await this.openedBy().throwIfUnavailable(\"(library setup)\")\n\n      throwIfEnding()\n\n      await setupLibraryDataDir(this.rootDir)\n      await readLibrarySettings(this.rootDir.nativePath)\n\n      const originalsDir = this.originalsDir()\n\n      if (\n        originalsDir == null ||\n        null == (await originalsDir.mkdirp()) ||\n        !(await originalsDir.isReadWritable())\n      ) {\n        throw new Error(\n          `Invalid value for ${Settings.originalsDir.key}: ${originalsDir} must be readable and writable.`\n        )\n      }\n\n      // Prevent health checks from initially failing by setting up all these\n      // directories in setup():\n\n      // these throw on error:\n      await this.statsDbDir()\n      await imgCacheDir()\n\n      throwIfEnding()\n\n      setBroadcasterIfUnset(BroadcasterImpl)\n\n      if (isRpcClient()) {\n        if (await rpcClientReady()) {\n          await checkRemoteVacuuming() // make sure our db vacuuming state is in sync\n          setupVolumeRpc() // this toggles between client and server.\n        }\n      }\n\n      throwIfEnding()\n\n      await this.modelDb()\n\n      throwIfEnding()\n\n      if (isStatsDbClient()) {\n        await this.statsDb()\n      }\n    } catch (err) {\n      if (!this.ended && !ending()) {\n        onError(\n          \"Library.setup() failed\" + (isWebService() ? \"\" : FatalErrorFlag),\n          err\n        )\n        void this._ready.reject(err)\n      }\n    } finally {\n      if (this._ready.pending) {\n        this.logger.info(\"Library.setup() finished.\")\n        void this._ready.resolve()\n      }\n    }\n  })\n\n  get ready() {\n    return this._ready.promise\n  }\n\n  readonly openedBy = lazy(() => new OpenedByIO(this.dataDir))\n\n  readonly statsDbDir = lazy(() => statsDbDir())\n\n  readonly previews = lazy(\n    () =>\n      new Previews(\n        this.rootDir.join(Settings.previewsDir.valueOrDefault),\n        DbAdvisoryLockProvider\n      )\n  )\n\n  readonly originalsDir = lazy(() => libraryOriginalsDir(this.rootDir)!)\n\n  readonly assetFileRepository = lazy(() => {\n    return new AssetFileRepository(\n      this.originalsDir(),\n      () => Settings.copyAssetsToLibrary.valueOrDefault\n    )\n  })\n\n  readonly modelDbJanitor = lazy(async () =>\n    ModelDbJanitor.for(this.dataDir, () => this.openedBy().isLockOwner())\n  )\n  readonly modelDb = lazy(async () => (await this.modelDbJanitor()).db.promise)\n  readonly statsDb = lazy(async () => statsDbJanitor(await this.statsDbDir()))\n  readonly statsDbFile = lazy(() => this.statsDb().then(ea => ea.dbfile))\n\n  async requiredFiles(): Promise<DescribedFile[]> {\n    const arr: DescribedFile[] = []\n\n    if (await nativePathIsReadableDirectory(Settings.cacheDir.valueOrDefault)) {\n      arr.push({\n        desc: \"Cache directory\",\n        isDir: true,\n        file: () => cacheDir()\n      })\n    }\n\n    if (this._ready.resolved) {\n      arr.push(\n        { desc: \"Library directory\", isDir: true, file: () => this.rootDir },\n        {\n          desc: \"Library model DB\",\n          isDir: false,\n          file: () => thenMap(this.modelDbJanitor(), ea => ea.srcDbFile)\n        },\n        {\n          desc: \"Library model DB (local replica)\",\n          isDir: false,\n          file: () => thenMap(this.modelDbJanitor(), ea => ea.localDbReplica)\n        }\n      )\n    }\n    return arr\n  }\n\n  // Used when library path changes and by tests:\n  private readonly onEnd = lazy(async () => {\n    for (const { ea, t } of [\n      { ea: this.statsDb, t: CmdTimeoutMs },\n      { ea: this.modelDbJanitor, t: minuteMs },\n      { ea: this.openedBy, t: CmdTimeoutMs }\n    ]) {\n      await map(await ea.clear(), endable => end(endable, t))\n    }\n    this.logger.info(\"onEnd(): finished.\")\n  })\n}\n", "import { Knex } from \"knex\"\nimport {\n  filterAsync,\n  thenMap,\n  thenMapOr,\n  thenOrElse\n} from \"../../core/async/Promise\"\nimport { localToDateObject, localToTs } from \"../../core/date/Date\"\nimport { fmtDateShort } from \"../../core/date/ExtendedDate\"\nimport { PosixFile } from \"../../core/fs/PosixFile\"\nimport { Previews } from \"../../core/img/Previews\"\nimport { identity } from \"../../core/Object\"\nimport { AssetVersion } from \"../../core/PhotoStructureVersions\"\nimport { CapturedAt } from \"../../core/tags/CapturedAt\"\nimport { AssetId } from \"../../fe/api/Asset\"\nimport { ID } from \"../../fe/api/ID\"\nimport { ApiTag, TagPath } from \"../../fe/api/Tag\"\nimport { compact, isEmpty, isNotEmpty, sortBy, uniqBy } from \"../../fe/Array\"\nimport { AssetUrls } from \"../../fe/AssetUrls\"\nimport { isTrue } from \"../../fe/Boolean\"\nimport { secondMs } from \"../../fe/Date\"\nimport { ReducerName, ReducerNames } from \"../../fe/ImageReducers\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { pick, StrBoolValued, StringValued, tap } from \"../../fe/Object\"\nimport { MaybeSyncOrAsync, SyncOrAsync, thenOpt } from \"../../fe/OptAsync\"\nimport { thenCollect } from \"../../fe/Promise\"\nimport { compressWhitespace } from \"../../fe/String\"\nimport { toA } from \"../../fe/toA\"\nimport { dateTag } from \"../curators/DateTagger\"\nimport { joinTagPath } from \"../curators/Taggers\"\nimport { Library } from \"../Library\"\nimport { AssetFile } from \"./AssetFile\"\nimport { AssetTag } from \"./AssetTag\"\nimport { TableName } from \"./TableName\"\nimport { Tag } from \"./Tag\"\nimport { coalesceStreams, TaggedAssetStream } from \"./TaggedAssetStream\"\nimport { TimestampedModel, toID } from \"./TimestampedModel\"\n\nexport interface AssetTagsParams {\n  assetId: number\n  tagPaths: TagPath[]\n}\n\nexport class Asset extends TimestampedModel {\n  static tableName: TableName = \"Asset\"\n  static uniqueColumnName = \"id\"\n\n  capturedAtLocal!: number\n  // shown is set by sync, and is false during import or if all files are\n  // missing. It should be renamed to something like \"ready\":\n  shown?: boolean\n  // hidden is set by the user\n  hidden?: boolean\n  excluded?: boolean\n  version?: number\n  updateCount?: number\n\n  files?: AssetFile[]\n  tags?: Tag[]\n\n  // For UI use (transient/not persisted):\n  streams?: TaggedAssetStream[]\n  attrs = {}\n  afterId?: ID\n  beforeId?: ID\n\n  readonly urls = lazy(() => new AssetUrls(this.toID()!))\n  imgAttrs?: Map<ReducerName, StringValued>\n  /**\n   * The \"poster\" image for a video assets\n   */\n  poster?: string\n  existingFiles?: AssetFile[]\n\n  static readonly booleanFields = [\"shown\", \"hidden\", \"excluded\"]\n\n  static shownUnhidden(qb?: Knex.QueryBuilder): Knex.QueryBuilder {\n    return orElse(qb, () => Asset.query()).andWhere({\n      shown: 1,\n      hidden: 0,\n      excluded: 0\n    })\n  }\n\n  static readonly shownAssetCounts = lazy(\n    () =>\n      Asset.dbl.pluckFirst<number>(\n        {\n          sql: compressWhitespace(\n            \"SELECT\",\n            \"  COUNT(DISTINCT Asset.id)\",\n            \"FROM Asset\",\n            \"WHERE\",\n            \"  Asset.shown = 1\",\n            \"  AND Asset.excluded = 0\",\n            \"  AND hidden = 0\"\n          )\n        }\n        // q.select(countDistinct().where({ shown: 1, excluded: 0, hidden: 0 })\n      ),\n    7 * secondMs\n  )\n\n  static shownCount(): Promise<number> {\n    return this.ops().countf(q => q.where({ shown: 1, excluded: 0 }))\n  }\n\n  private static outdatedQuery() {\n    return this.query()\n      .where(\"version\", \"<\", AssetVersion)\n      .andWhere({ shown: 1, excluded: 0 })\n  }\n\n  static deletePreviews(assetId: number) {\n    return Library.instance()!.previews().ap(assetId).deleteAll()\n  }\n\n  static async delete(assetId: number) {\n    this.logger().warn(\"Deleting asset \" + assetId)\n    await AssetTag.dbl.runf(q => q.delete().where({ assetId }))\n    await AssetFile.dbl.runf(q => q.delete().where({ assetId }))\n    await Asset.dbl.runf(q => q.delete().where({ id: assetId }))\n    await Asset.deletePreviews(assetId)\n  }\n\n  static async exclude(assetId: number) {\n    this.logger().info(\"Excluding asset \" + assetId)\n    return {\n      dbResult: await Asset.dbl.runf(q =>\n        q.update({ excluded: 1 }).where({ id: assetId })\n      ),\n      deletedPreviews: await Asset.deletePreviews(assetId)\n    }\n  }\n\n  static nextOutdated(\n    q: (qb: Knex.QueryBuilder) => Knex.QueryBuilder = identity\n  ) {\n    return this.ops().findOne(q(this.outdatedQuery()))\n  }\n\n  static nextOutdateds(q: (qb: Knex.QueryBuilder) => Knex.QueryBuilder) {\n    return this.ops().all(q(this.outdatedQuery()))\n  }\n\n  static outdatedCount(\n    q: (qb: Knex.QueryBuilder) => Knex.QueryBuilder = identity\n  ) {\n    return this.dbl.pluckFirst<number>(q(this.outdatedQuery()).count())\n  }\n\n  static findFirstByFile(f: (qb: Knex.QueryBuilder) => Knex.QueryBuilder) {\n    return this.ops().findOne(\n      f(\n        this.query()\n          .select(\"Asset.*\")\n          .join(\"AssetFile\", \"AssetFile.assetId\", \"Asset.id\")\n      )\n    )\n  }\n\n  static async addTags(assetId: number, tagPaths: TagPath[]) {\n    const uniqTagPaths = uniqBy(tagPaths.filter(isNotEmpty), t =>\n      joinTagPath(t)\n    )\n    this.logger().debug(\"addTags()\", { assetId, tagPaths, uniqTagPaths })\n    return isEmpty(uniqTagPaths)\n      ? undefined\n      : Asset.tx(async () => {\n          const tags = await thenCollect(uniqTagPaths, tp =>\n            Tag.findOrCreate(tp)\n          )\n          const tagIds = tags.map(ea => ea.id!)\n          return AssetTag.addTagsToAsset(assetId, tagIds)\n        })\n  }\n\n  static async removeTags(assetId: number, tagPaths: TagPath[]) {\n    if (isEmpty(tagPaths)) return\n    const tags = await thenCollect(tagPaths, ea => Tag.findByPath(ea))\n    this.logger().info(\"removeTags()\", {\n      assetId,\n      tags: tags.map(ea => pick(ea, \"id\", \"path\")),\n      tagPaths\n    })\n    return AssetTag.removeTagsFromAsset(assetId, compact(tags.map(ea => ea.id)))\n  }\n\n  static unshownAssetIds() {\n    return this.dbl.pluckAll<number>(`\n        SELECT DISTINCT af1.assetId\n        FROM AssetFile af1\n          LEFT JOIN (SELECT DISTINCT assetId FROM AssetFile WHERE shown = 1) AS af2 \n            ON af1.assetId = af2.assetId\n        WHERE af2.assetId IS NULL`)\n  }\n\n  static archive(assetId: number) {\n    return this.tx(async () => {\n      const a = await Asset.ops().findById(assetId)\n      if (a != null) {\n        await AssetTag.dbl.runf(q => q.where({ assetId }).delete())\n        await AssetFile.dbl.runf(q => q.where({ assetId }).delete())\n        await Asset.dbl.runf(q => q.where({ id: assetId }).delete())\n      }\n    })\n  }\n\n  get capturedAt() {\n    return localToDateObject(this.capturedAtLocal)\n  }\n\n  get capturedAtMs() {\n    return localToTs(this.capturedAtLocal)\n  }\n\n  markUnshownAndUpsert() {\n    this.shown = false\n    this.version = AssetVersion // don't touch with modelDbUpdater.\n    return this.upsert()\n  }\n\n  markShownAndUpsert() {\n    this.shown = true\n    if (this.excluded == null) this.excluded = false\n    this.version = AssetVersion\n    return this.upsert()\n  }\n\n  toAssetId(): AssetId {\n    return {\n      assetId: this.id!,\n      capturedAtLocal: this.capturedAtLocal\n    }\n  }\n\n  // get fitWidths() {\n  //   return mapNotBlank(this._fitWidths, ea => JSON.parse(ea) as number[])\n  // }\n\n  // set fitWidths(arr: number[]) {\n  //   this._fitWidths = stringify(arr)\n  // }\n\n  renderCaption(locale?: string) {\n    return map(this.capturedAtMs, ea => \"Taken \" + fmtDateShort(ea, locale))\n  }\n\n  // async whenApiTag(): PromiseMaybe<ApiTag> {\n  //   const ca = this.capturedAt\n  //   const path = await dateTag(ca)\n  //   const tag = path == null ? undefined : await Tag.findOrCreate(path)\n  //   return tag == null ? undefined : tag.toApiTag()\n  // }\n\n  async whenApiTag(): PromiseMaybe<ApiTag> {\n    return thenOpt(this.capturedAt)\n      .flatMap(ea => dateTag(ea))\n      .flatMap(ea => Tag.findOrCreate(ea))\n      .flatMap(ea => ea.toApiTag())\n      .get()\n  }\n\n  addTagPaths(tagPaths: TagPath[]) {\n    return Asset.addTags(this.id!, tagPaths)\n  }\n\n  async findAssetFileByUri(uri: string): PromiseMaybe<AssetFile> {\n    await this.getFiles()\n    return this.files!.find(ea => ea.uri === uri)\n  }\n\n  async addAssetFile(af: AssetFile): Promise<AssetFile> {\n    if (null == (await this.findAssetFileByUri(af.uri))) {\n      this.files!.push(af)\n      af.asset = this\n      af.assetId = this.id\n    }\n    return af\n  }\n\n  static getTags(assetId: number) {\n    return Tag.ops().all(\n      Tag.query()\n        .select(\"Tag.*\")\n        .join(\"AssetTag\", \"AssetTag.tagId\", \"Tag.id\")\n        .where(\"AssetTag.assetId\", assetId)\n        .orderByRaw(\"COALESCE(Tag.ordinal, Tag._path)\")\n    )\n  }\n\n  async getTags() {\n    if (this.tags == null) {\n      this.tags = await Asset.getTags(this.id!)\n    }\n    return this.tags\n  }\n\n  /**\n   * Tags will be strings concatenated by `Tag.sep`\n   */\n  static getTagPaths(assetId: number) {\n    const q = Tag.query()\n      .select(\"Tag._path\")\n      .join(\"AssetTag\", \"AssetTag.tagId\", \"Tag.id\")\n      .where(\"AssetTag.assetId\", assetId)\n      .orderByRaw(\"COALESCE(Tag.ordinal, Tag._path)\")\n    return Tag.dbl.pluckAll(q) as MaybeSyncOrAsync<string[]>\n  }\n\n  async tagPaths() {\n    const tags = await this.getTags()\n    return tags.map(t => t.path.join(\"/\")).sort()\n  }\n\n  async getStreams(limit: number): Promise<TaggedAssetStream[]> {\n    if (this.streams == null) {\n      const tags = await this.getTags()\n      this.logger().info(\"getStreams(): fetched tags \" + tags, { limit })\n      const streams = await thenCollect(tags, tag =>\n        tag.getAssetStream(this, limit)\n      )\n      this.streams = coalesceStreams(compact(streams))\n      // Backfull the ancestors:\n      for (const stream of this.streams) {\n        for (const tag of stream.tags) {\n          await tag.getAncestors()\n        }\n      }\n    }\n    return this.streams\n  }\n\n  async getBeforeAfterId() {\n    // Do we have multiple assets with the same capturedAt?\n    const sameIds = (await Asset.dbl.all(\n      Asset.shownUnhidden()\n        .select(\"id\", \"updateCount\")\n        .andWhere(\"capturedAtLocal\", this.capturedAtLocal)\n        .orderBy(\"id\")\n    )) as Pick<Asset, \"id\" | \"updateCount\">[]\n    this.afterId = map(\n      sameIds.find(ea => ea.id! > this.id!),\n      toID\n    )\n    // use id as a secondary sort for capturedAt.\n    this.beforeId = map(\n      sameIds.reverse().find(ea => ea.id! < this.id!),\n      toID\n    )\n    await thenOrElse(this.beforeId, () => this.getBeforeId())\n    await thenOrElse(this.afterId, () => this.getAfterId())\n  }\n\n  private async getBeforeId() {\n    return thenMap(\n      Asset.dbl.first(\n        Asset.shownUnhidden()\n          .select(\"id\", \"updateCount\")\n          // This needs to be <, not <=. See getBeforeAfterId.\n          .andWhere(\"capturedAtLocal\", \"<\", this.capturedAtLocal)\n          .orderBy([\n            { column: \"capturedAtLocal\", order: \"desc\" },\n            // we have to add this if the prev is a batch of same-time assets:\n            { column: \"id\", order: \"desc\" }\n          ])\n      ),\n      ea => (this.beforeId = toID(ea))\n    )\n  }\n\n  private async getAfterId() {\n    return thenMap(\n      Asset.dbl.first(\n        Asset.shownUnhidden()\n          .select(\"id\", \"updateCount\")\n          // This needs to be >, not >=. See getBeforeAfterId.\n          .andWhere(\"capturedAtLocal\", \">\", this.capturedAtLocal)\n          .orderBy([\n            { column: \"capturedAtLocal\", order: \"asc\" },\n            // we have to add this if the prev is a batch of same-time assets:\n            { column: \"id\", order: \"asc\" }\n          ])\n      ),\n      ea => (this.afterId = toID(ea))\n    )\n  }\n\n  async getTagPaths() {\n    const tags = await this.getTags()\n    return tags.map(tag => tag.path)\n  }\n\n  async getFiles() {\n    if (this.files != null) return this.files\n    if (this.id == null) return (this.files = []) // < we're not inserted yet.\n    const files = await AssetFile.ops().findBy({ assetId: this.id! })\n    return (this.files = sortBy(\n      files,\n      // First shown, then by mtime desc:\n      ea => [!isTrue(ea.shown), -ea.mtime]\n    ))\n  }\n\n  async setShown(assetFileId: number) {\n    return AssetFile.setShown(this.id!, assetFileId)\n  }\n\n  async getShown() {\n    // af.shown may be 1 or true, due to boolean transcribing:\n    if (this.files != null) {\n      const shown = this.files.find(af => isTrue(af.shown))\n      if (shown != null) return shown\n    }\n    return thenMap(\n      AssetFile.ops().findOneBy({ assetId: this.id!, shown: 1 }),\n      af => tap(af, ea => (ea.asset = this)) // don't need to re-fetch this\n    )\n  }\n\n  async getCapturedAts(): Promise<CapturedAt[]> {\n    return thenCollect(this.getFiles(), ea => ea.toCapturedAt())\n  }\n\n  link(): string {\n    return \"/asset/\" + this.id\n  }\n\n  sqAttrs(lazyLoad: boolean = true): any {\n    return {\n      ...this.urls().sqImgAttrs(lazyLoad),\n      title: this.renderCaption(),\n      ...this.attrs\n    }\n  }\n\n  async getImgAttrs(previews: Previews, reducer: ReducerName, skipFs = false) {\n    if (this.imgAttrs == null)\n      this.imgAttrs = new Map<ReducerName, StringValued>()\n    if (this.imgAttrs.get(reducer) == null) {\n      const ap = previews.ap(this.toID()!)\n      await thenMap(ap.readInfo(), async info => {\n        if (info.mimetype.startsWith(\"video/\")) {\n          this.poster = await ap.posterLink()\n        }\n      })\n      const stat = true\n      this.imgAttrs.set(reducer, await ap.imgAttrs(reducer, stat, skipFs))\n    }\n    return this.imgAttrs.get(reducer)\n  }\n\n  async fitAttrs(previews: Previews): Promise<StrBoolValued> {\n    return {\n      ...(await this.getImgAttrs(previews, ReducerNames.fit)),\n      // title: this.renderCaption(),\n      ...this.attrs\n    }\n  }\n\n  isVideo(): boolean {\n    if (this.files == null) {\n      throw new Error(\".video called before getFiles()\")\n    }\n    return this.files.some(ea => ea.isVideo)\n  }\n\n  videoAttrs(): StrBoolValued {\n    return {\n      controls: true,\n      autoplay: true,\n      poster: this.poster,\n      ...this.attrs\n    }\n  }\n\n  videoSources() {\n    if (this.existingFiles == null) {\n      throw new Error(\".videoSources called before getExistingFiles()\")\n    }\n\n    // We need at least one video to be an mp4.\n    // 1. prefer the shown asset file if it's an mp4\n    // 2. if any siblings are an mp4, use that\n    // 3. otherwise, videolink the shown or first existing asset file with an \"mp4=\"\n\n    // Only take the first file for a given mimetype:\n    const result = this.existingFiles\n      .filter(ea => ea.isVideo)\n      .map(af => ({\n        src: this.urls().videoLink(af.id!),\n        type: af.mimetype\n      }))\n\n    const uniqByType = uniqBy(result, ea => ea.type)\n\n    if (uniqByType.every(ea => ea.type !== \"video/mp4\")) {\n      // The first element should be the shown value, or the newest:\n      const src = this.existingFiles[0]\n      uniqByType.unshift({\n        src: this.urls().videoLink(src.id!) + \".mp4\",\n        type: \"video/mp4\"\n      })\n    }\n    return uniqByType\n  }\n\n  async getPosixFiles(): PromiseMaybe<PosixFile[]> {\n    const afs = await this.getFiles()\n    return compact(await Promise.all(afs.map(ea => ea.posixFile())))\n  }\n\n  async getExistingAssetFiles() {\n    if (this.existingFiles == null)\n      this.existingFiles = await filterAsync(await this.getFiles(), af =>\n        thenMapOr(\n          af.posixFile(),\n          pf => pf.exists(),\n          () => false\n        )\n      )\n\n    return this.existingFiles\n  }\n\n  async findOrCreateByFile(f: PosixFile) {\n    const uri = await f.uri()\n    if (uri == null) return\n    const prior = toA(await AssetFile.findByAsset({ id: this.id }, { uri }))[0]\n    return orElse<SyncOrAsync<AssetFile>>(prior, async () => {\n      const af = new AssetFile()\n      af.asset = this\n      af.assetId = this.id\n      await af.setFile(f)\n      return af\n    })\n  }\n\n  clear() {\n    this.existingFiles = undefined\n    this.files = undefined\n    this.imgAttrs = undefined\n    this.streams = undefined\n    this.tags = undefined\n    return this\n  }\n\n  async setHidden(hidden: boolean) {\n    this.hidden = hidden\n    return this.upsert()\n  }\n}\n", "import { AssetFileVersion, AssetVersion } from \"../core/PhotoStructureVersions\"\nimport { tx } from \"./db/Transactions\"\nimport { Asset } from \"./model/Asset\"\nimport { AssetFile } from \"./model/AssetFile\"\nimport { modelDb } from \"./model/ModelDb\"\nimport { Operation, OperationNames } from \"./model/Operation\"\n\nexport function forceRebuildLibrary() {\n  return tx(modelDb(), async () => {\n    await Asset.dbl.runf(q => q.update({ version: 0 }))\n    await AssetFile.dbl.runf(q => q.update({ version: 0 }))\n    await Operation.dbl.runf(q =>\n      q\n        .where({\n          name: OperationNames.enqueueAssetFileUpdates,\n          version: AssetFileVersion\n        })\n        .orWhere({\n          name: OperationNames.enqueueAssetUpdates,\n          version: AssetVersion\n        })\n        .delete()\n    )\n  })\n}\n", "import p from \"process\"\nimport { AppName } from \"../core/AppName\"\nimport { endEndables, ending } from \"../core/async/Endable\"\nimport { Promises } from \"../core/async/Promises\"\nimport { thenOrTimeout } from \"../core/async/thenOrTimeout\"\nimport { untilTrue } from \"../core/async/until\"\nimport { psenv } from \"../core/child/ChildEnv\"\nimport { ChildServiceExitCommand } from \"../core/child/ChildService\"\nimport { isDaemon } from \"../core/cli/IsDaemon\"\nimport { fmtMs } from \"../core/date/Date\"\nimport { getEnv } from \"../core/Env\"\nimport { onError } from \"../core/error/Error\"\nimport { addErrorFlags, FatalErrorFlag } from \"../core/error/ErrorTypes\"\nimport { WrappedError } from \"../core/error/WrappedError\"\nimport {\n  eventEmitter,\n  onPause,\n  onResume,\n  onWriteRecentLogEntries\n} from \"../core/event/EventEmitter\"\nimport { LineReader } from \"../core/fs/LineReader\"\nimport { maybeSizeSync } from \"../core/fs/Stat\"\nimport { LogTail } from \"../core/log/LogTail\"\nimport {\n  Logger,\n  mkLogger,\n  setupLogger,\n  writeRecentLogEntries\n} from \"../core/Logger\"\nimport { start } from \"../core/NodeEnv\"\nimport { Pojo, Try } from \"../core/Object\"\nimport { isDocker, isElectron, isPacked } from \"../core/Platform\"\nimport {\n  isMainService,\n  isWelcomeService,\n  ServiceName,\n  ServiceNames,\n  setServiceName\n} from \"../core/ServiceNames\"\nimport { Settings } from \"../core/settings/Settings\"\nimport {\n  libraryHasSettings,\n  librarySettingsVersion,\n  readLibrarySettings,\n  readSystemSettings,\n  systemSettingsVersion,\n  writeLibrarySettings,\n  writeSystemSettings\n} from \"../core/settings/SettingsIO\"\nimport { version } from \"../core/Version\"\nimport { setDoNotRunImpl } from \"../core/work/Idle\"\nimport { isPaused, pause, resume } from \"../core/work/WorkPlanner\"\nimport { mapNotBlank } from \"../fe/Blank\"\nimport { isTrue } from \"../fe/Boolean\"\nimport { secondMs } from \"../fe/Date\"\nimport { delay, later } from \"../fe/Delay\"\nimport { errorToS, errorToVerbose } from \"../fe/Error\"\nimport { Latch } from \"../fe/Latch\"\nimport { lazy } from \"../fe/Lazy\"\nimport { map } from \"../fe/Maybe\"\nimport { toS } from \"../fe/toS\"\nimport { doNotRun, healthChecks } from \"./HealthChecks\"\nimport { Library } from \"./Library\"\nimport { libraryModelDbFile } from \"./model/ModelDb\"\nimport { rpcClientReady } from \"./rpc/RpcClient\"\nimport { sendRecentLogs } from \"./SendRecentLogs\"\nimport { installSentry } from \"./SentrySetup\"\nimport { stdoutWrite } from \"./StdoutWrite\"\n\nexport const setupEventHandlers = lazy(() => {\n  onWriteRecentLogEntries(() => writeRecentLogEntries())\n  onResume(() => resume())\n  onPause(() => pause())\n})\n\nexport interface ServiceOptions {\n  name: ServiceName\n  stdinReceiver?: (stdin: string) => any\n  maxErrorsPerMinute?: number\n}\n\n/**\n * Framework for creating services that accept async commands from stdin and\n * emit results to stdout. Every process will have a Service instance.\n *\n * The initial service will only be the webservice, propped up in \"libraryless\"\n * mode.\n *\n * The constructor doesn't take an interface with ready and shutdown fields\n * because the services depend on the library that this service creates, which\n * creates a circular dependency.\n */\nexport class Service {\n  readonly name: ServiceName\n  private readonly logger: Logger\n  private _exitted = false\n  private readonly _ready = new Latch()\n  readonly jobs = new Promises()\n\n  private readonly onFatalHandlers: ((reason: string) => any)[] = []\n  private readonly inputHandlers = new Map<string, (input: string) => any>()\n\n  constructor(readonly opts: ServiceOptions) {\n    // TODO: FIXME: SITS: service name is being set in both CLI and here:\n    setServiceName((this.name = this.opts.name))\n    setupLogger()\n    Settings.logDir.addListener(() => setupLogger())\n    if (Settings.tailLogs.valueOrDefault) {\n      LogTail.instance()\n    }\n    this.logger = mkLogger(\"Service(\" + this.name + \")\")\n\n    this.addDefaultInputHandlers()\n\n    // By pushing the setup job onto this.jobs, we get two things:\n    // 1) exit() can wait for setup()\n    // 2) onLine() will implicitly wait for setup.\n    void this.jobs.push(\"Service.setupOrTimeout\", () => this.setupOrTimeout())\n  }\n\n  async setupOrTimeout() {\n    {\n      const ready = await thenOrTimeout(\n        this.setup().then(() => true),\n        Settings.setupTimeoutMs.valueOrDefault\n      )\n      if (isTrue(ready)) return // YAY\n    }\n    const dbFileSize = maybeSizeSync(libraryModelDbFile()?.nativePath)\n\n    if (dbFileSize != null) {\n      // Extend the timeout to be proportional to the size of the library:\n      const timeoutMs = dbFileSize / 10\n      const remainingTimeoutMs = timeoutMs - (Date.now() - start)\n      if (remainingTimeoutMs > 0) {\n        this.logger.warn(\n          \"Startup is taking a while, but the database looks like it's large, so we're going to wait for another \" +\n            fmtMs(remainingTimeoutMs),\n          {\n            dbFileSize,\n            timeoutMs,\n            setupTimeoutMs: Settings.setupTimeoutMs.valueOrDefault\n          }\n        )\n      }\n\n      const ready = await thenOrTimeout(\n        this.setup().then(() => true),\n        remainingTimeoutMs\n      )\n      if (isTrue(ready)) return // YAY\n    }\n\n    return this.exit({\n      reason:\n        \"Setup timed out after \" +\n        fmtMs(Date.now() - start) +\n        \".\\nPlease visit https://photostructure.com/troubleshooting for help.\",\n      status: 13,\n      waitForJobs: false\n    })\n  }\n\n  get ready(): Promise<void> {\n    return this._ready.promise\n  }\n\n  get isReady(): boolean {\n    return this._ready.resolved\n  }\n\n  get exitted() {\n    return this._exitted\n  }\n\n  onFatal(f: (reason: string) => any) {\n    this.onFatalHandlers.push(f)\n  }\n\n  private logStartup() {\n    this.logger.info(\"setup()\", {\n      version,\n      start,\n      argv: p.argv,\n      arch: p.arch,\n      platform: p.platform,\n      isDocker: isDocker(),\n      isPacked,\n      isElectron,\n      versions: p.versions,\n      settings: {\n        logLevel: Settings.logLevel.valueOrDefault,\n        httpPort: Settings.httpPort.valueOrDefault,\n        rpcPort: Settings.rpcPort.valueOrDefault,\n        libraryPath: Settings.libraryPath.valueOrDefault\n      },\n      ...psenv()\n    })\n  }\n\n  readonly setup = lazy<Promise<void>>(async () => {\n    this.logger.info(\"setup()\")\n    const canContinue = () => !this._exitted && !ending()\n\n    try {\n      // set up crash handlers\n      {\n        // Test crash handler (see https://gitlab.com/photostructure/photostructure/issues/163)\n        mapNotBlank(getEnv(\"PS_FATAL_\" + this.name), message => {\n          throw new WrappedError({ fatal: true, message })\n        })\n        mapNotBlank(getEnv(\"PS_CRASH_\" + this.name), message => {\n          later(() => {\n            throw new WrappedError({ message })\n          }, 5 * secondMs)\n        })\n      }\n\n      // set process title\n      {\n        // the title is the menu bar name on electron 5 now, so don't include the\n        // opts.name if we're the main process.\n        const title =\n          AppName() + (this.name === ServiceNames.main ? \"\" : ` ${this.name}`)\n        // Node typings say title is read-only:\n        const proc: any = p\n        try {\n          proc.title = title\n        } catch {\n          //\n        }\n      }\n\n      await readSystemSettings()\n      if (libraryHasSettings()) {\n        await readLibrarySettings()\n      }\n\n      // set up error handling as early as we can, but only after we've read the\n      // library settings:\n      await this.setupErrorHandling()\n\n      // log after we've read settings:\n      this.logStartup()\n\n      if (isMainService()) {\n        await this.maybeUpgradeSystemSettings()\n        await this.maybeUpgradeLibrarySettings()\n      }\n\n      setupEventHandlers()\n      setDoNotRunImpl(doNotRun)\n      await this.stdinReadline()\n\n      // Wait for library setup to finish:\n      if (canContinue()) {\n        const l = Library.instance()\n        if (l == null && !isWelcomeService()) {\n          throw new Error(\n            \"Cannot start, library path is unset\" + FatalErrorFlag\n          )\n        }\n        if (l != null) {\n          await l.ready\n        }\n      }\n\n      // We're a service: make sure RPC is set up, but we don't need to wait for\n      // it.\n      void rpcClientReady()\n\n      const reject = !canContinue()\n      this.logger.debug(\"setup done.\", { reject })\n\n      if (reject) {\n        void this._ready.reject()\n      } else {\n        void this._ready.resolve()\n      }\n    } catch (err) {\n      console.error(errorToVerbose(err))\n      void this._ready.reject(err)\n      // We couldn't start up. No need to wait for jobs:\n      void this.exit({\n        reason: addErrorFlags(\n          this.name + \" setup failed: \" + errorToS(err),\n          FatalErrorFlag\n        ),\n        status: 14,\n        waitForJobs: false\n      })\n    }\n  })\n\n  private async maybeUpgradeSystemSettings() {\n    // write system settings if they are missing or outdated.\n    if (version !== (await systemSettingsVersion())) {\n      await writeSystemSettings()\n    }\n  }\n\n  private async maybeUpgradeLibrarySettings() {\n    if (libraryHasSettings() && version !== (await librarySettingsVersion())) {\n      await writeLibrarySettings()\n    }\n  }\n\n  private async setupErrorHandling() {\n    eventEmitter.on(\"fatal\", ({ message, error }) =>\n      this.exit({\n        reason: message + map(error, ea => \": \" + errorToS(ea)),\n        status: 12,\n        waitForJobs: false\n      })\n    )\n\n    // This will only be used by main on the command line.\n    this.setInputHandler(\"--send-recent-logs\", () => sendRecentLogs())\n\n    p.on(\"unhandledRejection\", err =>\n      map(err, ea => onError(\"unhandledRejection\", ea as any))\n    )\n    p.on(\"uncaughtException\", err =>\n      map(err, ea => onError(\"uncaughtException\", ea))\n    )\n\n    p.on(\"SIGINT\", () =>\n      this.exit({ reason: \"SIGINT\", status: 0, waitForJobs: false })\n    )\n    p.on(\"SIGTERM\", () =>\n      this.exit({ reason: \"SIGTERM\", status: 0, waitForJobs: false })\n    )\n    // Zombie prevention for Alpine?\n    p.on(\"SIGCHLD\", (...ea: any[]) => this.logger.debug(\"Received SIGCHLD\", ea))\n    // If the Node.js process is spawned with an IPC channel (see the Child\n    // Process and Cluster documentation), the 'disconnect' event will be\n    // emitted when the IPC channel is closed.\n    p.on(\"disconnect\", () =>\n      this.exit({ reason: \"disconnect\", status: 0, waitForJobs: false })\n    )\n    if (isDaemon() || (isMainService() && isDocker())) {\n      this.logger.info(\n        \"setupErrorHandling(): not adding stdin/stdout/stderr close handlers: we're daemonized or in docker.\"\n      )\n    } else {\n      const waitForJobs = true\n      p.stdin.on(\"close\", () =>\n        this.exit({ reason: \"stdin.close\", status: 0, waitForJobs })\n      )\n      // We're not rendering the stack here because sourcemaps caused an issue (?!)\n      p.stdin.on(\"error\", err => this.logger.warn(\"stdin.error: \" + err))\n      p.stdin.on(\"disconnect\", () =>\n        this.exit({ reason: \"stdin.disconnect\", status: 0, waitForJobs })\n      )\n      p.stdout.on(\"disconnect\", () =>\n        this.exit({ reason: \"stdout.disconnect\", status: 0, waitForJobs })\n      )\n      p.stdout.on(\"error\", err => this.logger.warn(\"stdout.error: \" + err))\n      p.stderr.on(\"disconnect\", () =>\n        this.exit({ reason: \"stderr.disconnect\", status: 0, waitForJobs })\n      )\n      p.stderr.on(\"error\", err => this.logger.warn(\"stderr.error: \" + err))\n    }\n\n    await installSentry(this)\n\n    return\n  }\n\n  private readonly stdinReadline = lazy(() => {\n    const rl = p.stdin.pipe(new LineReader())\n    rl.on(\"data\", line => this.onLine(toS(line)))\n    return rl\n  })\n\n  async exit({\n    reason,\n    status,\n    waitForJobs\n  }: {\n    reason: string\n    status: number\n    waitForJobs: boolean\n  }) {\n    // NOTE: we don't want to no-op here if we're already exitted, because then\n    // waitForJobs = false will be ignored.\n\n    this._exitted = true\n    this.logger.info(\"exit()\", {\n      status,\n      reason,\n      waitForJobs,\n      ending: ending()\n    })\n\n    if (waitForJobs) {\n      // Allow stdin to be consumed:\n      await delay(250)\n      await untilTrue(\n        () => {\n          this.logger.info(\"exit(): waiting for enqueued jobs to complete...\", {\n            pendingNames: this.jobs.pendingNames()\n          })\n          return this.jobs.settled\n        },\n        {\n          timeoutMs: undefined, // < this might be hundreds of jobs, so a timeout doesn't make sense.\n          timeBetweenMs: secondMs\n        }\n      )\n\n      this.logger.info(\"exit(): enqueued jobs finished.\")\n    }\n    // Only write to stdout if we're exiting uncleanly:\n    if (status !== 0) {\n      await Promise.all(this.onFatalHandlers.map(f => f(reason)))\n      const out: Pojo = {\n        fatal: true,\n        exit: true,\n        status,\n        pid: p.pid,\n        ppid: p.ppid\n      }\n      out[\"error\"] = reason\n      Try(() => stdoutWrite(out, false))\n    }\n    await endEndables()\n    // this doesn't seem necessary:\n    // await tryAll([end(p.stdout), end(p.stderr)])\n    return p.exit(status)\n  }\n\n  setInputHandler(command: string, f: (input: string) => any) {\n    this.inputHandlers.set(command.trim().toLowerCase(), f)\n  }\n\n  private addDefaultInputHandlers() {\n    this.setInputHandler(\"--version\", async () => {\n      stdoutWrite({ version })\n    })\n    this.setInputHandler(\"--status\", async () => {\n      const hc = await healthChecks()\n      this.logger.debug(\"--status\", hc)\n      return stdoutWrite({ healthChecks: hc })\n    })\n    {\n      // if the commands are via the stdin, it's safe to assume they want the\n      // jobs to complete, so the following should waitForJobs:\n      // alias for --exit:\n      this.setInputHandler(\"--quit\", () =>\n        // later this so we aren't considered a job to wait for (which causes exit() to hang):\n        later(() =>\n          this.exit({\n            reason: \"--quit from stdin\",\n            status: 0,\n            waitForJobs: true\n          })\n        )\n      )\n      this.setInputHandler(ChildServiceExitCommand, () =>\n        // later this so we aren't considered a job to wait for (which causes exit() to hang):\n        later(() =>\n          this.exit({\n            reason: ChildServiceExitCommand + \" from stdin\",\n            status: 0,\n            waitForJobs: true\n          })\n        )\n      )\n    }\n    this.setInputHandler(\"--pause\", () => {\n      pause()\n      return stdoutWrite({ paused: isPaused() }, false)\n    })\n    this.setInputHandler(\"--resume\", () => {\n      resume()\n      return stdoutWrite({ paused: isPaused() }, false)\n    })\n  }\n\n  // This shouldn't be async, so this.stdinReadline().pause() can take effect.\n  private onLine(line: string) {\n    this.logger.debug(\"onLine()\", { line, ending: this._exitted || ending() })\n    return this.jobs.serial(\"Service.onLine(\" + line + \")\", async () => {\n      await this.setup()\n      if (line.trim().startsWith(\"--\")) {\n        const cmd = line.split(\" \", 1)[0]\n        const f = this.inputHandlers.get(cmd)\n        if (f == null) {\n          this.logger.error(\"onLine(): unknown command\", { line })\n          console.warn(\"unknown command \" + line)\n        } else {\n          await f(line.substr(cmd.length).trim())\n        }\n      } else {\n        try {\n          await map(this.opts.stdinReceiver, f => f(line))\n        } catch (error) {\n          this.logger.error(\"onLine(): failed to process\", { line, error })\n        }\n      }\n      return\n    })\n  }\n}\n", "import { FSWatcher, watch } from \"fs\"\nimport { mkdirp } from \"fs-extra\"\nimport { join, sep } from \"path\"\nimport { pid, stdout } from \"process\"\nimport { clearInterval, setInterval } from \"timers\"\nimport { fmtIsoDate, minuteMs, secondMs } from \"../../fe/Date\"\nimport { errorToVerbose } from \"../../fe/Error\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { getOrSet } from \"../../fe/Map\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { gte } from \"../../fe/Primitive\"\nimport { thenMap } from \"../../fe/Promise\"\nimport { EndableRanks, ending } from \"../async/Endable\"\nimport { EndableWrapper } from \"../async/EndableWrapper\"\nimport { Promises } from \"../async/Promises\"\nimport { nowish } from \"../date/Date\"\nimport { DirectoryEntry } from \"../fs/DirectoryEntry\"\nimport { isTest } from \"../NodeEnv\"\nimport { serviceName } from \"../ServiceNames\"\nimport { Settings } from \"../settings/Settings\"\nimport { readSystemSettings } from \"../settings/SettingsIO\"\nimport { stdoutEnded } from \"../Stdout\"\nimport { TTLSet } from \"../TTLSet\"\nimport { DefaultLogFormatter } from \"./DefaultLogFormatter\"\nimport { DefaultLogFlushMs } from \"./LogCommon\"\nimport { LogEntry } from \"./LogEntry\"\nimport { ifLog } from \"./LogFilter\"\nimport { LogLevels } from \"./LogLevel\"\nimport {\n  popExpiredLogEntries,\n  pushLogEntries,\n  setLogTailEnabled\n} from \"./LogTailEntries\"\nimport { readLogEntries } from \"./LogWriter\"\n\n/**\n * Tail all PhotoStructure\u2731/log/\u2731\u2731/\u2731.log files.\n */\nexport class LogTail extends EndableWrapper {\n  static readonly instance = lazy(() => {\n    return stdoutEnded() ? undefined : new LogTail()\n  })\n  private root!: DirectoryEntry\n  private watchers: Map<string, FSWatcher> = new Map()\n  private flushTimeout?: NodeJS.Timeout\n  private scanTimeout?: NodeJS.Timeout\n  private ignorableFilename: string\n\n  private readonly file2pos = new Map<string, number>()\n  private readonly lastReadFiles = new TTLSet<string>(5 * secondMs)\n  private readonly mutex = new Promises()\n\n  private constructor() {\n    super(\"LogTail\", () => this.onEnd(), EndableRanks.logger)\n    this.ignorableFilename = sep + serviceName() + \"-\" + pid + \"-\"\n    if (stdout.writableFinished) return\n    setLogTailEnabled(true)\n    // Not an unref'ed interval, so logtail doesn't exit:\n    this.flushTimeout = setInterval(() => this.flush(), DefaultLogFlushMs / 2)\n    this.scanTimeout = setInterval(() => this.scan(), minuteMs)\n    stdout.on(\"end\", () => this.end())\n    void this.setup()\n  }\n\n  readonly setup = lazy(async () => {\n    await readSystemSettings()\n    const logdir = Settings.logDir.valueOrDefault\n    if (isTest) console.log(\"tailing \" + logdir + \"...\")\n    await mkdirp(logdir)\n    this.root = (await DirectoryEntry.for(logdir))!\n    await this.scan(true)\n  })\n\n  async flush() {\n    this.write(popExpiredLogEntries())\n  }\n\n  private readable(nativePath: string) {\n    return (\n      // Don't tail .gz files: they're never updated.\n      nativePath.endsWith(\".log\") &&\n      !nativePath.includes(this.ignorableFilename)\n    )\n  }\n\n  private watchDir(dir: string) {\n    if (ending() || this.ended) return\n    getOrSet(this.watchers, dir, () => {\n      ifLog(LogLevels.debug, () => console.log(\"LogTail(): watching \" + dir))\n      try {\n        return watch(dir, (event: string, filename: string) =>\n          this.watchListener(event, join(dir, filename))\n        )\n      } catch (err) {\n        ifLog(LogLevels.warn, () =>\n          console.error(\"LogTail(): failed to read \" + dir, err)\n        )\n        return\n      }\n    })\n  }\n\n  async scan(firstTime = false) {\n    if (ending() || this.ended) return\n    // scan through logs and set the position for all current entries:\n    await this.root.visitDescendantFiles(async ea => {\n      if (!this.readable(ea.nativePath)) return\n      if (firstTime) {\n        await thenMap(ea.size(), size => this.file2pos.set(ea.nativePath, size))\n      }\n      if (nowish(await ea.mtimeMs())) {\n        this.watchDir(ea.dir)\n      }\n    })\n    if (ending() || this.ended) return\n    try {\n      const currentDir = join(this.root.nativePath, fmtIsoDate(new Date()))\n      await mkdirp(currentDir)\n      this.watchDir(currentDir)\n    } catch (err) {\n      ifLog(LogLevels.warn, () =>\n        console.error(\"LogTail(): Failed to create the current log dir\", err)\n      )\n    }\n    if (ending() || this.ended) return\n    if (firstTime) {\n      console.log(\"LogTail(): Tailing \" + this.root + \"/**/*.log...\")\n    }\n  }\n\n  private async onEnd() {\n    setLogTailEnabled(false)\n    map(this.flushTimeout, clearInterval)\n    this.flushTimeout = undefined\n    map(this.scanTimeout, clearInterval)\n    this.scanTimeout = undefined\n    for (const ea of this.watchers.values()) {\n      ea.close()\n    }\n    this.watchers.clear()\n    for (const ea of this.lastReadFiles) {\n      await this.watchListener(\"onEnd\", ea)\n    }\n    try {\n      this.write(popExpiredLogEntries(-1))\n    } catch {\n      //\n    }\n  }\n\n  private write(arr: LogEntry[]) {\n    for (const ea of arr) {\n      console.log(DefaultLogFormatter().formatLogEntry(ea))\n    }\n  }\n\n  private async watchListener(event: string, filename: string) {\n    if (!this.readable(filename)) {\n      return\n    }\n    await this.mutex.serialByName(filename, async () => {\n      try {\n        const f = await DirectoryEntry.for(filename)\n        if (f == null) {\n          ifLog(LogLevels.warn, () =>\n            console.error(\"watchListener: missing file\", { event, filename })\n          )\n          return\n        }\n        // if (!nowish(await f.mtimeMs(), 2 * minuteMs)) return // old file\n        const currentSize = await f.size()\n        if (currentSize == null || currentSize <= 0) {\n          // console.error(\"watchListener: empty file\", { event, filename })\n          return\n        }\n        const priorSize = orElse(this.file2pos.get(f.nativePath), () => 0)\n        if (gte(priorSize, currentSize)) return\n        await thenMap(\n          readLogEntries(f, { start: priorSize, end: currentSize }),\n          arr => pushLogEntries(...arr)\n        )\n        this.lastReadFiles.add(f.nativePath)\n        // If gzip reading fails, don't update current size:\n        this.file2pos.set(f.nativePath, currentSize)\n      } catch (err) {\n        ifLog(LogLevels.warn, () =>\n          console.error(\n            \"Failed to read \" + filename + \": \" + errorToVerbose(err)\n          )\n        )\n      }\n    })\n    return\n  }\n}\n", "import { count, filterInPlace, isEmpty } from \"../fe/Array\"\n\nexport class RoundRobin<T> implements Iterator<T | undefined> {\n  private readonly arr: T[] = []\n  private iterIdx = 0\n\n  get size(): number {\n    return this.arr.length\n  }\n\n  count(predicate: (t: T) => boolean) {\n    return count(this.arr, predicate)\n  }\n\n  /**\n   * Add t to the next-to-be-iterated-on index.\n   */\n  unshift(...t: T[]) {\n    this.arr.splice(this.iterIdx, 0, ...t)\n  }\n\n  /**\n   * Add t to the last-to-be-iterated-on index.\n   */\n  push(...t: T[]) {\n    this.unshift(...t)\n    this.incrIdx(t.length)\n  }\n\n  remove(t: T) {\n    return this.filterInPlace(ea => ea !== t)\n  }\n\n  /**\n   * @return true iff the array was mutated\n   */\n  filterInPlace(keepIfTrue: (item: T, index: number, arr: T[]) => boolean) {\n    let changed = false\n    filterInPlace(this.arr, (item: T, index: number, arr: T[]) => {\n      const keep = keepIfTrue(item, index, arr)\n      if (!keep) {\n        changed = true\n        if (index < this.iterIdx) this.iterIdx--\n      }\n      return keep\n    })\n    this.incrIdx(0)\n    return changed\n  }\n\n  next(predicate: (t: T) => boolean = () => true) {\n    if (this.size === 0) {\n      return { value: undefined, done: true }\n    } else {\n      for (let i = 0; i < this.size; i++) {\n        const value = this.arr[this.iterIdx]\n        this.incrIdx()\n        // value might be null if this.filterInPlace happened while we're trying\n        // to get the next item:\n        if (value != null && predicate(value)) return { value, done: false }\n      }\n      return { value: undefined, done: true }\n    }\n  }\n\n  toA(predicate: (t: T) => boolean = () => true) {\n    if (isEmpty(this.arr)) return [] //Avoid 0 modding\n    const arr = []\n    for (let i = 0; i < this.size; i++) {\n      const value = this.arr[(this.iterIdx + i) % this.arr.length]\n      if (predicate(value)) arr.push(value)\n    }\n    return arr\n  }\n\n  private incrIdx(diff: number = 1) {\n    // DONT MOD BY 0 ITS BAD\n    this.iterIdx =\n      this.arr.length === 0 ? 0 : (this.iterIdx + diff) % this.arr.length\n  }\n}\n", "import { secondMs } from \"../../fe/Date\"\nimport { later } from \"../../fe/Delay\"\nimport { ending } from \"../async/Endable\"\nimport { EndableInterval } from \"../async/EndableInterval\"\nimport { Later } from \"../async/Later\"\nimport { Promises } from \"../async/Promises\"\nimport { onIdle, onResume } from \"../event/EventEmitter\"\nimport { RoundRobin } from \"../RoundRobin\"\nimport { maxCpus } from \"./MaxCpus\"\nimport { isPaused } from \"./WorkPlanner\"\n\n/**\n * Instances have long-running tasks that can be done in \"chunks,\" whenever\n * there is free CPU.\n */\nexport interface IdleListener {\n  readonly name: string\n\n  runnable: boolean\n\n  /**\n   * Invoked when the system is idle and `runnable` is true.\n   */\n  onIdle(): any\n}\n\nonResume(() => maybeRunOnIdle())\nonIdle(() => later(maybeRunOnIdle))\n\nconst onIdleMutex = new Promises()\nconst workItems = new Promises()\nconst idleListeners = new RoundRobin<IdleListener>()\n\nexport const idleRunner = new EndableInterval({\n  name: \"Idle\",\n  callback: maybeRunOnIdle,\n  intervalMs: 7 * secondMs,\n  initialDelayMs: 20 * secondMs\n})\n\nlet _doNotRunImpl: Later<boolean> = async () => false\n\nexport function setDoNotRunImpl(impl: Later<boolean>) {\n  _doNotRunImpl = impl\n}\n\nasync function doNotRun(): Promise<boolean> {\n  return (\n    isPaused() ||\n    ending() ||\n    idleListeners.size === 0 ||\n    workItems.pendingCount >= maxCpus() ||\n    (await _doNotRunImpl())\n  )\n}\n\nconst IdleDelay = maxCpus() > 4 ? 250 : 750\n\nasync function maybeRunOnIdle() {\n  // This prevents more GC on the onIdleMutex array:\n  return (await doNotRun())\n    ? undefined\n    : onIdleMutex.maybeRun(\"runOnIdle\", async () => {\n        if (await doNotRun()) return\n        const { value } = idleListeners.next(ea => ea.runnable)\n        if (value != null) {\n          void workItems\n            .push(value.name, async () => value.onIdle())\n            .finally(() => maybeRunOnIdle)\n        }\n        // Only immediately reschedule maybeRunOnIdle if we've got more than 1\n        // idle listener:\n\n        if (idleListeners.size > 0) later(maybeRunOnIdle, IdleDelay)\n      })\n}\n\nexport function addIdleListener(listener: IdleListener): void {\n  idleListeners.push(listener)\n  later(maybeRunOnIdle)\n}\n\nexport function removeIdleListener(name: string): boolean {\n  return idleListeners.filterInPlace(ea => ea.name !== name)\n}\n\nexport async function idleStats() {\n  return {\n    doNotRun: {\n      isPaused: isPaused(),\n      ending: ending(),\n      doNotRunImpl: await _doNotRunImpl()\n    },\n    idleListeners: idleListeners.toA().map(ea => ea?.name),\n    runnableIdleListeners: idleListeners\n      .toA(ea => ea?.runnable)\n      .map(ea => ea?.name),\n    pendingWorkItems: workItems.pendingNames()\n  }\n}\n", "import Sentry from \"@sentry/node\"\nimport { PleaseSendErrorFlag } from \"../core/error/ErrorTypes\"\nimport { EventStore } from \"../core/event/EventStore\"\nimport { sentryEnabled } from \"./SentryEnabled\"\nimport { annotateEvent, mkBreadcrumbs } from \"./SentrySetup\"\n\nexport function pleaseSendMessage() {\n  return (\n    // this needs to be a different to ensure multiple requests over a single\n    // day go through:\n    \"User requested recent logs at \" +\n    new Date().toISOString() +\n    PleaseSendErrorFlag\n  )\n}\n\nexport async function sendRecentLogs() {\n  const message = pleaseSendMessage()\n  const event = await annotateEvent({\n    message,\n    breadcrumbs: await mkBreadcrumbs()\n  })\n\n  if (sentryEnabled()) {\n    Sentry.captureEvent(event)\n  } else {\n    await EventStore.instance().writeEvent(event)\n  }\n  return event\n}\n", "import { secondMs } from \"../../fe/Date\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { omit } from \"../../fe/Object\"\nimport { toA } from \"../../fe/toA\"\nimport { toS } from \"../../fe/toS\"\nimport { ending } from \"../async/Endable\"\nimport { thenMap } from \"../async/Promise\"\nimport { isPleaseSendError, PleaseSendErrorFlag } from \"../error/ErrorTypes\"\nimport { BaseFile } from \"../fs/BaseFile\"\nimport { shortStringSha } from \"../fs/Hash\"\nimport { mkLogger } from \"../Logger\"\nimport { GeoRadix } from \"../math/Radix\"\nimport { Pojo } from \"../Object\"\nimport { Settings } from \"../settings/Settings\"\nimport { userData } from \"../UserData\"\n\nconst logger = lazy(() => mkLogger(\"EventStore\"))\n\nexport const ExtraEventsForPlease = 7\n\nexport type StoredEvent = Pojo & {\n  message: string\n  timestamp: number // UNIX TIMESTAMP, not millis!\n}\n\nfunction event2log(event: StoredEvent) {\n  // Skip breadcrumbs (all recent logs) because they are enormous.\n  return omit(event, \"breadcrumbs\")\n}\n\n/**\n * We don't want the same event spammed N-thousand times from a given host. Send\n * the first, throttle the next N for the next time period.\n *\n * Everything is FS based (rather than using sqlite) to minimize deps and have\n * fewer moving parts.\n *\n * Files are placed in YYYY/MM/DD subdirectories so the current day's events are\n * in one place.\n */\nexport class EventStore<T extends StoredEvent> {\n  static readonly instance = lazy(() => new EventStore())\n  readonly root = BaseFile.for(userData()).join(\"events\")\n\n  datedRoot(d = new Date()) {\n    return this.root.joinYMD(d)!\n  }\n\n  rmrf() {\n    return this.root.rmrf()\n  }\n\n  msg2file(e: StoredEvent): BaseFile {\n    return this.datedRoot(new Date(e.timestamp * secondMs)).join(\n      shortStringSha(e.message, 8, GeoRadix) + \".json\"\n    )\n  }\n\n  async eventsFrom(when = new Date()) {\n    return toA(\n      await this.datedRoot(when).childFiles(\n        ea => ea.ext === \".json\" && !ea.isHiddenPosix()\n      )\n    )\n  }\n\n  async eventQuotaExceeded(event: T | any) {\n    const pleaseSend =\n      toS(event).includes(PleaseSendErrorFlag) ||\n      toS(event.message).includes(PleaseSendErrorFlag)\n    const recentEventCount = await this.eventCount()\n    const maxErrorsPerDay =\n      Settings.maxErrorsPerDay.valueOrDefault +\n      (pleaseSend ? ExtraEventsForPlease : 0)\n    return recentEventCount >= maxErrorsPerDay\n  }\n\n  async eventCount(when = new Date()) {\n    const f = await this.eventsFrom(when)\n    return f.length\n  }\n\n  async maybeSendEvent(event: T): Promise<T | null> {\n    if (ending()) {\n      logger().error(\"maybeSendEvent(): REJECT: we're ending.\", {\n        event: event2log(event)\n      })\n      return null\n    }\n    try {\n      const pleaseSend = isPleaseSendError(event.message)\n      const recentEventCount = await this.eventCount()\n      const maxErrorsPerDay =\n        Settings.maxErrorsPerDay.valueOrDefault +\n        (pleaseSend ? ExtraEventsForPlease : 0)\n\n      if (recentEventCount >= maxErrorsPerDay) {\n        logger().error(\n          \"maybeSendEvent(): REJECT: too many events sent in the last day.\",\n          {\n            recentEventCount,\n            pleaseSend,\n            maxErrorsPerDay,\n            event: event2log(event)\n          }\n        )\n        return null\n      } else {\n        const file = await this.writeEvent(event as any)\n        if (file == null) {\n          logger().error(\n            \"maybeSendEvent(): REJECT: event was already sent in the last day.\",\n            {\n              event: event2log(event)\n            }\n          )\n          return null\n        } else {\n          logger().error(\"maybeSendEvent(): ACCEPT\", {\n            event: event2log(event),\n            pleaseSend,\n            recentEventCount,\n            maxErrorsPerDay\n          })\n          return (event as any) as T\n        }\n      }\n    } catch (err) {\n      logger().error(\n        \"maybeSendEvent(): Failed to determine if we should squelch the event. Failing closed.\",\n        err\n      )\n      return null\n    }\n  }\n\n  // Only exposed for tests\n  async writeEvent(event: StoredEvent) {\n    const file = this.msg2file(event)\n    return thenMap(\n      file\n        .ensureNew_({\n          maxVersions: Settings.maxErrorsPerDay.valueOrDefault,\n          emptyIsNew: false\n        })\n        .catch(() => undefined),\n      ea => ea.writeJsonMaybe(event)\n    )\n  }\n}\n", "import { isEnvTrue } from \"../core/Env\"\nimport { isProd } from \"../core/NodeEnv\"\nimport { isPacked } from \"../core/Platform\"\nimport { Settings } from \"../core/settings/Settings\"\nimport { lazy } from \"../fe/Lazy\"\n\nexport const sentryEnabled = lazy(\n  () =>\n    isEnvTrue(\"ENABLE_SENTRY\") ||\n    (isProd && isPacked && Settings.reportErrors.valueOrDefault)\n)\n\nSettings.reportErrors.addListener(() => sentryEnabled.clear())\n", "import Sentry from \"@sentry/node\"\nimport { Breadcrumb, Event, EventHint, Severity } from \"@sentry/types\"\nimport { freemem, totalmem } from \"os\"\nimport _p from \"process\"\nimport { EndableRanks, ending } from \"../core/async/Endable\"\nimport { EndableWrapper } from \"../core/async/EndableWrapper\"\nimport { addMessage, onError } from \"../core/error/Error\"\nimport { isDoNotSendError } from \"../core/error/ErrorTypes\"\nimport { onFatal, onNonFatal } from \"../core/event/EventEmitter\"\nimport { EventStore, StoredEvent } from \"../core/event/EventStore\"\nimport { ffmpegVersionDescription } from \"../core/img/ffmpeg\"\nimport { vlcVersionDescription } from \"../core/img/vlc\"\nimport { locale } from \"../core/Locale\"\nimport { allRecentLogEntries } from \"../core/log/AllRecentLogEntries\"\nimport { DefaultLogFlushMs } from \"../core/log/LogCommon\"\nimport { LogEntry } from \"../core/log/LogEntry\"\nimport { LogLevel } from \"../core/log/LogLevel\"\nimport { mkLogger } from \"../core/Logger\"\nimport { memoryUsageMb, memoryUsageRssMb } from \"../core/Memory\"\nimport { nodeEnv, start } from \"../core/NodeEnv\"\nimport { CPUs, OS } from \"../core/os\"\nimport { isDocker, isElectron } from \"../core/Platform\"\nimport { broadcast } from \"../core/rpc/Broadcaster\"\nimport {\n  processName,\n  serviceName,\n  serviceShutdownTimeoutMs\n} from \"../core/ServiceNames\"\nimport { Settings } from \"../core/settings/Settings\"\nimport { ellipsize, isString, stripAnsiEsc } from \"../core/String\"\nimport { release, version } from \"../core/Version\"\nimport {\n  compact,\n  compactBlankish,\n  compactBlanks,\n  isEmpty,\n  mapNotEmpty,\n  uniq\n} from \"../fe/Array\"\nimport { blank, notBlank } from \"../fe/Blank\"\nimport { secondMs } from \"../fe/Date\"\nimport { delay } from \"../fe/Delay\"\nimport { errorToS } from \"../fe/Error\"\nimport { stringify } from \"../fe/JSON\"\nimport { lazy } from \"../fe/Lazy\"\nimport { map, orElse } from \"../fe/Maybe\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { toA } from \"../fe/toA\"\nimport { toS } from \"../fe/toS\"\nimport { fmtBytes } from \"../fe/Units\"\nimport { sentryEnabled } from \"./SentryEnabled\"\nimport { Service } from \"./Service\"\n\nconst logger = mkLogger(\"Sentry\")\n\nconst MaxBreadcrumbs = 100\n\nexport async function installSentry(service: Service) {\n  try {\n    if (!sentryEnabled()) return false\n    Sentry.init({\n      // See https://sentry.io/settings/photostructure-inc/projects/photostructure-for-desktop/keys/\n\n      dsn: isElectron\n        ? \"https://0652cdd351054fe9853ff944b1f54e2c@sentry.io/289071\"\n        : \"https://408e2f8d62c3494d8ed663d9e488d67a@sentry.io/1828379\",\n      shutdownTimeout: serviceShutdownTimeoutMs(service.name),\n      release: release, // Must match webpack and bin/release\n      environment: nodeEnv,\n      maxBreadcrumbs: MaxBreadcrumbs,\n      integrations: () => [], // we do everything\n      beforeSend: eventFilter().beforeSend,\n      onFatalError: (error: Error) => onError(\"sentry.onFatalError\", error)\n    })\n    return true\n  } catch (err) {\n    logger.warn(\"Failed to set up sentry: \" + err)\n    return false\n  }\n}\n\nexport function sendToSentry(message: string, error?: Error) {\n  if (sentryEnabled()) {\n    if (error != null && !isDoNotSendError(error)) {\n      Sentry.captureException(addMessage(error, message))\n    } else if (!isDoNotSendError(message)) {\n      Sentry.captureMessage(message)\n    }\n  }\n}\n\nexport const eventFilter = lazy(() => new EventFilter())\n\nexport class EventFilter {\n  private readonly eventStore = EventStore.instance()\n  constructor() {\n    onNonFatal(sendToSentry)\n    onFatal(sendToSentry)\n    new EndableWrapper(\"EventFilter\", () => this.end(), EndableRanks.first)\n  }\n\n  private end() {\n    return map(Sentry.getCurrentHub().getClient(), ea => ea.close(5 * secondMs))\n  }\n\n  readonly beforeSend = async (\n    event: Event,\n    hint?: EventHint\n  ): Promise<Event | null> => {\n    if (!sentryEnabled()) {\n      logger.warn(\"Sentry.beforeSend(): not sending event\", event)\n      return null\n    }\n\n    if (await this.eventStore.eventQuotaExceeded(event)) {\n      logger.warn(\"Sentry.beforeSend(): event quota exceeded\", event)\n      return null\n    }\n\n    const message = extractMessage(event, hint)\n\n    if (isDoNotSendError(message)) {\n      logger.info(\"Sentry.beforeSend(): event not sendable. vetoing\", {\n        event,\n        hint,\n        msg: message\n      })\n      return null\n    }\n    if (blank(event.message)) {\n      event.message = ellipsize(message, 256)\n    }\n    const e = await annotateEvent(event as any)\n    return this.eventStore.maybeSendEvent(e)\n  }\n}\n\nexport function extractMessage(event: Event, hint?: EventHint): string {\n  return uniq(\n    compactBlankish([\n      event.message,\n      ...toA(sentryExceptionsToS(event.exception?.values)),\n      errorToS(hint?.originalException)\n    ])\n  ).join(\": \")\n}\n\nexport function sentryExceptionsToS(\n  e: Maybe<Sentry.Exception[]>\n): Maybe<string[]> {\n  return mapNotEmpty(e, arr => compactBlanks(arr.map(sentryExceptionToS)))\n}\n\nexport function sentryExceptionToS(e: Maybe<Sentry.Exception>): Maybe<string> {\n  return mapNotEmpty(\n    compactBlanks(\n      [e?.type, e?.value].filter(ea => toS(ea).toLowerCase() !== \"error\")\n    ),\n    arr => arr.join(\": \")\n  )\n}\n\n// NOTE: Calling annotateEvent twice on an Event must be idempotent (see\n// sendRecentLogs)\nexport async function annotateEvent(\n  event: Event & { message: string }\n): Promise<Event & StoredEvent> {\n  const email = Settings.email.value\n  if (notBlank(email)) {\n    if (event.user == null) event.user = {}\n    event.user.email = email\n  }\n\n  if (isEmpty(event.breadcrumbs)) event.breadcrumbs = await mkBreadcrumbs()\n\n  const extra = orElse(event.extra, {})\n  extra.pid = _p.pid\n  extra.serviceName = serviceName()\n  extra.serviceEnding = ending()\n  extra.runtimeMs = Date.now() - start\n  extra.version = version\n  extra.os = OS()\n  extra.isDocker = isDocker()\n  extra.nodeVersion = _p.versions.node\n  extra.locale = await locale()\n  extra.cpus = CPUs()\n  extra.memoryUsageMb = memoryUsageMb()\n  extra.memoryUsageRssMb = memoryUsageRssMb()\n  extra.systemMemory = fmtBytes(freemem()) + \" / \" + fmtBytes(totalmem())\n  extra.ffmpeg = await ffmpegVersionDescription()\n  extra.vlc = await vlcVersionDescription()\n  extra.argv = stringify(_p.argv)\n\n  event.extra = extra\n\n  return {\n    timestamp: Date.now() / secondMs,\n    ...event\n  }\n}\n\nexport async function mkBreadcrumbs() {\n  await broadcast(\"writeRecentLogEntries\")\n  // wait for fs flush:\n  await delay(DefaultLogFlushMs * 3)\n  const entries = await allRecentLogEntries()\n  return compact(entries.map(logEntryToBreadcrumb))\n}\n\nexport function logEntryToBreadcrumb(le: LogEntry): Maybe<Breadcrumb> {\n  return map(logLevelToSeverity(le.l), level => ({\n    timestamp: le.ts / secondMs, // sentry is unixtime (seconds)\n    level,\n    category: orElse(le.from, processName()),\n    message: stripAnsiEsc(le.ctx + \": \" + le.msg),\n    data:\n      // SITS: why does Sentry require a data object?\n      typeof le.meta === \"object\"\n        ? le.meta\n        : { value: isString(le.meta) ? stripAnsiEsc(le.meta) : le.meta }\n  }))\n}\n\nexport function logLevelToSeverity(l: LogLevel): Maybe<Severity> {\n  switch (l) {\n    case \"error\":\n      return Severity.Error\n    case \"warn\":\n      return Severity.Warning\n    case \"info\":\n      return Severity.Info\n    case \"debug\":\n      return Severity.Debug\n    default:\n      return\n  }\n}\n", "import { lte } from \"../fe/Primitive\"\nimport { retainLastN } from \"./Array\"\nimport { SortedArray } from \"./SortedArray\"\n\nexport class BoundedGreatestList<T> {\n  readonly sortedArray: SortedArray<T>\n\n  constructor(readonly maxLength: number, readonly toValue: (t: T) => number) {\n    this.sortedArray = new SortedArray(toValue)\n  }\n\n  toArray() {\n    return this.sortedArray.store\n  }\n\n  vacuum() {\n    if (this.sortedArray.length > this.maxLength) {\n      retainLastN(this.sortedArray.store, this.maxLength)\n    }\n    return this.toArray()\n  }\n\n  private get min() {\n    return this.sortedArray.length >= this.maxLength\n      ? this.toValue(this.sortedArray[0])\n      : undefined\n  }\n\n  add(...arr: T[]) {\n    const min = this.min\n    for (const ea of arr) {\n      if (ea != null) {\n        const v = this.toValue(ea)\n        if (v != null) {\n          if (!lte(v, min)) this.sortedArray.add(ea)\n        }\n      }\n    }\n    if (this.sortedArray.length >= 2 * this.maxLength) this.vacuum()\n  }\n}\n", "import { createReadStream, ReadStream } from \"fs\"\nimport { createBrotliDecompress, createGunzip } from \"zlib\"\nimport { LineReader } from \"../fs/LineReader\"\nimport { nameWithoutCount } from \"../fs/Path\"\nimport { SimpleFile } from \"../fs/SimpleFile\"\nimport { parseMaybe } from \"../JSON\"\nimport { SortedArray } from \"../SortedArray\"\nimport { LogEntry, logEntrySorter } from \"./LogEntry\"\n\n// Lines were out of order on speedy with 128, and seemed OK at 512.\nconst HighWatermark = 2048\nconst LowWatermark = HighWatermark / 4\n\nexport class LogReader {\n  private readonly lines: SortedArray<LogEntry> = new SortedArray(\n    logEntrySorter\n  )\n  private readonly fileStream: ReadStream\n  private readonly stream: LineReader\n  private readonly from: string\n  private _hasFirstLine = false\n  private _ended = false\n  private _paused = false\n  private _errors = false\n\n  constructor(readonly f: SimpleFile, errorHandler: (error: Error) => any) {\n    this.from = nameWithoutCount(f.name)\n    this.fileStream = createReadStream(f.nativePath, { autoClose: true })\n    this.stream = (f.ext.toLowerCase().endsWith(\".gz\")\n      ? this.fileStream.pipe(createGunzip())\n      : f.ext.toLowerCase().endsWith(\".br\")\n      ? this.fileStream.pipe(createBrotliDecompress())\n      : this.fileStream\n    )\n      .pipe(new LineReader())\n      .on(\"error\", err => {\n        errorHandler(err)\n        this._errors = true\n      })\n    this.stream.on(\"data\", this.onData.bind(this))\n    this.stream.on(\"end\", () => {\n      this._ended = true\n    })\n  }\n\n  private onData(chunk: string) {\n    const le = parseMaybe(chunk)\n    if (le != null) {\n      this.lines.add({ ...le, from: this.from } as LogEntry)\n      this._hasFirstLine = true\n    }\n    if (this.lines.length > HighWatermark && !this._paused) {\n      this.fileStream.pause()\n      this._paused = true\n    }\n  }\n\n  toString() {\n    return \"LogReader(\" + this.f.nativePath + \")\"\n  }\n\n  hasFirstLine() {\n    return this._hasFirstLine\n  }\n\n  hasErrors() {\n    return this._errors\n  }\n\n  ended() {\n    return this._ended && this.lines.length === 0\n  }\n\n  peek() {\n    return this.lines.store[0]\n  }\n\n  shift() {\n    const result = this.lines.store.shift()\n    if (result != null && this.lines.length < LowWatermark && this._paused) {\n      this.fileStream.resume()\n      this._paused = false\n    }\n    return result\n  }\n}\n", "import { flatten, isNotEmpty } from \"../../fe/Array\"\nimport { hourMs, minuteMs, secondMs } from \"../../fe/Date\"\nimport { delay } from \"../../fe/Delay\"\nimport { errorToS } from \"../../fe/Error\"\nimport { fromEntries, values } from \"../../fe/Object\"\nimport { cmp, gte, lt } from \"../../fe/Primitive\"\nimport { thenMap } from \"../../fe/Promise\"\nimport { withBoundedConcurrency } from \"../async/Promises\"\nimport { untilTrue } from \"../async/until\"\nimport { BoundedGreatestList } from \"../BoundedGreatestList\"\nimport { DirectoryEntry } from \"../fs/DirectoryEntry\"\nimport { mkLogger, writeRecentLogEntries } from \"../Logger\"\nimport { Settings } from \"../settings/Settings\"\nimport { LogEntry, logEntrySorter } from \"./LogEntry\"\nimport { LogLevels } from \"./LogLevel\"\nimport { LogReader } from \"./LogReader\"\n\nexport function recentLogFiles(ttlMs = 10 * minuteMs) {\n  const minMtime = Date.now() - ttlMs\n  return thenMap(DirectoryEntry.for(Settings.logDir.valueOrDefault), dir =>\n    dir.filterDescendantFiles(\n      async ea =>\n        [\".log\", \".log.gz\"].includes(ea.ext) &&\n        gte(await ea.mtimeMs(), minMtime)\n    )\n  )\n}\n\nexport async function allRecentLogEntries(maxEntriesPerLevel = 50) {\n  await writeRecentLogEntries()\n\n  const entriesByLevel: {\n    [level: string]: BoundedGreatestList<LogEntry>\n  } = fromEntries(\n    LogLevels.values.map(logLevel => [\n      logLevel,\n      new BoundedGreatestList(maxEntriesPerLevel, logEntrySorter)\n    ])\n  )\n\n  const oldestTs = Date.now() - hourMs\n  const logger = mkLogger(\"allRecentLogEntries()\")\n\n  await thenMap(recentLogFiles(), files =>\n    withBoundedConcurrency({\n      name: \"allRecentLogEntries()\",\n      laters: files.map(f => async () => {\n        try {\n          const errors: Error[] = []\n          const lr = new LogReader(f, err => errors.push(err))\n          await untilTrue(() => lr.hasFirstLine(), { timeoutMs: 10 * secondMs })\n          while (!lr.ended() && !lr.hasErrors()) {\n            const le = lr.shift()\n            if (le == null) {\n              // We exhausted the buffer. Wait for it to fill again.\n              await delay(5)\n            } else if (le.ts > oldestTs) {\n              entriesByLevel[le.l]?.add(le)\n            }\n          }\n          if (isNotEmpty(errors)) {\n            logger.warn(\"Read error(s) for \" + f, errors)\n            if (\n              errors.some(\n                (ea: any) =>\n                  ea.code === \"Z_BUF_ERROR\" ||\n                  errorToS(ea).includes(\"unexpected end of file\")\n              ) &&\n              lt(await f.mtimeMs(), Date.now() - minuteMs)\n            ) {\n              logger.warn(\"Unlinking corrupt logfile \" + f)\n              await f.unlink_()\n            }\n          }\n        } catch (err) {\n          logger.warn(\"Failed to read entries from \" + f, err)\n        }\n      })\n    })\n  )\n\n  const entries = flatten(values(entriesByLevel).map(ea => ea.vacuum()))\n  return entries.sort((a, b) => cmp(a.ts, b.ts))\n}\n", "import { execSync } from \"child_process\"\nimport { readFileSync } from \"fs\"\nimport { arch, cpus, platform, release } from \"os\"\nimport { mapNotBlankOr, notBlank } from \"../fe/Blank\"\nimport { minuteMs } from \"../fe/Date\"\nimport { lazy } from \"../fe/Lazy\"\nimport { map2Or, orElse } from \"../fe/Maybe\"\nimport { uniqCount } from \"./Array\"\nimport { parseEnvTokens } from \"./EnvTokens\"\nimport { mkLogger } from \"./Logger\"\n\nconst logger = lazy(() => mkLogger(\"os\"))\n\nexport const OS = lazy(() => [osName(), \"on\", arch()].join(\" \"))\n\nfunction osName() {\n  switch (platform()) {\n    case \"linux\":\n      return osNameLinux()\n    case \"darwin\":\n      return osNameMac()\n    case \"win32\": // doesn't mean 32 bit (BECAUSE WINDOWS)\n      return osNameWin()\n    default:\n      return osNameDefault()\n  }\n}\n\nfunction osNameDefault() {\n  return platform() + \" \" + release()\n}\n\n// Ubuntu:\n\n// NAME=\"Ubuntu\"\n// VERSION=\"20.04.1 LTS (Focal Fossa)\"\n// ID=ubuntu\n// ID_LIKE=debian\n// PRETTY_NAME=\"Ubuntu 20.04.1 LTS\"\n// VERSION_ID=\"20.04\"\n// HOME_URL=\"https://www.ubuntu.com/\"\n// SUPPORT_URL=\"https://help.ubuntu.com/\"\n// BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n// PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n// VERSION_CODENAME=focal\n// UBUNTU_CODENAME=focal\n\n// Alpine:\n\n// NAME=\"Alpine Linux\"\n// ID=alpine\n// VERSION_ID=3.11.6\n// PRETTY_NAME=\"Alpine Linux v3.11\"\n// HOME_URL=\"https://alpinelinux.org/\"\n// BUG_REPORT_URL=\"https://bugs.alpinelinux.org/\"\n\nexport function osNameLinux() {\n  try {\n    const input = readFileSync(\"/etc/os-release\").toString()\n    const t = parseEnvTokens({ input, lowerCaseKeys: true })\n    if (notBlank(t.pretty_name)) return t.pretty_name\n\n    const ver = orElse(t.version, t.version_id)\n    return map2Or(t.name, ver, (n, v) => n + \" \" + v, osNameDefault)\n  } catch (err) {\n    logger().warn(\"Failed to fetch /etc/os-release\", err)\n    return osNameDefault()\n  }\n}\n\nfunction majorMinor(ver: string): string {\n  return ver.split(\".\").slice(0, 2).join(\".\")\n}\n\nconst MacCodenames = {\n  \"10.6\": \"Snow Leopard\",\n  \"10.7\": \"Lion\",\n  \"10.8\": \"Mountain Lion\",\n  \"10.9\": \"Mavericks\",\n  \"10.10\": \"Yosemite\",\n  \"10.11\": \"El Capitan\",\n  \"10.12\": \"Sierra\",\n  \"10.13\": \"High Sierra\",\n  \"10.14\": \"Mojave\",\n  \"10.15\": \"Catalina\",\n  \"11.1\": \"Big Sur\"\n}\n\nconst macProductVersion = lazy(() =>\n  execSync(\"sw_vers -productVersion\").toString().trim()\n)\n\nfunction macCodename(productVersion = macProductVersion()) {\n  return MacCodenames[majorMinor(productVersion)]\n}\n\nexport function osNameMac(productVersion = macProductVersion()) {\n  try {\n    return mapNotBlankOr(\n      macCodename(productVersion),\n      ea => `macOS ${ea} (${productVersion})`,\n      osNameDefault\n    )\n  } catch (err) {\n    logger().warn(\"osNameMac(): unknown release\", err)\n    return osNameDefault()\n  }\n}\n\nconst WinReleaseToVersions = {\n  \"10.0\": \"10\",\n  \"6.3\": \"8.1\",\n  \"6.2\": \"8\",\n  \"6.1\": \"7\",\n  \"6.0\": \"Vista\",\n  \"5.2\": \"Server 2003\",\n  \"5.1\": \"XP\",\n  \"5.0\": \"2000\",\n  \"4.9\": \"ME\",\n  \"4.1\": \"98\",\n  \"4.0\": \"95\"\n}\n\nexport function osNameWin(r = release()) {\n  const ver = WinReleaseToVersions[majorMinor(r)]\n  if (ver != null) {\n    return `Windows ${ver} (${r})`\n  } else {\n    logger().warn(\"osNameWin(): unknown release: \" + r)\n    return `Windows (${r})`\n  }\n}\n\nexport const CPUs = lazy(\n  () =>\n    uniqCount(cpus().map(c => c.model))\n      .map(ea => `${ea.count} \u00D7 ${ea.t}`)\n      .join(\", \"),\n  minuteMs\n)\n", "import { stdout } from \"process\"\nimport { BaseFile } from \"../core/fs/BaseFile\"\nimport { mkLogger } from \"../core/Logger\"\nimport { isSyncFileService } from \"../core/ServiceNames\"\nimport { Setting } from \"../core/settings/Setting\"\nimport { Settings } from \"../core/settings/Settings\"\nimport { stdoutEnded } from \"../core/Stdout\"\nimport { notBlank } from \"../fe/Blank\"\nimport { stringify } from \"../fe/JSON\"\nimport { UpdateResult } from \"./sync-file/UpdateResult\"\n\nexport function stdoutWrite(obj: any, ready = isSyncFileService()) {\n  // No need to burp this to stdout for users:\n  if (stdoutEnded()) return\n\n  mkLogger(\"stdoutWrite\").debug(\"()\", { obj, ready })\n  // We want to emit even if we don't think something is watching us (to make\n  // tests pass):\n  stdout.write(stringify(obj) + \"\\n\")\n  // Only the sync-file service runs under batch-cluster, which will look for the `readyStr`\n  if (ready) {\n    stdout.write(ReadyStr + \"\\n\")\n  }\n}\n\nexport const ReadyStr = stringify({ ready: true })\n\nexport function stdoutWriteSettings(...arr: Setting<any>[]) {\n  const o = {}\n  for (const ea of arr) {\n    ea.addToEnv(o)\n  }\n  stdoutWrite(o)\n}\n\nexport function stdoutWriteUpdateResult(obj: UpdateResult) {\n  return stdoutWrite(obj)\n}\n\nexport function stdoutWriteMigration(migrationFile: BaseFile) {\n  return stdoutWrite({ migration: migrationFile.name })\n}\n\nexport interface MigrationEvent {\n  migration: string\n}\n\nexport function isMigrationEvent(o: any): o is MigrationEvent {\n  return o != null && notBlank(o.migration)\n}\n\nexport const StdoutWrite = {\n  pauseHealthChecks: () => stdoutWrite({ pauseHealthChecks: true }),\n  resumeHealthChecks: () => stdoutWrite({ pauseHealthChecks: false }),\n  shutdownSync: () => stdoutWrite({ shutdownSync: true }),\n\n  restartSync: () =>\n    stdoutWrite(\n      Settings.libraryPath.addToEnv({ restartSync: true, pause: false } as any)\n    ),\n  forceRestartSync: () => stdoutWrite({ forceRestartSync: true, pause: false }),\n  rebuildLibrary: () => stdoutWrite({ rebuildLibrary: true, pause: false }),\n\n  pause: () => stdoutWrite({ pause: true }),\n  resume: () => stdoutWrite({ pause: false }),\n  shutdown: () => stdoutWrite({ shutdown: true }),\n\n  sendRecentLogs: () => stdoutWrite({ sendRecentLogs: true })\n}\n", "import { Task } from \"batch-cluster\"\nimport { compactBlanks } from \"../../fe/Array\"\nimport { stringify } from \"../../fe/JSON\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { toS } from \"../../fe/toS\"\nimport { ImportResult, isErrorResult, isSuccessResult } from \"./ImportResult\"\n\nexport interface FileProcessor {\n  (nativePath: string): PromiseMaybe<ImportResult>\n}\n\nexport class NativePathImportTask extends Task<ImportResult> {\n  private readonly name: string\n\n  constructor(readonly nativePath: string) {\n    super(stringify({ file: nativePath }), input => this.parse(input))\n    this.name = `ImportTask(${nativePath})`\n  }\n\n  toString() {\n    return this.name\n  }\n\n  // NOTE: progress events are handled by SyncService's `bc.on(\"taskData\")`\n  // listener.\n\n  private parse(input: string): ImportResult {\n    for (const line of compactBlanks(toS(input).split(\"\\n\")).reverse()) {\n      const obj = JSON.parse(line)\n      if (isErrorResult(obj) || isSuccessResult(obj)) return obj\n    }\n    return {\n      path: this.nativePath,\n      error: \"INTERNAL ERROR: no result found in input\"\n    }\n  }\n}\n", "import { notBlank } from \"../../fe/Blank\"\nimport { gt0 } from \"../../fe/Number\"\n\nexport interface ImportErrorResult {\n  path: string\n  error: string\n}\n\nexport interface ImportSuccessResult {\n  path: string\n  assetId: number\n  assetFileId: number\n}\n\nexport type ImportResult = ImportErrorResult | ImportSuccessResult\n\nexport function isErrorResult(obj: any): obj is ImportErrorResult {\n  return obj != null && notBlank(obj.path) && notBlank(obj.error)\n}\n\nexport function isSuccessResult(obj: any): obj is ImportSuccessResult {\n  return (\n    obj != null &&\n    !isErrorResult(obj) &&\n    notBlank(obj.path) &&\n    gt0(obj.assetId) &&\n    gt0(obj.assetFileId)\n  )\n}\n", "import { Task } from \"batch-cluster\"\nimport { parseMaybe } from \"../../core/JSON\"\nimport { compactBlanks } from \"../../fe/Array\"\nimport { stringify } from \"../../fe/JSON\"\nimport { firstDefined } from \"../../fe/Maybe\"\nimport { toS } from \"../../fe/toS\"\nimport {\n  isUpdateErrorResult,\n  isUpdateSuccessResult,\n  UpdateResult\n} from \"./UpdateResult\"\n\nexport interface Forceable {\n  force?: boolean\n}\n\nexport interface UpdateAssetCommand extends Forceable {\n  updateAssetId: number\n  skipPreviews: boolean\n}\nexport interface UpdateAssetFileCommand extends Forceable {\n  updateAssetFileId: number\n}\nexport interface UpdateAssetPreviewCommand extends Forceable {\n  updateAssetPreviewId: number\n}\n\nexport type UpdateCommand =\n  | UpdateAssetCommand\n  | UpdateAssetFileCommand\n  | UpdateAssetPreviewCommand\n\nexport class UpdateTask extends Task<UpdateResult> {\n  private readonly id: number\n  private readonly name: string\n\n  constructor(readonly cmd: UpdateCommand) {\n    super(stringify(cmd), input => this.parse(input))\n    this.name = `UpdateTask(${stringify(cmd)})`\n    this.id = firstDefined(\n      cmd[\"updateAssetId\"],\n      cmd[\"updateAssetFileId\"],\n      cmd[\"updateAssetPreviewId\"]\n    )!\n  }\n\n  toString() {\n    return this.name\n  }\n\n  private parse(input: string): UpdateResult {\n    for (const line of compactBlanks(toS(input).split(\"\\n\")).reverse()) {\n      const obj = parseMaybe(line)\n      if (isUpdateErrorResult(obj) || isUpdateSuccessResult(obj)) return obj\n    }\n    return {\n      id: this.id,\n      error: \"INTERNAL ERROR: no result found in input: \" + input\n    }\n  }\n}\n\nexport type SyncFileCommand = UpdateCommand | { file: string; force?: boolean }\n", "import { notBlank } from \"../../fe/Blank\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { gt0 } from \"../../fe/Number\"\n\nexport interface UpdateErrorResult {\n  id: number\n  nativePath?: string\n  error: string\n}\n\nexport interface UpdateSuccessResult {\n  id: number\n  nativePath?: string\n  skipped?: boolean\n  assetIdsToUpdate?: number[]\n}\n\nexport type UpdateResult = UpdateErrorResult | UpdateSuccessResult\n\nexport type AssetUpdater = (assetId: number) => PromiseMaybe<UpdateResult>\nexport type AssetFileUpdater = (\n  assetFileId: number\n) => PromiseMaybe<UpdateResult>\n\nexport function isUpdateErrorResult(obj: any): obj is UpdateErrorResult {\n  return obj != null && gt0(obj.id) && notBlank(obj.error)\n}\n\nexport function isUpdateSuccessResult(obj: any): obj is UpdateSuccessResult {\n  return !isUpdateErrorResult(obj) && obj != null && gt0(obj.id)\n}\n", "import { compact } from \"../../fe/Array\"\nimport { minuteMs, weekMs } from \"../../fe/Date\"\nimport { fmtDuration } from \"../../fe/fmtDuration\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { lt } from \"../../fe/Number\"\nimport { mkLogger } from \"../Logger\"\nimport { mapGt0 } from \"../Number\"\nimport { Average } from \"./Average\"\nimport { avg } from \"./Vector\"\n\nexport class ETA {\n  private readonly remainingMs = new Average(10)\n  private readonly logger = mkLogger(\"ETA\")\n\n  push(ms: Maybe<number>) {\n    mapGt0(ms, ea => this.remainingMs.push(ea))\n  }\n\n  clear() {\n    this.remainingMs.clear()\n  }\n\n  avg() {\n    return avg(\n      compact([this.remainingMs.weightedSampleAvg, this.remainingMs.sampleMode])\n    )\n  }\n\n  fmtEstimate(delta = 1): Maybe<string> {\n    return mapGt0(this.avg(), ea => {\n      const eta = ea * delta\n      if (eta < minuteMs) {\n        return \"less than a minute remains\"\n      }\n      if (\n        // no crazy-long estimates:\n        eta < weekMs &&\n        // No wildly-fluctuating estimates. 1 sigma should\n        // be < 1/3 mean (people may be irritated with higher fluctuations)\n        lt(this.remainingMs.sampleStdDev, ea / 5)\n      ) {\n        return (\n          \"about \" +\n          fmtDuration(eta, 1, { plural: \"remains\", singular: \"remain\" })\n        )\n      } else {\n        this.logger.debug(\n          \"Skipping remaining, avgMillisRemaining is too wiggly\",\n          {\n            avg: eta,\n            ...this.remainingMs.stats()\n          }\n        )\n        return\n      }\n    })\n  }\n}\n", "import { strEnum, StrEnumKeys } from \"../StrEnum\"\n\nexport const SyncStatuses = strEnum(\"processing\", \"paused\", \"done\")\nexport type SyncStatus = StrEnumKeys<typeof SyncStatuses>\n\nexport interface Percents {\n  /**\n   * Percent of the found assets that have been processed\n   */\n  completePct?: number\n  /**\n   * Percent of the found assets that remain to be processed\n   */\n  incompletePct?: number\n  /**\n   * Percent of the current volume that has not yet been scanned\n   */\n  scanningPct?: number\n}\n\n// Called \"ProgressState\" rather than \"SyncState\" because it sometimes holds\n// \"oes noes I'm paused\" or \"hey I'm starting now yay\"\nexport interface ProgressState extends Percents {\n  uri?: string\n  /** \"C:\" or \"/homes/matthew/Pictures\" */\n  volume: string\n  state?: SyncStatus\n  /** heading for the progress panel */\n  hed?: string\n  dek?: string[]\n}\n\nexport interface ProgressStateWithAssets extends ProgressState {\n  recentAssetIds: number[]\n}\n\nexport const ProgressWithAssetsProps: (keyof ProgressStateWithAssets)[] = [\n  \"uri\",\n  \"volume\",\n  \"state\",\n  \"hed\",\n  \"dek\",\n  \"completePct\",\n  \"incompletePct\",\n  \"scanningPct\",\n  \"recentAssetIds\"\n]\n\nexport const RebuildingURI = \"rebuilding://\"\n", "import { Knex } from \"knex\"\nimport { EndableRanks, ending } from \"../../core/async/Endable\"\nimport { EndableWrapper } from \"../../core/async/EndableWrapper\"\nimport { thenOrElse } from \"../../core/async/Promise\"\nimport { ETA } from \"../../core/math/ETA\"\nimport { max } from \"../../core/math/Vector\"\nimport { groupBy } from \"../../core/MultiMap\"\nimport { RebuildingURI } from \"../../fe/api/ProgressState\"\nimport { TagRoots } from \"../../fe/api/Tag\"\nimport { isNotEmpty } from \"../../fe/Array\"\nimport { mapNotBlankOr } from \"../../fe/Blank\"\nimport { delay } from \"../../fe/Delay\"\nimport { Latch } from \"../../fe/Latch\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { sigFigs } from \"../../fe/Number\"\nimport { fmt } from \"../../fe/Units\"\nimport { addFileUriTagsToAsset } from \"../curators/FilePathTagger\"\nimport { AssetFile } from \"../model/AssetFile\"\nimport { Operation } from \"../model/Operation\"\nimport { Progress } from \"../model/Progress\"\nimport { Sync } from \"./Sync\"\n\nexport class DirectoryTaggerOperation extends EndableWrapper implements Sync {\n  readonly start = Date.now()\n  private readonly _eta = new ETA()\n  readonly _done = new Latch()\n  private doneCount: Maybe<number>\n  private todoCount: Maybe<number>\n\n  constructor(readonly priorProgress?: Progress) {\n    super(\"TagAssetsWithFiles\", () => null, EndableRanks.first)\n    void this._done.observeQuietly(\n      Operation.applyOnce(\n        { name: \"applyNewTagger\", value: TagRoots.FS, version: 1 },\n        () => this._run()\n      )\n    )\n  }\n\n  done() {\n    return !this._done.pending\n  }\n\n  donePromise() {\n    return this._done.promise\n  }\n\n  readonly _progress = lazy(\n    () =>\n      thenOrElse(this.priorProgress, () =>\n        Progress.insertNew(RebuildingURI, \"\uD83D\uDD04\")\n      )\n    // NO TTL! This needs to be the same instance for the same process.\n  )\n\n  async progress() {\n    if (this.done()) {\n      return (await this._progress()).assignFromPojo({\n        state: \"done\",\n        hed: \"Finished rebuilding your library \uD83C\uDF89\",\n        dek: [],\n        completePct: 100,\n        incompletePct: 0,\n        scanningPct: 0\n      })\n    }\n    const eta = this.eta()\n    if (eta == null || this.doneCount == null || this.todoCount == null) return\n\n    const p = await this._progress()\n\n    const complete = this.doneCount / (this.todoCount + this.doneCount)\n    const completePct = sigFigs(100 * complete, 2)\n    const est = this._eta.fmtEstimate()\n    const hed =\n      `Adding ${TagRoots.FS} tags to your library` +\n      mapNotBlankOr(est, ea => \", \" + ea, \"\u2026\")\n    return p.assignFromPojo({\n      state: \"processing\",\n      hed,\n      dek: [\n        `Tagged ${fmt(this.doneCount)} URIs, ${fmt(this.todoCount)} remain.`\n      ],\n      completePct,\n      incompletePct: 100 - completePct,\n      scanningPct: 0 // everything's been scanned, so 0.\n    })\n  }\n\n  eta() {\n    if (\n      this.todoCount == null ||\n      this.doneCount == null ||\n      this.todoCount === 0\n    )\n      return undefined\n    const elapsedMs = Date.now() - this.start\n    const msPerItem = elapsedMs / this.doneCount\n    const msRemaining = msPerItem * this.todoCount\n    this._eta.push(msRemaining)\n    return this._eta.avg()\n  }\n\n  private async _run() {\n    this.todoCount = await AssetFile.dbl.pluckFirstf<number>(q =>\n      onlyShownAssetFiles(q.countDistinct(\"AssetFile.id\"))\n    )\n    this.doneCount = 0\n    return AssetFile.dbl.batched<{\n      assetId: number\n      assetFileId: number\n      uri: string\n    }>({\n      onResults: async arr => {\n        for (const byAsset of groupBy(arr, ea => ea.assetId).values()) {\n          if (ending()) return\n          await addFileUriTagsToAsset(\n            byAsset[0].assetId,\n            byAsset.map(ea => ea.uri)\n          )\n          this.doneCount! += byAsset.length\n          this.todoCount! -= byAsset.length\n        }\n        await delay(5) // < allow other things to run every batch\n      },\n      qb: (qb, priors) => {\n        qb = onlyShownAssetFiles(\n          qb.select({\n            assetId: \"AssetFile.assetId\",\n            assetFileId: \"AssetFile.id\",\n            uri: \"AssetFile.uri\"\n          })\n        )\n        if (isNotEmpty(priors)) {\n          qb = qb.andWhere(\n            \"AssetFile.id\",\n            \">\",\n            max(priors.map(ea => ea.assetFileId))!\n          )\n        }\n        return qb\n      }\n    })\n  }\n}\n\nfunction onlyShownAssetFiles(qb: Knex.QueryBuilder) {\n  return qb\n    .from(\"AssetFile\")\n    .join(\"Asset\", \"Asset.id\", \"AssetFile.assetId\")\n    .where(\"Asset.shown\", 1)\n    .andWhere(\"Asset.excluded\", 0)\n    .andWhere(\"Asset.hidden\", 0)\n}\n", "import { EventEmitter } from \"events\"\nimport { Endable, EndableRanks, ending } from \"../core/async/Endable\"\nimport { EndableWrapper } from \"../core/async/EndableWrapper\"\nimport { Promises } from \"../core/async/Promises\"\nimport { time } from \"../core/async/PromiseTimer\"\nimport { untilTrue } from \"../core/async/until\"\nimport { emitIdle } from \"../core/event/EventEmitter\"\nimport { prngOrderByClause } from \"../core/math/PRNG\"\nimport { Rate } from \"../core/math/Rate\"\nimport { TTLArray } from \"../core/TTLArray\"\nimport {\n  addIdleListener,\n  IdleListener,\n  removeIdleListener\n} from \"../core/work/Idle\"\nimport { maxPendingSyncFileJobs } from \"../core/work/MaxCpus\"\nimport { isPaused } from \"../core/work/WorkPlanner\"\nimport { compact, isNotEmpty } from \"../fe/Array\"\nimport { minuteMs, secondMs } from \"../fe/Date\"\nimport { later } from \"../fe/Delay\"\nimport { lazy } from \"../fe/Lazy\"\nimport { map, orElse } from \"../fe/Maybe\"\nimport { Maybe } from \"../fe/MaybeTypes\"\nimport { sigFigs } from \"../fe/Number\"\nimport { SyncOrAsync } from \"../fe/OptAsync\"\nimport { prngSeed } from \"../fe/PRNG\"\nimport { Queue, WorkItem } from \"./stats/Queue\"\nimport { QueueItem } from \"./stats/QueueItem\"\n\n/**\n * Class that feeds work from a Queue to SyncFile jobs.\n *\n * Used for importing new files and updating assets and asset files.\n */\nexport class WorkQueue extends EndableWrapper implements Endable, IdleListener {\n  readonly processRate = new Rate(2 * minuteMs)\n  readonly ee = new EventEmitter()\n  private _maxQueueSize: number\n  private _queueIsEmpty = false\n  private readonly nextMutex = new Promises()\n\n  // currently-in-progress work items:\n  private readonly workItems = new Promises<QueueItem>()\n\n  readonly recentlyProcessed = new TTLArray<string>(10 * secondMs)\n\n  /**\n   * It's up to the caller to addIdleListener(this).\n   *\n   * @param _itemIsReady `true` if the given item can run\n   */\n  constructor(\n    readonly queueNames: string[],\n    private readonly _itemIsReady: (qi: QueueItem) => SyncOrAsync<boolean>,\n    private readonly _processItem: (qi: QueueItem) => SyncOrAsync<any>,\n    private readonly _singleThreaded = false,\n    private readonly _currentWorkQueueLength: () => number\n  ) {\n    super(\n      `WorkQueue(${queueNames.sort().join(\",\")})`,\n      () => removeIdleListener(this.name),\n      EndableRanks.first\n    )\n    this._maxQueueSize = this._singleThreaded ? 1 : maxPendingSyncFileJobs()\n\n    this.resume()\n  }\n\n  on(event: \"processed\", listener: (qi: QueueItem) => void) {\n    this.ee.addListener(event, listener)\n  }\n\n  resume() {\n    addIdleListener(this)\n    return this\n  }\n\n  pause() {\n    removeIdleListener(this.name)\n    return this\n  }\n\n  readonly queues = lazy(() =>\n    Queue.ops().upsert(this.queueNames.map(name => ({ name })))\n  )\n\n  readonly queueIds = lazy(() =>\n    this.queues().then(arr => arr.map(ea => ea.id!))\n  )\n\n  async donePromise() {\n    await untilTrue(\n      async () => {\n        await this.pendingWorkCount.refresh()\n        return this.done()\n      },\n      { timeoutMs: undefined, timeBetweenMs: 2 * secondMs }\n    )\n  }\n\n  done() {\n    return (\n      this.ended ||\n      (this._queueIsEmpty && this.nextMutex.settled && this.workItems.settled)\n    )\n  }\n\n  get runnable() {\n    return (\n      !isPaused() &&\n      !ending() &&\n      !this.done() &&\n      !this.ended &&\n      !this._queueIsEmpty &&\n      this.currentWorkCount() < this._maxQueueSize\n    )\n  }\n\n  async enqueueWork(items: WorkItem[], queueName?: string) {\n    if (isNotEmpty(items)) {\n      const arr = await this.queues()\n      const q = orElse(\n        map(queueName, name => arr.find(ea => ea.name === name)),\n        arr[0]\n      )\n      await q.upsertWorkItemsQuietly(items)\n      this.logger.debug(\"enqueueWork()\", { items })\n    }\n    this._queueIsEmpty = false\n    this.pendingWorkCount.unset()\n    later(() => emitIdle())\n  }\n\n  async dequeue(item: QueueItem) {\n    await item.delete()\n    // invalidate the caches:\n    this.pendingWorkCount.unset()\n    this._queueIsEmpty = false\n  }\n\n  get recentFileProgress(): Maybe<string> {\n    return map(this.recentlyProcessed.shiftOrFirst(), ea => \"Processed \" + ea)\n  }\n\n  currentQueueItems() {\n    return this.workItems.pendingNames()\n  }\n\n  doneCount() {\n    return this.processRate.eventCount\n  }\n\n  async todoCount() {\n    return this.workItems.pendingCount + (await this.pendingWorkCount())\n  }\n\n  currentWorkCount() {\n    // if we're *internally* single-threaded, we don't have to wait for the\n    // queue to be empty before doing work:\n    return this._singleThreaded\n      ? this.workItems.pendingCount\n      : // the current work queue length should always be >= this.pendingCount.\n        Math.max(this.workItems.pendingCount, this._currentWorkQueueLength())\n  }\n\n  readonly pendingWorkCount = lazy(async () => {\n    const queueIds = await this.queueIds()\n    const result = (await QueueItem.dbl.pluckFirstf(qb =>\n      qb.whereIn(\"queueId\", queueIds).count()\n    )) as number\n    this._queueIsEmpty = result === 0\n    return result\n  }, secondMs)\n\n  async percents() {\n    const done = this.doneCount()\n    const todo = await this.todoCount()\n    // this.eta.push(mapGt0(this.processRate.msPerEvent, ea => ea * todo))\n    const completePct = sigFigs(100 * (done / (todo + done)), 2)\n    return { done, todo, completePct, incompletePct: 100 - completePct }\n  }\n\n  private currentQueueItemIds() {\n    return this.currentQueueItems().map(ea => ea.id!)\n  }\n\n  async onIdle() {\n    return this.next()\n  }\n\n  async peek(limit = this._maxQueueSize * 3, random: boolean) {\n    const queueIds = await this.queueIds()\n    let q = QueueItem.query()\n      .whereIn(\"queueId\", queueIds)\n      .whereNotIn(\"id\", this.currentQueueItemIds())\n      .limit(limit) // this should be large enough to find assets that won't collide with current advisory locks\n    if (random) {\n      q = q.orderByRaw(prngOrderByClause(prngSeed(), \"id\", 500))\n    }\n    return QueueItem.ops().all(q)\n  }\n\n  private async next() {\n    return !this.runnable\n      ? undefined\n      : this.nextMutex.maybeRun(this.name + \".next()\", () => this._next())\n  }\n\n  // Must be called serially:\n  private async _next(random = false) {\n    if (!this.runnable) return\n    const items = await this.peek(this._maxQueueSize * 3, random)\n\n    if (items.length === 0) {\n      this.logger.info(\"_next(): peek was currently empty\")\n      this._queueIsEmpty = true\n      return\n    }\n\n    let workSlotsRemaining = this._maxQueueSize - this.currentWorkCount()\n    this.logger.debug(\"_next()\", {\n      random,\n      workSlotsRemaining,\n      eligibleItemCount: items.length\n    })\n\n    while (\n      !isPaused() &&\n      !ending() &&\n      !this.ended &&\n      workSlotsRemaining > 0 &&\n      isNotEmpty(items)\n    ) {\n      const item = items.shift()!\n      if (await this._itemIsReady(item)) {\n        this._queueIsEmpty = false\n        workSlotsRemaining--\n        const desc = compact([\n          \"q.\" + this.constructor.name + \".process\",\n          item.type\n        ]).join(\".\")\n        this.logger.info(\"starting \" + item.contents, { workSlotsRemaining })\n        void this.workItems.push(item, async () => {\n          try {\n            this.processRate.onEvent()\n            await time(\n              desc,\n              () => this._processItem(item),\n              (_result, elapsed) =>\n                this.logger.info(\"finished processing\", { elapsed, ...item })\n            )\n            this.ee.emit(\"processed\", item)\n          } catch (err) {\n            this.logger.warn(\"failed processing\", item)\n          } finally {\n            await this.dequeue(item)\n            later(emitIdle, 2)\n          }\n        })\n      }\n    }\n    if (!random && workSlotsRemaining > 0) {\n      // try to fill with anything from the work queue:\n      await this._next(true)\n    }\n  }\n}\n", "import { Schema } from \"../db/Schema\"\nimport { TimestampedModel } from \"../model/TimestampedModel\"\nimport { statsDb } from \"./StatsDb\"\n\nexport class StatsModel extends TimestampedModel {\n  static readonly schema: Schema = \"stats\"\n  static readonly db = statsDb\n}\n", "import { TableName } from \"../model/TableName\"\nimport { StatsModel } from \"./StatsModel\"\n\nexport class QueueItem extends StatsModel {\n  static tableName: TableName = \"QueueItem\"\n  static readonly uniqueColumnName = \"queueId,contents\"\n  id!: number\n  queueId!: number\n  contents!: string\n  type?: string\n}\n", "import { thenOrElse } from \"../../core/async/Promise\"\nimport {\n  AssetFileVersion,\n  AssetVersion\n} from \"../../core/PhotoStructureVersions\"\nimport { stripPrefix } from \"../../core/String\"\nimport { TableName } from \"../model/TableName\"\nimport { QueueItem } from \"./QueueItem\"\nimport { StatsModel } from \"./StatsModel\"\n\nexport type WorkItem = Pick<QueueItem, \"contents\" | \"type\">\n\nexport function assetFileUpdatesUri2QueueName(uri: string) {\n  return `assetFileUpdates:${AssetFileVersion}:${uri}`\n}\n\nexport function assetFileUpdatesQueueName2uri(queueName: string) {\n  return stripPrefix(queueName, assetFileUpdatesUri2QueueName(\"\"))\n}\nexport function assetUpdatesUri2QueueName(uri: string) {\n  return `assetUpdates:${AssetVersion}:${uri}`\n}\nexport function assetUpdatesQueueName2uri(queueName: string) {\n  return stripPrefix(queueName, assetUpdatesUri2QueueName(\"\"))\n}\n\nexport class Queue extends StatsModel {\n  static tableName: TableName = \"Queue\"\n  static readonly uniqueColumnName = \"name\"\n  id!: number\n  name!: string\n\n  static itemCountForQueues(queueNames: string[]) {\n    return thenOrElse(\n      QueueItem.dbl.pluckFirstf(q =>\n        q\n          .countDistinct(\"QueueItem.id\")\n          .join(\"Queue\", \"Queue.id\", \"QueueItem.queueId\")\n          .whereIn(\"Queue.name\", queueNames)\n      ),\n      () => 0\n    )\n  }\n\n  itemCount() {\n    return QueueItem.dbl.pluckFirstf(q =>\n      q.where({ queueId: this.id! }).count()\n    )\n  }\n\n  async upsertWorkItemsQuietly(workItems: WorkItem[]): Promise<void> {\n    await QueueItem.ops().upsert(\n      workItems.map(ea => ({ queueId: this.id!, ...ea })),\n      true\n    )\n  }\n\n  upsertWorkItems(workItems: WorkItem[]): Promise<QueueItem[]> {\n    const arr = workItems.map(ea => ({ queueId: this.id!, ...ea }))\n    this.logger().info(\"upserting into queue \" + this.name, workItems)\n    return QueueItem.ops().upsert(arr)\n  }\n}\n", "import { Knex } from \"knex\"\nimport { mkLogger } from \"../../core/Logger\"\nimport { max } from \"../../core/math/Vector\"\nimport {\n  AssetFileVersion,\n  AssetVersion\n} from \"../../core/PhotoStructureVersions\"\nimport { nativePath2uri } from \"../../core/uri/FileURI\"\nimport { PSLIB_ROOT_URI } from \"../../core/uri/pslib\"\nimport { volumes } from \"../../core/volumes/Volumes\"\nimport { isNotEmpty } from \"../../fe/Array\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { thenCollect } from \"../../fe/Promise\"\nimport { toS } from \"../../fe/toS\"\nimport { Asset } from \"../model/Asset\"\nimport { AssetFile } from \"../model/AssetFile\"\nimport { Operation, OperationNames } from \"../model/Operation\"\nimport {\n  assetFileUpdatesQueueName2uri,\n  assetUpdatesUri2QueueName,\n  Queue\n} from \"../stats/Queue\"\n\nfunction addIdsToQueue(q: Queue, ids: number[]) {\n  return q.upsertWorkItemsQuietly(ids.map(ea => ({ contents: toS(ea) })))\n}\n\nexport async function currentUriRoots(): Promise<string[]> {\n  const uris = await thenCollect(volumes(), async vol =>\n    nativePath2uri(vol.mountpoint, vol)\n  )\n  return [...uris, PSLIB_ROOT_URI].map(toS)\n}\n\nexport async function enqueueAssetFileUpdates(): Promise<string[]> {\n  return thenCollect(currentUriRoots(), enqueueAssetFileUpdatesForUri)\n}\n\nasync function enqueueAssetFileUpdatesForUri(uri: string) {\n  const log = mkLogger(\"enqueueAssetFileUpdatesForUri(\" + uri + \")\")\n  // Always make the queue:\n  const queue = await Queue.ops().upsertOne({\n    name: assetFileUpdatesQueueName2uri(uri)\n  })\n  // Only enqueue new files once:\n  await Operation.applyOnce(\n    {\n      name: OperationNames.enqueueAssetFileUpdates,\n      version: AssetFileVersion,\n      value: uri\n    },\n    () => {\n      log.info(\"starting\", { queue: queue.name })\n      return AssetFile.dbl.pluckBatched({\n        onResults: async (arr: number[]) => addIdsToQueue(queue, arr),\n        qb: (qb: Knex.QueryBuilder, priors: Maybe<number[]>) => {\n          qb = qb\n            .select(\"id\")\n            .orderBy(\"id\", \"asc\")\n            .where(\"version\", \"<\", AssetFileVersion)\n            .andWhere(\"uri\", \"like\", uri + \"%\")\n          if (isNotEmpty(priors)) {\n            qb = qb.andWhere(\"id\", \">\", max(priors)!)\n          }\n          return qb\n        }\n      })\n    }\n  )\n  // Only return the queue if there's work previously enqueued, or were just enqueued:\n  const assetFileCount = await queue.itemCount()\n  log.info(\"Added outdated assetFiles:\", {\n    queue: queue.name,\n    assetFileCount\n  })\n\n  return assetFileCount > 0 ? queue.name : undefined\n}\n\nexport async function outdatedAssetCount() {\n  const uris = await currentUriRoots()\n  return Asset.dbl.pluckFirstf<number>(q =>\n    q\n      .count(\"Asset.id\")\n      .distinct()\n      .leftJoin(\"AssetFile\", \"AssetFile.assetId\", \"Asset.id\")\n      .where(\"Asset.version\", \"<\", AssetVersion)\n      .andWhere(q2 =>\n        uris.forEach(uri => q2.where(\"AssetFile.uri\", \"like\", uri + \"%\"))\n      )\n  )\n}\n\nexport async function enqueueAssetUpdates() {\n  return thenCollect(currentUriRoots(), enqueueAssetUpdatesForUri)\n}\n\nexport async function enqueueAssetUpdatesForUri(uri: string) {\n  const log = mkLogger(\"enqueueAssetUpdatesForUri(\" + uri + \")\")\n  const queue = await Queue.ops().upsertOne({\n    name: assetUpdatesUri2QueueName(uri)\n  })\n\n  await Operation.applyOnce(\n    {\n      name: OperationNames.enqueueAssetUpdates,\n      version: AssetVersion,\n      value: uri\n    },\n    () => {\n      log.info(\"starting\", { queue })\n      return Asset.dbl.pluckBatched({\n        onResults: arr => addIdsToQueue(queue, arr),\n        qb: (qb: Knex.QueryBuilder, priors: Maybe<number[]>) => {\n          qb = qb\n            .select(\"Asset.id\")\n            .distinct()\n            .leftJoin(\"AssetFile\", \"AssetFile.assetId\", \"Asset.id\")\n            .orderBy(\"Asset.id\", \"asc\")\n            .where(\"Asset.version\", \"<\", AssetVersion)\n            .andWhere(\"AssetFile.uri\", \"like\", uri + \"%\")\n          if (isNotEmpty(priors)) {\n            qb = qb.andWhere(\"Asset.id\", \">\", max(priors)!)\n          }\n          return qb\n        }\n      })\n    }\n  )\n  const assetCount = await queue.itemCount()\n  log.info(\"Added outdated assets:\", {\n    queue: queue.name,\n    assetCount\n  })\n\n  return assetCount > 0 ? queue.name : undefined\n}\n", "import { thenMap } from \"../../core/async/Promise\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { map } from \"../../fe/Maybe\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { toInt } from \"../../fe/Number\"\nimport { QueueItem } from \"../stats/QueueItem\"\nimport { AssetFileUpdater } from \"../sync-file/UpdateResult\"\nimport { WorkQueue } from \"../WorkQueue\"\nimport { enqueueAssetFileUpdates, enqueueAssetUpdates } from \"./UpdateQueue\"\n\nexport class AssetFileUpdateQueue extends WorkQueue {\n  static async for(\n    assetFileUpdater: AssetFileUpdater,\n    currentWorkQueueLength: () => number\n  ): PromiseMaybe<AssetFileUpdateQueue> {\n    // we schedule the affected assets *now*, before the asset files get upgraded:\n    await enqueueAssetUpdates()\n    return Settings.skipAssetFileUpdates.valueOrDefault\n      ? undefined\n      : thenMap(\n          enqueueAssetFileUpdates(),\n          queueNames =>\n            new AssetFileUpdateQueue(\n              queueNames,\n              assetFileUpdater,\n              currentWorkQueueLength\n            )\n        )\n  }\n\n  constructor(\n    queueNames: string[],\n    readonly assetFileUpdater: AssetFileUpdater,\n    currentWorkQueueLength: () => number\n  ) {\n    super(\n      queueNames,\n      () => true, // < asset files can run in parallel.\n      qi => this.processItem(qi),\n      false, // not singlethreaded\n      currentWorkQueueLength\n    )\n    void this.donePromise().then(() => this.end())\n  }\n\n  private async processItem(qi: QueueItem) {\n    const result = await this.assetFileUpdater(toInt(qi.contents)!)\n    map(result?.nativePath, ea => this.recentlyProcessed.push(ea))\n  }\n}\n", "import { map } from \"../../fe/Maybe\"\nimport { toInt } from \"../../fe/Number\"\nimport { QueueItem } from \"../stats/QueueItem\"\nimport { WorkQueue } from \"../WorkQueue\"\n\nexport const AssetPreviewQueueName = \"AssetPreview\"\n\nexport class AssetPreviewQueue extends WorkQueue {\n  constructor(\n    readonly repairAssetPreviews: (\n      assetId: number,\n      force: boolean\n    ) => Promise<any>,\n    currentWorkQueueLength: () => number\n  ) {\n    super(\n      [AssetPreviewQueueName],\n      () => true, // embarrassingly parallelizable\n      qi => this.processItem(qi),\n      false, // not single-threaded\n      currentWorkQueueLength\n    )\n  }\n\n  private async processItem(qi: QueueItem) {\n    const assetId = toInt(qi.contents)\n    this.logger.info(\"processItem\", { assetId, qi })\n    const result = await this.repairAssetPreviews(assetId!, false)\n    map(result?.path, ea => this.recentlyProcessed.push(ea))\n  }\n}\n", "import { thenMap } from \"../../core/async/Promise\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { map } from \"../../fe/Maybe\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { toInt } from \"../../fe/Number\"\nimport { QueueItem } from \"../stats/QueueItem\"\nimport { AssetUpdater } from \"../sync-file/UpdateResult\"\nimport { WorkQueue } from \"../WorkQueue\"\nimport { enqueueAssetUpdates } from \"./UpdateQueue\"\n\nexport class AssetUpdateQueue extends WorkQueue {\n  static async for(\n    assetUpdater: AssetUpdater,\n    currentWorkQueueLength: () => number\n  ): PromiseMaybe<AssetUpdateQueue> {\n    return Settings.skipAssetUpdates.valueOrDefault\n      ? undefined\n      : thenMap(\n          enqueueAssetUpdates(),\n          queueNames =>\n            new AssetUpdateQueue(\n              queueNames,\n              assetUpdater,\n              currentWorkQueueLength\n            )\n        )\n  }\n\n  private constructor(\n    queueNames: string[],\n    readonly assetUpdater: AssetUpdater,\n    currentWorkQueueLength: () => number\n  ) {\n    super(\n      queueNames,\n      () => true, // we only run one at a time. FIXME?\n      qi => this.processItem(qi),\n      true, // singlethreaded\n      currentWorkQueueLength\n    )\n\n    // TODO: FIXME: To make this multi-threaded, we need to look at all asset\n    // files with the same SHA, same captured at, and pre-acquiring all the\n    // advisory locks to prevent asset mutation collisions)\n\n    void this.donePromise().then(() => this.end())\n  }\n\n  private async processItem(qi: QueueItem) {\n    const result = await this.assetUpdater(toInt(qi.contents)!)\n    map(result?.nativePath, ea => this.recentlyProcessed.push(ea))\n  }\n}\n", "import { EndableRanks, endAll, ending } from \"../../core/async/Endable\"\nimport { EndableWrapper } from \"../../core/async/EndableWrapper\"\nimport { onError } from \"../../core/error/Error\"\nimport { ETA } from \"../../core/math/ETA\"\nimport { mapGt0 } from \"../../core/Number\"\nimport { idleStats } from \"../../core/work/Idle\"\nimport { RebuildingURI } from \"../../fe/api/ProgressState\"\nimport { compactBlanks, mapNotEmpty, uniq } from \"../../fe/Array\"\nimport { mapNotBlankOr } from \"../../fe/Blank\"\nimport { isTrue } from \"../../fe/Boolean\"\nimport { secondMs } from \"../../fe/Date\"\nimport { Latch } from \"../../fe/Latch\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { mapOr, orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { gt0, sigFigs } from \"../../fe/Number\"\nimport { toS } from \"../../fe/toS\"\nimport { fmt } from \"../../fe/Units\"\nimport { Library } from \"../Library\"\nimport { Asset } from \"../model/Asset\"\nimport { Progress } from \"../model/Progress\"\nimport {\n  AssetFileUpdater,\n  AssetUpdater,\n  isUpdateSuccessResult\n} from \"../sync-file/UpdateResult\"\nimport { AssetFileUpdateQueue } from \"./AssetFileUpdateQueue\"\nimport { AssetPreviewQueue } from \"./AssetPreviewQueue\"\nimport { AssetUpdateQueue } from \"./AssetUpdateQueue\"\nimport { Sync } from \"./Sync\"\nimport { outdatedAssetCount } from \"./UpdateQueue\"\n\n/**\n * Updating file metadata...\n * Refreshing assets and previews...\n */\nexport class ModelDbUpdater extends EndableWrapper implements Sync {\n  readonly name = \"ModelDbUpdater\"\n  readonly _done = new Latch()\n  readonly eta = new ETA()\n  readonly updatedAssetIds = new Set<number>()\n\n  private afq: Maybe<AssetFileUpdateQueue>\n  private pq: Maybe<AssetPreviewQueue>\n  private aq: Maybe<AssetUpdateQueue>\n\n  constructor(\n    readonly opts: {\n      assetFileUpdater: AssetFileUpdater\n      assetUpdater: AssetUpdater\n      assetPreviewUpdater: (assetId: number) => any\n      currentWorkQueueLength: () => number\n    }\n  ) {\n    super(\"ModelDbUpdater\", () => this.onEnd(), EndableRanks.first)\n    void this.run()\n  }\n\n  readonly _progress = lazy(\n    () => Progress.insertNew(RebuildingURI, \"\uD83D\uDD04\")\n    // NO TTL! This needs to be the same instance for the same process.\n  )\n\n  readonly saveSyncProgress = lazy(\n    () => Progress.saveSyncState(this),\n    // lazy with 1s db write throttle:\n    secondMs\n  )\n\n  private async run() {\n    try {\n      if (this.ended || ending()) return\n\n      // this should be a no-op (SyncService.setup should have awaited it\n      // already):\n      await Library.instanceRequired().ready\n\n      this.afq = await AssetFileUpdateQueue.for(\n        this.opts.assetFileUpdater,\n        this.opts.currentWorkQueueLength\n      )\n\n      this.logger.info(\"Starting asset file updates\", {\n        afqName: this.afq?.name,\n        afqEnded: this.afq?.ended,\n        afqRunnable: this.afq?.runnable,\n        idleStats: await idleStats()\n      })\n\n      await this.afq?.donePromise()\n\n      this.logger.info(\"Completed asset file updates\", {\n        afqName: this.afq?.name,\n        afqEnded: this.afq?.ended,\n        afqRunnable: this.afq?.runnable,\n        idleStats: await idleStats()\n      })\n\n      await this.afq?.end()\n\n      this.eta.clear()\n      await this.saveSyncProgress()\n\n      if (this.ended || ending()) return\n\n      // pq will be getting jobs from aq, so it needs to be started first...\n      this.pq = new AssetPreviewQueue(\n        this.opts.assetPreviewUpdater,\n        this.opts.currentWorkQueueLength\n      )\n\n      this.aq = await AssetUpdateQueue.for(\n        this.assetUpdater,\n        this.opts.currentWorkQueueLength\n      )\n\n      this.logger.info(\"Starting asset updates\", {\n        aqName: this.aq?.name,\n        aqEnded: this.aq?.ended,\n        aqRunnable: this.aq?.runnable,\n        idleStats: await idleStats()\n      })\n\n      await this.aq?.donePromise()\n      await this.saveSyncProgress()\n\n      await this.aq?.end()\n\n      // and don't check that pq is done until aq is completed.\n      await this.pq?.donePromise()\n      await this.pq?.end()\n\n      // Make sure the \"we're done now\" progress gets persisted:\n      await this.saveSyncProgress.refresh()\n\n      this.logger.info(\"run(): finished\")\n\n      if (!this.ended) {\n        // We only mark _done on completion:\n        void this._done.resolve()\n        await Progress.saveSyncState(this)\n      }\n    } catch (err) {\n      onError(\"ModelDbUpdater.run() failed\", err)\n      void this._done.reject(err)\n    }\n  }\n\n  private readonly _outdatedAssetCount = lazy(() => outdatedAssetCount())\n\n  outdatedAssetCount() {\n    return mapOr(\n      this.aq,\n      aq => aq.pendingWorkCount(),\n      () => this._outdatedAssetCount()\n    )\n  }\n\n  private readonly assetUpdater = async (assetId: number) => {\n    const result = await this.opts.assetUpdater(assetId)\n    this.updatedAssetIds.add(assetId)\n    this.logger.info(\"ModelDbUpdater.assetUpdater(\" + assetId + \")\", { result })\n\n    if (isUpdateSuccessResult(result)) {\n      if (!isTrue(result.skipped)) {\n        await this.pq!.enqueueWork([{ contents: toS(assetId) }])\n      }\n\n      await mapNotEmpty(result?.assetIdsToUpdate, async ids => {\n        // Don't update the same asset on the same rebuild run:\n        const newIds = ids.filter(id => !this.updatedAssetIds.has(id))\n        await Asset.dbl.runf(q =>\n          q.whereIn(\"id\", newIds).update({ version: 0 })\n        )\n        if (this.aq == null || this.aq.ended) {\n          this.logger.warn(\n            \"non-empty assetIdsToUpdate, and AssetQueue is null/ended\"\n          )\n        } else {\n          await this.aq.enqueueWork(newIds.map(ea => ({ contents: toS(ea) })))\n        }\n      })\n    }\n\n    return result\n  }\n\n  private async onEnd() {\n    // NOTE: DO NOT resolve this._done here! end() does not mean done!\n    await endAll(this.afq, this.pq, this.aq)\n    this.afq = this.pq = this.aq = undefined\n  }\n\n  isNoOp() {\n    return (\n      !gt0(this.afq?.doneCount()) &&\n      !gt0(this.pq?.doneCount()) &&\n      !gt0(this.aq?.doneCount())\n    )\n  }\n\n  done() {\n    return !this._done.pending\n  }\n\n  donePromise() {\n    return this._done.promise\n  }\n\n  async progress() {\n    // We might not need to have done anything. If the queues are empty, return\n    // undefined.\n    if (this.ended || this.isNoOp()) return\n    const p = await this._progress()\n\n    if (this.done()) {\n      return [\n        p.assignFromPojo({\n          state: \"done\",\n          hed: \"Finished rebuilding your library \uD83C\uDF89\",\n          dek: [],\n          completePct: 100,\n          incompletePct: 0,\n          scanningPct: 0\n        })\n      ]\n    }\n    const scanningPct = 0 // everything's been scanned, so 0.\n\n    const afq = this.afq\n    if (afq != null && !afq.done()) {\n      const assetFilesTodo = await afq.todoCount()\n      await mapGt0(afq.processRate.msPerEvent, async msPerEvent => {\n        this.eta.push(\n          ((await this.outdatedAssetCount()) + assetFilesTodo) * msPerEvent\n        )\n      })\n      const { completePct } = await afq.percents()\n      const est = this.eta.fmtEstimate()\n      const hed =\n        \"Rebuilding your library\" + mapNotBlankOr(est, ea => \", \" + ea, \"\u2026\")\n\n      return [\n        p.assignFromPojo({\n          state: \"processing\",\n          hed,\n          dek: compactBlanks([\n            afq.recentFileProgress,\n            `Updating file metadata (${fmt(assetFilesTodo)} remain)`\n          ]),\n          completePct: 0,\n          incompletePct: completePct,\n          scanningPct\n        })\n      ]\n    } else if (this.aq != null && this.pq != null) {\n      const aqTodo = await this.aq.todoCount()\n      // Ignore PQ: AQ is the critical path.\n      this.eta.push(aqTodo * orElse(this.aq.processRate.msPerEvent, secondMs))\n\n      const todo = aqTodo\n      const done = this.aq.doneCount()\n      const complete = done / (todo + done)\n      const completePct = sigFigs(100 * complete, 2)\n      const est = this.eta.fmtEstimate()\n      const hed =\n        \"Rebuilding your library\" + mapNotBlankOr(est, ea => \", \" + ea, \"\u2026\")\n      return p.assignFromPojo({\n        state: \"processing\",\n        hed,\n        dek: uniq([\n          this.pq.recentFileProgress,\n          this.aq.recentFileProgress,\n          `Refreshing assets and previews (${fmt(aqTodo)} remain)`\n        ]),\n        completePct,\n        incompletePct: 100 - completePct,\n        scanningPct\n      })\n    }\n    return\n  }\n}\n", "import { ending } from \"../../core/async/Endable\"\nimport { EndableInterval } from \"../../core/async/EndableInterval\"\nimport { thenMap } from \"../../core/async/Promise\"\nimport { isPaused } from \"../../core/work/WorkPlanner\"\nimport { MaybeSyncOrAsync } from \"../../fe/OptAsync\"\nimport { Progress, ProgressRateMs } from \"../model/Progress\"\nimport { runTagMaintenance } from \"../model/TagSql\"\nimport { Sync } from \"./Sync\"\n\nexport class ProgressUpdater extends EndableInterval {\n  constructor(readonly sync: () => MaybeSyncOrAsync<Sync>) {\n    super({\n      name: \"ProgressUpdater\",\n      callback: () =>\n        ending() || isPaused()\n          ? undefined\n          : thenMap(this.sync(), async ea => {\n              await Progress.saveSyncState(ea)\n              await runTagMaintenance()\n            }),\n      intervalMs: ProgressRateMs()\n    })\n  }\n}\n", "import { Latch } from \"../../fe/Latch\"\nimport { Endable } from \"./Endable\"\nimport { EndableWrapper } from \"./EndableWrapper\"\n\nexport interface Done extends Endable {\n  done(): boolean\n  donePromise(): Promise<void>\n}\n\nexport class DoneWrapper extends EndableWrapper {\n  readonly doneLatch = new Latch()\n\n  done() {\n    return !this.doneLatch.pending\n  }\n\n  donePromise() {\n    return this.doneLatch.promise\n  }\n}\n", "import { sortBy } from \"../../fe/Array\"\nimport { Primitive } from \"../../fe/Primitive\"\nimport { toA } from \"../../fe/toA\"\nimport { ExtTypes, extTypes } from \"../tags/FileExts\"\nimport { DirectoryEntry } from \"./DirectoryEntry\"\nimport { PosixFile } from \"./PosixFile\"\n\nexport interface FileSorter {\n  (items: PosixFile[]): PosixFile[]\n}\n\nfunction idx(de: DirectoryEntry) {\n  if (de.isDirectory()) return 0\n  const types = toA(extTypes(de.ext))\n  if (types.includes(ExtTypes.Sharp)) return 1\n  if (types.includes(ExtTypes.RawImage)) return 2\n  if (types.includes(ExtTypes.Video)) return 3\n  return 4\n}\n\nexport function extSortCriteria(f: DirectoryEntry): Primitive[] {\n  return [idx(f), f.base] // add the f.base for deterministic ordering\n}\n\n/**\n * First dirs, then unknown EXTs, then cheapest-to-expensive EXTs.\n */\nexport function sortByExt(items: DirectoryEntry[]): DirectoryEntry[] {\n  // booleans sort to [false, true], so we want files with exts first.\n  return sortBy(items, ea => extSortCriteria(ea))\n}\n", "/* eslint-disable @typescript-eslint/unbound-method */\nimport { isNotEmpty } from \"../../fe/Array\"\nimport { retryOnReject } from \"../../fe/AsyncRetry\"\nimport { secondMs } from \"../../fe/Date\"\nimport { unrefDelay } from \"../../fe/Delay\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { pick } from \"../../fe/Object\"\nimport { randomInt } from \"../../fe/Random\"\nimport { toA } from \"../../fe/toA\"\nimport { firstAsync, partition } from \"../Array\"\nimport { thenOrTimeout } from \"../async/thenOrTimeout\"\nimport { Logger, mkLogger } from \"../Logger\"\nimport { Settings } from \"../settings/Settings\"\nimport { MountpointsTtlMs } from \"../volumes/VolumeTtls\"\nimport { isPaused } from \"../work/WorkPlanner\"\nimport { DirectoryEntry } from \"./DirectoryEntry\"\nimport { DirectoryWalker } from \"./DirectoryWalker\"\nimport { ignorableDirectory, ignorableFile } from \"./Ignorable\"\nimport { hasNoMedia } from \"./NoMedia\"\nimport { containedByNativePath } from \"./Path\"\nimport { noStatFileFilter } from \"./PosixFileFilters\"\nimport { sortByExt } from \"./PosixFileSorters\"\n\nexport interface Next {\n  done: boolean\n}\n\nexport const Done: Next = { done: true }\nexport const Undone: Next = { done: false }\n\n/**\n * Recurses through the given directory, sending files that may be eligible for\n * import to a given fileHandler, and finished directories to a\n * directoryListener.\n */\nexport class DirectoryIterator {\n  readonly name: string\n  private readonly logger: Logger\n\n  private readonly pendingChildDirs: DirectoryEntry[] = []\n  private childDelegate?: DirectoryIterator\n  private _done = false\n\n  constructor(\n    readonly dir: DirectoryEntry,\n    readonly ctx: DirectoryWalker,\n    readonly parent?: DirectoryIterator\n  ) {\n    this.name = \"stats.DirectoryIterator(\" + dir + \")\"\n    this.logger = mkLogger(this.name)\n  }\n\n  get isRoot(): boolean {\n    return this.parent == null\n  }\n\n  root(): DirectoryIterator {\n    return this.parent == null ? this : this.parent.root()\n  }\n\n  done(): boolean {\n    return this._done\n  }\n\n  /**\n   * @param untilTs run until the millisecond timestamp is less than Date.now()\n   * @throws if there are problems, even after retries.\n   */\n  // Note this doesn't need a mutex because the only consumer, DirectoryCounter,\n  // already only runs one at a time.\n  async next(untilTs: number): Promise<Next> {\n    if (this.ctx.ended) return Undone\n    const start = Date.now()\n    const result: Maybe<Next> = await retryOnReject(\n      () =>\n        firstAsync(this.nextChain, f => (this.ctx.ended ? Undone : f(untilTs))),\n      {\n        maxRetries: this.ctx.maxRetries,\n        // maybe things will be OK in a couple seconds?\n        onRetryWaitUntil: () =>\n          unrefDelay(randomInt(500, MountpointsTtlMs / this.ctx.maxRetries))\n      }\n    )\n    if (result == null) return Undone\n    this._done = result.done === true\n    this.logger.debug(\"next()\", {\n      result,\n      ttr: untilTs - start,\n      elapsed: Date.now() - start\n    })\n    return result\n  }\n\n  private canContinue(until: number) {\n    return !this._done && !isPaused() && Date.now() < until\n  }\n\n  private maybeTimeout(until: number) {\n    return this._done ? Done : this.canContinue(until) ? undefined : Undone\n  }\n\n  private readonly setupChildren = lazy(async () => {\n    if (true === (await hasNoMedia(this.dir))) {\n      this.logger.info(\"skipping .nomedia dir, \" + this.dir)\n    } else {\n      const children = await this.dir.children()\n      const notHidden = sortByExt(toA(children)).filter(ea => {\n        // console.log(ea.nativePath, {\n        //   lt: lt(ea.nativePath, this.ctx.startAtNativePath),\n        //   gt: gt(ea.nativePath, this.ctx.startAtNativePath),\n        //   startsWith: this.ctx.startAtNativePath?.startsWith(ea.nativePath)\n        // })\n\n        if (this.ctx.startAtNativePath != null) {\n          if (\n            ea.isDirectory() &&\n            ea.nativePath < this.ctx.startAtNativePath &&\n            !containedByNativePath(this.ctx.startAtNativePath, ea.nativePath)\n          ) {\n            this.logger.info(\n              \"skipping child that is before \" + this.ctx.startAtNativePath,\n              ea.nativePath\n            )\n            return false\n          }\n        }\n        return !ignorableFile(ea)\n      })\n      const [dirs, files] = partition(notHidden, ea => ea.isDirectory())\n      this.pendingChildDirs.push(...dirs)\n      // TODO: fix the typings!\n      await this.ctx.fileHandler((await noStatFileFilter.filter(files)) as any)\n    }\n  })\n\n  private async maybeDelegateToChild(until: number) {\n    while (\n      this.canContinue(until) &&\n      (this.childDelegate != null || isNotEmpty(this.pendingChildDirs))\n    ) {\n      if (this.ctx.ended) return Undone\n      if (this.childDelegate == null) {\n        const child = this.pendingChildDirs.shift()!\n        if (!(await ignorableDirectory(child))) {\n          this.childDelegate = new DirectoryIterator(child, this.ctx, this)\n        }\n      }\n\n      const delegate = this.childDelegate\n      if (delegate != null) {\n        // Let the nearest delegate catch the timeout first:\n        const timeoutMs =\n          Settings.statTimeoutSeconds.valueOrDefault * secondMs -\n          this.dir.pathnames.length * 100\n        const n = await thenOrTimeout(delegate.next(until), timeoutMs, () => {\n          this.logger.warn(\n            \"Failed to descend into \" +\n              delegate.dir +\n              \": TIMEOUT after \" +\n              timeoutMs\n          )\n          return Done\n        })\n        if (n == null || n.done === true) {\n          this.childDelegate = undefined\n        }\n      }\n    }\n    return\n  }\n\n  /**\n   * Note that as this method is the last in the chain,  it must return a\n   * response.\n   */\n  private async maybeCompleteResult(): Promise<Next> {\n    if (this.childDelegate != null || isNotEmpty(this.pendingChildDirs)) {\n      this.logger.warn(\n        \"maybeCompleteResult, not done (?!)\",\n        pick(\n          this as any,\n          \"result\",\n          \"pendingChildren\",\n          \"childDelegate\",\n          \"pendingChildDirs\"\n        )\n      )\n      return Undone\n    } else {\n      await this.ctx.directoryListener(this.dir)\n      return Done\n    }\n  }\n\n  private readonly nextChain = [\n    this.maybeTimeout,\n    this.setupChildren,\n    this.maybeTimeout,\n    this.maybeDelegateToChild,\n    this.maybeTimeout,\n    this.maybeCompleteResult\n  ].map(f => async (until: number) => {\n    // const m = \".\" + f.name + \"()\"\n    const result = await f.bind(this)(until)\n    // this.logger.info(m, { result })\n    return result\n  })\n}\n", "import { lazy } from \"../../fe/Lazy\"\nimport { DoneWrapper } from \"../async/Done\"\nimport { EndableRanks } from \"../async/Endable\"\nimport { Promises } from \"../async/Promises\"\nimport { isTest } from \"../NodeEnv\"\nimport { isWin } from \"../Platform\"\nimport { addIdleListener, IdleListener, removeIdleListener } from \"../work/Idle\"\nimport { DirectoryEntry } from \"./DirectoryEntry\"\nimport { DirectoryIterator } from \"./DirectoryIterator\"\n\nexport const SliceMs = lazy(() => (isTest ? (isWin ? 100 : 25) : 500))\n\n/**\n * Wraps a DirectoryIterator with an IdleListener to run at most one at a time,\n * for only a set time slice.\n */\nexport class DirectoryWalker extends DoneWrapper implements IdleListener {\n  private mutex = new Promises()\n  private readonly iterator: DirectoryIterator\n  readonly startAtNativePath?: string\n\n  constructor(\n    readonly root: DirectoryEntry,\n    readonly fileHandler: (files: DirectoryEntry[]) => any,\n    readonly directoryListener: (dir: DirectoryEntry) => any,\n    startAtNativePath?: string,\n    readonly maxRetries = 2\n  ) {\n    super(\n      \"DirectoryWalker(\" + root.nativePath + \")\",\n      () => {\n        removeIdleListener(this.name)\n      },\n      EndableRanks.first\n    )\n    if (startAtNativePath != null) {\n      if (this.root.nativePath.startsWith(startAtNativePath)) {\n        this.startAtNativePath = startAtNativePath\n      } else {\n        this.logger.error(\"bad startAtNativePath: ignoring.\")\n      }\n    }\n\n    this.iterator = new DirectoryIterator(root, this)\n    addIdleListener(this)\n  }\n\n  get runnable() {\n    return !this.ended && this.doneLatch.pending\n  }\n\n  onIdle() {\n    return this.run()\n  }\n\n  run() {\n    return this.mutex.oneRunAtATime(this.name + \".run()\", () => this._run())\n  }\n\n  private async _run() {\n    if (this.ended || this.doneLatch.resolved) return\n    const result = await this.iterator.next(Date.now() + SliceMs())\n    if (result.done) {\n      this.logger.info(\"run(): completed iteration\")\n      removeIdleListener(this.name)\n      void this.doneLatch.resolve()\n    }\n  }\n}\n", "import { extname } from \"path\"\nimport { thenMap } from \"../../core/async/Promise\"\nimport { withBoundedConcurrency } from \"../../core/async/Promises\"\nimport { time } from \"../../core/async/PromiseTimer\"\nimport { isRetriableError } from \"../../core/error/ErrorTypes\"\nimport {\n  onProgressEvt,\n  ProgressEvt,\n  removeProgressEvtListener\n} from \"../../core/event/ProgressEvt\"\nimport { BaseFile } from \"../../core/fs/BaseFile\"\nimport { DirectoryEntry } from \"../../core/fs/DirectoryEntry\"\nimport { PosixFile } from \"../../core/fs/PosixFile\"\nimport { maxConcurrentVideoImports } from \"../../core/img/Video\"\nimport { arr2log } from \"../../core/log/LogMeta\"\nimport { Average } from \"../../core/math/Average\"\nimport { Rate } from \"../../core/math/Rate\"\nimport { extTypes, ExtTypes, isVideoExt } from \"../../core/tags/FileExts\"\nimport { bname } from \"../../core/tags/TagInference\"\nimport { TTLArray } from \"../../core/TTLArray\"\nimport { TTLSet } from \"../../core/TTLSet\"\nimport { compact, count, isEmpty, uniq } from \"../../fe/Array\"\nimport { minuteMs, secondMs } from \"../../fe/Date\"\nimport { asError } from \"../../fe/Error\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { clamp } from \"../../fe/Number\"\nimport { AssetFile } from \"../model/AssetFile\"\nimport { QueueItem } from \"../stats/QueueItem\"\nimport { isErrorResult, isSuccessResult } from \"../sync-file/ImportResult\"\nimport { FileProcessor } from \"../sync-file/NativePathImportTask\"\nimport { WorkQueue } from \"../WorkQueue\"\nimport { precheckFiles } from \"./PrecheckFiles\"\n\nfunction queueType(ext: string): \"image\" | \"raw\" | \"video\" {\n  const et = compact(extTypes(ext))\n  return et.includes(ExtTypes.Video)\n    ? \"video\"\n    : et.includes(ExtTypes.RawImage)\n    ? \"raw\"\n    : \"image\"\n}\n\n/**\n * AssetFileQueue manages receiving files (presumably from DirectoryIterator),\n * pushing those files onto a queue for later, and popping files off when the\n * work iterator says there's free CPU. Those files are then sent to the\n * `sync-file` to be imported (by AssetFileImporter)\n */\nexport class AssetFileQueue extends WorkQueue {\n  static queueNameForUri(uri: string) {\n    return \"afq:\" + uri\n  }\n  static readonly MaxErrors = 2\n  private _processedImages = 0\n  private _processedVideo = 0\n\n  private readonly _imageProcessTimeMs = new Average(50)\n  private readonly _videoProcessTimeMs = new Average(50)\n  private readonly recentProgress = new TTLArray<string>(15 * secondMs)\n  private readonly recentlyRetried = new TTLSet<string>(30 * minuteMs)\n\n  /**\n   * Average milliseconds to process a file\n   */\n  readonly processMs = new Average()\n  readonly assetProcessRate = new Rate(5 * minuteMs)\n\n  private _lastOpProgress: number = 0\n\n  private readonly progressCallback: (ctx: any) => void\n\n  static async for(\n    root: PosixFile,\n    importer: FileProcessor,\n    currentWorkQueueLength: () => number\n  ) {\n    return new AssetFileQueue(\n      root,\n      (await root.uri())!,\n      importer,\n      await maxConcurrentVideoImports(),\n      currentWorkQueueLength\n    )\n  }\n\n  private constructor(\n    readonly root: PosixFile,\n    readonly uri: string,\n    readonly importer: FileProcessor,\n    readonly maxConcurrentVideos: number,\n    currentWorkQueueLength: () => number\n  ) {\n    super(\n      [AssetFileQueue.queueNameForUri(uri)],\n      qi => this.itemIsReady(qi),\n      qi => this.processItem(qi),\n      false, // not singlethreaded\n      currentWorkQueueLength\n    )\n    this.progressCallback = (p: ProgressEvt) => {\n      this.logger.debug(\"progressCallback()\", p)\n      if (this.hasPath(p.path)) {\n        this.recentProgress.push(`${p.op} ${p.path}: ${p.pct.toFixed(0)}%`) // < don't need \"3.6%\"\n        this._lastOpProgress = Date.now()\n      }\n    }\n\n    // Support per-file percent progress:\n    onProgressEvt(this.progressCallback)\n    this.onEnds.push(() => removeProgressEvtListener(this.progressCallback))\n  }\n\n  get lastOpProgress() {\n    return this._lastOpProgress\n  }\n\n  get currentPaths() {\n    return this.currentQueueItems().map(ea => ea.contents)\n  }\n\n  get currentBaseFiles() {\n    return this.currentPaths.map(ea => BaseFile.for(ea))\n  }\n\n  hasPath(nativePath: string) {\n    for (const path of this.currentPaths) {\n      if (nativePath === path) return true\n    }\n    return false\n  }\n\n  get currentVideoJobCount(): number {\n    return count(this.currentPaths, path => isVideoExt(extname(path)))\n  }\n\n  get currentVideoJobCapacity(): number {\n    return clamp(\n      0,\n      this.maxConcurrentVideos,\n      this.maxConcurrentVideos - this.currentVideoJobCount\n    )\n  }\n\n  get preventAdditionalVideoJobs(): boolean {\n    return this.currentVideoJobCount >= this.maxConcurrentVideos\n  }\n\n  get processedCount(): number {\n    return this._processedImages + this._processedVideo\n  }\n\n  get processedImageCount(): number {\n    return this._processedImages\n  }\n\n  get processedVideoCount(): number {\n    return this._processedVideo\n  }\n\n  get avgImageProcessingTime() {\n    return this._imageProcessTimeMs.p84\n  }\n\n  get avgVideoProcessingTime() {\n    return this._videoProcessTimeMs.p84\n  }\n\n  async stats() {\n    return {\n      pendingCount: await this.pendingCount(),\n      processedImageCount: this.processedImageCount,\n      processedVideoCount: this.processedVideoCount,\n      avgImageProcessingTime: this.avgImageProcessingTime,\n      avgVideoProcessingTime: this.avgVideoProcessingTime\n    }\n  }\n\n  currentCounterState() {\n    return {\n      processedImageCount: this.processedImageCount,\n      processedVideoCount: this.processedVideoCount\n    }\n  }\n\n  private itemQuery(queueIds: number[]) {\n    // DON'T GET THIS NEAR ASYNC (knex will try to execute the query)\n    return QueueItem.query().whereIn(\"queueId\", queueIds)\n  }\n\n  /**\n   * The count of enqueued and currently-being-processed items.\n   */\n  async pendingCount() {\n    return QueueItem.dbl.pluckFirst<number>(\n      this.itemQuery(await this.queueIds()).count(\"id\")\n    )\n  }\n\n  async pendingImagesCount() {\n    return QueueItem.dbl.pluckFirst<number>(\n      this.itemQuery(await this.queueIds())\n        .andWhere(\"type\", \"!=\", \"video\")\n        .count(\"id\")\n    )\n  }\n\n  async pendingVideoCount() {\n    return QueueItem.dbl.pluckFirst<number>(\n      this.itemQuery(await this.queueIds())\n        .andWhere(\"type\", \"=\", \"video\")\n        .count(\"id\")\n    )\n  }\n\n  get recentFileProgress(): Maybe<string> {\n    return orElse(this.recentProgress.shift(), () =>\n      map(this.recentlyProcessed.shiftOrFirst(), ea => \"Processed \" + ea)\n    )\n  }\n\n  async enqueueOrTouchAssetFiles(assetFiles: AssetFile[]) {\n    const freshAssetFileIds: number[] = []\n    const stale: { contents: string; type: ReturnType<typeof queueType> }[] = []\n    await withBoundedConcurrency({\n      name: \"enqueueOrTouchAssetFiles\",\n      laters: assetFiles.map(af => async () => {\n        const pf = await af.posixFile()\n        if (pf != null) {\n          if (true === (await af.matchesFile())) {\n            freshAssetFileIds.push(af.id!)\n          } else {\n            stale.push({ contents: pf.nativePath, type: queueType(pf.ext) })\n          }\n        }\n      })\n    })\n    await AssetFile.touch(freshAssetFileIds)\n    await this.enqueueWork(stale)\n    this.logger.info(\"enqueueOrTouchAssetFiles()\", {\n      freshAssetFileIds,\n      stale\n    })\n  }\n\n  /**\n   * Give this method to DirectoryIterator's constructor\n   */\n  readonly fileListener = async (possibleAssets: DirectoryEntry[]) => {\n    this.logger.debug(\"fileListener()\", {\n      possibleAssetPaths: arr2log(possibleAssets, ea => ea.nativePath)\n    })\n    const updateFreshFiles = true\n    const { fresh, stale } = await time(\"precheckFiles\", () =>\n      precheckFiles(possibleAssets, updateFreshFiles)\n    )\n    this.logger.debug(\"fileListener()\", { fresh, stale })\n    if (isEmpty(stale)) {\n      // no-op!\n      return\n    }\n\n    await this.enqueueWork(\n      stale.map(ea => ({\n        contents: ea.nativePath,\n        type: queueType(ea.ext)\n      }))\n    )\n  }\n\n  private async handleError(qi: QueueItem, err: Error) {\n    this.logger.warn(\"handleError()\", { qi, err })\n    if (isRetriableError(err) && !this.recentlyRetried.has(qi.contents)) {\n      await thenMap(DirectoryEntry.for(qi.contents), de => {\n        this.recentlyRetried.add(qi.contents)\n        this.logger.info(\"Re-enqueuing \" + de)\n        return this.fileListener([de])\n      })\n    }\n  }\n\n  private onFileDone(pq: QueueItem, elapsedMs: number) {\n    this.logger.debug(\"onFileDone(\" + pq.contents + \", \" + elapsedMs + \" ms)\")\n    const f = fileForItem(pq)\n    if (isVideoExt(f.ext)) {\n      this._processedVideo++\n    } else {\n      this._processedImages++\n    }\n\n    if (elapsedMs > 0) {\n      if (isVideoExt(f.ext)) {\n        this._videoProcessTimeMs.push(elapsedMs)\n      } else {\n        // NOTE: We're putting raw and jpg together here:\n        this._imageProcessTimeMs.push(elapsedMs)\n      }\n    }\n  }\n\n  private async itemIsReady(qi: QueueItem): Promise<boolean> {\n    const isVideo = qi.type === \"video\"\n    if (isVideo && this.currentVideoJobCapacity <= 0) return false\n\n    const f = BaseFile.for(qi.contents)\n    return !uniq(this.currentBaseFiles.map(bname)).includes(bname(f))\n  }\n\n  private async processItem(qi: QueueItem) {\n    const start = Date.now()\n    try {\n      const result = await this.importer(qi.contents)\n      if (isSuccessResult(result)) {\n        await this.onFileDone(qi, Date.now() - start)\n      } else if (isErrorResult(result)) {\n        await this.handleError(qi, asError(result.error))\n      }\n    } catch (err) {\n      return this.handleError(qi, err)\n    } finally {\n      this.assetProcessRate.onEvent()\n      this.processMs.push(Date.now() - start)\n      this.recentlyProcessed.push(qi.contents)\n    }\n  }\n}\n\nfunction fileForItem(pq: QueueItem): PosixFile {\n  return PosixFile.for(pq.contents)\n}\n", "import { batches } from \"../../core/Array\"\nimport { withBoundedConcurrency } from \"../../core/async/Promises\"\nimport { DirectoryEntry } from \"../../core/fs/DirectoryEntry\"\nimport { PosixFile } from \"../../core/fs/PosixFile\"\nimport { nativePath2uri } from \"../../core/uri/FileURI\"\nimport { URI } from \"../../core/uri/URI\"\nimport { AssetFile } from \"../model/AssetFile\"\n\n/**\n * Remove the files in `files` that are already in sync with the library.\n */\nexport async function precheckFiles(\n  files: DirectoryEntry[],\n  updateFreshFiles = false\n) {\n  const fresh: { path: string; assetId: number; assetFileId: number }[] = []\n\n  for (const fileBatch of batches(files, 256)) {\n    const filesWithUri: { file: DirectoryEntry; uri: URI }[] = []\n    for (const file of fileBatch) {\n      filesWithUri.push({ file, uri: await nativePath2uri(file.nativePath) })\n    }\n\n    const priors = await AssetFile.ops().allf(q =>\n      q.whereIn(\n        \"uri\",\n        filesWithUri.map(ea => ea.uri.toString())\n      )\n    )\n\n    const freshBatch: typeof fresh = []\n\n    await withBoundedConcurrency({\n      name: \"precheckFiles\",\n      laters: priors.map(af => async () => {\n        const fwu = filesWithUri.find(ea => ea.uri.toString() === af.uri)!\n        const pf = PosixFile.for(fwu.file.nativePath, fwu.file)\n        if (await af.matchesFile(pf)) {\n          freshBatch.push({\n            path: fwu.file.nativePath,\n            assetId: af.assetId!,\n            assetFileId: af.id!\n          })\n        }\n      })\n    })\n\n    if (updateFreshFiles) {\n      await AssetFile.touch(freshBatch.map(ea => ea.assetFileId))\n    }\n    fresh.push(...freshBatch)\n  } // end batches\n\n  const freshPaths = fresh.map(ea => ea.path)\n\n  return {\n    fresh,\n    stale: files.filter(ea => !freshPaths.includes(ea.nativePath))\n  }\n}\n", "import { Knex } from \"knex\"\nimport { DoneWrapper } from \"../../core/async/Done\"\nimport { end, EndableRanks, ending } from \"../../core/async/Endable\"\nimport { thenOrElse } from \"../../core/async/Promise\"\nimport { BoundedList } from \"../../core/BoundedList\"\nimport { onError } from \"../../core/error/Error\"\nimport { DirectoryEntry } from \"../../core/fs/DirectoryEntry\"\nimport { DirectoryWalker } from \"../../core/fs/DirectoryWalker\"\nimport { PosixFile } from \"../../core/fs/PosixFile\"\nimport { mkLogger } from \"../../core/Logger\"\nimport { ETA } from \"../../core/math/ETA\"\nimport { avg, sum } from \"../../core/math/Vector\"\nimport { isTest } from \"../../core/NodeEnv\"\nimport { mapGt0 } from \"../../core/Number\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { capitalize } from \"../../core/String\"\nimport { isVideoExt } from \"../../core/tags/FileExts\"\nimport { maxSyncFileJobs } from \"../../core/work/MaxCpus\"\nimport { isPaused } from \"../../core/work/WorkPlanner\"\nimport { Percents } from \"../../fe/api/ProgressState\"\nimport { compact, compactBlanks } from \"../../fe/Array\"\nimport { firstNotBlank, mapNotBlank } from \"../../fe/Blank\"\nimport { secondMs } from \"../../fe/Date\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map, orElse } from \"../../fe/Maybe\"\nimport { Maybe, PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { round, sigFigs, toInt } from \"../../fe/Number\"\nimport { fmt, plur } from \"../../fe/Units\"\nimport { AssetFile } from \"../model/AssetFile\"\nimport { Progress } from \"../model/Progress\"\nimport { ProgressMetaNames } from \"../model/ProgressMeta\"\nimport { QueueItem } from \"../stats/QueueItem\"\nimport { FileProcessor } from \"../sync-file/NativePathImportTask\"\nimport { AssetFileUpdater } from \"../sync-file/UpdateResult\"\nimport { AssetFileQueue } from \"./AssetFileQueue\"\nimport { Sync } from \"./Sync\"\n\n// For rusty's volume2, there were 739197 folders in 4899456376 bytes.\n// That's ~800K folders in ~5TB of data: 4899456376 / 739197 = 6628 bytes\n// per folder. That seems OKish?\n\n// const DirectoryContentsEstimateBytes = 5 * KB\n\n/**\n * Manages a DirectoryWalker, AssetProcessor, and cleanup queue, and restoring\n * previous state when available.\n *\n * Also assembles Progress reports.\n */\nexport class DirectorySync extends DoneWrapper implements Sync {\n  static async for({\n    root,\n    uri,\n    fileHandler,\n    assetFileUpdater,\n    currentWorkQueueLength\n  }: {\n    root: PosixFile\n    uri?: string\n    fileHandler: FileProcessor\n    assetFileUpdater: AssetFileUpdater\n    currentWorkQueueLength: () => number\n  }): PromiseMaybe<DirectorySync> {\n    const rootUri = await thenOrElse(uri, () => root.uri())\n    const rootDE = await root.directoryEntry()\n    if (rootUri == null || rootDE == null) {\n      mkLogger(\"DirectorySync\").warn(\"Cannot make DirectorySync for \" + root, {\n        rootUri,\n        rootDE\n      })\n      return\n    }\n\n    // The AssetProcessor is unique per directory, so the MQ can be specific\n    // for the drive. If the drive disappears (temporarily or otherwise), the\n    // enqueued files will be paused.\n    const assetFileQueue = await AssetFileQueue.for(\n      root,\n      fileHandler,\n      currentWorkQueueLength\n    )\n\n    return new DirectorySync(\n      root,\n      rootUri,\n      fileHandler,\n      assetFileQueue,\n      assetFileUpdater,\n      currentWorkQueueLength\n    )\n  }\n\n  readonly start = Date.now()\n  private _isScanning = true // assume we start scanning\n  private _staleEnqueued = false\n  private readonly eta = new ETA()\n  readonly recentlyScannedDirs = new BoundedList<string>(10)\n  scannedDirsCount = 0\n  processedImageCount = 0\n  processedVideoCount = 0\n  private directoryWalker: Maybe<DirectoryWalker>\n\n  protected constructor(\n    readonly root: PosixFile,\n    readonly rootUri: string,\n    readonly fileHandler: FileProcessor,\n    readonly assetFileQueue: AssetFileQueue,\n    readonly assetFileUpdater: AssetFileUpdater,\n    readonly currentWorkQueueLength: () => number\n  ) {\n    super(\"DirectorySync(\" + root + \")\", () => this.onEnd(), EndableRanks.first)\n    this.assetFileQueue.on(\"processed\", this.onProcessed)\n    void this.doneLatch.observe(this.setup())\n  }\n\n  private async onEnd() {\n    await end(this.directoryWalker)\n    await end(this.assetFileQueue)\n    await this.saveSyncProgress.refresh()\n  }\n\n  private readonly onProcessed = (qi: QueueItem) => {\n    if (isVideoExt(qi.contents)) this.processedVideoCount++\n    else this.processedImageCount++\n  }\n\n  // NO TTL! This must be the same instance for the same directory sync run.\n  readonly _progress = lazy(() =>\n    Progress.insertNew(this.rootUri, this.root.nativePath)\n  )\n\n  readonly priorMeta = lazy(async () =>\n    (await this._progress()).getMetaAsRecord()\n  )\n\n  // the lazy is to throttle saves:\n  readonly saveSyncProgress = lazy(\n    () => Progress.saveSyncState(this),\n    isTest ? 100 : secondMs\n  )\n\n  readonly saveLastScannedDirectory = lazy(\n    async () => {\n      const p = await this._progress()\n      await p.setMeta(\n        ProgressMetaNames.scannedDirectoryCount,\n        this.scannedDirsCount.toString()\n      )\n      const lastScannedDirectory = this.recentlyScannedDirs.item(-1)\n      if (lastScannedDirectory != null) {\n        await p.setMeta(\n          ProgressMetaNames.lastScannedDirectory,\n          lastScannedDirectory\n        )\n      }\n    },\n    isTest ? 50 : 500\n  )\n\n  readonly directoryListener = (dir: DirectoryEntry) => {\n    return mapNotBlank(dir?.nativePath, ea => {\n      this.scannedDirsCount++\n      this.recentlyScannedDirs.push(ea)\n      this.logger.debug(\"directoryListener()\", {\n        scannedDirsCount: this.scannedDirsCount,\n        dir: dir.nativePath\n      })\n      return this.saveLastScannedDirectory()\n    })\n  }\n\n  readonly earliestStartTime = lazy(async () => {\n    const times = await Progress.times()\n    const priorTimes = times.find(ea => ea.uri === this.rootUri)\n    return orElse(priorTimes?.lastStartedAt, Date.now())\n  }) // cache forever\n\n  readonly staleAssetFileCount = lazy(async () => {\n    if (this._staleEnqueued) return 0\n    const minUpdatedAt = await this.earliestStartTime()\n    return AssetFile.dbl.pluckFirstf<number>(q =>\n      q\n        .where(\"uri\", \"LIKE\", this.rootUri + \"%\")\n        .andWhere(\"updatedAt\", \"<\", minUpdatedAt)\n    )\n  }, 20 * secondMs) // only needs to be directionally accurate\n\n  private async maybeRunDirectorySync() {\n    const priorMeta = await this.priorMeta()\n\n    // NOTE: THEY MUST BE IN THIS ORDER!\n    // ALSO NOTE: these may throw exceptions!\n    if (null != priorMeta.completedDirectoryScan) {\n      this.logger.info(\"setup() skipping scan: prior sync finished.\")\n      return\n    }\n    const progress = await this._progress()\n    this.scannedDirsCount = orElse(toInt(priorMeta.scannedDirectoryCount), 0)\n    this.directoryWalker = new DirectoryWalker(\n      (await this.root.directoryEntry())!,\n      this.assetFileQueue.fileListener,\n      this.directoryListener,\n      priorMeta.lastScannedDirectory\n    )\n    this.logger.info(\"maybeRunDirectorySync() started directoryWalker\", {\n      lastScannedDirectory: priorMeta.lastScannedDirectory\n    })\n    await this.directoryWalker.donePromise().catch(err => {\n      onError(\"directoryCounter donePromise failed\", err)\n    })\n    this.logger.info(\"maybeRunDirectorySync() completed directoryWalker\", {\n      scannedDirsCount: this.scannedDirsCount\n    })\n    await progress.setMeta(ProgressMetaNames.completedDirectoryScan, \"true\")\n  }\n\n  private async maybeEnqueueStaleAssetFiles() {\n    if (\n      !Settings.forceSync.valueOrDefault &&\n      null != (await this.priorMeta())?.enqueuedStaleFiles\n    ) {\n      this.logger.info(\"setup() skipping scan: prior sync finished.\")\n    } else {\n      const progress = await this._progress()\n      const earliestStartTime = await this.earliestStartTime()\n\n      this.logger.info(\"maybeEnqueueStaleAssetFiles() starting enqueue\", {\n        assetFileQueuePendingCount: await this.assetFileQueue.pendingCount()\n      })\n      await AssetFile.ops().batched({\n        onResults: async (arr: AssetFile[]) =>\n          this.assetFileQueue.enqueueOrTouchAssetFiles(arr),\n        qb: (qb: Knex.QueryBuilder) =>\n          qb\n            .where(\"uri\", \"LIKE\", this.rootUri + \"%\")\n            .andWhere(\"updatedAt\", \"<\", earliestStartTime)\n      })\n      this.logger.info(\"maybeEnqueueStaleAssetFiles() finished enqueue\", {\n        assetFileQueuePendingCount: await this.assetFileQueue.pendingCount()\n      })\n      await progress.setMeta(ProgressMetaNames.enqueuedStaleFiles, \"true\")\n    }\n    this.staleAssetFileCount.unset()\n    this._staleEnqueued = true\n    return\n  }\n\n  private readonly setup = lazy(async () => {\n    const priorMeta = await this.priorMeta()\n    const earliestStartTime = await this.earliestStartTime()\n\n    this.logger.info(\"setup()\", {\n      priorMeta,\n      earliestStartTime\n    })\n\n    map(priorMeta.lastScannedDirectory, ea => this.recentlyScannedDirs.push(ea))\n    mapGt0(\n      priorMeta.processedImageCount,\n      ea => (this.processedImageCount += ea)\n    )\n    mapGt0(\n      priorMeta.processedVideoCount,\n      ea => (this.processedVideoCount += ea)\n    )\n\n    await this.maybeRunDirectorySync()\n\n    this.logger.info(\"setup() setting isScanning to false.\")\n    this._isScanning = false\n\n    await this.maybeEnqueueStaleAssetFiles()\n\n    // We don't need to short-circuit this. We either have work to do or we\n    // don't.\n\n    await this.assetFileQueue.donePromise().catch(err => {\n      onError(\"assetFileQueue donePromise failed\", err)\n    })\n\n    // We're complete! Let's do some cleanup:\n\n    if (!this.ended) {\n      await this.doneLatch.resolve()\n      const p = await this.progress()\n      this.logger.info(\"DONE! Marking Progress as complete:\")\n      await p.upsert({ completedAt: Date.now() })\n    }\n  })\n\n  processedCount() {\n    return this.processedImageCount + this.processedVideoCount\n  }\n\n  pendingCount() {\n    return this.assetFileQueue.pendingCount()\n  }\n\n  get isScanning() {\n    return this._isScanning\n  }\n\n  /**\n   * Terrible hack to just give *some* progress without requiring statting every\n   * file for it's size (which is excruciatingly slow over NASes).\n   *\n   * NEVER SHOW THIS NUMBER TO THE USER. IT IS BOGUS.\n   */\n  async estimatedScannedPct(): Promise<number> {\n    if (!this.isScanning) return 100\n    // this will be undefined for UNC directories:\n    // const estTotFiles = await this.estimatedTotalFileCount\n    // const scanDirEst =\n    //   gte0(estTotFiles) && this.scannedDirsCount <= estTotFiles\n    //     ? (100 * this.scannedDirsCount) / estTotFiles\n    //     : undefined\n    // https://www.desmos.com/calculator/jwzkxpulmt\n    const bogusEst = 100 / -(this.scannedDirsCount / 500 + 1) + 100\n    // const result = clamp(0, 100, avg([scanDirEst, bogusEst])!)\n    return sigFigs(bogusEst, 4)\n  }\n\n  async progress(): Promise<Progress> {\n    const done = this.done()\n    const paused = isPaused() || ending()\n    const state = this.done() ? \"done\" : paused ? \"paused\" : \"processing\"\n\n    const dek: string[] = []\n    if (!done && !paused) {\n      mapNotBlank(this.assetFileQueue.recentFileProgress, ea => dek.push(ea))\n      if (this.isScanning) {\n        dek.push(\n          \"Scanning \" +\n            firstNotBlank(\n              this.recentlyScannedDirs.shiftOrFirst(),\n              this.root.nativePath\n            )\n        )\n      }\n    }\n\n    const msg: string[] = []\n\n    if (this.processedImageCount + this.processedVideoCount > 0) {\n      msg.push(\n        \"Processed\",\n        plur(this.processedImageCount, \"photo\"),\n        \"and\",\n        plur(this.processedVideoCount, \"video\") + \".\"\n      )\n    }\n\n    const pendingCount = await this.pendingCount()\n    if (!done && pendingCount > 0) {\n      msg.push(\n        this.isScanning ? \"At least\" : \"\",\n        fmt(pendingCount),\n        \"remain to be processed\"\n      )\n    }\n    dek.push(compactBlanks(msg).join(\" \"))\n\n    const hed: string[] = []\n    hed.push(capitalize(state))\n    if (!done) map(this.eta.fmtEstimate(), ea => hed.push(ea))\n\n    const p = await this._progress()\n\n    if (this.processedImageCount > 1) {\n      await p.setMeta(\n        ProgressMetaNames.processedImageCount,\n        String(this.processedImageCount)\n      )\n    }\n    if (this.processedVideoCount > 1) {\n      await p.setMeta(\n        ProgressMetaNames.processedVideoCount,\n        String(this.processedVideoCount)\n      )\n    }\n\n    return this.logger.tap({\n      msg: \".progress()\",\n      result: p.assignFromPojo({\n        state,\n        hed: hed.join(\", \"),\n        dek,\n        ...(await this.percents())\n      })\n    })\n  }\n\n  async percents(): Promise<Percents> {\n    if (this.done()) {\n      return {\n        completePct: 100,\n        incompletePct: 0,\n        scanningPct: 0\n      }\n    }\n\n    // How much has already been scanned:\n    const scannedPct = await this.estimatedScannedPct()\n\n    // How much remains to be scanned:\n    const scanningPct = 100 - scannedPct\n\n    const processed = await this.processedCount()\n    const pending = await this.pendingCount()\n    const completePct =\n      pending === 0 && processed === 0\n        ? 0\n        : sigFigs(scannedPct * (processed / (pending + processed)), 4)\n    const incompletePct = 100 - (completePct + scanningPct)\n    const p = { completePct, incompletePct, scanningPct }\n    this.logger.debug(\"percents(): \", { scannedPct, processed, pending, p })\n\n    if (sum([p.completePct, p.incompletePct, p.scanningPct]) !== 100) {\n      this.logger.warn(\"percents(): BUGGED\", {\n        p,\n        processed,\n        pending,\n        scannedPct,\n        scanningPct,\n        incompletePct,\n        completePct\n      })\n    }\n    if (scannedPct === 100 && processed > 7) {\n      const afq = this.assetFileQueue\n      let remainingMs = 0\n      const imgCount = await afq.pendingImagesCount()\n      const vidCount = await afq.pendingVideoCount()\n      {\n        const ms = afq.avgImageProcessingTime\n        if (imgCount > 0 && ms != null) {\n          remainingMs += imgCount * ms\n        }\n      }\n      {\n        const ms = afq.avgVideoProcessingTime\n        if (vidCount > 0 && ms != null) {\n          remainingMs += vidCount * ms\n        }\n      }\n      {\n        const eta1 =\n          remainingMs > 0 ? remainingMs / maxSyncFileJobs() : undefined\n        const eta2 =\n          afq.assetProcessRate.eventCount > 5\n            ? map(\n                afq.assetProcessRate.msPerEvent,\n                ms => (imgCount + vidCount) * ms\n              )\n            : undefined\n        this.logger.info(\"ETAs\", {\n          eta1,\n          eta2,\n          msPerAssetProcessed: afq.assetProcessRate.msPerEvent,\n          ...afq.stats()\n        })\n        map(avg(compact([eta1, eta2])), eta => this.eta.push(round(eta)))\n      }\n    }\n    return p as Percents\n  }\n}\n", "import { greatestBy, uniqInPlace } from \"../../core/Array\"\nimport { filterAsync, thenMap, thenMapOr } from \"../../core/async/Promise\"\nimport { nativePathIsReadableDirectory } from \"../../core/fs/Path\"\nimport { PosixFile } from \"../../core/fs/PosixFile\"\nimport { mkLogger } from \"../../core/Logger\"\nimport { libraryOriginalsDir } from \"../../core/settings/LibraryDirs\"\nimport { Settings } from \"../../core/settings/Settings\"\nimport { TTLSet } from \"../../core/TTLSet\"\nimport { nativePath2uri } from \"../../core/uri/FileURI\"\nimport { volumes } from \"../../core/volumes/Volumes\"\nimport { dayMs, hourMs, minuteMs } from \"../../fe/Date\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { orElse } from \"../../fe/Maybe\"\nimport { PromiseMaybe } from \"../../fe/MaybeTypes\"\nimport { gt, gt0 } from \"../../fe/Number\"\nimport { thenCollect } from \"../../fe/Promise\"\nimport { Operation, OperationNames } from \"../model/Operation\"\nimport { Progress, ProgressTimes } from \"../model/Progress\"\n\nconst logger = lazy(() => mkLogger(\"SyncPaths\"))\n\nexport const nativePathBlocklist = new TTLSet(10 * minuteMs)\n\nexport interface UriPath {\n  nativePath: string\n  uri: string\n}\n\nasync function volumeUriPaths() {\n  return thenCollect(volumes(), vol =>\n    vol.ignorable !== false && gt0(vol.size)\n      ? thenMap(nativePath2uri(vol.mountpoint, vol), uri => ({\n          nativePath: vol.mountpoint,\n          uri: uri.toString()\n        }))\n      : undefined\n  )\n}\n\nfunction posixFileToUriPath(f: PosixFile) {\n  return thenMap(f.uri(), uri => ({ nativePath: f.nativePath, uri }))\n}\n\nfunction nativePathToUriPath(nativePath: string) {\n  return thenMap(nativePath2uri(nativePath), uri => ({\n    nativePath,\n    uri: uri.toString()\n  }))\n}\n\nasync function scanPaths() {\n  return thenCollect(Settings.scanPaths.values, nativePathToUriPath)\n}\n\nexport async function pathsToSync() {\n  const arr: UriPath[] = []\n  arr.push(...(await scanPaths()))\n  if (Settings.scanAllDrives.valueOrDefault) {\n    arr.push(...(await volumeUriPaths()))\n  }\n\n  const lp = await thenMapOr(libraryOriginalsDir(), posixFileToUriPath, () =>\n    logger().throw(\"libraryOriginalsDir was null\", Settings.libraryPath.value)\n  )\n\n  if (Settings.scanLibraryFirst.valueOrDefault) {\n    arr.unshift(lp!)\n  }\n\n  if (Settings.scanLibraryLast.valueOrDefault) {\n    arr.push(lp!)\n  }\n\n  uniqInPlace(arr, ea => ea.nativePath)\n\n  const result = await filterAsync(\n    arr,\n    ea =>\n      !nativePathBlocklist.has(ea.nativePath) &&\n      nativePathIsReadableDirectory(ea.nativePath)\n  )\n\n  logger().info(\"pathsToSync\", result)\n  return result\n}\n\nexport type UriPathTimes = UriPath & Partial<Exclude<ProgressTimes, \"uri\">>\n\nexport async function pathsAndTimesToSync() {\n  const todo = await pathsToSync()\n  const times = await Progress.times()\n  return todo.map(path => ({\n    ...times.find(ea => ea.uri === path.uri),\n    ...path\n  }))\n}\n\nexport async function bestPathToSync(): PromiseMaybe<UriPathTimes> {\n  const arr = await pathsAndTimesToSync()\n  return bestStable(arr)\n}\n\n/**\n * This algorithm tries to keep a stable \"best\" pick, until the best is done.\n */\nexport async function bestStable(arr: UriPathTimes[]) {\n  const op = await Operation.getFirstPendingOp({\n    name: OperationNames.forceRestartSync\n  })\n\n  const staleCompletedAt = orElse(\n    op?.createdAt,\n    Date.now() - Settings.syncIntervalHours.valueOrDefault * hourMs\n  )\n\n  // If we aren't being forced to resync, and syncIntervalHours is <= 0, we've\n  // disabled auto rescan: notCompletedRecently should be empty.\n\n  const notCompletedRecently =\n    op == null && Settings.syncIntervalHours.valueOrDefault <= 0\n      ? []\n      : arr.filter(ea => !gt(ea.lastCompletedAt, staleCompletedAt))\n\n  logger().info(\"bestStable()\", {\n    arr,\n    staleCompletedAt,\n    notCompletedRecently: notCompletedRecently.map(ea => ea.nativePath)\n  })\n\n  {\n    // If any paths have never been completed before, work on the path most-recently worked on.\n    const longAgo = Date.now() - 30 * dayMs\n    const notCompleted = notCompletedRecently.filter(\n      ea => !gt(ea.lastCompletedAt, longAgo)\n    )[0]\n    if (notCompleted != null) {\n      logger().info(\"bestStable()\", { notCompleted })\n      return notCompleted\n    }\n  }\n\n  logger().info(\n    \"bestStable(): all paths have been completed at least once in the last month (yay)\"\n  )\n\n  {\n    const mostRecentlyUpdated = greatestBy(notCompletedRecently, ea =>\n      orElse(ea.lastUpdatedAt, Date.now())\n    )\n\n    if (mostRecentlyUpdated != null) {\n      logger().info(\"bestStable()\", { mostRecentlyUpdated })\n      return mostRecentlyUpdated\n    }\n  }\n\n  logger().info(\n    \"bestPathToSync(): all paths have been recently completed (yay). Marking sync as complete.\"\n  )\n\n  await Operation.markOpCompleted({ name: OperationNames.forceRestartSync })\n\n  return\n}\n", "import { end, EndableRanks } from \"../../core/async/Endable\"\nimport { EndableWrapper } from \"../../core/async/EndableWrapper\"\nimport { thenMap } from \"../../core/async/Promise\"\nimport { PosixFile } from \"../../core/fs/PosixFile\"\nimport { Latch } from \"../../fe/Latch\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { FileProcessor } from \"../sync-file/NativePathImportTask\"\nimport { AssetFileUpdater } from \"../sync-file/UpdateResult\"\nimport { DirectorySync } from \"./DirectorySync\"\nimport { Sync } from \"./Sync\"\nimport { bestPathToSync, nativePathBlocklist, UriPathTimes } from \"./SyncPaths\"\n\n/**\n * Manages running Sync jobs for all valid volumes or scan paths.\n */\nexport class SyncRunner extends EndableWrapper implements Sync {\n  private readonly _doneLatch = new Latch()\n\n  private currentSyncUri: Maybe<UriPathTimes>\n  private currentSync: Maybe<Sync>\n\n  constructor(\n    readonly fileHandler: FileProcessor,\n    readonly assetFileUpdater: AssetFileUpdater,\n    readonly currentWorkQueueLength: () => number\n  ) {\n    super(\"SyncRunner\", () => this.endCurrentSync(), EndableRanks.first)\n    void this.maybeSetupNextSync()\n  }\n\n  async progress() {\n    return thenMap(this.currentSync, ea => ea.progress())\n  }\n\n  done(): boolean {\n    return this._doneLatch.settled\n  }\n\n  donePromise() {\n    return this._doneLatch.promise\n  }\n\n  private endCurrentSync(): Promise<void> {\n    const s = this.currentSync\n    this.currentSync = undefined\n    this.currentSyncUri = undefined\n    return end(s)\n  }\n\n  private async setSyncPath(upt: UriPathTimes) {\n    if (this.ended) return\n\n    const s = DirectorySync.for({\n      root: PosixFile.for(upt.nativePath),\n      uri: upt.uri.toString(),\n      fileHandler: this.fileHandler,\n      assetFileUpdater: this.assetFileUpdater,\n      currentWorkQueueLength: this.currentWorkQueueLength\n    })\n\n    void s\n      .then(async sync => {\n        this.currentSync = sync\n        this.currentSyncUri = sync == null ? undefined : upt\n        if (sync != null) {\n          this.logger.info(\"setSyncPath(): waiting for completion...\", upt)\n          await sync.donePromise()\n          this.logger.info(\"setSyncPath(): done\", upt)\n        } else {\n          nativePathBlocklist.add(upt.nativePath)\n          this.logger.warn(\"setSyncPath(): no-op (CHECK ME!)\", upt)\n        }\n      })\n      .catch(err => {\n        this.logger.warn(\"setSyncPath(): caught\", err)\n      })\n      .then(() => this.maybeSetupNextSync())\n  }\n\n  /**\n   * Make sure we're working on the \"best\" directory.\n   */\n  async maybeSetupNextSync() {\n    if (this.ended || this._doneLatch.resolved) return\n\n    const newBest = await bestPathToSync()\n    if (newBest == null) {\n      void this._doneLatch.resolve()\n      return this.endCurrentSync()\n    }\n\n    // If we're already working on the best, no-op\n    if (this.currentSyncUri?.nativePath !== newBest.nativePath) {\n      return this.setSyncPath(newBest)\n    }\n  }\n}\n", "import { Deferred } from \"../../core/async/Deferred\"\nimport { thenOrElse } from \"../../core/async/Promise\"\nimport { PosixFile } from \"../../core/fs/PosixFile\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { Progress } from \"../model/Progress\"\nimport { Sync } from \"./Sync\"\n\n/**\n * FileSync doesn't save progress to the db.\n */\nexport class FileSync implements Sync {\n  private _ended = false\n  readonly name: string\n  readonly sync: Deferred<any>\n\n  constructor(readonly root: PosixFile, sync: Promise<any>) {\n    this.name = \"FileSync(\" + root + \")\"\n    this.sync = new Deferred(this.name).observe(sync)\n  }\n\n  get ended() {\n    return this._ended\n  }\n\n  end() {\n    this._ended = true\n  }\n\n  done() {\n    return this.sync.settled\n  }\n\n  donePromise() {\n    return this.sync.promise\n  }\n\n  readonly uri = lazy(() =>\n    thenOrElse(this.root.uri(), () => \"file:///\" + this.root.posixPath)\n  )\n\n  get volume() {\n    return this.root.nativePath\n  }\n\n  readonly _progress = lazy(async () =>\n    Progress.insertNew(await this.uri(), this.volume)\n  )\n\n  async progress() {\n    const p = await this._progress()\n    return p.assignFromPojo({\n      state: this.sync.pending ? \"processing\" : \"done\"\n    })\n  }\n}\n", "import { end, EndableRanks } from \"../../core/async/Endable\"\nimport { EndableWrapper } from \"../../core/async/EndableWrapper\"\nimport { MaybeLaterMaybe } from \"../../core/async/Later\"\nimport { onError } from \"../../core/error/Error\"\nimport { PosixFile } from \"../../core/fs/PosixFile\"\nimport { mkLogger } from \"../../core/Logger\"\nimport { blank } from \"../../fe/Blank\"\nimport { Latch } from \"../../fe/Latch\"\nimport { lazy } from \"../../fe/Lazy\"\nimport { map } from \"../../fe/Maybe\"\nimport { Maybe } from \"../../fe/MaybeTypes\"\nimport { toA } from \"../../fe/toA\"\nimport { FileProcessor } from \"../sync-file/NativePathImportTask\"\nimport { AssetFileUpdater } from \"../sync-file/UpdateResult\"\nimport { DirectorySync } from \"./DirectorySync\"\nimport { FileSync } from \"./FileSync\"\nimport { Sync } from \"./Sync\"\n\nconst logger = lazy(() => mkLogger(\"Syncs\"))\n\nexport async function syncForPath(\n  nativePath: string,\n  importer: FileProcessor,\n  assetFileUpdater: AssetFileUpdater,\n  currentWorkQueueLength: () => number\n) {\n  if (blank(nativePath)) return\n\n  const root = PosixFile.for(nativePath)\n\n  if (await root.isNonEmptyFile()) {\n    return new FileSync(root, importer(nativePath))\n  } else if (await root.isDirectory()) {\n    // Let's see if it's time.\n    return DirectorySync.for({\n      root,\n      fileHandler: importer,\n      assetFileUpdater,\n      currentWorkQueueLength\n    })\n  } else {\n    logger().warn(\"syncPaths(): Cannot import non-empty-file, non-dir: \" + root)\n    return\n  }\n}\n\n/**\n * Expose multiple Sync instances as a Sync\n */\nexport class Syncs extends EndableWrapper implements Sync {\n  static forPaths(\n    paths: string[],\n    fileHandler: FileProcessor,\n    assetFileUpdater: AssetFileUpdater,\n    currentWorkQueueLength: () => number\n  ): Syncs {\n    return new Syncs(\n      \"import paths fs sync\",\n      toA(paths).map(path => () =>\n        syncForPath(path, fileHandler, assetFileUpdater, currentWorkQueueLength)\n      )\n    )\n  }\n\n  private currentSync: Maybe<Sync>\n  private readonly _done = new Latch()\n  constructor(name: string, private readonly laters: MaybeLaterMaybe<Sync>[]) {\n    super(`Syncs(${name})`, () => end(this.currentSync), EndableRanks.first)\n    void this.run()\n  }\n\n  // only run once:\n  private run = lazy(async () => {\n    try {\n      for (const later of this.laters) {\n        const next = await later()\n        if (next == null) continue\n        this.currentSync = next\n        await next.donePromise()\n      }\n      void this._done.resolve()\n    } catch (err) {\n      onError(\"Syncs.run() failed\", err)\n      void this._done.reject(err)\n    }\n  })\n\n  done(): boolean {\n    return !this._done.pending\n  }\n\n  donePromise(): Promise<void> {\n    return this._done.promise\n  }\n\n  async progress() {\n    return map(this.currentSync, ea => ea.progress())\n  }\n}\n", "try {\n  require(\"source-map-support\").install()\n} catch {\n  //\n}\nimport { CLI } from \"../core/cli/CLI\"\nimport { CommonArgs } from \"./cli/CommonArgs\"\nimport { ExitWhenDoneArg } from \"./cli/ExitWhenDoneArg\"\nimport { ForceArg } from \"./cli/ForceArg\"\nimport { NoFilterArg } from \"./cli/NoFilterArg\"\nimport { RebuildArg } from \"./cli/RebuildArg\"\nimport { SkipUpdateArg } from \"./cli/SkipUpdateArg\"\nimport { SyncService } from \"./sync/SyncService\"\n\nasync function run() {\n  const cmd = await new CLI(\n    \"sync\",\n    \"[files-or-directories...]\",\n    \"If paths are provided on the command line, they should be fully-qualified.\\n\\n* Paths to directories will be scanned recursively.\\n* Paths to files will be imported if they pass configured filters.\\n\\nNote that sync will spawn 1 or more `sync-file` processes to work in parallel.\\n\\nIf a sync job is running, it can be cancelled by sending process signal SIGUSR1, or by sending `--cancel-sync` (followed by a newline) to stdin.\"\n  )\n    .add(\n      ForceArg,\n      RebuildArg,\n      NoFilterArg,\n      CommonArgs,\n      SkipUpdateArg,\n      ExitWhenDoneArg\n    )\n    .parse()\n  new SyncService(cmd.args)\n}\n\nvoid run()\n"],
  "mappings": ";;;;k1BAAA,uBAAM,IAAQ,CACZ,mBAAoB,2BACpB,uBAAwB,+BACxB,cAAe,qBACf,yBAA0B,iCAC1B,mBAAoB,2BACpB,oBAAqB,6BAGvB,gBAA0B,MAAM,CAC9B,YAAa,EAAS,CACpB,MAAM,GACN,KAAK,KAAO,KAAK,YAAY,KAC7B,KAAK,KAAO,GAAM,KAAK,YAAY,MACnC,MAAM,kBAAkB,KAAM,KAAK,eAIvC,GAAO,QAAQ,YAAc,GAE7B,GAAO,QAAQ,mBAAqB,aAAiC,GAAY,GACjF,GAAO,QAAQ,uBAAyB,aAAqC,GAAY,GACzF,GAAO,QAAQ,cAAgB,aAA4B,GAAY,GACvE,GAAO,QAAQ,yBAA2B,aAAuC,GAAY,GAC7F,GAAO,QAAQ,mBAAqB,aAAiC,GAAY,GACjF,GAAO,QAAQ,oBAAsB,aAAkC,GAAY,KCzBnF,uBAAO,QAAU,GAAS,CAAC,CAAC,GAAS,EAAM,cAAgB,SCA3D,uBAAM,IAAmB,KAEzB,GAAO,QAAU,SAAsB,EAAQ,CAC7C,GAAI,MAAO,IAAW,YACpB,MAAO,QAAO,KAAK,IAGrB,GAAI,OAAO,SAAS,GAClB,MAAO,GAGT,GAAI,GAAS,GACX,MAAO,QAAO,KAAK,KAAK,UAAU,GAAS,QAG7C,GAAI,MAAO,IAAW,SACpB,KAAM,IAAI,WAAU,8DAGtB,MAAO,QAAO,KAAK,EAAQ,WCnB7B,uBAAM,IAAS,IACT,GAAS,GAAS,GAClB,GAAO,GAAS,GAChB,GAAM,GAAO,GACb,GAAO,GAAM,EACb,GAAO,GAAM,OAEb,GAAQ,sGAEd,GAAO,QAAU,AAAC,GAAQ,CACxB,GAAM,GAAU,GAAM,KAAK,GAE3B,GAAI,CAAC,EACH,KAAM,IAAI,WAAU,gCAAgC,OAGtD,GAAM,GAAQ,WAAW,EAAQ,IAGjC,OAFa,EAAQ,GAAG,mBAGjB,UACA,WACA,aACA,cACA,IACH,MAAO,MAAK,MAAM,EAAQ,QACvB,aACA,cACA,UACA,WACA,IACH,MAAO,MAAK,MAAM,EAAQ,QACvB,WACA,YACA,SACA,UACA,IACH,MAAO,MAAK,MAAM,EAAQ,QACvB,UACA,WACA,IACH,MAAO,MAAK,MAAM,EAAQ,QACvB,WACA,YACA,IACH,MAAO,MAAK,MAAM,EAAQ,QACvB,WACA,YACA,SACA,UACA,IACH,MAAO,MAAK,MAAM,EAAQ,QCnDhC,uBAAM,IAAa,KAEnB,GAAO,QAAU,CAAC,CAChB,WAAU,YAAW,MAAM,GAAM,SAAQ,MAAK,MAAK,YAAW,MAAM,GAAI,MAAQ,WAC/E,IAAY,CACb,GAAI,CAAE,aAAe,QAAS,CAAC,EAAI,UACjC,KAAM,IAAI,WAAU,2CAGtB,GAAM,GAAO,EAAI,UAEjB,GAAI,IAAQ,OAAW,CACrB,GAAI,MAAO,IAAQ,UACjB,KAAM,IAAI,WAAU,iCAGtB,AAAI,GACF,GAAQ,IAAM,GAAI,MAAK,IAI3B,GAAI,IAAc,OAAW,CAC3B,GAAI,MAAO,IAAc,SACvB,KAAM,IAAI,WAAU,sCAGtB,EAAQ,IAAM,GAAI,MAAK,EAAO,GAAG,IAGnC,GAAI,IAAc,OAAW,CAC3B,GAAI,MAAO,IAAc,SACvB,KAAM,IAAI,WAAU,sCAGtB,EAAQ,IAAM,GAAI,MAAK,EAAO,GAAG,IAGnC,GAAI,IAAa,OAAW,CAC1B,GAAI,MAAO,IAAa,SACtB,KAAM,IAAI,WAAU,qCAGtB,EAAQ,IAAM,EAGhB,GAAI,IAAW,OAAW,CACxB,GAAI,MAAO,IAAW,SACpB,KAAM,IAAI,WAAU,mCAGtB,EAAQ,IAAM,EAGhB,GAAI,IAAY,OAAW,CACzB,GAAI,MAAO,IAAY,SACrB,KAAM,IAAI,WAAU,oCAGtB,EAAQ,IAAM,EAGhB,GAAI,IAAQ,OAAW,CACrB,GAAI,MAAO,IAAQ,SACjB,KAAM,IAAI,WAAU,gCAGtB,EAAQ,IAAM,EAGhB,GAAI,IAAQ,OAAW,CACrB,GAAI,MAAO,IAAQ,SACjB,KAAM,IAAI,WAAU,gCAGtB,EAAQ,IAAM,EAGhB,MAAO,MC7ET,uBAAM,IAAuB,KACvB,GAAmB,KACnB,GAAY,GAAW,KAAK,MAAM,KAAK,UAAU,IAEvD,GAAO,QAAU,CAAC,EAAS,IAAY,CACrC,GAAI,OAAO,SAAS,GAAU,CAC5B,GAAI,OAAO,KAAK,GAAS,SAAW,EAClC,KAAM,IAAI,WAAU,0DAGtB,MAAO,GAET,GAAI,CAAC,GAAS,GACZ,KAAM,IAAI,WAAU,8CAGtB,SAAU,GAAU,GACpB,EAAU,GAAa,EAAS,GACzB,OAAO,KAAK,KAAK,UAAU,GAAU,YClB9C,uBAAM,CAAE,uBAA+B,KAEvC,GAAO,QAAU,AAAC,GAAM,CACtB,GAAI,CAAC,OAAO,cAAc,GACxB,KAAM,IAAI,IAAmB,qDAG/B,GAAM,GAAK,CAAC,CAAE,GAAI,YACZ,EAAM,EAAI,WAAc,EAExB,EAAM,OAAO,YAAY,GAE/B,SAAI,cAAc,EAAI,GACtB,EAAI,cAAc,EAAI,GAEf,KCfT,uBAAM,IAAe,KAErB,GAAO,QAAU,IAAI,IAAW,CAC9B,GAAI,GAAc,GAAK,EAAO,QAC9B,OAAS,KAAS,GAAQ,CACxB,EAAQ,OAAO,KAAK,EAAO,QAC3B,GAAM,GAAM,GAAK,OAAO,WAAW,IACnC,EAAc,OAAO,OAAO,CAAC,EAAa,EAAK,IAEjD,MAAO,MCTT,uBAAM,IAAa,AAAC,GACX,EAAO,QAAQ,KAAM,IAAI,QAAQ,MAAO,KAAK,QAAQ,MAAO,KAG/D,GAAW,AAAC,GACT,EAAU,QAAQ,KAAM,KAAK,QAAQ,KAAM,KAG9C,GAAS,AAAC,GACP,GAAW,EAAI,SAAS,WAG3B,GAAS,AAAC,GACP,OAAO,KAAK,GAAS,GAAQ,UAGtC,GAAO,QAAQ,OAAS,GACxB,GAAO,QAAQ,OAAS,KCjBxB,uBAAM,CAAE,WAAmB,KAE3B,GAAO,QAAU,SAAe,EAAQ,EAAS,EAAQ,CACvD,MAAI,GAAO,SAAW,EACb,GAAG,IAAS,GAAO,OAAO,OAAO,OAAa,GAAO,KAGvD,GAAG,IAAS,GAAO,OAAO,OAAO,SCP1C,uBAAM,CAAE,gBAAiB,IAAgB,kBAEnC,GAAe,CAAC,EAAO,IAAW,CACtC,GAAI,EAAM,SAAW,EACnB,MAAO,GAGT,GAAM,GAAS,OAAO,MAAM,GAC5B,SAAM,KAAK,GACJ,GAGH,GAAkB,CAAC,EAAG,IAAM,CAChC,GAAM,GAAS,KAAK,IAAI,EAAE,OAAQ,EAAE,QACpC,MAAO,IAAI,GAAa,EAAG,GAAS,GAAa,EAAG,KAGtD,GAAO,QAAU,KCjBjB,uBAAM,IAAiB,kBACjB,GAAe,gBACf,CAAE,yBAAgC,KAElC,GAAc,KAChB,GACJ,GAAI,GAAO,KAAM,CACf,GAAM,GAAQ,GAAK,UAAU,GAAO,MACpC,GAAO,CAAC,EAAK,EAAQ,EAAM,IAAS,EAAM,SAAU,EAAK,EAAM,EAAM,OAErE,IAAO,CAAC,EAAK,EAAQ,EAAM,IAAS,CAClC,GAAM,GAAM,GAAQ,KAAK,SAAU,EAAK,GAElC,EAAI,OAAO,KAAK,GAElB,EAAI,OAAO,KAAK,IAChB,EAAK,OAAO,KAAK,IACjB,EAEJ,OAAS,GAAK,EAAG,OAAO,WAAW,GAAK,EAAQ,EAAE,EAAG,CACnD,EAAI,OAAO,KAAK,OAAO,aAAa,IACpC,GAAM,GAAM,OAAO,OAAO,CAAC,EAAI,EAAG,IAElC,EAAK,GAAQ,KAAK,SAAU,EAAK,GACjC,EAAI,OAAO,OAAO,CAAC,EAAG,IAIxB,MADY,QAAO,KAAK,GAAG,MAAM,EAAG,IAKxC,GAAM,IAAe,KACf,GAA0B,KAE1B,GAAU,MACR,mCAAoC,EAAG,EAAG,EAAG,EAAO,CACxD,GAAI,GAAI,GAAQ,KAAK,SAAU,EAAG,GAClC,EAAI,EAAE,MAAM,EAAG,IACf,EAAI,OAAO,KAAK,GAEhB,GAAM,GAAO,EAAE,MAAM,EAAG,IAClB,CAAC,EAAI,GAAM,KAAM,SAAQ,IAAI,CACjC,GAAK,EAAG,GAAI,EAAM,yBAClB,GAAK,EAAG,GAAI,EAAM,8BAGd,EAAI,GAAQ,QAAQ,cAAe,EAAG,EAAI,EAAE,MAAM,KAClD,EAAU,GAAI,YAAa,EAAG,EAAG,GACjC,EAAI,GAAQ,KAAK,SAAU,EAAS,GAE1C,MAAO,IAAK,YAAa,CAAC,EAAG,EAAG,GAAI,SAEhC,mCAAoC,EAAK,EAAG,EAAG,CACnD,GAAM,GAAI,EAAI,MAAM,EAAG,IACjB,EAAI,EAAI,MAAM,KACd,EAAI,EAAI,MAAM,GAAI,KAElB,EAAO,EAAE,MAAM,EAAG,IAClB,CAAC,EAAI,GAAM,KAAM,SAAQ,IAAI,CACjC,GAAK,EAAG,GAAI,EAAM,yBAClB,GAAK,EAAG,GAAI,EAAM,8BAGd,EAAU,GAAI,YAAa,EAAG,EAAG,GAEjC,EAAK,GAAQ,KAAK,SAAU,EAAS,GACrC,EAAU,GAAQ,QAAQ,cAAe,EAAG,EAAI,EAAE,MAAM,KAE9D,MAAI,CAAC,GAAgB,EAAG,IAAO,CAAC,EACvB,GAGF,GAET,KAAM,EAAK,EAAS,EAAK,CACvB,GAAM,GAAO,GAAO,WAAW,EAAK,GACpC,SAAK,OAAO,GACL,EAAK,UAEd,OAAQ,EAAK,EAAS,EAAK,EAAW,CACpC,MAAO,IAAO,OAAO,EAAK,EAAS,EAAK,IAE1C,KAAM,EAAK,EAAS,EAAK,CACvB,MAAO,IAAO,KAAK,EAAK,EAAS,IAEnC,QAAS,EAAQ,EAAW,EAAK,EAAI,CACnC,GAAM,GAAY,GAAO,eAAe,EAAQ,EAAK,GACrD,MAAO,QAAO,OAAO,CAAC,EAAU,OAAO,GAAY,EAAU,WAE/D,QAAS,EAAQ,EAAY,EAAK,EAAI,CACpC,GAAM,GAAY,GAAO,iBAAiB,EAAQ,EAAK,GACvD,MAAO,QAAO,OAAO,CAAC,EAAU,OAAO,GAAa,EAAU,YAIlE,GAAO,QAAU,KChGjB,uBAAM,CAAE,SAAiB,KAEnB,GAAc,KACd,GAAe,KAErB,GAAO,QAAU,eAA2B,EAAG,EAAG,EAAG,EAAK,EAAK,EAAmB,CAChF,GAAM,GAAK,GAAI,EAAG,EAAG,GACf,EAAM,KAAM,IAAK,EAAK,EAAI,GAEhC,GAAI,EAAI,SAAW,EACjB,KAAM,IAAI,WAAU,WAAW,EAAE,MAAM,EAAG,8BAG5C,MAAO,IAAK,EAAG,CAAC,EAAG,GAAM,MCb3B,uBAAM,CACJ,UAAW,CACT,sBAAuB,GACvB,uBAAwB,IAE1B,oBACA,cACU,kBAEN,GAAsB,KACtB,GAAuB,KACvB,GAAe,KAErB,YAAmB,EAAK,CAKtB,GAJM,YAAe,KACnB,GAAM,GAAiB,IAGrB,EAAI,OAAS,WAAa,EAAI,oBAAsB,MACtD,KAAM,IAAI,WAAU,mDAGtB,MAAO,GAGT,GAAO,QAAU,eAAuB,EAAS,EAAK,EAAyB,GAAI,CAA7B,GAAE,WAAF,EAAa,KAAb,EAAa,CAAX,WACtD,GAAM,GAAI,GAAa,EAAS,GAC1B,EAAI,GAAY,GACtB,SAAM,GAAS,GACR,GAAK,aAAc,EAAG,EAAG,SAAU,CAAE,MAAK,WAAS,eAAc,QC7B1E,uBAAM,CAAE,uBAA+B,KACjC,GAAa,KAEnB,GAAO,QAAU,CAAC,CAChB,YAAW,YAAW,YAAW,cAAa,UAAS,SAAQ,iBAAgB,WAAU,MAAM,GAAI,OAClG,IAAY,CACb,GAAI,CAAE,aAAe,QAAS,CAAC,EAAI,UACjC,KAAM,IAAI,WAAU,2CAGtB,GAAM,GAAO,EAAI,UAGjB,GAAI,OAAS,IAAW,MAAO,GAAQ,KAAQ,SAC7C,KAAM,IAAI,IAAmB,gCAG/B,GAAI,IAAW,OAAW,CACxB,GAAI,MAAO,IAAW,SACpB,KAAM,IAAI,WAAU,mCAGtB,GAAI,EAAQ,MAAQ,EAClB,KAAM,IAAI,IAAmB,mBAKjC,GAAI,OAAS,IAAW,MAAO,GAAQ,KAAQ,SAC7C,KAAM,IAAI,IAAmB,gCAG/B,GAAI,IAAY,OAAW,CACzB,GAAI,MAAO,IAAY,SACrB,KAAM,IAAI,WAAU,oCAGtB,GAAI,EAAQ,MAAQ,EAClB,KAAM,IAAI,IAAmB,oBAKjC,GAAI,OAAS,IAAW,MAAO,GAAQ,KAAQ,SAC7C,KAAM,IAAI,IAAmB,gCAG/B,GAAI,IAAa,OAAW,CAC1B,GAAI,MAAO,IAAa,SACtB,KAAM,IAAI,WAAU,qCAGtB,GAAI,EAAQ,MAAQ,EAClB,KAAM,IAAI,IAAmB,qBAIjC,GAAI,IAAmB,QAAa,MAAO,IAAmB,SAC5D,KAAM,IAAI,WAAU,2CAGtB,GAAM,GAAY,EAAiB,GAAG,GAAkB,EAGpD,EACJ,GAAI,OAAS,GAAS,CACpB,GAAI,MAAO,GAAQ,KAAQ,SACzB,KAAM,IAAI,IAAmB,gCAG/B,GADA,EAAM,GAAI,MAAK,EAAQ,KAAK,UACxB,CAAC,EACH,KAAM,IAAI,IAAmB,8CAE/B,GAAI,CAAC,GACC,EAAM,EAAO,EACf,KAAM,IAAI,IAAmB,8BAMnC,GAAI,OAAS,GAAS,CACpB,GAAI,MAAO,GAAQ,KAAQ,SACzB,KAAM,IAAI,IAAmB,gCAE/B,GAAM,GAAM,GAAI,MAAK,EAAQ,KAAK,UAClC,GAAI,CAAC,EACH,KAAM,IAAI,IAAmB,8CAE/B,GAAI,CAAC,GACC,EAAM,EAAO,EACf,KAAM,IAAI,IAAmB,2BAMnC,GAAI,OAAS,GAAS,CACpB,GAAI,MAAO,GAAQ,KAAQ,SACzB,KAAM,IAAI,IAAmB,gCAE/B,GAAM,GAAM,GAAI,MAAK,EAAQ,KAAK,UAClC,GAAI,CAAC,EACH,KAAM,IAAI,IAAmB,8CAE/B,GAAI,CAAC,GACC,GAAO,EAAO,EAChB,KAAM,IAAI,IAAmB,oBAMnC,GAAI,IAAgB,OAAW,CAC7B,GAAI,MAAO,IAAgB,SACzB,KAAM,IAAI,WAAU,wCAGtB,GAAI,CAAE,QAAS,IACb,KAAM,IAAI,IAAmB,qBAG/B,GAAI,EAAM,GAAG,GAAe,EAAO,EACjC,KAAM,IAAI,IAAmB,4BC3HnC,uBAAM,CAAE,kBAA0B,KAE5B,CAAE,OAAQ,IAAmB,kBAC7B,GAAmB,KAEzB,GAAO,QAAU,AAAC,GAAY,CAC5B,GAAI,CACF,GAAM,GAAS,KAAK,MAAM,GAC1B,UAAO,GAAS,IACT,QACA,EAAP,CACA,KAAM,IAAI,IAAc,iDCX5B,uBAAM,CAAE,iBAAe,6BAAqC,KAEtD,CAAE,WAAmB,KACrB,CAAE,WAAmB,KACrB,GAAc,KAEpB,GAAO,QAAU,eAA6B,EAAG,EAAO,EAAK,EAAW,EAAK,CAC3E,GAAI,MAAO,IAAU,SACnB,KAAM,IAAI,WAAU,0BAGtB,GAAI,EAAM,OAAO,EAAG,EAAE,UAAY,EAChC,KAAM,IAAI,IAAc,kBAAkB,EAAE,MAAM,EAAG,aAGvD,GAAM,CAAE,EAAG,EAAO,EAAG,EAAM,UAAW,EAAM,OAAO,EAAE,QAAQ,MAAM,KACnE,GAAI,IAAW,GAAK,IAAW,EAC7B,KAAM,IAAI,IAAc,+CAG1B,GAAI,GACA,EAEJ,GAAI,CACF,EAAK,GAAO,GACZ,EAAI,GAAO,GAAQ,UACZ,GAAP,CACA,KAAM,IAAI,IAAc,+CAG1B,GAAM,GAAI,EAAG,MAAM,EAAG,CAAC,GACjB,EAAI,EAAG,MAAM,CAAC,GACd,EAAK,GAAI,EAAG,EAAG,GAIrB,GAAI,CAFU,KAAM,IAAO,EAAK,EAAI,EAAK,GAGvC,KAAM,IAAI,IAAyB,qBAGrC,MAAO,CACL,IACA,OAAQ,EAAE,OAAS,EAAI,WC1C3B,uBAAM,CACJ,UAAW,CACT,sBAAuB,GACvB,uBAAwB,IAE1B,mBACA,cACU,kBAEN,GAAwB,KACxB,GAAgB,KAChB,GAAiB,KAEvB,YAAmB,EAAK,CAKtB,GAJI,EAAE,aAAe,MAAc,EAAI,OAAS,YAC9C,GAAM,GAAgB,IAGpB,EAAI,OAAS,UAAY,EAAI,oBAAsB,MACrD,KAAM,IAAI,WAAU,iDAGtB,MAAO,GAGT,GAAO,QAAU,eAAyB,EAAO,EAAK,EAAmD,GAAI,CAAvD,GAAE,YAAW,GAAO,SAAS,IAA7B,EAAuC,KAAvC,EAAuC,CAArC,WAAkB,WACxE,EAAM,GAAS,GAEf,GAAM,CAAE,IAAG,UAAW,KAAM,IAAO,aAAc,EAAO,SAAU,IAAK,CAAE,MAAK,WAAS,gBAEvF,GAAI,EACF,MAAI,GACK,CAAE,QAAS,EAAG,SAAQ,QAAS,KAAM,QAAS,UAGhD,EAGT,GAAM,GAAU,GAAM,GAGtB,MAFA,IAAc,EAAS,GAEnB,EACK,CAAE,UAAS,SAAQ,QAAS,KAAM,QAAS,UAG7C,KC7CT,uBAAM,CAAE,mBAAiB,cAAsB,kBAE/C,GAAO,QAAU,SAAmB,EAAQ,EAAK,CAK/C,GAJM,YAAe,KACnB,GAAM,GAAgB,IAGpB,EAAI,OAAS,UAAY,EAAI,mBAAqB,GACpD,KAAM,IAAI,WAAU,GAAG,oDAGzB,MAAO,MCXT,uBAAM,IAAiB,kBACjB,CAAE,cAAsB,gBAExB,GAAa,GAAU,GAAO,YAEpC,GAAO,QAAU,eAA4B,EAAO,CAClD,GAAM,GAAM,OAAO,YAAY,GAC/B,MAAO,IAAW,MCPpB,uBAAM,IAAsB,KACtB,GAAW,AAAQ,KAA+B,KAAK,OAAW,YAClE,GAAuB,KACvB,GAAsB,KACtB,CAAE,mCAAoC,IAAoB,KAEhE,GAAO,QAAU,eAA0B,EAAS,EAAK,EAAgC,GAAI,CAApC,GAAE,UAAQ,SAAV,EAAoB,KAApB,EAAoB,CAAlB,SAAQ,UACjE,GAAM,GAAI,GAAa,EAAS,GAChC,EAAM,GAAS,GACf,GAAM,GAAI,GAAY,GAEhB,EAAI,EAAI,SAEd,MAAK,IAAS,QAAQ,IAAI,WAAa,QAAW,CAAC,IACjD,GAAQ,KAAM,IAAY,KAGrB,GAAQ,EAAG,EAAG,EAAG,MCjB1B,uBAAM,CAAE,WAAmB,KACrB,CAAE,mCAAoC,IAAoB,KAC1D,CAAE,0BAAwB,kBAA0B,KACpD,GAAwB,KACxB,GAAW,AAAQ,KAA+B,KAAK,OAAW,YAClE,GAAgB,KAEhB,GAAI,YAEV,GAAO,QAAU,eAA0B,EAAO,EAAK,EAAmD,GAAI,CAAvD,GAAE,YAAW,GAAO,SAAS,IAA7B,EAAuC,KAAvC,EAAuC,CAArC,WAAkB,WACzE,GAAI,MAAO,IAAU,SACnB,KAAM,IAAI,WAAU,gCAAgC,MAAO,MAK7D,GAFA,EAAM,GAAS,GAEX,EAAM,OAAO,EAAG,GAAE,UAAY,GAChC,KAAM,IAAI,IAAc,kCAG1B,GAAM,CAAE,EAAG,EAAK,EAAG,EAAO,GAAI,UAAW,EAAM,OAAO,GAAE,QAAQ,MAAM,KACtE,GAAI,EAAS,EACX,KAAM,IAAI,IAAc,+CAG1B,GAAM,GAAI,GAAO,GACX,EAAM,GAAO,GACb,EAAI,EAAI,SAER,EAAI,KAAM,IAAQ,EAAK,EAAG,GAChC,GAAI,CAAC,EACH,KAAM,IAAI,IAAuB,qBAGnC,GAAI,EAAQ,CACV,GAAI,OAAO,KAAK,GAAS,SAAW,EAClC,KAAM,IAAI,WAAU,6DAEtB,MAAI,GACK,CAAE,QAAS,EAAG,OAAQ,EAAE,OAAS,EAAI,OAAW,QAAS,KAAM,QAAS,SAG1E,EAGT,GAAM,GAAU,GAAM,GAItB,MAFA,IAAc,EAAS,GAEnB,EACK,CAAE,UAAS,OAAQ,EAAE,OAAS,EAAI,OAAW,QAAS,KAAM,QAAS,SAGvE,KCrDT,uBAAM,IAAiB,kBACjB,CAAE,cAAsB,gBAExB,CAAE,uBAA+B,KACjC,GAAsB,KAEtB,GAAkB,GAAU,GAAO,iBAEnC,GAAmB,GACnB,GAAkB,CAAC,MAAO,CAAE,cAAe,OAEjD,kBAA4B,EAAS,CACnC,OAAQ,OACD,QACH,MAAO,IAAO,gBAAgB,KAAM,IAAY,SAC7C,SAAU,CACb,GAAM,CAAE,cAAe,KAAM,IAAgB,GAAG,IAChD,MAAO,WAGP,KAAM,IAAI,IAAmB,2BAInC,GAAO,QAAU,KCxBjB,uBAAM,IAAe,KACf,GAAiB,KACjB,GAAkB,KAClB,GAAkB,KAClB,GAAsB,KAE5B,GAAO,QAAU,CAAE,QAAM,UAAQ,WAAS,WAAS,kBCNnD,uBAAM,CACJ,oBACA,cACU,kBAEN,GAAsB,KACtB,GAAuB,KACvB,GAAe,KAErB,YAAmB,EAAK,CAKtB,GAJM,YAAe,KACnB,GAAM,GAAiB,IAGrB,EAAI,OAAS,WAAa,EAAI,oBAAsB,UACtD,KAAM,IAAI,WAAU,uDAGtB,MAAO,GAGT,GAAO,QAAU,eAAuB,EAAS,EAAK,EAAyB,GAAI,CAA7B,GAAE,WAAF,EAAa,KAAb,EAAa,CAAX,WACtD,GAAM,GAAI,GAAa,EAAS,GAChC,EAAM,GAAS,GACf,GAAM,GAAI,GAAY,GACtB,MAAO,IAAK,aAAc,EAAG,EAAG,OAAW,EAAK,OCzBlD,uBAAM,CACJ,mBACA,cACU,kBAEN,GAAwB,KACxB,GAAgB,KAChB,GAAiB,KAEvB,YAAmB,EAAK,CAKtB,GAJI,EAAE,aAAe,MAAc,EAAI,OAAS,YAC9C,GAAM,GAAgB,IAGpB,EAAI,OAAS,UAAY,EAAI,oBAAsB,UACrD,KAAM,IAAI,WAAU,qDAGtB,MAAO,GAGT,GAAO,QAAU,eAAyB,EAAO,EAAK,EAAmD,GAAI,CAAvD,GAAE,YAAW,GAAO,SAAS,IAA7B,EAAuC,KAAvC,EAAuC,CAArC,WAAkB,WACxE,EAAM,GAAS,GAEf,GAAM,CAAE,IAAG,UAAW,KAAM,IAAO,aAAc,EAAO,OAAW,GAAI,GAEvE,GAAI,EACF,MAAI,GACK,CAAE,QAAS,EAAG,SAAQ,QAAS,KAAM,QAAS,UAGhD,EAGT,GAAM,GAAU,GAAM,GAGtB,MAFA,IAAc,EAAS,GAEnB,EACK,CAAE,UAAS,SAAQ,QAAS,KAAM,QAAS,UAG7C,KCzCT,uBAAM,IAAiB,kBACjB,CAAE,cAAsB,gBAExB,CAAE,uBAA+B,KAEjC,GAAkB,GAAU,GAAO,iBAEzC,kBAA4B,EAAS,CACnC,OAAQ,OACD,SAAU,CACb,GAAM,CAAE,cAAe,KAAM,IAAgB,WAC7C,MAAO,WAGP,KAAM,IAAI,IAAmB,2BAInC,GAAO,QAAU,KClBjB,uBAAM,IAAe,KACf,GAAiB,KACjB,GAAsB,KAE5B,GAAO,QAAU,CAAE,QAAM,UAAQ,kBCJjC,uBAAM,CAAE,iBAAe,uBAA+B,KAChD,CAAE,WAAmB,KACrB,GAAuB,KAE7B,GAAO,QAAU,CAAC,EAAsC,CAAE,QAAQ,IAAS,KAAO,CAChF,GAAI,MAAO,IAAU,SACnB,KAAM,IAAI,WAAU,0BAGtB,GAAM,CACJ,EAAG,EACH,EAAG,EACH,EAAG,EACH,EAAG,EACH,UACE,EAAM,MAAM,KAEhB,GAAI,IAAW,GAAK,IAAW,EAC7B,KAAM,IAAI,IAAc,+CAG1B,GAAI,IAAY,MAAQ,IAAY,KAClC,KAAM,IAAI,IAAmB,8BAG/B,GAAI,IAAY,SAAW,IAAY,SACrC,KAAM,IAAI,IAAmB,8BAG/B,GAAM,GAAS,CAAE,OAAQ,EAAS,GAAO,GAAU,OAAW,QAAS,OAAW,UAAS,WAE3F,GAAI,IAAY,QACd,MAAO,GAGT,GAAM,GAAY,IAAY,KAAO,IAAM,GAEvC,EACJ,GAAI,CACF,EAAM,GAAO,GAAS,MAAM,EAAG,CAAC,SACzB,EAAP,CACA,KAAM,IAAI,IAAc,+CAG1B,MAAK,GAGH,EAAO,QAAU,GAAa,GAF9B,EAAO,QAAU,EAKZ,KClDT,uBAAM,IAAiB,KAEvB,GAAO,QAAU,CAAE,aCFnB,uBAAM,IAAiB,KACjB,GAAa,KACb,GAAa,KAEb,CAAE,WAAmB,KAE3B,GAAO,QAAU,CAAE,UAAQ,MAAI,MAAI,6ECLnC,GAAY,IAAZ,AAAA,UAAY,EAAQ,CAElB,EAAA,EAAA,KAAA,GAAA,OAEA,EAAA,EAAA,MAAA,GAAA,QAEA,EAAA,EAAA,MAAA,GAAA,QAEA,EAAA,EAAA,QAAA,GAAA,YARU,GAAA,GAAA,UAAA,IAAA,SAAQ,uECoDpB,GAAY,IAAZ,AAAA,UAAY,EAAa,CAEvB,EAAA,GAAA,KAEA,EAAA,OAAA,SAEA,EAAA,QAAA,UAEA,EAAA,SAAA,aARU,GAAA,GAAA,eAAA,IAAA,cAAa,uECnDzB,GAAY,IAAZ,AAAA,UAAY,EAAQ,CAElB,EAAA,MAAA,QAEA,EAAA,MAAA,QAEA,EAAA,QAAA,UAEA,EAAA,IAAA,MAEA,EAAA,KAAA,OAEA,EAAA,MAAA,QAEA,EAAA,SAAA,aAdU,GAAA,GAAA,UAAA,IAAA,SAAQ,KAkBpB,AAAA,UAAiB,EAAQ,CAOvB,WAA2B,EAAa,CACtC,OAAQ,OACD,QACH,MAAO,GAAS,UACb,OACH,MAAO,GAAS,SACb,WACA,UACH,MAAO,GAAS,YACb,QACH,MAAO,GAAS,UACb,QACH,MAAO,GAAS,UACb,WACH,MAAO,GAAS,aACb,cAEH,MAAO,GAAS,KAjBN,EAAA,WAAU,IAPX,GAAA,GAAA,UAAA,IAAA,SAAQ,uEClBzB,GAAY,IAAZ,AAAA,UAAY,EAAM,CAEhB,EAAA,QAAA,UAEA,EAAA,QAAA,UAEA,EAAA,QAAA,UAEA,EAAA,UAAA,aAEA,EAAA,QAAA,UAEA,EAAA,OAAA,WAZU,GAAA,GAAA,QAAA,IAAA,OAAM,KAgBlB,AAAA,UAAiB,EAAM,CAOrB,WAA6B,EAAY,CACvC,MAAI,IAAQ,KAAO,EAAO,IACjB,EAAO,QAGZ,IAAS,IACJ,EAAO,UAGZ,GAAQ,KAAO,EAAO,IACjB,EAAO,QAGZ,GAAQ,IACH,EAAO,OAGT,EAAO,QAjBA,EAAA,aAAY,IAPb,GAAA,GAAA,QAAA,IAAA,OAAM,uEC2FvB,GAAY,IAAZ,AAAA,UAAY,EAAyB,CACnC,EAAA,SAAA,iBACA,EAAA,QAAA,iBACA,EAAA,KAAA,cACA,EAAA,YAAA,gBAJU,GAAA,GAAA,2BAAA,IAAA,0BAAyB,uECjGrC,GAAA,IAAA,KAAS,GAAA,SAAA,GAAA,SAWT,GAAA,IAAA,KAAkC,GAAA,cAAA,GAAA,cAClC,GAAA,IAAA,KAAS,GAAA,SAAA,GAAA,SAIT,GAAA,IAAA,KAAS,GAAA,OAAA,GAAA,OACT,GAAA,IAAA,KAOE,GAAA,0BAAA,GAAA,4BCpCF,cAOA,GAAI,IAAe,mEAAmE,MAAM,IAK5F,GAAQ,OAAS,SAAU,EAAQ,CACjC,GAAI,GAAK,GAAU,EAAS,GAAa,OACvC,MAAO,IAAa,GAEtB,KAAM,IAAI,WAAU,6BAA+B,IAOrD,GAAQ,OAAS,SAAU,EAAU,CACnC,GAAI,GAAO,GACP,EAAO,GAEP,EAAU,GACV,EAAU,IAEV,EAAO,GACP,EAAO,GAEP,EAAO,GACP,EAAQ,GAER,EAAe,GACf,EAAe,GAGnB,MAAI,IAAQ,GAAY,GAAY,EAC1B,EAAW,EAIjB,GAAW,GAAY,GAAY,EAC7B,EAAW,EAAU,EAI3B,GAAQ,GAAY,GAAY,EAC1B,EAAW,EAAO,EAIxB,GAAY,EACP,GAIL,GAAY,EACP,GAIF,MCjET,cAqCA,GAAI,IAAiB,KAcjB,GAAiB,EAGjB,GAAW,GAAK,GAGhB,GAAgB,GAAW,EAG3B,GAAuB,GAQ3B,YAAqB,EAAQ,CAC3B,MAAO,GAAS,EACV,EAAC,GAAW,GAAK,EAClB,IAAU,GAAK,EAStB,YAAuB,EAAQ,CAC7B,GAAI,GAAc,GAAS,IAAO,EAC9B,EAAU,GAAU,EACxB,MAAO,GACH,CAAC,EACD,EAMN,GAAQ,OAAS,SAA0B,EAAQ,CACjD,GAAI,GAAU,GACV,EAEA,EAAM,GAAY,GAEtB,EACE,GAAQ,EAAM,GACd,KAAS,GACL,EAAM,GAGR,IAAS,IAEX,GAAW,GAAO,OAAO,SAClB,EAAM,GAEf,MAAO,IAOT,GAAQ,OAAS,SAA0B,EAAM,EAAQ,EAAW,CAClE,GAAI,GAAS,EAAK,OACd,EAAS,EACT,EAAQ,EACR,EAAc,EAElB,EAAG,CACD,GAAI,GAAU,EACZ,KAAM,IAAI,OAAM,8CAIlB,GADA,EAAQ,GAAO,OAAO,EAAK,WAAW,MAClC,IAAU,GACZ,KAAM,IAAI,OAAM,yBAA2B,EAAK,OAAO,EAAS,IAGlE,EAAe,CAAC,CAAE,GAAQ,IAC1B,GAAS,GACT,EAAS,EAAU,IAAS,GAC5B,GAAS,SACF,GAET,EAAU,MAAQ,GAAc,GAChC,EAAU,KAAO,KC1InB,cAiBA,YAAgB,EAAO,EAAO,EAAe,CAC3C,GAAI,IAAS,GACX,MAAO,GAAM,GACR,GAAI,UAAU,SAAW,EAC9B,MAAO,GAEP,KAAM,IAAI,OAAM,IAAM,EAAQ,6BAGlC,GAAQ,OAAS,GAEjB,GAAI,IAAY,iEACZ,GAAgB,gBAEpB,YAAkB,EAAM,CACtB,GAAI,GAAQ,EAAK,MAAM,IACvB,MAAK,GAGE,CACL,OAAQ,EAAM,GACd,KAAM,EAAM,GACZ,KAAM,EAAM,GACZ,KAAM,EAAM,GACZ,KAAM,EAAM,IAPL,KAUX,GAAQ,SAAW,GAEnB,YAAqB,EAAY,CAC/B,GAAI,GAAM,GACV,MAAI,GAAW,QACb,IAAO,EAAW,OAAS,KAE7B,GAAO,KACH,EAAW,MACb,IAAO,EAAW,KAAO,KAEvB,EAAW,MACb,IAAO,EAAW,MAEhB,EAAW,MACb,IAAO,IAAM,EAAW,MAEtB,EAAW,MACb,IAAO,EAAW,MAEb,EAET,GAAQ,YAAc,GAatB,YAAmB,EAAO,CACxB,GAAI,GAAO,EACP,EAAM,GAAS,GACnB,GAAI,EAAK,CACP,GAAI,CAAC,EAAI,KACP,MAAO,GAET,EAAO,EAAI,KAKb,OAHI,GAAa,GAAQ,WAAW,GAEhC,EAAQ,EAAK,MAAM,OACd,EAAM,EAAK,EAAG,EAAI,EAAM,OAAS,EAAG,GAAK,EAAG,IACnD,EAAO,EAAM,GACb,AAAI,IAAS,IACX,EAAM,OAAO,EAAG,GACX,AAAI,IAAS,KAClB,IACS,EAAK,GACd,CAAI,IAAS,GAIX,GAAM,OAAO,EAAI,EAAG,GACpB,EAAK,GAEL,GAAM,OAAO,EAAG,GAChB,MAUN,MANA,GAAO,EAAM,KAAK,KAEd,IAAS,IACX,GAAO,EAAa,IAAM,KAGxB,EACF,GAAI,KAAO,EACJ,GAAY,IAEd,EAET,GAAQ,UAAY,GAkBpB,YAAc,EAAO,EAAO,CAC1B,AAAI,IAAU,IACZ,GAAQ,KAEN,IAAU,IACZ,GAAQ,KAEV,GAAI,GAAW,GAAS,GACpB,EAAW,GAAS,GAMxB,GALI,GACF,GAAQ,EAAS,MAAQ,KAIvB,GAAY,CAAC,EAAS,OACxB,MAAI,IACF,GAAS,OAAS,EAAS,QAEtB,GAAY,GAGrB,GAAI,GAAY,EAAM,MAAM,IAC1B,MAAO,GAIT,GAAI,GAAY,CAAC,EAAS,MAAQ,CAAC,EAAS,KAC1C,SAAS,KAAO,EACT,GAAY,GAGrB,GAAI,GAAS,EAAM,OAAO,KAAO,IAC7B,EACA,GAAU,EAAM,QAAQ,OAAQ,IAAM,IAAM,GAEhD,MAAI,GACF,GAAS,KAAO,EACT,GAAY,IAEd,EAET,GAAQ,KAAO,GAEf,GAAQ,WAAa,SAAU,EAAO,CACpC,MAAO,GAAM,OAAO,KAAO,KAAO,GAAU,KAAK,IASnD,YAAkB,EAAO,EAAO,CAC9B,AAAI,IAAU,IACZ,GAAQ,KAGV,EAAQ,EAAM,QAAQ,MAAO,IAO7B,OADI,GAAQ,EACL,EAAM,QAAQ,EAAQ,OAAS,GAAG,CACvC,GAAI,GAAQ,EAAM,YAAY,KAS9B,GARI,EAAQ,GAOZ,GAAQ,EAAM,MAAM,EAAG,GACnB,EAAM,MAAM,sBACd,MAAO,GAGT,EAAE,EAIJ,MAAO,OAAM,EAAQ,GAAG,KAAK,OAAS,EAAM,OAAO,EAAM,OAAS,GAEpE,GAAQ,SAAW,GAEnB,GAAI,IAAqB,UAAY,CACnC,GAAI,GAAM,OAAO,OAAO,MACxB,MAAO,CAAE,cAAe,OAG1B,YAAmB,EAAG,CACpB,MAAO,GAYT,YAAqB,EAAM,CACzB,MAAI,IAAc,GACT,IAAM,EAGR,EAET,GAAQ,YAAc,GAAoB,GAAW,GAErD,YAAuB,EAAM,CAC3B,MAAI,IAAc,GACT,EAAK,MAAM,GAGb,EAET,GAAQ,cAAgB,GAAoB,GAAW,GAEvD,YAAuB,EAAG,CACxB,GAAI,CAAC,EACH,MAAO,GAGT,GAAI,GAAS,EAAE,OAMf,GAJI,EAAS,GAIT,EAAE,WAAW,EAAS,KAAO,IAC7B,EAAE,WAAW,EAAS,KAAO,IAC7B,EAAE,WAAW,EAAS,KAAO,KAC7B,EAAE,WAAW,EAAS,KAAO,KAC7B,EAAE,WAAW,EAAS,KAAO,KAC7B,EAAE,WAAW,EAAS,KAAO,KAC7B,EAAE,WAAW,EAAS,KAAO,KAC7B,EAAE,WAAW,EAAS,KAAO,IAC7B,EAAE,WAAW,EAAS,KAAO,GAC/B,MAAO,GAGT,OAAS,GAAI,EAAS,GAAI,GAAK,EAAG,IAChC,GAAI,EAAE,WAAW,KAAO,GACtB,MAAO,GAIX,MAAO,GAWT,YAAoC,EAAU,EAAU,EAAqB,CAC3E,GAAI,GAAM,GAAO,EAAS,OAAQ,EAAS,QAqB3C,MApBI,KAAQ,GAIZ,GAAM,EAAS,aAAe,EAAS,aACnC,IAAQ,IAIZ,GAAM,EAAS,eAAiB,EAAS,eACrC,IAAQ,GAAK,IAIjB,GAAM,EAAS,gBAAkB,EAAS,gBACtC,IAAQ,IAIZ,GAAM,EAAS,cAAgB,EAAS,cACpC,IAAQ,GACH,EAGF,GAAO,EAAS,KAAM,EAAS,MAExC,GAAQ,2BAA6B,GAWrC,YAA6C,EAAU,EAAU,EAAsB,CACrF,GAAI,GAAM,EAAS,cAAgB,EAAS,cAqB5C,MApBI,KAAQ,GAIZ,GAAM,EAAS,gBAAkB,EAAS,gBACtC,IAAQ,GAAK,IAIjB,GAAM,GAAO,EAAS,OAAQ,EAAS,QACnC,IAAQ,IAIZ,GAAM,EAAS,aAAe,EAAS,aACnC,IAAQ,IAIZ,GAAM,EAAS,eAAiB,EAAS,eACrC,IAAQ,GACH,EAGF,GAAO,EAAS,KAAM,EAAS,MAExC,GAAQ,oCAAsC,GAE9C,YAAgB,EAAO,EAAO,CAC5B,MAAI,KAAU,EACL,EAGL,IAAU,KACL,EAGL,IAAU,KACL,GAGL,EAAQ,EACH,EAGF,GAOT,YAA6C,EAAU,EAAU,CAC/D,GAAI,GAAM,EAAS,cAAgB,EAAS,cAqB5C,MApBI,KAAQ,GAIZ,GAAM,EAAS,gBAAkB,EAAS,gBACtC,IAAQ,IAIZ,GAAM,GAAO,EAAS,OAAQ,EAAS,QACnC,IAAQ,IAIZ,GAAM,EAAS,aAAe,EAAS,aACnC,IAAQ,IAIZ,GAAM,EAAS,eAAiB,EAAS,eACrC,IAAQ,GACH,EAGF,GAAO,EAAS,KAAM,EAAS,MAExC,GAAQ,oCAAsC,GAO9C,YAA6B,EAAK,CAChC,MAAO,MAAK,MAAM,EAAI,QAAQ,iBAAkB,KAElD,GAAQ,oBAAsB,GAM9B,YAA0B,EAAY,EAAW,EAAc,CA8B7D,GA7BA,EAAY,GAAa,GAErB,GAEE,GAAW,EAAW,OAAS,KAAO,KAAO,EAAU,KAAO,KAChE,IAAc,KAOhB,EAAY,EAAa,GAiBvB,EAAc,CAChB,GAAI,GAAS,GAAS,GACtB,GAAI,CAAC,EACH,KAAM,IAAI,OAAM,oCAElB,GAAI,EAAO,KAAM,CAEf,GAAI,GAAQ,EAAO,KAAK,YAAY,KACpC,AAAI,GAAS,GACX,GAAO,KAAO,EAAO,KAAK,UAAU,EAAG,EAAQ,IAGnD,EAAY,GAAK,GAAY,GAAS,GAGxC,MAAO,IAAU,GAEnB,GAAQ,iBAAmB,KCve3B,cAOA,GAAI,IAAe,KACf,GAAM,OAAO,UAAU,eACvB,GAAe,MAAO,MAAQ,YAQlC,aAAoB,CAClB,KAAK,OAAS,GACd,KAAK,KAAO,GAAe,GAAI,KAAQ,OAAO,OAAO,MAMvD,GAAS,UAAY,SAA4B,EAAQ,EAAkB,CAEzE,OADI,GAAM,GAAI,IACL,EAAI,EAAG,EAAM,EAAO,OAAQ,EAAI,EAAK,IAC5C,EAAI,IAAI,EAAO,GAAI,GAErB,MAAO,IAST,GAAS,UAAU,KAAO,UAAyB,CACjD,MAAO,IAAe,KAAK,KAAK,KAAO,OAAO,oBAAoB,KAAK,MAAM,QAQ/E,GAAS,UAAU,IAAM,SAAsB,EAAM,EAAkB,CACrE,GAAI,GAAO,GAAe,EAAO,GAAK,YAAY,GAC9C,EAAc,GAAe,KAAK,IAAI,GAAQ,GAAI,KAAK,KAAK,KAAM,GAClE,EAAM,KAAK,OAAO,OACtB,AAAI,EAAC,GAAe,IAClB,KAAK,OAAO,KAAK,GAEd,GACH,CAAI,GACF,KAAK,KAAK,IAAI,EAAM,GAEpB,KAAK,KAAK,GAAQ,IAUxB,GAAS,UAAU,IAAM,SAAsB,EAAM,CACnD,GAAI,GACF,MAAO,MAAK,KAAK,IAAI,GAErB,GAAI,GAAO,GAAK,YAAY,GAC5B,MAAO,IAAI,KAAK,KAAK,KAAM,IAS/B,GAAS,UAAU,QAAU,SAA0B,EAAM,CAC3D,GAAI,GAAc,CAChB,GAAI,GAAM,KAAK,KAAK,IAAI,GACxB,GAAI,GAAO,EACP,MAAO,OAEN,CACL,GAAI,GAAO,GAAK,YAAY,GAC5B,GAAI,GAAI,KAAK,KAAK,KAAM,GACtB,MAAO,MAAK,KAAK,GAIrB,KAAM,IAAI,OAAM,IAAM,EAAO,yBAQ/B,GAAS,UAAU,GAAK,SAAqB,EAAM,CACjD,GAAI,GAAQ,GAAK,EAAO,KAAK,OAAO,OAClC,MAAO,MAAK,OAAO,GAErB,KAAM,IAAI,OAAM,yBAA2B,IAQ7C,GAAS,UAAU,QAAU,UAA4B,CACvD,MAAO,MAAK,OAAO,SAGrB,GAAQ,SAAW,KCxHnB,cAOA,GAAI,IAAe,KAMnB,YAAgC,EAAU,EAAU,CAElD,GAAI,GAAQ,EAAS,cACjB,EAAQ,EAAS,cACjB,EAAU,EAAS,gBACnB,EAAU,EAAS,gBACvB,MAAO,GAAQ,GAAS,GAAS,GAAS,GAAW,GAC9C,GAAK,oCAAoC,EAAU,IAAa,EAQzE,aAAuB,CACrB,KAAK,OAAS,GACd,KAAK,QAAU,GAEf,KAAK,MAAQ,CAAC,cAAe,GAAI,gBAAiB,GASpD,GAAY,UAAU,gBACpB,SAA6B,EAAW,EAAU,CAChD,KAAK,OAAO,QAAQ,EAAW,IAQnC,GAAY,UAAU,IAAM,SAAyB,EAAU,CAC7D,AAAI,GAAuB,KAAK,MAAO,GACrC,MAAK,MAAQ,EACb,KAAK,OAAO,KAAK,IAEjB,MAAK,QAAU,GACf,KAAK,OAAO,KAAK,KAarB,GAAY,UAAU,QAAU,UAA+B,CAC7D,MAAK,MAAK,SACR,MAAK,OAAO,KAAK,GAAK,qCACtB,KAAK,QAAU,IAEV,KAAK,QAGd,GAAQ,YAAc,KC9EtB,cAOA,GAAI,IAAoB,KACpB,GAAe,KACf,GAAW,AAAQ,KAAe,SAClC,GAAc,AAAQ,KAAkB,YAU5C,YAA4B,EAAO,CACjC,AAAK,GACH,GAAQ,IAEV,KAAK,MAAQ,GAAK,OAAO,EAAO,OAAQ,MACxC,KAAK,YAAc,GAAK,OAAO,EAAO,aAAc,MACpD,KAAK,gBAAkB,GAAK,OAAO,EAAO,iBAAkB,IAC5D,KAAK,SAAW,GAAI,IACpB,KAAK,OAAS,GAAI,IAClB,KAAK,UAAY,GAAI,IACrB,KAAK,iBAAmB,KAG1B,GAAmB,UAAU,SAAW,EAOxC,GAAmB,cACjB,SAA0C,EAAoB,CAC5D,GAAI,GAAa,EAAmB,WAChC,EAAY,GAAI,IAAmB,CACrC,KAAM,EAAmB,KACzB,WAAY,IAEd,SAAmB,YAAY,SAAU,EAAS,CAChD,GAAI,GAAa,CACf,UAAW,CACT,KAAM,EAAQ,cACd,OAAQ,EAAQ,kBAIpB,AAAI,EAAQ,QAAU,MACpB,GAAW,OAAS,EAAQ,OACxB,GAAc,MAChB,GAAW,OAAS,GAAK,SAAS,EAAY,EAAW,SAG3D,EAAW,SAAW,CACpB,KAAM,EAAQ,aACd,OAAQ,EAAQ,gBAGd,EAAQ,MAAQ,MAClB,GAAW,KAAO,EAAQ,OAI9B,EAAU,WAAW,KAEvB,EAAmB,QAAQ,QAAQ,SAAU,EAAY,CACvD,GAAI,GAAiB,EACrB,AAAI,IAAe,MACjB,GAAiB,GAAK,SAAS,EAAY,IAGxC,EAAU,SAAS,IAAI,IAC1B,EAAU,SAAS,IAAI,GAGzB,GAAI,GAAU,EAAmB,iBAAiB,GAClD,AAAI,GAAW,MACb,EAAU,iBAAiB,EAAY,KAGpC,GAaX,GAAmB,UAAU,WAC3B,SAAuC,EAAO,CAC5C,GAAI,GAAY,GAAK,OAAO,EAAO,aAC/B,EAAW,GAAK,OAAO,EAAO,WAAY,MAC1C,EAAS,GAAK,OAAO,EAAO,SAAU,MACtC,EAAO,GAAK,OAAO,EAAO,OAAQ,MAEtC,AAAK,KAAK,iBACR,KAAK,iBAAiB,EAAW,EAAU,EAAQ,GAGjD,GAAU,MACZ,GAAS,OAAO,GACX,KAAK,SAAS,IAAI,IACrB,KAAK,SAAS,IAAI,IAIlB,GAAQ,MACV,GAAO,OAAO,GACT,KAAK,OAAO,IAAI,IACnB,KAAK,OAAO,IAAI,IAIpB,KAAK,UAAU,IAAI,CACjB,cAAe,EAAU,KACzB,gBAAiB,EAAU,OAC3B,aAAc,GAAY,MAAQ,EAAS,KAC3C,eAAgB,GAAY,MAAQ,EAAS,OAC7C,OAAQ,EACR,KAAM,KAOZ,GAAmB,UAAU,iBAC3B,SAA6C,EAAa,EAAgB,CACxE,GAAI,GAAS,EACb,AAAI,KAAK,aAAe,MACtB,GAAS,GAAK,SAAS,KAAK,YAAa,IAG3C,AAAI,GAAkB,KAGf,MAAK,kBACR,MAAK,iBAAmB,OAAO,OAAO,OAExC,KAAK,iBAAiB,GAAK,YAAY,IAAW,GACzC,KAAK,kBAGd,OAAO,MAAK,iBAAiB,GAAK,YAAY,IAC1C,OAAO,KAAK,KAAK,kBAAkB,SAAW,GAChD,MAAK,iBAAmB,QAqBhC,GAAmB,UAAU,eAC3B,SAA2C,EAAoB,EAAa,EAAgB,CAC1F,GAAI,GAAa,EAEjB,GAAI,GAAe,KAAM,CACvB,GAAI,EAAmB,MAAQ,KAC7B,KAAM,IAAI,OACR,gJAIJ,EAAa,EAAmB,KAElC,GAAI,GAAa,KAAK,YAEtB,AAAI,GAAc,MAChB,GAAa,GAAK,SAAS,EAAY,IAIzC,GAAI,GAAa,GAAI,IACjB,EAAW,GAAI,IAGnB,KAAK,UAAU,gBAAgB,SAAU,EAAS,CAChD,GAAI,EAAQ,SAAW,GAAc,EAAQ,cAAgB,KAAM,CAEjE,GAAI,GAAW,EAAmB,oBAAoB,CACpD,KAAM,EAAQ,aACd,OAAQ,EAAQ,iBAElB,AAAI,EAAS,QAAU,MAErB,GAAQ,OAAS,EAAS,OACtB,GAAkB,MACpB,GAAQ,OAAS,GAAK,KAAK,EAAgB,EAAQ,SAEjD,GAAc,MAChB,GAAQ,OAAS,GAAK,SAAS,EAAY,EAAQ,SAErD,EAAQ,aAAe,EAAS,KAChC,EAAQ,eAAiB,EAAS,OAC9B,EAAS,MAAQ,MACnB,GAAQ,KAAO,EAAS,OAK9B,GAAI,GAAS,EAAQ,OACrB,AAAI,GAAU,MAAQ,CAAC,EAAW,IAAI,IACpC,EAAW,IAAI,GAGjB,GAAI,GAAO,EAAQ,KACnB,AAAI,GAAQ,MAAQ,CAAC,EAAS,IAAI,IAChC,EAAS,IAAI,IAGd,MACH,KAAK,SAAW,EAChB,KAAK,OAAS,EAGd,EAAmB,QAAQ,QAAQ,SAAU,EAAY,CACvD,GAAI,GAAU,EAAmB,iBAAiB,GAClD,AAAI,GAAW,MACT,IAAkB,MACpB,GAAa,GAAK,KAAK,EAAgB,IAErC,GAAc,MAChB,GAAa,GAAK,SAAS,EAAY,IAEzC,KAAK,iBAAiB,EAAY,KAEnC,OAcP,GAAmB,UAAU,iBAC3B,SAA4C,EAAY,EAAW,EACvB,EAAO,CAKjD,GAAI,GAAa,MAAO,GAAU,MAAS,UAAY,MAAO,GAAU,QAAW,SAC/E,KAAM,IAAI,OACN,gPAMR,GAAI,KAAc,QAAU,IAAc,UAAY,IAC/C,EAAW,KAAO,GAAK,EAAW,QAAU,GAC5C,CAAC,GAAa,CAAC,GAAW,CAAC,GAI7B,IAAI,GAAc,QAAU,IAAc,UAAY,IAC/C,GAAa,QAAU,IAAa,UAAY,IAChD,EAAW,KAAO,GAAK,EAAW,QAAU,GAC5C,EAAU,KAAO,GAAK,EAAU,QAAU,GAC1C,EAEV,OAGA,KAAM,IAAI,OAAM,oBAAsB,KAAK,UAAU,CACnD,UAAW,EACX,OAAQ,EACR,SAAU,EACV,KAAM,OASd,GAAmB,UAAU,mBAC3B,UAAgD,CAc9C,OAbI,GAA0B,EAC1B,EAAwB,EACxB,EAAyB,EACzB,EAAuB,EACvB,EAAe,EACf,EAAiB,EACjB,EAAS,GACT,EACA,EACA,EACA,EAEA,EAAW,KAAK,UAAU,UACrB,EAAI,EAAG,EAAM,EAAS,OAAQ,EAAI,EAAK,IAAK,CAInD,GAHA,EAAU,EAAS,GACnB,EAAO,GAEH,EAAQ,gBAAkB,EAE5B,IADA,EAA0B,EACnB,EAAQ,gBAAkB,GAC/B,GAAQ,IACR,YAIE,EAAI,EAAG,CACT,GAAI,CAAC,GAAK,oCAAoC,EAAS,EAAS,EAAI,IAClE,SAEF,GAAQ,IAIZ,GAAQ,GAAU,OAAO,EAAQ,gBACJ,GAC7B,EAA0B,EAAQ,gBAE9B,EAAQ,QAAU,MACpB,GAAY,KAAK,SAAS,QAAQ,EAAQ,QAC1C,GAAQ,GAAU,OAAO,EAAY,GACrC,EAAiB,EAGjB,GAAQ,GAAU,OAAO,EAAQ,aAAe,EACnB,GAC7B,EAAuB,EAAQ,aAAe,EAE9C,GAAQ,GAAU,OAAO,EAAQ,eACJ,GAC7B,EAAyB,EAAQ,eAE7B,EAAQ,MAAQ,MAClB,GAAU,KAAK,OAAO,QAAQ,EAAQ,MACtC,GAAQ,GAAU,OAAO,EAAU,GACnC,EAAe,IAInB,GAAU,EAGZ,MAAO,IAGX,GAAmB,UAAU,wBAC3B,SAAmD,EAAU,EAAa,CACxE,MAAO,GAAS,IAAI,SAAU,EAAQ,CACpC,GAAI,CAAC,KAAK,iBACR,MAAO,MAET,AAAI,GAAe,MACjB,GAAS,GAAK,SAAS,EAAa,IAEtC,GAAI,GAAM,GAAK,YAAY,GAC3B,MAAO,QAAO,UAAU,eAAe,KAAK,KAAK,iBAAkB,GAC/D,KAAK,iBAAiB,GACtB,MACH,OAMP,GAAmB,UAAU,OAC3B,UAAqC,CACnC,GAAI,GAAM,CACR,QAAS,KAAK,SACd,QAAS,KAAK,SAAS,UACvB,MAAO,KAAK,OAAO,UACnB,SAAU,KAAK,sBAEjB,MAAI,MAAK,OAAS,MAChB,GAAI,KAAO,KAAK,OAEd,KAAK,aAAe,MACtB,GAAI,WAAa,KAAK,aAEpB,KAAK,kBACP,GAAI,eAAiB,KAAK,wBAAwB,EAAI,QAAS,EAAI,aAG9D,GAMX,GAAmB,UAAU,SAC3B,UAAuC,CACrC,MAAO,MAAK,UAAU,KAAK,WAG/B,GAAQ,mBAAqB,KCxa7B,cAOA,GAAQ,qBAAuB,EAC/B,GAAQ,kBAAoB,EAe5B,YAAyB,EAAM,EAAO,EAAS,EAAW,EAAU,EAAO,CAUzE,GAAI,GAAM,KAAK,MAAO,GAAQ,GAAQ,GAAK,EACvC,EAAM,EAAS,EAAS,EAAU,GAAM,IAC5C,MAAI,KAAQ,EAEH,EAEA,EAAM,EAET,EAAQ,EAAM,EAET,GAAgB,EAAK,EAAO,EAAS,EAAW,EAAU,GAK/D,GAAS,GAAQ,kBACZ,EAAQ,EAAU,OAAS,EAAQ,GAEnC,EAKL,EAAM,EAAO,EAER,GAAgB,EAAM,EAAK,EAAS,EAAW,EAAU,GAI9D,GAAS,GAAQ,kBACZ,EAEA,EAAO,EAAI,GAAK,EAuB7B,GAAQ,OAAS,SAAgB,EAAS,EAAW,EAAU,EAAO,CACpE,GAAI,EAAU,SAAW,EACvB,MAAO,GAGT,GAAI,GAAQ,GAAgB,GAAI,EAAU,OAAQ,EAAS,EAC/B,EAAU,GAAS,GAAQ,sBACvD,GAAI,EAAQ,EACV,MAAO,GAMT,KAAO,EAAQ,GAAK,GACd,EAAS,EAAU,GAAQ,EAAU,EAAQ,GAAI,MAAU,GAG/D,EAAE,EAGJ,MAAO,MC7GT,cA2BA,YAAc,EAAK,EAAG,EAAG,CACvB,GAAI,GAAO,EAAI,GACf,EAAI,GAAK,EAAI,GACb,EAAI,GAAK,EAWX,YAA0B,EAAK,EAAM,CACnC,MAAO,MAAK,MAAM,EAAO,KAAK,SAAY,GAAO,IAenD,YAAqB,EAAK,EAAY,EAAG,EAAG,CAK1C,GAAI,EAAI,EAAG,CAYT,GAAI,GAAa,GAAiB,EAAG,GACjC,EAAI,EAAI,EAEZ,GAAK,EAAK,EAAY,GAStB,OARI,GAAQ,EAAI,GAQP,EAAI,EAAG,EAAI,EAAG,IACrB,AAAI,EAAW,EAAI,GAAI,IAAU,GAC/B,IAAK,EACL,GAAK,EAAK,EAAG,IAIjB,GAAK,EAAK,EAAI,EAAG,GACjB,GAAI,GAAI,EAAI,EAIZ,GAAY,EAAK,EAAY,EAAG,EAAI,GACpC,GAAY,EAAK,EAAY,EAAI,EAAG,IAYxC,GAAQ,UAAY,SAAU,EAAK,EAAY,CAC7C,GAAY,EAAK,EAAY,EAAG,EAAI,OAAS,MChH/C,cAOA,GAAI,GAAe,KACf,GAAuB,KACvB,GAAW,AAAQ,KAAe,SAClC,GAAoB,KACpB,GAAY,AAAQ,KAAgB,UAExC,YAA2B,EAAY,EAAe,CACpD,GAAI,GAAY,EAChB,MAAI,OAAO,IAAe,UACxB,GAAY,EAAK,oBAAoB,IAGhC,EAAU,UAAY,KACzB,GAAI,IAAyB,EAAW,GACxC,GAAI,IAAuB,EAAW,GAG5C,GAAkB,cAAgB,SAAS,EAAY,EAAe,CACpE,MAAO,IAAuB,cAAc,EAAY,IAM1D,GAAkB,UAAU,SAAW,EAgCvC,GAAkB,UAAU,oBAAsB,KAClD,OAAO,eAAe,GAAkB,UAAW,qBAAsB,CACvE,aAAc,GACd,WAAY,GACZ,IAAK,UAAY,CACf,MAAK,MAAK,qBACR,KAAK,eAAe,KAAK,UAAW,KAAK,YAGpC,KAAK,uBAIhB,GAAkB,UAAU,mBAAqB,KACjD,OAAO,eAAe,GAAkB,UAAW,oBAAqB,CACtE,aAAc,GACd,WAAY,GACZ,IAAK,UAAY,CACf,MAAK,MAAK,oBACR,KAAK,eAAe,KAAK,UAAW,KAAK,YAGpC,KAAK,sBAIhB,GAAkB,UAAU,wBAC1B,SAAkD,EAAM,EAAO,CAC7D,GAAI,GAAI,EAAK,OAAO,GACpB,MAAO,KAAM,KAAO,IAAM,KAQ9B,GAAkB,UAAU,eAC1B,SAAyC,EAAM,EAAa,CAC1D,KAAM,IAAI,OAAM,6CAGpB,GAAkB,gBAAkB,EACpC,GAAkB,eAAiB,EAEnC,GAAkB,qBAAuB,EACzC,GAAkB,kBAAoB,EAkBtC,GAAkB,UAAU,YAC1B,SAAuC,EAAW,EAAU,EAAQ,CAClE,GAAI,GAAU,GAAY,KACtB,EAAQ,GAAU,GAAkB,gBAEpC,EACJ,OAAQ,OACH,IAAkB,gBACrB,EAAW,KAAK,mBAChB,UACG,IAAkB,eACrB,EAAW,KAAK,kBAChB,cAEA,KAAM,IAAI,OAAM,+BAGlB,GAAI,GAAa,KAAK,WACtB,EAAS,IAAI,SAAU,EAAS,CAC9B,GAAI,GAAS,EAAQ,SAAW,KAAO,KAAO,KAAK,SAAS,GAAG,EAAQ,QACvE,SAAS,EAAK,iBAAiB,EAAY,EAAQ,KAAK,eACjD,CACL,OAAQ,EACR,cAAe,EAAQ,cACvB,gBAAiB,EAAQ,gBACzB,aAAc,EAAQ,aACtB,eAAgB,EAAQ,eACxB,KAAM,EAAQ,OAAS,KAAO,KAAO,KAAK,OAAO,GAAG,EAAQ,QAE7D,MAAM,QAAQ,EAAW,IAyBhC,GAAkB,UAAU,yBAC1B,SAAoD,EAAO,CACzD,GAAI,GAAO,EAAK,OAAO,EAAO,QAM1B,EAAS,CACX,OAAQ,EAAK,OAAO,EAAO,UAC3B,aAAc,EACd,eAAgB,EAAK,OAAO,EAAO,SAAU,IAI/C,GADA,EAAO,OAAS,KAAK,iBAAiB,EAAO,QACzC,EAAO,OAAS,EAClB,MAAO,GAGT,GAAI,GAAW,GAEX,EAAQ,KAAK,aAAa,EACA,KAAK,kBACL,eACA,iBACA,EAAK,2BACL,GAAa,mBAC3C,GAAI,GAAS,EAAG,CACd,GAAI,GAAU,KAAK,kBAAkB,GAErC,GAAI,EAAM,SAAW,OAOnB,OANI,GAAe,EAAQ,aAMpB,GAAW,EAAQ,eAAiB,GACzC,EAAS,KAAK,CACZ,KAAM,EAAK,OAAO,EAAS,gBAAiB,MAC5C,OAAQ,EAAK,OAAO,EAAS,kBAAmB,MAChD,WAAY,EAAK,OAAO,EAAS,sBAAuB,QAG1D,EAAU,KAAK,kBAAkB,EAAE,OASrC,QANI,GAAiB,EAAQ,eAMtB,GACA,EAAQ,eAAiB,GACzB,EAAQ,gBAAkB,GAC/B,EAAS,KAAK,CACZ,KAAM,EAAK,OAAO,EAAS,gBAAiB,MAC5C,OAAQ,EAAK,OAAO,EAAS,kBAAmB,MAChD,WAAY,EAAK,OAAO,EAAS,sBAAuB,QAG1D,EAAU,KAAK,kBAAkB,EAAE,GAKzC,MAAO,IAGX,GAAQ,kBAAoB,GAoC5B,YAAgC,EAAY,EAAe,CACzD,GAAI,GAAY,EAChB,AAAI,MAAO,IAAe,UACxB,GAAY,EAAK,oBAAoB,IAGvC,GAAI,GAAU,EAAK,OAAO,EAAW,WACjC,EAAU,EAAK,OAAO,EAAW,WAGjC,EAAQ,EAAK,OAAO,EAAW,QAAS,IACxC,EAAa,EAAK,OAAO,EAAW,aAAc,MAClD,EAAiB,EAAK,OAAO,EAAW,iBAAkB,MAC1D,EAAW,EAAK,OAAO,EAAW,YAClC,EAAO,EAAK,OAAO,EAAW,OAAQ,MAI1C,GAAI,GAAW,KAAK,SAClB,KAAM,IAAI,OAAM,wBAA0B,GAG5C,AAAI,GACF,GAAa,EAAK,UAAU,IAG9B,EAAU,EACP,IAAI,QAIJ,IAAI,EAAK,WAKT,IAAI,SAAU,EAAQ,CACrB,MAAO,IAAc,EAAK,WAAW,IAAe,EAAK,WAAW,GAChE,EAAK,SAAS,EAAY,GAC1B,IAOR,KAAK,OAAS,GAAS,UAAU,EAAM,IAAI,QAAS,IACpD,KAAK,SAAW,GAAS,UAAU,EAAS,IAE5C,KAAK,iBAAmB,KAAK,SAAS,UAAU,IAAI,SAAU,EAAG,CAC/D,MAAO,GAAK,iBAAiB,EAAY,EAAG,KAG9C,KAAK,WAAa,EAClB,KAAK,eAAiB,EACtB,KAAK,UAAY,EACjB,KAAK,cAAgB,EACrB,KAAK,KAAO,EAGd,GAAuB,UAAY,OAAO,OAAO,GAAkB,WACnE,GAAuB,UAAU,SAAW,GAM5C,GAAuB,UAAU,iBAAmB,SAAS,EAAS,CACpE,GAAI,GAAiB,EAKrB,GAJI,KAAK,YAAc,MACrB,GAAiB,EAAK,SAAS,KAAK,WAAY,IAG9C,KAAK,SAAS,IAAI,GACpB,MAAO,MAAK,SAAS,QAAQ,GAK/B,GAAI,GACJ,IAAK,EAAI,EAAG,EAAI,KAAK,iBAAiB,OAAQ,EAAE,EAC9C,GAAI,KAAK,iBAAiB,IAAM,EAC9B,MAAO,GAIX,MAAO,IAYT,GAAuB,cACrB,SAAyC,EAAY,EAAe,CAClE,GAAI,GAAM,OAAO,OAAO,GAAuB,WAE3C,EAAQ,EAAI,OAAS,GAAS,UAAU,EAAW,OAAO,UAAW,IACrE,EAAU,EAAI,SAAW,GAAS,UAAU,EAAW,SAAS,UAAW,IAC/E,EAAI,WAAa,EAAW,YAC5B,EAAI,eAAiB,EAAW,wBAAwB,EAAI,SAAS,UACb,EAAI,YAC5D,EAAI,KAAO,EAAW,MACtB,EAAI,cAAgB,EACpB,EAAI,iBAAmB,EAAI,SAAS,UAAU,IAAI,SAAU,EAAG,CAC7D,MAAO,GAAK,iBAAiB,EAAI,WAAY,EAAG,KAYlD,OAJI,GAAoB,EAAW,UAAU,UAAU,QACnD,EAAwB,EAAI,oBAAsB,GAClD,EAAuB,EAAI,mBAAqB,GAE3C,EAAI,EAAG,EAAS,EAAkB,OAAQ,EAAI,EAAQ,IAAK,CAClE,GAAI,GAAa,EAAkB,GAC/B,EAAc,GAAI,IACtB,EAAY,cAAgB,EAAW,cACvC,EAAY,gBAAkB,EAAW,gBAErC,EAAW,QACb,GAAY,OAAS,EAAQ,QAAQ,EAAW,QAChD,EAAY,aAAe,EAAW,aACtC,EAAY,eAAiB,EAAW,eAEpC,EAAW,MACb,GAAY,KAAO,EAAM,QAAQ,EAAW,OAG9C,EAAqB,KAAK,IAG5B,EAAsB,KAAK,GAG7B,UAAU,EAAI,mBAAoB,EAAK,4BAEhC,GAMX,GAAuB,UAAU,SAAW,EAK5C,OAAO,eAAe,GAAuB,UAAW,UAAW,CACjE,IAAK,UAAY,CACf,MAAO,MAAK,iBAAiB,WAOjC,aAAmB,CACjB,KAAK,cAAgB,EACrB,KAAK,gBAAkB,EACvB,KAAK,OAAS,KACd,KAAK,aAAe,KACpB,KAAK,eAAiB,KACtB,KAAK,KAAO,KAQd,GAAuB,UAAU,eAC/B,SAAyC,EAAM,EAAa,CAe1D,OAdI,GAAgB,EAChB,EAA0B,EAC1B,EAAuB,EACvB,EAAyB,EACzB,EAAiB,EACjB,EAAe,EACf,EAAS,EAAK,OACd,EAAQ,EACR,EAAiB,GACjB,EAAO,GACP,EAAmB,GACnB,EAAoB,GACpB,GAAS,GAAK,GAAS,EAAK,GAEzB,EAAQ,GACb,GAAI,EAAK,OAAO,KAAW,IACzB,IACA,IACA,EAA0B,UAEnB,EAAK,OAAO,KAAW,IAC9B,QAEG,CASH,IARA,GAAU,GAAI,IACd,GAAQ,cAAgB,EAOnB,EAAM,EAAO,EAAM,GAClB,MAAK,wBAAwB,EAAM,GADT,IAC9B,CAOF,GAHA,GAAM,EAAK,MAAM,EAAO,GAExB,GAAU,EAAe,IACrB,GACF,GAAS,GAAI,WACR,CAEL,IADA,GAAU,GACH,EAAQ,GACb,GAAU,OAAO,EAAM,EAAO,GAC9B,GAAQ,EAAK,MACb,EAAQ,EAAK,KACb,GAAQ,KAAK,IAGf,GAAI,GAAQ,SAAW,EACrB,KAAM,IAAI,OAAM,0CAGlB,GAAI,GAAQ,SAAW,EACrB,KAAM,IAAI,OAAM,0CAGlB,EAAe,IAAO,GAIxB,GAAQ,gBAAkB,EAA0B,GAAQ,GAC5D,EAA0B,GAAQ,gBAE9B,GAAQ,OAAS,GAEnB,IAAQ,OAAS,EAAiB,GAAQ,GAC1C,GAAkB,GAAQ,GAG1B,GAAQ,aAAe,EAAuB,GAAQ,GACtD,EAAuB,GAAQ,aAE/B,GAAQ,cAAgB,EAGxB,GAAQ,eAAiB,EAAyB,GAAQ,GAC1D,EAAyB,GAAQ,eAE7B,GAAQ,OAAS,GAEnB,IAAQ,KAAO,EAAe,GAAQ,GACtC,GAAgB,GAAQ,KAI5B,EAAkB,KAAK,IACnB,MAAO,IAAQ,cAAiB,UAClC,EAAiB,KAAK,IAK5B,GAAU,EAAmB,EAAK,qCAClC,KAAK,oBAAsB,EAE3B,GAAU,EAAkB,EAAK,4BACjC,KAAK,mBAAqB,GAO9B,GAAuB,UAAU,aAC/B,SAAuC,EAAS,EAAW,EACpB,EAAa,EAAa,EAAO,CAMtE,GAAI,EAAQ,IAAc,EACxB,KAAM,IAAI,WAAU,gDACE,EAAQ,IAEhC,GAAI,EAAQ,GAAe,EACzB,KAAM,IAAI,WAAU,kDACE,EAAQ,IAGhC,MAAO,IAAa,OAAO,EAAS,EAAW,EAAa,IAOhE,GAAuB,UAAU,mBAC/B,UAAgD,CAC9C,OAAS,GAAQ,EAAG,EAAQ,KAAK,mBAAmB,OAAQ,EAAE,EAAO,CACnE,GAAI,GAAU,KAAK,mBAAmB,GAMtC,GAAI,EAAQ,EAAI,KAAK,mBAAmB,OAAQ,CAC9C,GAAI,GAAc,KAAK,mBAAmB,EAAQ,GAElD,GAAI,EAAQ,gBAAkB,EAAY,cAAe,CACvD,EAAQ,oBAAsB,EAAY,gBAAkB,EAC5D,UAKJ,EAAQ,oBAAsB,WA4BpC,GAAuB,UAAU,oBAC/B,SAA+C,EAAO,CACpD,GAAI,GAAS,CACX,cAAe,EAAK,OAAO,EAAO,QAClC,gBAAiB,EAAK,OAAO,EAAO,WAGlC,EAAQ,KAAK,aACf,EACA,KAAK,mBACL,gBACA,kBACA,EAAK,oCACL,EAAK,OAAO,EAAO,OAAQ,GAAkB,uBAG/C,GAAI,GAAS,EAAG,CACd,GAAI,GAAU,KAAK,mBAAmB,GAEtC,GAAI,EAAQ,gBAAkB,EAAO,cAAe,CAClD,GAAI,GAAS,EAAK,OAAO,EAAS,SAAU,MAC5C,AAAI,IAAW,MACb,GAAS,KAAK,SAAS,GAAG,GAC1B,EAAS,EAAK,iBAAiB,KAAK,WAAY,EAAQ,KAAK,gBAE/D,GAAI,GAAO,EAAK,OAAO,EAAS,OAAQ,MACxC,MAAI,KAAS,MACX,GAAO,KAAK,OAAO,GAAG,IAEjB,CACL,OAAQ,EACR,KAAM,EAAK,OAAO,EAAS,eAAgB,MAC3C,OAAQ,EAAK,OAAO,EAAS,iBAAkB,MAC/C,KAAM,IAKZ,MAAO,CACL,OAAQ,KACR,KAAM,KACN,OAAQ,KACR,KAAM,OAQZ,GAAuB,UAAU,wBAC/B,UAA0D,CACxD,MAAK,MAAK,eAGH,KAAK,eAAe,QAAU,KAAK,SAAS,QACjD,CAAC,KAAK,eAAe,KAAK,SAAU,EAAI,CAAE,MAAO,IAAM,OAHhD,IAWb,GAAuB,UAAU,iBAC/B,SAA4C,EAAS,EAAe,CAClE,GAAI,CAAC,KAAK,eACR,MAAO,MAGT,GAAI,GAAQ,KAAK,iBAAiB,GAClC,GAAI,GAAS,EACX,MAAO,MAAK,eAAe,GAG7B,GAAI,GAAiB,EACrB,AAAI,KAAK,YAAc,MACrB,GAAiB,EAAK,SAAS,KAAK,WAAY,IAGlD,GAAI,GACJ,GAAI,KAAK,YAAc,MACf,GAAM,EAAK,SAAS,KAAK,aAAc,CAK7C,GAAI,GAAiB,EAAe,QAAQ,aAAc,IAC1D,GAAI,EAAI,QAAU,QACX,KAAK,SAAS,IAAI,GACvB,MAAO,MAAK,eAAe,KAAK,SAAS,QAAQ,IAGnD,GAAK,EAAC,EAAI,MAAQ,EAAI,MAAQ,MACvB,KAAK,SAAS,IAAI,IAAM,GAC7B,MAAO,MAAK,eAAe,KAAK,SAAS,QAAQ,IAAM,IAQ3D,GAAI,EACF,MAAO,MAGP,KAAM,IAAI,OAAM,IAAM,EAAiB,+BA2B7C,GAAuB,UAAU,qBAC/B,SAAgD,EAAO,CACrD,GAAI,GAAS,EAAK,OAAO,EAAO,UAEhC,GADA,EAAS,KAAK,iBAAiB,GAC3B,EAAS,EACX,MAAO,CACL,KAAM,KACN,OAAQ,KACR,WAAY,MAIhB,GAAI,GAAS,CACX,OAAQ,EACR,aAAc,EAAK,OAAO,EAAO,QACjC,eAAgB,EAAK,OAAO,EAAO,WAGjC,EAAQ,KAAK,aACf,EACA,KAAK,kBACL,eACA,iBACA,EAAK,2BACL,EAAK,OAAO,EAAO,OAAQ,GAAkB,uBAG/C,GAAI,GAAS,EAAG,CACd,GAAI,GAAU,KAAK,kBAAkB,GAErC,GAAI,EAAQ,SAAW,EAAO,OAC5B,MAAO,CACL,KAAM,EAAK,OAAO,EAAS,gBAAiB,MAC5C,OAAQ,EAAK,OAAO,EAAS,kBAAmB,MAChD,WAAY,EAAK,OAAO,EAAS,sBAAuB,OAK9D,MAAO,CACL,KAAM,KACN,OAAQ,KACR,WAAY,OAIlB,GAAQ,uBAAyB,GAmDjC,YAAkC,EAAY,EAAe,CAC3D,GAAI,GAAY,EAChB,AAAI,MAAO,IAAe,UACxB,GAAY,EAAK,oBAAoB,IAGvC,GAAI,GAAU,EAAK,OAAO,EAAW,WACjC,EAAW,EAAK,OAAO,EAAW,YAEtC,GAAI,GAAW,KAAK,SAClB,KAAM,IAAI,OAAM,wBAA0B,GAG5C,KAAK,SAAW,GAAI,IACpB,KAAK,OAAS,GAAI,IAElB,GAAI,GAAa,CACf,KAAM,GACN,OAAQ,GAEV,KAAK,UAAY,EAAS,IAAI,SAAU,EAAG,CACzC,GAAI,EAAE,IAGJ,KAAM,IAAI,OAAM,sDAElB,GAAI,GAAS,EAAK,OAAO,EAAG,UACxB,EAAa,EAAK,OAAO,EAAQ,QACjC,EAAe,EAAK,OAAO,EAAQ,UAEvC,GAAI,EAAa,EAAW,MACvB,IAAe,EAAW,MAAQ,EAAe,EAAW,OAC/D,KAAM,IAAI,OAAM,wDAElB,SAAa,EAEN,CACL,gBAAiB,CAGf,cAAe,EAAa,EAC5B,gBAAiB,EAAe,GAElC,SAAU,GAAI,IAAkB,EAAK,OAAO,EAAG,OAAQ,MAK7D,GAAyB,UAAY,OAAO,OAAO,GAAkB,WACrE,GAAyB,UAAU,YAAc,GAKjD,GAAyB,UAAU,SAAW,EAK9C,OAAO,eAAe,GAAyB,UAAW,UAAW,CACnE,IAAK,UAAY,CAEf,OADI,GAAU,GACL,EAAI,EAAG,EAAI,KAAK,UAAU,OAAQ,IACzC,OAAS,GAAI,EAAG,EAAI,KAAK,UAAU,GAAG,SAAS,QAAQ,OAAQ,IAC7D,EAAQ,KAAK,KAAK,UAAU,GAAG,SAAS,QAAQ,IAGpD,MAAO,MAuBX,GAAyB,UAAU,oBACjC,SAAsD,EAAO,CAC3D,GAAI,GAAS,CACX,cAAe,EAAK,OAAO,EAAO,QAClC,gBAAiB,EAAK,OAAO,EAAO,WAKlC,EAAe,GAAa,OAAO,EAAQ,KAAK,UAClD,SAAS,EAAQ,EAAS,CACxB,GAAI,GAAM,EAAO,cAAgB,EAAQ,gBAAgB,cACzD,MAAI,IAII,EAAO,gBACP,EAAQ,gBAAgB,kBAEhC,EAAU,KAAK,UAAU,GAE7B,MAAK,GASE,EAAQ,SAAS,oBAAoB,CAC1C,KAAM,EAAO,cACV,GAAQ,gBAAgB,cAAgB,GAC3C,OAAQ,EAAO,gBACZ,GAAQ,gBAAgB,gBAAkB,EAAO,cAC/C,EAAQ,gBAAgB,gBAAkB,EAC1C,GACL,KAAM,EAAM,OAfL,CACL,OAAQ,KACR,KAAM,KACN,OAAQ,KACR,KAAM,OAmBd,GAAyB,UAAU,wBACjC,UAA4D,CAC1D,MAAO,MAAK,UAAU,MAAM,SAAU,EAAG,CACvC,MAAO,GAAE,SAAS,6BASxB,GAAyB,UAAU,iBACjC,SAAmD,EAAS,EAAe,CACzE,OAAS,GAAI,EAAG,EAAI,KAAK,UAAU,OAAQ,IAAK,CAC9C,GAAI,GAAU,KAAK,UAAU,GAEzB,EAAU,EAAQ,SAAS,iBAAiB,EAAS,IACzD,GAAI,EACF,MAAO,GAGX,GAAI,EACF,MAAO,MAGP,KAAM,IAAI,OAAM,IAAM,EAAU,+BAsBtC,GAAyB,UAAU,qBACjC,SAAuD,EAAO,CAC5D,OAAS,GAAI,EAAG,EAAI,KAAK,UAAU,OAAQ,IAAK,CAC9C,GAAI,GAAU,KAAK,UAAU,GAI7B,GAAI,EAAQ,SAAS,iBAAiB,EAAK,OAAO,EAAO,aAAe,GAGxE,IAAI,GAAoB,EAAQ,SAAS,qBAAqB,GAC9D,GAAI,EAAmB,CACrB,GAAI,GAAM,CACR,KAAM,EAAkB,KACrB,GAAQ,gBAAgB,cAAgB,GAC3C,OAAQ,EAAkB,OACvB,GAAQ,gBAAgB,gBAAkB,EAAkB,KAC1D,EAAQ,gBAAgB,gBAAkB,EAC1C,IAEP,MAAO,KAIX,MAAO,CACL,KAAM,KACN,OAAQ,OASd,GAAyB,UAAU,eACjC,SAAgD,EAAM,EAAa,CACjE,KAAK,oBAAsB,GAC3B,KAAK,mBAAqB,GAC1B,OAAS,GAAI,EAAG,EAAI,KAAK,UAAU,OAAQ,IAGzC,OAFI,GAAU,KAAK,UAAU,GACzB,EAAkB,EAAQ,SAAS,mBAC9B,EAAI,EAAG,EAAI,EAAgB,OAAQ,IAAK,CAC/C,GAAI,GAAU,EAAgB,GAE1B,EAAS,EAAQ,SAAS,SAAS,GAAG,EAAQ,QAClD,EAAS,EAAK,iBAAiB,EAAQ,SAAS,WAAY,EAAQ,KAAK,eACzE,KAAK,SAAS,IAAI,GAClB,EAAS,KAAK,SAAS,QAAQ,GAE/B,GAAI,GAAO,KACX,AAAI,EAAQ,MACV,GAAO,EAAQ,SAAS,OAAO,GAAG,EAAQ,MAC1C,KAAK,OAAO,IAAI,GAChB,EAAO,KAAK,OAAO,QAAQ,IAO7B,GAAI,GAAkB,CACpB,OAAQ,EACR,cAAe,EAAQ,cACpB,GAAQ,gBAAgB,cAAgB,GAC3C,gBAAiB,EAAQ,gBACtB,GAAQ,gBAAgB,gBAAkB,EAAQ,cACjD,EAAQ,gBAAgB,gBAAkB,EAC1C,GACJ,aAAc,EAAQ,aACtB,eAAgB,EAAQ,eACxB,KAAM,GAGR,KAAK,oBAAoB,KAAK,GAC1B,MAAO,GAAgB,cAAiB,UAC1C,KAAK,mBAAmB,KAAK,GAKnC,GAAU,KAAK,oBAAqB,EAAK,qCACzC,GAAU,KAAK,mBAAoB,EAAK,6BAG5C,GAAQ,yBAA2B,KCxnCnC,cAOA,GAAI,IAAqB,AAAQ,KAA0B,mBACvD,GAAe,KAIf,GAAgB,UAGhB,GAAe,GAKf,GAAe,qBAcnB,YAAoB,EAAO,EAAS,EAAS,EAAS,EAAO,CAC3D,KAAK,SAAW,GAChB,KAAK,eAAiB,GACtB,KAAK,KAAO,GAAgB,KAC5B,KAAK,OAAS,GAAkB,KAChC,KAAK,OAAS,GAAkB,KAChC,KAAK,KAAO,GAAgB,KAC5B,KAAK,IAAgB,GACjB,GAAW,MAAM,KAAK,IAAI,GAWhC,GAAW,wBACT,SAA4C,EAAgB,EAAoB,EAAe,CAG7F,GAAI,GAAO,GAAI,IAMX,EAAiB,EAAe,MAAM,IACtC,EAAsB,EACtB,EAAgB,UAAW,CAC7B,GAAI,GAAe,IAEf,EAAU,KAAiB,GAC/B,MAAO,GAAe,EAEtB,YAAuB,CACrB,MAAO,GAAsB,EAAe,OACxC,EAAe,KAAyB,SAK5C,EAAoB,EAAG,EAAsB,EAK7C,EAAc,KAElB,SAAmB,YAAY,SAAU,EAAS,CAChD,GAAI,IAAgB,KAGlB,GAAI,EAAoB,EAAQ,cAE9B,EAAmB,EAAa,KAChC,IACA,EAAsB,MAEjB,CAIL,GAAI,GAAW,EAAe,IAAwB,GAClD,EAAO,EAAS,OAAO,EAAG,EAAQ,gBACR,GAC9B,EAAe,GAAuB,EAAS,OAAO,EAAQ,gBAC1B,GACpC,EAAsB,EAAQ,gBAC9B,EAAmB,EAAa,GAEhC,EAAc,EACd,OAMJ,KAAO,EAAoB,EAAQ,eACjC,EAAK,IAAI,KACT,IAEF,GAAI,EAAsB,EAAQ,gBAAiB,CACjD,GAAI,GAAW,EAAe,IAAwB,GACtD,EAAK,IAAI,EAAS,OAAO,EAAG,EAAQ,kBACpC,EAAe,GAAuB,EAAS,OAAO,EAAQ,iBAC9D,EAAsB,EAAQ,gBAEhC,EAAc,GACb,MAEC,EAAsB,EAAe,QACnC,IAEF,EAAmB,EAAa,KAGlC,EAAK,IAAI,EAAe,OAAO,GAAqB,KAAK,MAI3D,EAAmB,QAAQ,QAAQ,SAAU,EAAY,CACvD,GAAI,GAAU,EAAmB,iBAAiB,GAClD,AAAI,GAAW,MACT,IAAiB,MACnB,GAAa,GAAK,KAAK,EAAe,IAExC,EAAK,iBAAiB,EAAY,MAI/B,EAEP,WAA4B,EAAS,EAAM,CACzC,GAAI,IAAY,MAAQ,EAAQ,SAAW,OACzC,EAAK,IAAI,OACJ,CACL,GAAI,GAAS,EACT,GAAK,KAAK,EAAe,EAAQ,QACjC,EAAQ,OACZ,EAAK,IAAI,GAAI,IAAW,EAAQ,aACR,EAAQ,eACR,EACA,EACA,EAAQ,UAWxC,GAAW,UAAU,IAAM,SAAwB,EAAQ,CACzD,GAAI,MAAM,QAAQ,GAChB,EAAO,QAAQ,SAAU,EAAO,CAC9B,KAAK,IAAI,IACR,cAEI,EAAO,KAAiB,MAAO,IAAW,SACjD,AAAI,GACF,KAAK,SAAS,KAAK,OAIrB,MAAM,IAAI,WACR,8EAAgF,GAGpF,MAAO,OAST,GAAW,UAAU,QAAU,SAA4B,EAAQ,CACjE,GAAI,MAAM,QAAQ,GAChB,OAAS,GAAI,EAAO,OAAO,EAAG,GAAK,EAAG,IACpC,KAAK,QAAQ,EAAO,YAGf,EAAO,KAAiB,MAAO,IAAW,SACjD,KAAK,SAAS,QAAQ,OAGtB,MAAM,IAAI,WACR,8EAAgF,GAGpF,MAAO,OAUT,GAAW,UAAU,KAAO,SAAyB,EAAK,CAExD,OADI,GACK,EAAI,EAAG,EAAM,KAAK,SAAS,OAAQ,EAAI,EAAK,IACnD,EAAQ,KAAK,SAAS,GACtB,AAAI,EAAM,IACR,EAAM,KAAK,GAGP,IAAU,IACZ,EAAI,EAAO,CAAE,OAAQ,KAAK,OACb,KAAM,KAAK,KACX,OAAQ,KAAK,OACb,KAAM,KAAK,QAYhC,GAAW,UAAU,KAAO,SAAyB,EAAM,CACzD,GAAI,GACA,EACA,EAAM,KAAK,SAAS,OACxB,GAAI,EAAM,EAAG,CAEX,IADA,EAAc,GACT,EAAI,EAAG,EAAI,EAAI,EAAG,IACrB,EAAY,KAAK,KAAK,SAAS,IAC/B,EAAY,KAAK,GAEnB,EAAY,KAAK,KAAK,SAAS,IAC/B,KAAK,SAAW,EAElB,MAAO,OAUT,GAAW,UAAU,aAAe,SAAiC,EAAU,EAAc,CAC3F,GAAI,GAAY,KAAK,SAAS,KAAK,SAAS,OAAS,GACrD,MAAI,GAAU,IACZ,EAAU,aAAa,EAAU,GAE9B,AAAI,MAAO,IAAc,SAC5B,KAAK,SAAS,KAAK,SAAS,OAAS,GAAK,EAAU,QAAQ,EAAU,GAGtE,KAAK,SAAS,KAAK,GAAG,QAAQ,EAAU,IAEnC,MAUT,GAAW,UAAU,iBACnB,SAAqC,EAAa,EAAgB,CAChE,KAAK,eAAe,GAAK,YAAY,IAAgB,GASzD,GAAW,UAAU,mBACnB,SAAuC,EAAK,CAC1C,OAAS,GAAI,EAAG,EAAM,KAAK,SAAS,OAAQ,EAAI,EAAK,IACnD,AAAI,KAAK,SAAS,GAAG,KACnB,KAAK,SAAS,GAAG,mBAAmB,GAKxC,OADI,GAAU,OAAO,KAAK,KAAK,gBACtB,EAAI,EAAG,EAAM,EAAQ,OAAQ,EAAI,EAAK,IAC7C,EAAI,GAAK,cAAc,EAAQ,IAAK,KAAK,eAAe,EAAQ,MAQtE,GAAW,UAAU,SAAW,UAA+B,CAC7D,GAAI,GAAM,GACV,YAAK,KAAK,SAAU,EAAO,CACzB,GAAO,IAEF,GAOT,GAAW,UAAU,sBAAwB,SAA0C,EAAO,CAC5F,GAAI,GAAY,CACd,KAAM,GACN,KAAM,EACN,OAAQ,GAEN,EAAM,GAAI,IAAmB,GAC7B,EAAsB,GACtB,EAAqB,KACrB,EAAmB,KACnB,EAAqB,KACrB,EAAmB,KACvB,YAAK,KAAK,SAAU,EAAO,EAAU,CACnC,EAAU,MAAQ,EAClB,AAAI,EAAS,SAAW,MACjB,EAAS,OAAS,MAClB,EAAS,SAAW,KACtB,MAAuB,EAAS,QAC7B,IAAqB,EAAS,MAC9B,IAAuB,EAAS,QAChC,IAAqB,EAAS,OAClC,EAAI,WAAW,CACb,OAAQ,EAAS,OACjB,SAAU,CACR,KAAM,EAAS,KACf,OAAQ,EAAS,QAEnB,UAAW,CACT,KAAM,EAAU,KAChB,OAAQ,EAAU,QAEpB,KAAM,EAAS,OAGnB,EAAqB,EAAS,OAC9B,EAAmB,EAAS,KAC5B,EAAqB,EAAS,OAC9B,EAAmB,EAAS,KAC5B,EAAsB,IACb,GACT,GAAI,WAAW,CACb,UAAW,CACT,KAAM,EAAU,KAChB,OAAQ,EAAU,UAGtB,EAAqB,KACrB,EAAsB,IAExB,OAAS,GAAM,EAAG,EAAS,EAAM,OAAQ,EAAM,EAAQ,IACrD,AAAI,EAAM,WAAW,KAAS,GAC5B,GAAU,OACV,EAAU,OAAS,EAEnB,AAAI,EAAM,IAAM,EACd,GAAqB,KACrB,EAAsB,IACb,GACT,EAAI,WAAW,CACb,OAAQ,EAAS,OACjB,SAAU,CACR,KAAM,EAAS,KACf,OAAQ,EAAS,QAEnB,UAAW,CACT,KAAM,EAAU,KAChB,OAAQ,EAAU,QAEpB,KAAM,EAAS,QAInB,EAAU,WAIhB,KAAK,mBAAmB,SAAU,EAAY,EAAe,CAC3D,EAAI,iBAAiB,EAAY,KAG5B,CAAE,KAAM,EAAU,KAAM,IAAK,IAGtC,GAAQ,WAAa,KC5ZrB,cAKA,GAAQ,mBAAqB,AAAQ,KAA8B,mBACnE,GAAQ,kBAAoB,AAAQ,KAA6B,kBACjE,GAAQ,WAAa,AAAQ,KAAqB,aCPlD,uBAAI,IAAW,OAAO,UAAU,SAE5B,GACF,MAAO,QAAO,OAAU,YACxB,MAAO,QAAO,aAAgB,YAC9B,MAAO,QAAO,MAAS,WAGzB,YAAwB,EAAO,CAC7B,MAAO,IAAS,KAAK,GAAO,MAAM,EAAG,MAAQ,cAG/C,YAA0B,EAAK,EAAY,EAAQ,CACjD,KAAgB,EAEhB,GAAI,GAAY,EAAI,WAAa,EAEjC,GAAI,EAAY,EACd,KAAM,IAAI,YAAW,6BAGvB,GAAI,IAAW,OACb,EAAS,UAET,KAAY,EAER,EAAS,EACX,KAAM,IAAI,YAAW,6BAIzB,MAAO,IACH,OAAO,KAAK,EAAI,MAAM,EAAY,EAAa,IAC/C,GAAI,QAAO,GAAI,YAAW,EAAI,MAAM,EAAY,EAAa,KAGnE,YAAqB,EAAQ,EAAU,CAKrC,GAJI,OAAO,IAAa,UAAY,IAAa,KAC/C,GAAW,QAGT,CAAC,OAAO,WAAW,GACrB,KAAM,IAAI,WAAU,8CAGtB,MAAO,IACH,OAAO,KAAK,EAAQ,GACpB,GAAI,QAAO,EAAQ,GAGzB,YAAqB,EAAO,EAAkB,EAAQ,CACpD,GAAI,MAAO,IAAU,SACnB,KAAM,IAAI,WAAU,yCAGtB,MAAI,IAAc,GACT,GAAgB,EAAO,EAAkB,GAG9C,MAAO,IAAU,SACZ,GAAW,EAAO,GAGpB,GACH,OAAO,KAAK,GACZ,GAAI,QAAO,GAGjB,GAAO,QAAU,KCpEjB,sBAAI,IAAoB,AAAQ,KAAc,kBAC1C,GAAe,gBAEf,GACJ,GAAI,CACF,GAAa,cACT,EAAC,GAAG,YAAc,CAAC,GAAG,eAExB,IAAK,YAEA,EAAP,EAIF,GAAI,IAAqB,KAQzB,YAAwB,EAAK,EAAS,CACpC,MAAO,GAAI,QAAQ,GAIrB,GAAI,IAA0B,GAC1B,GAAwB,GAGxB,GAA8B,GAG9B,GAAc,OAGd,GAAoB,GAGpB,GAAiB,GAGjB,GAAc,sCAGd,GAAuB,GACvB,GAAsB,GAE1B,aAAuB,CACrB,MAAI,MAAgB,UACX,GACL,KAAgB,OACX,GACA,MAAO,SAAW,aAAiB,MAAO,iBAAmB,YAAe,CAAE,QAAO,SAAW,OAAO,QAAU,OAAO,SAAW,OAAO,QAAQ,OAAS,YAGtK,aAAwC,CACtC,MAAS,OAAO,UAAY,UAAc,UAAY,MAAU,MAAO,SAAQ,IAAO,WAGxF,YAAqB,EAAM,CACzB,MAAO,UAAS,EAAK,CACnB,OAAS,GAAI,EAAG,EAAI,EAAK,OAAQ,IAAK,CACpC,GAAI,GAAM,EAAK,GAAG,GAClB,GAAI,EACF,MAAO,GAGX,MAAO,OAIX,GAAI,IAAe,GAAY,IAE/B,GAAqB,KAAK,SAAS,EAAM,CAWvC,GATA,EAAO,EAAK,OACR,SAAS,KAAK,IAEhB,GAAO,EAAK,QAAQ,oBAAqB,SAAS,EAAU,EAAO,CACjE,MAAO,GACL,GACA,OAGF,IAAQ,IACV,MAAO,IAAkB,GAG3B,GAAI,GAAW,GACf,GAAI,CACF,GAAK,GAQE,AAAI,GAAG,WAAW,IAEvB,GAAW,GAAG,aAAa,EAAM,aAV1B,CAEP,GAAI,GAAM,GAAI,gBACd,EAAI,KAAK,MAAO,EAAmB,IACnC,EAAI,KAAK,MACL,EAAI,aAAe,GAAK,EAAI,SAAW,KACzC,GAAW,EAAI,qBAMZ,EAAP,EAIF,MAAO,IAAkB,GAAQ,IAKnC,YAA4B,EAAM,EAAK,CACrC,GAAI,CAAC,EAAM,MAAO,GAClB,GAAI,GAAM,GAAK,QAAQ,GACnB,EAAQ,kBAAkB,KAAK,GAC/B,EAAW,EAAQ,EAAM,GAAK,GAC9B,EAAY,EAAI,MAAM,EAAS,QACnC,MAAI,IAAY,UAAU,KAAK,GAE7B,IAAY,IACL,EAAW,GAAK,QAAQ,EAAI,MAAM,EAAS,QAAS,GAAK,QAAQ,MAAO,MAE1E,EAAW,GAAK,QAAQ,EAAI,MAAM,EAAS,QAAS,GAG7D,YAA8B,EAAQ,CACpC,GAAI,GAEJ,GAAI,KACD,GAAI,CACF,GAAI,GAAM,GAAI,gBACd,EAAI,KAAK,MAAO,EAAQ,IACxB,EAAI,KAAK,MACT,EAAW,EAAI,aAAe,EAAI,EAAI,aAAe,KAGrD,GAAI,GAAkB,EAAI,kBAAkB,cACtB,EAAI,kBAAkB,eAC5C,GAAI,EACF,MAAO,SAEF,EAAP,EAKL,EAAW,GAAa,GAKxB,OAJI,GAAK,wHAGL,EAAW,EACR,EAAQ,EAAG,KAAK,IAAW,EAAY,EAC9C,MAAK,GACE,EAAU,GADM,KASzB,GAAI,IAAoB,GAAY,IACpC,GAAoB,KAAK,SAAS,EAAQ,CACxC,GAAI,GAAmB,GAAqB,GAC5C,GAAI,CAAC,EAAkB,MAAO,MAG9B,GAAI,GACJ,GAAI,GAAY,KAAK,GAAmB,CAEtC,GAAI,GAAU,EAAiB,MAAM,EAAiB,QAAQ,KAAO,GACrE,EAAgB,GAAW,EAAS,UAAU,WAC9C,EAAmB,MAGnB,GAAmB,GAAmB,EAAQ,GAC9C,EAAgB,GAAa,GAG/B,MAAK,GAIE,CACL,IAAK,EACL,IAAK,GALE,OASX,YAA2B,EAAU,CACnC,GAAI,GAAY,GAAe,EAAS,QACxC,GAAI,CAAC,EAAW,CAEd,GAAI,GAAY,GAAkB,EAAS,QAC3C,AAAI,EACF,GAAY,GAAe,EAAS,QAAU,CAC5C,IAAK,EAAU,IACf,IAAK,GAAI,IAAkB,EAAU,MAKnC,EAAU,IAAI,gBAChB,EAAU,IAAI,QAAQ,QAAQ,SAAS,EAAQ,EAAG,CAChD,GAAI,GAAW,EAAU,IAAI,eAAe,GAC5C,GAAI,EAAU,CACZ,GAAI,GAAM,GAAmB,EAAU,IAAK,GAC5C,GAAkB,GAAO,MAK/B,EAAY,GAAe,EAAS,QAAU,CAC5C,IAAK,KACL,IAAK,MAMX,GAAI,GAAa,EAAU,KAAO,MAAO,GAAU,IAAI,qBAAwB,WAAY,CACzF,GAAI,GAAmB,EAAU,IAAI,oBAAoB,GAOzD,GAAI,EAAiB,SAAW,KAC9B,SAAiB,OAAS,GACxB,EAAU,IAAK,EAAiB,QAC3B,EAIX,MAAO,GAKT,YAAuB,EAAQ,CAE7B,GAAI,GAAQ,yCAAyC,KAAK,GAC1D,GAAI,EAAO,CACT,GAAI,GAAW,GAAkB,CAC/B,OAAQ,EAAM,GACd,KAAM,CAAC,EAAM,GACb,OAAQ,EAAM,GAAK,IAErB,MAAO,WAAa,EAAM,GAAK,KAAO,EAAS,OAAS,IACtD,EAAS,KAAO,IAAO,GAAS,OAAS,GAAK,IAKlD,MADA,GAAQ,6BAA6B,KAAK,GACtC,EACK,WAAa,EAAM,GAAK,KAAO,GAAc,EAAM,IAAM,IAI3D,EAST,aAA4B,CAC1B,GAAI,GACA,EAAe,GACnB,GAAI,KAAK,WACP,EAAe,aACV,CACL,EAAW,KAAK,2BACZ,CAAC,GAAY,KAAK,UACpB,GAAe,KAAK,gBACpB,GAAgB,MAGlB,AAAI,EACF,GAAgB,EAKhB,GAAgB,cAElB,GAAI,GAAa,KAAK,gBACtB,GAAI,GAAc,KAAM,CACtB,GAAgB,IAAM,EACtB,GAAI,GAAe,KAAK,kBACxB,AAAI,GACF,IAAgB,IAAM,IAK5B,GAAI,GAAO,GACP,EAAe,KAAK,kBACpB,EAAY,GACZ,EAAgB,KAAK,gBACrB,EAAe,CAAE,MAAK,cAAgB,GAC1C,GAAI,EAAc,CAChB,GAAI,GAAW,KAAK,cAEpB,AAAI,IAAa,mBACf,GAAW,QAEb,GAAI,GAAa,KAAK,gBACtB,AAAI,EACE,IAAY,EAAa,QAAQ,IAAa,GAChD,IAAQ,EAAW,KAErB,GAAQ,EACJ,GAAc,EAAa,QAAQ,IAAM,IAAe,EAAa,OAAS,EAAW,OAAS,GACpG,IAAQ,QAAU,EAAa,MAGjC,GAAQ,EAAW,IAAO,IAAc,mBAErC,AAAI,GACT,GAAQ,OAAU,IAAgB,eAC7B,AAAI,EACT,GAAQ,EAER,IAAQ,EACR,EAAY,IAEd,MAAI,IACF,IAAQ,KAAO,EAAe,KAEzB,EAGT,YAAuB,EAAO,CAC5B,GAAI,GAAS,GACb,cAAO,oBAAoB,OAAO,eAAe,IAAQ,QAAQ,SAAS,EAAM,CAC9E,EAAO,GAAQ,cAAc,KAAK,GAAQ,UAAW,CAAE,MAAO,GAAM,GAAM,KAAK,IAAY,EAAM,KAEnG,EAAO,SAAW,GACX,EAGT,YAAsB,EAAO,EAAO,CAKlC,GAHI,IAAU,QACZ,GAAQ,CAAE,aAAc,KAAM,YAAa,OAE1C,EAAM,WACP,SAAM,YAAc,KACb,EAMT,GAAI,GAAS,EAAM,eAAiB,EAAM,2BAC1C,GAAI,EAAQ,CACV,GAAI,GAAO,EAAM,gBACb,EAAS,EAAM,kBAAoB,EAOnC,EAAW,8EACX,EAAe,EAAS,KAAK,QAAQ,SAAW,EAAI,GACxD,AAAI,IAAS,GAAK,EAAS,GAAgB,CAAC,MAAiB,CAAC,EAAM,UAClE,IAAU,GAGZ,GAAI,GAAW,GAAkB,CAC/B,OAAQ,EACR,KAAM,EACN,OAAQ,IAEV,EAAM,YAAc,EACpB,EAAQ,GAAc,GACtB,GAAI,GAAuB,EAAM,gBACjC,SAAM,gBAAkB,UAAW,CACjC,MAAI,GAAM,cAAgB,KACjB,IAEF,EAAM,aAAa,MAAQ,KAEpC,EAAM,YAAc,UAAW,CAAE,MAAO,GAAS,QACjD,EAAM,cAAgB,UAAW,CAAE,MAAO,GAAS,MACnD,EAAM,gBAAkB,UAAW,CAAE,MAAO,GAAS,OAAS,GAC9D,EAAM,yBAA2B,UAAW,CAAE,MAAO,GAAS,QACvD,EAIT,GAAI,GAAS,EAAM,UAAY,EAAM,gBACrC,MAAI,IACF,GAAS,GAAc,GACvB,EAAQ,GAAc,GACtB,EAAM,cAAgB,UAAW,CAAE,MAAO,KACnC,EASX,YAA2B,EAAO,EAAO,CACvC,AAAI,IACF,IAAoB,GACpB,GAAiB,IASnB,OANI,GAAO,EAAM,MAAQ,QACrB,EAAU,EAAM,SAAW,GAC3B,EAAc,EAAO,KAAO,EAE5B,EAAQ,CAAE,aAAc,KAAM,YAAa,MAC3C,EAAiB,GACZ,EAAI,EAAM,OAAS,EAAG,GAAK,EAAG,IACrC,EAAe,KAAK;AAAA,SAAc,GAAa,EAAM,GAAI,IACzD,EAAM,aAAe,EAAM,YAE7B,SAAM,YAAc,EAAM,aAAe,KAClC,EAAc,EAAe,UAAU,KAAK,IAIrD,YAAwB,EAAO,CAC7B,GAAI,GAAQ,sCAAsC,KAAK,EAAM,OAC7D,GAAI,EAAO,CACT,GAAI,GAAS,EAAM,GACf,EAAO,CAAC,EAAM,GACd,EAAS,CAAC,EAAM,GAGhB,EAAW,GAAkB,GAGjC,GAAI,CAAC,GAAY,IAAM,GAAG,WAAW,GACnC,GAAI,CACF,EAAW,GAAG,aAAa,EAAQ,cAC5B,EAAP,CACA,EAAW,GAKf,GAAI,EAAU,CACZ,GAAI,GAAO,EAAS,MAAM,kBAAkB,EAAO,GACnD,GAAI,EACF,MAAO,GAAS,IAAM,EAAO;AAAA,EAAO,EAAO;AAAA,EACzC,GAAI,OAAM,GAAQ,KAAK,KAAO,KAItC,MAAO,MAGT,YAA4B,EAAO,CACjC,GAAI,GAAS,GAAe,GAG5B,AAAI,QAAQ,OAAO,SAAW,QAAQ,OAAO,QAAQ,aACnD,QAAQ,OAAO,QAAQ,YAAY,IAGjC,GACF,SAAQ,QACR,QAAQ,MAAM,IAGhB,QAAQ,MAAM,EAAM,OACpB,QAAQ,KAAK,GAGf,aAAsC,CACpC,GAAI,GAAW,QAAQ,KAEvB,QAAQ,KAAO,SAAU,EAAM,CAC7B,GAAI,IAAS,oBAAqB,CAChC,GAAI,GAAY,UAAU,IAAM,UAAU,GAAG,MACzC,EAAgB,KAAK,UAAU,GAAM,OAAS,EAElD,GAAI,GAAY,CAAC,EACf,MAAO,IAAkB,UAAU,IAIvC,MAAO,GAAS,MAAM,KAAM,YAIhC,GAAI,IAA+B,GAAqB,MAAM,GAC1D,GAA8B,GAAoB,MAAM,GAE5D,GAAQ,aAAe,GACvB,GAAQ,eAAiB,GACzB,GAAQ,kBAAoB,GAC5B,GAAQ,kBAAoB,GAE5B,GAAQ,QAAU,SAAS,EAAS,CAGlC,GAFA,EAAU,GAAW,GAEjB,EAAQ,aACV,IAAc,EAAQ,YAClB,CAAC,OAAQ,UAAW,QAAQ,QAAQ,MAAiB,IACvD,KAAM,IAAI,OAAM,eAAiB,GAAc,6DAyBnD,GAnBI,EAAQ,cACN,GAAQ,sBACV,IAAqB,OAAS,GAGhC,GAAqB,QAAQ,EAAQ,eAKnC,EAAQ,mBACN,GAAQ,2BACV,IAAoB,OAAS,GAG/B,GAAoB,QAAQ,EAAQ,oBAIlC,EAAQ,aAAe,CAAC,KAAe,CAEzC,GAAI,GAAS,GAAe,GAAQ,UAChC,EAAW,EAAO,UAAU,SAEhC,AAAK,EAAS,oBACZ,GAAO,UAAU,SAAW,SAAS,EAAS,EAAU,CACtD,UAAkB,GAAY,EAC9B,GAAe,GAAY,OACpB,EAAS,KAAK,KAAM,EAAS,IAGtC,EAAO,UAAU,SAAS,mBAAqB,IAgBnD,GAXK,IACH,IAA8B,+BAAiC,GAC7D,EAAQ,4BAA8B,IAIrC,IACH,IAA0B,GAC1B,MAAM,kBAAoB,IAGxB,CAAC,GAAuB,CAC1B,GAAI,GAAiB,4BAA8B,GACjD,EAAQ,yBAA2B,GAKrC,GAAI,CAEF,GAAI,GAAiB,GAAe,GAAQ,kBAC5C,AAAI,EAAe,eAAiB,IAClC,GAAiB,UAEb,EAAN,EASF,AAAI,GAAkB,MACpB,IAAwB,GACxB,QAKN,GAAQ,sBAAwB,UAAW,CACzC,GAAqB,OAAS,EAC9B,GAAoB,OAAS,EAE7B,GAAuB,GAA6B,MAAM,GAC1D,GAAsB,GAA4B,MAAM,GAExD,GAAoB,GAAY,IAChC,GAAe,GAAY,OC1lB7B,OAAiC,wBACjC,GAAc,sBCDd,OAAoB,sBCGb,YAAoB,EAAgC,CACzD,MACE,IAAO,MACP,MAAO,IAAQ,UACf,MAAO,GAAI,OAAO,WAAc,WCH7B,WAAa,EAAyB,CAE3C,MAAO,IAAK,KACR,GACA,MAAO,IAAM,SACb,EACA,MAAM,QAAQ,GACd,EAAE,IAAI,GAAK,KAAK,KAChB,EAAE,WCPR,GAAM,IAAiB,CAAC,SAAU,SAAU,WAgBrC,YAAqB,EAA4B,CACtD,MAAO,IAAe,QAAQ,MAAO,MAAS,IAAM,YAAe,MAe9D,YAA0B,EAA8B,CAC7D,MAAO,OAAM,QAAQ,IAAS,EAAc,MAAM,IAWpD,GAAM,IAAY,CAChB,UACA,SACA,SACA,SACA,SACA,SACA,YAOK,YACL,EACA,EACQ,CAER,GAAI,GAAK,MAAQ,GAAK,KAAM,MAAO,GAInC,GAAI,GAAK,KAAM,MAAO,GACtB,GAAI,GAAK,KAAM,MAAO,GAEtB,GAAM,GAAQ,MAAO,GACf,EAAQ,MAAO,GAErB,MACG,KAAU,UAAY,IAAU,WAChC,KAAU,UAAY,IAAU,UAG1B,EAAI,GAAG,cAAc,EAAI,IAE9B,MAAM,QAAQ,IAAM,MAAM,QAAQ,GAC7B,GAAO,EAAU,GAEtB,IAAU,EACL,GAAU,QAAQ,GAAS,GAAU,QAAQ,GAE7C,EAAI,EAAI,EAAI,EAAI,EAAI,GAAK,EAI7B,YACL,EACA,EACS,CACT,MAAO,IAAI,EAAG,GAAK,EAGd,YACL,EACA,EACS,CACT,MAAO,IAAI,EAAG,IAAM,EAGf,YACL,EACA,EACS,CACT,MAAO,IAAI,EAAG,IAAM,EAGf,YACL,EACA,EACS,CACT,MAAO,IAAI,EAAG,GAAK,EAGd,YAAqC,EAAQ,EAAgB,CAClE,GAAI,EAAQ,IAAM,EAAQ,GAAI,MAAO,GACrC,GAAM,GAAM,KAAK,IAAI,EAAE,OAAQ,EAAE,QACjC,OAAS,GAAI,EAAG,EAAI,EAAK,IAAK,CAC5B,GAAM,GAAI,GAAI,EAAE,GAAI,EAAE,IACtB,GAAI,IAAM,EACR,MAAO,GAGX,MAAO,IAAI,EAAE,OAAQ,EAAE,QC/HlB,GAAK,IAAL,UAAK,EAAL,CACL,qBACA,6BACA,uBACA,uBACA,qBACA,2BACA,2BACA,2BACA,2BATU,aAYL,YAAkB,EAAyB,CAChD,MAAO,OAAO,IAAQ,SAIjB,YAAoB,EAA2B,CACpD,MAAO,OAAO,IAAQ,WAIjB,YAAkB,EAA+B,CACtD,MAAO,IAAW,KAAS,EAGtB,YAAoB,EAAoB,CAC7C,MAAI,IAAK,KACA,EACE,GAAS,GACX,EACE,GAAY,GACd,EACE,MAAM,QAAQ,GAChB,EACE,GAAW,GACb,EACE,GAAW,GACb,EACE,MAAO,IAAM,SAEf,EAAE,aAAe,MAAQ,EAAE,YAAY,OAAS,SACnD,EACA,EAEG,ECpCJ,YAAgB,EAAmB,CACxC,MAAO,IAAW,GAAK,IAAM,EAexB,GAAM,IAAO,IAAG,GC1BhB,WAAmB,EAAmB,EAA0B,CACrE,MAAO,IAAO,KAAO,OAAY,EAAE,GAW9B,YACL,EACA,EACA,EACU,CACV,MAAO,IAAM,MAAQ,GAAM,KAAO,OAAY,EAAE,EAAI,GAG/C,YACL,EACA,EACA,EACA,EACU,CACV,MAAO,IAAM,MAAQ,GAAM,MAAQ,GAAM,KAAO,OAAY,EAAE,EAAI,EAAI,GAGjE,WAAmB,EAAmB,EAA8B,CACzE,MAAO,IAAoB,GAAI,GAG1B,WACL,EACA,EACA,EACG,CACH,MAAO,IAAO,KAAO,EAAE,GAAO,GAAI,GAG7B,YACL,EACA,EACA,EACA,EACG,CACH,MAAO,GAAO,GAAK,EAAI,EAAI,GAAI,GAc1B,YAAoB,EAAiC,CAC1D,MAAO,IAAU,KAGZ,YAAuB,EAA+B,CAC3D,MAAO,IAAO,MAAQ,EAAI,MAAM,IAG3B,eAA4B,EAAmC,CACpE,MAAO,GAAQ,KAAK,IAGf,YAAmB,EAAwC,CAChE,MAAO,IAAK,MAAQ,EAAI,KAAO,OAAS,OAAY,ECzE/C,WAAe,EAAwB,CAE5C,GAAI,GAAK,KAAM,MAAO,GACtB,GAAM,GAAI,EAAI,GACd,MAAO,GAAE,SAAW,GAAK,EAAE,OAAO,SAAW,EAG/C,GAAM,IAAa,+BAEZ,YAAkB,EAAkC,CACzD,MAAO,IAAK,MAAQ,GAAW,KAAK,IAAM,KAGrC,WAAqB,EAAuB,CACjD,MAAO,CAAC,EAAM,GAIT,YAAoB,EAAuB,CAChD,GAAI,GAAK,KAAM,OACf,GAAM,GAAI,EAAI,GACd,MAAO,GAAE,SAAW,GAAK,EAAE,OAAO,SAAW,EAAI,OAAY,EAMxD,YAAoB,EAAQ,EAAmC,CACpE,GAAI,GAAK,KAAM,MAAO,IAAI,GAC1B,GAAM,GAAM,EAAI,GAAG,OACnB,MAAO,GAAI,OAAS,EAAI,EAAM,GAAI,GAG7B,YAAqB,EAAQ,EAAqC,CACvE,MAAO,AAAC,GAAM,GAAY,GAAP,EAAE,GAGhB,WAAwB,EAAU,EAA+B,CACtE,GAAI,IAAQ,IAAS,GAAO,MAAQ,IAAQ,GAC1C,OAEF,GAAM,GAAI,EAAI,GACd,MAAO,GAAS,GAAK,EAAE,GAAM,OAGxB,YACL,EACA,EACA,EACG,CACH,MAAO,GAAO,EAAY,EAAK,GAAI,GAG9B,eAA6B,EAA+B,CAEjE,OAAW,KAAM,GACf,GAAI,EAAS,GAAK,MAAO,GCtDtB,WACL,EACA,EACA,EACA,EACQ,CACR,MAAO,MAAK,UAAU,EAAI,GAAW,EAAU,GAAgB,GAAO,IAGxE,YACE,EACA,EAC6C,CAC7C,GAAM,GAAe,GACf,EAAc,GAEd,EACJ,GAEI,EAAC,EAAc,IACb,EAAM,KAAO,EACT,eACA,eACA,EAAK,MAAM,EAAG,EAAM,QAAQ,IAAQ,KAAK,KACzC,KAMZ,MAAO,UAAqB,EAAa,EAAY,CACnD,GAAI,EAAM,OAAS,EAAG,CACpB,GAAM,GAAU,EAAM,QAAQ,MAC9B,AAAI,GAAW,EACb,GAAM,OAAO,EAAU,GACvB,EAAK,OAAO,EAAS,SAAU,IAE/B,GAAM,KAAK,MACX,EAAK,KAAK,IAER,EAAM,QAAQ,IAAU,GAC1B,GAAQ,EAAG,KAAK,KAAM,EAAK,QAG7B,GAAM,KAAK,GAGb,MADe,IAAY,KAAO,EAAQ,EAAS,KAAK,KAAM,EAAK,ICnDhE,YAAa,EAAQ,EAAiB,CAC3C,MAAO,GAAU,KAAO,EAAU,GC4B7B,YAAgB,EAAwB,CAC7C,MACE,IAAK,MACJ,OAAM,QAAQ,IACZ,SAAS,EAAE,SACV,GAAW,EAAE,OAAO,YACpB,GAAW,EAAE,OACb,GAAW,EAAE,MACb,GAAW,EAAE,UACb,GAAW,EAAE,OCxCd,YACL,EACA,EACA,EACG,CACH,GAAI,GAAK,KAAM,KAAM,IAAI,OAAM,YAC/B,GAAI,EAAE,IAAI,GACR,MAAO,GAAE,IAAI,GACR,CACL,GAAM,GAAI,IACV,MAAI,IAAK,MAAM,EAAE,IAAI,EAAG,GACjB,GCuEX,GAAU,IAAV,UAAU,EAAV,CACS,AAAM,YAAY,GACZ,UAAU,GACV,MAAM,IAAG,GACT,SAAS,IAAM,GAC5B,GAAM,GAAO,IAAM,EACZ,AAAM,MAAM,EACN,UAAU,EACV,SAAS,EACT,UAAU,EACV,YAAY,AAAI,IAAkB,KAClC,SAAS,AAAI,IAAiC,EAAI,MAClD,OAAO,EACP,OAAO,EACP,OAAO,IAdZ,aAiBH,GAAM,IAAiB,GAEvB,QAAgC,CAIrC,YAA6B,EAAM,CAAN,SAHpB,eAAY,GACZ,aAAU,GAInB,KAAS,CACP,MAAO,MAAK,EAGd,OAAO,EAA+B,CACpC,MAAO,GAAE,KAAK,GAGhB,IAAO,EAAwB,CAC7B,MAAO,IAAI,IAAK,EAAE,KAAK,IAGzB,QAAW,EAA4C,CACrD,GAAM,GAAI,EAAE,KAAK,GACjB,MAAO,IAAM,GAAK,EAAI,EAAI,GAG5B,OAAO,EAA8B,CACnC,MAAO,GAAI,EAAE,KAAK,GAAK,KAAK,EAAI,QAGlC,QAAQ,EAAyB,CAC/B,SAAE,KAAK,GACA,KAGT,WAAe,CACb,MAAO,MAAK,EAGd,QAAiB,CACf,MAAO,MAGT,KAAW,EAAgB,EAAwC,CACjE,MAAO,GAAI,GAAG,QAAQ,GAAM,EAAE,KAAK,EAAG,IAGxC,KACE,EACA,EACA,EACQ,CACR,MAAO,GAAI,GAAG,QAAQ,GAAM,EAAI,GAAG,QAAQ,GAAM,EAAE,KAAK,EAAG,EAAI,KAGjE,KACE,EACA,EACA,EACA,EACQ,CACR,MAAO,GAAI,GAAG,QAAQ,GACpB,EAAI,GAAG,QAAQ,GAAM,EAAI,GAAG,QAAQ,GAAM,EAAE,KAAK,EAAG,EAAI,EAAI,QAK3D,YAAkB,EAA6B,CACpD,MAAO,aAAa,KAAQ,IAAM,GAM7B,WAAgB,EAAwB,CAC7C,MAAO,IAAM,GAAK,EAAI,GAAK,KAAO,GAAI,IAAK,GAAK,GCrK3C,YAAkB,EAAqB,CAC5C,MAAO,OAAO,IAAM,UAAY,CAAC,MAAM,IAAM,SAAS,GAGjD,YAAsB,EAAkB,EAAgC,CAC7E,MAAO,IAAS,GAAK,EAAE,GAAK,OAG9B,GAAM,IAAe,AAAC,GAA6C,CACjE,EACA,IACG,GAAS,IAAQ,GAAS,IAAQ,EAAE,EAAK,GAEjC,GAAK,GAAa,CAAC,EAAG,IAAM,EAAI,GAChC,GAAM,GAAa,CAAC,EAAG,IAAM,GAAK,GAClC,GAAK,GAAa,CAAC,EAAG,IAAM,EAAI,GAChC,GAAM,GAAa,CAAC,EAAG,IAAM,GAAK,GA8BxC,YACL,EACA,EACA,EACS,CACT,MAAO,IAAY,MAAQ,GAAU,KACjC,GACA,KAAK,IAAI,EAAW,GAAU,EAG7B,YAAe,EAAiC,CACrD,GAAI,CAAC,GAAS,GAAI,OAClB,GAAM,GAAI,KAAK,MAAM,GACrB,MAAO,KAAM,EAAI,KAAK,IAAI,GAAK,EAO1B,YAAoB,EAAuB,CAChD,MAAO,IAAW,EAAE,UAGtB,YACE,EACA,EAKA,CACA,GAAI,EAAM,GAAQ,MAAO,GAAK,aAC9B,GAAI,GAAS,GAAQ,MAAO,GAAK,KAAK,GACtC,GAAI,GAAW,GAAQ,MAAO,GAAK,KAAK,EAAM,YAC9C,GAAI,CACF,GAAM,GAAI,EAAK,KAAK,EAAI,IACxB,MAAO,IAAS,GAAK,EAAK,KAAK,GAAK,EAAK,kBACzC,CACA,MAAO,GAAK,cAIT,WACL,EACA,EACe,CACf,MAAO,IAAS,EAAO,GACrB,aAAc,OACd,KAAM,GAAK,GAAM,GACjB,KAAM,UACH,IAIA,YACL,EACA,EACe,CACf,MAAO,IAAS,EAAO,GACrB,aAAc,OACd,KAAM,GAAK,EACX,KAAM,YACH,IAaA,WAAa,EAAqB,CACvC,MAAO,IAAS,IAAM,EAAI,EAGrB,YACL,EACA,EACe,CACf,MAAO,IAAS,IAAM,GAAS,IAAsB,EAAI,EACrD,EACA,OAOC,YAAc,EAAqB,CACxC,MAAO,IAAS,IAAM,GAAK,EAGtB,YAAmB,EAAQ,EAA+B,CAC/D,MAAO,GAAI,GACR,QAAQ,GAAK,EAAM,IACnB,QAAQ,GACR,MAaE,YAAY,EAA8C,CAC/D,GAAM,GAAI,EAAM,GAChB,MAAO,GAAI,GAAK,OAAO,GAAK,OAOvB,YAAuB,EAAQ,EAA+B,CACnE,MAAO,IAAS,GAAK,EAAE,GAAK,OAGvB,YACL,EACA,EACA,EACU,CACV,MAAO,IAAW,EAAG,GAAO,GAAW,EAAG,GAAO,EAAE,EAAK,KAGnD,YACL,EACA,EACA,EACG,CACH,MAAO,IAAS,GAAK,EAAE,GAAK,EAGvB,YAAmB,EAAQ,EAAwC,CACxE,MAAO,IAAS,GAAK,EAAI,GAAI,GAGxB,YAAe,EAAmB,CAEvC,MAAO,GAAI,EAAI,CAAC,KAAK,MAAM,CAAC,GAAK,KAAK,MAAM,GAyBvC,YAAiB,EAAW,EAAwB,CACzD,GAAI,IAAM,GAAK,IAAW,EACxB,MAAO,GAET,GAAM,GAAM,EAAS,GAAM,KAAK,KAAK,KAAK,MAAM,KAAK,IAAI,MACnD,EAAM,KAAK,IAAI,GAAI,KAAK,IAAI,IAElC,MAAO,GAAM,EAAI,GAAM,EAAI,GAAO,EAAM,GAAM,EAAI,GAAO,EAWpD,YAAe,EAAa,EAAa,EAAuB,CACrE,GAAI,EAAM,GAAO,CAAC,GAAS,IAAQ,CAAC,GAAS,GAC3C,KAAM,IAAI,OAAM,iBAAiB,MAAQ,MAAQ,MACnD,MAAK,IAAS,GACP,EAAQ,EAAM,EAAM,EAAQ,EAAM,EAAM,EADlB,GAAO,GAAM,GAAO,GAQ5C,YAAkB,EAAe,EAA0B,CAChE,GAAI,CAAC,EAAI,GAAQ,MAAO,GACxB,GAAM,GAAI,KAAK,MAAM,GACrB,MAAI,IAAK,EAAU,GACZ,CAAC,GAAG,MAAM,IAAI,IAAI,CAAC,EAAG,IAAM,EAAE,IC5PhC,YACL,EACA,EACA,EAAqB,GACb,CAGR,GAFA,EAAM,KAAK,KAAK,GAChB,EAAM,KAAK,MAAM,GACb,EAAM,EAAK,MAAO,GACtB,GAAI,EAAW,IAAa,EAAS,OAAS,GAAK,EAAM,EAAK,CAC5D,GAAM,GAAW,GAAM,EAAK,GAAK,OAAO,GAAM,CAAC,EAAS,SAAS,IACjE,MAAO,IAAY,EAAU,GAAO,EAAI,GAAU,EAAG,EAAS,UAGhE,GAAM,GAAS,KAAK,MAAM,KAAK,SAAY,GAAM,IAAQ,EACzD,MAAO,GAAS,SAAS,GAAU,GAAU,EAAK,EAAK,GAAY,EAoB9D,GAAM,IAAc,sCAEpB,YACL,EACA,EAAgB,GACR,CACR,GAAI,GAAS,GACb,OAAS,GAAI,EAAG,EAAI,EAAO,IACzB,GAAU,GAAW,GAEvB,MAAO,GAGF,YAAoB,EAAgB,GAAqB,CAC9D,MAAO,GAAM,GAAU,EAAG,EAAM,SCtD3B,YAAkB,EAAyB,CAChD,MAAO,OAAO,IAAQ,SAGjB,YAAsB,EAAW,EAAwB,CAC9D,SAAI,EAAI,GACR,EAAS,EAAI,GACN,EAAE,WAAW,GAAU,EAAI,EAAS,EAGtC,YAAsB,EAAW,EAAwB,CAC9D,SAAI,EAAI,GACR,EAAS,EAAI,GACN,EAAE,SAAS,GAAU,EAAI,EAAI,EAG/B,YAAmB,EAAQ,EAAiB,GAAY,CAC7D,GAAI,GAAK,KACP,MAAO,GAET,GAAM,GAAI,EAAI,GACd,MAAO,GAAE,QAAU,EAAS,EAAI,EAAE,MAAM,EAAG,EAAS,GAAK,SAGpD,GAAM,IAAY,UAQlB,YACL,EACA,EACA,EACA,CACA,AAAI,GAAY,MAAM,GAAW,EAAS,QAC1C,OAAS,GAAI,EAAU,GAAK,EAAG,IAC7B,GAAI,EAAS,OAAO,GAAG,WAAW,GAAS,MAAO,GAEpD,MAAO,GAGF,YACL,EACA,EAAO,CAAE,WAAY,GAAI,OAAQ,IACvB,CACV,GAAI,EAAE,SAAS;AAAA,GACb,MAAO,IAAQ,EAAE,MAAM,IAAW,IAAI,GAAM,GAAK,EAAI,KAGvD,GADA,EAAI,GAAa,EAAI,GAAI,EAAK,QAAQ,OAClC,EAAE,QAAU,EAAK,WACnB,MAAO,CAAC,GAEV,GAAM,GAAc,GAAY,EAAG,IAAK,EAAK,YAE7C,GAAI,EAAc,EAAK,OAAO,OAC5B,MAAO,CAAC,EAAE,MAAM,EAAG,GAAc,GAAG,GAAK,EAAE,MAAM,EAAc,GAAI,IAC9D,CACL,GAAM,GAAe,EAAE,QAAQ,IAAK,EAAK,OAAO,OAAS,GACzD,MAAI,GAAe,GAAK,EAAe,EAAE,OAAS,EACzC,CACL,EAAE,MAAM,EAAG,GACX,GAAG,GAAK,EAAE,MAAM,EAAe,GAAI,IAG9B,CAAC,IAmBP,YACL,EACA,EACA,EACQ,CACR,MAAI,KAAgB,GAAW,EACxB,EAAE,MAAM,GAAa,KAAK,GAG5B,eAA+B,EAAqB,CACzD,MAAO,GAAE,KAAK,KAAK,QAAQ,OAAQ,KAAK,OC9FnC,WAAgB,EAAkC,CACvD,MAAO,IAAO,KACV,GACA,MAAM,QAAQ,GACb,EACD,GAAW,GACX,MAAM,KAAK,GACX,CAAC,GCaA,WAAyC,EAAyB,CACvE,MAAO,IAAO,IAAQ,EAAI,OAAS,GAAK,EAAI,KAAK,GAAM,GAAM,MAUxD,WAAiB,EAAyC,CAC/D,MAAO,CAAC,EAAW,GAOd,YACL,EACA,EACU,CACV,MAAO,GAAW,GAAO,EAAE,GAAO,OAWpC,YACE,EACyB,CACzB,MAAO,IAAY,IAAM,GAAiB,GAAK,EAAI,EAAE,UAMhD,YACL,EACA,EAAc,GACT,CACL,GAAI,GAAO,KAAM,MAAO,GACxB,OAAW,KAAM,GACf,GAAI,GAAM,KACR,GAAI,MAAM,QAAQ,GAEhB,OAAW,KAAO,GAChB,AAAI,GAAO,MAAM,EAAO,KAAK,OAG/B,GAAO,KAAK,GAIlB,MAAO,GAGF,YAEL,EAAyD,CACzD,MAAO,IAAc,EAAQ,GAAM,IAG9B,YAAwB,EAAa,EAAuB,CACjE,OAAS,GAAI,EAAG,EAAI,EAAO,OAAQ,IACjC,EAAY,GAAK,EAAO,GAE1B,SAAY,OAAS,EAAO,OACrB,EAGF,YAA0B,EAAU,EAA8B,CACvE,MAAO,IAAY,GAAO,EAAK,GAAI,GA0B9B,YACL,EACA,EACK,CACL,MAAO,GAAI,GACR,OAAO,GAAM,GAAM,MACnB,IAAI,CAAC,EAAM,IAAS,EACnB,OACA,IAAK,EAAI,EAAE,EAAM,GAAM,GAAM,CAAC,EAAI,OAEnC,OAAO,GAAM,EAAG,KAAO,MACvB,KAAK,CAAC,EAAG,IAAM,GAAI,EAAE,IAAM,EAAE,MAC7B,IAAI,GAAM,EAAG,MAYX,YAAuC,EAAQ,EAAiB,CACrE,MACE,IAAK,MACL,GAAK,MACL,EAAE,SAAW,EAAE,QACf,EAAE,MAAM,CAAC,EAAI,IAAQ,IAAO,EAAE,IAO3B,YACL,EACA,EACS,CACT,MAAO,IAAS,EAAS,MAAM,EAAG,EAAO,QAAS,GAO7C,YACL,EACA,EACK,CACL,OAAS,GAAI,EAAG,EAAI,EAAI,QACtB,AAAI,EAAW,EAAI,GAAI,EAAG,GACxB,IAEA,EAAI,OAAO,EAAG,GAGlB,MAAO,GAoBF,YACL,EACA,EACS,CACT,GAAI,GAAY,KAAM,MAAO,GAC7B,OAAW,KAAM,GACf,GAAI,EAAO,YAAc,EAAG,UAAW,MAAO,GAEhD,MAAO,GAmBF,YACL,EACA,EACS,CACT,MAAI,IAAY,MAAQ,GAAW,KAAa,GACzC,EAAQ,MAAM,GAAU,GAAS,EAAU,IAmB7C,YACL,EACA,EACA,EACK,CACL,GAAM,GAAO,EAAI,IAAI,GACrB,OAAW,KAAQ,GAAO,CACxB,GAAM,GAAI,EAAQ,GAClB,AAAK,EAAK,SAAS,IACjB,GAAI,KAAK,GACT,EAAK,KAAK,IAGd,MAAO,GAsCF,WAAoB,EAA4C,CACrE,GAAI,GAAQ,KAAM,MAAO,GACzB,GAAM,GAAM,EAAI,GAChB,MAAO,GAAI,MAAM,IAAY,EAAuB,EAAI,OAAO,IAG1D,YAA4B,EAA4C,CAC7E,GAAM,GAAM,EAAI,GAAM,OAAO,GAAM,CAAC,GAAS,EAAI,KACjD,MAAQ,IAAS,EAAI,IAAM,EAAI,IAAI,GAAM,EAAI,GAAI,QAAU,EAGtD,WAAuB,EAA6B,CAEzD,MAAO,GAAI,GACR,IAAI,GAAM,EAAI,GAAI,QAClB,OAAO,GAAM,EAAG,OAAS,GAGvB,WAAiB,EAAsC,CAC5D,MAAO,IAAO,EAAQ,GAAM,GAAM,EAAU,IAMvC,YACL,EACA,EAAwB,GAAM,EAAU,GACnC,CACL,GAAI,EAAQ,GAAM,MAAO,GACzB,GAAM,GAAI,GAAI,KACd,OAAW,KAAM,GACf,GAAI,GAAM,KAAM,CACd,GAAM,GAAI,EAAE,GACZ,AAAI,GAAK,MACP,GAAS,EAAG,EAAG,IAAM,GAI3B,MAAO,CAAC,GAAG,EAAE,UA+BR,YACL,EACA,EACQ,CACR,MAAO,GAAI,OAAO,CAAC,EAAK,EAAI,IAAQ,EAAO,GAAU,EAAI,GAAO,EAAI,GAAI,GASnE,YACL,EACA,EACQ,CACR,MAAO,GAAI,OAAO,CAAC,EAAK,EAAI,IAAQ,EAAM,EAAE,EAAI,GAAM,GAcjD,YACL,EACA,EACQ,CACR,GAAI,GAAK,MAAQ,GAAK,KAAM,MAAO,GAInC,GAHI,IAAM,GACN,OAAO,IAAM,UAAU,GAAK,EAAE,MAAM,KACpC,MAAO,IAAM,UAAU,GAAK,EAAE,MAAM,KACpC,GAAS,EAAG,IAAI,MAAO,GAAE,OAC7B,GAAI,GAAS,EACb,KAAO,EAAE,KAAY,EAAE,IAAS,IAChC,MAAO,GA2CF,YACL,EACA,EACA,EAAsB,GAAM,EACvB,CACL,MAAO,IAAU,EAAM,EAAI,EAAG,GAOzB,YACL,EACA,EACA,EAAe,EACf,EAAsB,GAAM,EACvB,CACL,GAAM,GAAS,GACf,GAAI,EAAO,EACT,OAAS,GAAI,EAAM,EAAI,EAAI,GAAK,EAC9B,EAAE,KAAK,EAAE,QAGX,QAAS,GAAI,EAAM,EAAI,EAAI,GAAK,EAC9B,EAAE,KAAK,EAAE,IAGb,MAAO,GAYF,YAAmC,EAAc,EAAsB,CAC5E,GAAM,GAAI,GAAI,KAAI,GAClB,MAAO,GAAQ,OAAO,GAAM,CAAC,EAAE,IAAI,IAG9B,YAAiB,EAA2B,CACjD,MAAO,IAAO,KAAO,EAAI,EAAI,OAAS,GAAK,OCvdtC,WAAiB,EAAgB,EAAkC,CACxE,MAAO,IAAI,IAAK,EAAO,GAAO,kBAGzB,YAAc,CAKnB,YAAqB,EAAuB,EAAgB,CAAvC,aAAuB,aAJpC,aAAU,EAED,eAAiC,GAIlD,iBAAoC,CAElC,GAAM,GAAS,KAAK,MAAM,KAAK,MAC/B,SAAE,IAAM,KAAK,IAAI,KAAK,MACtB,EAAE,MAAQ,KAAK,MAAM,KAAK,MAC1B,EAAE,MAAQ,KAAK,MAAM,KAAK,MAC1B,EAAE,MAAQ,KAAK,MAAM,KAAK,MAC1B,EAAE,QAAU,KAAK,QAAQ,KAAK,MAC9B,EAAE,IAAM,KAAK,IAAI,KAAK,MACtB,EAAE,OAAS,KAAK,OAAO,KAAK,MAC5B,EAAE,SAAW,KAAK,SAAS,KAAK,MAChC,EAAE,OAAS,KAAK,OAAO,KAAK,MAC5B,EAAE,aAAe,KAAK,aAAa,KAAK,MACjC,OAGK,aAAY,EAAkB,EAAoB,CAC9D,GAAI,EAAQ,KAAK,WAAY,OAC7B,GAAM,GAAQ,KAAM,GACd,EAAU,KAAM,GACtB,GAAI,CAAC,GAAI,EAAO,GACd,OAAW,KAAM,MAAK,UAAW,EAAG,EAAS,GAIjD,UAAU,EAAM,CACd,YAAK,QAAU,KAAK,MACf,KAAK,YAAY,KAAK,OAAQ,GAC3B,KAAK,OAAS,EAGxB,OAAQ,CACN,MACE,MAAK,UAAY,GAChB,KAAK,OAAS,MAAQ,KAAK,QAAU,KAAK,OAAS,KAAK,QAIzD,KAAK,UAAU,KAAK,SAEf,KAAK,OAGd,IAAI,EAAM,CACR,MAAO,MAAK,UAAU,GAGxB,OAAQ,CACN,KAAK,UAAU,QACf,KAAK,QAAU,EAGjB,OAAQ,CACN,GAAM,GAAQ,KAAK,OACnB,YAAK,QACE,EAGT,OAAQ,CACN,MAAO,MAAK,OAGd,SAAU,CACR,MAAO,MAAK,UAAU,KAAK,SAG7B,KAAM,CACJ,MAAO,MAAK,MAGd,OAAO,EAAa,CAClB,KAAK,MAAQ,EAGf,SAAS,EAA6B,CACpC,KAAK,UAAU,KAAK,GACpB,EAAI,KAAK,OAAQ,GAInB,QAAS,CACP,MAAO,SAGT,cAAe,CACb,MAAO,MAAK,MAAQ,KAAK,UClItB,GAAM,GAAW,IACX,EAAW,GAAK,EAChB,GAAS,GAAK,EACd,GAAQ,GAAK,GACb,GAAS,EAAI,GACb,GAAS,OAAS,GAEzB,GAAM,EACV,IACE,GAAI,MAAK,eAAe,OAAW,CACjC,QAAS,QACT,KAAM,UACN,MAAO,QACP,IAAK,UACL,KAAM,UACN,OAAQ,aAsBP,YAAgB,EAAuB,CAC5C,MAAO,aAAe,MAMjB,YAAa,EAAiB,EAAmB,CACtD,MAAO,IAAI,MAAK,EAAO,EAAM,GAAI,OAAQ,UAAY,GAUhD,YAAkB,EAA2B,CAClD,GAAM,GAAK,GAAO,GAAK,EAAE,UAAY,GAAS,GAAK,EAAI,KAAK,MAC5D,MAAO,MAAK,MAAM,EAAK,GAIzB,YAAc,EAAW,CACvB,GAAM,GAAI,OAAO,GACjB,MAAO,GAAE,QAAU,EAAI,EAAK,KAAM,GAAG,MAAM,IAMtC,YAAmB,EAA4B,CACpD,GAAM,GAAI,GAAO,GAAO,EAAM,GAAI,MAAK,GACvC,MACE,GAAE,cACF,GAAK,EAAE,WAAa,GACpB,GAAK,EAAE,WACP,GAAK,EAAE,YACP,GAAK,EAAE,cACP,GAAK,EAAE,cAOJ,YAAoB,EAA2B,CACpD,GAAM,GAAI,GAAO,GAAM,EAAK,GAAI,MAAK,GACrC,MACE,GAAE,cAAgB,IAAM,GAAK,EAAE,WAAa,GAAK,IAAM,GAAK,EAAE,WCtE3D,eAAsC,EAAoB,CAC/D,GAAM,GAAS,OAAO,OAAO,GAEvB,EAAuB,GAC7B,OAAW,KAAM,GACf,EAAK,GAAM,EAGb,GAAM,GAAM,AAAC,GACX,GAAK,MAAQ,EAAO,SAAS,GAEzB,EAAU,AAAC,GACf,GAAK,KAAO,GAAK,EAAO,QAAQ,GAE5B,EAAc,CAAI,EAAsB,IAC5C,EAAI,GAAK,EAAI,GAAI,GAEb,EAAW,CAAI,EAAW,IAC9B,EAAI,GAAK,EAAE,GAAU,OAEvB,MAAO,QACF,GADE,CAEL,SACA,OAAQ,EAAO,OACf,MACA,UACA,cACA,aCjDJ,OAA0B,sBCEnB,YAAmB,EAAgC,CACxD,MAAO,OAAO,IAAW,UAQpB,WAAgB,EAAiB,CACtC,GAAI,MAAO,IAAM,UAAW,MAAO,GACnC,GAAI,GAAK,KAAM,MAAO,GACtB,GAAI,IAAM,EAAG,MAAO,GACpB,GAAM,GAAI,OAAO,GAAG,cACpB,MAAO,CAAC,OAAQ,KAAK,SAAS,GAMzB,YAAmB,EAAwB,CAChD,MAAO,GAAO,GAAK,GAAO,GAAQ,GAAK,GAAQ,OAG1C,YAAmB,EAAQ,CAChC,MAAO,GAAO,GAAK,EAAI,EASlB,YAAiB,EAAiB,CACvC,GAAI,MAAO,IAAM,UAAW,MAAO,CAAC,EACpC,GAAI,GAAK,KAAM,MAAO,GACtB,GAAI,IAAM,EAAG,MAAO,GACpB,GAAM,GAAI,OAAO,GAAG,cACpB,MAAO,CAAC,QAAS,KAAK,SAAS,GDrC1B,aAAoB,CACzB,OAAQ,EAAI,OAAI,UAAU,mBACnB,WACA,UACH,MAAO,WACJ,UACA,cACH,MAAO,kBACJ,WACA,aACH,MAAO,qBAEP,MAAI,SAAK,KAAK,GAAM,EAAG,SAAS,UAAY,EAAG,SAAS,aAC/C,OAEA,cAKR,GAAM,IAAW,KAAM,CAC5B,GAAM,GAAK,KAGX,cAAI,SAAW,EACR,MAIF,GAAM,IAAS,KAAY,OACrB,GAAS,KAAY,aAE3B,aAA6B,CAClC,MAAO,KAAU,EAAO,OAAI,mBAOvB,GAAM,IAAQ,KAAK,MEzCnB,GAAM,IAAgB,iBAEhB,GAAU,EAAK,IAAM,GAAiB,IAAS,GAAK,IAAI,OCLrE,YAAe,EAAY,EAAa,CACtC,MAAO,AAAC,IAAgB,KAAU,KAAM,MAAa,KAKhD,GAAM,IAAQ,GAAM,GAAI,IAClB,GAAM,GAAM,GAAI,IAChB,GAAQ,GAAM,GAAI,IAClB,GAAS,GAAM,GAAI,IACnB,GAAO,GAAM,GAAI,IACjB,GAAU,GAAM,GAAI,IACpB,GAAO,GAAM,GAAI,IACjB,GAAY,GAAM,GAAI,IACtB,GAAW,GAAM,GAAI,IACrB,GAAY,GAAM,GAAI,IACtB,GAAc,GAAM,GAAI,IACxB,GAAe,GAAM,GAAI,IACzB,GAAa,GAAM,GAAI,IACvB,GAAgB,GAAM,GAAI,IAC1B,GAAa,GAAM,GAAI,IACvB,GAAQ,GAAM,GAAI,IAClB,GAAU,GAAM,GAAI,IACpB,GAAQ,GAAM,GAAI,IAClB,GAAU,GAAM,GAAI,IACpB,GAAW,GAAM,GAAI,IACrB,GAAS,GAAM,GAAI,IACnB,GAAY,GAAM,GAAI,IACtB,GAAS,GAAM,GAAI,IACnB,GAAc,GAAM,GAAI,IACxB,GAAa,GAAM,IAAK,IACxB,GAAc,GAAM,IAAK,IACzB,GAAgB,GAAM,IAAK,IAC3B,GAAiB,GAAM,IAAK,IAC5B,GAAe,GAAM,IAAK,IAC1B,GAAkB,GAAM,IAAK,IAC7B,GAAe,GAAM,IAAK,IAC1B,GAAU,GAAM,IAAK,ICrClC,OAAoB,sBCoBb,YAAgB,EAAM,EAA2B,CACtD,MAAI,IAAS,KACX,EAAM,GAEN,AAAI,MAAO,IAAM,SACf,QAAQ,IAAI,GAEZ,QAAQ,IAAI,EAAG,CAAE,MAAO,IAGrB,EAGF,YAA6B,EAA2B,CAE7D,MAAI,IAAO,MAAQ,MAAO,IAAQ,SAAiB,GAC5C,OAAO,KAAK,GAAK,OACtB,GACE,MAAO,IAAM,UACZ,GAAI,sBAA2B,MAC9B,EAAI,qBAAwB,KAAO,KAiBpC,YAA+B,EAAqB,CACzD,MAAO,IAAK,GAAG,IAAI,GAAK,EAAE,IAIrB,YAAgC,EAAmC,CACxE,MAAO,IAAK,GAAK,IAAI,GAAM,CAAC,EAAI,EAAI,KAG/B,YACL,EACA,EACK,CACL,MAAI,OAAO,IAAQ,UAAU,GAAM,IAC5B,EAAQ,GAAK,OAClB,CAAC,EAAK,CAAC,EAAG,KACR,GAAI,EAAK,IAAM,CACb,AAAI,GAAK,MAAQ,GAAK,MACpB,GAAI,GAAK,KAGf,GAIG,YACL,EAC8B,CAC9B,GAAI,GAAK,KAAM,OACf,GAAM,GAAQ,GAAQ,GAAG,OAAO,CAAC,CAAC,EAAG,KAAO,GAAK,MAAQ,GAAK,MAC9D,MAAO,GAAQ,GAAS,OAAY,GAAY,GAG3C,YACL,EAC8B,CAC9B,GAAI,GAAK,KAAM,OACf,GAAM,GAAQ,GAAQ,GAAG,OAAO,CAAC,CAAC,EAAG,KAAO,GAAK,MAAQ,EAAS,IAClE,MAAO,GAAQ,GAAS,OAAY,GAAY,GAG3C,YACL,EACA,EACA,EAAM,GACD,CACL,GAAM,GAAM,EACV,GAAQ,GAGL,KAAK,CAAC,CAAC,GAAK,CAAC,KACZ,EAAG,cAAc,EAAI,OAAW,CAAE,YAAa,UAEhD,IAAI,CAAC,CAAC,EAAG,KAAO,EAAE,EAAG,KAE1B,MAAO,IACL,EAAI,OAAO,CAAC,CAAC,EAAG,KAAO,GAAK,MAAQ,GAAK,MACzC,GAIG,YACL,KACG,EACS,CACZ,GAAI,GAAO,KAAM,MAAO,GACxB,GAAI,CAAC,EAAS,MAAM,GAAM,MAAO,IAAO,UACtC,KAAM,IAAI,OAAM,aAAe,EAAU,IAC3C,GAAI,EAAQ,GAAW,MAAO,GAE9B,GAAM,GAAqB,GAC3B,OAAW,KAAM,GAAU,CACzB,GAAM,GAAI,EAAI,GACd,AAAI,GAAK,MAAM,GAAO,GAAM,GAE9B,MAAO,GAkBF,YACL,KACG,EACW,CACd,GAAI,GAAK,MAAQ,EAAW,MAAM,GAAM,EAAO,EAAU,KACvD,MAAO,GAET,GAAM,GAAQ,GAAQ,GAAG,OAAO,CAAC,CAAC,KAAO,CAAC,EAAW,SAAS,IAC9D,MAAO,GAAQ,GAAS,OAAY,GAAY,GAG3C,YAAwB,EAAsC,CACnE,MAAO,IAAO,GAAU,MAAM,GAAM,GAAM,MAGrC,YAA4B,EAAwC,CACzE,MAAO,IAAY,GAAK,EAAI,OAUvB,YAA0B,EAAuC,CACtE,MAAO,GAAI,OAAO,IAGb,YAAmC,EAAW,CACnD,MAAO,IAAY,GAAO,GAAQ,GAAM,CAAC,CAAC,KAAO,EAAE,gBAG9C,YACL,EACA,EACY,CACZ,MAAI,IAAO,KAAa,EACjB,GACL,GAAQ,GAAK,OAAO,CAAC,CAAC,EAAG,KAAO,EAAU,EAAQ,KAqB/C,YAAmB,EAAQ,KAAmB,EAAa,CAChE,MAAO,IAAK,MAAQ,GAAW,EAAE,IAC7B,EAAE,GAAQ,KAAK,GAAG,GAAG,GACrB,OAGC,YAAmC,EAAQ,EAAkB,CAClE,GAAI,EAAM,GAAM,OAChB,GAAI,EAAE,IAAQ,KAAM,MAAO,GAAE,GAC7B,GAAM,GAAQ,EAAI,oBAAoB,YACtC,OAAW,KAAK,IAAK,GACnB,GAAI,IAAU,EAAE,oBAAoB,aAAe,EAAE,IAAM,KAAM,MAAO,GAAE,GDtNvE,YAAgB,EAA4B,CACjD,MAAO,IAA0B,OAAK,GAGjC,YAAmB,EAAsB,CAC9C,MAAO,GAAO,GAAO,IEbvB,OAAwB,mBCKxB,GAAM,IAAa,oBAEZ,YAAgB,EAAa,EAAsB,CACxD,MAAO,IAAG,EAAG,GAWf,kBACE,EACA,EACkB,CAClB,MAAO,IAAO,KAAM,GAAG,KAAM,GAAG,GAAK,IAAM,IAG7C,kBACE,EACA,KACG,EACe,CAClB,MAAO,IACL,KAAM,GACN,KAAM,GACN,CAAC,EAAI,IAAO,GAAI,GAAK,EAAI,GAAG,GAAO,GAAK,EAAI,GAAG,IAC/C,IAAM,ID+BH,eAAwB,EAAgC,CAC7D,MAAO,IAAO,MAAQ,EAAI,MAAM,GAO3B,YAAuB,EAAyB,CACrD,MAAO,IAAW,MAAQ,EAAQ,KAAK,GAAM,GAAM,MAW9C,YACL,EACA,EACU,CACV,GAAI,GAAO,KACT,OAAW,KAAK,GAAQ,GAAM,CAC5B,GAAM,GAAI,EAAE,GACZ,GAAI,GAAK,KACP,MAAO,IAYf,kBACE,EACA,EACiB,CACjB,GAAI,GAAO,KAAM,CACf,GAAI,GAAQ,GACZ,OAAW,KAAK,GAAK,CACnB,IACA,GAAI,CACF,GAAI,GAAK,KAAM,SACf,GAAM,GAAI,KAAM,GAAE,EAAG,GACrB,GAAI,GAAK,KACP,MAAO,SAEF,EAAP,KA0BD,YAAqB,EAAU,EAAwC,CAC5E,OAAS,GAAI,EAAI,OAAS,EAAG,GAAK,EAAG,IACnC,GAAI,EAAU,EAAI,IAAK,MAAO,GAAI,GAiC/B,YAAmB,KAAa,EAAuB,CAC5D,GAAM,GAAS,EAAI,OACnB,UAAc,EAAK,GAAM,EAAQ,MAAM,GAAO,CAAC,GAAI,EAAI,KAChD,IAAW,EAAI,OAoBxB,GAAM,IAAyB,AAAC,GAAW,CACzC,GAAI,GAAY,GACd,MAAO,GAGT,GAAI,MAAM,QAAQ,GAChB,MAAO,GAAU,GAEnB,GAAI,GAAW,EAAE,SACf,MAAO,GAAE,UAET,KAAM,IAAI,OAAM,kCAAoC,eAAQ,KA0BzD,YACL,EACA,EACA,EAA+B,GAC1B,CACL,GAAM,GAAI,GAAI,KAAI,EAAE,IAAI,IACxB,MAAO,GAAE,OAAO,GAAM,EAAE,IAAI,EAAQ,KAG/B,YACL,EACA,EACA,EAA+B,GACvB,CACR,MAAI,GAAQ,IAAM,EAAQ,GAAW,EAC7B,GAAa,EAAG,EAAG,GAAS,OAAS,EAAM,GAAE,OAAS,EAAE,QAuB3D,YACL,EACA,EAAgC,GAAM,EAAU,GAC1C,CACN,GAAY,GAAO,EAAK,GAAI,GAGvB,YACL,EACA,EACY,CACZ,GAAM,GAAc,GACd,EAAc,GACpB,SAAI,QAAQ,CAAC,EAAI,IAAO,GAAO,EAAI,GAAK,EAAS,GAAQ,KAAK,IACvD,CAAC,EAAQ,GAMX,YACL,EAC2B,CAC3B,MAAO,IAAW,EAAI,QAGxB,YACE,EAC2B,CAC3B,GAAI,GAAa,MAAQ,EAAU,SAAW,EAAG,MAAO,GACxD,GAAM,GAAI,EAAU,GACd,EAAW,EAAU,YAAY,GACvC,MAAO,CACL,CAAE,IAAG,MAAO,EAAW,GACvB,GAAG,GAAW,EAAU,MAAM,EAAW,KAkBtC,YAAuB,EAAU,EAAqC,CAC3E,MAAO,GAAI,OACT,CAAC,EAAW,IAAY,EAAK,OAAO,GAAG,EAAQ,EAAE,KACjD,IAIG,YAAwB,EAAU,EAAqB,CAC5D,MAAI,GAAI,OAAS,GACf,EAAI,OAAO,EAAG,EAAI,OAAS,GAEtB,EAGF,YAAyB,EAAU,EAAqB,CAC7D,SAAI,OAAS,KAAK,IAAI,EAAI,OAAQ,GAC3B,EA0EF,eAAmB,EAAsB,CAC9C,GAAM,GAAM,KAAK,IAAI,GAAG,EAAO,IAAI,GAAM,EAAG,SAC5C,MAAO,IAAM,EAAK,GAAK,EAAO,IAAI,GAAM,EAAG,KAGtC,eAAuB,EAAoB,CAChD,GAAM,GAAM,KAAK,IAAI,GAAG,EAAO,IAAI,GAAM,EAAG,SACtC,EAAS,GACf,UAAM,EAAK,GAAK,EAAO,IAAI,GAAM,EAAE,KAAK,EAAG,MACpC,EAUF,YAAqB,EAAiB,CAC3C,MAAO,IAAM,EAAI,OAAQ,GAAK,EAAI,MAAM,EAAG,EAAI,IAW1C,YACL,EACQ,CACR,MAAO,IAAa,EAAK,GAAM,EAAG,WAG7B,YAAqC,EAA+B,CACzE,MAAO,GAAI,GAAc,IAOpB,YACL,EACQ,CACR,MAAO,IAAgB,EAAK,GAAM,EAAG,WAGhC,YACL,EACA,EACQ,CACR,MAAO,IAAS,EAAK,EAAS,CAAC,EAAG,IAAM,GAAG,EAAG,IAGzC,YACL,EACA,EACQ,CACR,MAAO,IAAS,EAAK,EAAS,CAAC,EAAG,IAAM,GAAG,EAAG,IAGzC,YACL,EACA,EACU,CACV,MAAO,GAAI,GAAa,EAAK,IAGxB,YACL,EACA,EACU,CACV,MAAO,GAAI,GAAgB,EAAK,IAGlC,YACE,EACA,EACA,EACQ,CACR,GAAI,EAAQ,GAAM,MAAO,GAEzB,GAAI,GAAS,GACT,EAEJ,OAAS,GAAI,EAAG,EAAI,EAAI,OAAQ,IAAK,CACnC,GAAM,GAAK,EAAI,GACf,GAAI,GAAM,KAAM,CACd,GAAM,GAAI,EAAQ,GAClB,AAAI,GAAK,MACH,IAAS,MAAQ,EAAU,EAAG,KAAW,KAC3C,GAAS,EACT,EAAQ,IAKhB,MAAO,GAgBF,YAAoB,EAAU,EAA0B,CAC7D,MAAI,IAAa,GAAG,GAAY,GACzB,GAAU,EAAG,EAAI,OAAQ,EAAW,GAAK,EAAI,MAAM,EAAG,EAAI,IE5hBnE,OAAwB,mBCIjB,YAAqD,CAK1D,YAAqB,EAAmB,CAAnB,iBAFb,aAAU,EACV,iBAAc,EAEpB,GAAI,EAAY,IACd,KAAM,IAAI,OAAM,4BAA8B,GAChD,KAAK,MAAQ,GAAI,OAAS,GAAI,GAAM,EAAW,IAAM,OAM/C,SAAY,EAAe,EAAwC,CACzE,SAAQ,KAAK,MAAM,IAAU,EACzB,EAAQ,GACV,IAAS,KAAK,SAET,EAAQ,GAAK,EAAQ,KAAK,QAAU,EACvC,OACA,EAAG,GAAQ,KAAK,YAAc,KAAK,WAAa,KAAK,WAU3D,KAAK,EAAc,CACjB,MAAO,MAAK,SAAS,EAAG,GAAO,KAAK,MAAM,IAG5C,IAAI,EAAW,EAAU,CACvB,MAAO,MAAK,SAAS,EAAG,GAAQ,KAAK,MAAM,GAAO,MAGhD,SAAiB,CACnB,MAAO,MAAK,WAGV,QAAO,EAAW,CACpB,KAAK,QAAU,GAAM,EAAG,KAAK,QAAS,GAGxC,OAAQ,CACN,KAAK,OAAS,GAGf,OAAO,WAAiC,CAEvC,GAAM,GAAO,KACb,YAAsC,CACpC,OAAS,GAAI,EAAG,EAAI,EAAK,OAAQ,IAC/B,KAAM,GAAK,SAAS,EAAG,GAAM,EAAK,MAAM,IAG5C,MAAO,KAGT,QAAQ,EAAoB,CAE1B,OAAW,KAAQ,GAAM,MAAM,CAAC,KAAK,WACnC,AAAI,KAAK,QAAU,KAAK,UACtB,KAAK,UAGL,MAAK,cACL,KAAK,YAAc,KAAK,YAAc,KAAK,WAE7C,KAAK,SAAS,KAAK,QAAU,EAAG,GAAO,CACrC,KAAK,MAAM,GAAO,IAGtB,MAAO,MAAK,QAGd,KAAqB,CACnB,MAAO,MAAK,SAAS,KAAK,QAAU,EAAG,GACrC,MAAK,UACE,KAAK,MAAM,KAItB,WAAW,EAAoB,CAC7B,OAAW,KAAQ,GAAM,UACvB,AAAI,KAAK,QAAU,KAAK,WACtB,KAAK,UAGP,KAAK,cACL,KAAK,SAAS,EAAG,GAAO,CACtB,KAAK,MAAM,GAAO,EAClB,KAAK,YAAc,IAGvB,MAAO,MAAK,QAGd,OAAuB,CACrB,MAAO,MAAK,SAAS,EAAG,GACtB,MAAK,cACL,KAAK,UACE,KAAK,MAAM,KAItB,cAAe,CACb,MAAO,MAAK,OAAS,EAAI,KAAK,QAAU,KAAK,KAAK,GAGpD,MAAM,EAA2D,CAC/D,OAAS,GAAI,EAAG,EAAI,KAAK,QAAS,IAChC,GAAI,CAAC,EAAW,KAAK,KAAK,GAAI,GAAI,MAAO,GAE3C,MAAO,GAGT,KAAK,EAA2D,CAC9D,OAAS,GAAI,EAAG,EAAI,KAAK,QAAS,IAChC,GAAI,EAAW,KAAK,KAAK,GAAI,GAAI,MAAO,GAE1C,MAAO,GAGT,QAAQ,EAAqD,CAC3D,OAAS,GAAI,EAAG,EAAI,KAAK,QAAS,IAChC,EAAW,KAAK,KAAK,GAAI,GAI7B,IAAO,EAAiD,CACtD,GAAM,GAAM,GACZ,OAAS,GAAI,EAAG,EAAI,KAAK,QAAS,IAChC,EAAI,KAAK,EAAW,KAAK,KAAK,GAAI,IAEpC,MAAO,GAGT,OACE,EACA,EACG,CACH,GAAI,GAAM,EACV,OAAS,GAAI,EAAG,EAAI,KAAK,QAAS,IAChC,EAAM,EAAW,EAAK,KAAK,KAAK,GAAI,GAEtC,MAAO,GAGT,SAAgB,CACd,OAAS,GAAI,EAAG,EAAI,KAAK,MAAM,KAAK,QAAU,GAAI,IAChD,KAAK,SAAS,EAAG,GAAQ,CACvB,KAAK,SAAS,KAAK,QAAU,EAAI,EAAG,GAAM,CACxC,GAAM,GAAO,KAAK,MAAM,GACxB,KAAK,MAAM,GAAM,KAAK,MAAM,GAC5B,KAAK,MAAM,GAAQ,MAIzB,MAAO,MAGT,KAAW,CACT,MAAO,CAAC,GAAG,MAGb,MAAM,EAA4B,EAA+B,CAC/D,MAAO,CAAC,GAAG,MAAM,MAAM,EAAO,KCpKlC,GAAM,IAAa,cAYb,GAAO,GAEN,YAAiB,EAAc,EAAwB,CAC5D,GAAI,EAAS,EAAG,MAAO,GAEvB,IADI,GAAK,IAAS,MAAM,IAAK,GAAQ,GAC9B,EAAS,GAAK,GAAM,QACzB,GAAK,IAAS,EAEhB,MAAO,IAAK,GAAM,UAAU,EAAG,GAI1B,YAAiB,EAAQ,EAAmB,EAAyB,CAC1E,GAAI,EAAQ,SAAW,EAAG,KAAM,IAAI,OAAM,6BAC1C,GAAI,MAAO,IAAM,UAAY,EAAI,EAC/B,MAAO,IAAM,GAAQ,OAAO,CAAC,GAAI,EAAY,EAAG,GAElD,GAAM,GAAM,OAAO,GACnB,MAAO,IAAQ,EAAS,EAAY,EAAI,QAAU,EAG7C,YAAkB,EAAQ,EAAmB,EAAyB,CAC3E,GAAI,EAAQ,SAAW,EAAG,KAAM,IAAI,OAAM,8BAC1C,GAAM,GAAM,OAAO,GACnB,MAAO,GAAM,GAAQ,EAAS,EAAY,EAAI,QAMzC,YAAc,EAAgB,CACnC,MAAO,IAAQ,EAAG,EAAG,KAGhB,YACL,EACA,EACA,EACA,EACA,CACA,MACE,GAAE,OAAO,EAAG,GAAW,GAAQ,EAAS,GAAU,EAAE,OAAO,EAAU,GAwClE,YAAoB,EAAW,EAAW,EAA8B,CAC7E,GAAM,GACJ,KAAK,IACH,KAAK,KAAK,EAAE,OAAS,GACrB,EAAO,EAAW,IAAM,EAAE,SACxB,EACN,MAAI,IAAc,EAAU,CAAC,GACtB,CACL,GAAG,GAAM,EAAY,GAAK,EAAE,MAAM,EAAI,EAAI,GAAI,GAAK,IACnD,EAAE,MAAM,EAAa,IAOlB,YAAuB,EAAW,EAAY,CACnD,GAAM,GAAI,EAAG,KAAK,GAClB,GAAI,GAAK,MAAQ,EAAE,IAAM,KAAM,OAC/B,GAAM,GAAe,EAAE,GAAG,QAAQ,EAAE,IAAM,EAAE,MAC5C,MAAO,CACL,SAAU,EAAE,GACZ,WACE,EAAE,UAAU,EAAG,GAAgB,EAAE,UAAU,EAAe,EAAE,GAAG,QACjE,UAAW,EAAE,UAAU,EAAG,EAAE,OAAS,EAAE,UAAU,EAAE,MAAQ,EAAE,GAAG,QAChE,gBAIG,YAAqB,EAAW,EAAwB,CAC7D,GAAM,GAAM,EAAI,GACV,EAAM,EAAI,GAChB,MAAO,GAAI,OAAS,GAAK,EAAI,WAAW,GAAO,EAAI,MAAM,EAAI,QAAU,EAGlE,YAA+B,EAAW,EAAwB,CACvE,SAAI,EAAI,GACR,EAAS,EAAI,GACN,GAAqB,EAAG,GAAU,EAAE,MAAM,EAAO,QAAU,EAG7D,YAAqB,EAAW,EAAwB,CAC7D,GAAI,GAAU,KAAM,MAAO,GAC3B,GAAM,GAAM,EAAI,GACV,EAAM,EAAI,GAChB,MAAO,GAAI,OAAS,GAAK,EAAI,SAAS,GAAO,EAAI,MAAM,EAAG,CAAC,EAAI,QAAU,EAMpE,YAAsB,EAAW,EAAgB,EAAgB,CACtE,MAAI,IAAU,KAAa,GAAY,EAAG,GAC1C,GAAI,EAAI,GACD,EAAE,SAAS,IAAW,EAAE,WAAW,GACtC,EAAE,MAAM,EAAO,OAAQ,CAAC,EAAO,QAC/B,GAGC,YAAc,EAAW,EAAS,GAAI,EAAU,GAAY,CACjE,GAAM,GAAI,EAAI,GACR,EAAe,EAAE,OAAU,GAAS,GAC1C,MAAO,IAAgB,EACnB,EACA,EAAE,MAAM,EAAG,GAAQ,OACjB,YACA,EACA,gBACA,EAAE,MAAM,CAAC,GAAS,OAGnB,YAAoB,EAA0B,CACnD,EAAI,EAAI,GACR,GAAM,GAAM,EAAE,YAAY,MAAM,IAChC,MAAO,GAAM,GAAK,EAAI,EAAI,GAAG,oBAAsB,EAAI,MAAM,GAAG,KAAK,IAGhE,YAA2B,EAAW,EAAW,CACtD,MAAO,GAAE,cAAc,EAAG,OAAW,CAAE,YAAa,SAG/C,YACL,EACA,EACS,CACT,GAAI,GAAK,MAAQ,GAAK,KAAM,MAAO,GACnC,GAAM,GAAK,EAAI,GACT,EAAK,EAAI,GACf,MAAI,GAAG,SAAW,EAAG,OAAe,GAChC,IAAO,GAEP,EAAG,gBAAkB,EAAG,cAAsB,GAEhD,EAAG,cAAc,EAAI,OAAW,CAC9B,YAAa,WACR,GAEP,AAAM,GAAkB,EAAG,YAAa,EAAG,eAA3C,EAQG,YAAwB,EAAyB,CACtD,MAAO,GAAI,KAAK,IAGX,YACL,EACA,EACK,CACL,MAAO,GAAI,GACR,OAAO,GAAM,GAAM,MACnB,IAAI,CAAC,EAAM,IAAS,EACnB,OACA,IAAK,EAAI,EAAE,EAAM,GAAM,GAAM,CAAC,EAAI,OAEnC,OAAO,GAAM,EAAG,KAAO,MACvB,KAAK,CAAC,EAAG,IAAM,CACd,GAAM,GAAK,GAAkB,EAAE,IAAI,GAAI,EAAE,IAAI,IAC7C,MAAO,KAAO,EAAI,EAAK,GAAI,EAAE,IAAI,GAAI,EAAE,IAAI,MAE5C,IAAI,GAAM,EAAG,MAMX,YACL,EACA,EACS,CACT,MAAO,IAAY,MACjB,GAAU,MACV,EAAO,SAAW,GAClB,EAAS,SAAW,EAClB,GACA,GAAiB,EAAS,UAAU,EAAG,EAAO,QAAS,GA2CtD,YAA0B,EAAoB,EAAyB,CAC5E,MAAO,GAAQ,IAAa,EAAM,GAC9B,GACA,EAAS,KAAK,GAAM,GAAiB,EAAQ,IAwB5C,YAAsB,EAAmB,CAE9C,MAAO,GAAI,GAAG,QAAQ,yBAA0B,IAGlD,GAAM,IAAiC,CACrC,CAAC,QAAS,KACV,CAAC,aAAc,MAGV,YAAmB,EAAmB,CAC3C,MAAO,IAAW,OAChB,CAAC,EAAK,CAAC,EAAO,KAAU,EAAI,QAAQ,EAAO,GAC3C,GACA,YAGJ,GAAM,IAAS,eAER,YAAqB,EAAmB,CAC7C,MAAI,GAAM,IAEV,GAAI,EAAI,GAAG,OACP,GAAO,KAAK,GAAU,KAAO,MAC/B,GAAI,EAAE,MAAM,EAAG,IAAI,SAEd,EAGF,YAAiB,EAAmB,CACzC,MAAO,GACJ,MAAM,oBACN,IAAI,GAAM,GAAG,OAAO,EAAG,cACvB,KAAK,SAqDH,YAAyB,EAAmB,CAEjD,MAAO,GAAI,GACR,UAAU,OACV,QAAQ,mBAAoB,IAG1B,YAAoB,EAAmB,CAE5C,MAAO,GAAI,GAAG,QACZ,qEACA,IAIG,YAAoB,EAAyB,CAClD,GAAM,GAAM,GAAe,EAAc,IACnC,EAAS,EAAI,OACjB,CAAC,EAAI,IAAQ,CAAC,GAAqB,EAAI,EAAM,GAAI,IAEnD,MAAO,IAAO,EAAQ,GAAM,EAAI,QAAQ,IC/YnC,eAAqB,EAA+B,CACzD,MAAO,GAAQ,KAAK,GAOf,eAAyB,EAA+B,CAC7D,OAAW,KAAM,IAAQ,GAAU,CACjC,GAAM,GAAI,GAAQ,GAClB,GAAI,GAAK,MAAQ,IAAM,EAAG,MAAO,IAK9B,YAAoB,EAAQ,EAA+B,CAChE,MAAO,IAAO,EAAG,GAAM,GAAK,EAAI,EAAE,GAAK,QAWlC,YAAqB,EAAQ,EAA+B,CACjE,MAAO,IAAW,EAAG,GAAM,GAAK,EAAI,EAAE,GAAK,QAGtC,YAAmB,EAAQ,EAA+B,CAC/D,MAAO,IAAO,EAAG,GAAM,EAAI,EAAI,EAAE,GAAK,QAOjC,YACL,EACA,EACA,EACG,CACH,MAAO,GAAO,GAAO,EAAG,GAAI,GAOvB,YAAgB,EAAa,EAAa,EAAqB,CACpE,MAAI,IAAK,MAAQ,CAAC,GAAS,GAAW,GACrC,EAAC,EAAK,GAAO,CAAC,KAAK,IAAI,EAAK,GAAM,KAAK,IAAI,EAAK,IAC1C,GAAI,EAAG,IAAQ,GAAI,EAAG,IAW/B,GAAM,IAAa,kBASZ,YAAsB,EAA2B,CACtD,GAAI,GAAS,GAAQ,MAAO,GAC5B,GAAI,EAAM,GAAQ,OAClB,GAAM,GAAI,OAAO,GACjB,MAAO,GAAI,GAAW,KAAK,GAAI,GAAK,GAAQ,EAAE,OAAO,EAAE,SASlD,YAAoB,EAA2B,CACpD,MAAO,GAAM,GAAa,IHlFrB,YAAc,CAwCnB,YAAqB,EAAqB,GAAI,CAAzB,kBACnB,KAAK,GAAK,EACV,KAAK,SAAW,GAAI,IAAY,SAzC3B,OAAM,EAAY,EAAqB,CAC5C,GAAI,EAAE,IAAM,GAAK,EAAE,IAAM,EACvB,MAAO,IAAI,IAAQ,KAAK,IAAI,EAAE,WAAY,EAAE,aACvC,GAAI,EAAE,IAAM,EACjB,MAAO,GAAE,QACJ,GAAI,EAAE,IAAM,EACjB,MAAO,GAAE,QACJ,GAAI,EAAE,GAAK,EAAE,WAAY,CAC9B,GAAM,GAAI,EAAE,QACZ,SAAE,QAAQ,EAAE,SACL,UACE,EAAE,GAAK,EAAE,WAAY,CAC9B,GAAM,GAAI,EAAE,QACZ,SAAE,QAAQ,EAAE,SACL,MACF,CACL,GAAM,GAAI,GAAI,IAAQ,KAAK,IAAI,EAAE,WAAY,EAAE,aAC/C,EAAE,GAAK,EAAE,EAAI,EAAE,EACf,EAAE,KAAQ,EAAE,KAAQ,EAAE,EAAK,EAAE,EAAK,EAAE,KAAQ,EAAE,EAAK,EAAE,EACrD,EAAE,KAAO,KAAK,IAAI,EAAE,KAAO,EAAE,MAC7B,EAAE,KAAO,KAAK,IAAI,EAAE,KAAO,EAAE,MAC7B,EAAE,GAAM,EAAE,GAAM,EAAE,EAAK,EAAE,EAAK,EAAE,GAAM,EAAE,EAAK,EAAE,EAC/C,EAAE,GAAM,EAAE,GAAM,EAAE,EAAK,EAAE,EAAK,EAAE,GAAM,EAAE,EAAK,EAAE,EAC/C,GAAM,GAAU,GAAQ,GAAI,EAAE,QAAS,EAAE,UACzC,SAAE,SAAS,KAAK,GAAG,GACnB,EAAE,kBAAoB,GAAY,CAAC,EAAE,KAAM,GAAG,IACvC,IAkBV,WAAQ,SAAU,CACjB,MAAO,MAAK,QAGd,KAAK,EAAmB,CACtB,GAAI,CAAC,SAAS,GAAI,KAAM,IAAI,OAAM,gBAAkB,EAAI,mBAQxD,GAPA,KAAK,KACL,KAAK,SAAS,KAAK,GACnB,KAAK,KAAO,KAAK,MAAQ,KAAO,EAAI,KAAK,IAAI,EAAG,KAAK,MACrD,KAAK,KAAO,KAAK,MAAQ,KAAO,EAAI,KAAK,IAAI,EAAG,KAAK,MAKnD,KAAK,KAAO,GACZ,KAAK,IAAM,MACX,KAAK,IAAM,MACX,KAAK,MAAQ,MACb,KAAK,mBAAqB,KAE1B,KAAK,GAAK,EACV,KAAK,GAAK,EACV,KAAK,KAAO,EACZ,KAAK,kBAAoB,MACpB,CACL,GAAM,GAAS,KAAK,GACpB,KAAK,IAAO,GAAI,KAAK,IAAM,KAAK,GAChC,KAAK,IAAO,GAAI,GAAW,GAAI,KAAK,IACpC,KAAK,KAAQ,KAAK,KAAQ,MAAK,GAAK,GAAM,KAAK,GAAK,EAAI,KAAK,GAC7D,KAAK,kBAAqB,MAAK,kBAAoB,GAAK,EAE1D,MAAO,GAGT,OAAiB,CACf,MAAO,IAAI,GAAI,IAAQ,KAAK,YAAa,GAAM,CAC7C,EAAG,GAAK,KAAK,GACb,EAAG,KAAO,KAAK,KACf,EAAG,KAAO,KAAK,KACf,EAAG,KAAO,KAAK,KACf,EAAG,GAAK,KAAK,GACb,EAAG,GAAK,KAAK,GACb,EAAG,kBAAoB,KAAK,kBAC5B,EAAG,SAAS,KAAK,GAAG,KAAK,YAI7B,QAAQ,EAAqB,CAC3B,SAAI,QAAQ,GAAM,KAAK,KAAK,IACrB,KAGT,MAAM,EAAU,EAAiB,CAC/B,GAAM,GAAK,AAAC,GAAe,EAAI,EAAG,AAAC,GAAe,GAAQ,EAAI,IACxD,EAAkB,GACxB,MAAK,MAAK,OACR,GAAE,IAAM,EAAG,KAAK,KAChB,EAAE,KAAO,EAAG,KAAK,KAEjB,EAAE,GAAK,EAAG,KAAK,SAIjB,EAAE,EAAI,GAAQ,KAAK,EAAG,GACf,KAGL,QAAiB,CACnB,MAAO,MAAK,KAAO,KAMjB,IAAY,CACd,MAAO,MAAK,MAGV,MAAqB,CACvB,MAAO,MAAK,MAAQ,OAAY,GAAQ,KAAK,KAAO,MAGlD,MAAc,CAChB,MAAO,MAAK,MAAQ,MAAQ,KAAK,MAAQ,EAAI,KAAK,KAAQ,KAAK,MAG7D,MAAqB,CACvB,MAAO,MAAK,QAGV,MAAqB,CACvB,MAAO,MAAK,QAMV,MAAqB,CACvB,MAAO,IAAO,KAAK,IAAK,GAAM,GAAO,KAAK,OAAQ,GAAM,EAAK,OAG3D,WAA0B,CAC5B,MAAO,MAAK,IAAM,EAAI,OAAY,KAAK,GAAO,MAAK,GAAK,MAGtD,SAAwB,CAC1B,MAAO,GAAI,KAAK,SAAU,KAAK,SAG7B,aAA4B,CAC9B,MAAO,GAAI,KAAK,YAAY,GAAI,GAAM,EAAG,IAG3C,YAAY,EAA4B,CACtC,GAAI,KAAK,MAAO,OAChB,GAAM,GAAI,GAAI,IACd,YAAK,SAAS,QAAQ,GAAM,EAAE,KAAK,IAC5B,EAAE,QAAQ,MAGf,eAA8B,CAChC,MAAO,IAAY,KAAK,SAAU,OAGhC,YAA2B,CAC7B,MAAO,IAAY,KAAK,SAAU,OAGhC,cAAsB,CACxB,MAAO,GAAO,GAAY,KAAK,SAAU,IAAQ,MAG/C,UAAoB,CACtB,MAAO,CAAC,GAAG,KAAK,UAGlB,EAAE,EAA4B,CAC5B,GAAI,KAAK,SAAS,SAAW,EAAG,MAAO,GACvC,GAAM,GAAM,CAAC,GAAG,KAAK,UAAU,KAAK,CAAC,EAAG,IAAM,EAAI,GAC5C,EAAM,KAAK,MAAM,EAAI,OAAU,GAAa,MAClD,MAAO,GAAI,MAMT,oBAAmC,CACrC,MAAO,IAAY,KAAK,SAAU,GAAO,GAAQ,GAAY,GAAM,OAMjE,mBAAkC,CACpC,MAAO,MAAK,kBAGd,OAAc,CACZ,KAAK,KAAO,EACZ,KAAK,GAAK,EACV,KAAK,kBAAoB,EACzB,KAAK,SAAS,OAAS,IIlOpB,YAA6C,CAA7C,aANP,CAOmB,OAAI,GAAI,KAEzB,KAAK,EAAQ,EAAgB,EAAS,CACpC,GAAM,GAAI,KAAK,IAAI,GAAO,EAC1B,MAAI,KAAM,EAAG,KAAK,EAAE,OAAO,GACtB,KAAK,EAAE,IAAI,EAAK,GACd,KAGT,IAAI,EAAgB,CAClB,MAAO,GAAO,KAAK,EAAE,IAAI,GAAM,IAAM,GAGvC,IAAI,EAAiB,CACnB,MAAO,MAAK,EAAE,IAAI,MAMhB,OAAe,CACjB,MAAO,MAAK,EAAE,KAGhB,MAA4B,CAC1B,MAAO,MAAK,EAAE,OAGhB,QAAS,CACP,GAAM,GAAM,GAAI,IAAQ,GACxB,OAAW,KAAK,MAAK,OACnB,GAAI,GAAS,GACX,EAAI,KAAK,OAET,QAGJ,MAAO,GAAI,IAGb,SAAyC,CACvC,MAAO,MAAK,EAAE,UAIhB,oBAAoC,CAClC,GAAM,GAAS,KAAK,SACpB,MAAO,IAAO,CAAC,GAAG,KAAK,WAAY,CAAC,CAAC,EAAG,KAAO,CAC7C,CAAC,EACD,GAAa,EAAQ,GAAM,KAAK,IAAK,EAAe,GAAK,KAI7D,IAAI,EAAI,EAAkB,CACxB,MAAO,MAAK,qBAAqB,MAAM,EAAG,GAG5C,QAAQ,EAAI,EAAQ,CAClB,MAAO,MAAK,IAAI,GAAG,IAAI,GAAM,EAAG,OAG9B,gBAAyB,CAC3B,MAAO,IAAI,GAAI,IAAQ,KAAK,MAAO,GACjC,CAAC,GAAG,KAAK,EAAE,UAAU,QAAQ,GAAM,EAAE,KAAK,KAI9C,QAAQ,EAAmD,CACzD,KAAK,EAAE,QAAQ,GAGjB,OAAc,CACZ,KAAK,EAAE,WAGL,MAAM,CACR,MAAO,IAAK,CAAC,GAAG,KAAK,SAClB,IAAI,GAAO,EAAM,IAAM,KAAK,IAAI,IAChC,KAAK;KCjFL,YAAkB,EAA+B,CACtD,MAAO,aAAa,KAAM,EAAI,GAAI,KAAI,EAAI,IA0BrC,YACL,EACA,EACQ,CACR,MAAO,IAAI,KAAI,CAAC,GAAG,EAAG,GAAG,IAMpB,YACL,EACA,EACQ,CACR,GAAM,GAAI,GAAM,GAChB,MAAO,IAAI,KAAI,CAAC,GAAG,GAAG,OAAO,GAAM,EAAE,IAAI,KAMpC,YACL,EACA,EACQ,CACR,GAAM,GAAI,GAAM,GAChB,MAAO,IAAI,KAAI,CAAC,GAAG,GAAG,OAAO,GAAM,CAAC,EAAE,IAAI,KCtCrC,YAAgB,EAAqB,CAC1C,GAAI,GACJ,OAAW,KAAM,GACf,AAAI,GAAM,MACJ,IAAU,MAAQ,EAAK,IACzB,GAAS,GAIf,MAAO,GAGF,YAAgB,EAAqB,CAC1C,GAAI,GACJ,OAAW,KAAM,GACf,AAAI,GAAM,MACJ,IAAU,MAAQ,EAAK,IACzB,GAAS,GAIf,MAAO,GAYF,YAAe,EAAiB,EAAwB,CAC7D,GAAM,GAAK,GAAI,IACf,SAAI,GAAK,QAAQ,GAAK,GAAU,EAAG,GAAM,EAAG,KAAK,KAC1C,EAAG,QAAQ,GAGb,YAAc,EAA8B,CACjD,MAAO,IAAM,EAAK,GAAG,GAGhB,YAAa,EAAyB,CAC3C,MAAO,GAAI,GAAK,OAAO,CAAC,EAAK,IAAQ,GAAS,GAAM,EAAM,EAAK,EAAM,GAGhE,YAAa,EAA6C,CAC/D,GAAM,GAAI,EAAQ,EAAI,IACtB,MAAO,GAAQ,GACX,OACA,EAAE,OACA,CAAC,EAAM,EAAI,IAET,IAAQ,EAAI,EAAM,EAAO,EAAQ,GAAM,GAAK,EAAM,GAAM,GAC1D,GA4BD,YAAe,EAAgC,CACpD,GAAM,GAAI,EAAI,GACd,MAAO,GAAI,GAAI,GAAI,GAAU,CAC3B,GAAM,GAAU,GAAE,OAAS,GAAK,EAC1B,EAAM,GAAI,EAAE,IAAI,CAAC,EAAG,IAAO,GAAI,GAAW,GAAI,KAC9C,EAAQ,GAAI,EAAE,IAAI,GAAM,GAAI,IAAW,IAC7C,MAAO,KAAU,EAAI,EAAI,EAAM,IAS5B,YAAkB,EAAkC,CACzD,MAAO,GAAI,GAAI,GAAM,GAAQ,GAAI,EAAI,IAAI,GAAK,KAAK,IAAI,EAAI,EAAM,MAG5D,YAAgB,EAAkC,CACvD,MAAO,GAAI,GAAS,GAAM,GAAM,KAAK,KAAK,IAGrC,YAAqB,EAA8C,CACxE,GAAI,GACJ,OAAW,KAAM,GACf,EAAM,GAAO,KAAO,EAAM,GAAM,GAAM,EAExC,MAAO,IAAc,ICrHhB,YAAqB,CAG1B,YAAY,EAAQ,GAAI,KAAe,CACrC,KAAK,MAAQ,EAGf,IAAI,EAAyB,CAC3B,MAAO,MAAK,MAAM,IAAI,GAGxB,IAAI,EAAiB,CACnB,MAAO,MAAK,MAAM,IAAI,MAMpB,WAAmB,CACrB,MAAO,MAAK,MAAM,QAMhB,aAAqB,CACvB,MAAO,IAAI,CAAC,GAAG,KAAK,MAAM,UAAU,IAAI,GAAM,EAAG,SAGnD,IAAI,KAAW,EAAkB,CAC/B,GAAM,GAAQ,GAAS,KAAK,MAAO,EAAK,IAAM,IAC9C,SAAM,KAAK,GAAG,GACP,EAGT,IAAI,EAAQ,EAAa,CACvB,KAAK,MAAM,IAAI,EAAK,GAGtB,OAAO,EAAQ,EAAoB,CACjC,GAAI,GAAS,KACX,MAAO,MAAK,MAAM,OAAO,GACpB,CACL,GAAM,GAAM,KAAK,MAAM,IAAI,GAC3B,GAAI,GAAO,KACT,MAAO,GACF,CACL,GAAM,GAAS,GAAO,EAAK,GAC3B,MAAI,IAAU,EAAI,SAAW,GAC3B,KAAK,MAAM,OAAO,GAEb,IAKb,OAAc,CACZ,YAAK,MAAM,QACJ,KAGT,MAA4B,CAE1B,GAAM,GAAO,KACb,YAAsC,CACpC,OAAW,CAAC,EAAG,IAAM,GAAK,MAAM,UAC9B,AAAI,EAAE,OAAS,GACb,MAAM,IAIZ,MAAO,KAGT,QAAgC,CAE9B,GAAM,GAAO,KACb,YAAwC,CACtC,OAAW,CAAC,CAAE,IAAM,GAAK,MAAM,UAC7B,AAAI,EAAE,OAAS,GACb,MAAM,IAIZ,MAAO,KAGT,YAAkC,CAEhC,GAAM,GAAO,KACb,YAAsC,CACpC,OAAW,CAAC,CAAE,IAAQ,GAAK,MAAM,UAC/B,GAAI,EAAI,OAAS,EACf,OAAW,KAAM,GACf,KAAM,GAKd,MAAO,KAGT,cAA2B,CACzB,MAAO,CAAC,GAAG,KAAK,MAAM,WAAW,OAAO,CAAC,CAAC,CAAE,KAAO,EAAW,IAGhE,SAAsC,CAEpC,GAAM,GAAO,KACb,YAA6C,CAC3C,OAAW,CAAC,EAAG,IAAM,GAAK,MAAM,UAC9B,AAAI,EAAE,OAAS,GACb,MAAM,CAAC,EAAG,IAIhB,MAAO,KAGT,QAAmC,CAEjC,GAAM,GAAO,KACb,YAA2C,CACzC,OAAW,CAAC,EAAG,IAAM,GAAK,MAAM,UAC9B,OAAW,KAAM,GAAI,GACnB,AAAI,GAAM,MAAM,MAAM,CAAC,EAAG,IAIhC,MAAO,KAGT,cAAc,EAAmD,CAC/D,GAAI,GAAU,GACd,OAAW,CAAC,EAAG,IAAQ,MAAK,MAAM,UAAW,CAC3C,GAAM,GAAM,EAAI,OAChB,GAAc,EAAK,GAAK,EAAU,EAAG,IACrC,EAAU,GAAW,IAAQ,EAAI,OAEnC,MAAO,KAQJ,YACL,EACA,EACgB,CAChB,GAAM,GAAI,GAAI,IACd,SAAI,QAAQ,GAAM,EAAI,EAAE,GAAK,GAAK,EAAE,IAAI,EAAG,KACpC,EC7IF,eAA0B,EAAqC,CACpE,OAAW,KAAK,GAAQ,CACtB,GAAM,GAAI,IACV,GAAI,GAAK,KACP,MAAO,IAMN,YACL,EACA,EACU,CACV,OAAW,KAAK,GAAQ,CACtB,GAAM,GAAI,IACV,GAAI,GAAK,MAAS,IAAa,MAAQ,EAAU,IAC/C,MAAO,IAmDN,YACL,EACA,EACU,CACV,GAAI,CACF,MAAO,WACA,EAAP,CACA,MAAO,IAAW,KAAO,EAAQ,GAAO,QAQrC,YAAqB,EAAM,CAChC,MAAO,GA0CF,YAAyB,EAAS,EAA6B,CACpE,GAAI,GAAO,KACT,MAAO,GAET,OAAW,CAAC,EAAG,IAAM,IAAQ,GAC3B,AAAI,GAAK,MAAO,GAAa,GAAK,GAEpC,MAAO,GAeF,YACL,EACA,EACoB,CACpB,GAAM,GAAI,GACV,OAAW,KAAK,IAAK,GAAM,CAEzB,GAAM,GAAI,EAAE,EAAG,EAAI,IACnB,AAAI,GAAK,MAAM,GAAE,GAAK,GAExB,MAAO,GAMF,YAAsB,EAAwB,EAAe,CAClE,MAAO,IAAK,KAAO,GAAQ,GAAK,GAAG,MAAM,GAAM,GAAI,EAAE,GAAK,EAAE,KCtL9D,kBAAmC,EAAiC,CAClE,GAAM,GAAI,KAAM,GAChB,MAAO,IAAW,GAAK,IAAM,ECPxB,YAAoB,EAAgB,CACzC,MAAO,IAAO,EAAQ,IAGjB,YAAe,EAAgB,CACpC,MAAO,IAAO,EAAQ,IAmBxB,YAAgB,EAAgB,EAA+B,CAE7D,MAAO,IAAI,SAAc,GAAW,CAClC,GAAI,GAAU,EACZ,QACK,CAKL,GAAM,GAAS,WAAW,IAAM,IAAW,KAAK,KAAK,EAAS,KAE9D,AAAI,GAAS,EAAE,OAAS,MAAQ,GAAW,EAAE,QAAQ,EAAE,WAKtD,WAAe,EAAc,EAAkB,EAAG,CACvD,MAAO,YAAW,EAAG,KAAK,IAAI,EAAG,KAAK,KAAK,KCzC7C,kBACE,EACA,EACA,EAAuB,IAAG,GAC1B,EAA0C,IAAG,GAC5B,CACjB,GAAI,GAAY,GACZ,EAAW,GACX,EACJ,YAAM,SAAQ,KAAK,CACjB,GAAU,GAAG,KAAK,GAAM,CACtB,GAAK,GACH,SAAS,EACT,EAAY,GACL,IAMX,GAAW,GAAW,KAAK,IAAM,CAC/B,AAAK,GACH,GAAW,QAIjB,AAAI,EACF,KAAM,GAAU,GAEhB,KAAM,KAED,ECnCT,OAAwC,qBAGjC,YACL,EACA,KACG,EACa,CAChB,MAAO,IAAI,kBAAW,EAAU,KAAK,MAAM,GAAK,GAAG,GAAO,GAAK,EAAE,SAG5D,YACL,EACA,KACG,EACa,CAChB,MAAO,IAAI,mBAAY,EAAU,KAAK,MAAM,GAAK,GAAG,GAAO,GAAK,EAAE,SCCpE,GAAM,IAAS,EAAK,IAAM,EAAS,GAAQ,aASrC,GAAiB,GAAI,IAE3B,GAAiB,IAAM,KAAkB,EAAI,GAE7C,GAAM,IAAmB,EAAI,EAEhB,EAAe,GAC1B,QACA,UACA,QACA,KACA,SACA,UAOK,YAA4C,EAAe,CAChE,MAAO,IAAW,EAAa,MAAO,GAqBjC,YAAyC,EAAe,CAE7D,MAAO,IAAW,EAAa,GAAI,GAe9B,YAA6C,EAAe,CACjE,MAAO,IAAW,EAAa,OAAQ,GAMlC,YACL,EACA,EACG,CACH,SAAa,YAAY,EAAM,IAAM,CACnC,KAAM,IAAI,OAAM,gCAAkC,KAEpD,GAAe,IAAI,EAAM,GAClB,EAGT,GAAI,IAAU,GAEP,YAA2B,CAChC,MAAO,IAWF,eAAmB,EAAuB,CAC/C,MAAO,SAAQ,IAAI,EAAI,IAAI,GAAM,GAAI,KAGvC,kBAA0B,EAA8B,EAAuB,CAC7E,GAAM,GAAU,KAAM,GACtB,GAAI,GAAW,MAAQ,EAAQ,MAAO,OACtC,GAAM,GACJ,IAAU,GAAU,qBAChB,IACA,GAAS,EAAc,EAAQ,aAAc,IACnD,YAAS,MAAM,EAAQ,KAAO,aAAc,CAAE,cACvC,GACL,EAAQ,MACR,EACA,IAAM,KAAS,KAAK,EAAQ,KAAO,oBACnC,IAAM,KAAS,MAAM,EAAQ,KAAO,qBACpC,MAAM,GAAO,CAEb,GAAI,IAAM,KAAS,KAAK,EAAQ,KAAO,oBAAsB,MAIjE,aAA0B,CACxB,GAAe,cAAc,CAAC,EAAG,IAAM,CAAC,EAAE,OAC1C,KAAS,MACP,mBACA,GAAe,eAAe,IAAI,CAAC,CAAC,EAAG,KAAO,CAAC,EAAG,EAAE,IAAI,GAAM,EAAG,SAI9D,GAAM,IAAc,EAAK,SAAY,CAC1C,GAAM,GAAe,KAAsB,IAAM,OAEjD,KAAS,KAAK,gBAAiB,CAAE,UAAQ,uBACpC,IAAQ,IAAU,IACvB,KACA,OAAW,KAAQ,GAAa,OAAQ,CACtC,GAAM,GAAM,EAAO,GAAe,IAAI,GAAO,IAC7C,AAAI,EAAW,IACb,MAAS,MAAM,yBAA2B,GAC1C,KAAM,SAAQ,IAAI,EAAI,IAAI,GAAM,GAAI,EAAI,SC7J9C,OAAqB,iBACrB,GAAgC,mBCCzB,GAAM,IAAW,GACtB,QACA,QACA,QACA,MACA,MACA,KACA,OACA,OACA,SAGW,GAAgB,GAAS,OAEzB,GAAU,GAAQ,OAAQ,OAAQ,OAAQ,OAG1C,GAAW,CAAC,GAAI,IAAK,IAAK,KCVvC,GAAM,IAAe,EAAK,IAAM,GAAI,MAAK,cAE5B,GAAe,EAAK,IAC/B,GAAW,KAAe,OAAO,MAAO,IAAK,IAAI,OAAO,IAG7C,GAAa,EAAK,IAC7B,GAAW,KAAe,OAAO,KAAM,IAAK,IAAI,OAAO,IAGlD,YAAa,EAAmB,CAErC,MAAO,MAAe,OAAO,GAYxB,GAAM,IAAK,IACL,GAAK,GAAK,IACV,GAAK,GAAK,IACV,GAAK,GAAK,IAEV,GAAM,KACN,GAAM,GAAM,KACZ,GAAM,GAAM,KACZ,GAAM,GAAM,KAEnB,GAAY,CAAC,IAAK,KAAM,KAAM,KAAM,KAAM,MAGzC,YAAkB,EAAe,EAAU,EAAW,CAC3D,GAAI,IAAU,EAAG,MAAO,IACxB,GAAI,CAAC,GAAS,GAAQ,MAAO,IAC7B,GAAM,GAAI,KAAK,MAAM,KAAK,MAAM,IAC1B,EAAM,KAAK,MAAM,EAAI,GACrB,EAAM,KAAK,IAAI,GAAI,EAAM,GACzB,EAAO,GAAU,GACvB,MAAO,IAAQ,EAAQ,EAAK,GAAW,IAAM,EAWxC,GAAM,IAAK,IAEX,YAAoB,EAAwB,CACjD,MAAO,IAAQ,EAAS,GAAI,GAGvB,GAAM,IAAmB,GAC9B,OACA,QACA,SACA,QACA,YAIK,YAAqB,EAAiC,CAC3D,MAAO,GAAS,IAAM,IAClB,OACA,EAAS,IAAM,IACf,QACA,EAAS,KAAO,KAChB,SACA,QAGC,YACL,EACA,EACA,EAAiB,EAAW,IAC5B,CACA,MAAO,IAAI,GAAK,IAAO,KAAM,EAAI,EAAW,GC9F9C,OAAe,iBACf,GAAgB,uBAChB,GAAe,mBACf,GAA2B,mBCI3B,iBACE,EACA,EACkB,CAClB,GAAM,GAAM,KAAM,GAClB,MAAO,IAAO,KAAO,OAAY,EAAE,GAOrC,kBACE,EACA,EACe,CACf,GAAM,GAAe,GACrB,OAAW,KAAO,GAAI,KAAM,IAC1B,GAAI,GAAO,KAAM,CACf,GAAM,GAAK,KAAM,GACjB,GAAI,GAAM,KAAM,CACd,GAAM,GAAI,KAAM,GAAE,GAClB,AAAI,GAAK,MAAM,EAAO,KAAK,IAIjC,MAAO,GAGT,kBACE,EACA,EAAmB,QAAQ,IAAI,KAAK,SACxB,CACZ,GAAM,GAAS,KAAM,GAErB,YAAM,GAAE,GACD,ECpCF,YAAyC,CAO9C,YAAqB,EAAU,CAAV,UAJb,YAAuB,UAK7B,KAAK,QAAU,GAAI,SAAc,CAAC,EAAS,IAAW,CACpD,KAAK,SAAW,EAChB,KAAK,QAAU,IAInB,SAAiB,CACf,MAAI,MAAK,SACP,MAAK,WACL,KAAK,OAAS,YAET,KAGT,OAAO,EAAoB,CACzB,MAAI,MAAK,SACP,MAAK,QAAQ,GACb,KAAK,OAAS,YAET,KAGT,QAAQ,EAAoB,CAC1B,YAAK,QAAQ,QAAQ,GACd,KAGT,QAAQ,EAAuB,CAC7B,SAAE,KACA,IAAM,KAAK,UACX,GAAO,KAAK,OAAO,IAEd,KAGT,eAAe,EAAuB,CACpC,SAAE,KACA,IAAM,KAAK,UACX,IAAM,KAAK,WAEN,QAGL,UAAmB,CACrB,MAAO,MAAK,SAAW,aAGrB,UAAU,CACZ,MAAO,CAAC,KAAK,WAGX,WAAW,CACb,MAAO,MAAK,SAAW,cAGrB,WAAW,CACb,MAAO,MAAK,SAAW,cAGrB,QAAsB,CACxB,MAAO,MAAK,OAGd,KACE,EACA,EACkB,CAClB,MAAO,MAAK,QAAQ,KAAK,EAAa,KClF1C,OAAwC,iBCAxC,OAA6B,qBCA7B,OAA6B,qBAItB,gBAA+B,gBAAa,CAA5C,aAJP,CAIO,oBACI,YAAkB,GAC3B,KAAK,KAA0B,EAAsB,CACnD,aAAM,KAAK,EAAM,GAAG,GACpB,KAAK,OAAO,KAAK,CAAE,OAAM,SAClB,GAET,OAAQ,CACN,KAAK,OAAO,OAAS,IDJzB,GAAM,IAAoB,EAAK,IAAM,GAAI,KACnC,GAAoB,EAAK,IAAM,CACnC,GAAM,GAAK,GAAI,iBACf,SAAG,gBAAgB,IACZ,IAGE,GAAmC,KASvC,aAA0B,CAC/B,EAAS,gBAAgB,KAAK,oBAC9B,GAAa,KAAK,cAGb,WAAsB,EAAkB,CAC7C,GAAa,GAAG,aAAc,GAGzB,aAAoB,CACzB,GAAa,KAAK,QAGb,YAAgB,EAAqB,CAC1C,GAAa,GAAG,OAAQ,GAGnB,YAAuB,EAAuB,CACnD,GAAa,KAAK,YAAa,GAO1B,aAAqB,CAC1B,GAAa,KAAK,SAGb,YAAiB,EAAqB,CAC3C,GAAa,GAAG,QAAS,GAGpB,aAAsB,CAC3B,GAAa,KAAK,UAGb,YAAkB,EAAqB,CAC5C,GAAa,GAAG,SAAU,GAGrB,YAAyB,EAAqB,CACnD,GAAa,KAAK,cAAe,GAG5B,YACL,EACA,CACA,GAAa,GAAG,aAAc,GAGzB,YACL,EACA,EACA,CACA,GAAa,KAAK,aAAc,EAAe,GAG1C,YAAuB,EAAwC,CACpE,GAAa,GAAG,cAAe,GAa1B,YAAiB,EAAmD,CACzE,GAAa,GAAG,QAAS,CAAC,CAAE,UAAS,WAAY,EAAS,EAAS,IAG9D,YAAoB,EAAmD,CAC5E,GAAa,GAAG,WAAY,CAAC,CAAE,UAAS,WAAY,EAAS,EAAS,IAOjE,YAA2B,EAAqB,CACrD,GAAa,GAAG,kBAAmB,GAc9B,aAA8B,CACnC,GAAa,KAAK,kBAGb,YAA0B,EAAqB,CACpD,GAAa,GAAG,iBAAkB,GAG7B,aAA+B,CACpC,GAAa,KAAK,mBAGb,YAA2B,EAAqB,CACrD,GAAa,GAAG,kBAAmB,GAO9B,YAAqB,EAAyC,CACnE,GAAa,GAAG,YAAa,GAOxB,YAAiC,EAAqB,CAC3D,GAAa,GAAG,wBAAyB,GDhJ3C,AAAK,EAAM,IAAM,CACf,EAAa,IAAM,CACjB,GAAiB,QACjB,GAAU,QACV,GAAQ,QACR,GAAsB,QACtB,GAAgB,QAChB,GAAmB,QACnB,GAAuB,YAKpB,GAAM,IAAmB,EAAK,IAAO,kBAAY,EAAI,mBAAc,GAE7D,GAAY,EAAK,IAAM,cAAO,QAE9B,GAAU,EAAK,IAAM,CAEhC,GAAM,GAAsB,EAAI,GAG1B,EAAW,KAAK,IACpB,EACA,KAAK,MAAM,KAAqB,IAE5B,EAAY,EAAS,eAAe,eAAiB,IAAO,KAClE,MAAO,IAAM,EAAG,EAAU,KAAK,MAAM,MAG1B,GAAwB,EAAK,IAAM,CAC9C,GAAM,GAA0B,IAAM,GAChC,EAAmB,KAAK,MAC5B,KAAqB,GAEjB,EAAa,KAAK,IACtB,EACA,KAAK,MACH,IAAM,KAAe,GAAS,eAAe,eAAiB,OAGlE,MAAO,IAAM,EAAG,EAAY,KAGjB,GAAkB,EAAK,IAG3B,GAAM,EAAG,GAAI,OAKT,GAAqB,EAAK,IAGrC,GAAM,EAAG,EAAG,KAAK,KAAK,KAA0B,QAKrC,GAAyB,GGpEtC,OAA6B,qBAC7B,GAAwB,mBCMjB,YAAkB,EAAkB,CACzC,GAAI,GAAS,GAAM,MAAO,GAC1B,GAAM,GACJ,YAAe,OACX,EACE,GAAgB,CACd,EAAI,EAAI,MAAM,OACd,EAAa,EAAY,KAAM,GAAM,QAAQ,EAAG,UAChD,EAAI,EAAI,SAAS,UAEnB,KAAK,MACP,EAAI,GACV,MAAO,IAAU,EAAQ,KAGpB,YAAwB,EAAkB,CAC/C,MAAI,IAAO,KAAa,cACjB,CAAC,GAAS,GAAM,GAAG,EAAI,GAAW,EAAI,SAAS,KAAK;AAAA,GAGtD,YAAoB,EAAiC,CAC1D,MAAO,GAAM,GAAS,OAAY,EAAI,GAAO,MAAM;AAAA,GAAM,MAAM,EAAG,GAG7D,YAAiB,EAAqB,CAC3C,GAAI,EAAM,GACR,KAAM,IAAI,OAAM,mBACX,GAAI,YAAkB,OAC3B,MAAO,GACF,GAAI,MAAM,QAAQ,GAAS,CAChC,GAAM,GAAQ,EAAO,GACrB,MAAI,aAAiB,OACf,GAAO,OAAS,GAChB,GAAc,OAAS,EAAO,MAAM,IAEjC,GAEA,GAAI,OACT,EACG,IAAI,GAAM,EAAI,IACd,OAAO,GACP,KAAK,WAGP,CAKL,GAAM,GAAI,GAAS,GACb,EAAgB,EAAE,QAAQ,KAChC,GAAI,EAAgB,GAAK,EAAgB,GAAI,CAC3C,GAAM,GAAI,GAAI,OAAM,EAAE,MAAM,EAAgB,GAAG,QAC/C,SAAE,KAAO,EAAE,MAAM,EAAG,GAAe,OAC5B,MAEP,OAAO,IAAI,OAAM,IAKhB,YAAiB,EAAwB,CAC9C,MAAO,aAAe,OCnEjB,GAAM,IAAgB,GAAQ,UAAW,WAAY,YCIrD,GAAM,IAAiB,OACjB,GAAwB,OACxB,GAAqB,OACrB,GAAsB,SACtB,GAAuB,SACvB,GAAqB,SACrB,GAAqB,SAIrB,GAAa,CACxB,GACA,GACA,GACA,GACA,GACA,GACA,IAYK,YAAuB,KAAgB,EAA2B,CACvE,MAAO,GAAM,EAAM,OAAO,GAAM,GAAM,MAAQ,CAAC,EAAI,SAAS,IAAK,KAAK,IAExE,GAAM,IAAe,0BAEd,YAAyB,EAAqB,CACnD,MAAO,GAAI,QAAQ,GAAc,IAG5B,YAA2B,EAAqB,CACrD,MAAO,GACJ,MAAM,IACN,OAAO,GAAM,GAAW,SAAS,IACjC,KAAK,IAWH,YAA2B,EAAmB,CACnD,MAAO,IAAS,GAAK,SAAS,IAGhC,GAAM,IAAoB,CACxB,GACA,yBACA,yCACA,wBACA,wCACA,oBACA,wBACA,wBACA,aACA,qCACA,QACA,WACA,uBACA,uCACA,2CACA,kCACA,YACA,4BACA,gDACA,kCACA,WACA,IAAI,GAAM,EAAG,eAKR,YAA0B,EAAmB,CAClD,GAAI,GAAO,KAAM,MAAO,GACxB,GAAM,GAAM,GAAS,GAAK,cACpB,EAAmB,GAAkB,KAAK,GAAM,EAAI,SAAS,IACnE,MACE,MACC,CAAC,GAAkB,IAAQ,CAAC,GAAa,IAAQ,EAiBtD,GAAM,IAAc,kCAEb,YAA2B,EAAmB,CACnD,MAAO,GAAI,OAAS,eAAiB,AAAQ,GAAS,GAAK,MAAM,KAA5B,KAGhC,YAAmC,EAAmB,CAC3D,MAAO,AAAQ,IAAS,GAAK,MAAM,0BAA5B,KAGF,YAAiC,EAAmB,CACzD,MAAO,AAAQ,IAAS,GAAK,MAAM,yCAA5B,KAGF,YAA0B,EAAmB,CAClD,MACE,CAAC,GAAa,IACd,CAAC,GAAS,GAAK,SAAS,KACxB,CAAC,GAAwB,IACzB,CAAC,GAAQ,EAAI,WAIV,YAA6B,EAAmB,CACrD,MAAO,CAAC,GAAiB,GAOpB,YAA0B,EAAmB,CAClD,GAAI,GAAkB,GAAM,MAAO,GACnC,GAAI,EAAO,GAAK,WAAY,MAAO,GAEnC,GAAM,GAAM,GAAS,GAAK,cAC1B,MAAO,IAAkB,KAAK,GAAM,EAAI,SAAS,KAAQ,GAAiB,GAG5E,GAAM,IAAoB,CACxB,GACA,oBACA,gCACA,YAMW,GAAe,GAAI,QAE9B,mEACE,GACF,KAMK,YAAsB,EAAmB,CAC9C,MAAI,IAAO,KAAa,GACpB,EAAO,EAAI,OAAe,GACvB,GAAa,KAAK,GAAS,KAAS,KH/JtC,YAA4C,CAgBjD,YAAqB,EAAqB,CAArB,YAdZ,WAAQ,KAAK,MAEd,WAAsB,GAAc,QAa1C,KAAK,QAAU,GAAI,SAAW,CAAC,EAAS,IAAW,CACjD,KAAK,SAAW,EAChB,KAAK,QAAU,IAEjB,KAAK,OAAS,EAAS,YAAc,KAAK,WAAa,KAGzD,UAAW,CACT,MAAO,IAAS,KAAK,MAAQ,KAAK,KAAO,EAAU,KAAK,OAGzD,WAAQ,SAAU,CACjB,MAAO,CACL,KAAM,WACN,KAAM,KAAK,WACX,MAAO,KAAK,MACZ,IAAK,KAAK,IACV,MAAO,KAAK,OAIhB,eAAe,EAAmC,CAChD,SAAE,KAAK,GAAc,CACnB,KAAK,QAAQ,KACZ,MAAM,GAAO,CACd,KAAK,OAAO,KAAK,0BAA2B,GAC5C,KAAK,QAAQ,UAER,KAGT,QAAQ,EAAqB,CAC3B,SAAE,KAAK,GAAc,CACnB,KAAK,aAAa,KACjB,MAAM,GAAO,CACd,KAAK,YAAY,KAEZ,KAOT,WAAW,EAAyB,CAClC,SAAI,KAAK,aAAc,iBAEvB,KAAK,aAAe,GAAgB,IAAM,CACxC,GAAI,KAAK,QAAS,CAChB,GAAM,GACJ,YAAc,KAAK,KAAO,UAAa,MAAK,MAAQ,KAAK,OAAS,KACpE,KAAK,OAAO,KAEb,GACI,QAGL,WAAmB,CACrB,MAAO,MAAK,QAAU,UAAY,KAAK,SAAW,WAAa,cAG7D,UAAU,CACZ,MAAO,MAAK,QAAU,GAAc,WAOlC,QAAkB,CACpB,MAAO,MAAK,SAAW,KAAK,OAAS,UAGnC,QAAsB,CACxB,MAAO,MAAK,UAMV,UAAU,CACZ,MAAO,MAAK,QAAU,GAAc,WAGlC,WAAW,CACb,MAAO,MAAK,QAAU,GAAc,YAGlC,WAAW,CACb,MAAO,MAAK,QAAU,GAAc,YAGlC,YAAgC,CAClC,MAAO,MAAK,KAAO,KAAO,OAAY,KAAK,IAAM,KAAK,MAMxD,QAAQ,EAAgB,CACtB,MAAO,MAAK,OAAO,IAAM,CACvB,KAAK,MAAQ,GAAc,SAC3B,KAAK,OAAS,EACd,KAAK,SAAS,KAIlB,aAAa,EAAgB,CAC3B,MAAO,MAAK,QAAU,KAAK,QAAQ,GAAS,KAG9C,OAAO,EAAoB,CACzB,KAAK,OAAO,IACV,GAAiB,GAAU,OAAS,OACpC,YACA,GAEF,GAAM,GAAM,GAAQ,GACpB,MAAO,MAAK,OAAO,IAAM,CACvB,KAAK,OAAS,EACd,KAAK,MAAQ,GAAc,SAC3B,KAAK,QAAQ,KAIjB,YAAY,EAAoB,CAC9B,MAAO,MAAK,QAAU,KAAK,OAAO,GAAU,KAG9C,QAAQ,EAAoB,CAC1B,YAAK,QAAQ,QAAQ,GACd,KAMT,KAAQ,EAAiD,CACvD,MAAO,MAAK,QAAQ,KAAK,GAG3B,MAAS,EAAiE,CACxE,MAAO,MAAK,QAAQ,MAAM,GAAO,EAAW,IAGtC,OAAO,EAA6B,CAC1C,GAAI,KAAK,QAAU,GAAc,QAAS,CACxC,EAAI,KAAK,aAAc,iBACvB,IACA,KAAK,IAAM,KAAK,MAChB,GAAM,GAAK,KAAK,UAChB,GAAI,KAAK,UAAY,EAAK,IAAM,CAC9B,GAAM,GAAQ,EAAK,IAAO,OAAS,QACnC,KAAK,OAAO,IAAI,EAAO,gBAAkB,EAAK,WAGhD,MAAK,OAAO,KACV,mCAAqC,KAAK,SAAW,IACrD,CAAE,MAAO,KAAK,SAGlB,MAAO,QIjLJ,YAAiD,CAAjD,aAjBP,CAkBU,gBAAa,EACrB,gBAAa,EACI,UAAwB,GACxB,wBAA8B,GACtC,sBAAmB,GAAI,IACvB,oBAAuC,MAEpC,MAAM,CAChB,UAAc,KAAK,KAAM,GAAM,EAAG,SAC3B,KAAK,QAGV,YAAY,CACd,MAAO,MAAK,WAOd,QAAQ,EAA4B,CAClC,KAAK,eAAe,KAAK,GAGnB,WAAW,EAAS,CAC1B,OAAW,KAAM,MAAK,eACpB,EAAG,GAIP,KAAQ,EAAS,EAAmD,CAClE,YAAK,WAAW,GACT,KAAK,MAAM,EAAM,GAGlB,MAAS,EAAS,EAAuC,CAC/D,KAAK,aACL,KAAK,WAAa,KAAK,MAGvB,GAAM,GAAI,GAAW,GAAkB,IAAmB,EAC1D,YAAK,IAAI,KACP,GAAI,IAAS,GAAM,eAAe,GAAG,QAAQ,IAAM,KAAK,gBAEnD,EAGD,aAAc,CACpB,OAAW,KAAM,MAAK,mBACpB,AAAK,EAAG,UAEV,KAAK,mBAAmB,OAAS,EAGnC,kBAA0B,CACxB,GAAM,GAAI,GAAI,IACd,YAAK,mBAAmB,KAAK,GACtB,EAMT,OAAU,EAAS,EAAiC,CAClD,GAAM,GAAQ,KAAK,MACnB,MAAO,MAAK,MACV,EACA,KAAK,WAAW,KAAK,IACnB,MAAK,iBAAiB,KAAK,KAAK,MAAQ,GACxC,KAAK,WAAW,GACT,OAQb,aAAgB,EAAS,EAAiC,CACxD,GAAM,GAAQ,KAAK,MACnB,MAAO,MAAK,MACV,EACA,KAAK,eAAe,GAAM,KAAK,IAC7B,MAAK,iBAAiB,KAAK,KAAK,MAAQ,GACxC,KAAK,WAAW,GACT,OASb,cAAiB,EAAS,EAAsC,CAC9D,MAAO,MAAK,QAAU,KAAK,WAAa,KAAK,OAAO,EAAM,GAO5D,SAAY,EAAS,EAAwC,CAC3D,MAAO,MAAK,mBAAmB,EAAM,EAAG,GAM1C,mBACE,EACA,EACA,EAAgB,KACG,CACnB,MAAO,MAAK,cAAgB,EAAgB,OAAY,KAAK,KAAK,EAAM,MAGtE,eAAe,CAEjB,MAAO,IAAM,KAAK,KAAM,GAAM,EAAG,YAG/B,UAAU,CACZ,MAAO,MAAK,aAAe,EAG7B,cAAoB,CAClB,MAAO,MAAK,IAAI,IAAI,GAAM,EAAG,SAG3B,UAAU,CAEZ,MAAO,MAAK,IAAI,SAAW,OAOvB,WAAW,CAEf,OAAW,KAAM,CAAC,GAAG,KAAK,KACxB,KAAM,GAAG,aAKP,gBAAe,EAAS,CAE5B,OAAW,KAAM,CAAC,GAAG,KAAK,KACxB,AAAI,EAAG,OAAS,GAAM,KAAM,GAAG,aAK7B,SAAW,CACf,OACA,SACA,gBAAgB,MAKD,CACf,EAAgB,GAAM,EAAG,KAAY,EAAG,GACxC,GAAM,GAAwB,GAC9B,OAAW,KAAS,GAAQ,CAC1B,KAAO,KAAK,cAAgB,GAC1B,KAAM,MAAK,mBAEb,EAAQ,KAAK,KAAK,KAAK,EAAM,IAE/B,MAAO,SAAQ,IAAI,KAoCvB,kBAAgD,CAC9C,OACA,SACA,iBAKe,CAGf,MAAO,IAAI,MAAW,QAAQ,CAAE,OAAM,SAAQ,kBCpNhD,kBACE,EACA,EACA,EACA,CACA,GAAM,GAAe,GACrB,OAAW,KAAY,IAAQ,EAAI,KAAM,IAAM,GAAY,CACzD,GAAM,GAAmB,GACzB,OAAW,KAAM,GACf,GAAI,GAAM,KAAM,CACd,GAAM,GAAI,KAAM,GAChB,AAAI,GAAK,MACP,EAAW,KAAK,GAItB,OAAW,KAAM,GAAI,KAAM,GAAE,IAC3B,AAAI,GAAM,MACR,EAAO,KAAK,GAIlB,MAAO,GAeF,YACL,EACA,EACkB,CAClB,MAAO,SAAQ,KAAK,CAClB,EAAE,KAAK,IAAM,IACb,GAAW,GAAU,KAAK,IAAM,MAC/B,MAAM,IAAM,IAGjB,kBAA+B,EAAmC,CAChE,GAAI,CACF,YAAM,GACC,SACA,EAAP,CACA,MAAO,IAIX,kBAA+B,EAAmC,CAChE,MAAO,CAAE,KAAM,IAAS,GAG1B,kBAAkC,EAAmC,CACnE,MAAQ,MAAM,IAAM,KAatB,kBACE,EACe,CACf,GAAM,GAAK,EAAQ,GACnB,AAAI,EAAW,IACb,KAAM,SAAQ,IAAI,GAKtB,kBACE,EACc,CACd,GAAM,GAAc,GACpB,OAAW,KAAM,GAAI,KAAM,IAAM,CAC/B,GAAM,GAAI,KAAM,GAChB,GAAI,GAAK,KACP,GAAI,MAAM,QAAQ,GAChB,OAAW,KAAO,GAAG,CACnB,GAAM,GAAK,KAAM,GACjB,AAAI,GAAM,MAAM,EAAO,KAAK,OAG9B,GAAO,KAAK,GAIlB,MAAO,GAGT,kBACE,EACc,CACd,GAAM,GAAI,EAAQ,KAAM,IACxB,MAAO,GAAQ,GAAK,GAAK,EAAQ,KAAM,SAAQ,IAAI,IA8BrD,kBACE,EACA,EACA,EACmB,CACnB,GAAI,GAAO,KAAM,MAAO,GACxB,GAAM,GAAQ,EAAQ,KAAM,IAC5B,MAAI,GAAQ,GAAe,GAQpB,AAPG,MAAM,IAAuB,CACrC,KAAM,sBACN,OAAQ,EAAM,IAAI,CAAC,EAAI,IAAU,SAC/B,CAAC,KAAM,GAAE,EAAI,GAAQ,IAEvB,mBAEO,OAAO,CAAC,CAAC,EAAG,KAAO,GAAK,MAAQ,GAAK,MAGhD,kBACE,EACA,EACA,EACc,CACd,MAAQ,MAAM,IAAoB,EAAK,EAAG,IAAgB,IAAI,GAAM,EAAG,IAMzE,kBACE,EACA,EACA,EACc,CAEd,MAAO,AADG,MAAM,IAAoB,EAAQ,GAAM,EAAG,IAC5C,OAAO,CAAC,CAAC,KAAO,GAAG,IAAI,CAAC,CAAC,CAAE,KAAO,GAsBtC,GAAM,IAAyB,GAAK,EAkD3C,kBACE,EACA,EAAc,GACI,CAClB,GAAI,GAAK,KAAM,MAAO,GACtB,GAAM,GAAI,KAAM,GAChB,MAAO,IAAK,KAAO,EAAc,CAAC,EAAO,GAkB3C,kBACE,EACA,EACA,EACkB,CAClB,GAAM,GAAM,KAAM,GAClB,GAAI,GAAO,KAAM,MAAO,KACxB,GAAM,GAAS,KAAM,GAAE,GACvB,MAAO,IAAiB,IAK1B,kBACE,EACA,EACA,EACA,EACkB,CAClB,GAAM,GAAK,KAAM,GACjB,GAAI,GAAM,KAAM,MAAO,KACvB,GAAM,GAAK,KAAM,GACjB,GAAI,GAAM,KAAM,MAAO,KACvB,GAAM,GAAS,KAAM,GAAE,EAAI,GAC3B,MAAO,IAAiB,IAe1B,kBACE,EACA,EACY,CACZ,MAAO,GAAO,KAAM,GAAM,GAgD5B,kBACE,EACA,EACiB,CACjB,OAAW,KAAK,GACd,GAAI,CACF,GAAM,GAAS,KAAM,KACrB,GAAI,GAAU,KACZ,MAAO,SAEF,EAAP,CACA,EAAQ,IAsCd,kBACE,EACA,EACc,CACd,MAAO,IAAO,KAAM,IAAoB,EAAK,GAAI,GAAM,EAAG,IAAI,IAAI,GAAM,EAAG,ICtb7E,OAA6B,iBAC7B,GAA+B,iBAC/B,GAAe,sBAQf,GAAM,IAAY,kBAEL,GACX,WAAG,KAAK,SAAS,cAAgB,EAAO,WAAG,IAAI,cAKpC,GAAW,CAAC,EAAI,YAAY,SAAS,YAErC,EAAQ,KAAc,SAAW,KAAc,SAC/C,GAAgB,GAAS,EAAS,WAAG,IAAI,yBAEzC,GAAQ,KAAc,SAEtB,GAAU,KAAc,QACxB,GAAc,IAAW,gBAAW,MACpC,GAAQ,gBAAW,MACnB,GAAc,IAAW,GACzB,GACX,IAAY,GAAS,WAAG,IAAI,WAAa,EAAS,WAAG,IAAI,SAC9C,GAAc,IAAW,EAAS,WAAG,IAAI,gBAEzC,GAAU,IAAS,GAEnB,GAAiB,iBACjB,GAAe,eAEf,GAGX,WAAG,SAAS,UAAe,MAAQ,EAAO,WAAG,IAAI,KAW5C,aAAoB,CAEzB,MACE,KACC,IAAU,KAET,GAAU,cAQT,GAAM,IAAgB,EAC3B,IAAM,IAAe,EAAI,MAAmB,WAAW,iBAM5C,GAAkB,EAAK,IAAM,CACxC,GAAI,CACF,MAAO,IACH,EAAI,oBAAa,2BAA4B,GAC7C,YACJ,CACA,UASS,GAAyB,EAClC,MACA,GACA,MACA,GACA,QACC,GCvFE,GAAM,IAAmB,GAAK,EAKxB,GAAuB,EAAI,EAO3B,EAAe,GAAK,EAMpB,GAAoB,EAAI,EAKxB,GAAY,EAAI,GAKhB,GAAY,EAAY,GAAI,ICjClC,GAAM,IAAgB,GAAK,ECAlC,OAMO,qBACP,GAA0B,mBA8B1B,kBACE,EACe,CACf,AAAI,GAAW,MACf,IAAI,IAAM,GAAU,EAAS,UAC7B,AAAI,IACF,EAAQ,IAAI,MAGZ,KAAM,IAAI,SAAc,GAAW,EAAQ,IAAI,KAAM,IAEvD,KAAM,IAAW,IAGjB,GAAI,IAAM,GAAU,EAAS,aAQ/B,kBACE,EACe,CACf,AAAI,GAAY,MAChB,IAAI,IAAM,GAAU,EAAU,UAC9B,AAAI,IACF,EAAS,MAAM,IAEf,KAAM,IAAI,SAAc,GAAW,EAAS,MAAM,KA0B/C,YAAsB,EAAkB,CAC7C,OAAW,KAAM,CAAC,GAAI,MAAO,GAAI,OAAQ,GAAI,QAC3C,GAAI,CACF,GAAI,eACJ,GAMC,GAAM,IAAgB,iBAAU,aAOhC,YAAoB,EAAmB,CAC5C,MAAO,GAAE,UACL,YACA,GAAG,EAAE,gBAAgB,EAAE,iBAAiB,EAAE,aAGzC,oBAA0B,aAAU,CAEzC,YAAqB,EAAoC,CACvD,MAAM,CACJ,UAAW,CACT,EACA,EACA,IACG,CACH,KAAK,WAAY,KAAK,OAAS,EAAM,QACrC,EAAS,MARM,kBADb,WAAQ,If9FlB,GAAM,IAAQ,WAAG,MAEV,YAAsB,EAAmB,EAA2B,CAEzE,GADI,EAAM,IACN,WAAG,MAAQ,GAAM,IAAK,MAAO,GACjC,GAAM,GAAS,EAAS,GAAY,WAAG,IAAM,WAAG,IAAM,EAAW,WAAG,IAAM,GACpE,EAAQ,EAAU,MAAM,GAAM,KACpC,MAAI,IAAiB,EAAM,GAAI,IAAW,EAAM,UACzC,EAAS,EAAM,KAAK,WAAG,KAGzB,YAAsB,EAA4B,CAEvD,MADI,GAAM,IACN,WAAG,MAAQ,GAAM,KACd,GAAM,MAAQ,WAAG,IADS,EAG7B,EAAW,MAAM,WAAG,KAAK,KAAK,GAAM,KAG1C,GAAM,IAAU,wBAEhB,YAA4B,EAAsB,CAChD,GAAM,GAAQ,GAAQ,KAAK,GAC3B,MAAO,IAAS,KAAO,EAAM,GAAG,cAAgB,KAAO,EAAM,GAAK,EAG7D,YAA2B,EAA2B,CAC3D,MAAO,GAAO,EAAK,WAAe,IAAM,GAAQ,EAAK,aAGhD,eAAoB,EAAyB,CAClD,GAAM,GAAO,WAAG,KAAK,GAAG,GACxB,MAAO,YAAG,QAAQ,EAAQ,GAAmB,GAAQ,GAchD,YAAwB,EAA+B,CAC5D,MAAO,IAAgB,GAAa,IAI/B,YAAiB,EAA4B,CAClD,MAAO,IAAgB,GAAY,IAGrC,GAAM,IAAkB,2BAKjB,YAAyB,EAAgC,CAC9D,GAAM,GAAI,GAAc,EAAY,IAC9B,EAAI,WAAG,MAAM,EAAO,GAAG,WAAY,IACzC,MAAO,QACF,GACC,GAAK,KACL,GACA,CACE,IAAK,EAAE,IAAM,EAAE,SACf,KAAM,EAAE,KAAO,EAAE,WAiBpB,YACL,EACA,EACS,CACT,MACE,GAAS,IACT,EAAS,IACR,KAAoB,GACnB,EAAgB,WAAW,GAAa,EAAkB,WAAG,OAI5D,YAAmB,EAAoB,CAC5C,MAAO,IAAY,EAAY,WAAG,KAAK,MAAM,WAAG,KAK3C,YACL,EACA,EACQ,CACR,MAAO,GAAO,aAAe,EAAM,WAC/B,GAEA,GACE,GAAa,EAAM,YACnB,GAAa,GAAa,EAAO,YAAa,MAQtD,GAAM,IAAU,qCACT,YAA0B,EAAsB,CACrD,MAAO,GACL,EAAI,GAAM,MAAM,IAChB,GAAK,EAAE,GACP,IAAM,GAEL,cACA,YAGE,YAAuB,EAA6B,CACzD,MAAO,GAAI,EAAI,GAAM,MAAM,IAAU,GAAK,GAAM,CAAC,EAAE,GAAI,EAAE,IAAK,IAQzD,YAAyB,EAA2B,CACzD,GAAI,EAAM,GAAa,MAAO,GAC9B,GAAI,CACF,MAAO,YAAG,SAAS,GAAY,mBAC/B,CACA,MAAO,IAIX,kBAA2B,EAA2B,CACpD,GAAI,GAAM,GACV,GAAI,CACF,MAAO,MAAM,IAAc,WAAI,KAAK,GAAa,SACjD,CACA,QAaJ,kBAAkC,EAA6C,CAC7E,MAAO,IACL,GAAK,GACL,GAAM,EAAG,cACT,IAAM,IAsBV,kBACE,EACkB,CAClB,GAAI,EAAM,GAAa,MAAO,GAC9B,GAAI,CACF,MAAO,AAAS,MAAM,IAAK,IAApB,UACP,CACA,MAAO,IAaX,kBACE,EACA,EAAY,GACZ,CACA,GAAI,EAAM,GAAa,MAAO,GAC9B,GAAI,CACF,GAAM,GAAI,KAAM,IAAc,GAAK,GAAa,GAChD,MAAI,IAAK,MAAQ,CAAC,EAAE,cAAsB,GACnC,KAAM,IACX,WAAI,OACF,EACA,WAAG,UAAU,KAAQ,GAAQ,EAAI,WAAG,UAAU,OAEhD,QAEF,CACA,MAAO,IAIJ,YAAe,EAAoB,CACxC,MAAO,GAAW,WAAW,QAGxB,YAAoB,EAAoB,CAC7C,MACG,KAAW,EAAW,WAAW,MACjC,GAAU,IAAM,IAAe,EAAW,MAAM,KAAY,MAa1D,GAAM,IAGT,OAAO,OAAO,CAChB,WAAY,GACZ,YAAa,IACb,cAAe,GACf,QAAS,EACT,WAAY,IAGd,YAAqB,EAAa,CAChC,MAAO,IAAK,MAAS,EAAE,UAAY,EAAE,OAAS,EAGhD,kBACE,EACiB,CACjB,GAAM,GAAmC,OACpC,IACA,GAGC,EAAI,GAAgB,EAAK,YAE/B,KAAM,YAAI,OAAO,EAAE,KAEnB,CACE,GAAM,GAAI,KAAM,IAAK,EAAK,YAC1B,GACE,CAAC,EAAK,eACL,IAAK,MAAS,EAAK,YAAc,GAAY,IAE9C,MAAO,GAAK,WAEhB,OAAS,GAAI,EAAK,WAAY,GAAK,EAAK,YAAa,IAAK,CACxD,GAAM,GAAI,WAAG,KACX,EAAE,IACF,GAAG,EAAE,QAAQ,GAAQ,EAAG,EAAK,QAAS,OAAO,EAAE,OAE3C,EAAI,KAAM,IAAK,GACrB,GAAI,GAAK,MAAS,EAAK,YAAc,GAAY,GAC/C,MAAO,GAGX,KAAM,IAAI,OACR,+BAAiC,EAAK,YAAc,OAAS,EAAK,YAItE,kBAA4B,EAAqC,CAC/D,GAAI,EAAW,SAAS,OAAQ,MAAO,GACvC,GAAM,GAAM,EAAa,MACzB,YAAM,IAAc,CAClB,WAAG,iBAAiB,GACpB,oBACA,WAAG,kBAAkB,KAEvB,KAAM,YAAI,OAAO,GACV,EgBlVT,OAAwB,iBACxB,GAAwB,mBAOjB,GAAM,IAAU,EAAK,IAAM,CAChC,GAAM,GAAQ,GACd,AAAI,EAEF,EAAM,KAAK,GAAO,gBAElB,EAAM,KAAK,GAAO,SAEpB,OAAW,KAAM,GAAc,GAAQ,CACrC,GAAM,GAAI,eAAQ,GAClB,GAAI,GAAgB,GAAI,MAAO,GAEjC,MAAO,mBCbF,aAA2B,CAChC,GAAI,MAAc,GAAgB,aAChC,MAAO,YAGT,GAAI,GACF,OAAW,KAAM,GAAc,CAAC,GAAO,QAAS,GAAO,kBACrD,GAAI,GAAgB,GAAK,MAAO,IAAQ,EAAI,MAIhD,GAAI,GAAO,CACT,GAAM,GAAI,GAAQ,KAAW,UAAW,UACxC,GAAI,GAAgB,GAAI,MAAO,IAAQ,EAAG,MAI5C,MAAO,IAAQ,KAAW,SAAU,KAAU,eCxBhD,OAAwB,mBCAxB,OAAyB,iBACzB,GAA2B,uBAC3B,GAAwB,mBACxB,GAAoB,sBAWb,GAAM,IAAU,EAAK,IAAM,CAEhC,GAAM,GAAa,CAEjB,OAAI,cACJ,KAAa,aAAe,QAI9B,AAAI,GACF,GAAW,KAAK,GAAO,YACvB,EAAW,KAAK,eAAQ,KAAW,UAAW,aAG5C,IACF,EAAW,KAAK,eAAQ,KAAW,UAAW,wBAI5C,CAAC,IAAS,IACZ,EAAW,KACT,GAAO,iBACP,GAAO,mBACP,eAAQ,KAAW,YAIvB,GAAM,GAAQ,EAAc,GAG5B,OAAW,KAAM,GACf,GAAI,CACF,GAAI,gBAAS,GAAI,cAAe,MAAO,QACvC,EAMJ,OAAW,KAAM,GACf,GAAI,CACF,wBAAW,GACJ,OACP,CACA,QAAQ,MAAM,oBAAsB,GAIxC,KAAM,IAAI,OAAM,2BAA6B,MDxDxC,aAAyB,CAC9B,MAAO,MACH,WACA,GACA,eAAQ,KAAW,UAAW,OAAQ,GAAc,eACpD,KAGC,aAA8B,CACnC,MAAO,eAAQ,KAAW,GAAc,cAAe,QEflD,GAAM,IAAU,gBACV,GAAU,+BAEhB,GAAM,IAAU,GAAI,MAAK,cCDzB,GAAM,IAAiB,IAAM,GAAQ,SAAS,UACxC,GAAgB,IAAM,GAAQ,SAAS,SACvC,GAAU,IACrB,KAAmB,QAAU,KAAkB,OAAS,SCL1D,OAAwB,mBCAxB,OAA2C,4BCiB3C,kBACE,EACA,CAAE,YAAW,gBAAe,aAAY,gBAAe,SACtC,CACjB,GAAM,GAAY,GAAa,KAAO,OAAY,EAAY,KAAK,MACnE,KAAO,GAAa,MAAQ,KAAK,MAAQ,GAAW,CAClD,GAAM,GAAQ,KAAK,MACb,EAAS,KAAM,KACrB,GACE,GAAU,MACT,IAAW,GAAc,CAAC,EAAW,GAAW,IAAmB,IACpE,CACA,GAAM,GAAU,KAAK,MAAQ,EACvB,EAAU,EAAO,EAAe,IACpC,GAAM,IAAK,IAAM,EAAU,GAAU,EAAG,MAE1C,KAAO,IAAQ,GAAS,GAAM,GAAW,GAAW,QAEpD,OAAO,GAGX,MAAO,GAST,kBACE,EACA,EACA,CACA,MAAO,IAAM,EAAG,OACX,GADW,CAEd,WAAY,AAAC,GAAuB,EAAO,GAC3C,cAAe,MCnDnB,OAAe,sBCKR,YAAwC,CAW7C,YACW,EACT,EACA,EACiB,EACR,EACT,CALS,YAGQ,gBACR,oBAdQ,YAAwB,GACnC,YAAS,GAef,KAAK,OAAS,EAAS,GACvB,KAAK,OAAO,KAAK,GACjB,GAAW,EAAM,SAGf,QAAQ,CACV,MACE,GACE,KAAK,SACL,GAAK,IACL,IAAM,KACH,KAAK,OAId,KAAM,CAEJ,GAAI,MAAK,OACT,YAAK,OAAS,GACP,GAAS,KAAK,OAAO,IAAI,GAAM,QC7C1C,OAAgB,4BAChB,GAAe,sBCMf,kBACE,EACA,EACY,CACZ,GAAI,GACJ,MAAO,SAAQ,KAAK,CAClB,IAAI,KAAK,GAAM,CACb,GAAI,GAAY,KACd,SAAW,GACJ,IAMX,GAAW,GAAW,KAAK,IAAM,CAC/B,GAAI,GAAY,KACd,QAAW,GACL,GAAI,OAAM,eAOjB,YACL,EACA,EAOY,CACZ,GAAM,GAAI,EAAI,EAAK,WAAa,IAAM,GAAc,EAAG,EAAK,WAAc,EAE1E,GAAI,EAAK,YAAc,EACrB,MAAO,KAET,GAAM,GAAmB,EACvB,EAAK,kBACL,UAAU,IAAM,AAAC,GACjB,GAAY,GAAK,YAAc,KAAO,EAAO,EAAO,KAElD,EAAa,EACX,EAAsB,SAAY,CACtC,GAAI,CACF,MAAO,MAAM,WACN,EAAP,CACA,GACE,AAAW,KAAM,GAAK,mBAAmB,KAAzC,IACA,EAAa,EAAK,WAElB,KAAM,GAEN,WACA,KAAM,GAAiB,GAChB,MAIb,MAAO,KCrET,OAAwB,mBCGjB,YAAyC,CAG9C,YAAqB,EAAwB,EAAoB,CAA5C,aAAwB,iBAF5B,WAAkB,GAClB,OAAS,IAGzB,OAAO,WAAyC,CAC/C,KAAK,SACL,GAAM,GAAM,CAAC,GAAG,KAAK,GACrB,YAAsC,CACpC,OAAW,KAAK,GACd,KAAM,GAGV,MAAO,KAGT,QAAQ,EAAQ,CACd,GAAM,EAAE,OAAQ,IAAM,KAAK,MAAM,KAAK,KAAK,QAC3C,KAAK,EAAE,KAAK,GAAG,GACX,KAAK,WAAa,MAAM,KAAK,SAGnC,YAAY,EAAQ,CAClB,EAAE,QAAQ,GAAM,CACd,AAAK,KAAK,SAAS,IAAK,KAAK,KAAK,KAItC,SAAS,EAAM,CACb,YAAK,SACE,KAAK,EAAE,QAAQ,IAAM,EAG9B,OAAQ,CACN,YAAK,SACL,KAAK,MAAM,QACJ,KAAK,EAAE,QAGhB,OAAQ,CACN,YAAK,SACE,KAAK,EAAE,GAGhB,cAAe,CACb,MAAO,MAAK,OAAS,EAAI,KAAK,QAAU,KAAK,QAG/C,KAAM,CACJ,YAAK,SACL,KAAK,MAAM,MACJ,KAAK,EAAE,SAGZ,SAAiB,CACnB,YAAK,SACE,KAAK,EAAE,OAGhB,OAAc,CACZ,YAAK,MAAM,OAAS,EACpB,KAAK,EAAE,OAAS,EACT,QAGL,SAAc,CAChB,YAAK,SACE,CAAC,GAAG,KAAK,GAGlB,gBAAgC,CAC9B,YAAK,SACE,KAAK,MAAM,GAMZ,QAAS,CACf,GAAI,KAAK,EAAE,SAAW,EAAG,OACzB,GAAI,KAAK,WAAa,KAAM,CAC1B,GAAM,GAAc,KAAK,EAAE,OAAS,KAAK,UACzC,KAAK,MAAM,OAAO,EAAG,GACrB,KAAK,EAAE,OAAO,EAAG,GAEnB,GAAM,GAAU,KAAK,MAAQ,KAAK,MAC5B,EAAiB,KAAK,MAAM,UAAU,GAAM,EAAK,GACvD,AAAI,IAAmB,GACrB,KAAK,QACI,EAAiB,GAC1B,MAAK,MAAM,OAAO,EAAG,GACrB,KAAK,EAAE,OAAO,EAAG,MDtFhB,YAAW,CAKhB,YAAqB,EAAe,CAAf,aAJb,iBAAc,EACd,oBAAiB,EAIvB,GAAI,GAAS,EAAG,KAAM,IAAI,OAAM,0BAChC,KAAK,YAAc,GAAI,IAAiB,IAGzC,WAAQ,SAAU,CACjB,MAAO,MAAK,QAGd,OAAQ,CACN,MAAO,CACL,KAAM,OACN,IAAK,KAAK,gBACV,WAAY,KAAK,YACjB,iBAAkB,KAAK,kBAI3B,SAAU,CACR,GAAM,GAAM,KAAK,MACjB,AAAI,KAAK,eAAiB,GACxB,KAAK,YAAY,KAAK,EAAM,KAAK,gBAEnC,KAAK,eAAiB,EACtB,KAAK,cAGP,OAAQ,CACN,KAAK,eAAiB,EACtB,KAAK,YAAc,EACnB,KAAK,YAAY,WAGf,gBAAwB,CAC1B,MAAO,MAAK,kBAGV,mBAAmB,CACrB,MAAO,MAAK,MAAQ,KAAK,kBAGvB,aAAqB,CACvB,MAAO,MAAK,eAGV,oBAAmC,CACrC,MAAO,IAAO,KAAK,YAAY,OAAQ,IAAM,GAAY,KAAK,iBAG5D,aAA4B,CAC9B,MAAO,IAAI,KAAK,gBAGd,cAA6B,CAC/B,MAAO,IAAS,KAAK,WAAY,GAAM,EAAI,MAGzC,kBAAiC,CACnC,MAAO,IAAS,KAAK,YAAa,GAAM,GAAQ,EAAW,EAAI,OAG7D,kBAAiC,CACnC,MAAO,IAAS,KAAK,YAAa,GAAM,GAAQ,EAAW,EAAI,MEvE5D,YAAuB,EAAY,CACxC,GAAM,GAAM,GAAY,EAAI,GAAI,OAAO,cAAe,KACtD,MAAO,GACL,GAAW,GACX,GAAM,EAAG,YACT,IAAM,GAIV,GAAM,IAAa,OAAO,OAAO,CAC/B,QAAS,CAAE,MAAO,GAAI,YAAa,iBACnC,GAAI,CAAE,MAAO,EAAG,YAAa,WAC7B,IAAK,CAAE,MAAO,EAAG,YAAa,eAC9B,UAAW,CAAE,MAAO,EAAG,YAAa,qBACpC,OAAQ,CAAE,MAAO,EAAG,YAAa,qBACjC,OAAQ,CAAE,MAAO,EAAG,YAAa,oCACjC,WAAY,CAAE,MAAO,EAAG,YAAa,0BACrC,cAAe,CAAE,MAAO,EAAG,YAAa,yBACxC,aAAc,CAAE,MAAO,EAAG,YAAa,gCACvC,SAAU,CAAE,MAAO,EAAG,YAAa,kCACnC,MAAO,CAAE,MAAO,EAAG,YAAa,uBAChC,MAAO,CAAE,MAAO,GAAI,YAAa,2BACjC,aAAc,CAAE,MAAO,GAAI,YAAa,oCACxC,aAAc,CAAE,MAAO,GAAI,YAAa,sBACxC,WAAY,CAAE,MAAO,GAAI,YAAa,4BACtC,aAAc,CAAE,MAAO,GAAI,YAAa,gCACxC,OAAQ,CAAE,MAAO,GAAI,YAAa,uCAClC,aAAc,CAAE,MAAO,GAAI,YAAa,uBACxC,MAAO,CAAE,MAAO,GAAI,YAAa,2BACjC,OAAQ,CAAE,MAAO,GAAI,YAAa,oBAClC,QAAS,CAAE,MAAO,GAAI,YAAa,+BACnC,OAAQ,CAAE,MAAO,GAAI,YAAa,uBAClC,SAAU,CAAE,MAAO,GAAI,YAAa,oBACpC,SAAU,CAAE,MAAO,GAAI,YAAa,mBACpC,YAAa,CAAE,MAAO,GAAI,YAAa,0BACvC,OAAQ,CAAE,MAAO,GAAI,YAAa,uBAClC,QAAS,CAAE,MAAO,GAAI,YAAa,6BACnC,OAAQ,CAAE,MAAO,GAAI,YAAa,qBAClC,QAAS,CAAE,MAAO,GAAI,YAAa,mBACnC,OAAQ,CAAE,MAAO,GAAI,YAAa,oCAClC,OAAQ,CAAE,MAAO,GAAI,YAAa,iCAClC,SAAU,CAAE,MAAO,GAAI,YAAa,2BACpC,SAAU,CAAE,MAAO,GAAI,YAAa,kCACpC,QAAS,CAAE,MAAO,GAAI,YAAa,qCACnC,OAAQ,CAAE,MAAO,GAAI,YAAa,6BAClC,OAAQ,CAAE,MAAO,GAAI,YAAa,4BAClC,MAAO,CAAE,MAAO,GAAI,YAAa,eACjC,OAAQ,CAAE,MAAO,GAAI,YAAa,kBAClC,gBAAiB,CAAE,MAAO,GAAI,YAAa,0BAC3C,WAAY,CAAE,MAAO,GAAI,YAAa,kCACtC,UAAW,CAAE,MAAO,GAAI,YAAa,wBACrC,SAAU,CAAE,MAAO,GAAI,YAAa,6BACpC,gBAAiB,CACf,MAAO,GACP,YAAa,6CAEf,WAAY,CACV,MAAO,GACP,YAAa,0CAEf,YAAa,CAAE,MAAO,GAAI,YAAa,6BACvC,UAAW,CACT,MAAO,GACP,YAAa,iDAEf,OAAQ,CAAE,MAAO,GAAI,YAAa,uBAClC,MAAO,CAAE,MAAO,GAAI,YAAa,mBACjC,aAAc,CAAE,MAAO,GAAI,YAAa,iBACxC,MAAO,CAAE,MAAO,GAAI,YAAa,2BACjC,MAAO,CAAE,MAAO,GAAI,YAAa,uCACjC,MAAO,CAAE,MAAO,GAAI,YAAa,mCACjC,UAAW,CAAE,MAAO,GAAI,YAAa,uBACrC,OAAQ,CAAE,MAAO,GAAI,YAAa,2BAClC,IAAK,CAAE,MAAO,GAAI,YAAa,aAC/B,MAAO,CAAE,MAAO,GAAI,YAAa,yBACjC,OAAQ,CAAE,MAAO,GAAI,YAAa,kBAClC,OAAQ,CAAE,MAAO,GAAI,YAAa,gBAClC,UAAW,CAAE,MAAO,GAAI,YAAa,wBCxDvC,GAAM,IAAU,KAAK,MAEf,GAAS,EAAK,IAAM,EAAS,UAE7B,GAAY,GAAI,IAAK,GACrB,GAAiB,GAAI,IAAK,GAMzB,YAAuB,EAAU,EAAqB,CAC3D,MAAO,GAAG,KAAK,GAAS,KAAS,KAM5B,aAAwC,CAC7C,GAAM,GACJ,KAAK,MAAQ,GAAU,EAAS,YAAY,eAExC,EAAe,GACnB,GAAe,gBACf,EAAS,wBAAwB,gBAMnC,MAAO,MAAS,IAAI,CAClB,MAAO,OACP,IAAK,wBACL,OAAQ,MAAmB,GAAiB,EAC5C,KAAM,CACJ,YAAa,KACb,gBACA,eACA,qBAAsB,GAAe,gBACrC,gBAAiB,GAAU,gBAC3B,+BACE,EAAS,wBAAwB,kBAclC,aAA2B,CAChC,GAAM,GAAS,GACf,aAAM,kBAAkB,EAAG,IACpB,EAAE,MAAM,MAAM,mBAAmB,MAAM,GAGhD,GAAM,IAAe,CACnB,aACA,WACA,0BACA,yBACA,mBACA,qBAGK,YAA0B,EAAqB,CACpD,GAAI,GAAS,GAAgB,GAAa,IACtC,EAAQ,EACZ,EACE,GAAQ,EACR,EAAS,GAAa,OAAO,CAAC,EAAG,IAAO,EAAE,QAAQ,EAAI,IAAK,GAAQ,aAC5D,IAAU,GAEnB,MAAO,GACL,EAAO,MAAM,OAAO,IAAI,GAAM,CAC5B,GAAI,EAAG,WAAW,KAAM,CACtB,GAAM,GAAO,GAAc,GAC3B,MAAI,GAAO,cAAc,SAAS,EAAK,eAC9B,GAEA,EAAO,IAGlB,MAAO,MAET,KAAK,KAGF,YACL,EACA,EAAW,IACH,CACR,GAAM,GAAI,GAAS,GACb,EAAQ,GAAkB,GAChC,MAAO,IAAU,GAAiB,GAAI,EAAW,EAAM,QAAU,EAG5D,YAAoB,EAAa,EAAyB,CAC/D,MAAO,GAAI,GACR,MAAM,SACN,IAAI,GAAM,GAAY,EAAI,IAC1B,IAAI,GAAM,EAAG,QAAQ,MAAO,KAC5B,OAAO,GACP,KAAK,MAGH,WAAiB,EAAiB,EAAe,EAAqB,CAC3E,GAAI,EAAM,IAAY,GAAS,KAAM,CACnC,KAAS,KAAK,4BAA6B,MAC3C,OAEF,GAAM,GAAI,GAAS,GAAW,GAAS,GAAS,GAAS,GACnD,EAAQ,GAAa,IAAU,GAAa,IAAM,EAAO,GAAS,OACxE,GAAI,CAAC,GAAS,GAAiB,GAAI,CACjC,KAAS,KAAK,2BAA6B,GAAe,GAAQ,GAChE,WACG,IAEL,OAGF,AAAK,EAAI,KAAqB,GAAM,EAAG,yBAEvC,GAAU,UACN,GAAO,GAAe,UAC1B,GAAM,GAAQ,CAAC,GAAS,KAAwB,WAAa,QAC7D,KAAS,IACP,IAAU,QAAU,QAAU,OAC9B,cAAgB,GAAe,GAC/B,GACE,QACA,WACG,EAAO,EAAS,MAGlB,KAEH,GAAa,KAAK,EAAO,CAAE,UAAS,UAIjC,YAAoB,EAAqB,EAAwB,CACtE,MAAI,IAAS,KAAa,GAAI,OAAM,GAEhC,GAAS,IACN,GAAM,QAAQ,cAAc,SAAS,EAAQ,gBAChD,GAAM,SAAW,KAAO,IAGrB,GCnLT,OAAgB,4BAChB,GAAe,sBCDf,OAAwB,mBAaxB,YAAc,EAAkB,CAC9B,MAAO,IAAK,KAAO,GAAK,OAAO,KAAK,GAS/B,YAAkD,CAQvD,YAAqB,EAA0B,EAAuB,CAAjD,eAA0B,oBANvC,wBAA6B,EAIpB,qBAAiD,GAGhE,GAAI,EAAU,EACZ,KAAM,IAAI,OAAM,4BAElB,GAAI,EAAU,IAEZ,KAAM,IAAI,OAAM,sBAGlB,KAAK,QACD,EAAI,IACN,MAAK,cAAgB,GAAiB,IAAM,CAC1C,KAAK,SACJ,GAAM,EAAe,KAIpB,OAAQ,CACd,GACE,KAAK,YAAc,MACnB,KAAK,cAAgB,MACrB,EAAW,KAAK,kBAEhB,OAAW,KAAK,MAAK,WACnB,GAAI,KAAK,aAAa,IAAM,KAAM,CAChC,GAAM,GAAI,KAAK,WAAW,GAC1B,GAAI,GAAK,KACP,OAAW,KAAM,MAAK,gBACpB,EAAG,EAAG,IAMhB,KAAK,WAAa,KAAK,cAAgB,OAAO,OAAO,MACrD,KAAK,aAAe,OAAO,OAAO,MAClC,KAAK,mBAAqB,GAG3B,WAAQ,SAAU,CACjB,MAAO,QACF,KAAK,YACL,KAAK,cAIZ,KAAM,CACJ,AAAI,KAAK,eAAiB,MAAM,cAAc,KAAK,eAGrD,OAAc,CACZ,YAAK,MAAM,CAAC,EAAG,IAAM,CACnB,OAAW,KAAM,MAAK,gBACpB,EAAG,EAAG,KAGV,KAAK,aAAe,OAAO,OAAO,MAClC,KAAK,WAAa,OAAO,OAAO,MAChC,KAAK,mBAAqB,EACnB,QAGL,OAAe,CACjB,GAAI,KAAK,cAAgB,MAAQ,KAAK,YAAc,KAAM,MAAO,GACjE,GAAI,GAAM,EACV,OAAW,KAAK,IAAM,GAAK,KAAK,YAAa,GAAK,KAAK,eACrD,AAAI,KAAK,IAAI,IAAI,IAEnB,MAAO,GAYT,IAAI,EAAsB,CACxB,MAAO,MAAK,aAAa,IAAQ,MAAQ,KAAK,WAAW,IAAQ,KAGnE,MAAiB,CACf,MAAO,GAAK,CAAC,GAAG,GAAK,KAAK,YAAa,GAAG,GAAK,KAAK,gBAAgB,OAClE,GAAK,AAAQ,KAAK,aAAa,IAA1B,MAIT,OAAO,EAAa,CAGlB,GAAM,GAAI,KAAK,aAAa,GAC5B,GAAI,GAAK,KAAM,CACb,KAAK,aAAa,GAAO,OACzB,OAAW,KAAM,MAAK,gBACpB,EAAG,EAAK,GAGZ,GAAM,GAAK,KAAK,WAAW,GAC3B,GAAI,GAAM,MACR,MAAK,WAAW,GAAO,OACnB,GAAK,MACP,OAAW,KAAM,MAAK,gBACpB,EAAG,EAAK,GAMhB,MAAM,EAAyC,CAC7C,OAAW,KAAK,IAAM,GAAK,KAAK,YAAa,GAAK,KAAK,eAAgB,CACrE,GAAM,GAAI,KAAK,aAAa,IAAM,KAAK,WAAW,GAClD,AAAI,GAAK,MAAM,EAAQ,EAAG,IAI9B,SAAS,EAA+C,CACtD,OAAW,KAAK,MAAK,OAAQ,CAC3B,GAAM,GAAI,EAAO,KAAK,aAAa,GAAI,KAAK,WAAW,IACvD,AAAI,GAAK,MACH,EAAU,EAAG,IACf,KAAK,OAAO,IAMpB,IAAI,EAAsB,CACxB,SAAM,EAAI,GACH,KAAK,aAAa,IAAQ,KAAK,WAAW,GAGnD,IAAI,EAAsB,EAAU,CAClC,EAAM,EAAI,GACN,KAAK,aAAa,IAAQ,MACxB,MAAK,oBAAsB,KAAK,SAAS,KAAK,QAClD,KAAK,sBAEP,KAAK,aAAa,GAAO,EAG3B,SAAS,EAAsB,EAAwB,CACrD,EAAM,EAAI,GACV,GAAM,GAAQ,KAAK,IAAI,GACvB,GAAI,GAAS,KAAM,MAAO,GAE1B,GAAM,GAAI,IACV,YAAK,IAAI,EAAK,GACP,EAGT,GAAG,EAAkB,EAAqC,CACxD,KAAK,gBAAgB,KAAK,KASvB,QAAwB,CAO7B,YACW,EACT,CADS,YAPH,SAAM,EACN,mBAAgB,EAChB,oBAAiB,EACjB,iBAAc,EACd,cAAW,EAKjB,KAAK,MAAQ,GAAI,IAAU,EAAK,QAAS,EAAK,iBAG5C,OAAO,CACT,MAAO,MAAK,MAAM,KAGpB,OAAQ,CACN,MAAO,CACL,KAAM,KAAK,KACX,cAAe,KAAK,cACpB,eAAgB,KAAK,eACrB,YAAa,KAAK,YAClB,SAAU,KAAK,UAInB,IAAI,EAAuB,CACzB,GAAM,GAAI,KAAK,MAAM,IAAI,GACzB,MAAO,IAAK,MAAQ,EAAE,OAAY,KAAO,OAAa,EAGxD,OAAQ,CACN,KAAK,MAAM,QACX,KAAK,cAAgB,EACrB,KAAK,eAAiB,EACtB,KAAK,YAAc,EACnB,KAAK,SAAW,EAGlB,SAAS,EAAqC,CAC5C,OAAW,KAAK,MAAK,MAAM,OACzB,AAAI,EAAU,IACZ,KAAK,MAAM,OAAO,QAKlB,eACJ,EACA,EACA,EAAU,EACO,CACjB,EAAM,EAAI,GACV,CACE,GAAM,GAAS,KAAK,IAAI,GACxB,GAAI,GAAU,KACZ,YAAK,gBAEE,EAIX,GAAM,GAAQ,KAAK,MACb,EAAU,KAAK,MACf,EAAQ,KAAK,MAAM,SAAS,EAAK,IAAO,EAC5C,QACA,aAOF,GAAI,EAAM,QAAa,EAMrB,YAAK,cAGE,GACL,EACA,KAAK,KAAK,UACV,IAAM,CACJ,KAAK,WACD,KAAK,MAAM,IAAI,IAAO,QAAa,GAAO,KAAK,MAAM,OAAO,IAGlE,GAAK,CAMH,KAAK,MAAM,IAAI,EAAK,KAGnB,CAEL,GAAM,GAAa,EAAM,QACzB,GAAI,GAAc,KAAM,CAEtB,GAAM,GAAiB,AADA,EAAa,KAAK,KAAK,UACN,KAAK,MAC7C,GAAI,EAAiB,EAAG,CAKtB,GAAM,GAAI,GAAM,IAAM,KAAK,IAAI,GAAM,CACnC,UAAW,IAEb,GAAI,GAAK,KACP,YAAK,iBAIE,GAIb,MAAO,GAAU,EACb,KAAK,cAAc,EAAK,EAAO,EAAU,GACzC,UC/TV,OAAe,iBACf,GAAgB,uBAChB,GAA0B,mBAE1B,GAAwB,mBACxB,GAA+D,mBCiE/D,kBACE,EACA,EACc,CACd,MAAI,IAAO,MAAQ,GAAK,KAAa,EAAM,EAAK,EAAS,IAAM,IACxD,GAAY,EAAK,GAG1B,kBACE,EACA,EACiB,CACjB,MAAO,IAAK,MAAQ,GAAK,MAAY,KAAM,GAAE,GAAb,EAAuB,OC7ElD,YAAc,CAEnB,YACW,EACA,EACT,CAFS,SACA,gBAHH,QAAK,KAAK,MAMlB,QAAQ,EAAa,CACnB,GAAM,GAAM,KAAK,MACX,EAAO,EAAM,KAAK,GACxB,KAAK,GAAK,EACV,EAAI,KAAK,SAAU,GAAM,EAAG,EAAK,IAC7B,EAAO,GACT,KAAK,EAAE,IAAI,EAAO,IAAM,OAAS,EAAO,IAAM,OAAS,QAAS,EAAK,CACnE,UAAW,MAYnB,kBACE,EAC2C,CAC3C,GAAM,GAAQ,KAAK,MACb,EAAS,KAAM,KACrB,MAAO,CAAE,UAAW,KAAK,MAAQ,EAAO,UAG1C,kBACE,EAC2C,CAC3C,GAAM,GAAQ,KAAK,MACb,EAAS,KAAM,GACrB,MAAO,CAAE,UAAW,KAAK,MAAQ,EAAO,UC3B1C,GAAM,IAAQ,GAEP,QAAmB,CAAnB,aAnBP,CAoBmB,YAAS,GAAI,IACb,WAAQ,GAAI,UAEvB,MACJ,EACA,EACA,EACY,CACZ,GAAM,GAAQ,KAAK,MACnB,GAAI,CACF,GAAM,GAAS,KAAM,KACf,EAAU,KAAK,MAAQ,EAC7B,MAAI,IAAQ,MAAM,EAAK,EAAQ,GAC/B,KAAK,KAAK,EAAM,GACZ,EAAU,EAAI,GAChB,EAAS,QAAU,EAAO,KAAK,KAAK,OAAQ,CAAE,YAEzC,QACA,EAAP,CACA,WAAK,OAAO,KAAK,GACb,GAAQ,MAAM,EAAK,EAAK,KAAK,MAAQ,GACnC,MAIN,mBAAmB,CACrB,MAAO,IAAO,CAAC,GAAG,KAAK,MAAM,WAAY,CAAC,CAAC,CAAE,KAAO,CAAC,EAAE,KAGzD,MAAM,EAAoB,CACxB,GAAM,GAAM,KAAK,iBAAiB,OAAO,CAAC,CAAC,KAAO,EAAE,WAAW,IACzD,EAAS,EAAI,OACjB,CAAC,EAAK,IAAO,GAAQ,MAAM,EAAG,GAAI,GAClC,GAAI,KAEA,EAAQ,EAAI,IAChB,CAAC,CAAC,EAAM,KAAS,CAAC,EAAM,EAAI,UAE9B,MAAO,IAAY,CAAC,CAAC,SAAU,EAAO,SAAU,GAAG,IAGrD,UAAU,EAAW,CACnB,MAAO,IAAI,IAAQ,EAAG,CAAC,EAAG,IAAO,KAAK,KAAK,EAAG,IAGhD,KAAK,EAAc,EAAmB,CACpC,AAAI,EAAY,IACd,GAAS,KAAK,MAAO,EAAM,IAAM,GAAI,KAAW,KAAK,GAIzD,YAAY,EAA6B,CACvC,MAAO,GAAI,KAAK,MAAM,IAAI,IACvB,IAAI,GAAO,EAAI,mBACf,MAGL,aAAc,CACZ,MAAO,MAAK,OAAO,qBAGrB,YAAyC,CACvC,MAAO,CAAC,GAAG,KAAK,MAAM,WAAW,OAC/B,CAAC,EAAG,CAAC,EAAG,KAAQ,OAAK,GAAL,EAAS,GAAI,EAAE,IAC/B,IAIJ,cAA2C,CACzC,MAAO,IACL,CAAC,GAAG,KAAK,MAAM,WAAW,OACxB,CAAC,EAAG,CAAC,EAAG,KAAQ,OAAK,GAAL,EAAS,GAAI,GAAU,EAAE,kBAAmB,MAC5D,KAKN,QAAmC,CAEjC,MAAO,MAAK,iBAAiB,OAC3B,CAAC,EAAG,CAAC,EAAG,KAAQ,OACX,GADW,EAEb,GAAI,GACH,OAAQ,GAAQ,EAAE,IAAM,EAAU,IAC/B,GAAK,EAAE,QAAS,UAGvB,MAKA,GAAW,EAAK,IACpB,GACE,GAAI,IACJ,GACE,GAAI,IACF,eACA,IAAM,CACJ,GAAM,GAAI,EAAS,gBACnB,EAAE,KAAK;AAAA,EAAc,EAAM,UAC3B,GAAY,EAAM,cAAe,GAC/B,EAAE,KAAK;AAAA,EAAmB,KAG9B,EAAa,WAKd,YAAmB,EAAc,CACtC,MAAO,MAAW,UAAU,EAAS,IAGhC,YACL,EACA,EACA,EACY,CACZ,MAAO,MAAW,KAAK,EAAM,EAAG,GAW3B,YACL,EACA,EACA,EACA,CACA,MAAO,GAAK,SAAY,GAAK,EAAM,GAAQ,GC3J7C,OAA4B,qBCA5B,OAAqC,mBAcrC,GAAM,IACJ,mEAEK,YAAmB,EAA4B,CACpD,GAAI,MAAO,IAAM,UAAY,EAAI,GAAW,OAC1C,MAAO,IAAW,GAEpB,GAAI,GAAM,EAAE,SAAS,IAErB,MAAI,GAAI,OAAS,GAAM,GACrB,GAAM,IAAM,GAEP,OAAO,KAAK,EAAK,OAAO,SAAS,UAoBnC,YAAW,EAAmB,CACnC,MAAO,kBAAW,OAAO,KAAK,EAAG,WAAW,SAAS,QCzChD,GAAM,IAAY,EAAK,IAC5B,GACE,w/ZACA,MAAM,MCKH,YAAgB,EAAqB,CAC1C,MAAO,IACL,EACG,QAAQ,KAAM,KACd,QAAQ,KAAM,KACd,QAAQ,KAAM,KACd,QAAQ,KAAM,KACd,QAAQ,KAAM,KACd,QAAQ,KAAM,KACd,QAAQ,KAAM,MAIrB,YAAgB,EAAqB,CACnC,GAAM,GAAI,EAAE,QAAQ,KACpB,GAAI,IAAM,GACR,MAAO,CAAC,GACH,CACL,GAAM,GAAM,EAAE,OAAO,EAAG,GAClB,EAAQ,GAAO,EAAE,OAAO,EAAI,IAClC,MAAO,IAAQ,EAAM,IAAI,GAAM,CAAC,EAAM,IAAM,EAAI,EAAM,IAAM,MC5BhE,GAAM,IAAW,EAAK,IAAM,GAAO,OAG7B,GAAmB,EAEzB,YAAgB,EAAiB,CAC/B,GAAM,GAAO,GAAI,IACX,EAAkB,GACxB,OAAW,KAAM,GACf,AAAI,EAAG,OAAS,GACd,EAAM,KAAK,GAEX,EAAK,IAAI,EAAG,MAAM,EAAG,IAAmB,GAY5C,MAAO,CAAE,OAAM,SAGV,YAAiB,EAAW,EAAyB,CAC1D,GAAM,GAAK,GAAW,GAAgB,EAAE,cAAc,cAChD,CAAE,QAAO,QACb,GAAgB,KAAO,KAAa,GAAO,GAC7C,OAAW,KAAK,CAAC,EAAG,QAAQ,WAAY,IAAK,GAAG,GAAO,IAAM,CAC3D,GAAM,GAAO,EAAM,KAAK,GAAM,EAAE,SAAS,IACzC,GAAI,GAAQ,KAAM,MAAO,GACzB,OAAS,GAAI,EAAG,EAAI,EAAE,OAAU,IAAmB,GAAI,IAAK,CAC1D,GAAM,GAAM,EAAK,IAAI,EAAE,OAAO,EAAG,KACjC,GAAI,GAAO,KAAM,CACf,GAAM,GAAM,EAAE,OAAO,GACf,EAAM,EAAI,KAAK,GAAM,EAAI,WAAW,IAC1C,GAAI,GAAO,KACT,MAAO,MAQV,YAAiB,EAAW,CACjC,MAAO,IAAQ,IAAM,KAGhB,YAAgB,EAAyB,CAC9C,GAAI,GAAU,GACV,EAAI,GACR,EACE,GAAI,UACG,KAAY,GAAK,GAAQ,EAAE,QAAQ,WAAY,MAExD,MAAO,GJxDT,GAAM,IAAY,OAAO,GAElB,YAAsB,EAAc,EAAW,EAAY,EAAa,CAC7E,GAAI,CAAC,SAAS,IAAM,GAAQ,EAAG,MAAO,GAEtC,GAAM,GAAmB,GAGzB,GAAI,IAAM,EACR,EAAO,KAAK,OAEZ,MAAO,EAAI,GACT,EAAO,KAAK,EAAI,GAChB,EAAI,KAAK,MAAM,EAAI,GAIvB,KAAO,EAAO,OAAS,GAAW,EAAO,KAAK,GAC9C,MAAO,GAAO,UAGT,YAAY,CAEjB,YACW,EACA,EACA,EAAyC,GAClD,CAHS,YACA,gBACA,uBAET,KAAK,KAAO,EAAS,OAGf,iBAAiB,EAA0B,CACjD,MAAO,GAAO,IAAI,GAAK,KAAK,SAAS,IAAI,KAAK,IAGhD,OAAO,EAAa,EAAoB,EAAW,CACjD,GAAI,CAAC,SAAS,GAAM,MAAO,GAE3B,GAAM,GAAS,EAAM,EACrB,MAAI,IACF,GAAM,KAAK,IAAI,GACf,KAGC,GAAS,IAAM,IAChB,KAAK,iBAAiB,GAAa,KAAK,KAAM,EAAK,IAIvD,aAAa,EAAoB,CAC/B,GAAI,MAAO,IAAO,SAAU,KAAM,IAAI,OAAM,aAC5C,GAAI,IAAO,GAAM,MAAO,MAAK,SAAS,GAEtC,GAAM,GAAmB,GACnB,EAAI,OAAO,KAAK,MAClB,EAAS,EAEb,KAAO,EAAI,IACT,EAAO,KAAK,OAAO,EAAI,IACvB,EAAI,EAAI,EAEV,MAAO,MAAK,iBAAiB,EAAO,WAGtC,aAAa,EAAqB,CAChC,GAAI,GAAO,MAAQ,EAAI,SAAW,EAAG,MAAO,GAC5C,GAAM,GAAS,CAAC,GAChB,OAAS,KAAK,GASZ,IARA,EAAO,QAAQ,CAAC,EAAG,IAAM,CAEvB,GAAK,GAAK,EACV,EAAO,GAAK,EAAI,KAAK,KACrB,EAAI,KAAK,MAAM,EAAI,KAAK,QAInB,EAAI,GACT,EAAO,KAAK,EAAI,KAAK,MACrB,EAAI,KAAK,MAAM,EAAI,KAAK,MAI5B,MAAO,MAAK,iBAAiB,EAAO,WAGtC,OAAO,EAAiC,CACtC,MAAO,GAAI,KAAK,aAAa,GAAI,GAAM,CACrC,GAAI,EAAK,OAAO,OAAO,kBACrB,KAAM,IAAI,OAAM,UAAY,EAAI,eAEhC,MAAO,QAAO,KAKpB,UAAU,EAAmB,CAC3B,MAAO,MAAK,gBAAgB,GAG9B,aAAa,EAAiC,CAC5C,GAAI,GAAK,MAAQ,EAAM,GAAI,OAC3B,EAAI,GAAW,KAAK,iBAAmB,KAAK,gBAAgB,GAAK,EACjE,GAAM,GAAS,EAAE,KAAO,IACxB,AAAI,GACF,GAAI,EAAE,MAAM,IAEd,GAAM,GAAI,OAAO,KAAK,MAClB,EAAM,OAAO,GACjB,OAAW,KAAM,GAAG,CAClB,GAAM,GAAM,KAAK,SAAS,QAAQ,GAClC,GAAI,EAAM,EACR,OAEF,EAAM,EAAM,EAAI,OAAO,GAEzB,MAAO,GAAS,OAAO,IAAM,EAAM,EAGrC,YAAY,EAAwB,CAMlC,MAAO,MAAK,aAAa,mBAAY,EAAS,IAAI,MAAM,EAAG,EAAS,GAGtE,gBAAgB,EAAwB,CACtC,MAAO,IAAO,IAAM,KAAK,YAAY,IAYvC,UAAU,EAAQ,GAAI,EAAc,EAAG,EAAU,IAAa,CAC5D,MAAO,IAAW,KAAK,YAAY,GAAQ,GAAa,KAAK,GAG/D,cAAc,EAAe,EAAc,EAAG,EAAU,IAAa,CACnE,MAAO,IAAO,IAAM,KAAK,UAAU,EAAO,EAAa,IAGzD,SAAS,EAAW,EAAW,EAAyB,CACtD,GAAM,GAAK,KAAK,eAAe,GACzB,EAAK,KAAK,eAAe,GAC/B,MAAO,GAAG,QAAU,GAAU,IAAO,EAGvC,eAAe,EAAW,CACxB,MAAO,MAAK,gBAAgB,EAAE,QAC3B,MAAM,IACN,OAAO,GAAM,KAAK,SAAS,SAAS,IACpC,KAAK,MAIC,GAAM,GAAI,IAAM,MAAO,mBAAoB,GAAK,EAAE,eAMlD,GAAU,GAAI,IACzB,UACA,8DAMW,GAAgB,GAAI,IAC/B,gBACA,uCACA,GAAK,EAAE,eAOI,GAAW,GAAI,IAC1B,WACA,mCACA,GAAK,EAAE,eAQI,GAAa,GAAI,IAC5B,aACA,iCACA,GACE,EACG,cACA,QAAQ,OAAQ,KAChB,QAAQ,QAAS,KACjB,QAAQ,OAAQ,KAChB,QAAQ,OAAQ,KAChB,QAAQ,OAAQ,MAGV,GAAa,GAAI,IAAM,aAAc,0BAErC,GAAe,GAAI,IAAM,eAAgB,aAAc,GAClE,EACG,cACA,QAAQ,OAAQ,KAChB,QAAQ,QAAS,KACjB,QAAQ,OAAQ,KAChB,QAAQ,OAAQ,KAChB,QAAQ,OAAQ,MKtJd,YAAmB,EAAW,EAAmB,CACtD,GAAM,GAAI,EAAE,cAAc,YACpB,EAAI,EAAE,cAAc,YAE1B,MAAO,IACL,IAAO,IAAM,EAAI,EAAI,OACrB,IAAO,EAAM,KAAO,EAAM,GAAK,EAAI,OACnC,IAAO,EAAE,SAAW,GAAK,EAAE,SAAW,EAAI,EAAI,OAC9C,IAAM,CACJ,GAAM,GAAS,GAAQ,GACjB,EAAS,GAAQ,GACjB,EAAgB,GAAoB,EAAQ,GAAQ,OAC1D,MAAQ,GAAI,EAAkB,GAAO,OAAS,EAAO,UAQpD,YAAiB,EAAqB,CAC3C,MAAO,IAAK,MAAQ,EAAE,SAAW,EAC7B,GACA,EACG,MAAM,EAAG,IACT,MAAM,IACN,IAAI,CAAC,EAAI,IAAM,EAAK,EAAE,EAAI,IAG5B,YAAkD,EAAQ,EAAa,CAC5E,GAAM,GAAoB,GAAa,EAAG,GACpC,EAAS,GACf,SAAkB,QAAQ,GAAM,CAC9B,GAAM,GAAI,KAAK,IACb,GAAM,EAAG,GAAK,IAAM,GACpB,GAAM,EAAG,GAAK,IAAM,IAEtB,GAAM,EAAG,IAAM,EAAE,KAAK,MAEjB,EChHF,YAAc,EAAmB,CACtC,GAAM,GAAS,EAAI;AAAA,EACnB,MAAO,GAAQ,EAAO,QAAQ,GAAW;AAAA,GAAU,EAG9C,eAAuB,EAAyB,CACrD,MAAO,IAAQ,EAAI,IAAI,GAAM,EAAI,GAAI,MAAM,MCX7C,OAA8B,iBAC9B,GAA6B,uBAC7B,GAAiC,mBCFjC,OAAsC,uBACtC,GAAqB,mBCDrB,OAAmB,qBACnB,GAAe,iBAoCR,GAAM,IAAW,IAMxB,kBACE,EACA,EAIiB,CACjB,GAAM,GAAO,WAAO,WAAW,UAC3B,EAAY,EACV,EAAM,EAAO,GAAM,OAAQ,IAAY,EAC7C,YAAM,IACJ,EACA,GACE,GAAI,SAAc,CAAC,EAAS,IAAW,CACrC,GAAM,GAAQ,WAAG,iBAAiB,EAAU,CAAE,UAAW,KACzD,EAAM,GAAG,QAAS,AAAC,GAAe,EAAO,IACzC,EAAM,GAAG,OAAQ,AAAC,GAA2B,CAC3C,GAAa,EAAM,OACnB,GAAM,UAAU,WAAW,GAC3B,EAAK,OAAO,KAEd,EAAM,GAAG,MAAO,IAAM,QAGrB,EAAK,SAAS,MAAM,EAAG,GAGzB,YAAmB,EAAe,EAAS,GAAkB,CAClE,MAAO,YACJ,WAAW,UACX,OAAO,GACP,SACA,MAAM,EAAG,EAAS,GAMhB,YACL,EACA,EAAM,EACN,EAAQ,GACR,EAAS,IACD,CACR,MAAO,GAAM,aAAa,GAAU,EAAO,IAAS,UAAU,EAAG,GAI5D,YACL,EACA,EAAM,GACN,EAAQ,GACR,EAAS,IACD,CACR,MAAO,IAAe,EAAO,EAAK,EAAO,GCjG3C,OAAiC,iBACjC,GAAiC,uBAEjC,GAA0B,mBAC1B,GAA2D,mBCY3D,YAA2B,CACzB,UACA,QACA,YACA,YACA,QACA,aAQS,CACT,GAAM,GAAM,CAAC,GACb,EAAY,GAAY,GAAS,GAAQ,WAAY,GAAM,EAAI,KAAK,IACpE,GAAM,GAAI,GAAW,EAAc,IAAM,KAAK,MAE9C,SAAQ,GAAS,EAAE,SAAS,IAC5B,EACG,IAAa,EAAE,SAAS,MACzB,CAAC,EAAE,SAAS,IACd,EAAY,GAAa,CAAC,EAAE,SAAS,IACrC,EAAY,GAAa,EAAE,SAAS,IAE7B,GACL,GAAgB,GAChB,EAAQ,GAAiB,OACzB,EAAY,GAAqB,OACjC,GAAa,CAAC,EAAQ,GAAqB,OAC3C,CAAC,GAAa,CAAC,EAAQ,GAAwB,OAC/C,GAAa,CAAC,EAAQ,GAAqB,QAIxC,oBAA2B,MAAM,CAItC,YAAY,CACV,QACA,UACA,YAAY,GACZ,YAAY,GACZ,QAAQ,GACR,YAAY,IAQX,CACD,MACE,GAAkB,CAChB,UACA,QACA,YACA,YACA,QACA,eAGJ,KAAK,MAAQ,EACT,GAAS,MAAM,MAAK,MAAQ,EAAM,OACtC,KAAK,UAAY,EACjB,KAAK,MAAQ,ICpFjB,OAA0C,qBAMnC,oBAA+B,YAAS,CAI7C,YAAY,EAAwB,CAClC,MAAM,GAJS,cAAW,GAAI,IAAiB,oBAChC,UAAiB,GAIhC,KAAK,GAAG,SAAU,IAAM,CACtB,KAAK,SAAS,QAAQ,KAAK,QAE7B,KAAK,GAAG,QAAS,GAAO,CACtB,KAAK,SAAS,OAAO,QAIrB,OAAe,CACjB,MAAO,QAAO,OAAO,KAAK,SAMxB,SAA0B,CAC5B,MAAO,MAAK,SAAS,QAGvB,OAAO,EAAY,EAA0B,EAAkB,CAC7D,KAAK,KAAK,KACR,OAAO,SAAS,GAAS,EAAQ,OAAO,KAAK,EAAO,IAEtD,MFpBJ,GAAM,IAAS,EAAK,IAAM,EAAS,SAEnC,kBACE,EACA,EACA,CACA,GAAI,CACF,MAAO,GAAQ,GAAe,EAAY,GAAU,SAC7C,EAAP,CACA,KAAS,KAAK,uBAAyB,EAAY,GACnD,QAIJ,kBACE,EACA,EACA,EACA,CAEA,GAAI,AADM,MAAM,YAAK,IACf,OAAS,EAAG,OAElB,GAAM,GAAgB,GAChB,EAAc,CAClB,wBAAiB,EAAY,GAAE,UAAW,IAAS,IAAW,GAC5D,QACA,GAAO,EAAK,KAAK,KAUrB,GAPA,AAAI,EAAW,cAAc,SAAS,OACpC,EAAE,KAAK,sBAAe,GAAG,QAAS,GAAO,EAAK,KAAK,KAC1C,EAAW,cAAc,SAAS,QAC3C,EAAE,KAAK,gCAAyB,GAAG,QAAS,GAAO,EAAK,KAAK,KAE/D,EAAE,KAAK,GACP,KAAM,IAAc,GAChB,EAAW,GACb,KAAM,IAAI,IAAa,CACrB,QAAS,aAAe,EAAa,WACrC,MAAO,EAAK,KASlB,kBACE,EACA,EACiB,CAEjB,GAAI,AADM,MAAM,YAAK,IACf,OAAS,EAAG,MAAO,QAAO,KAAK,IACrC,GAAM,GAAI,GAAI,IACd,YAAM,IAAS,EAAY,EAAG,GACvB,KAAM,GAAE,OAGjB,kBAAkC,EAAoB,CACpD,MAAO,MAAK,MAAO,MAAM,IAAe,IAAa,YAGvD,GAAM,IAAa,iBAAU,SAE7B,kBAAoC,EAAoB,EAAU,CAChE,GAAM,GAAO,EAAU,GACjB,EAAM,KAAM,IAAW,GAC7B,MAAO,kBAAW,EAAY,GFvDzB,GAAM,IAAmB,eAEnB,GAAkB,EAAK,SAAY,CAC9C,GAAM,GAAO,YAAK,EAAS,SAAS,eAAgB,IACpD,YAAM,cAAO,GACN,GACN,GAEH,kBAAwC,EAAoB,CAC1D,MAAO,YACL,KAAM,MACN,GAAG,GAAW,GAAiB,GAAc,WAAY,EAAG,IAIhE,GAAM,IAAS,EAAK,IAAM,EAAS,YAE5B,YAAwB,EAA2B,CACxD,MACE,IAAK,MACL,EAAS,EAAE,WACX,GAAU,EAAE,SACZ,GAAU,EAAE,aAIhB,EAAM,IAAM,CACV,EAAa,IAAM,GAAW,SAAS,SACvC,GAAc,AAAC,GAAoC,CACjD,GAAc,KACV,GAAW,SAAS,QACpB,GAAW,SAAS,SAAS,GAAM,EAAG,WAAW,QAIzD,GAAM,IAAa,EACjB,IACE,GAAI,IAA+B,CACjC,QAAS,IACT,UAAW,EACX,aAAc,KAOpB,kBAA+B,EAA6C,CAC1E,GAAM,GAAS,KAAM,MAAa,cAAc,EAAY,IAC1D,GAAU,IAEZ,GAAI,GAAU,KACZ,KAAM,IAAI,OAAM,yBAA2B,GAE3C,MAAO,GAIX,kBAAyB,EAA6C,CACpE,GAAM,GAAQ,KAAM,IAAkB,GACtC,GAAI,CACF,GAAM,GAAS,MAAM,YAAK,IAAQ,QAClC,GACE,KAAK,MAAQ,EACb,EAAS,oBAAoB,eAAiB,EAC9C,CAEA,GAAI,GAEJ,GACE,KAAM,IACJ,SACE,GAAQ,KAAM,IAAY,GAExB,GAAS,MACT,MAAM,QAAQ,IACd,EAAM,MAAM,KAGhB,CAAE,UAAW,EAAe,EAAU,cAAe,MAGvD,MAAO,UAGJ,EAAP,CACA,AAAI,EAAI,OAAS,UACf,KAAS,MAAM,oCAAqC,GAGxD,GAAM,GAAI,KAAM,IAAY,eAAQ,EAAY,CAAE,cAAe,MAE3D,EAAM,GACV,EAAE,OAAO,IAAI,GAAO,EAClB,SAAU,EAAG,KACb,OAAQ,EAAG,SACX,YAAa,EAAG,iBAElB,GAAM,EAAG,UAGX,GAAI,EAAE,WAAa,IACjB,GAAI,CAEF,KAAM,IAAc,EAAO,GAC3B,KAAS,MAAM,yCAA0C,CACvD,aACA,UAAW,EAAE,kBAER,EAAP,CACA,KAAS,MAAM,mCAAoC,GAGvD,MAAO,GD7HF,YAAqE,CAM1E,YAAqB,EAAc,EAAkC,CAAhD,YACnB,AAAI,GAAe,GAEjB,MAAK,OAAS,EAAE,OAChB,KAAK,YAAc,EAAE,aAErB,MAAK,OAAS,EAAE,SAChB,KAAK,YAAc,EAAE,eAGnB,YAAa,WACf,MAAK,KAAO,EAAE,KACd,KAAK,QAAU,EAAE,WAKjB,GAAS,EAAK,IAAM,EAAS,mBAE5B,QAAuD,CAiB5D,YAAqB,EAAsB,EAAoB,CAA1C,WAAsB,cACzC,KAAK,WAAa,YAAK,KAAK,IAAK,EAAO,MACxC,KAAK,IAAM,GAAgB,EAAO,MAAM,gBAG7B,KAAI,EAAkD,CACjE,GAAM,GAAI,GAAgB,GAC1B,GAAI,CACF,GAAM,GAAI,KAAM,YAAK,GACrB,MAAO,IAAI,IAAe,EAAE,IAAK,GAAI,IAAW,EAAE,KAAM,SACxD,CACA,aAIE,SAAQ,EAAgB,CAC5B,MAAO,IAAe,IAAI,YAAK,KAAK,WAAY,GAAG,OAMjD,OAAO,CACT,MAAO,MAAK,OAAO,QAMjB,OAAO,CACT,MAAO,IAAY,KAAK,KAAM,KAAK,QAGjC,YAAsB,CACxB,MAAO,MAAK,WAAW,MAAM,QAG/B,UAAW,CACT,MAAO,MAAK,WAGd,QAAS,CACP,MAAO,MAAK,OAAO,OAGrB,aAAc,CACZ,MAAO,MAAK,OAAO,eAGjB,SAAS,CACX,MAAO,MAAK,MAAQ,aAAM,KAAK,KAAK,IAGtC,QAAmC,CACjC,GAAM,GAAI,GAAgB,KAAK,KAC/B,MAAO,GAAE,MAAQ,KAAK,IAClB,KACC,GAAI,IAAe,EAAE,IAAK,CACzB,KAAM,EAAE,KACR,OAAQ,GACR,YAAa,GACb,QAAS,OACT,KAAM,cAIR,aAAa,CACjB,GAAI,CACF,MAAO,AAAC,MAAK,cAER,MAAM,IAAS,KAAK,aAAa,IAAI,GAAM,EAAG,UAD/C,aAEG,EAAP,CACA,KAAS,KACP,kCAAoC,KAAK,WAAa,IACtD,GAEF,aAIE,WAAW,CACf,GAAI,CACF,MAAK,MAAK,cAEH,AADK,MAAM,IAAS,KAAK,aACrB,IACT,GACE,GAAI,IACF,KAAK,WACL,GAAI,IAAW,EAAG,SAAU,KANT,aASlB,EAAP,CACA,KAAS,KACP,gCAAkC,KAAK,WAAa,IACpD,GAEF,aAIE,sBAAqB,EAAyB,CAClD,OAAW,KAAM,GAAI,KAAM,MAAK,YAC9B,KAAO,GAAG,SACN,EAAE,GACF,EAAG,cACH,EAAG,qBAAqB,GACxB,aAIF,uBAAsB,EAA0C,CACpE,GAAM,GAAc,GACpB,YAAM,MAAK,qBAAqB,KAAM,IAAM,CAC1C,AAAI,AAAU,KAAM,GAAE,KAAlB,IAAwB,EAAI,KAAK,KAEhC,EAGT,MAAO,CACL,MAAO,YAAK,KAAK,YAAY,MAAM,IAAG,SAGlC,OAA6B,CACjC,MAAO,IAAW,KAAK,OAAO,KAAM,IAClC,EAAQ,KAAK,OAAQ,GAAM,EAAG,YAI5B,UAAgC,CACpC,MAAO,IAAW,KAAK,OAAO,QAAS,IACrC,EAAQ,KAAK,OAAQ,GAAM,EAAG,UAIlC,SAAU,CACR,MAAO,cAAO,KAAK,cM3LhB,GAAM,IAAuB,GAE7B,gBAA4C,GAAa,CAC9D,aAAc,CACZ,MAAM,IAEN,EAAM,IAAM,GAAc,GAAQ,KAAK,cAAc,KACrD,EAAM,IAAM,EAAa,IAAM,KAAK,UAEpC,KAAK,GAAG,SAAU,CAAC,EAAI,IAAM,GAAG,SAGlC,cAAc,EAAmB,CAG/B,EAAM,GACF,KAAK,QACL,KAAK,MAAM,CAAC,EAAG,IAAM,CACnB,AAAI,EAAE,WAAW,IACf,EAAE,YCzBd,OAA6C,qBAMtC,oBAAyB,aAAU,CAGxC,aAAc,CACZ,MAAM,CAAE,WAAY,GAAO,YAAa,UAGpC,YACJ,EACA,EACA,EACA,CACA,GAAM,GAAS,GAAI,KAAK,QAAU,EAAI,IAAQ,MAAM,IAC9C,EAAO,EAAM,MAEnB,KAAK,OAAS,IAAS,GAAK,OAAY,EACxC,OAAW,KAAM,GACf,AAAK,KAAK,KAAK,IACb,KAAM,IAAW,GAGrB,IAGF,OAAO,EAA+B,CACpC,AAAI,KAAK,QAAU,MAAM,KAAK,KAAK,KAAK,QACxC,KAAK,OAAS,OACd,MCjCJ,OAA2C,qBCepC,YAAuB,EAA0B,CACtD,MACE,IAAK,MAAQ,EAAS,EAAE,OAAS,EAAS,EAAE,KAAO,GAAO,EAAG,IAAK,EAAE,KAIxE,GAAM,IAAY,WAEX,YAAyB,EAAgB,CAC9C,AAAI,GAAc,IAChB,GAAa,KAAK,GAAW,OACxB,GADwB,CAE3B,IAAK,GAAM,GAAM,EAAG,IAAK,EAAE,SAK1B,YAAuB,EAAmC,CAC/D,GAAa,GAAG,GAAW,GAGtB,YAAmC,EAAmC,CAC3E,MAAO,IAAa,eAAe,GAAW,GC9BzC,YACL,EACA,EACA,EAAc,GACA,CACd,GAAI,GAAO,EAAc,KAAK,MAAQ,EAAS,EAC3C,EAAQ,EACN,EAAS,IAAI,IAAgB,CACjC,GAAM,GAAM,KAAK,MACjB,GAAI,GAAO,EACT,SAAO,EAAM,EACb,IACO,EAAE,GAAG,IAKhB,SAAE,MAAQ,IAAM,EACT,EFbT,GAAM,IAAoB,IAEnB,QAA2B,CAIhC,YACW,EACA,EACA,EAAqB,GAC9B,CAHS,eACA,aACA,kBANM,WAAQ,KAAK,MAQ5B,KAAK,KAAO,GACV,IAAM,CACJ,GAAgB,OACX,KAAK,SADM,CAEd,IAAK,KAAK,IACV,UAAW,KAAK,cAGpB,KAAK,WACL,IAIJ,aAAa,EAAqB,CAChC,KAAK,WAAW,EAAc,EAAO,KAAK,QAAS,IAGrD,WAAW,EAAkB,CAC3B,KAAK,QAAU,GACb,EACA,KAAK,MACL,EAAO,EAAS,EAAO,KAAK,QAAS,GAAK,IAE5C,KAAK,UAGH,MAAM,CACR,MAAO,IAAO,IAAM,EAAO,KAAK,QAAS,GAAM,KAAK,UAGlD,YAAY,CACd,MAAO,MAAK,MAAQ,KAAK,QAItB,QAA2B,CAKhC,YACW,EACA,EACA,EACA,EAAqB,GAC9B,CAJS,WACA,aACA,gBACA,kBARM,WAAQ,KAAK,MAU5B,KAAK,WAAa,GAChB,IAAM,EAAQ,KAAK,WAAY,GAAM,KAAK,KAAK,IAC/C,KAAK,YAEP,KAAK,MAAQ,mBAAY,IAAM,KAAK,aAAc,IAGpD,QAAW,EAA2B,CAEpC,SAAE,KAAK,IAAM,KAAK,aAAa,MAAM,IAAM,KAAK,OACzC,EAGD,KAAK,EAAwB,CACnC,EAAI,EAAS,GACX,GAAgB,OACX,KAAK,KADM,CAEd,IAAM,IAAM,GAAM,EAAG,KAAK,MAAO,GAAO,KAAK,MAC7C,UAAW,KAAK,MAAQ,KAAK,UAKnC,WAAY,CACV,AAAI,KAAK,MAAQ,KAAK,MAAQ,IAC5B,KAAK,KAAK,KAAK,OAEjB,KAAK,MAGP,KAAM,CACJ,EAAI,KAAK,MAAO,GAAM,qBAAc,IACpC,KAAK,MAAQ,SGrGjB,OAA8B,mBAC9B,GAAoB,sBCDpB,OAA4B,iBAC5B,GAAwB,mBAGjB,YAAmB,EAAwB,CAChD,GAAM,GAAM,GACZ,KAAO,IAAS,eAAQ,IACtB,EAAO,eAAQ,GACf,EAAI,KAAK,GAEX,MAAO,GAGF,YAAsB,EAAwB,CACnD,GAAI,CACF,MAAO,mBAAY,SACZ,EAAP,CACA,MAAO,IAGJ,YAAqB,EAAc,EAA+B,CACvE,GAAM,GAAS,GAAa,GAC5B,MAAO,GAAW,MAAM,GAAM,EAAO,SAAS,IDbzC,GAAM,IAAU,EAAK,IAAM,eAAQ,QAAQ,WAEjC,GAAV,UAAU,EAAV,CACE,AAAM,OAAO,EAAK,IAAM,CAC7B,GAAM,GAAc,CAAC,MAAO,aAAc,SAAU,SAC9C,EAAiB,GACvB,AAAI,MACF,EAAK,KAAK,WAER,IACF,EAAK,KACH,YAAK,KAAW,aAChB,YAAK,KAAW,KAAM,cAG1B,EAAK,KAAK,GAAG,EAAc,CAAC,KAAW,aAAO,aAC9C,GAAY,GACZ,OAAW,KAAO,GAAM,CACtB,GAAI,GAAY,EAAK,GAAc,MAAO,GAE1C,OAAW,KAAU,IAAU,GAAK,MAAM,EAAG,GAAI,CAC/C,GAAI,GAAY,EAAQ,GAAc,MAAO,GAC7C,GAAM,GAAM,YAAK,EAAK,eAAgB,kBACtC,GAAI,GAAY,EAAK,GAAc,MAAO,IAG9C,KAAM,IAAI,OAAM,0CAA4C,KAE9D,GAAM,GAAS,AAAC,GAAkB,EAAK,IAAM,YAAK,SAAQ,IACnD,AAAM,MAAM,EAAO,OACb,MAAM,EAAO,OACb,aAAa,EAAO,cACpB,SAAS,EAAO,UAChB,QAAQ,EAAO,SACf,QAAQ,EAAO,SAE5B,iBAA8B,EAAkB,SAAQ,CACtD,MAAK,IAgBE,AAJO,GAAI,QAChB,iBAAiB,eAA0B,YAC3C,KAEW,KAAK,IAAoB,KAhBnB,GADrB,EAAsB,YAlCP,aERV,YACL,EACA,EACA,EACO,CACP,GAAM,GAAI,GAAI,IAAQ,EAAK,EAAQ,IACnC,SAAE,KAAK,GACA,EAAE,KAOJ,YAAc,CAInB,YACW,EACA,EACA,EAAe,GACxB,CAHS,WACA,cACA,oBANH,qBAAkB,GACjB,UAAO,GAAI,IAQpB,QAAQ,EAAwB,CAC9B,GAAI,GAAS,KAAM,OAEnB,GAAM,GAAQ,AADJ,MAAK,gBAAkB,EAAM,YACvB,MAAM,KAAK,KAK3B,KAAK,gBAAkB,EAAM,MAC7B,EAAM,QAAQ,GAAM,CAClB,AAAI,EAAC,KAAK,cAAgB,EAAS,KACjC,KAAK,OAAO,KAKlB,OAAQ,CACN,KAAK,QAAQ,IACT,EAAS,KAAK,kBAAkB,KAAK,OAAO,KAAK,iBACrD,KAAK,gBAAkB,GAGzB,KAAK,EAA0B,CAC7B,SAAE,GAAG,OAAQ,GAAM,KAAK,QAAQ,IAChC,EAAE,GAAG,MAAO,IAAM,CAChB,KAAK,QACA,KAAK,KAAK,YAEV,OxB4BJ,GAAM,IAAY,EAAQ,OAAS,IAuBpC,GAAQ,GAAI,IAOX,QAAqC,CAkBhC,YAAY,EAA4B,EAAyB,CAAzB,cAjB/B,WAAQ,EAAK,IAC9B,EAAS,YAAc,KAAK,WAAa,MAmL1B,4BAAyB,EAAK,IAC7C,EAAQ,KAAK,iBAAkB,GAAM,EAAG,aA6WjC,UAAO,EAEd,IACE,KAAK,KAAK,OAAQ,IAAM,WAAI,KAAK,KAAK,YAAY,MAAM,IAAG,KAC7D,GAAS,SAGF,cAAW,EAElB,IACE,KAAK,SAAS,WAAY,IAAM,GAAI,IAAM,WAAG,SAAS,KAAK,cAC7D,GAAS,SA6PF,eAAY,EAAK,SAAY,CACpC,GAAM,GAAO,KAAM,MAAK,OACxB,GAAI,IAAS,GAAK,GAAQ,KACxB,OAEF,GAAM,GACJ,EAAO,EAAI,GACP,GAAI,IACF,CAAE,GAAI,mBAAoB,KAAM,KAAK,YACrC,GAEF,OACA,EAAS,KAAM,IAAa,IAChC,KAAK,KAAK,MAAO,IAAM,GAAQ,CAAC,KAAK,YAAa,CAAE,eAEhD,EAAM,EAAI,EAAO,OAAQ,GAAM,EAAG,SAAS,WACjD,MAAO,CACL,UAAW,EAAO,UAClB,OAAQ,EAAO,OACf,QAED,GAAS,SA7yBV,GAAI,GAAU,KACZ,KAAK,WAAa,EAAO,WACzB,KAAK,IAAM,EAAO,IAClB,KAAK,KAAO,EAAO,KACnB,KAAK,KAAO,EAAO,KACnB,KAAK,IAAM,EAAO,QACb,CACL,KAAK,WAAa,GAAQ,GAC1B,GAAM,GAAS,GAAgB,KAAK,YACpC,KAAK,IAAM,EAAO,IAClB,KAAK,KAAO,EAAO,KACnB,KAAK,KAAO,EAAO,KACnB,KAAK,IAAM,EAAO,IAEpB,KAAK,UAAY,GAAa,KAAK,YAEnC,GAAM,IAAI,EAAY,MAGxB,QAAS,CACP,MAAO,CACL,WAAY,KAAK,aAIpB,WAAQ,SAAU,CACjB,MAAO,MAAK,qBAGD,mBACX,EACiB,CACjB,GAAM,GAAM,EAAQ,GACd,EAAQ,KAAM,SAAQ,IAAI,EAAI,IAAI,GAAK,EAAE,UAC/C,MAAO,GAAI,GAAW,UAYjB,UAAS,EAAoC,CAClD,MAAO,aAA2B,IAC9B,EACA,KAAK,IAAI,EAAgB,MAAM,KAAK,KAAK,eAGxC,mBAAkB,EAAoB,CAC3C,MAAO,MAAK,IAAI,EAAG,WAAY,SAG1B,KAAI,EAAqC,EAAyB,CACvE,GAAI,YAA4B,IAC9B,MAAO,GAGT,GAAM,GAAQ,GAAM,IAAI,GACxB,GAAI,GAAS,KAAM,MAAO,GAC1B,GAAM,GAAe,GAAQ,GAC7B,MAAO,IAAM,SACX,EACA,IAAM,GAAI,IAAS,EAAc,UAa9B,OAAM,EAAmB,CAC9B,GAAgB,GAGlB,IAAI,EAAc,EAA+B,CAC/C,MAAO,IAAS,IAAI,EAAM,GAG5B,OAAc,CACZ,YAAK,OAAS,OACd,KAAK,uBAAuB,QAC5B,KAAK,KAAK,QACV,KAAK,SAAS,QACd,KAAK,UAAU,QACR,KAGT,oBAA2B,CACzB,UAAgB,KAAK,KACd,KAGT,UAAW,CACT,MAAO,MAAK,WAGd,SAAU,CACR,MAAO,MAAK,UAGd,IAAI,EAAyC,CAC3C,MAAO,IAAQ,KACX,GACA,YAAgB,IAChB,KAAK,aAAe,EAAK,WACzB,KAAK,aAAe,GAAS,IAAI,GAAM,cAGzC,QAAQ,CACV,MAAO,IAAM,KAAK,eAMhB,iBAAyB,CAC3B,MAAQ,MAAK,OACT,IACA,KAAK,SAAS,OACd,IAAM,KAAK,KACV,MAAK,SAAS,SAAS,OAAS,IAAM,IACvC,KAAK,SAAS,KACd,IACA,KAAK,MACP,eAMA,sBAA8B,CAChC,MAAQ,MAAK,OACT,IACA,KAAK,SAAS,OACd,KAAK,eACL,KAAK,SAAS,eAAiB,IAAM,KAAK,MAC5C,YAGJ,cAAc,EAAwB,CACpC,MAAO,IAAc,EAAM,WAGvB,iBAA+C,CACnD,MAAI,MAAK,QAAU,MACjB,MAAK,OAAS,KAAM,GAClB,KAAK,OACL,GAAM,GAAI,IAAe,KAAK,IAAK,GAAI,IAAW,KAAK,KAAM,MAG1D,KAAK,YAOR,uBAAsB,EAA+B,CACzD,GAAM,GAAU,KAAM,MAAK,yBAC3B,MAAO,IAAW,MAAQ,GAAK,MAAQ,EAAQ,GAC3C,EACA,KAAM,IAAY,EAAS,GAGjC,qBAAqB,EAAoB,CACvC,MAAO,MAAK,IAAI,YAAK,KAAK,WAAY,EAAG,MAAO,GAMlD,YAAa,CACX,MAAO,GAAQ,KAAK,wBAAyB,GAAO,EAAI,IAAI,GAAM,EAAG,YAGjE,UAAS,EAA6D,CAC1E,MAAQ,MAAM,MAAK,sBAAsB,KAAa,IAAI,GACxD,KAAK,qBAAqB,SAIxB,YAAW,EAA2C,CAE1D,GAAM,GAAiB,GACvB,OAAW,KAAM,GAAI,KAAM,MAAK,yBAC9B,GAAI,EAAG,SAAU,CACf,GAAM,GAAK,KAAK,qBAAqB,GACrC,AAAI,IAAK,MAAS,KAAM,GAAE,KACxB,EAAO,KAAK,GAIlB,MAAO,QAGH,kBAAiB,EAAmD,CACxE,MAAO,GAAQ,KAAK,wBAAyB,GAC3C,GACE,EACG,OAAO,GAAM,EAAG,eAChB,IAAI,KAAM,IAAM,GAAM,KAAK,qBAAqB,GAAK,MAQ9D,cAAuB,CACrB,MAAO,GACL,KAAK,SAAS,eAAgB,IAC5B,WAAG,YAAY,KAAK,YAAY,IAAI,GAAM,KAAK,KAAK,KAEtD,SAIE,aAAY,EAAuB,CACvC,GAAM,GAAmB,KAAM,MAAK,aACpC,MAAO,GAAW,GACd,GAAY,EAAkB,GAC9B,EAAW,QAGX,gBAAgB,CACpB,MAAQ,MAAM,MAAK,UAAa,EAAQ,KAAM,MAAK,mBAM/C,kBACJ,EACe,CACf,MAAO,GAAQ,KAAK,WAAY,KAAM,IAAY,CAChD,OAAW,KAAS,GAClB,KAAM,GAAM,iBAAiB,GAC7B,KAAM,GAAE,UAUR,aAAY,EAAkD,CAClE,GAAM,GAAiB,GACvB,OAAW,KAAM,GAAI,KAAM,MAAK,cAC9B,AAAI,KAAM,GAAU,IAAK,EAAO,KAAK,GAGvC,GAAM,GAAO,KAAM,MAAK,mBACxB,GAAI,GAAQ,KACZ,YAAM,IAAuB,CAC3B,KAAM,cACN,OAAQ,EAAK,IAAI,GAAO,IACtB,EAAQ,EAAI,YAAY,GAAY,GAAM,EAAO,KAAK,GAAG,OAGtD,OAGH,sBAAqB,EAA0C,CACnE,MAAI,MAAM,MAAK,YAAY,GAClB,KACE,KAAK,OACd,OAEO,KAAK,SAAS,qBAAqB,QAIxC,UAAS,EAAqD,CAClE,GAAM,GAAI,KAAK,SACf,MAAQ,MAAM,MAAK,wBAAwB,KAAK,IAAI,GAClD,EAAE,qBAAqB,SAIrB,yBACJ,EACgC,CAChC,MAAO,MAAK,SAAS,sBACnB,KAAM,IAAM,EAAG,OAAS,KAAK,MAAS,IAAK,MAAS,KAAM,GAAE,UAI1D,kBAAkB,CACtB,MAAO,MAAK,SAAS,gBAGjB,8BAA6C,CACjD,MAAO,MAAK,QAAW,KAAM,MAAK,SAC9B,KACA,KAAK,SAAS,iCAOhB,YAAsB,CACxB,MAAO,MAAK,WAAW,MAAM,QAAK,OAAO,GAAM,GAAM,MAAQ,IAAO,OAGlE,wBAAkC,CACpC,MAAO,GAAQ,KAAK,UAAU,MAAM,GAAK,KAAK,aAM5C,QAAgB,CAClB,MAAO,MAAK,UAAU,OAAU,GAAQ,EAAI,MAG1C,SAAkB,CACpB,MAAO,MAAK,UAAU,SAAY,GAAQ,EAAI,GAOhD,KAAK,EAAgB,EAAS,CAE5B,MAAO,MAAK,OAAS,EAAQ,KAAO,KAAK,SAAS,KAAK,GAGzD,QAAe,CAEb,MAAO,MAAK,OAAS,KAAQ,KAAK,IAAI,KAAK,KAG7C,aAAa,EAA2C,CACtD,MACE,IAAmB,MAClB,MAAK,aAAe,EAAgB,YAEnC,GAAW,EAAgB,UAAW,KAAK,YAIjD,eAAe,EAAyC,CACtD,MAAO,IAAiB,MAAQ,EAAc,aAAa,MAG7D,gBAAyB,CACvB,MAAO,CAAC,GAAG,KAAK,UAAW,MAG7B,eAAe,EAAuB,CACpC,MAAO,CACL,KACA,GAAI,KAAK,QAAU,GAAS,EACxB,GACA,KAAK,SAAS,eAAe,EAAQ,IAO7C,SAAkB,CAChB,GAAM,GAAI,KAAK,SAGf,MAAO,MAAK,OAAS,GAAK,CAAC,GAAG,EAAE,UAAW,QAgBvC,YAAgC,CAEpC,MAAI,MAAK,MAAc,KAElB,KAAM,MAAK,UAAa,KAAK,OAAe,KAE1C,EAAQ,KAAK,SAAS,YAAa,KAAM,IAAK,CAGnD,GAAM,GAAe,KAAM,GAAE,aAE7B,GAAI,EAAW,GAAe,CAC5B,OAAW,KAAM,GACf,GAAI,IAAO,KAAK,KAAM,MAAO,GAAE,KAAK,GAGtC,GAAM,GAAiB,KAAK,KAAK,YACjC,OAAW,KAAM,GACf,GAAI,EAAG,cAAgB,EAAgB,MAAO,GAAE,KAAK,GAGvD,GAAI,IAAS,GACX,OAAW,KAAM,GACf,GAAI,GAAiB,EAAI,KAAK,MAAO,MAAO,GAAE,KAAK,OAS7D,QAAQ,EAAoB,CAC1B,MAAO,MAAK,SAAS,KAAK,GAG5B,WAAW,EAAsB,CAC/B,MAAO,MAAK,QAAQ,EAAS,KAAK,MAGpC,eAAe,EAAsB,CACnC,MAAO,MAAK,QAAQ,KAAK,KAAO,EAAS,KAAK,KAGhD,UAAU,EAAoC,CAC5C,MACE,MAAK,aAAe,EAAgB,YACpC,KAAK,MAAQ,EAAgB,IAOjC,QAAQ,EAAuB,CAC7B,MAAI,GAAQ,IAAU,GAAI,CAAC,KAAM,GAAe,KACzC,GAAW,EAAM,IACpB,KAAK,IAAI,YAAK,GAAG,IACjB,KAAK,IAAI,YAAK,KAAK,WAAY,GAAG,IAGxC,QAAQ,EAAI,GAAI,MAAqB,CACnC,MAAO,IACL,GAAG,cACH,GAAG,WACH,GAAG,UACH,CAAC,EAAM,EAAO,IAAQ,KAAK,KAAK,EAAI,GAAO,GAAK,EAAQ,GAAI,GAAK,KAQrE,SAAS,EAAuB,CAC9B,GAAI,EAAQ,GAAQ,MAAO,MAC3B,GAAM,GAAe,GAAQ,EAAM,IAAI,GAAM,EAAG,MAAM,UAAO,OAC3D,GAAM,IAAO,MAGf,MAAO,MAAK,KAAK,GAAG,QAQN,MACd,EACA,EACA,EAAwB,OACP,CACjB,GAAI,CACF,MAAO,MAAM,IAAK,MAAQ,EAAY,SAQ/B,EAAP,CACA,KAAK,QAAQ,IAAI,EAAa,SAAS,eAAwB,KAC/D,aAKY,QACd,EACA,EACA,EAAwB,OACN,CAClB,GAAI,CACF,YAAK,QAAQ,MAAM,UAAU,OAC7B,KAAM,KACC,SACA,EAAP,CACA,YAAK,QAAQ,IAAI,EAAa,WAAW,eAAwB,KAC1D,IAID,SAAY,EAAoB,EAAsB,CAC9D,GAAI,CACF,YAAK,QAAQ,MAAM,YAAY,OACxB,UACA,EAAP,CACA,KAAK,QAAQ,KAAK,aAAa,eAAwB,KACvD,aAkBE,SAA2B,CAC/B,MAAO,MAAK,QAAU,MAAS,KAAM,IAAY,KAAK,QAGxD,YAAsB,CACpB,MAAO,MAAK,QAAU,MAAQ,KAAK,YAAc,UAG7C,YAA8B,CAClC,MAAO,IAAQ,KAAK,UAGtB,OAA4B,CAC1B,MAAO,GAAQ,KAAK,OAAQ,GAAK,EAAE,OAGrC,SAAgC,CAC9B,MAAO,GAAQ,KAAK,OAAQ,GAAK,KAAK,MAAM,EAAE,UAGhD,UAAiC,CAC/B,MAAO,GAAQ,KAAK,OAAQ,GAAK,GAAS,EAAE,aAGxC,kBAAwC,CAC5C,MAAO,GAAQ,KAAK,OAAQ,GAAK,EAAE,MAAM,eAU3C,WAAoC,CAClC,MAAO,GAAQ,KAAK,OAAQ,GAG1B,EACE,CAAC,EAAE,YAAa,EAAE,QAAS,EAAE,SAAS,OACpC,GAAM,GAAM,MAAQ,IAAO,KAMnC,WAAkC,CAChC,MAAO,GAAQ,KAAK,YAAa,IAGnC,aAAkC,CAChC,MAAO,GAAQ,KAAK,YAAa,GAAM,GAAI,MAAK,IAGlD,WAAkC,CAChC,MAAO,GAAQ,KAAK,YAAa,IAGnC,aAAkC,CAChC,MAAO,GAAQ,KAAK,YAAa,GAAM,GAAI,MAAK,IAGlD,MAA6B,CAC3B,MAAO,GAAQ,KAAK,OAAQ,GAAK,EAAE,WAG/B,QAAO,EAAgC,CAC3C,GAAI,CACF,YAAM,YAAI,OAAO,KAAK,WAAY,GAC3B,QACP,CACA,MAAO,IAOX,cAAe,CACb,MAAO,MAAK,OAAO,WAAG,UAAU,KAAQ,GAAQ,EAAI,WAAG,UAAU,OAGnE,YAA+B,CAC7B,MAAO,MAAK,OAAO,WAAG,UAAU,MAGlC,eAAkC,CAChC,MAAO,IAAQ,KAAK,cAGtB,gBAAmC,CACjC,MAAO,MAAK,OAAO,WAAG,UAAU,KAAO,WAAG,UAAU,MAGtD,mBAAsC,CACpC,MAAO,IAAQ,KAAK,kBAGtB,eAAyB,CACvB,MAAO,MAAK,KAAK,WAAW,UAGxB,SAAQ,EAAuB,EAAqB,CACxD,GAAI,KAAM,MAAK,cACb,MAAO,GAAW,KAAM,MAAK,cACxB,CACL,GAAM,GAAI,KAAM,MAAK,OACrB,MAAO,IAAK,MAAQ,GAAK,GAI7B,WAAW,EAAe,EAAqB,CAC7C,MAAO,IAAQ,KAAK,QAAQ,SAGxB,gBAAe,EAAe,EAAqB,CACvD,MAAQ,MAAM,MAAK,UAAc,KAAM,MAAK,WAAW,QAGnD,aAAY,EAAoC,CACpD,MAAO,GACL,KAAK,QACL,GAEE,GAAS,IAAc,GAAS,SAIhC,iBACJ,EACA,EACuB,CACvB,MAAO,GACL,KAAK,UACL,GAAe,KAAK,IAAI,EAAc,IAAY,QAIhD,UAAS,EAAiC,CAC9C,GAAM,GAAQ,KAAM,MAAK,YACzB,MAAO,IAAS,MAAQ,EAAQ,KAAK,MAAQ,OAGzC,YAAW,EAA2C,CAC1D,GAAI,GAAS,KACb,MAAO,GACL,KAAK,QACL,GAEE,GAAS,GAAa,GAAS,SAI/B,cAAgC,CACpC,MAAI,MAAK,QAAU,KAAa,KAAK,OAAO,cACrC,GACL,KAAK,OACL,GAAM,EAAG,cACT,IAAM,SAIJ,iBAAmC,CACvC,MAAO,IAAQ,KAAK,eAGtB,iBAA2B,CACzB,MAAI,MAAK,QAAU,KAAa,KAAK,OAAO,cACrC,EACL,KAAK,WACL,GAAM,EAAG,cACT,IAAM,SAIJ,aAA4B,CAChC,MAAQ,MAAM,MAAK,cAAiB,KAAO,KAAK,cAG5C,SAA2B,CAC/B,MAAI,MAAK,QAAU,KAAa,KAAK,OAAO,SACrC,KAAK,OAAO,KAAK,GACtB,EAAI,GACD,IAAI,GAAM,EAAG,UACb,UAAU,IAAM,KAIvB,YAAsB,CACpB,MAAI,MAAK,QAAU,KAAa,KAAK,OAAO,SACrC,EAAI,KAAK,YAAY,OAAO,GAAM,EAAG,UAAU,UAGxD,MAAM,EAAwB,OAA0B,CACtD,YAAK,QACE,KAAK,OAAO,QAAS,IAAM,WAAI,MAAM,KAAK,YAAa,QAM1D,UAAyB,CAE7B,GAAI,CACF,KAAM,YAAI,OAAO,KAAK,kBACf,EAAP,CAEA,GAAI,EAAI,OAAS,SAAU,KAAM,GASnC,GAEE,AACC,KAAM,IAAU,IAAM,KAAK,QAAQ,cAAe,CACjD,UAAW,EAAI,EACf,cAAe,QAHjB,GAMA,KAAM,IAAI,OAAM,oBAAsB,MAGtC,MAAO,MAAK,0BAIV,SAA6B,CACjC,MAAK,MAAM,MAAK,QAAQ,eAAkB,KAAK,OAAe,KACvD,KAAK,KAAK,SAAU,SAAY,KAAK,WAM9C,aAAoB,CAClB,kBAAI,WAAW,KAAK,YACb,KAAK,qBAGd,YAA0B,CACxB,MAAI,MAAK,OAAe,KACjB,KAAK,SAAS,aAAc,IAAM,KAAK,eA6BhD,KAA4B,CAC1B,MAAO,GAAQ,KAAK,YAAa,GAAK,EAAE,KAM1C,OAA8B,CAC5B,MAAO,GAAQ,KAAK,YAAa,GAAK,EAAE,gBAOpC,cACJ,EACA,EACoB,CACpB,YAAM,IACJ,EAAQ,CACN,EACA,EAAI,GAAS,WAAY,GAAK,GAAI,IAAY,IAC9C,WAAI,kBAAkB,KAAK,WAAY,MAGpC,KAAK,0BAGR,gBACJ,EACA,EAGI,GACgB,CAGpB,MAAO,MAAK,KAAK,iBAAkB,IAAM,KAAK,WAAW,EAAQ,SAM7D,YACJ,EACA,EAGI,GACgB,CAGpB,YAAM,MAAK,SAAS,SAGpB,KAAM,YAAI,UACR,KAAK,WACL,EAAU,EAAQ,EAAQ,SAAU,EAAQ,QAC5C,GAAE,KAAM,KAAQ,IAEX,KAAK,qBAGd,SAAY,EAAwB,OAAyB,CAC3D,MAAO,MAAK,KACV,WACA,IACE,GACE,SACG,KAAM,MAAK,iBACR,WAAI,SAAS,KAAK,YAClB,OACN,CACE,WAAY,EACZ,iBAAkB,IAAM,GAAM,IAAgB,OAAS,IAAM,IAC7D,iBAAkB,GAAO,EAAI,QAAa,KAGhD,GAIJ,cAA2B,CACzB,MAAO,MAAK,SAAS,eAAgB,IACnC,WAAI,aAAa,KAAK,aAI1B,eAAgB,CACd,MAAO,YAAI,aAAa,KAAK,YAG/B,WAAY,CACV,MAAO,YAAI,SAAS,KAAK,YAG3B,SAAS,EAAwB,OAA8B,CAC7D,MAAO,MAAK,KAAK,WAAY,IAAM,KAAK,YAAa,QAOjD,YAAW,EAGQ,CACvB,MAAO,IAAe,KAAK,WAAY,QAGnC,MAAK,EAAkE,CAC3E,MAAO,MAAK,KAAK,OAAQ,IAAM,EAAQ,KAAK,WAAW,GAAU,SAG7D,WAAU,EAAY,EAA4C,CACtE,MAAO,MAAK,KAAK,YAAa,SAC5B,MAAM,GAAK,SAAS,SACpB,KAAM,IACJ,KAAK,WACL,WAAG,kBAAkB,EAAK,YAC1B,GAEK,IAIX,WAAoC,CAClC,MAAO,GAAQ,KAAK,WAAY,GAAO,GAAW,EAAI,aAGxD,cAA8B,CAC5B,MAAO,IAAI,IAAM,EAAI,WAAG,aAAa,KAAK,YAAa,IAMzD,UAAU,EAAa,CACrB,MAAO,MAAK,WAAW,GAAK,SAMxB,YAAW,EAAuB,CAEtC,YAAM,MAAK,SAAS,SACpB,KAAM,YAAI,UAAU,KAAK,WAAY,GAC9B,KAAK,qBAGd,IAAI,EAAY,GAAiB,CAC/B,MAAO,MAAK,QAAQ,EAAY,KAAK,WAMjC,QAAO,EAAY,GAA0B,CACjD,GAAM,GAAO,KAAK,QAAQ,GAAY,KAAK,KAAM,IACjD,MAAO,MAAK,IAAI,EAAM,CAAE,UAAW,UAGvB,MAAK,EAAoC,CACrD,GAAM,GAAY,EAAc,QAChC,MAAQ,GAAS,KAAK,MAAQ,EAAM,EAAU,MAC3C,KAAM,GAAU,cACf,EAAU,KAAK,KAAK,MACpB,EAcN,UAAU,EAAoC,CAC5C,MAAO,IAAK,cAAe,SAAY,CACrC,GAAM,GAAQ,MAAM,MAAK,KAAK,IAAgB,QAC9C,GAAI,KAAK,aAAe,EAAK,WAC3B,MAAO,MAGT,GAAI,AADU,KAAM,GAAK,SAAS,UACrB,KAAM,MAAO,MAAK,QAAQ,MAAM,iBAAmB,EAAK,KAErE,GAAI,CACF,MAAO,MAAM,MAAK,UAAU,SACrB,EAAP,CACA,GAAI,GAAoB,GACtB,KAAM,GAEN,YAAK,QAAQ,KAAK,2CAA4C,CAC5D,IAAK,KAAK,WACV,KAAM,EAAK,WACX,UAEK,KAAM,MAAK,gBAAgB,UAEpC,CACA,KAAK,6BAKG,WAAU,EAA2B,CACjD,GAAI,GACA,EACA,EAAS,EACb,GAAI,CACF,GAAM,GAAO,KAAM,IAAW,KAAK,OAAQ,IAAM,KAAK,QAAQ,QAC9D,GAAI,GAAQ,KACV,MAAO,MAAK,QAAQ,MAClB,2BAA6B,IAGjC,GAAI,EAAK,OAAS,EAEhB,KAAM,GAAK,MAAM,EAAK,MAAO,EAAK,WAC7B,CACL,GAAI,EAAS,iBAAiB,gBACvB,KAAM,MAAK,OAAU,KACxB,MAAO,MAAK,QAAQ,MAClB,8BAAgC,IAItC,EAAU,EAAK,MACf,GAAM,GAAI,WAAI,SAAS,KAAK,WAAY,EAAQ,YAChD,AAAI,EAAK,KAAO,EAAI,IAClB,GAAM,GAAI,IACR,CACE,GAAI,UACJ,KAAM,KAAK,WACX,KAAM,EAAK,YAEb,EAAK,KACL,IAAM,EAAS,QAAQ,SAG3B,KAAM,GACN,GAAM,GAAc,KAAM,IACxB,SAAY,EAAK,OAAU,KAAM,GAAS,QAAQ,OAClD,CAAE,UAAW,IAEf,GAAI,EAAS,iBAAiB,eAAgB,CAC5C,GAAM,GACJ,GACC,KAAM,IACL,IAAM,GAAS,KAAK,MAAO,EAAS,QAAQ,OAC5C,CAAE,UAAW,IAEjB,GAAI,CAAC,EACH,MAAO,MAAK,QAAQ,MAAM,qBAAsB,CAC9C,cACA,eAIN,GAAI,CAAC,EACH,MAAO,MAAK,QAAQ,MAAM,qBAAsB,CAC9C,aAAc,EAAK,KACnB,WAAY,KAAM,GAAQ,QAAQ,SAItC,GADA,EAAS,KAAM,GAAQ,SACnB,GAAU,KACZ,MAAO,MAAK,QAAQ,MAClB,aAAe,EAAO,+BAG1B,KAAM,YAAI,OAAO,EAAO,WAAY,EAAK,MAAO,EAAK,OAEvD,GAAI,CACF,KAAM,YAAI,MAAM,EAAO,WAAY,EAAK,YACjC,EAAP,CACA,KAAK,QAAQ,MACX,aAAa,EAAO,0CAA0C,EAAK,SAAS,KAGhF,YAAK,QAAQ,MAAM,aAAa,EAAK,wBACrC,GAAe,KAAK,WAAY,EAAK,YAC9B,QACA,EAAP,CACA,WAAK,QAAQ,KAAK,aAAa,GAAS,uBAAuB,KAC/D,KAAM,IAAS,SACf,KAAM,GAAK,SACL,SACN,CACA,EAAI,EAAK,GAAM,EAAG,aAIhB,gBAAiC,CACrC,MAAO,IACL,KAAK,OACL,GAAS,KAAK,IAAI,EAAc,EAAQ,IACxC,IAAM,QAII,iBAAgB,EAA2B,CACvD,GAAI,GACJ,GAAI,CACF,GAAI,AAAS,KAAM,GAAK,SAAS,UAA7B,KACF,MAAO,MAAK,QAAQ,MAAM,oCAAqC,CAC7D,IAAK,KAAK,WACV,KAAM,EAAK,aAGf,GAAM,GAAO,KAAM,MAAK,OAClB,EAAO,EAAI,EAAM,GAAM,EAAG,MAChC,MAAI,IAAQ,MAAQ,GAAQ,KACnB,KAAK,QAAQ,MAAM,4BAExB,GAAO,EAAI,IACb,GAAM,GAAI,IACR,CACE,GAAI,UACJ,KAAM,KAAK,WACX,KAAM,EAAK,YAEb,EACA,IAAM,EAAK,QAAQ,SAIvB,AAAI,EACF,KAAM,IAAW,WAAW,QAC1B,0BAA0B,GACxB,KAAK,4BACW,GAAU,EAAK,cACjC,GAAM,GAKR,KAAM,IAAO,KAAM,CAAC,KAAM,KAAM,KAAK,WAAY,EAAK,YAAa,CACjE,QAAS,KAAM,MAAK,kBAIxB,GAAe,KAAK,WAAY,EAAK,YAC9B,EAAK,4BACL,EAAP,CACA,MAAO,MAAK,QAAQ,MAAM,mBAAqB,EAAO,MAAQ,UAC9D,CACA,EAAI,EAAK,GAAM,EAAG,aAIhB,OACJ,EAAuB,KAAK,MAC5B,EACoB,CACpB,MAAO,MAAK,KAAK,QAAS,IACxB,EAAQ,KAAK,aAAc,IAAM,KAAK,OAAO,EAAO,UAIlD,QACJ,EACA,EACoB,CACpB,GAAM,GAAS,EAAO,EAAO,KAAK,OAC5B,EAAS,EAAO,EAAO,GAC7B,MAAO,MAAK,KAAK,SAAU,IACzB,WACG,OAAO,KAAK,WAAY,GAAS,GAAS,GAAS,IACnD,KAAK,IAAM,KAAK,4BAQjB,QAAO,EAAwB,OAAQ,CAC3C,MAAO,MAAK,KACV,SACA,SACE,MAAM,YAAI,OAAO,KAAK,YACf,KAAK,sBAEd,QAWE,MAAK,EAAqB,OAA4B,CAC1D,MAAO,MAAK,KAAK,OAAQ,SACvB,MAAK,QAAQ,IAAI,EAAU,UAC3B,KAAM,YAAI,OAAO,KAAK,YACf,KAAK,4BAYV,SAAwB,CAC5B,MAAI,KAAU,KAAM,MAAK,QAAQ,UAC/B,KAAM,IAAO,UAAW,CAAC,SAAU,KAAK,YAAa,CACnD,QAAS,IAGN,UAMH,uBAAsB,EAAwC,CAClE,MAAO,GACL,KAAK,eAAe,GAAY,WAAW,CAAE,WAAY,KACzD,GAAQ,EAAK,OAAO,SAAS,KAAK,IAAM,KAAK,IAAI,UAQ/C,KACJ,EACA,EAAwB,CAAE,UAAW,IACtB,CACf,GAAM,GAAO,KAAM,MAAK,KAAK,GAC7B,GAAI,KAAK,aAAe,EAAK,WAC3B,YAAK,QAAQ,KAAK,cAAe,GAAI,OAAM,mBACpC,KAET,KAAM,GAAK,SAAS,SACpB,KAAK,QAAQ,MAAM,KAAM,GAGzB,GAAI,CACF,KAAM,YAAI,KAAK,KAAK,WAAY,EAAK,WAAY,SAC1C,EAAP,CACA,KAAK,QAAQ,KACX,+EACA,GAEF,KAAM,SAAQ,IAAI,CAAC,KAAK,SAAU,EAAK,WACvC,KAAM,IAAU,IAAM,KAAK,QAAQ,iBAAkB,CACnD,UAAW,EAAI,IAEjB,KAAM,YAAI,KAAK,KAAK,WAAY,EAAK,WAAY,GAEnD,YAAM,GAAK,SACX,KAAK,qBACE,EAAK,0BAMA,QAAO,EAAc,EAAsB,CACvD,MAAO,MAAK,KAAK,UAAY,EAAO,IAAK,SAAY,CACnD,GAAM,GAAO,KAAM,MAAK,QAAQ,GAAM,aACtC,YAAM,IAAc,CAClB,WAAG,iBAAiB,KAAK,YACzB,EACA,WAAG,kBAAkB,EAAK,cAE5B,KAAM,MAAK,SACJ,SAIL,SAA6B,CACjC,MAAO,MAAK,OAAO,GAAY,KAAK,KAAM,OAAQ,4BAG9C,OAA2B,CAC/B,MAAO,MAAK,OAAO,KAAK,KAAO,MAAO,0BAGlC,iBAAqC,CACzC,MAAO,MAAK,OAAO,KAAK,KAAO,MAAO,+BAGxC,YAAiC,CAC/B,MAAO,MAAK,KAAK,aAAc,IAC7B,WAAI,WAAW,KAAK,YAAY,KAAK,IAAM,KAAK,uBAOpD,iBAAkB,CAChB,kBAAI,eAAe,KAAK,YACjB,KAAK,wBAMV,mBAA2B,CAC7B,MAAO,IAAiB,KAAK,SAM3B,mBAA2B,CAC7B,MAAO,MAAK,iBAAmB,KAAK,OAGlC,6BAAqC,CACvC,MAAO,MAAK,SAAS,KAAO,IAAM,KAAK,oBAGrC,sBAA4B,CAC9B,MAAO,MAAK,QAAQ,KAAK,uBAWrB,qBACJ,EACiB,CACjB,MAAO,IAAqB,GAAE,WAAY,KAAK,YAAe,IAMhE,WAAW,EAAkC,GAAmB,CAC9D,MAAO,MAAK,oBAAoB,GAAM,KAAK,GAAK,KAAK,IAAI,SAMrD,eAAc,EAAgC,CAClD,GAAI,KAAM,MAAK,QAAQ,YACrB,KAAM,IAAI,OAAM,kBAAoB,KAAO,mBAE7C,GAAM,GAAK,GAAU,KAAM,IAAW,KAAK,QAAS,IAAM,GAAI,QACxD,EAAU,EACd,EACA,GAAM,KAAK,SAAS,KAAK,GACzB,IAAM,KAAK,UAEb,MAAO,MAAK,IAAI,EAAQ,KAAK,KAAK,KAAO,IAAM,EAAK,KAAK,KAAM,CAC7D,UAAW,UAYT,mBAAkB,EAAkC,CACxD,GAAI,KAAM,MAAK,QAAQ,UAAW,CAEhC,KAAM,MAAK,OAAO,SAClB,OAEF,GAAM,GAAQ,KAAM,MAAK,0BACzB,GAAI,GAAS,KACX,YAAM,MAAK,SACJ,EAET,GAAM,GAAO,KAAM,MAAK,QAAQ,GAAM,aACtC,MAAO,MAAK,IAAI,QAMZ,OAAM,EAAsC,CAChD,YAAM,YAAI,MAAM,KAAK,WAAY,GAC1B,KAAK,QAGd,WAAwB,CACtB,MAAO,YACJ,iBAAiB,KAAK,YACtB,GAAG,QAAS,AAAC,GAAa,CACzB,KAAM,IAAI,OAAM,uBAAyB,KAAO,KAAO,KAExD,KAAK,uBACL,GAAG,QAAS,AAAC,GAAa,CACzB,KAAM,IAAI,OAAM,oBAAsB,KAAO,KAAO,KAErD,KAAK,GAAI,UAyBR,0BAA8C,CAClD,MAAO,MAAK,SAAS,sBAAsB,WAGvC,uBAAsB,EAAkC,CAC5D,MAAO,IAAK,2BAA4B,SAAY,CAClD,GAAK,KAAM,MAAK,aAAgB,CAAE,KAAM,MAAK,cAC3C,OAEF,GAAM,GAAa,KAAM,GAAO,OAC1B,EAAW,KAAM,MAAK,WACtB,EAAmB,GACzB,OAAW,KAAS,GAAI,GACtB,AAAK,KAAM,GAAM,SAAY,GAAc,CAAC,EAAO,IAAI,IACrD,EAAS,KAAK,GAIlB,GAAI,EAAQ,GACV,OAEF,GAAM,GAAY,KAAM,GAAO,MAE/B,OAAW,KAAS,GACjB,KAAK,CAAC,EAAG,IAAM,GAAU,EAAE,KAAM,EAAE,OACnC,UACD,GAAK,KAAM,GAAM,QAAW,EAC1B,MAAO,UAOT,UACJ,EACA,EAAe,EACf,EAAQ,GAAK,EACI,CACjB,GAAM,GAAM,KAAK,MACjB,GAAI,CAIF,GAHA,KAAM,GAAI,SAAS,SAIhB,MAAM,GAAI,QAAQ,SAAS,IAC3B,KAAM,MAAK,QAAQ,SAAS,KAE7B,MAAK,QAAQ,KACX,4FAGA,KAAM,IAAU,IAAM,KAAK,QAAQ,WAAW,GAAe,CAC3D,UAAW,EAAQ,EACnB,cAAe,OAEjB,CACA,KAAK,QAAQ,KAAK,8CAClB,OAIJ,KAAM,MAAK,QAEX,KAAM,GAAI,OAAO,SACjB,GAAM,GAAS,KAAM,GAAE,GAIvB,GAHmB,KAAM,IAAU,IAAM,EAAI,QAAQ,iBAAkB,CACrE,UAAW,IAGX,YAAM,GAAI,SACH,EAEP,KAAM,IAAI,OAAM,qCAAuC,YAElD,EAAP,CACA,WAAM,GAAI,SACV,KAAM,MAAK,SACL,QAOJ,eACJ,EACA,EAAe,EACK,CACpB,MAAI,MAAM,MAAK,QAAQ,WAAW,GAChC,KAAK,QAAQ,MAAM,6BAEnB,MAAK,QAAQ,MAAM,sCAEnB,KAAM,MAAK,SAAS,EAAG,IAGlB,KAAK,QAGd,kBAAkB,EAA4C,CAC5D,GAAM,GAAI,GAAI,IACZ,qBAAuB,KAAO,KAE1B,EAAI,WAAG,iBAAiB,KAAK,WAAY,CAAE,MAAO,MACxD,SAAE,GAAG,QAAS,AAAC,GAAa,CAC1B,AAAI,EAAI,QAAU,IAAM,EAAI,OAAS,SACnC,GAAE,aAAa,QACf,EAAE,SAEF,EAAE,YAAY,KAGlB,EAAE,GAAG,QAAS,IAAM,EAAE,aAAa,SAC9B,GAAc,EAAG,GAAW,GAAM,CACrC,GAAM,GAAI,EAAG,KAAK,GAClB,AAAI,GAAK,MACP,GAAE,aAAa,GACf,EAAE,WAGC,EAAE,QAGX,aAAa,EAAa,EAAqC,CAC7D,MAAO,IACL,KAAK,YACL,EAAE,YACF,CAAC,EAAM,IAAS,CACd,OAAW,KAAK,GACd,OAAW,KAAK,GACd,GAAI,GAAQ,EAAG,EAAG,GAChB,MAAO,GAIb,MAAO,IAET,IAAM,MAhlDL,MAKY,AALZ,GAKY,QAAU,EAAI,EAmDxB,AAxDF,GAwDE,YAAc,EAAK,IAAM,CAC9B,GAAM,GAAO,GAAY,OACzB,GAAI,GAAQ,KACV,KAAM,IAAI,OAAM,4BAEhB,MAAO,IAAS,IAAI,KyBhKnB,YACL,EACW,CACX,GAAM,GAAM,EAAQ,GAAG,OAAO,CAAC,CAAC,EAAG,KAAO,GAAK,MAAQ,GAAK,MAC5D,MAAO,IAAI,KAAU,GAGhB,YACL,EACA,EACW,CACX,MAAO,IAAW,EAAQ,GAAG,IAAI,IAGnC,kBACE,EACA,EACoB,CACpB,GAAI,GAAY,KAAM,MAAO,IAAI,KACjC,GAAM,GAAU,KAAM,SAAQ,IAAI,EAAQ,EAAI,IAAW,IAAI,GAAM,EAAE,KACrE,MAAO,IAAW,GClCpB,OAAe,sBCsBR,YAAsB,EAAW,CACtC,MAAO,GAAI,GAAG,QAAQ,wBAAyB,QAO1C,YAAsB,EAAe,EAAwB,CAClE,GAAM,GAAS,GACf,OAAW,KAAM,GACf,GAAI,CACF,GAAI,QAAO,GACX,EAAO,KAAK,QACZ,CACA,EAAO,KAAK,GAAa,IAG7B,MAAO,IAAI,QAAO,EAAO,KAAK,KAAM,GCrBtC,YAAuB,CAMrB,YAAqB,EAAmC,CAAnC,SACnB,KAAK,KAAO,EAAO,EAAE,KAAS,EAAI,IAClC,KAAK,WAAa,EAAO,EAAE,WAAe,IAG5C,QAAQ,EAA+B,CACrC,MAAO,CAAC,KAAK,KAAM,EAAI,UAAU,KAAK,QAAU,KAAK,UAAU,UAI7D,GAAS,EAAK,IAAM,EAAS,UAO5B,YACL,EACA,EACA,EAAuB,GAClB,CACL,MAAO,IAAI,IAAM,EAAS,EAAO,GAAsB,QAGlD,YAAe,CAOpB,YACE,EACA,EACS,EAAuB,GAChC,CADS,4BAET,GAAM,GAAO,EAAM,MAAM,eACzB,KAAK,UAAY,EAAK,GACtB,KAAK,KAAO,EAAK,MAAM,GACvB,GAAM,GAAY,KAAK,IAAI,GAAG,KAAK,KAAK,IAAI,GAAM,EAAG,SACrD,KAAK,WAAa,GAAI,KACpB,GACE,EACA,GAAO,CAAC,EAAK,GAAM,KAAK,KAAM,GAAM,EAAM,EAAG,QAGjD,KAAK,QAAU,KAAK,eAAe,EAAQ,IAAI,GAAM,GAAI,IAAc,KACvE,KAAK,QAAU,KAAK,KACjB,IAAI,GAAO,KAAK,QAAQ,IAAI,GAAK,EAAE,QAAQ,KAC3C,IAAI,GAAO,GAAY,IAEvB,OAAO,GAAO,GAAO,GAAK,KAAK,IAG5B,eAAe,EAAiD,CACtE,GAAI,GAAa,KAAK,UAGtB,GAAO,EAAS,GAAM,CAAC,EAAG,KAAK,QAI/B,EAAQ,QAAQ,GAAM,CACpB,GAAM,GAAK,GAAI,QAAO,MAAM,GAAa,EAAG,WAAY,KAClD,EAAQ,EAAG,KAAK,GACtB,AAAI,GAAS,KACP,KAAK,sBACP,KAAS,KAAK,2CAA4C,CACxD,KACA,eAGJ,GAAG,QAAU,EAAM,MACnB,EAAa,GAAW,EAAY,EAAM,MAAO,EAAG,KAAK,OAAQ,QAGrE,GAAM,GAAU,EAAQ,OAAO,GAAM,EAAG,SAAW,MAC7C,EAAe,GAAO,EAAS,GAAM,EAAG,SAI9C,EAAa,QAAQ,CAAC,EAAQ,IAAQ,CACpC,GAAM,GAAO,EAAO,QACd,EAAQ,EAAa,EAAM,GAE3B,EAAK,IAAQ,EAAI,EAAI,EAAM,QAAW,EAAM,KAAK,OAAS,EAC1D,CAAC,EAAG,GAAK,EAAO,WAAa,CAAC,EAAI,GAAQ,CAAC,EAAM,GACvD,EAAO,QAAU,EAAI,KAAK,iBAAiB,EAAG,GAAI,GAAM,EAAK,GACzD,IAAQ,GAAK,EAAO,SAAW,MACjC,GAAO,QAAU,GAGf,EAAO,SAAW,MACpB,KAAS,KACP,uBACE,EAAO,KACP,YACA,EACA,QACA,KAIR,GAAc,EAAc,GAAM,EAAG,SAAW,MAGhD,EAAa,MAAM,EAAG,IAAI,QAAQ,CAAC,EAAQ,IAAQ,CACjD,GAAM,GAAO,EAAa,EAAM,GAChC,EAAO,SAAW,EAAK,QAAW,IAEpC,GAAM,GAAiB,EACrB,GACE,EAAQ,IAAI,GAAM,EAAG,MACrB,EAAa,IAAI,GAAM,EAAG,QAG9B,MAAI,GAAe,OAAS,GAC1B,KAAS,KAAK,kBAAmB,CAAE,mBAE9B,EAOD,iBAAiB,EAAiB,EAA8B,CACtE,MAAO,IAAM,EAAS,GAAO,KAC3B,GAAO,KAAK,WAAW,IAAI,KAAS,KAAK,KAAK,UCjG7C,GAAM,IAAO,IAAM,OACb,GAAS,IAAM,SAErB,GAAM,IAAU,IAAM,OCrD7B,GAAM,IAAM,0FAML,YAAiB,EAAwB,CAC9C,GAAM,GAAI,GAAI,KAAK,GACnB,GAAI,GAAK,KAAM,OACf,GAAM,GAAM,EAAE,MAAM,EAAG,GAAG,IAAI,GAAM,EAAM,IAC1C,GAAI,CAAC,GAAW,GAAM,OACtB,GAAM,CAAC,EAAM,EAAK,EAAK,EAAM,EAAK,EAAK,GAAU,EAC3C,EAAS,EAAM,EAAE,GAAI,CAAE,aAAc,IAG3C,MAAO,IAAI,MACT,KAAK,IAAI,EAAM,EAAM,EAAG,EAAK,EAAM,EAAK,EAAK,EAAS,KACpD,EAAS,GAIf,GAAM,IAAY,gBAKX,YAAsB,EAAwB,CACnD,MAAO,GAAI,GACR,QAAQ,GAAM,GAAU,KAAK,IAC7B,QAAQ,GAAM,EAAG,IACjB,QAAQ,GACR,OAAO,GAAM,GAAO,EAAG,KAAK,MAAQ,GAAO,IAC3C,IAAI,GAAM,GAAI,MAAK,IACnB,MJVL,GAAM,IAAS,EAAK,IAAM,EAAS,OAEnC,YAAqB,EAA0B,CAC7C,MAAO,IAAM,MAAQ,EAAI,EAAG,MAAQ,EAAG,OAAS,MAAQ,EAAS,EAAG,KAWtE,kBAA8B,EAAsC,CAClE,MAAO,GAAQ,GAAS,CAAC,IAAO,GAAO,EAAI,GAAK,KAAK,GAAM,EAAG,MAAQ,IAGxE,kBAAmC,EAAwC,CACzE,MAAI,GAAQ,IAAS,GAAS,CAAC,WAAG,KAAM,GAAc,EAAI,GACnD,EAAQ,GAAS,GAAO,GAAO,EAAI,IAAI,GAAM,EAAG,MAWzD,kBAA+B,EAA2C,CACxE,GAAM,GAAM,EAAI,GAAM,OAAO,GAC7B,GAAI,EAAQ,GAAM,KAAM,IAAI,OAAM,iBAAmB,EAAU,IAE/D,MAAO,IACL,EAAQ,EAAQ,GAAW,GAAO,GAAa,GAAM,GACnD,EAAM,OAAO,GAAM,GAAY,IAAO,EAAI,SAAS,EAAG,OAExD,GAAU,KAAS,MAAM,YAAa,CAAE,KAAM,EAAK,YAIvD,YAAgB,EAAyB,CACvC,MAAO,GAAI,IAAI,AAAC,GAAgB,EAC9B,IAAK,EAAM,GACX,MAAO,GAAa,EAAM,WAC1B,IAAK,EAAM,eAIf,GAAM,IAAW,cACX,GAAiB,qDAUvB,YAAgB,EAAwB,CACtC,MAAO,GAAK,CAAC,GAAG,EAAK,OAAO,GAAM,WAAG,MAAM,KAAK,KAGlD,kBAA0B,EAA2C,CACnE,GAAI,KAAY,GAAW,WAAW,MAAO,MAAO,IAAU,GAC9D,GAAM,GAAM,CACV,GACA,MAEA,GAAO,GACP,gCACA,IACA,KAAK,KACP,MAAO,GAAQ,GAAW,WAAW,eAAe,GAAM,GAAM,GAAO,IAGzE,GAAM,IAAa,CACjB,UAAW,KAAO,KAClB,QAAS,GAAK,EACd,eAAgB,GAChB,aAAc,IAGV,GAA4D,CAChE,cACA,eACA,aAIF,kBAAgC,EAAuC,CACrE,GAAM,GAAO,CAAC,WACd,GAAI,EAAW,GAAO,CAGpB,GAAM,GAAkB,EAAK,CAAC,GAAG,EAAK,OAAO,GAAM,WAAG,MACnD,IAAI,GAAM,aAAa,KACvB,KAAK,QACR,EAAK,KAAK,QAAS,GAErB,EAAK,KAAK,MAAO,GAAQ,KAAK,MAC9B,GAAM,GAAS,KAAM,IAAa,KAAQ,EAAM,IAC1C,EAAU,GACd,GAAW,GAAS,EAAO,QAAQ,IAAI,GAAO,EAC5C,IAAK,EAAM,EAAG,UAAW,CAAE,aAAc,KACzC,MAAO,GAAQ,EAAG,cAClB,IAAK,EAAI,EAAG,iBAGhB,MAAK,GAAQ,KAAK,GAAM,EAAG,MAAQ,WAAG,MACpC,EAAQ,KAAK,CACX,IAAK,WAAG,IACR,MAAO,GAAI,MAAK,IAChB,IAAK,QAAU,WAAG,QAGf,EAGT,YAA4B,EAA6B,CACvD,MAAO,IACL,CAAC,MAAO,CAAE,WAAY,GAAM,KAAM,WAAa,WAC/C,GACA,IAAI,GAAO,EACX,IAAK,EAAM,EAAG,IAAK,CAAE,aAAc,KACnC,MAAO,GAAI,MAAK,EAAG,SACnB,IAAK,EAAI,EAAG,YAchB,kBAA4B,EAAsC,CAChE,GAAM,GAAI,KAAM,IACd,KAGA,CAAC,KAAM,GAAO,GAAO,QAAS,sBAC9B,OACK,IADL,CAEE,eAAgB,MAGpB,MAAO,IAAmB,EAAE,QKxL9B,OAAwB,mBACxB,GAAoB,sBAQb,aAAoB,CACzB,MAAO,IAAW,OAAI,cAAe,IACnC,eAAQ,KAAW,KAAU,gBjCmBjC,GAAM,IAAS,EAAK,IAAM,EAAS,SAmB7B,GAAuB,GAAK,EAElC,YACE,EACA,EACS,CACT,GAAI,GAAQ,MAAQ,GAAS,KAAM,MAAO,GAG1C,GAAM,GAAiB,EAAI,EAAM,MAAO,GAAM,EAAG,WAC3C,EAAgB,EAAK,UAC3B,MACE,GAAI,IACJ,EAAI,IACJ,KAAK,IAAI,EAAiB,GAAiB,GAM/C,kBACE,EACA,EACkB,CAElB,MADI,IAAW,MAAQ,GAAS,MAC5B,EAAQ,OAAS,EAAI,EAAM,KAAa,GACrC,GAAmB,KAAM,GAAQ,WAAyB,GAGnE,YAAyB,EAAa,EAAQ,GAAO,CACnD,GAAM,GAAO,CAAC,OAAQ,EAAI,EAAM,IAAO,MACvC,AAAI,GACF,EAAK,KAAK,MAEZ,WAAI,SAAS,WAAY,GAG3B,kBAAuB,EAAa,EAAQ,GAAO,CACjD,GAAI,KAAY,GAAW,WAAW,MACpC,MAAO,IAAgB,EAAK,GAG9B,GAAI,CAEF,GAAM,GAAM,EAAQ,CAClB,eACA,MACA,EAAM,GACN,EAAQ,SAAW,SAClB,KAAK,KACR,KAAM,IAAW,WAAW,QAAQ,EAAK,UAClC,EAAP,CACA,KAAS,KAAK,0CAA4C,GAC1D,GAAgB,EAAK,IAGzB,kBAAyB,EAAa,EAAQ,GAAO,CACnD,GAAI,CACF,WAAG,KAAK,EAAK,EAAQ,UAAY,iBAC1B,EAAP,CACA,GAAI,CAAC,OAAO,GAAK,SAAS,SAAU,KAAM,IAYvC,YACL,EACA,EAAQ,GACR,EAAwB,GACxB,CACA,GAAI,IAAQ,WAAG,KAAO,IAAQ,WAAG,KAC/B,KAAM,IAAI,OAAM,yBAElB,MAAI,IAAS,GACN,GAAK,WAAW,OAAO,GAEvB,EAAQ,GAAQ,EAAK,GAAS,GAAU,EAAK,GAGtD,kBAAgC,EAA+B,CAE7D,MAAO,AADI,MAAM,IAAQ,IACZ,KAOR,YAAW,CAIhB,YAAqB,EAAU,GAAS,IAAI,MAAY,KAAK,QAAS,CAAjD,eAFJ,OAAI,GAAI,IACR,gBAAa,GAAI,IAA6B,GAAK,GAiG3D,kBAAe,CACtB,EAII,KAEJ,KAAK,EAAE,OAAO,iBAAkB,SAAY,CAC1C,GAAM,GAAa,EAAO,EAAK,WAAY,IACrC,EAAQ,EAAO,EAAK,MAAO,GAC3B,EAAW,KAAM,MAAK,WACtB,EAAc,KAAM,IAAW,EAAU,GAC7C,EACE,EAAG,WACH,GAAQ,CAAC,EAAK,IAAK,KAGjB,EAAO,EACX,GAAQ,EAAI,EAAY,UAAU,IAAI,GAAM,CAAC,EAAG,IAAK,EAAG,SAE1D,GAAI,EAAQ,GACV,YAAS,MAAM,+BACR,GAET,GAAM,GAAa,KAAM,IAAS,GAElC,GADA,KAAS,MAAM,iBAAkB,CAAE,OAAM,eACrC,GAAc,KAAM,CACtB,EAAQ,0DACR,OAEF,GAAM,GAAc,GAAI,KAAI,EAAW,IAAI,GAAM,EAAG,MAC9C,EAAiB,EAAW,OAAO,GAAM,EAAY,IAAI,EAAG,MAE5D,EAA2C,GAC/C,EACE,EAAe,IAAI,GACjB,EAAI,EAAY,IAAI,EAAG,KAAM,GAC3B,GAAmB,EAAM,GAAM,OAAK,GAAU,GAAO,UAI3D,GAAM,EAAG,KACT,OAAO,GAAM,WAAG,MAAQ,EAAG,KAEvB,EAAU,EACZ,EACA,EAAY,OACV,GACE,CAAC,EAAY,IAAI,EAAG,OACpB,CAAC,EAAY,IAAI,EAAG,MACnB,EAAI,EAAG,cAAgB,KAAK,OAAS,EAAG,aACxC,EAAK,kBAAoB,MACxB,EAAG,UAAY,EAAK,kBAE9B,KAAS,MAAM,iBAAkB,CAC/B,iBACA,UACA,SAAU,EAAI,EAAY,YAG5B,OAAW,KAAS,GAClB,KAAS,MAAM,0BAA2B,CAAE,UACvC,GAAQ,EAAM,IAAK,EAAO,IAEjC,YAAM,MAAK,aACJ,GAAO,EAAS,GAAM,EAAG,YA/J9B,QACJ,EACA,EACA,EAAQ,GACW,CACnB,GAAI,GAAQ,KACV,KAAM,IAAI,OAAM,kBAElB,GAAM,GAAM,EAAK,IACjB,GAAI,CAAC,EAAI,GACP,KAAM,IAAI,OAAM,iBAElB,GAAM,GAAM,EAAK,KAAO,IAAM,EAAK,IACnC,MAAI,IAAO,KAAK,WAAW,OAAO,GAC3B,KAAK,WAAW,SAAS,EAAK,SAAY,CAC/C,GAAM,GAAI,KAAK,QAAQ,KAAK,EAAK,IAAM,SACjC,EAAM,EAAI,GAAI,IAAM,GAAgB,EAAK,KAAK,OACjD,OAAO,GACP,UAAU,IAAM,EAAK,KAElB,EAAY,EAAM,UAClB,EAAc,GAAO,EAAK,SAAU,GAAM,EAAY,GACtD,EAAoB,OACrB,GADqB,CAExB,MACA,YACA,gBAEF,MAAI,AAAS,MAAM,GAAE,eAAe,IAAhC,KACK,KAAS,MAAM,sBAAwB,EAAG,CAAE,OAAM,UAE3D,MAAS,MAAM,kBAAoB,EAAG,GAC/B,KAIX,UAAW,CACT,MAAO,MAAK,QACT,QACA,SAAS,GAAM,EAAG,MAAQ,SAAW,AAAQ,EAAM,EAAG,OAAjB,WAGpC,QAAO,EAAqC,CAChD,GAAM,GAAU,KAAK,QAAQ,KAAK,EAAM,SACxC,MAAO,GAAQ,EAAQ,QAAQ,WAAyB,GACtD,KAAK,OAAO,OAAK,GAAL,CAAgB,SAAU,IAAK,GAAI,GAAW,IAAM,MAC9D,GAAO,CACL,KAAS,KAAK,wCAA0C,EAAK,CAAE,gBAUzD,aAAa,CACzB,GAAM,GAAW,KAAM,MAAK,WACtB,EAAO,EAAI,GACd,IAAI,GAAM,EAAM,EAAG,OACnB,OAAO,GACV,GAAI,EAAQ,GAAO,OAEnB,GAAM,GAAU,KAAM,IAAS,GAC/B,GAAI,GAAW,KAAM,CACnB,EAAQ,kCAAoC,GAC5C,OAEF,KAAS,MAAM,aAAc,CAC3B,OACA,SAAU,EAAI,GAAU,IAAI,GAAM,EAAG,MACrC,YAEF,OAAW,KAAW,GAAW,CAC/B,GAAM,GAAU,EAAQ,KAAK,GAAM,EAAI,EAAG,OAAS,EAAQ,MAC3D,AAAI,IAAW,MAAQ,CAAE,KAAM,IAAe,EAAS,KACrD,MAAS,MAAM,sCAAwC,EAAQ,KAAM,CACnE,UACA,QAAS,KAAM,GACZ,WACA,KAAK,GACL,MAAM,GAAO,yBAA2B,EAAM,OAEnD,KAAM,GAAQ,aA1Ff,MACW,AADX,GACW,SAAW,EAAK,IAAM,GAAI,KAwKrC,YAAgB,EAAmB,EAAgC,CACxE,MAAO,IAAK,WAAW,OAAO,EAAM,GAI/B,GAAM,IAAc,EAAc,IAAM,CAC7C,GAAM,GAAS,CAEb,CAAE,WAAY,GAAO,MAAO,GAAO,WAAY,EAAI,GACnD,CAAE,WAAY,GAAO,MAAO,GAAM,WAAY,GAAK,IACnD,IAAI,GACJ,GAAiB,IAAM,GAAK,WAAW,aAAa,GAAK,EAAG,aAE9D,MAAO,IAAI,IACT,cACA,IACE,GAAO,IAAI,eACJ,GAAK,WAAW,gBAEzB,EAAa,SkCnTV,GAAM,IAAkB,GAC7B,cACA,SACA,cACA,QAKW,GAAY,OAAO,OAAO,CACrC,YAAa,GACb,OAAQ,EACR,YAAa,EACb,KAAM,KCnCD,YAAkC,CAOvC,YAAqB,EAAe,CAAf,aALJ,qBAAsC,GAGtC,cAAW,GAAI,KA6CvB,UAAO,KAAK,OAAO,KAAK,SAzC7B,OAAe,CACjB,YAAK,SACE,KAAK,SAAS,KAGvB,IAAI,EAAU,EAAgB,KAAK,MAAa,CAC9C,YAAK,SAAS,IAAI,EAAO,KAAK,MAAS,GAAQ,KAAK,QAC7C,KAGT,aAAgB,EAAU,EAA8B,CACtD,GAAM,GAAQ,KAAK,SAAS,IAAI,GAChC,GAAI,GAAS,MAAQ,KAAK,eAAe,EAAO,GAC9C,YAAK,IAAI,GACF,IAMX,OAAc,CACZ,YAAK,SAAS,QACP,KAGT,OAAO,EAAmB,CACxB,MAAO,MAAK,SAAS,OAAO,GAG9B,QAAQ,EAA6D,CACnE,OAAW,CAAC,EAAO,IAAU,MAAK,SAChC,AAAK,KAAK,eAAe,EAAO,IAC9B,EAAW,EAAO,EAAO,MAK/B,IAAI,EAAmB,CACrB,MAAO,CAAC,KAAK,eAAe,EAAO,KAAK,SAAS,IAAI,IAKvD,QAA8B,CAE5B,GAAM,GAAO,KACb,YAAsC,CACpC,OAAW,CAAC,EAAG,IAAM,GAAK,SAAS,UACjC,AAAK,EAAK,eAAe,EAAG,IAC1B,MAAM,IAIZ,MAAO,KAGT,SAAoC,CAElC,GAAM,GAAO,KACb,YAA2C,CACzC,OAAW,CAAC,EAAG,IAAM,GAAK,SAAS,UACjC,AAAK,EAAK,eAAe,EAAG,IAC1B,MAAM,CAAC,EAAG,IAIhB,MAAO,KAGT,KAAW,CACT,YAAK,SACE,CAAC,GAAG,KAAK,SAAS,SA/EjB,QAAO,YAkFhB,OAAO,YAAiC,CACvC,MAAO,MAAK,SAGd,GAAG,EAAkB,EAA0B,CAC7C,KAAK,gBAAgB,KAAK,GAMpB,eAAe,EAAQ,EAAyB,CACtD,MAAO,IAAI,GAAS,MAAQ,EAAQ,KAAK,OAAS,KAAK,MAAO,GAAW,CACvE,AAAI,GAAS,MAAQ,GACnB,MAAK,gBAAgB,QAAQ,GAAM,EAAG,IACtC,KAAK,SAAS,OAAO,MAQnB,QAAS,CACf,KAAK,SAAS,QAAQ,CAAC,EAAe,IAAW,CAC/C,KAAK,eAAe,EAAK,OChG/B,GAAM,IAAS,EAAK,IAAM,EAAS,WAEnC,EAAM,IAAM,EAAa,IAAM,GAAQ,SAAS,UAEhD,GAAM,IAAU,EAAK,IAAM,GAAI,IAAe,IAE9C,kBAA6B,EAAa,CACxC,GAAI,KAAU,IAAI,GAAM,OACxB,KAAU,IAAI,GAId,GAAM,GAAU,EAAS,gBAAgB,eAEzC,MAAO,IAAO,EAAK,SAAY,CAC7B,GAAI,CACF,KAAO,GACH,GAAU,EAAK,GACf,GAAY,EAAK,EAAO,GAAU,GAAU,GAAU,eAC1D,KAAS,KAAK,cAAgB,EAAM,OAAS,SACtC,EAAP,CAEA,KAAS,KAAK,wBAA0B,EAAM,GAAI,GAClD,UAKN,kBAAyB,EAAa,EAAmB,CACvD,MAAO,IAAO,EAAK,GACjB,GAAgB,SAAS,EAAI,GAC3B,GAAW,WAAW,QACpB,oBAAoB,uBAAyB,KAC7C,GAAM,KAMd,kBAA2B,EAAa,EAAO,GAAI,CACjD,MAAO,IAAa,SAAU,CAAC,EAAM,KAAM,GAAK,IAAI,GAAM,CACxD,QAAS,GAAK,EACd,iBAAkB,IAAM,GACxB,eAAgB,GAChB,WAAY,IC1DhB,OAAe,sBCDf,OAAe,sBCcR,YAAkB,CACvB,YAA6B,EAAkC,CAAlC,cAEf,MACZ,EACA,EACY,CACZ,GAAM,GAAM,KAAK,GAAK,KAAO,KAAM,MAAK,IAAM,OACxC,EAAI,GAAc,GAAO,KAAM,GAAI,MAAQ,EACjD,MAAO,IAAK,KAAO,EAAE,GAAK,SAMtB,YAAY,CAChB,MAAO,MAAK,KACV,IAAM,GACN,IAAM,SAOJ,UAA4B,CAChC,MAAO,MAAK,KACV,IAAM,GACN,IAAM,SAOJ,MAAyB,CAC7B,MAAO,MAAK,KACV,GAAM,EACN,IAAG,SAOD,cAA0B,CAC9B,MAAO,MAAK,KACV,GAAM,EACN,IAAM,CACJ,KAAM,IAAI,OAAM,iCAShB,QAAO,EAAqD,CAChE,MAAO,MAAK,KAAK,EAAG,IAAM,IAO5B,IAAO,EAA0C,CAC/C,MAAO,IAAI,IAAY,SAAY,KAAK,KAAK,EAAG,IAAG,KAQrD,QAAW,EAA4C,CACrD,MAAO,IAAI,IAAY,SAAY,KAAK,KAAK,EAAU,IAAG,KAO5D,OAAO,EAAgD,CACrD,MAAO,IAAI,IAAY,SACrB,KAAK,KACH,KAAM,IAAQ,KAAM,GAAE,GAAO,EAAK,OAClC,IAAG,KAST,MAAM,EAAmE,CACvE,MAAO,IAAI,IAAY,IAAM,KAAK,MAAM,MAAM,KAAM,IAAO,EAAQ,KAQrE,QAAQ,EAAgC,CACtC,MAAO,IAAI,IAAY,SAAY,CACjC,GAAM,GAAI,KAAM,MAAK,MACrB,YAAM,GAAI,EAAG,GACN,SAQL,WAAU,EAAqC,CACnD,MAAO,GAAO,KAAM,MAAK,MAAO,GAOlC,OAAO,EAA2D,CAChE,MAAO,IAAI,IAAY,SAAY,CACjC,GAAM,GAAI,KAAM,MAAK,MACf,EAAS,GAAY,KAAM,KACjC,MAAO,IAAW,GAAU,EAAO,MAAQ,MAKjD,YAAuB,EAA0B,CAC/C,MAAO,aAAa,IAGf,YAAoB,EAAkC,CAC3D,MAAO,IAAW,GAAK,EAAI,GAAI,IAAS,IAAM,GCjJzC,GAAU,IAAV,UAAU,EAAV,CACE,AAAM,MAAM,SACd,IACkB,CACrB,OAAW,KAAM,GACf,GAAI,CAAC,EAAO,KAAM,MAAO,MAAO,GAElC,MAAO,IAEI,KAAK,SACb,IACkB,CACrB,OAAW,KAAM,GACf,GAAI,EAAO,KAAM,MAAO,MAAO,GAEjC,MAAO,MAfM,aAwDjB,qBACK,EACc,CACjB,GAAI,GAAO,KACX,OAAW,KAAM,GAAK,CACpB,GAAI,GAAM,KAAM,SAChB,GAAM,GAAS,KAAM,KACrB,GAAI,GAAU,KAAM,MAAO,IFtDxB,GAAM,IAAgB,KAKhB,GAAS,EAAK,SAClB,GACL,KAAM,IACJ,IAAM,KACN,IAAO,EAAQ,KAAc,OAC7B,IAAO,GAAQ,KAAc,OAC7B,IAAO,GAAU,KAAgB,UAMvC,YAAuB,EAAY,WAAG,IAAK,CACzC,MAAO,IACL,EAAI,OACJ,EAAI,YACJ,EAAI,KACJ,EAAI,UAKR,GAAM,IAAQ,0CAEP,YAAmB,EAA2B,CAEnD,GAAI,EAAM,IAAO,GAAiB,IAAK,IAAO,GAAiB,QAAS,GACtE,MAAO,IACF,CAEL,GAAM,GAAI,GAAM,KAAK,GACrB,MAAI,IAAK,KAAa,GACf,EAAQ,CAAC,EAAE,GAAI,EAAE,KAAK,KAAK,MAI/B,aAAqB,CAC1B,MAAO,GACL,GAAW,WAAW,YACpB,sDAEF,GAAM,EAAG,MAIb,GAAM,IAAO,CACX,QAAS,GAAK,GAGT,aAAqB,CAC1B,MAAO,IACL,GAAO,WAAY,CAAC,OAAQ,gBAAiB,eAAgB,KAE5D,QAAQ,IACR,MAGL,GAAM,IAAW,4BAEV,aAAuB,CAC5B,MAAO,IAAQ,GAAO,SAAU,GAAI,KACjC,QAAQ,GACP,EAAO,MAAM;AAAA,GAAM,IACjB,GAAM,EAAI,EAAG,MAAM,IAAW,GAAK,CAAC,EAAE,GAAI,EAAE,OAG/C,QAAQ,IACR,QAAQ,IACR,QAAQ,IACR,MAGE,aAA2B,CAChC,MAAO,CACL,KAAM,IACN,OAAQ,KDxEZ,GAAM,IAAe,EAAK,IAAM,GAAI,KAAI,GAAO,GAAU,IAAI,GAAM,EAAG,OAE/D,aAA+B,CACpC,GAAM,GAAM,KACZ,MAAO,IAAW,GAAO,WAAG,IAAK,GAAK,IAAM,YAAc,EAAI,IAAI,KAG7D,GAAM,IAAwB,EACnC,IAAM,KAAoB,OAAO,GAAM,EAAG,aAG5C,aAA4B,CAC1B,GAAsB,QAGxB,GAAM,IAAiB,EAAK,IAAM,CAChC,GAAI,CACF,MAAO,IAAI,QAAO,EAAS,mBAAmB,eAAgB,WACvD,EAAP,CACA,eAAQ,MACN,6CAA6C,2BAExC,GAAI,QAAO,EAAS,mBAAmB,aAAc,QAIhE,EAAM,IAAM,CACV,EAAS,mBAAmB,YAAY,IAAM,CAC5C,GAAe,QACf,GAAa,UAGf,OAAW,KAAM,MACf,EAAG,YAAY,MAIZ,GAAM,IAAe,EAAK,IAAM,CACrC,GAAM,GAAK,KACX,MAAO,IAAW,WAAG,IAAK,CAAC,EAAG,IAAO,EAAG,KAAK,IAAM,KAAO,OAAY,KAGjE,aAA4B,CACjC,MAAO,MAAwB,OAAO,CAAC,EAAM,IAAO,EAAG,cAAc,GAAO,KAC1E,SAAU,IAEN,KAAa,CAAE,aAAc,KAAQ,IAErC,GAAa,CAAE,qBAAsB,IAAK,eAAgB,KAAQ,KAMnE,YAAsB,EAAkD,CAC7E,GAAM,GAA+B,EAAO,EAAW,IACjD,EAAe,EAAO,EAAK,aAAc,IAC/C,MAAO,QACF,GAAK,EAAM,iBADT,CAEL,IAAK,GAAS,EAAK,IAAK,GACxB,SAAU,GACV,MAAO,KAKJ,YACL,EACA,EACA,CACA,GAAM,GAAkB,GAAc,aAGjC,MAHiC,CAIpC,KAAM,OACF,EAAe,KAAoB,IACpC,MACA,EAAO,EAAW,MAIvB,SAAS,UAAU,cAAc,GAGjC,EAAS,SAAS,cAAc,GAEzB,E3ClFT,GAAM,IAAS,EAAK,IAAM,EAAS,iBAEnC,YAAgB,EAAsB,CACpC,MAAO,IAAK,EAAW,MAAO,SAAU,YAAa,WAAY,cAG5D,YAAqB,EAAa,EAAqC,CAC5E,MAAO,IAAU,IAAM,GAAQ,GAAU,IAAO,CAAE,cAGpD,kBACE,EACA,EAAY,GAAK,EACC,CAClB,GAAI,GAAM,KAAM,MAAO,GAEvB,GAAM,GAAM,EAAG,IAKf,GAJA,KAAS,MAAM,cAAgB,EAAM,IAAK,CACxC,OAAQ,EAAG,OACX,UAAW,EAAG,YAEZ,GAAO,EACT,YAAS,KAAK,yCAA0C,GAAO,IACxD,GAET,GAAI,IAAQ,WAAG,IACb,YAAS,KAAK,oCAAqC,GAAO,IACnD,GAIT,KAAM,IAAM,KACZ,KAAM,IAAa,GAEnB,CAEE,GAAM,GAAa,EAAG,OACtB,KAAS,MAAM,cAAgB,EAAM,IAAK,CACxC,aACA,gBAAiB,EAAG,SAEjB,GACH,KAAM,IAAQ,GAAK,MAAM,GAAO,CAC9B,KAAS,KAAK,sBAAwB,EAAM,mBAAqB,KAavE,GAHA,GAAI,IAAM,EAAG,SAGT,KAAqB,MAAO,GAEhC,GAAI,KAAM,IAAY,EAAK,GACzB,YAAS,MAAM,wBAAyB,GAAO,IACxC,GAGT,CAEE,AAAK,GAAK,WAAW,OAAO,GAC5B,GAAM,GAAa,EAAG,KAAK,WAC3B,KAAS,KAAK,cAAgB,EAAM,6BAA8B,CAChE,eAEG,GACH,KAAM,IAAQ,EAAK,IAAM,MAAM,GAAO,CACpC,KAAS,KAAK,sBAAwB,EAAM,kBAAoB,KAMtE,MAAO,IAAY,EAAK,KAGnB,YACL,EACA,EACS,CACT,MACE,KAAQ,UACR,IAAQ,SACR,IAAQ,SACR,CAAC,EAAK,GAAG,GAAM,MACb,GACE,CAAC,EAAG,SAAS,WACb,CAAC,EAAG,SAAS,UACb,CAAC,EAAG,SAAS,YAMrB,YACE,EACA,EACA,EACA,EACA,CACA,GAAM,GAAQ,GAAI,MAOd,EAAU,GACd,EAAG,GAAG,OAAQ,IAAO,EAAU,IAE/B,GAAM,GAAY,GAAS,EAAK,GAEhC,UACE,SAAY,CACV,GAAI,EAAS,OACb,KAAM,IAAU,IAAM,EAAI,EAAG,KAAM,CAAE,UAAW,EAAI,IACpD,GAAM,GAAM,EAAG,IACf,GAAK,EAAI,GAUP,MAAI,IAAW,KAAM,IAAO,GACrB,GAAO,CAAE,MAAK,MAAK,WAAU,KAAM,WAAG,KAAO,GAVpD,KAAS,KACP,2DACA,CACE,MACA,GAAI,GAAO,MASnB,EAAQ,IAAM,KAET,EAGF,YACL,EACA,EACA,EACA,EACkB,CAClB,GAAM,GAAO,GAAa,GAC1B,YAAS,MAAM,UAAW,CAAE,UAAS,OAAM,WAAU,SAC9C,GAAQ,WAAI,MAAM,EAAS,EAAM,GAAO,EAAS,EAAM,GAQzD,YACL,EACA,EACA,EACA,EACkB,CAClB,GAAM,GAAO,GAAa,GAC1B,MAAO,IAAQ,WAAI,SAAS,EAAS,EAAM,GAAO,EAAS,EAAM,GAsBnE,kBACE,EACA,EACA,EACuB,CACvB,MAAO,IAAc,IAAM,GAAc,EAAK,EAAM,GAAO,CACzD,UAAW,EAAK,QAChB,WAAY,EAAO,EAAK,WAAY,GACpC,iBAAkB,GAAc,GAAW,IAAM,GACjD,iBAAkB,GAChB,KAAS,IAAI,CACX,IAAK,kCACL,OAAQ,GAAc,EAAO,SAC7B,KAAM,CAAE,QAAO,MAAK,YAK5B,kBACE,EACA,EACA,EACuB,CACvB,GAAM,GAAQ,EAAO,EAAK,MAAO,IAC3B,EAAe,EAAO,EAAK,aAAc,IACzC,EAAiB,EAAO,EAAK,eAAgB,IAE7C,EAAkC,GACxC,KAAS,MAAM,2BAA4B,CAAE,MAAK,SAClD,GAAM,GAAO,KAAM,IACjB,EACA,EACA,EAAK,QACL,GACE,EACA,UACA,QACA,aACA,eACA,mBAIJ,GAAI,EAAK,aAAe,GACtB,SAAK,aACE,CAAE,OAAQ,GAAI,IAAK,EAAK,KAGjC,GAAM,GAAO,EAAU,CAAE,MAAK,SACxB,EAAI,GAAI,IAAuB,GACrC,WAAW,IAAM,CACf,AAAI,EAAE,SACJ,KAAS,KAAK,+BAAgC,CAAE,MAAK,UAEtD,EAAK,QAAU,GAAG,QAGrB,EAAE,WAAW,EAAK,SAElB,GAAM,GAAU,CAAC,EAAa,IAAe,CAC3C,GACE,GAAiB,IAChB,GAAW,EAAK,mBAAqB,EAAK,iBAAiB,GAC5D,CACA,KAAS,MAAM,uCAAyC,EAAK,CAC3D,MACA,OACA,OACA,UAEF,OAEF,AAAI,EAAK,KAAO,MACT,GAAW,GAEb,GACH,KAAS,KAAK,mBAAqB,EAAK,CAAE,MAAK,OAAM,OAAM,UACzD,EAAE,SAAS,EAAE,OAAO,IAE1B,GAAI,CACF,EAAK,GAAG,QAAS,GAAO,EAAQ,YAAa,IAC7C,EAAK,GAAG,QAAS,GAAQ,CACvB,GAAM,GAAY,KAAK,MAAQ,EAAE,MAC3B,EAAQ,IAAS,EAAI,OAAS,QAC9B,EAAS,EAAW,KAAK,IAC/B,AAAK,GACH,KAAS,IAAI,EAAO,4BAA6B,CAC/C,MACA,OACA,OACA,YACA,OAAQ,GAAK,EAAQ,IAAK,OAG9B,AAAI,CAAC,GAAkB,IAAS,EAC9B,EAAE,OACA,GAAI,OAAM,uBAAyB,EAAU,CAAE,OAAM,MAAK,WAEzD,EAAE,QAAQ,CAAE,SAAQ,KAAM,GAAO,GAAO,IAAK,EAAK,QAEpD,GAAU,EAAK,OACpB,EAAK,QAAQ,GAAG,OAAQ,GAAM,CAC5B,AAAI,GAAM,MAAM,EAAW,KAAK,KAElC,EAAK,QAAQ,GAAG,QAAS,GAAO,EAAQ,gBAAiB,IACzD,EAAK,QAAQ,GAAG,OAAQ,GACtB,EACI,KAAS,KAAK,iCAAmC,EAAI,IACrD,EAAQ,eAAgB,UAEvB,EAAP,CACA,EAAQ,YAAa,GAEvB,MAAO,MAAM,GAAE,QAOV,YACL,EACA,EACA,EACiB,CACjB,MAAO,IAAa,EAAK,EAAM,GAAM,KAAK,GAAM,EAAG,QF/T9C,oBAEG,GAAe,CAKvB,YACW,EACA,EACT,EAAoB,EAAa,QACjC,EAAiB,GACjB,CACA,MACE,EACA,IAAM,KAAK,EAAE,MACb,EACA,IAAM,KAAK,EAAE,MACb,IAAS,YAAc,EAAe,GAV/B,YACA,SAYT,EAAE,GAAG,aAAc,AAAC,GAAqB,CACvC,KAAK,OAAO,KAAK,yBAA2B,EAAO,IAAM,EAAG,KAC5D,GAAO,EAAG,KAAK,MAAM,GACnB,KAAK,QAAQ,qBAAuB,EAAM,IAIxC,GACF,EAAG,GAAG,OAAQ,IAAM,GAAW,EAAI,EAAI,IAGzC,GACE,CACE,IAAK,EAAG,IACR,KAAM,WAAG,IACT,IAAK,EACL,SAAU,EAAE,QAAQ,iBAAmB,GAEzC,GAAI,OACJ,MAAM,GAAO,KAAK,QAAQ,qBAAuB,EAAM,MAE3D,EAAE,GAAG,aAAc,GAAS,CAC1B,KAAK,eAAiB,EACtB,KAAK,QAAQ,kBAAmB,KAElC,EAAE,GAAG,YAAa,CAAC,EAAO,IAAS,CACjC,KAAK,cAAgB,EACrB,KAAK,QAAQ,iBAAmB,EAAI,EAAM,GAAM,EAAG,SAAU,KAE/D,EAAE,GAAG,gBAAiB,GAAS,CAC7B,KAAK,kBAAoB,EACzB,KAAK,QAAQ,iBAAkB,KAEjC,EAAE,GAAG,WAAY,GAAO,CACtB,KAAK,OAAO,MAAM,iCAAkC,KAIxD,QAAQ,EAAgB,EAAc,CAGpC,AAAI,CAAC,KAAK,EAAE,OAAS,CAAC,KAAY,CAAC,GAAiB,GAClD,EAAQ,KAAK,KAAO,KAAO,EAAQ,GAEnC,KAAK,OAAO,KAAK,oCAAsC,EAAQ,KiDhF9D,GAAM,IAAe,GAKrB,YAAkB,EAAW,EAAS,EAAQ,CACnD,GAAI,GAAU,EAAG,MAAO,GACxB,GAAI,GAAQ,KAGZ,MAAI,IAAiB,GACZ,EAEL,MAAM,QAAQ,GACT,GAAQ,GAEb,GAAY,GACP,EAEL,GAAQ,GACH,OAAK,GAAL,CAAW,MAAO,GAAW,EAAK,SAEvC,GAAS,GACJ,GAAW,EAAM,CAAC,EAAG,IAAM,GAAS,EAAG,EAAS,IAIlD,EAMF,YACL,EACA,EAA6B,GAC7B,CACA,GAAI,GAAK,KAEF,MAAI,GAAE,QAAU,GACd,EAAE,IAAI,GAEN,CACL,GAAG,EAAE,MAAM,EAAG,IAAc,IAAI,GAChC,WAAM,EAAE,uBC5CP,GAAM,IAAY,GAAQ,QAAS,OAAQ,OAAQ,QAAS,SAG7D,GAAe,GAAY,GAAU,OAAO,IAAI,CAAC,EAAG,IAAM,CAAC,EAAG,KAE7D,YAAoB,EAA0B,CACnD,MAAO,IAAa,IAAa,GAAa,MCLzC,GAAM,IAAgB,EAAK,IAChC,GAAU,OAAO,OAAO,GAAM,IAAO,GAAU,QAG3C,GAAc,GAYd,GAA0B,EAAmB,IACjD,GACE,KAAgB,IAAI,GAAM,CAAC,EAAI,GAAI,IAAsB,QAItD,aAAiC,CACtC,GAAO,MAA2B,QAAQ,GAAM,EAAG,SAG9C,YAA2B,EAAc,CAC9C,KAA0B,EAAG,IAAI,KAAK,GAGjC,aAA4B,CACjC,GAAM,GAAkB,GACxB,OAAW,KAAM,IAAO,MACtB,EAAI,KAAK,GAAG,EAAG,OAEjB,MAAO,IAAO,EAAK,GAAM,EAAG,ICtBvB,YAAkB,EAAmB,EAA2B,CACrE,MAAO,IAAa,EAChB,QACA,GAAa,EAAU,EACvB,OACA,GAAa,EAAU,EACvB,OACA,QA4CN,GAAM,IAAQ,WAMP,QAAuD,CAE5D,YACW,EACA,EACT,CAFS,eACA,eA8EF,WAAQ,CAAC,EAAa,IAAe,CAC5C,KAAK,IAAI,QAAS,EAAK,IAGhB,UAAO,CAAC,EAAa,IAAe,CAC3C,KAAK,IAAI,OAAQ,EAAK,IAGf,UAAO,CAAC,EAAa,IAAe,CAC3C,KAAK,IAAI,OAAQ,EAAK,IAGf,WAAQ,CAAC,EAAa,IAAe,CAC5C,KAAK,IAAI,QAAS,EAAK,IAGhB,WAAQ,CAAC,EAAa,IAAe,CAC5C,KAAK,IAAI,QAAS,EAAK,IA7FvB,KAAK,cAAgB,EACnB,GAAM,KAAK,EAAI,KAAK,UACpB,GAAM,EAAG,GACT,IAAM,KAAK,SAIf,WAAW,EAAW,CACpB,MAAO,IAAI,IAAiB,KAAK,QAAU,EAAG,KAAK,SAGrD,MACE,EACA,EACO,CACP,GAAM,GAAQ,GAAa,IAAM,GAAM,MAEjC,EAAY,CADG,IAAM,YAAc,KACN,GAAiB,GAC9C,EAAY,GAAiB,IAAM,GAAM,UAC/C,EACE,GAAQ,KACJ,OACA,GAAS,GAAK,EAAM,QAAS,YAAa,cAChD,GAAM,GAAM,GAAI,IAAa,CAC3B,MAAO,GAAQ,GACf,QAAS,EAAc,CACrB,KAAK,QACL,GAAQ,KAAO,OAAY,EAAU,KACpC,KAAK,KACR,QACA,YACA,cAEF,WAAK,IAAI,IAAc,GAAO,OAAS,QAAS,GAAe,GAAI,GAC7D,EAGR,IAAO,EAAgE,CACrE,YAAK,IAAI,EAAO,EAAE,MAAO,SAAU,EAAE,IAAK,GAAE,OAAQ,EAAE,QAAW,EAAE,OAC5D,EAAE,OAGX,IAAI,EAAiB,EAAiB,EAAkB,CAGtD,GAFA,EAAO,GAAS,GAEZ,KAAY,QAAQ,EAAO,KAAK,SAClC,OAAW,KAAM,MAAK,UACpB,EAAG,IAAI,EAAO,KAAK,QAAS,EAAS,OAGvC,AAAI,KAAU,SACZ,GAAkB,CAChB,GAAI,KAAK,MACT,EAAG,EACH,IAAK,KAAK,QACV,IAAK,EACL,cAMF,QAAQ,CACZ,OAAW,KAAM,MAAK,UACpB,KAAM,GAAG,aAIP,MAAM,CACV,OAAW,KAAM,MAAK,UACpB,KAAM,GAAG,QtDhIf,GAAM,IAAmB,GAAK,EAExB,GAAO,UAEP,GAA0B,8BAazB,YAAmB,EAAmB,CAC3C,GAAM,GAAK,EACR,QAAQ,YAAa,GAAM,IAAM,GACjC,QAAQ,MAAO,MACf,QAAQ,MAAO,MACf,QAAQ,MAAO,MACf,QAAQ,MAAO,MACf,QAAQ,MAAO,MAClB,MAAO,IAAM,EAAK,IAGpB,aAA0B,CACxB,MAAO,CACL,qBAAqB,OACrB,GAAG,GACD,EAAS,kBAAkB,eAC3B,GAAM,CACJ,8DAA8D,KAC9D,gEAAgE,MAElE,KAEF,KAAK,KAGT,EAAM,IAAM,EAAa,IAAM,GAAW,SAAS,SAAS,qBAErD,YAAoC,CAWjC,aAAc,CAVb,UAAO,aAKC,YAAS,EAAS,cAGlB,iBAAc,GAAI,KAGjC,KAAK,IAAM,GAAI,IACb,aACA,GAAI,iBAAa,CACf,eAAgB,IACd,GACE,aACA,EAAS,eAAe,OACxB,IAEJ,OAAQ,IAAM,EAAS,cACvB,eAAgB,KAChB,KAAM,GACN,KAAM,QACN,YAAa,OACb,SAAU,KAAY,EAAI,EAAI,EAC9B,mBAAoB,IACpB,kBAAmB,EACnB,kBAAmB,KAErB,EAAa,QAEf,KAAK,KAAO,KAAK,IAAI,KAGnB,iBAAiB,CACnB,MAAO,MAAK,IAAI,kBAGd,gBAAgB,CAClB,MAAO,MAAK,IAAI,cAGlB,KAAM,CACJ,MAAO,MAAK,KAAK,SAGf,QAAQ,CACV,MAAO,MAAK,KAAK,MAGnB,aAA+C,CAC7C,MAAO,MAAK,YAAY,6BAG1B,SAAgC,CAC9B,MAAO,GACL,KAAK,YAAY,6BACjB,GAAM,GAAG,EAAG,SAAS,EAAG,SAAS,EAAG,YAIpC,eAAe,CACjB,MAAO,MAAK,KAAK,aAGnB,mBAAmB,EAAa,EAAgB,CAC9C,KAAK,eAAe,GAAa,EAAK,IAA0B,GAGlE,eAAe,EAAa,EAAgB,CAC1C,KAAK,YAAY,IAAI,EAAK,GAG5B,kBAAmB,CACjB,KAAK,YAAY,aAGb,SAAW,EAAa,EAAoC,CAChE,GAAI,KAAK,KAAK,OAAS,IAAU,CAC/B,KAAK,OAAO,KAAK,2BAA4B,CAAE,QAC/C,OAGF,GAAI,IAAU,KAAK,YAAY,IAAI,GAAM,CACvC,GAAM,GAAI,KAAK,YAAY,IAAI,GAC/B,MAAO,GAAO,EAAE,OAAQ,EAAE,OAAQ,EAAE,QAGtC,GAAI,CACF,KAAK,OAAO,MAAM,YAAa,CAAE,QACjC,GAAM,GAAI,KAAM,IAAa,IAC3B,KAAK,KAAK,YACR,GAAI,SACF,EACA,CAAC,EAAgB,EAA4B,IAC3C,EAAO,EAAI,EAAQ,GAAM,GAAY,EAAI,IAAQ,EAAQ,MAKjE,YAAK,OAAO,IAAI,GAAS,EAAE,UAAW,EAAI,GAAW,YAAa,CAChE,MACA,UAAW,EAAE,YAER,EAAE,aACF,EAAP,CACA,KAAK,OAAO,KAAK,qBAAuB,EAAK,CAAE,QAC/C,aAIE,aAAY,EAAgC,CAChD,GAAM,GAAI,KAAM,MAAK,QACnB,GAAa,EAAK,IAClB,CAAC,EAAQ,EAAQ,IAAY,EAAE,SAAQ,SAAQ,YAEjD,GAAI,GAAK,KAAM,CACb,KAAK,OAAO,KAAK,6BAA8B,CAAE,QACjD,OAEF,GAAI,EAAM,EAAE,SAAW,EAAS,EAAE,SAAW,CAAC,EAAE,OAAQ,CACtD,KAAK,OAAO,KAAK,+BAAgC,GAAE,OAAQ,IAC3D,OAEF,GAAI,CACF,MAAO,MAAK,MAAM,EAAE,cACb,EAAP,CACA,GAAM,GAAQ,EAAE,OAAO,QAAQ,MAAO,QACtC,YAAK,OAAO,KACV,yDACA,CAAE,OAAQ,GAAU,EAAE,QAAS,MAAO,GAAU,KAE3C,KAAK,MAAM,SAIhB,gBAAe,EAAmC,CACtD,MAAO,GAAQ,KAAK,YAAY,GAAM,GACpC,MAAM,QAAQ,GAAQ,EAAO,CAAC,MA5I7B,MAEW,AAFX,GAEW,SAAW,EAAK,IAAM,CACpC,GAAI,CAAC,EAAO,KAAM,IAAI,OAAM,+CAC5B,MAAO,IAAI,MDlEf,mBAA2C,CACzC,MAAO,GACH,GAAW,WAAW,YACpB,uJAEF,OAGC,GAAM,IAAc,EAAK,SAAY,CAC1C,GAAI,EAAO,CACT,GAAM,GAAS,KAAM,MACrB,GAAI,EAAS,GAAS,MAAO,GAE/B,MAAO,QAGI,GAAqB,EAAK,IAAM,eAAQ,KAAW,awDvBzD,GAAM,IAAmB,CAC9B,YACA,QACA,QACA,aACA,SACA,OACA,WACA,QACA,aACA,QACA,OACA,SACA,QACA,UACA,WACA,QACA,SACA,UACA,SACA,QACA,UACA,SACA,YACA,WACA,SACA,QACA,aACA,UACA,OACA,UACA,UACA,QACA,QACA,QACA,UACA,OACA,SACA,SACA,SACA,SACA,SACA,QACA,iBACA,OACA,UACA,WACA,SC/CK,GAAM,IAAc,CAAC,OAAQ,MAAO,MAAO,OCAlD,OAA0B,mBAC1B,GAAoB,sBCCb,YAAqB,EAAmB,CAC7C,MAAO,GAAI,GACR,QAAQ,kBAAmB,CAAC,EAAG,EAAG,IAAM,IAAM,EAAE,cAAgB,GAChE,QAAQ,iBAAkB,GAAM,IAAM,GACtC,QAAQ,KAAM,IDoBZ,YAAgB,EAAsB,CAC3C,MAAO,MAAQ,GAAY,GAAM,cAO5B,GAAM,IAAe,EAAI,KAAK,SAClC,IAAI,GAAO,GAAS,OAAO,OAAO,GAAM,GACxC,MAEU,EAAoB,GAE/B,QACA,UACA,aACA,YACA,QACA,UACA,WACA,UAEA,KACA,eACA,UACA,WACA,YACA,WACA,WACA,OACA,UACA,MACA,iBAIW,GAAoD,OAAO,OAAO,CAC7E,EAAkB,GAClB,EAAkB,aAClB,EAAkB,QAClB,EAAkB,SAGlB,EAAkB,UAClB,EAAkB,SAClB,EAAkB,SAClB,EAAkB,KAClB,EAAkB,QAClB,EAAkB,IAClB,EAAkB,gBAIP,GAAmD,OAAO,OACrE,EAAkB,OAAO,OAAO,GAAM,CAAC,GAAkB,SAAS,KAgC9D,GAAc,AAAC,GACnB,EAAS,IAAM,IAAM,YAAc,EAAI,GAAG,OAAS,OAa9C,QAAiB,CAOtB,YAAqB,EAAsC,CAAtC,YAJb,cAAW,GAEF,eAAkC,GAInD,UAAW,CACT,MAAO,MAAK,QAAU,KAGxB,SAAU,CACR,MAAO,CAAC,KAAK,WAIf,UAAW,CACT,MAAO,CAAE,MAAO,KAAK,OAAQ,QAAS,KAAK,UAG7C,SAAS,EAAiC,CACxC,KAAK,SAAW,EAAE,QAClB,KAAK,OAAS,EAAE,MASlB,YAAY,EAAqB,CAC/B,GAAM,GAAO,EAAO,EAAM,QAC1B,OAAW,KAAK,CAAC,KAAK,IAAK,GAAG,EAAI,KAAK,KAAK,aAAc,CACxD,GAAM,GAAI,EAAI,EAAK,GAAI,GAAM,KAAK,KAAK,QAAQ,IAC/C,GAAI,GAAK,KAAM,MAAO,IAS1B,cAAc,EAA4B,OAAe,CACvD,GAAI,MAAK,SACT,MAAO,GAAI,KAAK,YAAY,GAAc,GAGjC,KAAK,SAAS,IAIzB,eAAe,EAA2B,CACxC,GAAI,OAAK,YAAc,CAAC,KAAK,UAE7B,MAAO,MAAK,SAAS,GAGvB,YAAY,EAAuB,CACjC,KAAK,UAAU,KAAK,GAChB,KAAK,UAGP,aAAa,IAAM,EAAE,KAAK,QAI9B,eAAe,EAAuB,CACpC,GAAc,KAAK,UAAW,GAAM,IAAO,GAGrC,UAAW,CACjB,GAAM,GAAI,KAAK,MACf,KAAK,UAAU,QAAQ,GAAM,EAAG,OAG9B,OAAe,CACjB,MAAO,MAAK,MAGd,SAAS,EAAc,CACrB,GAAI,KAAK,OAAS,KAAM,KAAM,IAAI,OAAM,yBACxC,KAAK,MAAQ,EACb,KAAK,KAAO,GAAO,GACnB,KAAK,mBAGH,UAAmB,CACrB,MAAO,MAAK,YAMV,MAAc,CAChB,MAAO,MAAK,QAGV,WAA4B,CAC9B,MAAO,MAAK,KAAK,YAGf,eAAqC,CACvC,MAAO,IAAkB,SAAS,KAAK,UAAY,UAAY,YAG7D,YAAqB,CACvB,MAAO,MAAK,KAAK,YAAc,MAM7B,WAAoB,CACtB,MAAO,GACL,KAAK,KAAK,SACV,GAAM,IACN,IAAM,OAIN,QAAkB,CACpB,MAAO,MAAK,UAOV,OAAM,EAAa,CACrB,KAAK,SAAW,GAChB,KAAK,SAAS,GAGhB,cAAc,EAAa,CACzB,AAAI,GAAK,MAAM,MAAK,MAAQ,MAG1B,aAAY,EAAa,CAC3B,KAAK,MAAQ,EACb,KAAK,SAAS,OAAK,MAMjB,oBAAmC,CACrC,MAAO,MAAK,KAAK,MAAM,KAAK,mBAQ1B,UAAS,EAAa,CACxB,KAAK,SAAW,GAEhB,KAAK,SAAS,OAAK,GACnB,KAAK,SAAS,MAGZ,iBAAgB,EAAa,CAC/B,AAAI,KAAK,WAAW,MAAK,SAAW,GAG9B,SAAS,EAAa,CAC5B,GAAM,GAAQ,KAAK,OACb,EAAQ,KAAK,KAAK,MAAM,GACxB,EAAU,KAAK,KAAK,QAAQ,GAClC,YAAK,OAAS,EACT,GAAI,EAAO,KAAK,SAAS,KAAK,WAC5B,KAAK,UAGV,eAAkB,CACpB,MAAO,IAAI,KAAK,KAAK,iBAGnB,eAAkB,CACpB,MAAO,GAAI,KAAK,KAAK,cAClB,QAAQ,GAAM,KACd,OAAO,GACP,UAAU,IAAM,KAAK,iBAGtB,iBAAoB,CAEtB,MAAO,MAAK,OAAS,KAAO,KAAK,MAAQ,KAAK,aAGhD,cAAuC,EAAW,EAAuB,CACvE,GAAM,GAAI,EAAO,EAAM,QAIvB,MAAI,MAAK,YACP,GAAE,KAAK,KAAO,GACZ,KAAK,KAAK,MAAM,EAAO,EAAe,KAAK,mBAGxC,EAGT,SAAkC,EAAW,EAAuB,CAClE,GAAM,GAAI,EAAO,EAAM,QACvB,SAAE,KAAK,KAAO,GACZ,KAAK,KAAK,MAAM,EAAO,EAAe,KAAK,kBAEtC,EAGT,cAAuC,EAAe,CACpD,GAAM,GAAI,EAAO,EAAM,QACvB,aAAO,GAAE,KAAK,KACd,EAAI,KAAK,KAAK,WAAY,GACxB,EAAI,QAAQ,GAAM,CAChB,MAAO,GAAE,MAGN,EAGT,eAAe,EAAgC,CAC7C,MAAO,MAAK,SAAW,KAAK,OAAS,EAGvC,OAAQ,CACN,YAAK,OAAS,OACd,KAAK,SAAW,GAChB,KAAK,gBACL,KAAK,WACL,EAAS,YAAc,KAAK,MAAM,KAAK,YAChC,KAGT,WAAY,CACV,MAAO,GAGT,QAAS,CACP,MAAO,CACL,IAAK,KAAK,IACV,MAAO,KAAK,MACZ,aAAc,KAAK,KAAK,gBAKvB,gBAAiC,GAAuB,CAC7D,YACE,EACA,CACA,MAAM,GACJ,MAAO,GACP,QAAS,GACT,aAAc,QACX,IAIP,UAAW,CACT,MAAO,GAAS,KAAK,SAIzB,YAAc,EAAkB,CAC9B,MAAO,IAAK,KAAO,OAAY,EAAE,OAG5B,oBAA4B,GAAgB,CACjD,YAAY,EAA2B,CACrC,MAAM,GACJ,MAAO,GACP,QAAS,IACN,IAIP,UAAW,CACT,MAAO,GAAS,KAAK,SAIzB,YAAsB,EAAkB,EAAsC,CAC5E,GAAM,GAAI,EAAI,GAAG,cACjB,MAAO,GAAY,KAAK,GAAM,EAAG,gBAAkB,GAG9C,oBAAgC,GAAgB,CAGrD,YAAY,EAAuD,CACjE,MAAM,GACJ,MAAO,GAAK,GAAa,EAAG,EAAK,aACjC,QAAS,GAAK,GAAa,EAAG,EAAK,cAChC,IAML,GAHA,KAAK,YAAc,EAAK,YAGpB,AAFO,KAAK,cAEN,MAAQ,CAAC,KAAK,YAAY,SAAS,KAAK,cAChD,KAAM,IAAI,OACR,gBAAgB,KAAK,8CAA8C,EAAK,gBAI9E,WAAY,CACV,MAAO,CAAE,YAAa,KAAK,eAI/B,YAAgB,EAAmC,CACjD,MAAO,GAAY,EAAI,GAAG,OAAQ,GAAO,CACvC,GAAI,EAAI,WAAW,MAAQ,EAAI,SAAS,KACtC,GAAI,CACF,MAAO,IAAQ,KAAK,MAAM,IAAM,IAAI,QACpC,EAKJ,OAAW,KAAM,CAAC,OAAK,cACrB,GAAI,EAAI,SAAS,GACf,MAAO,GAAI,MAAM,GAGrB,MAAO,CAAC,KAIL,YAA0B,EAAmC,CAClE,MAAO,IAAS,GAAK,OAAY,GAAY,GAAO,GAAI,IAG1D,YAAe,EAAqC,CAClD,MAAO,IAAY,GAAe,GAAM,GAG1C,YAAwB,EAAsB,CAC5C,MAAO,GAAK,GAAgB,IAGvB,oBAAiC,GAAkB,CACxD,YACE,EACA,CACA,MAAM,GACJ,aAAc,GACd,QAAS,GACT,MAAO,IACJ,IAIP,QAAQ,EAAkB,CACxB,KAAK,MAAQ,GAAe,CAAC,GAAG,KAAK,eAAgB,GAAG,OAGtD,SAAmB,CACrB,MAAO,IAAe,KAAK,mBAGzB,QAAO,EAAe,CACxB,KAAK,MAAQ,GAAe,GAG9B,mBAAmB,EAAW,CAC5B,EAAI,KAAK,MAAO,GAAQ,KAAK,SAAW,EAAI,OAAO,GAAM,IAAO,MAIpE,YACE,EACA,EACiB,CACjB,MAAO,IAAiB,GAAiB,GAAM,GAGjD,YACE,EACA,EACiB,CACjB,GAAI,GAAO,KAAM,OAEjB,GAAM,GAAmB,GACzB,OAAW,KAAM,GAAK,CACpB,GAAM,GAAI,GAAa,EAAI,GAC3B,AAAI,GAAK,MAAM,EAAO,KAAK,GAE7B,MAAO,GAGF,oBAAiC,GAAkB,CAExD,YACE,EAIA,CACA,MAAM,GACJ,QAAS,GAAK,GAAgB,EAAG,EAAK,aACtC,MAAO,GAAO,EAAI,EAAK,GAAM,EAAU,EAAK,MACzC,IAEL,KAAK,YAAc,EAAK,YAG1B,cAAc,EAAQ,CACpB,MAAO,IAAiB,EAAG,KAAK,aAGlC,WAAY,CACV,MAAO,CAAE,YAAa,KAAK,eAIxB,gBAA6B,GAAgB,CAClD,YAAY,EAA2B,CACrC,MAAM,OACD,GADC,CAEJ,MAAO,GACP,QAAS,OAgBR,oBAA2B,GAAgB,CAChD,YAAY,EAA2B,CACrC,MAAM,OACD,GADC,CAEJ,MAAO,GACP,QAAS,QAKR,gBAAoC,GAAgB,CACzD,YACW,EACT,CACA,MAAM,OACD,GADC,CAEJ,MAAO,GACP,QAAS,AAAC,GACR,EAAI,GACD,QAAQ,UACR,IAAI,GAAM,GAAM,EAAQ,IAAK,EAAQ,IAAK,IAC1C,SATE,eAYX,WAAY,CACV,MAAO,CAAE,SAAU,KAAK,QAAQ,IAAK,SAAU,KAAK,QAAQ,OAIzD,gBAAkC,GAAgB,CACvD,YACW,EACT,CACA,MAAM,OACD,GADC,CAEJ,MAAO,GACP,QAAS,AAAC,GACR,EAAI,GACD,QAAQ,YACR,IAAI,GAAM,GAAM,EAAQ,IAAK,EAAQ,IAAK,IAC1C,SATE,eAYX,WAAY,CACV,MAAO,CAAE,SAAU,KAAK,QAAQ,IAAK,SAAU,KAAK,QAAQ,OAIzD,eAA6B,GAAiB,CACnD,YAAY,EAA4B,CACtC,MAAM,OACD,GADC,CAEJ,MAAO,GACP,QAAS,QnF5kBf,GAAO,IAAa,mBAEd,GAAoB,OAAO,OAAO,CAEtC,kBACA,iBACA,kBACA,iBACA,YACA,WACA,QACA,SAIW,GAAS,EAAK,IAAM,IAC3B,GAAS,IAAM,CAAC,KAGT,GAAe,OAAO,OACjC,EACI,CACE,GAAG,GACD,GAAG,IAAI,WACP,GAAM,CACJ,EACA,YAAK,GAAG,IAAI,WAAa,YACzB,YAAK,GAAG,IAAI,WAAa,WAAY,SAEvC,IAAM,IAER,qBAEF,IAQO,EAAW,CACtB,oBAAqB,GAAI,GAAe,CACtC,SAAU,EAAkB,MAC5B,YAAa,mTACb,aAAc,GACd,SAAU,IAAM,KAGlB,YAAa,GAAI,IAAmB,CAClC,WAAY,CAAC,aAAc,kBAC3B,SAAU,EAAkB,MAC5B,YACE,8NACF,aAAc,IACZ,KACI,sBACA,KACA,cACA,KACN,aAAc,IAAO,MAAc,CAAC,KAAW,cAAgB,OAC/D,SAAU,IAAM,KAGlB,YAAa,GAAI,IAAc,CAC7B,SAAU,EAAkB,MAC5B,YAAa;AAAA,mNACb,aAAc,IAAM,6BAGtB,aAAc,GAAI,IAAc,CAC9B,SAAU,EAAkB,MAC5B,YAAa;AAAA;AAAA;AAAA,sNACb,aAAc,IAAM,MAGtB,UAAW,GAAI,GAAe,CAC5B,SAAU,EAAkB,MAC5B,YACE,4KACF,aAAc,GACd,UAAW,KAGb,cAAe,GAAI,GAAe,CAChC,SAAU,EAAkB,MAC5B,YACE,yGACF,aAAc,GACd,SAAU,IAAM,KAGlB,eAAgB,GAAI,GAAe,CACjC,SAAU,EAAkB,MAC5B,YACE,0JACF,aAAc,GACd,SAAU,IAAM,KAGlB,UAAW,GAAI,IAAmB,CAChC,SAAU,EAAkB,MAC5B,YAAa,oRACb,SAAU,IAAM,GAChB,aAAc,IACZ,KAAW,CAAC,YAAa,aAAe,CAAC,QAG7C,SAAU,GAAI,IAAc,CAC1B,SAAU,EAAkB,MAC5B,YACE,uOACF,aAAc,IAAO,KAAW,oBAAsB,KACtD,aAAc,IAAM,OAGtB,aAAc,GAAI,IAAmB,CACnC,SAAU,EAAkB,MAC5B,YACE,8GAGJ,QAAS,GAAI,IAAmB,CAC9B,WAAY,CAAC,WACb,SAAU,EAAkB,MAC5B,YACE,gIACF,aAAc,IAAM,gCAGtB,iBAAkB,GAAI,GAAe,CACnC,SAAU,EAAkB,MAC5B,YACE,mFACF,aAAc,KAGhB,gBAAiB,GAAI,GAAe,CAClC,SAAU,EAAkB,MAC5B,YACE,kFACF,aAAc,KAOhB,SAAU,GAAI,IAAc,CAC1B,WAAY,CAAC,SAAU,OACvB,SAAU,EAAkB,QAC5B,YACE,qKACF,aAAc,IAAO,KAAW,QAAU,SAG5C,OAAQ,GAAI,IAAc,CACxB,SAAU,EAAkB,QAC5B,YAAa,8DACb,aAAc,IAAM,KACpB,aAAc,IAAO,KAAW,0BAA4B,SAG9D,eAAgB,GAAI,GAAe,CACjC,SAAU,EAAkB,QAC5B,YAAa,sDACb,aAAc,IAAM,OAGtB,aAAc,GAAI,GAAe,CAC/B,SAAU,EAAkB,QAC5B,YACE,wHACF,aAAc,IAAM,KAGtB,eAAgB,GAAI,GAAe,CACjC,SAAU,EAAkB,QAC5B,YAAa,4CACb,aAAc,KAGhB,UAAW,GAAI,IAAmB,CAChC,SAAU,EAAkB,QAC5B,YACE,2FAGJ,UAAW,GAAI,GAAe,CAC5B,WAAY,CAAC,aAAc,aAC3B,SAAU,EAAkB,QAC5B,YACE,+EACF,aAAc,GACd,UAAW,KAGb,SAAU,GAAI,GAAe,CAC3B,SAAU,EAAkB,QAC5B,YACE,iIACF,aAAc,GACd,UAAW,KAGb,SAAU,GAAI,GAAe,CAC3B,SAAU,EAAkB,QAC5B,YACE,0IACF,aAAc,IAAM,EAAM,GAAG,IAAI,YAGnC,OAAQ,GAAI,GAAe,CACzB,SAAU,EAAkB,QAC5B,YACE,kJACF,aAAc,IAAM,KAOtB,UAAW,GAAI,IAAc,CAC3B,SAAU,EAAkB,WAC5B,YAAa,gTAGb,aAAc,IAAM,cAGtB,SAAU,GAAI,IAAe,CAC3B,SAAU,EAAkB,WAC5B,YAAa,+DACb,aAAc,OAGhB,WAAY,GAAI,IAAc,CAC5B,SAAU,EAAkB,WAC5B,YAAa,gTACb,aAAc,UAGhB,yBAA0B,GAAI,GAAe,CAC3C,SAAU,EAAkB,WAC5B,YACE;AAAA,2DACF,aAAc,IAAM,MAAc,CAAC,OAGrC,QAAS,GAAI,IAAe,CAC1B,SAAU,EAAkB,WAC5B,YAAa,iIACb,aAAc,OAOhB,sBAAuB,GAAI,IAAsB,CAC/C,SAAU,EAAkB,UAC5B,YACE,4NACF,IAAK,EACL,IAAK,EACL,aAAc,IAGhB,mBAAoB,GAAI,IAAc,CACpC,SAAU,EAAkB,UAC5B,YAAa,+bACb,aAAc,+BAGhB,cAAe,GAAI,IAAe,CAChC,SAAU,EAAkB,UAC5B,YACE,2FACF,aAAc,GAAM,MAAW,EAAI,GAAQ,EAAI,KAGjD,eAAgB,GAAI,IAAe,CACjC,SAAU,EAAkB,UAC5B,YAAa,oNACb,aAAc,GAAK,IAGrB,YAAa,GAAI,IAAe,CAC9B,SAAU,EAAkB,UAC5B,YACE,0iBACF,aAAc,EAAI,IAGpB,gCAAiC,GAAI,IAAe,CAClD,SAAU,EAAkB,UAC5B,YACE,+LACF,aAAc,EAAI,IAGpB,wBAAyB,GAAI,IAAe,CAC1C,SAAU,EAAkB,UAC5B,YACE,sUACF,aAAc,KAGhB,cAAe,GAAI,IAAe,CAChC,SAAU,EAAkB,UAC5B,YACE,gXACF,aAAc,IAGhB,eAAgB,GAAI,IAAsB,CACxC,SAAU,EAAkB,UAC5B,YACE,2mBACF,aAAc,GACd,IAAK,EACL,IAAK,MAGP,gBAAiB,GAAI,IAAkB,CACrC,SAAU,EAAkB,UAC5B,YAAa,2TACb,aAAc,IAAM,GAAgB,YACpC,YAAa,GAAgB,SAG/B,YAAa,GAAI,IAAsB,CACrC,SAAU,EAAkB,UAC5B,YACE,yMACF,aAAc,IACd,IAAK,IACL,IAAK,MAGP,eAAgB,GAAI,IAAsB,CACxC,SAAU,EAAkB,UAC5B,YACE,8IACF,aAAc,IACd,IAAK,IACL,IAAK,MAGP,mBAAoB,GAAI,IAAsB,CAC5C,SAAU,EAAkB,UAC5B,YACE,0MACF,aAAc,IAAO,KAAW,GAAK,IACrC,IAAK,EACL,IAAK,MAGP,eAAgB,GAAI,IAAe,CACjC,SAAU,EAAkB,UAC5B,YACE,uJACF,aAAc,IAAO,KAAW,EAAW,EAAI,IAGjD,QAAS,GAAI,GAAe,CAC1B,SAAU,EAAkB,UAC5B,YACE,6HACF,aAAc,GACd,UAAW,GACX,SAAU,IAAM,KAGlB,uBAAwB,GAAI,GAAe,CACzC,SAAU,EAAkB,QAC5B,YACE,mJACF,aAAc,KAGhB,oBAAqB,GAAI,GAAe,CACtC,SAAU,EAAkB,QAC5B,YACE,4EACF,aAAc,KAGhB,oBAAqB,GAAI,GAAe,CACtC,SAAU,EAAkB,QAC5B,YAAa,wTACb,aAAc,KAGhB,qBAAsB,GAAI,GAAe,CACvC,SAAU,EAAkB,QAC5B,YAAa,+SACb,aAAc,KAkBhB,oBAAqB,GAAI,GAAe,CACtC,SAAU,EAAkB,MAC5B,YACE,+aACF,aAAc,IAAM,MAAc,CAAC,OAQrC,eAAgB,GAAI,IAAe,CACjC,SAAU,EAAkB,GAC5B,YACE,iIACF,aAAc,KAGhB,YAAa,GAAI,IAAe,CAC9B,SAAU,EAAkB,GAC5B,YACE,iUACF,aAAc,IAAM,EAAI,IAG1B,YAAa,GAAI,IAAe,CAC9B,SAAU,EAAkB,GAC5B,YACE,gZACF,aAAc,IAAM,IAKtB,wBAAyB,GAAI,IAAoB,CAC/C,SAAU,EAAkB,GAC5B,YACE,oVACF,IAAK,KAAW,GAAM,EACtB,IAAK,GAAK,GACV,aAAc,IAAO,KAAW,GAAM,KAGxC,cAAe,GAAI,IAAe,CAChC,SAAU,EAAkB,GAC5B,YACE,kMACF,aAAc,MAGhB,kBAAmB,GAAI,IAAsB,CAC3C,SAAU,EAAkB,GAC5B,YACE,4GACF,aAAc,IACd,IAAK,EACL,IAAK,MAGP,kBAAmB,GAAI,IAAsB,CAC3C,SAAU,EAAkB,GAC5B,YACE,4GACF,aAAc,GACd,IAAK,EACL,IAAK,MAOP,oBAAqB,GAAI,GAAe,CACtC,SAAU,EAAkB,aAC5B,YACE,gFACF,aAAc,KAGhB,6BAA8B,GAAI,GAAe,CAC/C,SAAU,EAAkB,aAC5B,YACE,oFACF,aAAc,KAGhB,mBAAoB,GAAI,GAAe,CACrC,SAAU,EAAkB,aAC5B,YACE,gFACF,aAAc,KAGhB,qBAAsB,GAAI,GAAe,CACvC,SAAU,EAAkB,aAC5B,YACE,oGACF,aAAc,KAGhB,cAAe,GAAI,GAAe,CAChC,SAAU,EAAkB,aAC5B,YACE,gGACF,aAAc,KAOhB,WAAY,GAAI,GAAe,CAC7B,SAAU,EAAkB,MAC5B,YAAa,mJAEb,aAAc,IAAO,QAAY,MAGnC,gBAAiB,GAAI,GAAe,CAClC,SAAU,EAAkB,MAC5B,YAAa,4IACb,aAAc,IAAM,KAGtB,2BAA4B,GAAI,GAAe,CAC7C,SAAU,EAAkB,MAC5B,YAAa,+EACb,aAAc,KAGhB,4BAA6B,GAAI,GAAe,CAC9C,SAAU,EAAkB,MAC5B,YAAa,+HACb,aAAc,IAAM,GACpB,aAAc,IAAM,KAGtB,wBAAyB,GAAI,IAAmB,CAC9C,SAAU,EAAkB,MAC5B,YAAa;AAAA,kEACb,aAAc,KAGhB,cAAe,GAAI,IAAc,CAC/B,SAAU,EAAkB,MAC5B,YAAa,kNACb,aAAc,cAGhB,WAAY,GAAI,IAAc,CAC5B,SAAU,EAAkB,MAC5B,YAAa,kQACb,aAAc,WAGhB,oBAAqB,GAAI,IAAmB,CAC1C,SAAU,EAAkB,MAC5B,YAAa;AAAA,6QACb,aAAc,CACZ,OACA,MACA,OACA,UAEA,WACA,UACA,aACA,UAIJ,gBAAiB,GAAI,IAAc,CACjC,SAAU,EAAkB,MAC5B,YAAa,iOACb,aAAc,iBAGhB,eAAgB,GAAI,IAAmB,CACrC,SAAU,EAAkB,MAC5B,YAAa;AAAA;AAAA;AAAA;AAAA,sDACb,aAAc,CAAC,UAAW,aAAc,mBAAoB,YAG9D,kBAAmB,GAAI,IAAc,CACnC,SAAU,EAAkB,MAC5B,YACE,iOACF,aAAc,IAAM,UAGtB,UAAW,GAAI,IAAmB,CAChC,SAAU,EAAkB,MAC5B,YAAa,+MACb,aAAc,IACX,GAAU,oBACP,GACA,KAGR,QAAS,GAAI,IAAc,CACzB,SAAU,EAAkB,MAC5B,YAAa,+IACb,aAAc,QAOhB,YAAa,GAAI,GAAe,CAC9B,SAAU,EAAkB,SAC5B,YACE,0IACF,aAAc,GACd,SAAU,IAAM,CAAC,KAGnB,cAAe,GAAI,IAAkB,CACnC,SAAU,EAAkB,SAC5B,YACE,gZACF,aAAc,IAAM,KACpB,YAAa,CAAC,QAAS,OAAQ,YAGjC,eAAgB,GAAI,GAAe,CACjC,SAAU,EAAkB,SAC5B,YACE,0EACF,aAAc,KAGhB,mBAAoB,GAAI,IAAe,CACrC,SAAU,EAAkB,SAC5B,YACE,2FACF,aAAc,GAAK,KAGrB,gBAAiB,GAAI,GAAe,CAClC,SAAU,EAAkB,SAC5B,YACE,uHACF,aAAc,KAGhB,MAAO,GAAI,IAAmB,CAC5B,SAAU,EAAkB,UAC5B,YACE,gOACF,aAAc,IAAM,oBACpB,SAAU,IAAM,KAGlB,aAAc,GAAI,GAAe,CAC/B,SAAU,EAAkB,UAC5B,YACE,4LACF,aAAc,GACd,SAAU,IAAM,KAGlB,gBAAiB,GAAI,IAAe,CAClC,SAAU,EAAkB,UAC5B,YACE;AAAA;AAAA,qIACF,aAAc,IAOhB,iBAAkB,GAAI,IAAsB,CAC1C,SAAU,EAAkB,IAC5B,YAAa,yQACb,aAAc,IAAM,GACpB,IAAK,IACL,IAAK,IAGP,eAAgB,GAAI,IAAmB,CACrC,SAAU,EAAkB,IAC5B,YAAa,kIACb,aAAc,IAAM,CAAC,UAGvB,kBAAmB,GAAI,GAAe,CACpC,SAAU,EAAkB,IAC5B,YACE,0FACF,aAAc,GACd,UAAW,KAGb,cAAe,GAAI,GAAe,CAChC,SAAU,EAAkB,IAC5B,YACE,2FACF,aAAc,IAAM,KAGtB,aAAc,GAAI,IAAmB,CACnC,SAAU,EAAkB,IAC5B,YACE,8PACF,aAAc,IAAM,iCAkBtB,oBAAqB,GAAI,IAAe,CACtC,SAAU,EAAkB,KAC5B,YACE,wOACF,aAAc,MAGhB,iBAAkB,GAAI,GAAe,CACnC,SAAU,EAAkB,KAC5B,YAAa,0LACb,aAAc,KAGhB,iCAAkC,GAAI,IAAc,CAClD,SAAU,EAAkB,KAC5B,WAAY,CAAC,0BACb,YAAa;AAAA;AAAA;AAAA;AAAA;AAAA,4LACb,aAAc,cAGhB,gBAAiB,GAAI,GAAe,CAClC,SAAU,EAAkB,KAC5B,YAAa,ucACb,aAAc,KAGhB,qBAAsB,GAAI,IAAe,CACvC,SAAU,EAAkB,KAC5B,YACE,0RACF,aAAc,MAGhB,oBAAqB,GAAI,IAAe,CACtC,SAAU,EAAkB,KAC5B,YACE,qSACF,aAAc,OAGhB,wBAAyB,GAAI,IAAmB,CAC9C,SAAU,EAAkB,KAC5B,YAAa,iZACb,aAAc,IAAM,CAClB,kBACA,YACA,YACA,gBAIJ,0BAA2B,GAAI,IAAmB,CAChD,SAAU,EAAkB,KAC5B,YAAa,6MACb,aAAc,IAAM,CAAC,UAGvB,0BAA2B,GAAI,IAAmB,CAChD,SAAU,EAAkB,KAC5B,YAAa,mKACb,aAAc,IAAM,CAAC,OAAQ,UAG/B,mBAAoB,GAAI,IAAsB,CAC5C,SAAU,EAAkB,KAC5B,YAAa,6WACb,aAAc,GACd,IAAK,EACL,IAAK,MAGP,YAAa,GAAI,GAAe,CAC9B,SAAU,EAAkB,KAC5B,YACE,iJACF,aAAc,KAGhB,kBAAmB,GAAI,IAAe,CACpC,SAAU,EAAkB,KAC5B,YACE;AAAA;AAAA;AAAA,2GACF,aAAc,KAGhB,QAAS,GAAI,GAAe,CAC1B,SAAU,EAAkB,KAC5B,YACE,4EACF,aAAc,GACd,UAAW,KAGb,UAAW,GAAI,GAAe,CAC5B,SAAU,EAAkB,KAC5B,YACE,4FACF,aAAc,GACd,UAAW,KAGb,iBAAkB,GAAI,GAAe,CACnC,SAAU,EAAkB,KAC5B,YAAa,uDACb,aAAc,GACd,UAAW,KAGb,aAAc,GAAI,GAAe,CAC/B,SAAU,EAAkB,KAC5B,YACE,iGACF,aAAc,GACd,UAAW,KAGb,+BAAgC,GAAI,GAAe,CACjD,SAAU,EAAkB,SAC5B,YAAa;AAAA;AAAA,0FACb,aAAc,KAGhB,mBAAoB,GAAI,IAAkB,CACxC,SAAU,EAAkB,SAC5B,YACE,+EACF,aAAc,MACd,YAAa,KAGf,+BAAgC,GAAI,GAAe,CACjD,SAAU,EAAkB,SAC5B,YAAa,iLACb,aAAc,KAGhB,+BAAgC,GAAI,GAAe,CACjD,SAAU,EAAkB,SAC5B,YAAa,mQACb,aAAc,KAGhB,kBAAmB,GAAI,GAAe,CACpC,SAAU,EAAkB,KAC5B,YAAa,0XACb,aAAc,KAGhB,iBAAkB,GAAI,GAAe,CACnC,SAAU,EAAkB,KAC5B,YAAa,6MACb,aAAc,KAGhB,iBAAkB,GAAI,GAAe,CACnC,SAAU,EAAkB,KAC5B,YAAa;AAAA,0VACb,aAAc,KAGhB,aAAc,GAAI,IAAe,CAC/B,SAAU,EAAkB,KAC5B,YAAa,8YACb,aAAc,OAGhB,oBAAqB,GAAI,GAAe,CACtC,SAAU,EAAkB,KAC5B,YAAa,0WACb,aAAc,KAGhB,qBAAsB,GAAI,GAAe,CACvC,SAAU,EAAkB,KAC5B,YAAa,sJACb,aAAc,KAGhB,4BAA6B,GAAI,GAAe,CAC9C,SAAU,EAAkB,KAC5B,YAAa,mUACb,aAAc,KAGhB,yBAA0B,GAAI,IAAe,CAC3C,SAAU,EAAkB,KAC5B,YACE,8JACF,aAAc,IAGhB,qBAAsB,GAAI,GAAe,CACvC,SAAU,EAAkB,KAC5B,YAAa,2EACb,aAAc,GACd,UAAW,KAGb,iBAAkB,GAAI,GAAe,CACnC,SAAU,EAAkB,KAC5B,YAAa,uEACb,aAAc,GACd,UAAW,KAGb,mBAAoB,GAAI,GAAe,CACrC,SAAU,EAAkB,KAC5B,YAAa,4RACb,aAAc,IAAO,KAAW,GAAO,cAAO,QAAU,IAG1D,8BAA+B,GAAI,GAAe,CAChD,SAAU,EAAkB,KAC5B,YAAa,6HACb,aAAc,IAAM,KAStB,eAAgB,GAAI,GAAe,CACjC,SAAU,EAAkB,SAC5B,YAAa,ycACb,aAAc,KAGhB,eAAgB,GAAI,GAAe,CACjC,SAAU,EAAkB,SAC5B,YAAa,mSACb,aAAc,KAGhB,0BAA2B,GAAI,GAAe,CAC5C,SAAU,EAAkB,SAC5B,YAAa,yLACb,aAAc,KAGhB,4BAA6B,GAAI,IAAsB,CACrD,SAAU,EAAkB,SAC5B,YACE,+QACF,aAAc,IAAM,GACpB,IAAK,IACL,IAAK,IAGP,iBAAkB,GAAI,IAAsB,CAC1C,SAAU,EAAkB,SAC5B,YACE,qXACF,aAAc,IAAM,GACpB,IAAK,IACL,IAAK,IAGP,0BAA2B,GAAI,IAAsB,CACnD,SAAU,EAAkB,SAC5B,YACE,gYACF,aAAc,IAAM,GACpB,IAAK,IACL,IAAK,IAGP,iBAAkB,GAAI,IAAsB,CAC1C,SAAU,EAAkB,SAC5B,YACE,yXACF,aAAc,IAAM,GACpB,IAAK,IACL,IAAK,IAGP,gBAAiB,GAAI,IAAsB,CACzC,SAAU,EAAkB,SAC5B,YACE,sHACF,aAAc,IAAM,GACpB,IAAK,IACL,IAAK,IAGP,0BAA2B,GAAI,IAAoB,CACjD,SAAU,EAAkB,SAC5B,YAAa,+rBACb,aAAc,IAAM,IACpB,IAAK,EACL,IAAK,KAGP,wBAAyB,GAAI,IAAsB,CACjD,SAAU,EAAkB,SAC5B,YACE,8SACF,aAAc,EACd,IAAK,IACL,IAAK,IAGP,sBAAuB,GAAI,IAAoB,CAC7C,SAAU,EAAkB,SAC5B,YAAa,mMACb,aAAc,IAAM,GACpB,IAAK,EACL,IAAK,IAGP,wBAAyB,GAAI,IAAoB,CAC/C,SAAU,EAAkB,SAC5B,YAAa,qNACb,aAAc,IAAM,GACpB,IAAK,EACL,IAAK,IAGP,eAAgB,GAAI,IAAe,CACjC,SAAU,EAAkB,SAC5B,YAAa;AAAA,uEACb,aAAc,MAGhB,UAAW,GAAI,IAAmB,CAChC,SAAU,EAAkB,SAC5B,YAAa,kEACb,aAAc,IAAM,KAGtB,oBAAqB,GAAI,IAAmB,CAC1C,SAAU,EAAkB,SAC5B,YAAa,8ZACb,aAAc,CACZ,aACA,QACA,YACA,UACA,QACA,qBACA,cAIJ,yBAA0B,GAAI,IAAoB,CAChD,SAAU,EAAkB,SAC5B,YAAa,4OACb,aAAc,IAAM,IACpB,IAAK,EACL,IAAK,OAOP,YAAa,GAAI,IAAsB,CACrC,SAAU,EAAkB,SAC5B,YACE,6TACF,aAAc,IAAM,GACpB,IAAK,IACL,IAAK,KAGP,aAAc,GAAI,IAAmB,CACnC,SAAU,EAAkB,SAC5B,YAAa;AAAA;AAAA;AAAA;AAAA;AAAA,wGACb,aAAc,CAAC,KAAM,IAAK,QAG5B,mBAAoB,GAAI,IAAmB,CACzC,SAAU,EAAkB,SAC5B,YAAa,sJACb,aAAc,CACZ,0CACA,kCAIJ,oBAAqB,GAAI,IAAkB,CACzC,SAAU,EAAkB,SAC5B,YACE,maACF,aAAc,YACd,YAAa,CAAC,SAAU,UAAW,eAGrC,gBAAiB,GAAI,IAAa,CAChC,SAAU,EAAkB,SAC5B,YAAa;AAAA,2GACb,aAAc,MAIhB,QAAS,GAAI,GAAe,CAC1B,SAAU,EAAkB,SAC5B,YAAa,wIACb,aAAc,KAGhB,YAAa,GAAI,GAAe,CAC9B,SAAU,EAAkB,SAC5B,YAAa,iJACb,aAAc,KAIhB,mBAAoB,GAAI,IAAmB,CACzC,SAAU,EAAkB,SAC5B,YACE,kRACF,aAAc,GAAK,GAAe,CAAC,QAAS,QAAS,UACrD,YAAa,KAGf,iBAAkB,GAAI,IAAmB,CACvC,SAAU,EAAkB,SAC5B,YAAa;AAAA;AAAA,gEACb,aAAc,CAAC,eAAgB,cAAe,gBAGhD,mBAAoB,GAAI,IAAmB,CACzC,SAAU,EAAkB,SAC5B,YAAa;AAAA;AAAA,gEACb,aAAc,CAAC,iBAAkB,mBAGnC,aAAc,GAAI,GAAe,CAC/B,SAAU,EAAkB,SAC5B,YAAa,mEACb,aAAc,KAOhB,iBAAkB,GAAI,GAAe,CACnC,SAAU,EAAkB,QAC5B,YACE,+ZACF,aAAc,KAGhB,kBAAmB,GAAI,IAAe,CACpC,SAAU,EAAkB,QAC5B,YACE,+NACF,aAAc,MAGhB,kBAAmB,GAAI,IAAe,CACpC,SAAU,EAAkB,QAC5B,YACE,+NACF,aAAc,MAGhB,oBAAqB,GAAI,IAAa,CACpC,SAAU,EAAkB,QAC5B,YACE,mEACF,aAAc,IAGhB,sBAAuB,GAAI,IAAe,CACxC,WAAY,CACV,0BACA,oBACA,0BAEF,SAAU,EAAkB,QAC5B,YACE,iJACF,aAAc,GAAK,KAGrB,sBAAuB,GAAI,IAAe,CACxC,WAAY,CACV,0BACA,oBACA,0BAEF,SAAU,EAAkB,QAC5B,YACE,4JACF,aAAc,GAAM,KAItB,mBAAoB,GAAI,GAAe,CACrC,SAAU,EAAkB,QAC5B,YAAa,6MACb,aAAc,KAKhB,kBAAmB,GAAI,GAAe,CACpC,SAAU,EAAkB,QAC5B,YAAa,mPACb,aAAc,KAKhB,eAAgB,GAAI,GAAe,CACjC,SAAU,EAAkB,QAC5B,YAAa,kWACb,aAAc,IAAO,SAIvB,yBAA0B,GAAI,IAAmB,CAC/C,SAAU,EAAkB,QAC5B,YAAa;AAAA,kPACb,aAAc,IAAM,CAClB,0CACA,UACA,QACA,SACA,UACA,gBACA,uCACA,eACA,8BAQJ,UAAW,GAAI,GAAe,CAC5B,SAAU,EAAkB,QAC5B,YAAa,wDACb,aAAc,KAGhB,QAAS,GAAI,GAAe,CAC1B,SAAU,EAAkB,QAC5B,YAAa,qDACb,aAAc,KAGhB,iBAAkB,GAAI,GAAe,CACnC,SAAU,EAAkB,QAC5B,YAAa,kQACb,aAAc,KAGhB,OAAQ,GAAI,IAAkB,CAC5B,SAAU,EAAkB,QAC5B,YAAa,4MACb,aAAc,KACd,YAAa,CAAC,IAAK,KAAM,MAAO,MAGlC,gBAAiB,GAAI,GAAe,CAClC,SAAU,EAAkB,QAC5B,YAAa,kOACb,aAAc,IAAO,QAGvB,oBAAqB,GAAI,GAAe,CACtC,SAAU,EAAkB,QAC5B,YAAa,uEACb,aAAc,KAGhB,wBAAyB,GAAI,GAAe,CAC1C,SAAU,EAAkB,QAC5B,YAAa,mGACb,aAAc,KAGhB,kBAAmB,GAAI,IAAc,CACnC,SAAU,EAAkB,QAC5B,YAAa,wSACb,aAAc,OAGhB,sBAAuB,GAAI,IAAc,CACvC,SAAU,EAAkB,QAC5B,YAAa,0hBACb,aAAc,cAGhB,YAAa,GAAI,GAAe,CAC9B,SAAU,EAAkB,QAC5B,WAAY,CAAC,eACb,YAAa,yEACb,aAAc,KAGhB,eAAgB,GAAI,IAAmB,CACrC,SAAU,EAAkB,QAC5B,YAAa,2IACb,aAAc,IAAM,CAAC,SAAU,OAAQ,WAGzC,aAAc,GAAI,GAAe,CAC/B,SAAU,EAAkB,QAC5B,YAAa,sKACb,aAAc,KAGhB,eAAgB,GAAI,GAAe,CACjC,SAAU,EAAkB,QAC5B,YAAa,uKACb,aAAc,KAGhB,YAAa,GAAI,IAAmB,CAClC,SAAU,EAAkB,QAC5B,YAAa;AAAA,wEACb,aAAc,CACZ,SACA,gBACA,mCACA,uBAIJ,kBAAmB,GAAI,IAAkB,CACvC,SAAU,EAAkB,QAC5B,YAAa;AAAA;AAAA;AAAA,+DACb,aAAc,QACd,YAAa,CAAC,QAAS,kBAGzB,sBAAuB,GAAI,IAAc,CACvC,SAAU,EAAkB,QAC5B,YAAa,iPACb,aAAc,MAGhB,4BAA6B,GAAI,GAAe,CAC9C,SAAU,EAAkB,QAC5B,YAAa,mFACb,aAAc,KAGhB,cAAe,GAAI,IAAkB,CACnC,SAAU,EAAkB,QAC5B,YAAa,qMACb,aAAc,UACd,YAAa,CAAC,UAAW,aAG3B,wBAAyB,GAAI,IAAmB,CAC9C,SAAU,EAAkB,QAC5B,YAAa,gMACb,aAAc,IAAM,CAClB,IACA,UACA,KACA,QACA,SACA,KACA,MACA,QACA,MACA,MACA,KACA,KACA,KACA,MACA,KACA,KACA,KACA,KACA,MACA,QACA,MACA,MACA,cACA,UACA,MACA,UACA,MACA,IACA,QAIJ,iBAAkB,GAAI,IAAmB,CACvC,SAAU,EAAkB,QAC5B,YAAa,2dACb,aAAc,IAAM,KAGtB,cAAe,GAAI,IAAmB,CACpC,SAAU,EAAkB,QAC5B,YAAa,qYACb,aAAc,IAAM,KAGtB,wBAAyB,GAAI,IAAmB,CAC9C,SAAU,EAAkB,QAC5B,YAAa,kZACb,aAAc,CAAC,QAGjB,uBAAwB,GAAI,IAAmB,CAC7C,SAAU,EAAkB,QAC5B,YAAa,6YACb,aAAc,CAAC,KAAM,QAGvB,gBAAiB,GAAI,GAAe,CAClC,SAAU,EAAkB,QAC5B,YAAa,sWACb,aAAc,KAGhB,iBAAkB,GAAI,IAAmB,CACvC,SAAU,EAAkB,QAC5B,YAAa,2FACb,aAAc,IAAM,CAAC,QAAS,YAGhC,iBAAkB,GAAI,IAAc,CAClC,SAAU,EAAkB,QAC5B,YAAa,0WACb,aAAc,WAGhB,UAAW,GAAI,GAAe,CAC5B,SAAU,EAAkB,QAC5B,YAAa,kJACb,aAAc,KAGhB,kBAAmB,GAAI,IAAmB,CACxC,SAAU,EAAkB,QAC5B,YAAa,yKACb,aAAc,CAAC,mBAGjB,cAAe,GAAI,IAAc,CAC/B,SAAU,EAAkB,QAC5B,YAAa,4IACb,aAAc,oBAGhB,yBAA0B,GAAI,GAAe,CAC3C,SAAU,EAAkB,QAC5B,YAAa,8JACb,aAAc,KAGhB,oBAAqB,GAAI,IAAc,CACrC,SAAU,EAAkB,QAC5B,YAAa,4IACb,aAAc,0BAGhB,aAAc,GAAI,IAAc,CAC9B,SAAU,EAAkB,QAC5B,YAAa,4IACb,aAAc,mBAGhB,kBAAmB,GAAI,IAAmB,CACxC,SAAU,EAAkB,QAC5B,YAAa,2IACb,aAAc,CAAC,8CAiBjB,kBAAmB,GAAI,GAAe,CACpC,SAAU,EAAkB,cAC5B,YAAa,2VACb,aAAc,KAGhB,mBAAoB,GAAI,GAAe,CACrC,SAAU,EAAkB,cAC5B,YAAa;AAAA;AAAA;AAAA,iMACb,aAAc,KAGhB,QAAS,GAAI,IAAmB,CAC9B,SAAU,EAAkB,cAC5B,YAAa,iYAIjB,OAAW,CAAC,EAAG,IAAM,IAAQ,GAC3B,EAAE,SAAS,GAUN,YAA0B,EAA8B,CAC7D,GAAM,GAAK,GAAM,GAAS,GAAK,GAAO,MAAM,cAC5C,GAAI,GAAS,EAAM,GAAG,IAAI,YACxB,KAAM,IAAI,OAAM,2BAElB,SAAE,KAAK,GAAG,EAAS,UAAU,gBACtB,EAAK,GAAG,OAAO,GAAU,KAAK,cAGhC,GAAM,IAAmB,EAAK,IAAM,GAAiB,GAAG,IAAI,OAEtD,GAAoB,EAAK,IAAM,CAC1C,GAAM,GAAM,GAAO,GAAU,OAAO,GAAM,CAAC,EAAG,WAC9C,MAAO,IAAO,EAAK,GAAK,CACtB,EAAE,eAAiB,SAAW,EAAI,EAClC,EAAkB,QAAQ,EAAE,UAC5B,EAAE,SACF,EAAE,SAIO,GAA0B,EAAK,IAC1C,KAAoB,OAAO,GAAM,GAAiB,SAAS,EAAG,YAGnD,GAA2B,EAAK,IAC3C,KAAoB,OAAO,GAAM,GAAkB,SAAS,EAAG,YqFvjD1D,GAAU,IAAV,UAAU,EAAV,CACE,AAAM,YAAY,IAAM,GAClB,SAAkB,GAClB,UAAU,IAAM,CAAC,SACjB,oBAAoB,GAAW,WAJ7B,aAOjB,GAAM,IAAa,8CAOZ,QAAyC,CAQ9C,YAAY,EAAmB,CAP/B,YAAS,GAEQ,cAA8B,GAM7C,KAAK,MAAM,GAGb,MAAM,EAAmB,CACvB,KAAK,SAAS,OAAS,EACvB,GAAI,GAAoB,GAAW,EAAS,SAAS,cAC/C,EAAM,EAAS,GAAK,EAAI,EAAS,SAAS,eAChD,EAAc,EAAI,MAAM,MAAM,QAAQ,GAAM,CAC1C,GAAM,GAAQ,GAAW,KAAK,EAAG,QACjC,GAAI,GAAS,KACX,AAAK,IACH,QAAQ,MAAM,4BAA8B,EAAK,UAAY,OAE1D,CACL,GAAM,GAAS,EAAI,EAAM,IAAI,cACvB,EAAM,GAAW,EAAM,IAC7B,AAAI,EAAM,GACR,EAAoB,EAEpB,KAAK,SAAS,KAAK,CAAE,SAAQ,WAAY,OAI/C,KAAK,kBAAoB,EAGnB,gBAAgB,EAA0C,CAChE,GAAI,KAAK,SAAS,SAAW,GAAK,EAAM,GAAU,OAClD,GAAM,GAAI,EAAI,GAAS,cACvB,MAAO,MAAK,SAAS,KAAK,GAAM,EAAE,WAAW,EAAG,SAGlD,QAAQ,EAAiB,EAA2B,CAClD,GAAI,KAAK,OAAQ,MAAO,GACxB,GAAM,GAAK,GAAW,GAEtB,GAAI,GAAM,KAAK,kBACb,MAAO,GAET,GAAM,GAAK,KAAK,gBAAgB,GAEhC,MADe,IAAM,MAAQ,GAAM,EAAG,WAIxC,UAAU,EAAiB,CAEzB,GAAM,GAAK,KAAK,gBAAgB,GAChC,MAAO,IAAM,MAAQ,EAAG,YAAc,KAAK,oBAI3C,GAEG,aAAgC,CACrC,MAAI,KAAc,MAChB,IAAa,GAAI,IACjB,EAAS,SAAS,YAAY,IAAM,GAAY,UAE3C,GAGF,GAAM,IAAkB,EAC7B,IAAM,GAAU,OAAO,KAAY,mBACnC,EAAI,GAqCC,YAAkB,EAAoB,EAAsB,CACjE,MAAO,MAAY,QAAQ,GAAY,IAAM,OClJxC,YAAqB,CAG1B,YAAqB,EAAsC,CAAtC,eAFZ,WAAa,MAIlB,SAAS,CACX,MAAO,MAAK,MAAM,OAGpB,IAAI,EAAa,CACf,GAAI,GAAK,KACP,OAEF,GAAM,GAAI,KAAK,QAAQ,GACvB,GAAI,GAAK,KAGT,IAAI,KAAK,MAAM,SAAW,EAAG,CAC3B,KAAK,MAAM,KAAK,GAChB,OAGF,GAAI,GAAG,EAAG,KAAK,QAAQ,KAAK,MAAM,KAAM,CACtC,KAAK,MAAM,QAAQ,GACnB,OAEF,OAAS,GAAI,KAAK,MAAM,OAAS,EAAG,GAAK,EAAG,IAC1C,GAAI,GAAI,KAAK,QAAQ,GAAI,KAAK,QAAQ,KAAK,MAAM,KAAM,CACrD,KAAK,MAAM,OAAO,EAAI,EAAG,EAAG,GAC5B,OAIJ,KAAK,MAAM,QAAQ,IAMrB,QAAQ,EAAoB,CAC1B,GAAI,KAAK,SAAW,EAAG,MAAO,GAC9B,GAAI,GAAQ,EACZ,GAAI,GAAG,KAAK,QAAQ,GAAK,KAAK,QAAU,GAEtC,EAAQ,KAAK,MAAM,WAGnB,MAAO,GAAG,KAAK,QAAQ,KAAK,MAAM,IAAS,IACzC,IASJ,MANe,KAAU,EAAI,GAAK,KAAK,OAAO,EAAG,GAcnD,OAAO,EAAe,EAA2B,CAC/C,MAAO,MAAK,MAAM,OAAO,EAAO,KCtEpC,OAAoB,sBCApB,OAAwB,mBCAxB,OAAyB,oBAKzB,GAAM,IAAQ,KAAK,MAEZ,YAAoB,EAAY,CACrC,GAAM,GAAS,EAAS,aAAa,eAEjC,YAAS,WAAW,EAAK,IAAO,SAAS,kBACzC,GAAI,MAAK,GAAI,cAEjB,MAAI,GAAS,SAAS,eACb,EAAS,aAAa,eACzB,GAAO,GACP,GAAS,GAEN,EAIJ,GAAM,IAAoB,GAAS,IAAM,IDNzC,YAAkD,CAmBvD,YAAY,EAA4C,GAAI,CAlB3C,eAAY,CAC3B,MAAO,QACP,MAAO,GAAS,SAChB,KAAM,GAAK,SACX,MAAO,GAAU,SACjB,KAAM,GAAa,UAcnB,KAAK,eAAiB,OACjB,GAAoB,yBACpB,GAED,IACF,MAAK,eAAe,YAAc,KAItC,WAAW,EAAqB,CAC9B,GAAI,GAAQ,KAAM,OAClB,GAAM,GAAI,GAAS,GACnB,MAAO,IAAK,KAAO,OAAY,eAAQ,EAAG,KAAK,gBAGjD,eAAe,EAAsB,CACnC,GAAM,GAAe,KAAY,UAAU,EAAG,KAAO,GAAS,GAC9D,MAAO,GAAc,CACnB,GAAW,EAAG,IACd,GACE,EAAO,EAAG,KAAM,IAAM,KAAK,eAAe,gBAE5C,KAAK,UAAU,EAAG,GAClB,EAAa,EAAG,KAChB,EAAG,IACH,KAAK,WAAW,EAAG,QAElB,IAAI,GAAM,EAAI,IACd,KAAK,KAGV,OACE,EACA,EACA,EACA,EACQ,CACR,MAAO,MAAK,eAAe,CACzB,GAAI,KAAK,MACT,EAAG,EACH,KAAM,KACN,IAAK,EACL,IAAK,EACL,WA/DC,MASE,AATF,GASE,sBAAiD,IAAO,EAC7D,WAAY,GACZ,MAAO,EACP,OAAQ,GACR,QAAS,GACT,cAAe,GACf,eAAgB,GAAe,EAC/B,YAAa,KEhCjB,OAAwC,mBAYjC,YAAoD,CACzD,YACW,EAAiC,CACxC,OAAQ,GACR,MAAO,EACP,QAAS,GACT,cAAe,IAEjB,CANS,sBAQF,qBAAkB,GACzB,GAAU,OAAO,IAAI,GAAM,CAAC,EAAI,GAAS,EAAI,EAAG,QAGlD,eAAe,EAAsB,CACnC,MAAO,GAAc,CACnB,GAAW,EAAG,IACd,KACA,KAAK,gBAAgB,EAAG,GACxB,GAAa,EAAG,KAChB,GAAa,EAAG,KAChB,EAAI,EAAG,KAAM,GAAM,eAAQ,EAAI,KAAK,mBAEnC,IAAI,GAAM,EAAI,IACd,KAAK,KAGV,OACE,EACA,EACA,EACA,EACQ,CACR,MAAO,MAAK,eAAe,CACzB,GAAI,KAAK,MACT,EAAG,EACH,KAAM,KACN,IAAK,EACL,IAAK,EACL,WH7CN,GAAM,IAAgB,EAAK,IAAM,CAC/B,EAAS,SAAS,YAAY,IAAM,GAAoB,WAG7C,GAAsB,EAAK,IAClC,QAAI,UAAY,MAAM,GAAS,SAAS,SAAW,IACvD,KACO,EAAS,SAAS,eACrB,GAAI,IAAoB,CAAE,YAAa,IAAM,KAC7C,GAAI,MIUH,YAAwB,EAAc,CAC3C,MAAO,IAAI,GCnBb,GAAI,IAAkB,GAMf,YAA2B,EAAY,CAC5C,GAAkB,EAGpB,GAAM,IAAa,GAAI,IAAsB,IAEtC,eAA2B,EAAiB,CAEjD,OAAW,KAAM,GAEf,AAAI,GACF,GAAW,IAAI,GAEf,QAAQ,IAAI,KAAsB,eAAe,IAQhD,YAA8B,EAAM,GAAoB,EAAG,CAChE,MAAO,IAAW,QAAQ,KAAK,MAAQ,GCxBlC,YAA4C,CAGjD,IAAI,EAAiB,EAAiB,EAAa,EAAY,CAC7D,GAAe,CACb,GAAI,KAAK,MACT,EAAG,EACH,KAAM,KACN,IAAK,EACL,MACA,SAIJ,QAAQ,EAAiB,EAA0B,CACjD,MAAO,MAAY,QAAQ,EAAO,QAG9B,QAAQ,EAId,KAAM,IAtBD,MACW,AADX,GACW,SAAW,EAAK,IAAM,GAAI,KCX5C,OAAqB,mBACrB,GAA8B,qBCEvB,YAA8B,EAAqB,CAExD,GAAI,CACF,GAAI,EAAS,GACX,MAAO,MAAK,MAAM,QAEpB,GAMG,YAAsB,EAAW,EAA6B,CACnE,GAAI,CACF,GAAI,EAAS,GACX,MAAO,GAAE,KAAK,MAAM,SAEtB,GDrBJ,GAAO,IAAc,cAmEd,YAAiD,CAgBtD,YACW,EACT,EAAuD,GACvD,CAFS,cAfX,WAAQ,GACS,WAAQ,GAAI,IAErB,uBAA4B,EAGnB,mBAA0B,GAEnC,iBAAc,EAIb,kBAAe,GAAK,EA8CpB,SAAM,EAAK,SAClB,MAAK,MAAQ,GACb,EAAI,KAAK,cAAe,kBACxB,KAAK,cAAgB,OACrB,KAAM,MAAK,QACJ,KAAK,MAAM,OAAO,QAAS,IACzB,KAAK,mBAIC,gBAAa,IAC5B,KAAK,MAAM,SAAS,aAAc,IAAM,KAAK,UAEtC,kBAAe,IACtB,KAAK,SAAW,MAAQ,KAAK,mBAAqB,KAAK,KAAK,gBAtD5D,KAAK,KAAO,aAAe,EAAS,IACpC,KAAK,KAAO,GACV,gBAAiB,KACjB,YAAa,GAAc,WAC3B,aAAc,GACd,YAAa,IACV,GAEL,KAAK,cAAgB,GACnB,IAAM,KAAK,aACX,KAAK,KAAK,cAEZ,GAAiB,MAGnB,IAAI,EAAiB,EAAiB,EAAa,EAAY,CAC7D,GAAI,KAAK,OAAS,IAAU,QAE1B,KAAK,KAAK,YAAY,IAAI,EAAO,EAAS,EAAK,OAC1C,CACL,GAAM,GAAkB,CAAE,GAAI,KAAK,MAAO,EAAG,EAAO,IAAK,EAAS,OAClE,AAAI,GAAQ,MAAM,GAAM,KAAO,GAC3B,IAAU,SAEZ,MAAK,wBACA,KAAK,SAEZ,KAAK,cAAc,KAAK,EAAU,GAAS;AAAA,IAK/C,uBAAwB,CACtB,KAAK,cAAc,KACjB,GAAG,KAAmB,IAAI,GAAM,EAAU,GAAM;AAAA,IAGlD,UAmBI,QAAQ,CACZ,KAAM,MAAK,MAAM,OAAO,QAAS,IAAM,KAAK,eAGhC,SAAS,CACrB,GAAM,GAAU,CAAC,GAAG,KAAK,eAEzB,IADA,KAAK,cAAc,OAAS,EACrB,EAAQ,OAAS,GAAG,CACzB,AAAI,KAAK,gBAAgB,KAAM,MAAK,UACpC,GAAM,GAAS,KAAK,QACpB,GAAI,GAAU,KAAM,CAClB,KAAK,KAAK,YAAY,IACpB,QACA,oBACA,2CAEF,OAEF,GAAM,GACJ,KAAK,KAAK,gBAAkB,KAAK,kBAC7B,EAAQ,EAAQ,OAAO,EAAG,GAChC,KAAK,mBAAqB,EAAM,OAChC,EAAO,MAAM,EAAM,KAAK,MAKpB,QAAQ,EAAgB,CAC9B,MAAO,AAAC,IACN,KAAK,KAAK,YAAY,IAAI,QAAS,qBAAuB,EAAQ,QAGxD,UAAyB,CACrC,KAAM,MAAK,gBACX,KAAK,aAAe,KAAM,IAAqB,CAC7C,WAAY,YACV,KAAK,OACL,GAAW,GAAI,OACf,GAAa,KAAK,KAAK,eAAiB,QAE1C,WAAY,GACZ,WAAY,EAAE,KAAK,YACnB,cAAe,GACf,QAAS,IAEX,KAAK,QAAU,GACZ,kBAAkB,KAAK,cACvB,GAAG,QAAS,KAAK,QAAQ,2BAIhB,gBAAgB,CAE5B,GAAM,GAAc,KAAK,QACzB,KAAK,QAAU,OACf,KAAK,kBAAoB,EACzB,GAAM,GAAY,KAAK,aACvB,KAAK,aAAe,OAEpB,KAAM,IAAU,GACZ,EAAS,eAAe,gBAE1B,MAAM,IAAW,KAAK,KAAK,cAC3B,KAAM,GAAI,EAAW,OAK3B,kBACE,EACA,EAC0B,CAC1B,GAAM,GAAO,GAAiB,EAAE,MAChC,MAAO,GAAQ,GAAK,EAAE,WAAY,GAAU,GAC1C,EACE,EAAc,GAAW,IAAI,IAAI,GAC/B,GAAU,EAAI,GAAO,OAAK,GAAL,CAAS,aE1MtC,GAAM,IAAc,EAAqB,IAAM,CAAC,GAAc,aAEvD,aAA+C,CACpD,MAAO,MAAc,KAAK,GAAM,YAAc,KAGzC,aAAuB,CAC5B,GAAM,GAAS,EAAS,OAAO,eAC3B,EAAK,KACT,AAAI,IAAM,MAAQ,EAAG,SAAW,IACzB,IAAI,GACT,EAAK,GAAI,IAAU,IAErB,GAAM,GAAsB,CAAC,GAC7B,AAAI,GAAS,UAAU,gBAAkB,EAAS,SAAS,iBACzD,EAAI,KAAK,GAAc,YAEzB,GAAY,IAAI,GAGX,aAAiC,CACtC,MAAO,OAAqB,wBAKvB,WAAkB,EAAmC,CAC1D,MAAO,IAAI,IAAiB,EAAS,I3ItBhC,GAAM,IAAe,GAC1B,OACA,MACA,OACA,YACA,OACA,OACA,SACA,UACA,OACA,WAKK,YAA0B,EAA+B,CAC9D,GAAM,GAAM,GAAa,QAAQ,GACjC,MAAO,GAAM,EAAI,GAAa,OAAS,EAAI,EAGtC,GAAM,IAAmC,CAAC,OAAQ,QAK5C,GAAiC,CAAC,OAAQ,MAAO,OAAQ,QACzD,GAAiC,CAAC,OAAQ,aAMhD,YAAkC,EAA8B,CACrE,OAAQ,OACD,WACA,MACH,MAAO,OACJ,WACA,oBAEH,MAAO,IAAK,GAIlB,GAAI,IAA4B,GAEzB,aAAuB,CAC5B,GAAI,EAAM,IAAe,KAAM,OAAM,0BACrC,MAAO,IAGF,YAAwB,EAAgB,CAC7C,GAAI,CAAC,IAAU,IAAM,IAAiB,KAAyB,GAC7D,KAAM,IAAI,OAAM,iCAElB,GAAe,EACf,GAAY,QACZ,KAQF,GAAM,IAAa,EAAK,IAAM,CAC5B,CAAE,GAAI,oBAAqB,EAAG,IAC9B,CAAE,GAAI,OAAQ,EAAG,IACjB,CAAE,GAAI,MAAO,EAAG,IAChB,CAAE,GAAI,KAAM,EAAG,IACf,CAAE,GAAI,OAAQ,EAAG,IACjB,CAAE,GAAI,OAAQ,EAAG,IACjB,CAAE,GAAI,OAAQ,EAAG,MAGN,GAAc,EAAK,IAC9B,EAAc,CAAC,GAAc,EAAI,UAAO,KAAK,MAGxC,YAA0B,EAAmB,CAClD,GAAM,GAAK,KAAa,KAAK,GAAM,EAAE,MAAM,EAAG,KAC9C,MAAO,IAAM,KAAO,GAAQ,EAAG,EAAE,IAAM,EAGlC,aAAyB,CAI9B,MAAO,MAAiB,GAAa,KAGhC,aAAwB,CAI7B,MAAO,MAAiB,GAAa,IAOhC,aAAgC,CACrC,MAAO,IAAkB,SAAS,MAG7B,aAAgC,CACrC,MAAO,CAAC,MAAiB,KAAiB,OAGrC,aAAyB,CAE9B,MAAO,MAAiB,OAGnB,aAA6B,CAElC,MAAO,MAAiB,YAMnB,aAA4B,CACjC,MAAO,IAAgB,SAAS,MAG3B,aAA2B,CAEhC,MAAO,IAAgB,SAAS,MAI3B,GAAM,IAAoB,EAC/B,IAAM,MAAoB,IAAU,CAAC,M4I3JvC,OAAuB,sBAGvB,GAAM,IAAO,GAAI,QAAO,cAEX,GAAoB;AAAA;AAAA,sBAEd;AAAA;AAAA,qHAIN,GAAU,CACrB,KACE,iFACF,KAAM,6DACN,KAAM,+BACN,OAAQ,iEACR,QACE,yFACF,IAAK,+DACL,KACE,qFACF,YACE,iFAGG,YAAmB,EAAqB,CAC7C,MAAO,GAAE,GAAG,SAAU,IAAM,CAC1B,QAAQ,IACN;AAAA,EACE,GAAK,GAAmB,CACtB,WAAY,UAAO,SAAW,GAC9B,OAAQ,KACP,KAAK;AAAA,GACR;K7IrBD,YAAU,CAMf,YACW,EACA,EACA,EACT,CAHS,mBACA,YACA,6BARM,aAA2B,GAU1C,GAAe,GAGjB,OAAO,EAA0B,CAC/B,YAAK,QAAQ,KAAK,GAAG,GACd,UAGH,QAAQ,CACZ,GAAI,GAAM,GACR,WAAQ,YACN,GAAQ,KAAK,aACX,GACE,KAAK,sBACL,GAAM;AAAA;AAAA,EAAS,EACf,IAAM,MAKd,EAAI,KAAK,KAAM,GAAM,CACnB,EAAM,EAAI,UAAU,KAGtB,OAAW,KAAM,MAAK,QACpB,EAAM,EAAG,YAAY,GAGvB,EAAI,QACF,GACA,YACA,4CAA8C,GAAU,KAG1D,EAAI,MAAM,WAAE,MAEZ,GAAM,GAAO,EAAI,OAEjB,OAAW,KAAM,MAAK,QACpB,KAAM,GAAG,WAAW,GAGtB,MAAO,K8InEX,OAAc,sBAUP,YAAkB,EAAsB,CAC7C,MACE,GAAO,WAAE,IAAI,cAAgB,EAAO,GAAM,SAAW,CAAC,EAAM,GAAM,SCF/D,GAAM,IAAU,CACrB,YAAa,CAAC,EAAc,EAAkB,KAC5C,GAAI,OACF,SACA,+IAEG,GACH,EAAI,OACF,mBACA,wJAGJ,EACG,OACC,UACA,oQAED,OAAO,UAAW,+BAAgC,IAClD,OAAO,aAAc,iCAEjB,GAET,WAAY,AAAC,GAAe,CAC1B,EAAI,EAAK,MAAO,GAAO,EAAS,SAAS,SAAW,GAEpD,GAAM,GAAO,EAAO,EAAK,MACnB,EAAO,EAAO,EAAK,OAAS,EAAO,EAAK,SACxC,EAAQ,EAAO,EAAK,OAE1B,AAAI,GAAM,GAAS,SAAS,SAAW,QACnC,GAAM,GAAS,SAAS,SAAW,QACnC,GAAO,GAAS,SAAS,SAAW,SAEpC,CAAC,GAAS,IAAU,IAAQ,GAAQ,IACtC,GAAS,UAAU,SAAW,MCjC7B,GAAM,IAA4B,CACvC,YAAa,AAAC,GAAiB,CAC7B,GAAM,GAAkB,GACxB,SACG,OACC,SACA,wJAED,OACC,YACA,oGAED,OACC,SACA,4TAGJ,GAAQ,YAAY,EAAK,GAEzB,EAAI,OACF,2BACA,6JAGK,GAQT,WAAY,AAAC,GAAe,CAM1B,GALA,GAAQ,WAAW,GAEf,EAAO,EAAK,UACd,GAAS,aAAa,SAAW,EAAK,SAEpC,GAAS,GAEX,EAAS,UAAU,SAAW,GAC9B,EAAS,SAAS,SAAW,OACxB,CACL,GAAM,GAAU,EAAO,EAAK,SAC5B,AAAI,GAAW,EAAS,SAAS,WAC/B,GAAS,SAAS,SAAW,QAG3B,GAAO,EAAK,OAAS,IACvB,GAAS,SAAS,SAAW,IAG3B,EAAO,EAAK,YACd,GAAS,UAAU,SAAW,OC/D/B,GAAM,IAAe,mBCSrB,GAAM,IAAiC,CAC5C,YAAa,AAAC,GACZ,EAAI,OACF,GAAe,kBACf,oGAEJ,WAAY,AAAC,GAAe,CAC1B,AAAI,EAAO,EAAK,eACd,GAAS,aAAa,SAAW,MClBvC,OAAuB,uBCAvB,OAAoB,mBCqBb,GAAM,IAAiB,CAC5B,CAAC,CAAC,OAAQ,qCACV,CAAC,CAAC,OAAQ,+BACV,CAAC,CAAC,MAAO,QAAS,wDAClB,CAAC,CAAC,MAAO,QAAS,sDAUlB,CAAC,CAAC,OAAQ,2CACV,CAAC,CAAC,OAAQ,+BACV,CAAC,CAAC,OAAQ,qCACV,CAAC,CAAC,OAAQ,wCACV,CAAC,CAAC,QAAS,2CAMX,CAAC,CAAC,OAAQ,uCACV,CAAC,CAAC,OAAQ,4CACV,CAAC,CAAC,OAAQ,qCACV,CAAC,CAAC,MAAO,QAAS,iDAGlB,CAAC,CAAC,OAAQ,0CAKV,CAAC,CAAC,OAAQ,iCACV,CAAC,CAAC,OAAQ,yCAIV,CAAC,CAAC,OAAQ,iCAQV,CAAC,CAAC,MAAO,iBAMT,CAAC,CAAC,OAAQ,iCAEV,CAAC,CAAC,QAAS,wDAEX,CAAC,CAAC,OAAQ,oCAKV,CAAC,CAAC,OAAQ,gDACV,CAAC,CAAC,OAAQ,0CAQV,CAAC,CAAC,OAAQ,0CACV,CAAC,CAAC,OAAQ,yBAEV,CACE,CAAC,MAAO,MAAO,OACf,yDAEF,CAAC,CAAC,OAAQ,oCACV,CAAC,CAAC,OAAQ,OAAQ,OAAQ,kDAK1B,CAAC,CAAC,OAAQ,wDAEV,CAAC,CAAC,QAAS,iCACX,CAAC,CAAC,QAAS,oCAIX,CAAC,CAAC,MAAO,MAAO,OAAQ,wBACxB,CAAC,CAAC,MAAO,MAAO,MAAO,OAAQ,uCAC/B,CAAC,CAAC,OAAQ,MAAO,OAAQ,0CASzB,CACE,CAAC,OAAQ,MAAO,OAChB,kDAEF,CAAC,CAAC,MAAO,MAAO,MAAO,OAAQ,wCAG/B,CAAC,CAAC,OAAQ,+CACV,CAAC,CAAC,OAAQ,sDAOV,CAAC,CAAC,MAAO,MAAO,yBAEhB,CAAC,CAAC,OAAQ,4DAEV,CAAC,CAAC,OAAQ,MAAO,OAAQ,+CAEzB,CAAC,CAAC,OAAQ,+BACV,CAAC,CAAC,OAAQ,eAEV,CAAC,CAAC,OAAQ,8CAEV,CAAC,CAAC,OAAQ,8BAWV,CAAC,CAAC,OAAQ,mCAQV,CAAC,CAAC,OAAQ,+CAOV,CAAC,CAAC,MAAO,MAAO,OAAQ,iDACxB,CAAC,CAAC,MAAO,MAAO,OAAQ,+BAcxB,CAAC,CAAC,OAAQ,uBAGV,CAAC,CAAC,OAAQ,gCACV,CAAC,CAAC,OAAQ,8BAKV,CAAC,CAAC,OAAQ,gCACV,CAAC,CAAC,OAAQ,0BAKV,CAAC,CAAC,OAAQ,2BACV,CAAC,CAAC,OAAQ,gCACV,CAAC,CAAC,OAAQ,mCAKV,CAAC,CAAC,OAAQ,OAAQ,4BASlB,CAAC,CAAC,QAAS,qCACX,CAAC,CAAC,QAAS,mCACX,CAAC,CAAY,OAAQ,yCAGrB,CAAC,CAAC,OAAQ,oBAQV,CAAC,CAAC,OAAQ,8CAIC,GAAW,GACtB,WACA,QACA,QACA,UACA,YACA,OACA,4BACA,yBAKI,GAAY,EAAK,IAAM,CAC3B,GAAM,GAAI,GAAI,IAIR,EAAe,CACnB,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,OAEF,OAAW,KAAO,GAChB,EAAE,IAAI,EAAK,GAAS,UAGtB,GAAM,GAAY,EAAQ,CAAC,MAAO,OAAQ,MAAO,MAAO,OAAQ,SAEhE,OAAW,KAAO,GAChB,EAAE,IAAI,EAAK,GAAS,OAGtB,GAAM,GAAY,CAChB,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,OACA,MACA,MACA,OACA,OAEF,OAAW,KAAO,GAChB,EAAE,IAAI,EAAK,GAAS,OAGtB,GAAM,GAAgB,CAAC,GAAG,EAAW,OAAQ,GAAG,EAAc,GAAG,GAEjE,OAAW,KAAO,GAChB,EAAE,IAAI,EAAK,GAAS,WAGtB,OAAW,KAAO,IAChB,EAAE,IAAI,EAAK,GAAS,SAGtB,OAAW,KAAO,CAAC,GAAG,EAAe,GAAG,IACtC,EAAE,IAAI,EAAK,GAAS,MAGtB,OAAW,KAAO,CAAC,MAAO,OAAQ,MAAO,MAAO,OAAQ,QACtD,EAAE,IAAI,EAAK,GAAS,2BAGtB,OAAW,KAAO,CAAC,MAAO,OAAQ,MAAO,OACvC,EAAE,IAAI,EAAK,GAAS,uBAItB,GAAM,GAAO,GAAe,IAAI,GAAM,EAAG,IAEzC,OAAW,KAAO,GAAE,OAAQ,CAC1B,GAAM,GAAU,EAAK,KAAK,GAAM,EAAG,SAAS,IAC5C,GAAI,GAAW,MAAQ,EAAQ,OAAS,EAAG,CACzC,GAAM,GAAS,EAAE,IAAI,GACrB,OAAW,KAAS,GAClB,AAAK,EAAE,IAAI,IACT,EAAE,IAAI,EAAO,IAMrB,MAAO,KAGF,YAAkB,EAAsC,CAC7D,MAAO,GAAI,GAAa,GAAM,GAAM,KAAY,IAAI,IAGtD,GAAM,IAAa,uBAEZ,YAAsB,EAAmC,CAC9D,MAAO,GAAI,GAAW,KAAK,EAAI,IAAO,GAAK,EAAE,GAAG,eAG3C,YAAmB,EAAoB,EAAkB,CAC9D,MAAO,GACL,GAAS,GACT,GAAM,EAAG,SAAS,GAClB,IAAM,IAuBH,YAAoB,EAA6B,CACtD,MAAO,IAAU,EAAK,GAAS,OAE1B,YAAsB,EAA6B,CACxD,MAAO,IAAU,EAAK,GAAS,SAK1B,YAAmB,EAA6B,CACrD,MAAO,IAAU,EAAK,GAAS,MAE1B,YAAwC,EAA6B,CAC1E,MAAO,IAAU,EAAK,GAAS,2BCxY1B,YACL,EACA,EACQ,CACR,GAAM,GAAI,GAAU,GACpB,MAAO,KAAM,GAAK,EAAO,EAAO,IAAM,EAGjC,YACL,EACA,CACA,GAAI,GAAS,KAAM,MAAO,GAC1B,GAAM,GAAI,GAAQ,GAAO,OAAO,CAAC,CAAC,CAAE,KAAO,GAAK,MAChD,MAAI,GAAQ,GAAW,GAChB,EAAE,IAAI,GAAM,EAAG,IAAI,GAAK,IAAI,oBAAoB,KAAK,MAAM,KAAK,KAclE,GAAM,IAAsB,QAKtB,GAAyB,SAKzB,GAAiC,QC3C9C,OAAgC,kBCWzB,YACL,EACA,EACyB,CACzB,GAAI,GAAY,EACV,EAAQ,GAAI,IAAkB,GAC9B,EAAS,AAAC,GACd,KACO,EAAM,cAAc,EAAU,GAAI,SAAY,EAAE,KAEzD,SAAE,MAAQ,AAAC,GAAU,CACnB,GAAI,GAAK,KACP,EAAM,YACD,CACL,GAAM,GAAO,EAAU,GACvB,EAAM,SAAS,GAAM,IAAS,KAGlC,EAAE,KAAO,IAAM,EAAM,KACrB,EAAE,UAAY,IAAM,EACb,ECpBF,GAAM,IAAO,GAClB,KAAO,IAAmB,CACxB,GAAM,GAAM,EAAQ,KAAM,MAAY,OACtC,MAAO,IAAO,EAAK,CAAC,EAAQ,KAAO,KAAM,IAAK,GAAS,CACrD,QAAS,EAAI,KAGjB,CAAE,QAAS,IAAK,UAAW,GAAmB,aAAc,GAAK,IAGtD,GAAS,GAAI,QACxB,MAAQ,GAAM,EAAG,IAAM,cAAc,KAAK,OAAS,OAGxC,GAAiB,GAC5B,KAAO,IACE,EACL,KAAM,IAAK,GAAQ,MAAM,GAAO,CAC9B,QAAQ,KAAK,mBAAqB,MAInC,OAAO,GACP,QAAQ,GAAU,GAAO,KAAK,EAAI,KAClC,IAAI,GAAS,EAAM,IACnB,MAEL,CAAE,QAAS,IAAK,UAAW,GAAmB,aAAc,GAAK,IFpBnE,GAAM,IAAU,GAAI,QAAO,IAAM,GAAO,OAAS,KAKpC,GAAe,GAC1B,KAAO,IAAqB,CAC1B,GAAM,GACJ,GAAQ,KAAK,IAAa,KAAO,EAAW,KAAM,IAAS,GAC7D,MAAO,GAAI,GAAQ,cAAc,aAEnC,CAAE,QAAS,IAAK,UAAW,KAGvB,GAAa,yEAEZ,YAAoB,EAAuB,CAChD,MAAO,IAAW,KAAK,IAAS,KAG3B,YAAgB,EAAmC,CACxD,GAAM,GAAmB,EACtB,MAAM,KACN,IAAI,GAAM,EAAM,IAChB,OAAO,GAAM,GAAO,EAAG,IAAK,IAC/B,MAAO,GAAO,SAAW,EAAI,EAAS,OAMjC,GAAM,IAAW,GACtB,KAAO,IAA6C,CAClD,GAAI,GAAM,GACV,IAAI,GAAO,IAAa,KAAM,MAAO,CAAC,GACtC,GAAI,CACF,MAAO,MAAM,aAAI,SAAS,SACnB,EAAP,CACA,KAAS,KAAK,qBAAuB,GACrC,UAGJ,CAAE,QAAS,IAAK,UAAW,GAAmB,aAAc,GAAK,IAG7D,GAAS,EAAK,IAAM,EAAS,aAEnC,EAAM,IAAM,EAAa,IAAM,GAAS,UAKjC,GAAM,IAAW,GACtB,KAAO,IAAqB,CAC1B,GAAI,CACF,GAAM,GAAQ,KAAM,IAClB,IACE,GAAW,GACP,EAAS,WAAW,QAClB,CAAC,aACD,CAAC,aACH,GAAO,IAAa,KACpB,YAAI,QAAQ,GACZ,YAAI,SAAS,GACnB,EAAI,GAEN,GAAI,GAAS,KACX,YAAS,KAAK,YAAc,EAAW,cAChC,EAET,GAAM,GAAgB,EAAM,KAAK,GACjC,MAAI,IACF,MAAS,KAAK,qBAAuB,GAC9B,SAIF,EAAP,CACA,YAAS,KAAK,qBAAuB,EAAW,gBAAiB,GAC1D,IAGX,CAAE,QAAS,IAAK,UAAW,GAAmB,aAAc,GAAK,IAGnE,kBACE,EACA,EACkB,CAClB,MAAI,GAAM,IAAM,EAAM,GAAW,GAC7B,GAAiB,EAAG,IACpB,GAAW,IAAM,GAAW,GAAW,GACpC,GACL,GAAS,GACT,GAAS,GACT,CAAC,EAAQ,IAAW,EAAO,KAAK,GAAM,EAAO,SAAS,IACtD,IAAM,IGxGV,GAAM,IAAU,uCAOhB,mBAA+B,CAC7B,GAAM,GAAU,KAAM,IAAO,QAAS,GAAI,CAAE,QAAS,IACrD,MAAO,GACL,EAAQ,MAAM;AAAA,GAAM,IAAI,GACf,EAAI,GAAQ,KAAK,GAAK,GAAK,CAChC,GAAM,CAAC,EAAY,EAAY,GAAQ,EAAE,MAAM,GACzC,EAAU,EAAK,MAAM,KAAK,IAAI,GAAO,EAAI,QAC/C,MAAO,CACL,aACA,aACA,eAOH,GAAM,IAA0B,EAAK,SACnC,GAAY,KAAM,MAAU,KAAM,IAErC,EAAE,QAAQ,SAAS,aACnB,EAAE,QAAQ,SAAS,eAClB,KAAM,IAAa,EAAE,aAEvB,KAAK,GAAO,EAAI,IAAI,GAAM,EAAG,aAC/B,IAEH,kBAAmC,EAAoB,CACrD,GAAM,GAAI,GAAS,IAAI,GACjB,EAAQ,KAAM,IAClB,KAAM,GAAE,aACR,GACE,EACG,OAAO,GAAM,CAAC,EAAG,WAAW,MAC5B,IAAI,GAAM,EAAG,eACb,OACL,IAAM,IAER,MAAO,IAAI,EAAO,CAAC,eAAgB,uBC7CrC,YAAa,EAAmB,CAC9B,MAAO,GAAM,EAAG,CAAE,aAAc,IAAQ,KAG1C,GAAM,IAAsB,CAAC,SAIvB,GAAwB,CAAC,OAAQ,QAAS,WAAY,OACtD,GAAmB,GAAQ,GAAsB,GAEjD,GAAuB,CAAC,YAAa,YAE3C,kBACE,EACA,EACqB,CACrB,GAAM,GAAW,GAAQ,KAAM,MAA4B,GACrD,EAAO,CAAC,KAAM,MACpB,AAAI,GAAY,EAAK,KAAK,MACtB,EAAS,IAAO,EAAK,KAAK,GAC9B,GAAM,GAAS,KAAM,IAAO,KAAM,EAAM,CACtC,QAAS,EAET,aAAc,GACd,eAAgB,KAalB,MAAO,AAXQ,IACb,CACE,aACA,cACA,OACA,YACA,WACA,cAEF,GAGC,IAAI,GAAO,EACV,WAAY,EAAG,WACf,KAAM,GAAI,EAAG,gBACb,KAAM,GAAI,EAAG,MACb,UAAW,GAAI,EAAG,WAClB,WAAY,EAAG,iBAEhB,OAAO,GAAM,CACZ,GAAM,GAAK,EAAI,EAAG,YACZ,EAAK,EAAI,EAAG,YAClB,MACE,GAAS,IACT,CAAC,GAAqB,SAAS,IAC/B,EAAS,IACT,CAAC,EAAS,SAAS,IACnB,CAAC,GAAiB,SAAS,KCzC5B,GAAM,IAAiB,EAAK,SAAY,CAC7C,GAAI,CAAC,IAAW,KACd,MAAO,GAGT,GAAI,CAKF,MAAO,AAJQ,MAAM,IAAa,GAAY,CAAC,WAAY,CACzD,QAAS,EACT,aAAc,MAEF,OAAS,QAChB,EAAP,CACA,MAAO,MAIE,GAAa,MACb,GAAsB,CAAC,QAAS,YAAa,eAEpD,GAAQ,EAAK,IAAM,EAAS,qBAUrB,GAAa,EACxB,IACE,GACE,SAAY,CAEV,GAAM,GAAO,KAAM,MACb,EACJ,MAAM,IACJ,EAAK,IAAI,KAAM,IAAO,CACpB,GAAM,GAAU,KAAM,IAAW,GAAO,EAAI,YAAY,MACtD,GAAO,CACL,KAAQ,KAAK,gBAAkB,EAAM,KAAO,KAI1C,EAAM,EAAI,EAAS,GAAM,EAAG,IAClC,SAAI,EAAK,GAAO,EAAG,WAAa,EAAI,YAC7B,MAGX,OAAO,GAAO,EAAI,KAAO,GAE3B,MAAO,SAAQ,IACb,EAAK,IAAI,KAAM,IACb,GACE,GAAc,EAAI,YAClB,GACE,GAAI,WAAa,EAAW,WAC5B,EAAI,YAAc,EAAW,YAC7B,EAAI,MAAQ,EAAW,YACvB,EAAI,OAAS,GACN,GAET,IAAM,MAKd,GACA,IACE,EAAS,kBAAkB,KACzB,mBAAqB,GAAmB,OAGhD,IAGI,GAAQ,EAAS,uBAEjB,GAAgB,GACpB,KAAO,IAAuB,CAC5B,GAAI,CACF,GAAM,GACJ,MAAM,IAAO,GAAY,CAAC,OAAQ,GAAa,CAC7C,QAAS,KAEX,MAAM,WACF,EAAM,EACV,EAAM,KAAK,GAAM,EAAG,WAAW,UAC/B,GAAM,GAAI,KAAI,GAAY,EAAI,WAEhC,MAAO,CACL,YAAa,EACX,EAAM,KAAK,GAAM,EAAG,WAAW,mBAC/B,GAAM,GAAY,EAAI,mBAExB,WAAY,EAAI,EAAK,GAAM,EAAG,UAC9B,YAAa,EAAI,GACd,QAAQ,GAAM,EAAG,UACjB,QAAQ,GAAM,GAAY,EAAI,MAC9B,QAAQ,GAAM,GAAY,EAAI,MAC9B,QAAQ,oBACR,OAAO,GACP,aAEE,EAAP,CACA,GAAM,KAAK,kBAAmB,CAAE,aAAY,QAC5C,SAGJ,CAAE,QAAS,IAAK,UAAW,GAAmB,aAAc,GAAK,IAMtD,GAAc,EAA6B,SAC/C,EAAQ,GAAS,IAAI,gBAAgB,YAAa,GACvD,EACG,OAAO,GAAQ,EAAK,WAAW,gBAC/B,IAAI,GAAQ,EAAK,MAAM,KAAK,KAEhC,IAEH,mBAA0D,CACxD,MAAM,MAAM,MACL,GACL,KAAM,GAAQ,KAAe,GAC3B,EAAI,IAAI,GAAM,GAAS,IAAI,GAAI,QAAQ,sBAHL,GCnJxC,OAAqD,oBA+B9C,YAAiB,EAAgB,EAAgB,EAAoB,CAC1E,MACE,IAAK,MAAQ,GAAK,MAAQ,KAAK,IAAI,EAAE,UAAY,EAAE,YAAc,EAI9D,YAAgB,EAAyB,EAAa,KAAe,CAC1E,MAAO,IAAK,KACR,GACA,GAAO,GACP,GAAQ,EAAG,GAAI,MAAQ,GACvB,KAAK,IAAI,EAAI,KAAK,OAAS,EAG1B,YACL,EACA,EAAQ,EAAI,EACH,CACT,MAAO,GAAI,IAAW,KAAK,MAAQ,GAAU,EAaxC,YAAmB,EAAU,GAAI,MAAgB,CACtD,MAAO,CACL,EAAE,cACF,GAAK,EAAE,WAAa,GACpB,GAAK,EAAE,WACP,IACA,GAAK,EAAE,YACP,GAAK,EAAE,cACP,GAAK,EAAE,eACP,KAAK,IAGF,YAAsB,EAAU,GAAI,MAAgB,CACzD,MAAO,CACL,EAAE,iBACF,GAAK,EAAE,cAAgB,GACvB,GAAK,EAAE,cACP,IACA,GAAK,EAAE,eACP,GAAK,EAAE,iBACP,GAAK,EAAE,kBACP,KAAK,IAGF,YAAe,EAAoB,CACxC,MAAO,aAAS,WAAW,GAAI,SAAS,SAiBnC,YAAoB,EAAmC,CAC5D,MAAO,GAAI,GACR,OAAO,GACP,IAAI,GAAM,YAAS,QAAQ,IAC3B,OAAO,GAAM,EAAG,SAChB,IAAI,GAAM,EAAG,YACb,MAWE,YAAyB,EAA4B,CAC1D,MAAO,GACL,GAAmB,GACnB,GAAM,EAAK,IAAM,GAAoB,EAAE,cAIpC,YAA4B,EAA4B,CAC7D,MAAO,IAAK,MAAQ,CAAC,EAAE,QAAU,OAAY,EAAM,EAAE,SAAS,gBAGzD,YAA6B,EAAY,CAI9C,MAAO,MAAK,MAAM,EAAK,IAGlB,YACL,EACA,EACmB,CACnB,GAAI,GAAS,MAAQ,EAAQ,EAAG,OAChC,GAAI,GAAI,EACF,EAAO,IAAM,CACjB,GAAM,GAAS,EAAI,IACnB,SAAI,KAAK,MAAM,EAAI,KACZ,GAEH,EAAc,GAAK,IACnB,EAAS,IACT,EAAS,IACT,EAAO,IACP,EAAM,IACN,EAAQ,IAEd,MAAO,CACL,KAFW,EAGX,QACA,MACA,OACA,SACA,SACA,cACA,KAAM,EAAI,EAAQ,GAAM,QAAK,cAAc,KAIxC,YACL,EACA,EACiB,CACjB,MAAO,GAAI,GAAkB,EAAO,GAAS,GAAM,YAAS,WAAW,IAMlE,YACL,EACA,EACe,CACf,MAAO,GAAI,GAAgB,EAAO,GAAS,GAAM,EAAG,YAQ/C,YAAmB,EAAoB,CAC5C,GAAM,GAAI,GAAI,MAAK,GACnB,MAAO,GACL,CACE,EAAE,cACF,GAAG,CACD,EAAE,WAAa,EACf,EAAE,UACF,EAAE,WACF,EAAE,aACF,EAAE,aACF,GAAoB,EAAE,uBACtB,IAAI,KACN,KAAK,KCrIJ,YACL,EAIA,CAaA,MAZyB,IAAI,IAAa,GACxC,KAAM,EAAQ,CAAC,EAAK,IAAK,GAAG,EAAK,OAAO,KAAK,KAC7C,aAAc,IAEL,GAAM,EAAK,IAAK,EAAK,KAAM,GAAK,GAGzC,SAAU,IAAM,GAChB,QAAS,IAAM,GACf,iBAAkB,IACf,IAwBA,YAAsC,CAgB3C,YAAY,EAA+C,CAdlD,aAAU,KAAK,MAChB,cAAW,GACF,YAAS,EAAK,IAC7B,EAAS,gBAAkB,EAAQ,CAAC,KAAK,KAAM,KAAK,MAAM,KAAK,KAAO,MAE/D,eAAY,GAAI,IAAK,EAAI,GACzB,WAAQ,GAAI,IAEb,YAAS,GAkGR,aAAU,MAAO,EAAa,IAAiC,CACtE,GAAM,GAAQ,GAAa,IAAQ,GAAa,GAC1C,EAAQ,GAAI,IAAa,CAC7B,QAAS,EAAM,EAAI,EAAK,IACxB,MAAO,GAAQ,GAAO,EAAM,SAExB,EAAY,GAAiB,GAC7B,EAAM,CAAE,MAAK,QAAO,YAAW,OAAQ,GAAS,IAEtD,GADA,KAAK,SAAS,IAAI,EAAY,OAAS,QAAS,YAAa,GACzD,KAAK,QAAU,EACjB,OAMF,GAHA,KAAK,UAAY,EACjB,EAAQ,EAAK,GAET,EACF,MAAO,MAAK,MAId,GADwB,KAAK,KAAK,QAAQ,EAAK,GAE7C,YAAK,SAAS,KAAK,4BAA6B,GACzC,KAAK,YAlHd,KAAK,KAAO,EAAK,KACjB,KAAK,KAAO,GACV,QAAS;AAAA,EACT,mBAAoB,EACpB,YAAa,EAAa,MAC1B,YAAa,GACb,cAAe,IACZ,GAGL,KAAK,aAAe,GAAyB,KAAK,MAClD,GAAW,KAAK,KAAK,YAAa,MAC7B,KAAK,cAGR,UAAU,CACZ,MAAO,MAAK,YAGV,QAAQ,CACV,MAAO,MAAK,YAGR,MAAM,CACV,YAAK,OAAS,GACP,KAAK,WAGV,OAA4B,CAC9B,MAAO,MAAK,MAGV,MAAqB,CACvB,MAAO,GAAI,KAAK,GAAI,GAAM,EAAG,QAG3B,mBAA2B,CAC7B,MAAO,MAAK,UAAU,iBAGxB,SAA4B,CAC1B,MAAO,GACL,KAAK,IACL,GAAM,GAAU,GAChB,SAAY,IAIhB,YAA+B,CAC7B,MAAO,IAAQ,KAAK,gBAOhB,OAAyB,CAC7B,YAAK,SAAS,KAAK,UACnB,KAAK,SAAW,GACT,KAAK,MAAM,OAAO,gBAAgB,KAAK,aAAc,IAC1D,MAAK,SAAW,GACT,KAAK,eAIF,QAA0B,CACtC,KAAK,SAAS,KAAK,UAAW,CAC5B,QAAS,KAAK,SACd,MAAO,KAAK,SAEd,GAAM,GAAK,KAAK,GAEhB,MADA,MAAK,GAAK,OACN,GAAM,KAAa,GAChB,KAAK,UAAU,QAGV,WAAU,EAAkB,CAExC,YAAM,GAAI,KAAK,KAAK,aACjB,OAAO,GACP,QAAQ,GACP,EAAI,GACD,QAAQ,GAAM,EAAG,OACjB,OAAO,GAAM,EAAG,UAChB,QAAQ,GAAM,GAAI,IAAM,EAAG,MAAM,EAAM;AAAA,KACvC,IAAI,IACJ,OAEA,GAAW,EAAI,KAAK,cAgC7B,qBAAsB,CACpB,MAAO,MAAK,SAAS,IAAI,CACvB,IAAK,wBACL,OAAQ,GAAG,KAAK,UAAU,gBAAiB,KAAK,KAAK,oBACrD,KAAM,CACJ,gBAAiB,KAAK,UAAU,gBAChC,gBAAiB,KAAK,KAAK,2BAK3B,SAAQ,EAAQ,GAAO,CAK3B,GAJA,KAAK,SAAS,KAAK,YAAa,CAC9B,QAAS,KAAK,SACd,MAAO,KAAK,SAEV,KAAK,QAAU,IAAU,MAAO,GACpC,GACE,CAAC,GACD,KAAK,UAAU,iBACb,EAAS,gCAAgC,eAC3C,CACA,KAAK,SAAS,KAAK,oDAAqD,CACtE,iBAAkB,KAAK,UAAU,iBACjC,gCACE,EAAS,gCAAgC,iBAE7C,OAEF,MAAO,MAAK,MAAM,OAAO,gBAAgB,KAAK,gBAAiB,SAC7D,MAAM,MAAK,QACX,KAAK,SAAW,GACT,KAAK,gBAIV,QAAQ,CACZ,YAAK,SAAS,KAAK,UAAW,CAC5B,QAAS,KAAK,SACd,MAAO,KAAK,SAEP,KAAK,MAAM,OAAO,gBAAgB,KAAK,cAAe,SAC3D,MAAK,SAAW,GACT,KAAK,gBAQF,WAAW,CACvB,YAAK,SAAS,KAAK,aAAc,CAC/B,QAAS,KAAK,SACd,MAAO,KAAK,SAEP,KAAK,MAAM,SAChB,gBAAgB,KAAK,iBACrB,SACE,MAAM,MAAK,QACP,KAAK,UAAY,KAAK,OAAe,GACrC,KAAK,sBACP,MAAK,SAAS,KACZ,kDACA,CACE,gBAAiB,KAAK,UAAU,gBAChC,iBAAkB,KAAK,UAAU,mBAIjC,GAAW,KAAK,QAAS,EAAS,YAAY,iBAChD,EACE,iBACE,KAAK,KACL,8BACA,GACF,KAAK,WAGF,IAET,MAAK,SAAS,KAAK,YAAa,CAC9B,WAAY,KAAK,IACjB,UAAW,KAAK,UAChB,mBAAoB,KAAK,KAAK,qBAIhC,KAAK,KAAK,cAEH,KAAK,iBAUJ,SAA2B,CAMvC,GALA,KAAK,SAAS,KAAK,WAAY,CAC7B,QAAS,KAAK,SACd,MAAO,KAAK,SAEV,KAAK,UAAY,KAAK,QACtB,KAAM,MAAK,UAAW,MAAO,GACjC,KAAK,UAAU,UACf,GAAM,GAAM,KAAK,GAAK,KAAM,MAAK,KAAK,eAGtC,KAAK,OAAO,QACZ,KAAK,SAAS,KAAK,yBAA2B,KAAK,KAEnD,GAAM,GAAM,MAAQ,EAAG,IAAM,IAC5B,OACC,CAAE,EAAG,EAAI,KAAM,IACf,CAAE,EAAG,EAAG,MAAO,KAAM,UACrB,CAAE,EAAG,EAAG,OAAQ,KAAM,WACtB,CAAE,EAAG,EAAG,OAAQ,KAAM,YACtB,QAAQ,CAAC,CAAE,IAAG,UAAW,CACzB,EAAI,EAAG,GACL,EAAG,GAAG,QAAS,GAAO,KAAK,QAAQ,EAAM,EAAO,aAAc,OAI7D,EAAI,KAAK,GAAG,OAAQ,GACvB,GAAc,EAAM,KAAK,KAAK,QAAS,GAAM,CAC3C,KAAK,SAAS,MAAM,kBAAmB,GACvC,KAAK,KAAK,SAAS,MAIlB,EAAI,KAAK,GAAG,OAAQ,GACvB,EAAK,GAAG,OAAQ,GAAK,CACnB,AAAI,EAAI,GAAG,SAAS,8BAClB,EACE,mBAAqB,KAAK,KAAO,GACjC,GAAI,OAAM,GAAU,EAAG,OAGvB,KAAK,KAAK,WAAW,KAAO,IACzB,KAAK,QAAQ,EAAM,mBAAoB,MAKlD,KAAK,GAAG,GAAG,OAAQ,MAAO,EAAqB,IAA0B,CACvE,KAAK,SAAS,KAAK,SAAU,CAC3B,OACA,SACA,QAAS,KAAK,SACd,MAAO,KAAK,SAEd,AAAI,KAAK,KAAK,cACZ,MAAM,MAAK,WACX,KAAK,SAAS,KACZ,2CAA6C,KAAK,MAGpD,MAAK,SAAS,KACZ,sDAAwD,KAAK,KAE1D,KAAK,SAGP,KC9ZX,OAA6B,qBActB,YACL,EACA,EACW,CACX,EAAY,KAAK,KAAK,GACtB,GAAI,GACA,EAAc,GACZ,EAAS,IAAI,IAAa,CAC9B,EAAO,EACP,EAAI,EAAa,iBACjB,EAAc,GAAgB,IAAM,EAAE,GAAG,GAAO,IAElD,SAAE,MAAQ,IAAM,CACd,EAAI,EAAa,iBACjB,EAAc,QAEhB,EAAE,IAAM,IAAM,CACZ,EAAE,QACF,KAEK,EC3BT,GAAM,IAAM,EAAS,sCAErB,mBAAyC,CACvC,GAAM,GAAc,KAAM,GAAQ,GAAW,IAAQ,GACnD,EAAc,EAAK,IAAI,GAAO,EAAI,cAEpC,GAAI,GAAe,MAAS,KAAM,MAChC,GAAI,CACF,KAAM,GAAQ,KAAc,GAC1B,EAAY,KAAK,GAAG,EAAQ,IAAI,GAAM,EAAG,oBAEpC,EAAP,CAEA,GAAI,KAAK,8BAA+B,GAG5C,MAAO,GAAI,EAAa,GACtB,EAAI,OAAO,GAAM,CAAC,EAAG,WAAW,WAAa,IAAO,SCjBxD,GAAM,IAAgB,gBAKT,GAAiB,SACrB,GACL,GAAW,WAAW,eACpB,sEAGD,QAAkB,GAAO,EAAI,IAAI,GAAM,EAAG,OAC1C,OAAO,GACP,OAAO,IAAM,MACb,IAAI,GAAM,EAAG,QACb,cAQQ,GAAuB,SAAY,CAK9C,GAAM,GACJ,MAAM,IAAO,KAAM,MAAU,CAAC,SAAU,UAAW,CACjD,QAAS,GAAK,KAEhB,OACI,EAAmB,GACrB,EACJ,KAAQ,GAAQ,GAAc,KAAK,MAAW,MAC5C,EAAO,KAAK,EAAM,IAEpB,MAAO,ICdF,GAAM,IAAoB,IAC/B,EAAQ,KAAmB,KAEzB,GAEG,YAA+B,EAA0B,CAC9D,GAAiB,EACZ,KAGA,GAAM,IAAuB,EAAK,SAAY,CACnD,AAAI,KACF,EAAM,SAAY,CAChB,GAAM,GAAM,EAAS,sCACrB,AAAI,IACF,GAAI,KAAK,4CACT,GAAY,OAAO,IACnB,MAEE,IACE,MAAM,OACR,GAAI,KAAK,sCACT,GAAY,OAAO,IACnB,MAEE,KAAM,OACR,GAAI,KAAK,0CACT,GAAY,OAAO,IACnB,QAGH,GAAK,GAAU,QAElB,KAAM,IAAS,CACb,GAAI,GAAiB,SACrB,GAAI,GAAgB,SACpB,GAAI,GAAY,aAQT,GAAc,EAAK,SASvB,AAPQ,MAAM,IADR,IAAM,GAAkB,GAAgB,IACZ,CACvC,WAAY,EACZ,iBAAkB,GAAK,GAAW,EAAI,QACrC,MAAM,GAAO,CACd,EAAQ,uBAAwB,OAGnB,OACd,IAEH,EAAM,IAAM,EAAa,IAAM,GAAY,UAKpC,GAAM,IAAmB,EAAK,IACnC,GAAoB,CAClB,IAAK,WACL,KAAM,CAAC,YACP,SAAU,GAAS,IAAM,GAAY,QAAS,IAAM,MAI3C,GAAkB,EAAK,IAClC,GAAoB,CAClB,IAAK,GACL,KAAM,GACN,SAAU,GAAS,IAAM,CACvB,GAAW,QACX,GAAY,QACZ,GAAY,SACX,IAAM,MAIP,GAAqB,EAAK,SAAY,CAC1C,GAAI,CAAC,GAAS,MAAO,GACrB,GAAI,CAKF,MAAO,AAJQ,MAAM,IAAa,UAAW,CAAC,aAAc,CAC1D,QAAS,EACT,aAAc,MAEF,OAAS,QAChB,EAAP,CACA,MAAO,MAIE,GAAc,EAAK,IAC9B,GAAoB,CAClB,IAAK,UACL,KAAM,CAAC,UACP,SAAU,GAAS,IAAM,CACvB,GAAY,QACZ,GAAY,SACX,IAAM,MCvHN,YACL,EACA,EAC2B,CAC3B,GAAM,GAAS,GACb,OAAS,EACT,IACE,GAAc,EAAG,CACf,WAAY,EACZ,UAAW,EACX,iBAAkB,GAAO,GAAiB,KAE9C,IAEF,UAAY,SAAS,IAAM,EAAO,SAClC,EAAM,IAAM,EAAa,IAAM,EAAO,UAC/B,ECxBT,GAAM,IAAmB,GACvB,mBAGA,IAAM,EAAQ,GAAW,IAAO,GAAQ,EAAK,IAAI,GAAO,EAAI,cAGjD,GAAU,GAAY,UAAW,SAAY,CACxD,GAAM,GAAO,KAAM,IAAW,IAC9B,GAAI,GAAQ,KACZ,YAAM,GAAQ,KAAoB,GAAU,CAC1C,EAAK,QAAQ,GAAO,CAClB,EAAI,OAAS,CAAC,EAAO,SAAS,EAAI,gBAGlC,KAAM,OACR,KAAM,GAAQ,KAAc,GAAM,EAAK,KAAK,GAAG,IAE1C,ICGT,kBACE,EACA,EACmB,CACnB,GAAI,CAAC,EAAO,KAAM,IAAI,OAAM,OAC5B,YAAM,GACJ,EAA4C,EAAU,IAAM,MAC5D,GAAO,CACL,GAAM,GAAI,GAAM,EAAK,GAAM,CAAC,EAAG,WAAY,IAC3C,EAAQ,QAAQ,GAAO,CACrB,EAAI,EAAE,IAAI,EAAI,YAAa,GAAW,CACpC,EAAI,OAAS,GACb,EAAI,WAAa,EAAQ,KACzB,EAAI,YAAc,EAAQ,MAC1B,EAAI,GAAK,EAAQ,SAKlB,EAGT,GAAM,IAAU,CAAC,YAAa,aAAc,UACtC,GAAY,CAAC,SAAU,MAAO,GAAQ,KAAK,MAa3C,GAAS,oBACT,GAAgB,eAItB,mBAAiD,CAC/C,GAAM,GAAS,KAAM,IAAW,WAAW,eACzC,+GAGF,MAAO,IAAU,KACb,KACA,EACE,EACG,OAAO,AAAC,GAAY,EAAS,EAAG,YAChC,IAAI,AAAC,GACJ,EAAI,GAAgB,EAAG,YAAa,CAAC,CAAE,OAAM,WAC3C,EAAI,GAAc,KAAK,EAAI,EAAG,YAAa,GAAgB,EACzD,WAAY,GAAa,EAAY,GAAI,MACzC,OACA,QACA,GAAI,EAAG,SAAW,MAAQ,EAAG,kBAAoB,kBAO1D,YACL,EACwC,CACxC,GAAI,GAAM,GAEV,MAAO,GAAI,GACR,QAAQ,GAAM,GAAO,KAAK,IAC1B,IAAI,GAAO,EACV,KAAM,EAAG,GACT,MAAO,EAAG,MAEX,OAAO,IACN,EAAI,GACD,QAAQ,GAAO,GAAI,IAAM,GAAI,KAAI,KACjC,OAAO,GAAO,EAAS,EAAI,WAC3B,IAAI,GAAQ,EACX,KAAM,EAAI,SACV,MAAO,EAAI,EAAI,UACZ,OAAO,GACP,UAAU,IAAM,SAGxB,MAGL,mBAA4D,CAC1D,GAAM,GAAM,KACN,EAAO,KAAM,IAAO,EAAK,GAAW,CAAE,QAAS,GAAK,IACpD,EAAS,GAAW,GAAS,GACnC,MAAO,GACL,EAAO,IAAI,GACT,EAAI,GAAO,KAAK,EAAI,EAAG,aAAc,GACnC,EAAI,GAAc,KAAK,EAAI,EAAG,YAAa,GAAgB,EACzD,WAAY,GAAa,EAAY,GAAI,MACzC,KAAM,EAAW,GACjB,MAAO,EAAW,GAClB,GAAI,EAAG,SAAW,WAO5B,GAAM,IAAa,GAAY,aAAc,ICnH7C,GAAM,IAAS,EAAK,IAAM,EAAS,UAEtB,GAAQ,GAAY,QAAS,SAIjC,AADO,MAAM,OACP,OAAO,GAAK,EAAE,KAAO,IAAS,EAAI,EAAE,QAItC,GACX,sGAEF,YAA4B,EAAyB,CACnD,MAAO,GAAS,EAAG,OAAS,EAAG,MAAQ,MAAQ,EAAG,MAAQ,KACtD,GACE,WAAY,EAAG,KACf,MAAO,EAAG,YACV,KAAM,EAAG,KAAO,EAAG,KACnB,KAAM,EAAG,KACT,UAAW,EAAG,KACd,OAAQ,EAAS,EAAG,cACjB,EAAI,GAAgB,EAAG,aAAc,GAAW,EACjD,WAAY,EAAO,KACnB,YAAa,EAAO,UAGxB,OAMC,GAAM,IACX,yIAEI,GAAS,uBAKf,YAAuB,EAAkB,CACvC,MAAO,MAAS,IAAI,CAClB,IAAK,gBACL,OAAQ,EAAI,GAAO,KAAK,EAAI,IAAK,GAAK,EAAE,IACxC,KAAM,CAAE,OAIZ,YAA2B,EAAwB,CAEjD,GACE,EAAE,aAAe,MACjB,EAAE,cAAgB,QAClB,EAAE,kBAAoB,kBAEtB,OAEF,GAAM,GACJ,EAAE,MAAQ,MACV,EAAE,eAAiB,MACnB,EAAS,EAAE,cACV,IAAY,EAAE,aAAc,GAAM,GAAiB,EAAI,aACtD,GAAY,EAAE,kBAAmB,GAAM,GAAiB,EAAI,QAChE,MAAO,CACL,WAAY,EAAE,YAAc,MAC5B,WAAY,EAAE,WACd,MAAO,EAAE,gBACT,KAAM,GAAc,EAAE,UACtB,KAAM,EAAE,KACR,KAAM,EAAE,KAAO,EAAE,cACjB,UAAW,EAAE,cACb,OAAQ,GACR,MAIJ,mBAAyD,CACvD,GAAM,GAAa,KAAM,IACvB,GAAW,WACR,eAAe,IACf,MAAM,GACL,GAAQ,yCAA0C,GAC3C,KAEX,GAAM,GAAmB,GAAmB,KAGxC,EAAa,KAAM,IACvB,GAAW,WACR,eAAe,IACf,MAAM,GACL,GAAQ,kCAAmC,GACpC,KAEX,GAAM,GAAmB,GAAkB,KAIvC,EAAY,EAChB,CAAC,GAAG,EAAY,GAAG,GAChB,OAAO,GAAM,EAAG,KAAO,IACvB,IAAI,GAAM,EAAG,aAGZ,EAAc,GAClB,EAAK,CAAC,GAAG,EAAY,GAAG,GAAY,IAAI,GAAM,EAAG,aAAa,OAC5D,GAAM,CAAC,EAAU,SAAS,KAI9B,YAAS,KAAK,kBAAmB,CAC/B,aACA,aACA,cACA,cAGK,EAAY,IAAI,GAAe,OACjC,EAAW,KAAK,GAAM,IAAe,EAAG,aACxC,EAAW,KAAK,GAAM,IAAe,EAAG,cClD/C,kBACE,EACwB,CACxB,MAAO,GAAQ,KAAe,GAC5B,EAAK,IAAI,GACP,EACE,EAAM,IAAI,EAAI,YACd,GAAS,OAAK,GAAQ,GACtB,IAAM,KAMP,GAAM,IAAc,GAAY,cAAe,SAAY,CAIhE,GAAM,GAAU,AAHH,MAAM,IAAO,WAAY,CAAC,OAAQ,QAAS,CACtD,QAAS,KAEU,MAAM,qBAC3B,MAAO,IAAM,EAAS,GAAe,CACnC,GAAM,GAAa,GAAM,EAAY,MAAM,aAAc,GAAQ,CAC/D,GAAM,CAAC,EAAK,GAAO,EAAK,MAAM,KAAK,IAAI,GAAM,EAAG,QAChD,MAAO,IAAiB,CAAC,iBAAkB,kBAAmB,GAC1D,OACA,CAAC,EAAI,cAAe,KAEpB,EAAa,EAAW,IAAI,eAC5B,EAAQ,EAAW,IAAI,eACvB,EAAO,EAAW,IAAI,eAG5B,MAAO,GAAM,GAAc,OAAY,CAAC,EAAY,CAAE,QAAO,aC5G1D,YAAwB,CAC7B,QACA,iBAIe,CACf,GAAM,GAAS,GACX,EACJ,OAAW,KAAQ,IAAW,GAAO,OACnC,GAAM,EAAG,MAAM,UAAY,MAC1B,CACD,GAAM,GAAK,+DACX,KAAQ,GAAI,EAAG,KAAK,KAAU,MAAM,CAClC,GAAM,CAAC,CAAE,EAAK,EAAM,GAAO,EAC3B,EAAO,EAAgB,EAAI,cAAgB,GAAO,GAChD,EACA,EACA,IAIN,MAAO,GCuBT,GAAM,IAAS,EAAK,IAAM,EAAS,sBAEnC,kBAA8C,EAAkB,CAC9D,MAAO,GAAQ,KAAM,MAAwB,GAQpC,AAPa,GAClB,EAAK,CACH,GAAG,EAAM,OAAO,GAAM,CAAC,EAAG,WAAW,IAAI,GAAM,EAAG,YAClD,GAAG,EAAK,IAAI,GAAM,EAAG,eAIN,IAAI,GAAe,OACjC,EAAK,KAAK,GAAM,EAAG,aAAe,IAClC,EAAM,KAAK,GAAM,EAAG,aAAe,MAKrC,GAAM,IAAuB,GAClC,uBACA,SAAY,CACV,GAAM,GAAO,KAAM,IACjB,QACA,CAAC,KAAM,KAAM,WAAY,wCACzB,CACE,QAAS,IAGP,EAAiB,GAAW,GAC/B,IAAI,GAAS,GAAe,CAAE,QAAO,cAAe,MACpD,OAAO,GAAM,GAAM,MAEhB,EAAS,KAAM,IAAS,EAAgB,KAAM,IAAM,CACxD,GAAM,GACJ,EAAM,EAAG,aACT,EAAG,WAAW,WAAW,WACzB,EAAG,aAAe,SAClB,EAAG,WAAW,WAAW,WACzB,CAAE,KAAM,IAAY,EAAG,YACzB,MAAO,IACL,EAAM,EAAG,QACT,EAAM,EAAG,SACT,CAAC,EAAM,IAAe,GACpB,WAAY,EAAG,WACf,MAAO,EAAG,MACV,KAAM,EAAG,KACT,YACA,OACA,YACA,KAAM,EAAO,GACT,AAAC,KAAiC,OAApB,CAAE,OAAQ,QAKlC,MAAO,MAAS,IAAI,CAClB,IAAK,QACL,aC3FN,GAAM,IAAQ,wEAED,GAAQ,qBAErB,kBACE,EACmB,CACnB,SACG,OAAO,GAAM,EAAG,QAChB,QAAQ,GAAM,CACb,EACE,GAAM,KAAK,EAAI,EAAG,aAClB,GAAK,CACH,EAAG,WAAa,EAAE,GAClB,EAAG,YAAc,EAAE,IAErB,IACE,EAAI,GAAM,KAAK,EAAI,EAAG,aAAc,GAAK,CACvC,EAAG,WAAa,EAAE,GAClB,EAAG,YAAc,EAAE,QAItB,ECxCT,kBACE,EACA,EAKiB,CACjB,GAAI,CACF,MAAO,MAAO,GAAK,WAAa,KAC5B,IACA,GAAc,EAAG,EAAK,UAAW,IAC/B,EAAQ,EAAK,QAAU,YAAa,OAAW,EAAK,iBAEnD,EAAP,CACA,EAAQ,EAAK,QAAS,EAAO,EAAK,SAClC,QCrBJ,OAA4B,qBASrB,aAAgB,CACrB,GAAM,GAAI,mBAAY,IAGtB,EAAE,GAAM,EAAE,GAAK,GAAQ,GAGvB,GAAM,GAAI,EAAE,SAAS,OAGrB,MAAO,CACL,EAAE,MAAM,EAAG,GACX,EAAE,MAAM,EAAG,IACX,EAAE,MAAM,GAAI,IACZ,EAAE,MAAM,GAAI,IACZ,EAAE,MAAM,KACR,KAAK,KAMF,aAA4B,CACjC,MAAO,IAAO,IAIT,GAAM,KAAa,EAAK,IAAM,oCChBrC,GAAM,IAAS,EAAK,IAAM,EAAS,eAEtB,GAAsB,GAAmB,EAKhD,GAAQ,GAAI,KAElB,EAAM,IAAM,CACV,EAAa,IAAM,GAAM,SACzB,GAAY,SAAS,IAAM,GAAM,WAGnC,kBAAqC,EAA+B,CAClE,KAAM,IAAuB,CAC3B,KAAM,iBACN,OAAQ,EAAK,IAAI,GAAM,IAAM,GAAc,MAY/C,kBAA6B,EAA0B,CACrD,GAAI,EAAO,EAAE,WAAY,CAEvB,KAAS,MAAM,uCAAyC,EAAE,YAC1D,OAGF,GAAI,GAAQ,EAAE,IAAK,CAEjB,KAAS,MAAM,uCAAyC,EAAE,YAC1D,OAGF,KAAM,GACJ,GAAS,GAAO,EAAE,WAAY,IAC5B,GACE,IACE,GAAqB,IAAM,GAAe,GAAI,CAC5C,QAAS,kBAAoB,EAAE,WAAa,MAEhD,KAGJ,GAAS,EAAE,KAAO,GAOtB,kBAAqC,EAAiC,CACpE,GAAM,GAAc,EAAU,IAAI,EAAE,YAAY,KAAK,SAErD,GAAI,EAAS,oBAAoB,eAAgB,CAC/C,GAAM,GAAO,KAAM,IACjB,IACE,GAAQ,EAAY,SAAS,UAC1B,IAAI,GAAM,EAAG,WAAW,QACxB,OAAO,GACP,MACL,IAGF,GAAI,GAAQ,MAAQ,EAAK,OAAS,EAChC,YAAS,MAAM,0BAA2B,CACxC,OACA,WAAY,EAAE,aAET,EAKX,GAAI,EAAE,aAAe,IAAK,MAAO,GAAE,KAEnC,GAAI,EAAS,qBAAqB,eAAgB,CAEhD,GAAM,GAAO,GAAW,EAAE,KAAM,IAIhC,GAAI,KAAM,GAAY,SAAS,iBAC7B,GAAI,CACF,YAAM,GAAY,UAAU,GAC5B,KAAS,KAAK,oCAAsC,EAAE,WAAY,CAChE,SAEK,QACA,EAAP,CAEA,KAAS,KACP,6CAA+C,EAAE,WACjD,IAOR,MAAO,GAAE,KCnFX,GAAM,IAAS,EAAK,IAAM,EAAS,YAEnC,mBAAuD,CACrD,GAAM,GAAY,KAAM,IACtB,EAAQ,KAAU,KAClB,GACA,IAAM,EAAQ,4CAEhB,GAAI,GAAa,KAAM,CACrB,KAAS,KAAK,aACd,OAGF,GAAM,GAAS,EAAS,oBAAoB,eACxC,EACE,KAAM,IAAuB,CAC3B,KAAM,0CACN,OAAQ,EAAU,IAAI,GAAO,SAAY,CACvC,GAAI,CAOF,GAJc,KAAM,IAClB,EAAI,WACJ,GAAgB,GAGhB,MAAO,GAEP,KAAS,KACP,0BACE,EAAI,WACJ,6BAGC,EAAP,CACA,KAAS,KACP,yCAA2C,EAAI,WAC/C,SAOV,EAIJ,AAAI,EAAO,KAAK,GAAM,EAAG,QAAU,EAAM,EAAG,cAC1C,KAAM,IACJ,EAAQ,GAAuB,GAAU,GAAyB,GAClE,GAAK,GACL,MAAM,GAAO,CACb,EAAQ,mCAAoC,KAGhD,GAAM,GAAiB,EACrB,KAAO,GACH,EACA,GACA,GAAsB,GACtB,GAAwB,IAC5B,GAGF,GAAc,EAAM,GAAM,CAAC,EAAO,EAAG,YAEjC,EAAS,uBAAuB,gBAClC,GAAc,EAAM,GAAM,CAAC,GAAQ,EAAG,KAIxC,OAAW,KAAO,GAChB,EAAI,OAAS,EAAO,EAAI,QACxB,EACE,EAAI,WAEJ,GAAO,EAAI,WAAa,EAAG,cAAc,YAAY,QAKzD,OAAW,KAAO,GAChB,AAAI,EAAM,EAAI,QAAQ,MAAO,GAAI,MAGnC,KAAS,MAAM,yCAA0C,GACzD,KAAM,IAAe,GAErB,GAAM,GAAS,GAAO,EAAM,GAAM,EAAG,YACrC,YAAS,MAAM,2BAA4B,CAAE,WACtC,OAAO,OAAO,GAGvB,GAAI,IAEG,YAA2B,EAAsB,CACtD,GAAa,EAKf,GAAI,IAAmC,GAEjC,GAAc,SAAY,CAC9B,GAAI,CAEF,GAAM,GAAS,KAAM,IAAkB,GAAY,IACnD,UAAY,EAAQ,GAAO,CACzB,GAAM,GAAoB,EAAI,IAAI,GAAM,EAAG,YAAY,OACvD,AAAK,GAAI,GAAwB,IAC/B,MACA,GAAyB,KAGtB,QACA,EAAP,CACA,EAAQ,mBAAoB,GAC5B,SAIS,GAAU,GAAY,UAAW,IAEjC,IAAW,EAAK,IAC3B,EACI,EAAI,GAAO,gBACR,OAAO,GACP,OAAO,IAAM,MACb,IAAI,GAAM,GAAa,EAAI,OAC3B,MACH,KAON,kBAAgC,EAA0C,CACxE,MAAO,GAAQ,KAAW,GAAQ,GAAW,EAAM,IAG9C,YAAoB,EAAgB,EAAmC,CAC5E,GAAM,GAAa,EAAK,OAAO,GAC7B,GAAsB,EAAY,EAAI,aAExC,MAAO,IAAW,EAAY,GAC5B,GAAmB,EAAI,WAAY,IChMvC,OAA0B,mBCUnB,YACL,EACA,EACoB,CACpB,GAAI,GAAY,EACV,EAAQ,GAAI,IAAa,EAAK,QAAS,EAAK,OAC5C,EAAS,AAAC,GACd,KACO,EAAM,SAAS,EAAU,GAAI,IAAM,EAAE,KAE9C,SAAE,MAAQ,AAAC,GAAW,GAAK,KAAO,EAAM,QAAU,EAAM,OAAO,EAAU,IACzE,EAAE,KAAO,IAAM,EAAM,KACrB,EAAE,UAAY,IAAM,EACb,ECtBT,OAA6B,mBAC7B,GAA0B,uBAC1B,GAAwB,mBCQjB,GAAW,IAAX,UAAW,EAAX,CACL,SAAO,GAAP,OAIA,cAAY,GAAZ,YAIA,QAAM,GAAN,MAIA,aAAW,IAAX,WAIA,mBAAiB,IAAjB,iBACA,UAAQ,IAAR,QAIA,oBAAkB,IAAlB,kBAIA,gBAAc,IAAd,cAIA,SAAO,IAAP,OAIA,eAAa,IAAb,aAIA,gBAAc,IAAd,cAIA,cAAY,IAAZ,YAIA,gBAAc,IAAd,cAIA,cAAY,IAAZ,YAIA,eAAa,IAAb,aAIA,aAAW,IAAX,WAIA,SAAO,IAAP,OAIA,UAAQ,IAAR,QAIA,SAAO,IAAP,OAIA,WAAS,IAAT,SAIA,UAAQ,IAAR,QAEA,WAAS,IAAT,SACA,WAAS,IAAT,SACA,WAAS,IAAT,SACA,WAAS,IAAT,SACA,WAAS,IAAT,SACA,WAAS,IAAT,SACA,WAAS,IAAT,SACA,WAAS,IAAT,SACA,WAAS,IAAT,SACA,WAAS,IAAT,SAKA,UAAQ,IAAR,QAIA,cAAY,IAAZ,YAIA,aAAW,IAAX,WAIA,WAAS,IAAT,SAIA,gBAAc,IAAd,cAIA,iBAAe,IAAf,eAIA,WAAS,IAAT,SAEA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IAKA,sBAAoB,IAApB,oBAIA,cAAY,IAAZ,YAIA,uBAAqB,IAArB,qBAIA,UAAQ,IAAR,QAIA,cAAY,IAAZ,YAIA,aAAW,IAAX,WAEA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,IAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IACA,MAAI,KAAJ,IAKA,mBAAiB,KAAjB,iBAIA,SAAO,KAAP,OAIA,oBAAkB,KAAlB,kBAIA,UAAQ,KAAR,QAEA,6BAA2B,KAA3B,2BACA,6BAA2B,KAA3B,2BACA,kCAAgC,KAAhC,gCACA,sBAAoB,KAApB,oBACA,uBAAqB,KAArB,qBACA,yBAAuB,KAAvB,uBACA,sBAAoB,KAApB,oBACA,0BAAwB,KAAxB,wBACA,0BAAwB,KAAxB,wBACA,2BAAyB,KAAzB,yBACA,2BAAyB,KAAzB,yBACA,oCAAkC,KAAlC,kCACA,sBAAoB,KAApB,oBACA,oCAAkC,KAAlC,kCACA,2CAAyC,KAAzC,yCACA,oCAAkC,KAAlC,kCACA,4BAA0B,KAA1B,0BACA,+BAA6B,KAA7B,6BACA,mCAAiC,KAAjC,iCACA,4BAA0B,KAA1B,0BACA,qCAAmC,KAAnC,mCACA,kCAAgC,KAAhC,gCACA,mCAAiC,KAAjC,iCACA,mCAAiC,KAAjC,iCACA,gCAA8B,KAA9B,8BACA,iCAA+B,KAA/B,+BACA,iCAA+B,KAA/B,+BACA,qBAAmB,KAAnB,mBACA,qCAAmC,KAAnC,mCACA,8BAA4B,KAA5B,4BACA,gCAA8B,KAA9B,8BACA,gCAA8B,KAA9B,8BACA,iCAA+B,KAA/B,+BACA,uCAAqC,KAArC,qCACA,qCAAmC,KAAnC,mCACA,0BAAwB,KAAxB,wBACA,gCAA8B,KAA9B,8BACA,2BAAyB,KAAzB,yBACA,4BAA0B,KAA1B,0BACA,wBAAsB,KAAtB,sBACA,uBAAqB,KAArB,qBACA,oCAAkC,KAAlC,kCACA,6BAA2B,KAA3B,2BACA,2CAAyC,KAAzC,yCACA,4BAA0B,KAA1B,0BACA,wCAAsC,KAAtC,sCACA,4BAA0B,KAA1B,0BACA,qCAAmC,KAAnC,mCACA,4BAA0B,KAA1B,0BACA,6BAA2B,KAA3B,2BACA,yBAAuB,KAAvB,uBACA,gCAA8B,KAA9B,8BACA,8BAA4B,KAA5B,4BACA,qCAAmC,KAAnC,mCACA,oCAAkC,KAAlC,kCACA,sCAAoC,KAApC,oCACA,qCAAmC,KAAnC,mCACA,sCAAoC,KAApC,oCACA,sCAAoC,KAApC,oCACA,6BAA2B,KAA3B,2BACA,8BAA4B,KAA5B,4BACA,wBAAsB,KAAtB,sBACA,+BAA6B,KAA7B,6BACA,gCAA8B,KAA9B,8BACA,gCAA8B,KAA9B,8BACA,gCAA8B,KAA9B,8BACA,kCAAgC,KAAhC,gCACA,8BAA4B,KAA5B,4BACA,sCAAoC,KAApC,oCACA,oCAAkC,KAAlC,kCACA,6BAA2B,KAA3B,2BACA,kCAAgC,KAAhC,gCACA,2CAAyC,KAAzC,yCACA,iCAA+B,KAA/B,+BACA,gCAA8B,KAA9B,8BACA,iCAA+B,KAA/B,+BACA,sCAAoC,KAApC,oCACA,uCAAqC,KAArC,qCACA,oCAAkC,KAAlC,kCACA,gCAA8B,KAA9B,8BACA,sCAAoC,KAApC,oCACA,qCAAmC,KAAnC,mCACA,wBAAsB,KAAtB,sBACA,wBAAsB,KAAtB,sBACA,qCAAmC,KAAnC,mCACA,sCAAoC,KAApC,oCACA,uDAAqD,KAArD,qDACA,sCAAoC,KAApC,oCACA,gCAA8B,KAA9B,8BACA,+BAA6B,KAA7B,6BACA,kCAAgC,KAAhC,gCACA,6BAA2B,KAA3B,2BACA,mCAAiC,KAAjC,iCACA,6BAA2B,KAA3B,2BACA,8BAA4B,KAA5B,4BACA,oCAAkC,KAAlC,kCACA,6BAA2B,KAA3B,2BACA,sCAAoC,KAApC,oCACA,8CAA4C,KAA5C,4CACA,qCAAmC,KAAnC,mCACA,qCAAmC,KAAnC,mCACA,qCAAmC,KAAnC,mCACA,qCAAmC,KAAnC,mCACA,qCAAmC,KAAnC,mCACA,qCAAmC,KAAnC,mCACA,qCAAmC,KAAnC,mCACA,qCAAmC,KAAnC,mCACA,qCAAmC,KAAnC,mCACA,qCAAmC,KAAnC,mCACA,qCAAmC,KAAnC,mCACA,qCAAmC,KAAnC,mCACA,qCAAmC,KAAnC,mCAMA,mBAAiB,MAAjB,iBAKA,wBAAsB,MAAtB,sBAKA,cAAY,KAAZ,YAGA,iBAAe,IAAf,eACA,mBAAiB,IAAjB,iBACA,gBAAc,KAAd,cACA,aAAW,KAAX,WACA,mBAAiB,KAAjB,iBACA,cAAY,KAAZ,YACA,qCAAmC,KAAnC,mCACA,sCAAoC,KAApC,oCACA,mCAAiC,KAAjC,iCACA,qCAAmC,KAAnC,mCACA,8CAA4C,KAA5C,4CACA,6CAA2C,KAA3C,2CACA,8BAA4B,KAA5B,4BACA,gCAA8B,KAA9B,8BACA,gCAA8B,KAA9B,8BACA,iCAA+B,KAA/B,+BACA,YAAU,KAAV,UACA,gBAAc,KAAd,cACA,iBAAe,KAAf,eACA,aAAW,KAAX,WACA,kBAAgB,KAAhB,gBACA,0BAAwB,KAAxB,wBACA,kCAAgC,KAAhC,gCACA,mCAAiC,KAAjC,iCACA,0CAAwC,KAAxC,wCACA,oCAAkC,KAAlC,kCACA,mCAAiC,KAAjC,iCACA,mCAAiC,KAAjC,iCACA,yCAAuC,KAAvC,uCACA,8CAA4C,KAA5C,4CACA,+CAA6C,KAA7C,6CACA,kCAAgC,KAAhC,gCACA,yCAAuC,KAAvC,uCACA,uCAAqC,KAArC,qCACA,yCAAuC,KAAvC,uCACA,0CAAwC,KAAxC,wCACA,+BAA6B,KAA7B,6BACA,0CAAwC,KAAxC,wCACA,iDAA+C,KAA/C,+CACA,iDAA+C,KAA/C,+CACA,gCAA8B,KAA9B,8BACA,mCAAiC,KAAjC,iCACA,sCAAoC,KAApC,oCACA,oCAAkC,KAAlC,kCACA,qCAAmC,KAAnC,mCACA,mCAAiC,KAAjC,iCACA,4BAA0B,KAA1B,0BACA,iCAA+B,KAA/B,+BACA,qCAAmC,KAAnC,mCACA,+BAA6B,KAA7B,6BACA,kBAAgB,KAAhB,gBACA,4BAA0B,KAA1B,0BACA,oBAAkB,MAAlB,kBACA,kBAAgB,MAAhB,gBACA,wBAAsB,MAAtB,sBACA,sCAAoC,MAApC,oCACA,4BAA0B,MAA1B,0BACA,2BAAyB,MAAzB,yBACA,kCAAgC,MAAhC,gCACA,4BAA0B,MAA1B,0BACA,2BAAyB,MAAzB,yBACA,kCAAgC,MAAhC,gCACA,gCAA8B,MAA9B,8BACA,+BAA6B,MAA7B,6BACA,kBAAgB,MAAhB,gBACA,iBAAe,MAAf,eACA,kBAAgB,MAAhB,gBAEA,eAAa,MAAb,aAOA,aAAW,OAAX,aAragB,aDClB,GAAM,IAAiB,iBACjB,GAAoB,MACpB,GAAoB,QAE1B,YAAsB,EAAU,EAAyB,CAEvD,GAAI,CAAC,EAAI,QAAU,IAAY,GAC7B,KAAM,IAAI,OACR,2DAA2D,EAAI,sBAAsB,EAAI,kBAAkB,EAAI,sBAAsB,EAAI,cAM7I,GAAI,EAAI,QAAU,CAAC,GAAe,KAAK,EAAI,QACzC,KAAM,IAAI,OAAM,mDAQlB,GAAI,EAAI,MACN,GAAI,EAAI,WACN,GAAI,CAAC,GAAkB,KAAK,EAAI,MAC9B,KAAM,IAAI,OACR,oJAIA,GAAkB,KAAK,EAAI,MAC7B,KAAM,IAAI,OACR,8HAWV,YAAoB,EAAgB,EAA0B,CAC5D,MAAI,CAAC,GAAU,CAAC,EACP,OAEF,EAIT,YAA8B,EAAgB,EAAsB,CAKlE,OAAQ,OACD,YACA,WACA,OACH,AAAK,EAEM,EAAK,KAAO,IACrB,GAAO,GAAS,GAFhB,EAAO,GAIT,MAEJ,MAAO,GAGT,GAAM,IAAS,GACT,GAAS,IACT,GAAU,+DAkBT,QAAmC,OACjC,OAAM,EAA0B,CACrC,MAAI,aAAiB,IACZ,GAEL,GAAS,KACJ,GAGP,MAAa,GAAO,WAAc,UAClC,MAAa,GAAO,UAAa,UACjC,MAAa,GAAO,MAAS,UAC7B,MAAa,GAAO,OAAU,UAC9B,MAAa,GAAO,QAAW,UAC/B,MAAa,GAAO,QAAW,YAC/B,MAAa,GAAO,MAAS,YAC7B,MAAa,GAAO,UAAa,WAmD3B,YACR,EACA,EACA,EACA,EACA,EACA,EAAmB,GACnB,CACA,AAAI,MAAO,IAAiB,SAC1B,MAAK,OAAS,EAAa,QAAU,GACrC,KAAK,UAAY,EAAa,WAAa,GAC3C,KAAK,KAAO,EAAa,MAAQ,GACjC,KAAK,MAAQ,EAAa,OAAS,GACnC,KAAK,SAAW,EAAa,UAAY,IAKzC,MAAK,OAAS,GAAW,EAAc,GACvC,KAAK,UAAY,EAAO,EAAW,IACnC,KAAK,KAAO,GAAqB,KAAK,OAAQ,EAAO,EAAM,KAC3D,KAAK,MAAQ,EAAO,EAAO,IAC3B,KAAK,SAAW,EAAO,EAAU,IAEjC,GAAa,KAAM,OA8BnB,SAAiB,CAInB,MAAO,IAAY,KAAM,IAK3B,KAAK,EAMG,CACN,GAAI,GAAU,KACZ,MAAO,MAGT,GAAI,CAAE,SAAQ,YAAW,OAAM,QAAO,YAAa,EA2BnD,MA1BA,AAAI,KAAW,OACb,EAAS,KAAK,OACL,IAAW,MACpB,GAAS,IAEX,AAAI,IAAc,OAChB,EAAY,KAAK,UACR,IAAc,MACvB,GAAY,IAEd,AAAI,IAAS,OACX,EAAO,KAAK,KACH,IAAS,MAClB,GAAO,IAET,AAAI,IAAU,OACZ,EAAQ,KAAK,MACJ,IAAU,MACnB,GAAQ,IAEV,AAAI,IAAa,OACf,EAAW,KAAK,SACP,IAAa,MACtB,GAAW,IAIX,IAAW,KAAK,QAChB,IAAc,KAAK,WACnB,IAAS,KAAK,MACd,IAAU,KAAK,OACf,IAAa,KAAK,SAEX,KAGF,GAAI,IAAI,EAAQ,EAAW,EAAM,EAAO,SAW1C,OAAM,EAAe,EAAmB,GAAY,CACzD,GAAM,GAAQ,GAAQ,KAAK,GAC3B,GAAI,CAAC,EACH,MAAO,IAAI,IAAI,GAAQ,GAAQ,GAAQ,GAAQ,IAEjD,GAAM,GAAS,EAAM,IAAM,GACrB,EAAY,GAAc,EAAM,IAAM,IACtC,EAAQ,GAAM,IAAM,IAAQ,MAAM,KAAK,IAAI,IAAe,KAAK,KAC/D,EACJ,IAAW,UAAY,EAAK,WAAW,MAAQ,EAAK,MAAM,GAAK,EAC3D,EAAQ,GAAc,EAAM,IAAM,IAClC,EAAW,GAAc,EAAM,IAAM,IAC3C,MAAO,IAAI,IAAI,EAAQ,EAAW,EAAW,EAAO,EAAU,SAwBzD,MAAK,EAAmB,CAC7B,GAAI,GAAY,GAWhB,GANI,GACF,GAAO,EAAK,QAAQ,MAAO,KAKzB,EAAK,KAAO,IAAU,EAAK,KAAO,GAAQ,CAC5C,GAAM,GAAM,EAAK,QAAQ,GAAQ,GACjC,AAAI,IAAQ,GACV,GAAY,EAAK,UAAU,GAC3B,EAAO,IAEP,GAAY,EAAK,UAAU,EAAG,GAC9B,EAAO,EAAK,UAAU,IAAQ,IAIlC,MAAO,IAAI,IAAI,OAAQ,EAAW,EAAM,GAAQ,UAG3C,MAAK,EAMJ,CACN,MAAO,IAAI,IACT,EAAW,OACX,EAAW,UACX,EAAW,KACX,EAAW,MACX,EAAW,gBAWR,UAAS,KAAa,EAA6B,CACxD,GAAI,CAAC,EAAI,KACP,KAAM,IAAI,OAAM,yDAElB,GAAI,GACJ,MAAI,IAAS,EAAI,SAAW,OAC1B,EAAU,GAAI,KAAK,SAAM,KAAK,GAAY,EAAK,IAAO,GAAG,IACtD,KAEH,EAAU,SAAM,KAAK,EAAI,KAAM,GAAG,GAE7B,EAAI,KAAK,CAAE,KAAM,IAG1B,YAAsB,CACpB,MAAO,MAAK,MAAQ,MAAQ,KAAK,OAAS,MAGxC,WAA0B,CAC5B,MAAO,MAAK,aACR,GACA,EAAI,KAAK,KAAM,GAAQ,GAAS,EAAK,MAAM,IAAS,IAG1D,QAAc,CACZ,MAAI,MAAK,aAAqB,KACvB,KAAK,KAAK,CACf,KAAM,KAAK,KAAK,MAAM,EAAG,KAAK,KAAK,YAAY,OAInD,QAAQ,EAAqB,CAC3B,MAAO,MAAK,KAAK,CACf,KAAM,GAAa,KAAK,KAAM,IAAU,EAAK,KAAK,MAiBtD,SAAS,EAAwB,GAAe,CAC9C,MAAO,IAAa,KAAM,GAG5B,QAAwB,CACtB,MAAO,OAGR,WAAQ,SAAU,CACjB,MAAO,MAAK,aAmBV,GAAiB,GAAgB,EAAI,OAG3C,gBAAkB,GAAI,CAAtB,aA1cA,CA0cA,oBACE,gBAA4B,KAC5B,aAAyB,QAErB,SAAiB,CACnB,MAAI,MAAK,SAAW,MAClB,MAAK,QAAU,GAAY,KAAM,KAE5B,KAAK,QAGd,SAAS,EAAwB,GAAe,CAC9C,MAAK,GAOI,GAAa,KAAM,IANtB,MAAK,YAAc,MACrB,MAAK,WAAa,GAAa,KAAM,KAEhC,KAAK,YAOhB,QAAwB,CACtB,GAAM,GAAgB,CACpB,KAAM,GAGR,MAAI,MAAK,SAAW,MAClB,GAAI,OAAS,KAAK,QAClB,EAAI,KAAO,IAET,KAAK,YAAc,MACrB,GAAI,SAAW,KAAK,YAGlB,KAAK,MACP,GAAI,KAAO,KAAK,MAEd,KAAK,QACP,GAAI,OAAS,KAAK,QAEhB,KAAK,WACP,GAAI,UAAY,KAAK,WAEnB,KAAK,OACP,GAAI,MAAQ,KAAK,OAEf,KAAK,UACP,GAAI,SAAW,KAAK,UAEf,IAKL,GAAwC,EAC3C,GAAS,OAAQ,OACjB,GAAS,OAAQ,OACjB,GAAS,cAAe,OACxB,GAAS,MAAO,OAChB,GAAS,mBAAoB,OAC7B,GAAS,oBAAqB,OAC9B,GAAS,QAAS,OAElB,GAAS,iBAAkB,OAC3B,GAAS,YAAa,OACtB,GAAS,WAAY,OACrB,GAAS,aAAc,OACvB,GAAS,WAAY,OACrB,GAAS,YAAa,OACtB,GAAS,UAAW,OACpB,GAAS,MAAO,OAChB,GAAS,OAAQ,OACjB,GAAS,WAAY,OACrB,GAAS,QAAS,OAElB,GAAS,OAAQ,OAGb,YACL,EACA,EACQ,CACR,GAAI,GACA,EAAkB,GAEtB,OAAS,GAAM,EAAG,EAAM,EAAa,OAAQ,IAAO,CAClD,GAAM,GAAO,EAAa,WAAW,GAGrC,GACG,GAAQ,GAAS,GAAK,GAAQ,GAAS,GACvC,GAAQ,GAAS,GAAK,GAAQ,GAAS,GACvC,GAAQ,GAAS,QAAU,GAAQ,GAAS,QAC7C,IAAS,GAAS,MAClB,IAAS,GAAS,QAClB,IAAS,GAAS,WAClB,IAAS,GAAS,OACjB,GAAc,IAAS,GAAS,MAGjC,AAAI,IAAoB,IACtB,IAAO,mBAAmB,EAAa,UAAU,EAAiB,IAClE,EAAkB,IAGhB,IAAQ,QACV,IAAO,EAAa,OAAO,QAExB,CAEL,AAAI,IAAQ,QACV,GAAM,EAAa,OAAO,EAAG,IAI/B,GAAM,GAAU,GAAY,GAC5B,AAAI,IAAY,OAEV,KAAoB,IACtB,IAAO,mBACL,EAAa,UAAU,EAAiB,IAE1C,EAAkB,IAIpB,GAAO,GACE,IAAoB,IAE7B,GAAkB,IAKxB,MAAI,KAAoB,IACtB,IAAO,mBAAmB,EAAa,UAAU,KAG5C,IAAQ,OAAY,EAAM,EAGnC,YAAmC,EAAsB,CACvD,GAAI,GACJ,OAAS,GAAM,EAAG,EAAM,EAAK,OAAQ,IAAO,CAC1C,GAAM,GAAO,EAAK,WAAW,GAC7B,AAAI,IAAS,GAAS,MAAQ,IAAS,GAAS,aAC1C,KAAQ,QACV,GAAM,EAAK,OAAO,EAAG,IAEvB,GAAO,GAAY,IAEf,IAAQ,QACV,IAAO,EAAK,IAIlB,MAAO,KAAQ,OAAY,EAAM,EAM5B,YAAqB,EAAU,EAAwC,CAC5E,GAAI,GACJ,MAAI,GAAI,WAAa,EAAI,KAAK,OAAS,GAAK,EAAI,SAAW,OAEzD,EAAQ,KAAK,EAAI,YAAY,EAAI,OAC5B,AACL,EAAI,KAAK,WAAW,KAAO,GAAS,OAClC,GAAI,KAAK,WAAW,IAAM,GAAS,GACnC,EAAI,KAAK,WAAW,IAAM,GAAS,GAClC,EAAI,KAAK,WAAW,IAAM,GAAS,GAClC,EAAI,KAAK,WAAW,IAAM,GAAS,IACvC,EAAI,KAAK,WAAW,KAAO,GAAS,MAEpC,AAAK,EAIH,EAAQ,EAAI,KAAK,OAAO,GAFxB,EAAQ,EAAI,KAAK,GAAG,cAAgB,EAAI,KAAK,OAAO,GAMtD,EAAQ,EAAI,KAEV,GACF,GAAQ,EAAM,QAAQ,MAAO,OAExB,EAMT,YAAsB,EAAU,EAA+B,CAC7D,GAAM,GAAU,AAAC,EAEb,GADA,GAGA,EAAM,GACJ,CAAE,SAAQ,QAAO,YAAa,EAChC,CAAE,YAAW,QAAS,EAS1B,GARI,GACF,IAAO,EACP,GAAO,KAEL,IAAa,IAAW,SAC1B,IAAO,GACP,GAAO,IAEL,EAAW,CACb,GAAI,GAAM,EAAU,QAAQ,KAC5B,GAAI,IAAQ,GAAI,CAEd,GAAM,GAAW,EAAU,OAAO,EAAG,GACrC,EAAY,EAAU,OAAO,EAAM,GACnC,EAAM,EAAS,QAAQ,KACvB,AAAI,IAAQ,GACV,GAAO,EAAQ,EAAU,IAGzB,IAAO,EAAQ,EAAS,OAAO,EAAG,GAAM,IACxC,GAAO,IACP,GAAO,EAAQ,EAAS,OAAO,EAAM,GAAI,KAE3C,GAAO,IAIT,EAAM,EAAU,QAAQ,KACxB,AAAI,IAAQ,GACV,GAAO,EAAQ,EAAW,IAG1B,IAAO,EAAQ,EAAU,OAAO,EAAG,GAAM,IACzC,GAAO,EAAU,OAAO,IAG5B,GAAI,EAAM,CAER,GACE,EAAK,QAAU,GACf,EAAK,WAAW,KAAO,GAAS,OAChC,EAAK,WAAW,KAAO,GAAS,MAChC,CACA,GAAM,GAAO,EAAK,WAAW,GAC7B,AAAI,GAAQ,GAAS,GAAK,GAAQ,GAAS,GACzC,GAAO,IAAI,OAAO,aAAa,EAAO,OAAO,EAAK,OAAO,cAElD,EAAK,QAAU,GAAK,EAAK,WAAW,KAAO,GAAS,MAAO,CACpE,GAAM,GAAO,EAAK,WAAW,GAC7B,AAAI,GAAQ,GAAS,GAAK,GAAQ,GAAS,GACzC,GAAO,GAAG,OAAO,aAAa,EAAO,OAAO,EAAK,OAAO,MAI5D,GAAO,EAAQ,EAAM,IAEvB,MAAI,IACF,IAAO,IACP,GAAO,EAAQ,EAAO,KAEpB,GACF,IAAO,IACP,GAAO,AAAC,EAAyD,EAA1C,GAAuB,EAAU,KAEnD,EAKT,YAAoC,EAAqB,CACvD,GAAI,CACF,MAAO,oBAAmB,QAC1B,CACA,MAAI,GAAI,OAAS,EACR,EAAI,OAAO,EAAG,GAAK,GAA2B,EAAI,OAAO,IAEzD,GAKb,GAAM,IAAiB,8BAEvB,YAAuB,EAAqB,CAC1C,MAAI,GAAI,WAAW,QAAgB,iBAAU,GACxC,EAAI,MAAM,IAGR,EAAI,QAAQ,GAAgB,GAAS,GAA2B,IAF9D,EAKJ,YAAe,EAAsB,CAC1C,MAAO,IAAI,MAAM,GAAK,EAAI,GAAI,MAAM,GFhuB/B,GAAM,IAAS,GACpB,AAAC,GAAwB,EAAY,EAAM,IAC3C,CAAE,QAAS,IAAK,MAAO,IAIzB,EAAM,IAAM,CACV,EAAa,IAAM,GAAmB,SACtC,GAAQ,SAAS,IAAM,GAAmB,WAG5C,GAAM,IAAqB,EAAK,SACvB,EAAQ,KAAW,GACxB,GAAW,EAAK,IAAI,GAAO,CAAC,GAAO,EAAI,MAAO,EAAI,gBAI/C,YAA2B,EAAoB,EAAoB,CACxE,GAAI,EAAM,IAAe,GAAO,MAAQ,EAAM,EAAI,MAAO,OAEzD,GAAM,GAAW,GAAa,GACxB,EAAU,GAAa,EAAI,YACjC,GAAI,CAAC,EAAS,YAAY,WAAW,EAAQ,aAAc,OAC3D,GAAM,GAAO,GAAa,EAAS,MAAM,EAAQ,QAAS,KAE1D,MAAO,IAAI,KAAK,CACd,OAAQ,GACR,UAAW,GAAO,EAAI,MACtB,SAIG,YAAwB,EAAoB,EAAmB,CACpE,MAAO,YAAK,EAAY,GAAG,EAAU,MAAM,KAAK,MAAM,IAGxD,kBACE,EACA,EACsB,CACtB,GAAI,EAAI,SAAW,GACjB,KAAM,IAAI,OAAM,gBAAkB,EAAM,iBAE1C,GAAI,EAAM,EAAI,WACZ,KAAM,IAAI,OAAM,gBAAkB,EAAM,wBAQ1C,GAAM,GACJ,GAAc,MAAQ,EAAW,SAAS,QAE5C,GAAI,EAA2B,CAC7B,GAAM,GAAM,KAAM,IAAU,GAC5B,GAAI,GAAK,MAAQ,MAEX,AADc,GAAO,EAAI,QACX,EAAI,UACpB,MAAO,IAAe,EAAa,EAAI,MAO7C,GAAM,GAAgB,KAAM,GAAQ,KAAsB,GACxD,EAAE,IAAI,EAAI,YAEZ,GAAI,EAAS,GACX,MAAO,IAAe,EAAe,EAAI,MAG3C,GAAI,EACF,MAAO,IAAe,EAAa,EAAI,MI7F3C,OAAqB,mBAQd,GAAM,IAAiB,GAAI,KAAK,CACrC,OAAQ,GACR,KAAM,KAGD,YAA0B,EAAoB,CACnD,GAAM,GAAK,EAAS,YAAY,MAEhC,GAAI,EAAM,IAAO,EAAM,IAAe,CAAC,EAAW,WAAW,GAAK,OAElE,GAAM,GAAO,IAAM,GAAc,CAAE,WAAY,GAAM,CAAE,eAEvD,MAAO,IAAI,KAAK,CACd,OAAQ,GACR,SAIG,YAA0B,EAAyB,CACxD,GAAI,EAAI,SAAW,GACjB,KAAM,IAAI,OAAM,gBAAkB,EAAM,iBAG1C,GAAM,GAAK,EAAS,YAAY,MAEhC,GAAI,EAAM,GACR,KAAM,IAAI,OAAM,gBAAkB,EAAM,qBAG1C,MAAO,YAAK,EAAI,GAAG,EAAI,KAAK,MAAM,MCrCpC,OAAiC,mBAa1B,YACL,EACA,EACY,CACZ,GAAI,GAAM,GAGV,IACE,GAAO,MACP,EAAI,SAAW,IACf,EAAS,EAAI,aACb,EAAS,EAAI,aAEb,MAAO,IAAI,KAAK,CACd,OAAQ,GACR,UAAW,EAAI,WACf,KAAM,SAAM,KACV,IAAM,EAAI,YACV,GAAY,GAAa,GAAa,GAAa,EAAI,gBAM7D,GAAI,EAAW,WAAW,QACxB,MAAO,IAAI,KAAK,GAAY,KAAK,CAAE,OAAQ,MAO/C,kBACE,EACA,EACsB,CACtB,GAAI,EAAI,SAAW,GACjB,KAAM,IAAI,OAAM,gBAAkB,EAAM,iBAG1C,GAAI,EAAM,EAAI,WACZ,KAAM,IAAI,OAAM,gBAAkB,EAAM,wBAG1C,GAAM,GAAM,EAAI,KAAK,MAAM,KAAK,MAAM,GAChC,EAAQ,EAAI,GAElB,GAAI,EAAM,GACR,KAAM,IAAI,OAAM,gBAAkB,EAAM,oBAG1C,GAAI,EACF,MAAO,OAAO,EAAI,cAAc,EAAI,KAAK,UAG3C,GAAM,GAAO,EAAI,MAAM,GAGjB,EAAO,KAAM,MAEnB,OAAW,KAAO,GAAI,GACpB,GAAI,EAAC,EAAI,QAEP,GAAiB,EAAI,YAAa,IACjC,KAAM,IAAiB,EAAI,UAAW,EAAI,YAE3C,MAAO,YAAK,EAAI,WAAY,GAAG,GAInC,GAAI,KAAM,IAA8B,GACtC,MAAO,YAAK,EAAa,GAAG,GCtEhC,GAAM,IAAc,CAClB,QACA,SACA,QACA,GACA,IACA,IAAI,GAAM,EAAK,MAEV,YAAe,EAAoB,CACxC,GAAM,GAAI,EAAI,GAAG,cACjB,MAAO,IAAY,KAAK,GAAM,EAAE,WAAW,IAG7C,GAAM,IAAS,EAAK,IAAM,EAAS,qBAE5B,YAAsB,EAAqB,CAChD,GAAI,CACF,MAAO,IAAI,MAAM,GAAK,iBACf,EAAP,CACA,YAAS,KAAK,kCAAmC,CAAE,MAAK,QACjD,GAcJ,YAAoB,EAAW,EAAW,CAC/C,GAAI,CACF,GAAI,GAAK,MAAQ,GAAK,KAAM,MAAO,GACnC,GAAM,GAAK,GAAI,MAAM,GACf,EAAK,GAAI,MAAM,GACrB,MACE,GAAG,SAAW,EAAG,QACjB,EAAG,YAAc,EAAG,WACpB,EAAG,KAAK,cAAgB,EAAG,KAAK,iBAElC,CACA,MAAO,IAIX,kBACE,EACA,EACA,CACA,GAAI,CACF,GAAI,GAAK,MAAQ,GAAK,KAAM,MAAO,GACnC,GAAI,GAAI,EAAG,GAAI,MAAO,GACtB,GAAM,GAAO,EAAE,WACT,EAAO,EAAE,WACf,MAAI,IAAW,EAAM,GAAc,GAC5B,KAAM,IACX,GAAe,GACf,GAAe,GACf,CAAC,EAAI,IAAO,EAAG,cAAgB,EAAG,YAClC,IAAM,SAER,CACA,MAAO,IC3DX,GAAM,IAAS,EAAK,IAAM,EAAS,YAEnC,kBACE,EACA,EACc,CACd,GAAI,GAAc,MAAQ,EAAM,GAC9B,MAAO,MAAS,MAAM,8CAA+C,CACnE,UAAW,KAIf,GAAM,GAAM,EAAK,IAAM,GAAW,EAAQ,IAAM,GAAU,KAE1D,MAAO,IACL,IAAM,GAAiB,GACvB,SAAY,GAAkB,EAAY,KAAM,MAChD,SAAY,GAAiB,EAAY,KAAM,MAC/C,IAAM,GAAI,KAAK,IAkCnB,YAAe,EAA+B,CAC5C,GAAI,CACF,MAAI,IAAI,MAAM,GAAa,EACpB,GAAI,MAAM,EAAK,UACf,EAAP,CACA,KAAS,KAAK,UAAW,CAAE,MAAK,QAChC,QAIJ,kBACE,EACA,EACsB,CACtB,GAAI,EAAM,GAAM,OAChB,GAAM,GAAI,GAAM,GAChB,GAAI,GAAK,KAET,OAAQ,EAAE,YACH,OACH,MAAO,GAAE,WACN,IACH,MAAO,IAAkB,EAAG,OACzB,IACH,MAAO,IAAiB,EAAG,OACxB,IACH,MAAO,IAAiB,WAExB,KAAM,IAAI,OAAM,oBAAsB,IC3F5C,kBAAyB,EAAkB,CACzC,GAAM,GAAO,KAAM,IAAW,WAAW,eACvC,CACE,+BACA,GAAU,EAAK,YACf,gCACA,wCACA,KAAK,MAET,MACE,GAAI,GACD,QAAQ,GAAM,EAAG,IACjB,QAAQ,GAAM,EAAG,MACjB,OAAO,GAEP,QAAQ,AAAC,GAAiB,EAAK,SAAS,MAAQ,EAAK,SAAS,MAC9D,UAAU,IAAM,IAIvB,kBAAyB,EAAkB,CACzC,GAAI,CACF,GAAM,GAAM,KAAM,IAAO,OAAQ,CAAC,KAAM,KAAM,EAAK,YAAa,CAC9D,QAAS,GAAK,IAEV,EAAQ,EAAM,GACpB,MAAI,IAAS,KACH,GAAQ,OAAU,EAEnB,SAEF,EAAP,CACA,MAAO,IAIJ,YAAgB,EAAwC,CAC7D,MAAI,GAAK,KAAK,WAAW,KAAa,GAC/B,EAAQ,GAAU,GAAQ,GAAQ,GAAU,GAAQ,GCjBtD,YACL,EACA,EACA,EACS,CACT,GAAM,GAAyB,GAC/B,GAAI,CACF,OAAW,KAAa,GACtB,OAAW,KAAM,IAAK,GAAY,CAChC,GAAM,GAAS,EAAU,KAEzB,GADA,EAAQ,GAAM,EAAO,EAAQ,IACzB,IAAW,GAAM,MAAO,GAGhC,MAAO,UACP,CACA,GAAU,EAAQ,EAAM,IAyB5B,YAAmB,EAA0B,EAAc,EAAkB,CAC3E,GAAM,GAAQ,GAAK,KAAO,OAAS,QACnC,EAAO,IAAI,EAAO,EAAM,GAG1B,kBACE,EACA,EACA,EACkB,CAClB,GAAM,GAAyB,GAC/B,GAAI,CACF,OAAW,KAAa,GACtB,OAAW,KAAM,IAAK,GAAY,CAChC,GAAM,GAAS,KAAM,GAAU,KAE/B,GADA,EAAQ,GAAM,EACV,EAAQ,MAAO,GAGvB,MAAO,UACP,CACA,GAAU,EAAQ,EAAM,ICrFrB,YAAa,CAAb,aARP,CASmB,WAAQ,GAAI,KAE7B,IAAI,EAAe,EAAe,CAChC,GAAS,KAAK,MAAO,EAAO,IAAM,GAAI,MAAe,IAAI,GAG3D,OAAO,EAAe,EAAe,CACnC,EAAI,KAAK,MAAM,IAAI,GAAQ,GAAO,CAChC,EAAI,OAAO,GACP,EAAI,OAAS,GAAG,KAAK,MAAM,OAAO,KAI1C,KAAK,EAAmC,CACtC,MAAO,IACL,EAAO,UAAU,CAAC,EAAI,IAAQ,KAAK,MAAM,IAAI,IAAK,IAAI,EAAO,EAAM,KACnE,GAAO,EAAO,MAAM,EAAK,EAAM,IAInC,IAAI,EAAe,CACjB,MAAO,MAAK,KAAK,IAAQ,OCpB7B,GAAM,IAAS,EAAK,IAAM,EAAS,sBAE7B,GAAmB,EAAK,IAAM,CAClC,EAAS,aAAa,YAAY,IAAM,CACtC,GAAa,QACb,KACA,KAAS,KAAK,gCAAiC,EAAS,aAAa,SAEvE,EAAS,UAAU,YAAY,IAAM,CACnC,GAAa,QACb,OAEF,EAAa,IAAM,GAAa,WAG5B,GAAe,EAAK,IACxB,MACO,GAAI,KACT,EAAc,CACZ,GAAG,EAAS,UAAU,OACtB,GAAG,EAAS,aAAa,YAKxB,YAA4B,EAA6B,CAC9D,MACE,MAAe,IAAI,IACnB,KAAe,IAAI,EAAW,eAI3B,eAAwB,EAA8B,CAC3D,EAAS,aAAa,KAAK,GAAG,EAAc,GAAK,IAAI,KAGhD,YACL,EACmB,CACnB,MAAO,IAAmB,GACtB,CAAE,mBAAoB,IAAM,IAC5B,OCnDN,OAAqB,mBAgBrB,GAAM,IAAY,gBAEZ,GAAU,UAEhB,YAAkB,EAAW,CAC3B,MAAO,CAAC,EAAG,EAAE,cAAe,EAAE,eAGhC,GAAM,IAAe,OAAO,OAAO,CACjC,GAAG,GAAS,IAAM,IAClB,GAAG,GAAS,MAGP,YAAuB,EAA2B,CACvD,MAAO,IAAU,KAAK,IAAa,KAGrC,GAAM,IAAQ,GAAI,IAA+B,CAC/C,QAAS,KACT,UAAW,GACX,aAAc,IAGhB,EAAM,IAAM,EAAa,IAAM,GAAM,UACrC,EAAM,IACJ,GAAc,GAAQ,CACpB,GAAQ,KAAO,GAAM,QAAU,GAAM,SAAS,GAAO,EAAI,WAAW,OAIxE,GAAM,IAAS,EAAK,IAAM,EAAS,iBAEnC,kBAAiC,EAA8C,CAC7E,MAAI,IAAM,KAAa,GAInB,GAAmB,EAAG,YACjB,KAAS,IAAI,CAAE,IAAK,EAAK,oBAAqB,OAAQ,KAG3D,YAAc,IAET,GAAW,KAAM,GAAG,kBAKzB,GAAc,EAAG,MAEZ,KAAS,IAAI,CAAE,IAAK,EAAK,uBAAwB,OAAQ,KAK9D,GAAU,EAAG,YAAY,KAAK,IAEzB,KAAS,IAAI,CAAE,IAAK,EAAK,0BAA2B,OAAQ,KAGjE,KAAM,GAAG,eAgBP,AAfmB,KAAM,IAAM,cACjC,EAAG,WACH,SAAY,CACV,OAAW,KAAM,IACf,GAAI,KAAM,IAAiB,YAAK,EAAG,WAAY,IAC7C,MAAO,MAAS,IAAI,CAClB,IAAK,EAAK,4CAA8C,EACxD,OAAQ,KAId,MAAO,OAIY,GAAa,GAE/B,EAAG,OAAS,GAAQ,EAAQ,EAAG,SAAU,ICxF3C,YAAwB,EAAyB,CACtD,GAAM,GAAM,EAAS,yBAAyB,eAC9C,OAAW,KAAM,IAAI,KAAI,GACvB,GAAI,GAAM,EAAM,GAAM,IAAO,GAAM,EAAK,MAAO,GAEjD,MAAO,GCAF,YAAqB,CAC1B,YAAqB,EAAsC,CAAtC,mBAEd,MAAS,EAAoD,CAClE,MAAO,IAAI,IAAY,SAGlB,QAAW,EAA2C,CAC3D,MAAO,IAAI,IAAY,KAAO,IAAa,CACzC,OAAW,KAAK,GACd,GAAI,CAAE,KAAM,GAAE,MAAM,GAAQ,MAAO,GAErC,MAAO,WAIJ,OAAU,EAA2C,CAC1D,MAAO,IAAI,IAAY,KAAO,IAAa,CACzC,OAAW,KAAK,GACd,GAAI,KAAM,GAAE,MAAM,GAAO,MAAO,GAElC,MAAO,WAIJ,QACL,KACG,EACH,CACA,MAAO,IAAQ,EAAS,GACtB,GAAQ,GAAI,IAAI,CAAC,CAAC,EAAK,KAAW,EAAM,UAAU,OAAO,EAAQ,WAO9D,WACL,KACG,EACc,CACjB,MAAO,MAAK,IAAI,GAAG,KAAK,OAAO,EAAQ,GAAG,UAGrC,UACL,KACG,EACc,CACjB,MAAO,MAAK,GAAG,GAAG,KAAK,OAAO,EAAQ,GAAG,gBAG9B,YACX,EACA,EACqD,CACrD,GAAM,GAAqB,GACrB,EAAqB,GAC3B,OAAW,KAAa,GACtB,OAAW,CAAC,EAAM,IAAO,IAAQ,GAC9B,AAAE,MAAM,GAAG,MAAM,GAAM,EAAW,GAAU,KAAK,GAGtD,MAAO,CACL,WACA,YAIJ,SAAgB,CACd,MAAO,MAGT,OAAO,EAAoB,CACzB,MAAO,IAAY,IAAI,KAAM,GAAG,GAGlC,KAAY,CACV,MAAO,IAAI,IAAY,AAAC,GAAS,GAAQ,KAAK,MAAM,KAGtD,GAAG,EAAkB,CACnB,MAAO,IAAI,IACT,KAAO,IAEJ,KAAM,MAAK,MAAM,IAAW,KAAM,GAAK,MAAM,SAI9C,QAAO,EAAwB,CACnC,MAAO,IAAO,EAAK,GAAM,KAAK,MAAM,IAItC,OAAO,EAAgB,EAAqC,CAa1D,MAZW,IAAI,IAAY,KAAO,IAAY,CAC5C,GAAM,GAAS,KAAM,MAAK,MAAM,GAChC,SAAO,IACL,EAAS,QAAU,OACnB,CACE,GAAS,GACT,EAAS,GAAM,UAAY,GAAI,UAC/B,GAAU,IACV,KAAK,MAEF,MCxGb,GAAM,IAAS,EAAS,QAMX,GAA4C,GAAY,KACnE,KAAO,IAAqB,CAE1B,GAAI,CAAE,KAAM,MAAY,MAAO,GAG/B,GAAM,GAAM,AADE,GAAU,EAAK,YACX,QAAQ,QAC1B,MAAI,GAAM,EAAU,GACb,EAAI,KAAM,OAAS,SAAS,GAAU,EAAM,MAI1C,GAAU,EAAK,SAAY,CAEtC,GAAI,CAAC,IAAW,KAAY,MAAO,GAEnC,GAAI,CACF,YAAM,IAAO,OAAQ,CAAC,aAAc,CAClC,QAAS,GAAK,EACd,MAAO,GACP,WAAY,IAEP,QACP,CACA,MAAO,MAkBE,GAAQ,EAAK,SAAY,CACpC,GAAI,CAAE,KAAM,MAAY,MAAO,GAC/B,GAAI,CAGF,MAAO,MAAM,IACX,CAAC,OAAQ,WACT,KAAM,IAAO,OAAQ,CAAC,QAAS,CAAE,QAAS,GAAK,KAC/C,IAAI,GAAM,EAAG,YACR,EAAP,CACA,UAAO,KAAK,cAAe,GACpB,KAER,GAAK,GClCD,YAAgB,CA2IrB,YAAY,EAAmB,GAAQ,CA1ItB,8BAA2B,GAAI,KAC9C,CAQE,MACA,MACA,SACA,MACA,aACA,OAEA,OACA,MACA,MAGA,SAGA,OACA,QACA,YACA,SACA,OAGA,cACA,WACA,IAAI,GAAK,EAAE,cAAc,cAQZ,0BAAuB,GAAI,KAC1C,CACE,YACA,WACA,YACA,SACA,WACA,gBACA,WACA,eACA,WACA,mBACA,sBACA,eACA,WACA,QACA,SACA,YACA,QACA,uCACA,OACA,kBACA,aACA,aACA,cACA,gBAGA,cACA,eACA,eACA,eACA,SACA,aACA,uBACA,eACA,YACA,OACA,sBACA,gBACA,cACA,gBACA,eACA,YACA,4BACA,WACA,OACA,kBACA,aACA,YACA,cACA,aACA,YACA,MACA,QACA,mBACA,aACA,IAAI,GAAK,EAAE,gBAIE,gCAA6B,CAC5C,8BACA,4BACA,kBACA,qDACA,8BACA,gCACA,0BACA,oBACA,uBACA,qCACA,oCAGe,gBAAa,EAC5B,EAAc,CACZ,KACA,GAAO,WACP,GAAO,cACP,GAAO,gBACP,GAAO,uBACN,IAAI,GAAM,EAAG,cAAc,cAMf,sBAAmB,GAAI,IAUtC,AAAI,IACF,MAAK,yBAAyB,IAAI,OAClC,KAAK,yBAAyB,IAAI,SAGpC,KAAK,oBAAoB,MAAO,CAAC,UAEjC,GAAM,GAAU,CACd,MACA,WACA,MACA,MACA,QACA,UACA,MACA,QACA,QACA,SACA,MACA,OACA,OACA,QACA,MACA,MACA,MACA,OAGF,KAAK,oBAAoB,MAAO,GAChC,KAAK,oBAAoB,SAAU,GACnC,KAAK,oBAAoB,WAAY,GACrC,KAAK,oBAAoB,QAAS,GAGlC,KAAK,oBAAoB,UAAW,CAClC,OACA,aACA,UACA,QACA,OACA,YACA,OACA,gBACA,uBACA,SACA,WACA,WACA,SAGF,KAAK,oBAAoB,MAAO,CAC9B,WACA,UACA,UACA,OACA,qBAEF,KAAK,oBAAoB,MAAO,CAAC,SAAU,MAAO,GAAG,IAGrD,KAAK,oBAAoB,MAAO,CAAC,YAGjC,KAAK,oBAAoB,MAAO,CAC9B,QACA,QACA,QACA,MACA,QACA,OACA,MACA,OACA,MACA,OACA,QACA,QAIF,KAAK,oBAAoB,MAAO,CAC9B,QACA,MACA,MACA,OACA,MACA,OACA,MACA,KACA,YACA,QACA,WACA,SACA,SACA,MACA,MACA,MACA,MACA,YACA,MACA,SAEF,KAAK,oBAAoB,OAAQ,CAC/B,OACA,SACA,MACA,SACA,KACA,OACA,MACA,MACA,OACA,OACA,MACA,UACA,cACA,QAIF,KAAK,oBAAoB,UAAW,CAClC,sBACA,QACA,UACA,SACA,eACA,YACA,aACA,eACA,wBACA,gBACA,cACA,mBACA,YACA,eACA,oBACA,gBACA,aACA,cACA,QACA,aACA,aACA,WACA,gBACA,gBACA,oBACA,SACA,OACA,mBACA,YACA,eACA,gBACA,OACA,WACA,gBACA,gBACA,gBACA,eACA,OACA,kBACA,cACA,WACA,wBACA,SACA,YACA,YACA,WACA,OACA,UACA,gBACA,qBACA,UACA,WACA,SACA,YACA,mBACA,eACA,iBACA,UACA,gBACA,QACA,YACA,YAIF,KAAK,oBAAoB,MAAO,CAAC,OAAQ,SACzC,KAAK,oBAAoB,WAAY,CAAC,MAAO,OAAQ,QACrD,KAAK,oBAAoB,OAAQ,CAC/B,QACA,UACA,UACA,YACA,QAEF,KAAK,oBAAoB,MAAO,CAC9B,aACA,MACA,MACA,MACA,SACA,MACA,UACA,KACA,OACA,aAGF,KAAK,oBAAoB,MAAO,CAC9B,OACA,OACA,WACA,WACA,UACA,OACA,UACA,OACA,UAIF,KAAK,oBAAoB,KAAM,CAC7B,MACA,OACA,MACA,MACA,MACA,OACA,MACA,MACA,OACA,OAIF,GAAM,GAAW,CAAC,MAAO,KAAM,MAAO,OAAQ,MAAO,QAErD,KAAK,oBAAoB,OAAQ,GACjC,KAAK,oBAAoB,SAAU,GAGnC,KAAK,oBAAoB,MAAO,CAC9B,cACA,WACA,SACA,UACA,YACA,iBACA,UACA,UAIF,KAAK,oBAAoB,OAAQ,CAC/B,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,QAGF,KAAK,oBAAoB,OAAQ,CAAC,aAClC,KAAK,oBAAoB,OAAQ,CAAC,QAClC,KAAK,oBAAoB,SAAU,CAAC,YACpC,KAAK,oBAAoB,WAAY,CACnC,aACA,UACA,YACA,kBAEF,KAAK,oBAAoB,KAAM,CAAC,UAG3B,GACH,MAAK,oBAAoB,UAAW,CAAC,QAAS,WAAY,YAC1D,KAAK,oBAAoB,GAAO,WAAa,CAC3C,QACA,WACA,aAIA,GAEF,MAAK,qBAAqB,OAAO,OACjC,KAAK,yBAAyB,OAAO,OACrC,KAAK,qBAAqB,OAAO,QACjC,KAAK,yBAAyB,OAAO,QAErC,KAAK,yBAAyB,OAAO,OACrC,KAAK,iBAAiB,OAAO,MAAO,OAChC,GACF,KAAK,iBAAiB,OAAO,WAAY,QAnT/C,oBAAoB,EAAc,EAAoB,CACpD,GAAI,EAAM,GAAO,OACjB,GAAM,GAAI,EAAK,cAAc,YAC7B,EAAc,GAAU,QAAQ,GAC9B,KAAK,iBAAiB,IAAI,EAAG,EAAG,cAAc,cAoTlD,wBAAwB,EAAgC,CACtD,GAAM,GAAe,GAA4B,GACjD,GAAI,GAAgB,KAAM,MAAO,GAEjC,GAAM,GAAK,EAAW,cAAc,YAC9B,EAAQ,EAAc,GAAU,IACtC,MAAO,CACL,YAAa,IAAM,EAAM,KAAK,GAAM,EAAG,WAAW,MAClD,UAAW,IAAM,KAAK,WAAW,KAAK,GAAM,EAAG,WAAW,IAC1D,cAAe,IAAM,KAAK,yBAAyB,IAAI,EAAM,IAC7D,mBAAoB,IAClB,EAAM,KAAK,GAAM,KAAK,qBAAqB,IAAI,IACjD,cAAe,IAAM,KAAK,iBAAiB,IAAI,GAC/C,iBAAkB,IAAM,CACtB,GAAM,GAAY,GAAa,GAC/B,MAAO,MAAK,2BAA2B,KAAK,GAAM,EAAG,KAAK,MAKhE,cAAc,EAA6B,CACzC,MAAO,IACL,CAAC,KAAK,wBAAwB,IAC9B,EACA,EAAS,sBAKT,GAAW,EAAK,IAAM,GAAI,KAEzB,YAAiC,EAAqC,CAC3E,MAAO,QACF,KAAW,wBAAwB,IADjC,CAEL,UAAW,IAAM,EAAU,IAAI,GAAY,cAIxC,YAAuB,EAA6B,CACzD,MAAO,MAAW,cAAc,GAG3B,YAAuB,EAA2B,CACvD,MAAO,IAAc,EAAK,YAMrB,YACL,EACiB,CACjB,GAAM,GAAK,EAAK,WAAW,cAAc,YACzC,MAAI,IAAmB,EAAK,aAAe,GAAmB,GACrD,CACL,mBAAoB,IAAM,IAGvB,OACF,GAAwB,EAAK,aAD3B,CAEL,cAAe,SAAY,IAAY,KAAM,IAAiB,MAAM,GAEpE,QAAS,SAAY,AAAU,KAAM,IAAW,KAA3B,GACrB,OAAQ,IAAM,GAAO,GACrB,eAAgB,IAAM,GAAe,EAAK,WAC1C,WAAY,SACV,GACE,KACA,GAAO,EAAI,SAAS,EAAK,YACzB,IAAM,MAad,kBAAyC,EAAoC,CAC3E,MAAO,IACL,CAAC,GAA6B,IAC9B,EAAK,WACL,EAAS,yB3C1gBb,GAAM,IAAQ,GAAI,IAiCX,mBAAwB,GAA+B,CAKlD,YAAqB,EAAoB,EAAyB,CAC1E,MAAM,EAAY,GADW,kBAJZ,WAAQ,EAAK,IAC9B,EAAS,aAAe,KAAK,WAAa,MA+DnC,eAAY,EAAK,IAAM,GAAe,KAAK,aAC3C,SAAM,EAAK,IAAM,EAAQ,KAAK,YAAa,IAC3C,aAAU,EAAK,IAAM,GAAI,KAAK,KAAK,YAAY,YAE/C,gBAAa,EAAK,IACrB,GAAS,KAAK,WAAW,WAAW,QAC/B,KAAK,IAAI,KAAK,WAAW,MAAM,MAAM,MAAM,EAAG,GAAG,KAAK,OAExD,EAAQ,KAAe,GAC5B,KAAK,eAAe,EAAI,IAAI,GAAM,KAAK,IAAI,OAyFtC,UAAO,EAAK,IACnB,EAAQ,KAAK,OAAQ,GACnB,CAAC,EAAE,KAAM,EAAE,MAAM,WAAW,IAAI,GAAK,GAAQ,OAAO,IAAI,KAAK,OA2FxD,kBAAe,EACtB,SACG,KAAM,MAAK,eACX,KAAM,IACL,KACA,GAAO,EAAI,SAAS,KAAK,YACzB,IAAM,KAYH,cAAW,EAAsB,SAAY,CACpD,GAAI,KAAK,YAAa,MAAO,GAC7B,GAAM,GAAM,KAAM,MAAK,SAAS,sBAC9B,GACE,EAAG,OAAS,KAAK,MACjB,GAAa,EAAG,MACf,GAAG,OAAS,KAAK,MAChB,EAAG,OAAS,KAAK,MAChB,GAAS,+BAA+B,eACrC,GAAiB,EAAG,KAAM,KAAK,OAC/B,GAAiB,EAAG,KAAM,KAAK,MAC/B,KACJ,GAAiB,EAAG,QAAU,GAAiB,KAAK,OACnD,GAAS,+BAA+B,eACrC,GACE,GAAiB,EAAG,MACpB,GAAiB,KAAK,OAExB,MAGV,GAAI,GAAO,KAAM,MAAO,GACxB,GAAM,GAAa,EAAI,IAAI,GAAM,KAAK,SAAS,qBAAqB,IACpE,MAAO,IAAY,EAAY,GAAM,EAAG,eAqBjC,qBAAkD,EAAK,SAAY,CAC1E,GAAM,GAAY,CAAC,KAAM,GAAI,KAAM,MAAK,YAAa,IACnD,GAAM,EAAG,YAGX,MAAO,AADQ,MAAM,IAAQ,GAAK,KACpB,SAAS,WACtB,GAAS,eA1TL,mBAAkB,EAAoB,CAC3C,MAAO,MAAK,IAAI,EAAG,WAAY,SAG1B,KACL,EACA,EACW,CACX,GAAI,EAAM,GAAmB,KAAM,IAAI,OAAM,2BAC7C,GAAI,YAA4B,GAC9B,MAAO,GAET,GAAI,YAA4B,IAC9B,MAAO,MAAK,IAAI,EAAiB,WAAY,GAE/C,GAAI,GAAM,GAAmB,KAAM,IAAI,OAAM,cAG7C,GAAM,GAAQ,GAAM,IAAI,GACxB,GAAI,GAAS,KAAM,MAAO,GAC1B,GAAM,GAAe,GAAQ,GAE7B,MAAO,IAAM,SACX,EACA,IAAM,GAAI,GAAU,EAAc,UAM/B,UAAS,EAAyB,CACvC,MAAO,MAAK,IAAI,EAAK,QAAQ,MAAO,eAG/B,QAAO,EAAa,EAA8C,CACvE,MAAO,GAAQ,GAAe,EAAK,GAAa,GAC9C,KAAK,IAAI,IAIb,IAAI,EAAc,EAA+B,CAC/C,MAAO,GAAU,IAAI,EAAM,GAG7B,OAAc,CACZ,aAAM,QACN,KAAK,UAAU,QACf,KAAK,IAAI,QACT,KAAK,QAAQ,QACb,KAAK,WAAW,QAChB,KAAK,KAAK,QACV,KAAK,SAAS,QACP,KAgBT,eAAe,EAAwC,CACrD,MAAO,IACL,EACG,OAAO,GAAM,GAAsB,KAAK,WAAY,EAAG,aACvD,IAAI,GAAM,EAAU,IAAI,IAC3B,GACE,EAAI,GAAmB,KAAK,UAAW,EAAM,YAC1C,OAAO,GAAO,GAAO,EAAM,UAAU,QACrC,YAQH,WAAU,EAA2C,CAEzD,GADA,EAAM,KAAM,IAAW,EAAK,IAAM,KAAK,OACnC,KAAK,MACP,MAAO,MAAK,QAAQ,IAAI,CACtB,OAAQ,OACR,IAAK,mCAKT,GAAI,KAAM,MAAK,SACb,MAAO,MAAK,QAAQ,IAAI,CACtB,OAAQ,GACR,IAAK,6BAIT,GAAI,GAAO,KACT,MAAO,MAAK,QAAQ,IAAI,CACtB,OAAQ,OACR,MAAO,OACP,IAAK,6BAQT,GAFA,EAAM,GAAM,GAER,EAAI,aAEN,MAAO,MAAK,QAAQ,IAAI,CACtB,OAAQ,OACR,IAAK,8BACL,KAAM,CAAE,SAMZ,GAAI,EAAI,EAAI,UAAU,cAAgB,KAAK,KAAK,YAC9C,MAAO,MAAK,QAAQ,IAAI,CACtB,MAAO,OACP,OAAQ,OACR,IAAK,iCACL,KAAM,CAAE,MAAK,aAAc,KAAK,KAAM,QAAS,EAAI,YAMvD,GAAM,GAAgB,KAAM,MAAK,SAAS,UAAU,EAAI,UAExD,MAAI,IAAiB,KACZ,KAAK,QAAQ,IAAI,CACtB,OAAQ,OACR,IAAK,gDACL,KAAM,CAAE,SAGH,KAAK,QAAQ,IAAI,CACtB,OAAQ,GACR,IACE,mFACF,KAAM,CAAE,gBAAe,cAWvB,cAAqC,CACzC,MAAO,CACL,KAAM,KAAM,MAAK,OACjB,gBAAiB,KAAM,MAAK,wBAI1B,OAA2B,CAC/B,GAAM,GAAM,KAAO,GACf,GAAO,SAAU,CAAC,KAAM,KAAK,YAAa,CACxC,QAAS,GAAK,IACb,MAAM,GAAO,GAChB,GACA,GAAO,UAAW,CAAC,SAAU,KAAK,YAAa,CAC7C,QAAS,GAAK,IACb,MAAM,GAAO,GAChB,IACJ,GAAI,EAAS,GAAM,CACjB,KAAK,QAAQ,KAAK,QAAU,KAAK,WAAa,aAAe,GAC7D,WAEA,OAAO,MAAK,QAOhB,iBAAkB,CAChB,MAAO,MAAK,OAAO,kBAAmB,IACpC,KAAK,aAAa,KAAK,GAAK,EAAE,mBAO5B,aAAa,CACjB,GAAI,KAAM,MAAK,SACb,KAAM,IAAI,OAAM,gBAAkB,KAAO,eAE3C,KAAM,MAAK,UACX,GAAM,GAAI,KAAK,KAAK,YACpB,AAAK,KAAM,GAAE,kBAAsB,KAAM,GAAE,WACzC,MAAM,GAAE,UACN,CACE,wEACA,GACA,0DACA,KAAK;AAAA,IAET,GAAgB,KAAK,kBAQnB,YAAgC,CACpC,GAAI,CACF,YAAM,MAAK,aACJ,WACA,EAAP,CACA,KAAK,QAAQ,KAAK,kCAAoC,KAAM,GAC5D,QAIJ,YAAoC,CAClC,MAAO,IAAW,MAGpB,gBAAiB,CACf,MAAO,IAAc,KAAK,iBAGtB,YAAY,CAChB,MAAQ,MAAM,MAAK,cACf,GAAmB,MACnB,GAAc,MAGpB,QAAS,CACP,MAAO,IAAO,MAahB,WAAY,CACV,MAAO,IAAa,KAAK,UAoCrB,UAAU,CACd,MAAO,IAAQ,KAAK,YACjB,QAAQ,GAAO,EAAI,EAAI,OAAS,IAChC,UAAU,IACT,KAAK,QACH,KAAK,KACH,GACE,EAAS,mBAAmB,eAC5B,KACA,qBAcN,eAAqC,CAEzC,GAAM,GAAU,KAAM,MAAK,SACzB,GACE,GAAiB,EAAG,IAAK,UACxB,GAAG,OAAS,KAAK,MAChB,EAAG,OAAS,KAAK,MACjB,GAAiB,EAAG,QAAU,GAAiB,KAAK,QAE1D,MAAO,MAAK,QAAQ,IAAI,CACtB,IAAK,iBACL,OACE,GAAW,KACP,OACA,KAAM,IAAY,EAAS,GAAM,EAAG,eAO9C,0BAAiD,CAC/C,MAAO,MAAK,KAAK,mBAAoB,SAAY,CAC/C,GAAM,GAAgB,KAAM,MAAK,UAC3B,EAAW,KAAM,MAAK,WACtB,EAAkB,KAAM,SAAQ,IACpC,EAAI,GAAU,IAAI,GAAM,EAAG,YAEvB,EAAM,CAAC,EAAe,GAAG,GAAiB,OAAO,GACvD,MAAO,IAAY,EAAK,GAAM,KAAK,MAAM,KAAK,IAAI,GAAG,OAIzD,2BAAkD,CAChD,MAAO,GAAQ,KAAK,2BAA4B,GAAM,GAAS,M4C/anE,GAAM,IAAsB,EAAK,IAAM,CACrC,EAAS,SAAS,YAAY,IAAM,GAAS,WAGlC,GAAW,EAAK,IAAM,CACjC,GAAI,CACF,KACA,GAAM,GAAI,EAAU,IAAI,EAAS,SAAS,gBAC1C,MAAK,GAAE,aACA,QACA,EAAP,CACA,QAAQ,4BAA8B,GAAgB,GAChD,IAEP,GCbI,GAAM,IAAmB,GAInB,GAAe,E9CC5B,GAAM,IAAS,EAAK,IAAM,EAAS,eAEnC,mBAAwD,CACtD,MAAO,IACL,KAAW,QAAQ,WACnB,GAAO,EAAI,OAAO,GAAM,EAAG,KAAK,WAAW,KAC3C,IAAM,IAIH,GAAM,IAAiB,cAS9B,kBAAiC,EAAkB,GAA0B,CAE3E,GAAM,GAA0B,GAIhC,EAAO,KAAK,CAAC,gBAAiB,KAC9B,EAAO,KAAK,CAAC,qBAAsB,KACnC,EAAO,KAAK,CAAC,eAAgB,EAAS,YAAY,QAClD,GAAM,GAAS,GAAe,EAAU,GAAS,GAAI,IAC/C,EAAM,KAAW,KAAK,GAAiB,GAC7C,MAAK,IAEL,MAAM,cAAO,EAAI,YACjB,KAAM,GAAI,KAAK,cAAc,cAAc,GACzC,EACG,UACC;AAAA;AAAA,EAEN,EAAS,YAAY;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOnB,EAAO,IAAI,CAAC,CAAC,EAAG,KAAO,GAAG,MAAM,KAAK,KAAK;AAAA,IAEvC,MAAM,GAAO,CACZ,KAAS,KAAK,6BAA+B,EAAK,MAGxD,KAAS,KAAK,yBAA2B,IAClC,EAGT,kBAAoC,EAAiB,CACnD,GAAM,GAAI,EAAO,EAAK,KAAM,OAC5B,GAAI,CAAC,EAAE,KAAK,WAAW,IACrB,KAAM,IAAI,OAAM,gCAAkC,GAEpD,KAAM,GAAE,OAYV,mBAAuC,CACrC,OAAW,KAAO,MAAM,MACtB,KAAM,IAAc,G+C7EjB,GAAM,IAA0B,CACrC,YAAa,AAAC,GACZ,EAAI,OACF,UACA,wFAEJ,WAAY,KAAO,IAAe,CAChC,AAAI,EAAO,EAAK,QACd,GAAS,UAAU,SAAW,GAC9B,KAAM,SCVL,GAAM,IAA6B,CACxC,YAAa,AAAC,GACZ,EAAI,OACF,yBACA,+GAEJ,WAAY,KAAO,IAAe,CAChC,AAAI,EAAO,EAAK,WACd,GAAS,sBAAsB,SAAW,EAC1C,EAAS,iBAAiB,SAAW,GACrC,EAAS,kBAAkB,SAAW,EACtC,EAAS,kBAAkB,SAAW,KCXrC,GAAM,IAA4B,CACvC,YAAa,AAAC,GACZ,EAAI,OACF,YACA,2EAEJ,WAAY,KAAO,IAAe,CAChC,AAAI,EAAO,EAAK,UACd,GAAS,QAAQ,SAAW,MCR3B,GAAM,IAA+B,CAC1C,YAAa,AAAC,GACZ,EAAI,OACF,+BACA,6QAEJ,WAAY,AAAC,GAAe,CAC1B,AAAI,EAAO,EAAK,cACd,GAAS,iBAAiB,SAAW,MCjB3C,OAAmC,4BACnC,GAAc,sBCAd,OAA8B,sBAC9B,GAA8B,qBC2BvB,YAAiB,EAAyC,CAC/D,MAAQ,IAAM,MAAQ,EAAW,EAAG,OAAU,GAAO,GAGhD,YAAgB,EAAyC,CAC9D,MAAQ,IAAM,MAAQ,EAAW,EAAG,MAAS,GAAQ,GAGhD,YAAiB,EAAyC,CAC/D,MAAO,IAAM,MAAQ,EAAW,EAAG,MAW9B,YAAgB,EAAmD,CACxE,MAAO,CACL,GAAI,EAAI,EAAG,IACX,KAAM,EAAI,EAAG,MACb,IAAK,EAAI,EAAG,KACZ,KAAM,EAAI,EAAG,OAgBV,eACF,EACgB,CACnB,EAAM,EAAQ,GACd,WACE,EACU,CACV,MAAO,GAAK,EAAQ,GAAQ,EAAI,IAAI,MAGtC,MAAO,CACL,GAAI,EAAK,GAAM,EAAG,IAClB,KAAM,EAAK,GAAM,EAAG,MACpB,IAAK,EAAK,GAAM,EAAG,KACnB,KAAM,EAAK,GAAM,EAAG,ODrCjB,GAAM,IAA0B,SAEjC,GAAS,EAAK,IAAM,EAAS,iBAOnC,kBACE,EACwB,CACxB,GAAM,GAAM,GAAa,EAAS,OAC5B,EAAO,GAAS,cAChB,EAAU,GAAS,IAAI,cACvB,EAAO,GACT,CAEE,EAAK,KAAK,MAAO,GAEjB,EAAK,KAAK,WAAY,IAExB,CAEE,EAAQ,KAAK,OAAQ,UAAW,GAEhC,EAAQ,KAAK,MAAO,UAAW,IAIrC,EAAK,KAAK,EAAQ,KAAK,OAAQ,MAAO,IAEtC,GAAM,GAAS,GAAW,EAAM,KAAM,IACnC,KAAM,GAAG,WAAW,KAAQ,EAAK,QAEpC,MAAO,MAAS,IAAI,CAClB,IAAK,kBACL,MAAO,OACP,SACA,KAAM,CAAE,MAAK,YAAU,KAAM,EAAK,IAAI,MAc1C,GAAI,IAAgB,EACb,YAAqB,EAA0B,CACpD,OAAQ,OACD,MACH,MAAO,UACJ,OACH,MAAO,UACJ,YACH,MAAO,MAAQ,KAAkB,WAEjC,MAAO,OAIN,YAAkB,EAA4B,CACnD,GAAM,GAAO,GACb,MAAI,GAAS,QAAQ,gBACnB,EAAK,KAAK,aAAe,GAAY,IAEhC,EE9GF,oBAA8B,GAAe,CAElD,YAAY,EAST,CACD,MACE,EAAK,KACL,IAAM,CACJ,EAAI,KAAK,MAAO,eAChB,KAAK,MAAQ,QAEf,EAAO,EAAK,KAAM,EAAa,OAC/B,IACE,EACE,EAAK,SACL,GAAK,IACL,IAAM,IAEV,EAAK,cAEP,AAAK,KAAK,MAAM,QAGJ,OAAM,EAAwD,CAE1E,AADI,EAAI,EAAK,iBAAiB,KAAM,IAAW,EAAK,gBAChD,MAAK,OACT,MAAK,MAAQ,GACX,EAAK,SACL,KAAK,MAAM,EAAK,YAChB,GAAG,EAAI,EAAK,UCjCX,oBAA6B,GAAgB,CAIlD,YACW,EACA,EACA,EACA,EAAkB,GAC3B,CACA,MAAM,CACJ,KAAM,iBACN,WAAY,GAAM,GAAK,EAAU,GAAK,EAAU,EAAW,GAC3D,SAAU,IAAM,KAAK,YARd,YACA,gBACA,cACA,uBAPF,WAAQ,GAAI,IACrB,yBAAsB,OAehB,SAAQ,EAAW,KAAK,SAAoC,CAChE,MAAO,MAAK,OAAS,KAAK,MAAQ,KAAK,oBAAsB,GAAK,EAC9D,OACA,KAAK,MAAM,SAAS,UAAW,IAAM,KAAK,SAAS,SAG3C,UAAS,EAAuC,CAC5D,GAAM,GAAO,KAAM,MAAK,OACxB,GAAI,GAAQ,KAAM,MAAO,GACzB,GAAM,GAAQ,KAAK,MAAQ,EACrB,EAAqB,GAC3B,KAAM,GAAK,QAAQ,iBAAiB,KAAM,IAAK,CAG7C,GAAM,GAAS,KAAM,GAAE,YACvB,AACG,KAAM,GAAE,UACT,GAAU,MAEV,CAAE,GAAE,SAAS,IAAI,IAAS,GAAc,EAAE,QACzC,KAAM,MAAK,OAAO,IACnB,EAAS,GAET,GAAO,KAAK,GACZ,KAAM,GACH,SACA,MAAM,GAAO,KAAK,OAAO,KAAK,oBAAsB,EAAG,OAG9D,GAAM,GAAY,EAAO,OACzB,YAAK,OAAO,KAAK,WAAa,EAAY,WAC1C,KAAM,GAAK,QAAQ,iBAAiB,KAAM,IAAK,CAE7C,GADA,EAAE,QACG,KAAM,GAAE,eAAkB,CAAE,KAAM,GAAE,gBAAkB,CAEzD,GAAM,GAAa,KAAM,GAAE,wBAC3B,AAAI,EAAW,IAEmB,AADb,EAAW,IAAI,GAAM,EAAG,YACA,MAAM,GAC/C,EAAO,KAAK,GAAU,EAAO,aAAe,KAGxC,KAAM,IAAU,IAAM,EAAE,QAAS,CAAE,UAAW,EAAI,KACpD,EAAO,KAAK,GAKpB,AAAK,KAAM,GAAE,eAAmB,KAAM,GAAE,iBACtC,GAAO,KAAK,GACZ,KAAM,GACH,QACA,MAAM,GAAO,KAAK,OAAO,KAAK,mBAAqB,EAAG,OAI7D,KAAK,OAAO,KACV,UAAa,GAAO,OAAS,GAAa,uBAE5C,KAAK,oBAAsB,KAAK,MACzB,ICzFX,OAA2C,wBAC3C,GAAqB,uBACrB,GAAwB,mBCFxB,OAA0C,gCAC1C,GAAwB,mBCDxB,OAAe,iBAaf,kBAA6B,EAAoC,CAC/D,GAAM,GAAM,EAAQ,QAAU,QAC9B,GAAI,CACF,GAAM,GAAS,KAAM,IAAa,EAAK,CAAC,GAAO,CAC7C,QAAS,EAET,eAAgB,GAChB,aAAc,KAQhB,MAAO,GAAO,OAAS,GAAK,EAAS,EAAO,QACxC,EAAO,OAAO,OAAO,MAAM;AAAA,GAAM,IAAI,OACrC,YACJ,CACA,QAIJ,kBAA4B,EAAoB,CAC9C,MAAO,IAAK,MAAS,KAAM,GAAE,SAAY,EAAE,WAAa,OAO1D,kBACE,EACA,EACiB,CACjB,GAAM,GAAW,EAAI,GAAY,QAAS,GAAM,GAAS,IAAI,IAC7D,GAAI,IAAe,IAAY,MAAS,KAAM,GAAS,kBAErD,KAAM,IAAI,OAAM,qCAAuC,IAGzD,WAAiB,EAAc,CAE7B,MAAO,IAAU,KACf,GAAe,IAAM,EACrB,EAAO,EAAa,GACpB,EAAQ,GAAQ,OAAS,KAG7B,MAAO,IAEL,IAAM,GAAa,EAAQ,WAAG,SAE9B,IAAO,WAAG,SAAW,MAAQ,GAAa,EAAQ,SAAW,OAE7D,IAAM,GAAiB,IAI3B,kBAAgC,EAA+B,CAC7D,MAAO,IAEL,IAAM,GAAO,GAEb,IAAM,GAAa,GAAS,IAAI,GAAY,QAAQ,KAAK,IACzD,IAAM,CACJ,KAAM,IAAI,OAAM,wBAA0B,KAKzC,GAAM,IAAqB,EAAK,IAAM,GAAW,YAAa,WAExD,GAAwB,EAAK,IACxC,GAAW,eAAgB,WAGhB,GAAqB,EAAK,IAAM,GAAW,aAE3C,GAAmB,EAAK,IAAM,GAAW,YCvEtD,GAAM,IAAQ,GAAI,IAAiC,KAEnD,EAAa,IAAM,GAAM,SACzB,GAAc,GAAO,GAAM,KAAO,GAAM,QAAU,GAAM,OAAO,IAC/D,GAAM,IAAS,EAAK,IAAM,EAAS,YAEnC,kBAA8B,EAAuC,CACnE,MAAO,IAAM,SAAS,EAAI,WAAY,SAAY,CAChD,GAAI,CACF,GAAM,GAAM,KAAM,MAEZ,EAAI,KAAM,IAAO,EAAK,CAAC,KAAM,EAAI,YAAa,CAClD,QAAS,KAEX,MAAO,GAAY,EAAG,UACf,EAAP,CACA,KAAS,KAAK,sBAAuB,CACnC,KAAM,EAAI,WACV,MAAO,GAAS,KAElB,UAKC,YAA4B,EAAe,CAChD,GAAM,CAAC,EAAU,EAAM,EAAO,EAAG,GAAK,EAAM,MAAM,KAClD,MAAO,MAAS,IAAI,CAClB,IAAK,uBACL,OAAQ,GAAY,EAAM,GAAI,EAAM,GAAI,CAAC,EAAO,IAAY,EAC1D,WACA,OACA,QACA,UAAW,CAAE,QAAO,aAEtB,KAAM,CAAE,WCvDZ,OAAyB,iBCDlB,YAAc,EAAY,EAAY,EAAI,GAAa,CAE5D,MAAQ,GAAI,GAAK,EAAK,EAAI,EAWrB,YAAgB,EAAW,EAAW,EAAmB,CAC9D,GAAM,GAAK,EAAG,EAAI,EAAG,EAEf,EAAI,AADE,GAAI,EAAG,GACH,EAChB,MAAO,IAAK,EAAG,EAAG,EAAG,EAAG,GCdnB,YAAyB,EAAkC,CAChE,MACE,GAAS,IACR,GAAS,WAAW,WACnB,IAAa,mBACb,IAAa,mBCCZ,YAA4B,EAA+B,CAChE,MAAO,GAAI,EAAG,GACZ,CAAC,EAAG,SAAU,EAAG,cAAe,EAAG,eAAe,KAAK,ICLpD,YAAoB,EAAuB,CAChD,MAAO,IAAS,IAAM,CAAC,EAAG,GAAI,IAAK,KAAK,SAAS,GAI5C,YAA2B,EAA0C,CAC1E,GAAM,GAAI,EAAI,EAAU,GAAM,GAAM,EAAK,KAAK,KAAK,CAAC,EAAK,KAAO,MAChE,MAAO,IAAW,GAAK,EAAI,OAOtB,YAAmB,EAAyB,CACjD,GAAM,GAAI,GAAkB,GAC5B,MAAO,KAAM,IAAM,IAAM,ICFpB,YAAyB,EAAkC,CAChE,MAAO,GAAI,EAAM,GACf,GACE,IAAM,GAAsB,EAAG,aAC/B,IAAM,GAAsB,EAAG,mBAC/B,IAAM,GAAkB,EAAG,YAKjC,GAAM,IAA4B,GAAI,KAA6B,CACjE,CAAC,sBAAuB,GACxB,CAAC,eAAgB,IACjB,CAAC,aAAc,KACf,CAAC,gBAAiB,KAClB,CAAC,EAAG,GACJ,CAAC,EAAG,IACJ,CAAC,EAAG,KACJ,CAAC,EAAG,OAOC,YACL,EACe,CACf,MAAO,GAAI,EAAa,GAAM,GAA0B,IAAI,IAG9D,GAAM,KAA2B,GAAI,KAAoB,CACvD,CAAC,EAAG,GACJ,CAAC,GAAI,GACL,CAAC,IAAK,GACN,CAAC,IAAK,KC7CD,YAAsB,EAAyB,CACpD,MAAO,IAAK,MAAQ,EAAI,EAAE,QAAU,EAAI,EAAE,QAGrC,YAAgB,EAAe,CACpC,MAAO,GAAG,EAAE,cAAW,EAAE,SAGpB,YAAmB,EAAe,CACvC,MAAO,IAAY,EAAE,MAAQ,EAAE,QAG1B,YAAc,EAA6B,CAChD,MAAO,CAAE,MAAO,EAAI,OAAQ,OAAQ,EAAI,OAGnC,YACL,EACA,EACY,CACZ,MAAO,IAAU,GAAY,GAAK,GAAO,EASpC,YAAoB,EAA0B,CACnD,MAAO,GAAI,MAAQ,EAAI,OAAS,EAG3B,YAAqB,EAAiB,CAC3C,MAAO,IAAW,EAAI,MAAQ,EAAI,QCtBpC,GAAM,IAAS,EAAK,IAAM,EAAS,aAE5B,YACL,EAGA,EACA,EACiB,CACjB,GAAM,GAAiB,GACrB,CACE,GAAS,UAGT,CAAE,MAAO,EAAK,WAAY,OAAQ,EAAK,cAEzC,GAAM,GAAa,GAAK,EAAI,QAW9B,GARA,KAAS,MAAM,oBAAqB,CAClC,SAAU,EAAK,SACf,SAAU,EAAK,SACf,UACA,mBAIE,GAAkB,KACpB,OAEF,GAAM,GAAa,GAAU,EAAgB,GACvC,EAAc,GAAQ,EAAW,MAAQ,EAAW,OAAQ,GAClE,MAAO,CACL,YAAa,EAAW,OACxB,WAAY,EAAW,MACvB,cACA,aACA,WACA,kBC7CG,GAAM,IAAuB,EAQvB,GAAuB,GAAK,EAG5B,GAAqB,GAuB5B,GAAc,CAClB,GAAI,CAAE,EAAG,GAAM,GAAI,EAAG,EAAI,GAC1B,GAAI,CAAE,EAAG,GAAK,GAAI,EAAG,GAAK,IAGtB,GAAY,CAChB,GAAI,CAAE,EAAG,GAAK,GAAI,EAAG,GAAK,GAC1B,GAAI,CAAE,EAAG,GAAK,GAAI,EAAG,GAAK,IAGtB,GAAc,CAClB,GAAI,CAAE,EAAG,EAAI,GAAI,EAAG,GAAK,GACzB,GAAI,CAAE,EAAG,GAAK,GAAI,EAAG,GAAK,IASrB,YAA0B,EAA+B,CAC9D,MAAO,IAAW,EAAK,KACnB,KAAK,IACH,EACE,GAAO,EAAK,WAAY,GAAK,EAAI,IACjC,GAEF,GAAO,GAAY,GAAI,GAAY,GAAI,EAAK,QAE9C,EAGC,YAAkC,EAAiB,CACxD,MAAO,GAAQ,GAAuB,GAAO,GAAM,EAAG,QAGjD,YAAgC,EAAiB,CACtD,MAAO,GAAQ,GAAS,GAAO,IAGjC,YAAkB,EAAgD,CAChE,MAAO,GAAQ,EAAK,OAAQ,KAAM,IAAU,EAC1C,QACA,IAAK,EAAK,IACV,WAAY,GAAW,EAAK,KACxB,KAAM,GAAQ,GAAY,GAAO,GAC/B,GAAO,EAAE,SAAU,GAAK,EAAI,IAE9B,UAUD,YAAsB,EAA8B,CACzD,MAAO,IACL,GAAU,GACV,GAAU,GACV,GAAM,GAAK,GAAI,IAAM,GAAI,EAAO,EAAO,KAIpC,YAAyB,EAAuB,CAErD,GAAM,GAAQ,GAAM,GAAM,GAAI,GAAK,GAAI,EAAK,OAKtC,EAAO,EAAI,EAIX,EAAQ,EAMR,EAAS,EAAI,EAAQ,GAErB,EAAa,AAAC,GAClB,GAAO,EAAE,GAAI,EAAE,GAAI,GAAM,GAAM,GAAI,GAAK,GAAI,IAExC,EAAU,EAAW,IAIrB,EACJ,AAHY,GAAS,EAAK,MAGnB,SAAS,GAAS,YAAc,GAAO,EAAW,IAAa,EAElE,EAAc,GAAiB,GAC/B,EAAa,EAAS,eAAe,eAAiB,EAAc,EAU1E,MAAO,CACL,OATa,GACb,GACA,GACA,KAAK,MACH,EAAO,EAAQ,EAAS,EAAU,EAAc,EAAc,IAMhE,OACA,QACA,SACA,UACA,cACA,cACA,cC3JJ,GAAM,IAAQ,GAAI,IAAoB,KAEtC,EAAM,IAAM,EAAa,IAAM,GAAM,UACrC,EAAM,IACJ,GAAa,CAAC,EAAK,IAAS,CAC1B,GAAM,SAAS,EAAK,IAAM,IAAI,KAAK,GACnC,GAAM,SAAS,EAAM,IAAM,IAAI,KAAK,MAIjC,YAAyB,EAAkC,CAChE,MAAO,CAAC,EAAI,WAAY,GAAG,EAAI,GAAM,IAAI,EAAI,cAGxC,YACL,EACA,EACA,EACG,CACH,OAAW,KAAM,IAAgB,GAAM,CACrC,GAAM,GAAQ,EAAM,IAAI,GACxB,GAAI,GAAS,KAAM,MAAO,GAE5B,GAAM,GAAS,EAAY,GAC3B,SAAM,IAAI,EAAI,WAAY,GACnB,EC/BF,GAAM,IAAI,GAAQ,OAAQ,QCGjC,GAAM,IAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,8CAgB+B,KAMvC,YACL,EAA6C,EAAS,YAAY,MAChD,CAClB,MAAO,GAAY,EAAiB,GAGlC,EAAU,IAAI,GAAI,KAAK,oBAIpB,YACL,EAA6C,EAAS,YAAY,MAChD,CAClB,MAAO,GAAY,EAAiB,GAClC,EAAU,IAAI,GAAI,KAAK,EAAS,aAAa,iBAqBjD,kBACE,EACoB,CACpB,GAAM,GAAU,GAAe,GAC/B,GAAI,GAAW,KACb,KAAM,IAAI,OAAM,iBAElB,GAAI,AAAS,KAAM,GAAQ,UAAvB,KACF,KAAM,IAAI,OAAM,oBAAsB,GAExC,KAAM,GAAQ,YACd,GAAM,GAAa,EAAQ,KAAK,cAChC,MAAK,MAAM,GAAW,SAAY,GAAO,QACvC,KAAM,GAAW,UAAU,IAEtB,EC7ET,GAAO,IAAgB,iBAwBvB,kBACE,EACA,EAA+B,GAC/B,CACA,MAAI,GAAQ,SAAW,MAAM,GAAQ,QAAU,IAC3C,EAAM,EAAQ,QAAQ,gBACxB,GAAQ,QAAQ,cAAgB,GAAU,KAAO,IAG5C,GAAI,SAAyB,CAAC,EAAS,IAAW,CACvD,GAAM,GAAM,GAAM,QAAQ,EAAI,WAAY,GAC1C,EAAI,WAAW,EAAO,EAAQ,QAAS,GAAe,IAAM,CAC1D,EACE,GAAI,IAAa,CACf,QAAS,qBAAuB,EAAM,IACtC,UAAW,GACX,UAAW,QAKjB,EACG,GAAG,WAAY,AAAC,GAA8B,CAC7C,GAAM,GAAkC,GACxC,EAAS,YAAY,QACrB,EAAS,GAAG,OAAQ,GAAS,EAAW,KAAK,IAC7C,EAAS,GAAG,MAAO,IAAM,CACvB,EAAQ,CACN,GAAI,GAAO,IAAK,IAAK,EAAS,YAC9B,QAAS,EAAS,QAClB,KAAM,EAAW,KAAK,IACtB,WAAY,EAAS,WACrB,cAAe,EAAS,oBAI7B,GAAG,QAAS,GAAK,CAChB,EAAO,KAGX,EAAI,EAAQ,KAAM,GAAM,EAAI,MAAM,IAClC,EAAI,QClER,OAAqC,mBAsB9B,GAAM,KAAI,EAQf,IACE,KAAK,MACH,GACE,0IAQD,YAAW,EAAW,CAC3B,MAAO,MAAK,MACV,4BAAqB,OAAO,KAAK,EAAG,WAAW,SAAS,SC3C5D,OAAqB,iBCArB,OAAyB,0BAKzB,GAAM,IAAS,EAAK,IAAM,EAAS,aAEnC,kBAAoC,EAA0C,CAC5E,GAAI,CAEF,MADU,MAAM,gBAAS,SAElB,EAAP,CACA,KAAS,KAAK,kBAAoB,EAAa,IAAK,GACpD,QCDG,YAAyC,CAC9C,YACW,EACA,EACA,EACT,CAHS,YACA,gBACA,eAGM,WAAQ,EAAK,IAAM,KAAK,KAAK,SAAY,eAEpD,OAAwB,CAC5B,GAAM,GAAQ,KAAM,MAAK,QAEzB,MADA,GAAS,iBAAiB,MAAM,SAAW,KAAK,KAAM,GAClD,GAGK,EAAQ,KAAK,WAAY,GAAK,KAAK,MAAM,SAI9C,OAAM,EAAkB,CAC5B,GAAI,CACF,YAAM,MAAK,KAAK,WAAW,EAAG,CAAE,OAAQ,IACxC,KAAM,MAAK,MAAM,IAAI,QAAQ,QAAQ,IACrC,EAAS,iBAAiB,KAAK,YAAc,KAAK,KAAM,GACpD,KAAK,SAAW,MAClB,KAAM,MAAK,QAAQ,KAAK,KAAM,GAEzB,QACA,EAAP,CACA,KAAM,IAAI,IAAa,CACrB,MAAO,EACP,QAAS,sBAAwB,KAAK,UCxBvC,aAAiB,CACtB,MAAO,IAAW,cAAc,GAAI,GAiB/B,oBAAuB,GAAuB,CACnD,YAAqB,EAA6B,EAAuB,CAEvE,MACE,EAAQ,KAAK,IAAM,EAAO,aAC1B,IAAO,EACL,IAAK,KACL,WACA,KAAM,KAAK,KACX,UAAW,KAAK,QAElB,GAAK,EAAE,QAVU,eAA6B,YAczC,WAAQ,EAAK,IACpB,GACE,KAAK,OACL,GAAM,EAAG,IACT,IAAM,YACN,MAAM,GAAS,CACf,KAAM,IAAI,IAAa,CACrB,QACA,MAAO,GACP,QAAS,kBAAoB,KAAK,eAc7B,GAAkB,EAAK,IAClC,EAAI,KAAkB,GAAW,GAAI,IAAS,EAAS,aAGzD,EAAM,IAAM,CACV,EAAa,IAAM,CAEjB,GAAgB,UAElB,EAAS,YAAY,YAAY,IAAM,GAAgB,WCpFzD,OAAkC,iBASlC,GAAM,IAAU,qBAEH,GAAO,EAAK,IACvB,EACE,GACE,GAAO,4BAAqB,IAAI,GAAO,EAAI,GAAK,IAAI,GAAM,EAAG,OAC7D,OAAO,GAAM,EAAS,IAAO,GAAQ,KAAK,IAAO,QCkBvD,GAAM,IAAI,EAUP,IACD,GACE,iJAqBS,GAAI,GAAQ,KAAM,KAAM,KAAM,KAAM,KAAM,KAAM,KAAM,KAAM,MAGlE,YAAkB,EAAgB,CACvC,MAAO,IAAO,EAAK,EAAK,OAAO,KAAc,GAAM,CACjD,GAAE,QAAQ,EAAG,MAAM,KAAK,IACxB,IAIG,YAAuB,EAAsB,CAClD,MAAO,MAAI,GAGN,GAAM,IAAY,GAEzB,kBACE,EACA,EACsB,CACtB,GAAI,CACF,GAAM,GAAM,EAAI,KAAM,IACtB,MAAO,GAAM,IAAQ,EAAI,MAAM,kBAAoB,KAC/C,OACA,EAAM,IAAM,GAAe,EAAI,OAAQ,GAAW,UAC/C,EAAP,CACA,EAAS,SAAS,KAAK,SAAU,CAAE,MAAK,QACxC,QAIJ,GAAM,IAAQ,EACZ,IAAM,GAAI,QAAO,KAAK,GAAE,OAAO,KAAK,qBAAqB,SAGpD,YAAoB,EAAW,CACpC,MAAO,IAAK,MAAQ,KAAQ,KAAK,IAAM,KL/DlC,GAAM,IAAI,EAQd,IACD,GACE,yPAIE,GAAS,EAAK,IAAM,EAAS,KAAI,IAEvC,mBAA2B,CACzB,MAAO,IAAM,GAAE,GAAI,KAAM,OAAmB,SAG9C,aAAsB,CACpB,MAAO,IAAM,GAAE,GAAI,cAAO,GAAG,OAG/B,aAAyB,CACvB,MAAO,MAAO,IAAI,GAAM,GAAM,GAAE,GAAI,IAGtC,mBAA2B,CACzB,MAAO,GAAI,KAAM,OAAW,IAAI,GAAK,GAAM,GAAE,GAAI,EAAE,OAGrD,mBAA8B,CAC5B,GAAM,GAAM,KAAM,IAAO,KAAI,EAAG,CAAC,MAAO,CAAE,QAAS,EAAI,IACvD,MAAO,MAAS,IAAI,CAClB,IAAK,KAAI,EACT,OAAQ,EAAI,MAAM,mCAAmC,KAIzD,mBAA4B,CAC1B,GAAI,CACF,MAAO,GAAY,KAAM,MAAgB,GAEvC,GAAM,GAAE,GAAI,EAAK,IAAM,cAAO,GAAG,cAE5B,EAAP,CACA,KAAS,KAAK,KAAI,EAAI,UAAW,GACjC,QAIJ,mBAA0B,CACxB,GAAI,CACF,GAAM,GAAK,KAAM,MACjB,MAAO,IAAM,GAAE,GAAI,SACZ,EAAP,CACA,KAAS,KAAK,eAAgB,GAC9B,QAIJ,mBAAqC,CAMnC,MADW,AAJC,MAAM,IAAO,KAAI,EAAG,KAAI,GAAI,CACtC,QAAS,EAAI,KAGA,MAAM,iCAAiC,GAIxD,mBAAkC,CAChC,MAAQ,MAAM,IAAW,WAAW,YAAY,KAAI,KAAK,YAE3D,mBAA0B,CACxB,GAAM,GAAM,KAAM,MAClB,MAAO,IAAM,GAAE,GAAI,GAGrB,GAAM,IAAa,EAAK,SAClB,KACK,GAGA,GACA,CACL,GAAM,GAAE,GAAI,GAAc,KAAI,KAC9B,GAAM,GAAE,GAAI,GAAc,KAAI,KAC9B,MAEO,GACF,CAAC,MACC,EACF,CAAC,MAED,IAIX,mBAA6B,CAC3B,GAAM,GAAM,KAAM,SAAQ,IACxB,CAAC,GAAW,GAAY,GAAW,GAAe,IAAY,IAC5D,KAAM,IAAM,CACV,GAAI,CAEF,MAAO,MAAM,IAAc,IAAM,EAAI,SAC9B,EAAP,CACA,MAAO,MAAS,KAAK,OAK7B,MAAO,IAAS,EAAK,KAAM,IAAY,KM3IlC,YAAiC,CAMtC,YACW,EACA,EACA,EACT,EACA,CAJS,SACA,UACA,aAGT,KAAK,KAAO,CAAE,UAGZ,IAAI,CACN,MAAO,MAAK,MAGV,KAAK,CACP,GAAI,KAAK,IAAM,KACb,MAAO,GACT,GAAM,GAAc,GAAa,KAAK,MAAO,KAAK,GAAG,MAC/C,EAAwB,EAAK,EAAY,IAAI,GAAM,EAAG,MAAM,KAAK,KACjE,EAAiB,EACrB,EAAsB,IAAI,GAAM,GAAc,KAE1C,EAAS,EAAe,QAAU,KAAK,GAAG,IAC1C,EAAS,GACb,KAAK,GAAG,KAAK,UACb,KAAK,GAAG,KAAK,UAAY,GACzB,KAAK,OAGP,YAAK,KAAK,KAAI,GAAK,EACnB,KAAK,KAAK,KAAI,GAAK,EACnB,KAAK,KAAK,KAAI,GAAK,EAWZ,GAAU,EAGnB,QAAS,CACP,MAAO,CACL,KAAK,GACL,CAAC,GAAE,QAAQ,KAAK,IAAI,KAAI,IACxB,KAAK,GAAG,KAAK,WAAa,EAC1B,KAAK,KAAK,gBAOd,IAAI,EAAM,CACR,MAAO,IAAI,KAAK,SAAU,EAAE,YChEhC,GAAM,IAAS,EAAK,IAAM,EAAS,iBAMnC,kBAAmC,EAAa,CAE9C,GAAM,GAAK,KAAM,IAAI,EAAK,aAC1B,GAAI,GAAM,KACR,MAAO,MAAS,MAAM,MAAO,GAI/B,KAAM,IAAa,EAAI,MAAkB,KAAK,KAAI,IAClD,KAAM,IAAa,EAAI,GAAS,IAAI,MAAY,KAAK,KAAI,IAEzD,GAAE,QAGJ,kBAA0C,EAA6B,CACrE,MACE,MAAM,IAAY,EAAI,aAAc,KAAM,IACxC,GAAK,MAAM,GAAG,aAAa,WAAW,OAAQ,EAAG,cAEnD,OAAO,GAAM,EAAG,IAAM,YAAc,KAGxC,kBAAmC,EAAO,EAAsB,CAC9D,GAAI,GAAO,KAAM,OAEjB,GAAI,AADU,MAAM,IAAoB,IAC9B,KAAK,GAAM,EAAG,IAAI,IAAO,GAAI,CACrC,KAAS,KAAK,6BAA+B,GAC7C,WACK,CACL,GAAM,GAAI,EAAI,KAAK,GAAe,EAAG,GAAK,QAC1C,MAAO,MAAM,GACV,WAAW,EAAG,GACd,KAAK,IACJ,MAAS,KAAK,4BAA8B,GACrC,IAER,MAAM,GAAO,CACZ,KAAS,MAAM,6CAA+C,EAAK,MCtC3E,GAAM,IAAS,EAAK,IAAM,EAAS,KAAI,IAkBjC,GAAI,EAOP,IACD,GACE,qKAiBS,GAAI,EAAK,SAAY,CAChC,GAAM,GAAM,KAAI,EAAI,KACpB,GAAI,CACF,GAAI,CAAC,EAAS,KAAI,GAAG,eACnB,MAAO,MAAS,MAAM,EAAM,6BAG9B,GAAM,GAAO,MAAM,OAAK,OAAO,GAAM,EAAG,GAAK,MAAQ,EAAS,EAAG,IAC3D,EAAM,GAAI,MAGV,EAAU,EAAI,KAAK,GAAM,EAAG,IAAM,EAAM,EAAG,EAAG,KACpD,GAAI,GAAW,KACb,MAAO,MAAS,MAAM,EAAM,UAAW,GAEzC,GAAM,GAAM,KAAM,IAAS,IAAI,MAAY,KAAK,KAAI,GAAG,UACvD,OAAW,KAAO,GAAK,CAErB,GAAI,EAAM,EAAI,IAAM,EAAI,GAAK,MAAQ,EAAM,EAAI,EAAG,IAAK,SACvD,GAAM,GAAI,EAAI,EAAE,KAAK,KAAK,GAAM,EAAG,WAAW,QAC9C,GAAI,GAAK,KAAM,CACb,KAAS,MAAM,EAAM,mBAAoB,GACzC,SAEF,KAAM,GACH,KAAK,GAAiB,EAAI,EAAG,IAAM,QACnC,cAAc,KAAM,IAAQ,CAC3B,KAAM,IAAE,GACR,KAAM,GAAK,WAAW,CAAE,EAAG,EAAI,EAAG,GAAI,KAAK,QAC3C,KAAS,KAAK,EAAM,YAAa,YAGhC,EAAP,CACA,KAAS,KAAK,EAAM,SAAU,KAE/B,GAAK,GAMR,kBAAiB,EAAc,CAC7B,GAAI,CACF,GAAM,GAAO,KAAM,MACnB,GAAI,EAAQ,GACV,MAAO,MAAS,KAAK,qBAIvB,GAAM,GAAO,EAAU,CAAE,KAAM,CAAC,GAAG,EAAM,KACnC,EAAM,OAEP,KAAI,GAFG,CAGV,SAEI,EAAW,KAAM,IAAQ,KAAI,EAAG,GACtC,KAAS,KAAK,KAAI,EAAG,CAAE,MAAK,aAC5B,AAAI,EAAS,GAGX,KAAM,IAAa,KAAK,MAAM,EAAS,QAAQ,KAAI,IAEnD,KAAS,KAAK,KAAI,EAAG,CAAE,MAAK,mBAEvB,EAAP,CACA,KAAS,KAAK,KAAI,EAAG,IC7HzB,OAAmB,QAwBZ,GAAM,IAAI,EAUf,IACE,GACE,qPAKO,IAAI,EAAK,IAAM,CAC1B,GAAI,CAEF,MAAO,AADW,AAAR,SAAQ,KAAI,GACb,KAAI,GAAG,KAAI,SACb,EAAP,CACA,EAAQ,KAAI,EAAI,GAAgB,MAO7B,YAAW,EAAW,CAC3B,MAAO,OAAG,KAAI,GAAG,EAAG,KAAI,GCKnB,GAAM,IAAI,EAmBd,IACD,GACE,yNAIE,GAAS,EAAK,IAAM,EAAS,KAAI,IAYvC,kBAAyB,EAAoB,CAC3C,GAAM,GAAK,KAAM,IAAE,GAAa,EAAI,GAAK,OAAQ,KAAI,IAC/C,EAAM,GAAW,EAAE,KAAI,IAC7B,GAAI,GAAO,KACT,KAAM,IAAI,OAAM,OAAS,KAAI,EAAI,KAAO,EAAE,KAAI,GAAK,KAAO,EAAM,KAElE,GAAM,GAAM,GAAW,EAAE,KAAI,IAC7B,GAAI,GAAO,KACT,KAAM,IAAI,OAAM,OAAS,KAAI,EAAI,KAAO,EAAE,KAAI,GAAK,KAAO,EAAM,KAGlE,SAAE,KAAI,GAAK,EAAE,KAAI,IAAM,EAAI,EAAE,KAAI,GAAK,EACtC,EAAE,KAAI,GAAK,GAAI,MAAK,GACpB,EAAE,KAAI,GAAK,GAAI,MAAK,GACpB,EAAE,KAAI,GAAK,EAAI,EAAE,MAAM,MAAM,KACtB,EAgBT,kBAAwB,EAAa,EAAyC,CAC5E,GAAI,CACF,MAAO,IAAI,IAAE,EAAK,KAAM,IAAG,GAAM,KAAM,MAAQ,SACxC,EAAP,CACA,MAAO,MAAS,IAAI,CAClB,IAAK,KAAI,EACT,OAAQ,CACN,EAAG,EACH,GAAI,GACJ,KAAM,CAAE,WAShB,kBAA0B,EAAoB,EAA8B,CAC1E,GAAI,EAAM,GAAM,OAChB,GAAM,GAAK,KAAM,IAAE,EAAK,GACxB,MAAO,GAAO,GAAI,KAAO,YAAc,IAAI,EAAK,OAS3C,GAAM,IAAI,EAAK,SAAY,CAGhC,GAAM,GAAU,EAAQ,CACtB,MAAkB,KAAK,KAAI,GAC3B,GAAS,IAAI,MAAY,KAAK,KAAI,KAG9B,EAAQ,GAAQ,KAAM,IAAS,EAAS,GAAO,EAAI,eAKnD,EAAM,GACV,KAAM,IAAS,EAAO,KAAM,IAC1B,EACE,EAAI,KAAM,GAAI,aACX,IAAI,GAAM,EAAG,QACb,KAAK,IACR,GAAM,GAAE,EAAI,EAAI,eAItB,KAAM,GAAY,EAAS,KAAI,GAAG,MAAO,KAAM,IAC7C,EAAI,KAAK,KAAM,IAAE,EAAI,cAGvB,GAAM,GAAS,GAAG,GAGlB,SAAM,IAEC,KAAS,IAAI,CAClB,IAAK,KAAI,EAAI,KACb,aAOJ,kBAAyB,EAAsB,CAC7C,MAAO,IAAO,EAAK,GAAM,CACvB,CAAC,EAAG,GACJ,GAAE,QAAQ,EAAG,IAAI,KAAI,IACrB,CAAE,GAAG,GAAG,KAAK,WAAa,KAgB9B,EAEE,IAAO,GAAE,KAAI,GAAM,IAAM,MAMpB,aAAa,CAClB,MAAO,GAAQ,KAAK,GAAQ,EAAI,IAAI,GAAK,EAAI,GAAK,QAMpD,mBAA0B,CACxB,MAAO,IAAQ,MACZ,QAAQ,GAAM,EAAG,IAAI,KAAI,IACzB,UAAU,IAAM,KAAI,GAMzB,mBAA0B,CACxB,GAAI,CACF,MAAQ,MAAM,QAAS,KAAI,OAC3B,CACA,MAAO,ICvOX,GAAM,IAAU,EAAQ,MAAQ,YAE1B,GAAS,EAAK,IAAM,EAAS,aAKnC,kBAAgC,EAA+B,CAC7D,GAAM,GAAM,KAAM,MAClB,GAAI,CACF,KAAM,IAAa,EAAK,CAAC,WAAY,GAAS,EAAI,YAAa,CAC7D,QAAS,GAAK,EACd,iBAAkB,WAEb,EAAP,CACA,KAAM,IAAI,IAAa,CACrB,QACA,UAAW,GACX,MAAO,GACP,UAAW,MAQjB,kBACE,EACA,EACe,CACf,GAAM,GAAO,EAAI,MACjB,KAAS,KAAK,iBAAmB,EAAM,IAAK,GAC5C,KAAM,IAAO,EAAK,EAAM,GACxB,KAAM,GAAK,SACX,GAAgB,EAAI,YAOtB,kBACE,EACA,EACA,EACe,CACf,GAAM,GAAM,KAAM,MAClB,GAAI,CAAC,GAAW,GACd,KAAM,IAAI,OAAM,sBAAwB,EAAM,KAAO,EAAU,KAEjE,KAAM,IACJ,EACA,CACE,QACA,MACA,QACA,UACA,EAAQ,QAAQ,GAChB,WACA,EAAK,WACL,EAAI,YAEN,CAAE,QAAS,IC3ER,GAAM,IAAgB,uDAEtB,QAAkB,CACvB,YAAqB,EAAyB,CAAzB,yBAGhB,YAA6B,EAA0B,CAC5D,GAAI,MAAO,IAAM,SAAU,OAC3B,GAAM,GAAI,EAAE,MAAM,IAClB,MAAO,IAAK,KACR,OACA,GAAI,IAAY,EAAM,EAAE,GAAI,CAAE,aAAc,KCVlD,GAAM,IAA0B,CAC9B,YACA,aACA,cACA,YACA,aACA,cAGK,YAAyB,EAAkC,CAChE,MAAO,IAAwB,SAAS,EAAI,GAAU,eAGxD,GAAM,IAA2B,GAAI,KAAI,CAGvC,oBACA,oBAEA,oBACA,oBACA,mBACA,uBACA,oBACA,oBACA,oBACA,sBACA,oBACA,oBACA,sBACA,wBACA,wBACA,qBACA,sBACA,oBACA,mBACA,mBACA,qBAGK,YAA0B,EAAkC,CACjE,MAAO,IAAyB,IAAI,EAAI,GAAU,eC7B7C,YAAgB,EAAiB,EAAiB,CACvD,MAAO,IAAG,EAAI,MAAO,EAAI,QAAU,GAAG,EAAI,OAAQ,EAAI,QAMjD,YAAiB,EAAiB,EAAiB,CACxD,MAAO,IAAI,EAAI,MAAO,EAAI,QAAU,GAAI,EAAI,OAAQ,EAAI,QClBnD,YAAoB,EAA2C,CACpE,MAAO,GAAQ,GAAS,EAAK,YAAa,GAAO,EAC/C,MAAO,EAAG,WACV,OAAQ,EAAG,eCKf,GAAM,IAAS,EAAK,IAAM,EAAS,gBAEnC,EAAM,IAAM,EAAa,IAAM,GAAgB,UAExC,GAAM,IAAkB,EAAK,SAClC,GAAO,EAAS,gBAAgB,iBAGlC,mBAA+C,CAC7C,GAAM,GAAI,KAAM,MAChB,MAAO,MAAS,IAAI,CAClB,IAAK,2BACL,OAAQ,EAAS,GACjB,KAAM,CAAE,gBAAiB,KAQ7B,kBAAgC,EAAyC,CACvE,GAAI,EAAE,KAAM,MACZ,MAAO,GAAQ,GAAc,EAAK,OAAQ,SAAU,GAClD,EAAK,cAAc,KAAM,IAAO,CAC9B,GAAI,CACF,KAAM,IACJ,EAAS,gBAAgB,eACzB,CACE,KACA,OAAO,EAAS,YAAY,gBAC5B,EAAI,WACJ,EAAI,YAEN,CACE,QAAS,UAGN,EAAP,CACA,KAAS,KACP,kCACE,EACA,OACA,EAAI,WACJ,KACA,GAEJ,WClDR,GAAM,IAAS,EAAK,IAAM,EAAS,SAItB,GAAW,EAAK,SAAY,CACvC,GAAI,CACF,MAAO,MAAM,IAAO,UAAW,CAAC,KAAM,QAAS,CAC7C,QAAS,WAEJ,EAAP,CACA,GAAM,GAAI,GAAS,IAAI,iBACvB,GAAI,KAAM,GAAE,eACV,MAAO,GAAE,WAET,KAAS,KAAK,6BAA8B,GAC5C,UAON,kBAAgC,EAAyC,CACvE,MAAO,GAAQ,GAAc,EAAK,OAAQ,SAAU,GAClD,EAAK,cAAc,KAAM,IAAO,CAC9B,GAAI,CACF,KAAM,IACJ,OACA,CACE,KACA,SACA,OACA,KACA,gBACA,OAAO,EAAS,YAAY,gBAC5B,EAAI,WACJ,QACA,EAAI,YAEN,CACE,QAAS,UAGN,EAAP,CACA,KAAS,KACP,6BACE,EACA,OACA,EAAI,WACJ,KACA,GAEJ,WCnDR,GAAM,IAAS,EAAK,IAAM,EAAS,SAEtB,GAAwB,EAA2B,SAAY,CAC1E,GAAI,CACF,GAAI,GACF,GAAI,CACF,GAAM,GAAM,KAAM,MAClB,GAAI,CAAC,EAAM,GACT,MAAO,CAAE,GAAI,GAAM,aAEd,EAAP,CACA,KAAS,MACP,6DACA,GAKN,GAAM,GAAO,KAAM,MAEnB,MAAO,CACL,GAAI,EAAS,GACb,IAAK,GACH,EACA,EAAS,gBAAgB,eAAiB,0BAGvC,EAAP,CACA,MAAO,CACL,GAAI,GACJ,IAAK,GAAmB,OAK9B,mBAAwC,CACtC,MAAQ,MAAM,OAAyB,GAGzC,EAAM,IAAM,EAAa,IAAM,GAAsB,UCjDrD,GAAM,IAAiB,oBAEhB,YAAwB,EAAkB,CAC/C,MAAO,IAAe,KAAK,EAAI,KAAc,KCM/C,kBACE,EACA,EACA,EACA,EAAY,IACM,CAClB,GAAM,GAAQ,KAAM,IAAU,IAAM,EAAW,EAAG,UAAU,IAAS,CACnE,cAEF,MAAI,IAAO,EAAG,KAAK,EAAO,GACnB,ECpBT,OAAwB,mBCCjB,YAAmB,EAAmB,EAAiB,CAC5D,GAAM,GAAmB,EAAM,MAAQ,EAAM,OACvC,EAAiB,EAAI,MAAQ,EAAI,OAEvC,GAAI,GAAoB,EAAgB,CAEtC,GAAM,GAAQ,KAAK,IAAI,EAAI,MAAO,EAAM,OACxC,MAAO,CACL,QACA,OAAQ,KAAK,KAAK,EAAQ,QAEvB,CAEL,GAAM,GAAS,KAAK,IAAI,EAAI,OAAQ,EAAM,QAC1C,MAAO,CAAE,MAAO,KAAK,KAAK,EAAI,OAAS,GAAmB,WCbvD,GAAM,IAAe,GAAQ,MAAO,MCSpC,GAAM,IAAY,GACvB,QACA,UACA,OACA,SACA,WAiBe,GAAV,UAAU,EAAV,CACL,GAAM,GAAS,EAAK,IAAM,EAAS,oBAC5B,AAAM,OAAO,GAAa,GACpB,MAAM,QACZ,WACL,EACA,EACmB,CACnB,GAAM,GAAS,AAAC,GAAQ,EAAK,GAEzB,OACK,GADL,CAEE,IAAK,GAAU,QAHjB,OAMJ,MAAO,KAAS,IAAI,CAClB,IAAK,WACL,SACA,KAAM,CACJ,MACA,WAhBC,EAAS,WAJD,aA+CV,GAAU,IAAV,UAAU,EAAV,CACL,GAAM,GAAS,EAAK,IAAM,EAAS,iBAE5B,AAAM,OAAO,GAAa,IACpB,MAAM,SACZ,WACL,EACA,EACmB,CAEnB,GAAI,GAAO,EAAO,GAAM,CACtB,IAAS,MACP,mBAAmB,GAAO,uBAA2B,GAAO,MAE9D,OAEF,MAAO,IAAU,EAAO,GAXnB,EAAS,WALD,aHjFjB,GAAO,KAAiB,iBAsFjB,QAAgB,CA2Fb,YACG,EACA,EACA,EACA,EACA,EAAa,GACtB,CALS,YACA,gBACA,iBACA,eACA,kBAmBF,gBAAa,EAAK,IAAM,GAAW,KAAK,SAAW,KAAK,YAjB/D,KAAK,IAAM,CAAE,MAAO,EAAU,OAAQ,GACtC,GAAU,OAAO,KAAK,YAhGjB,KAAK,CACV,MAAO,MAAK,OAAO,OAAO,GAAM,EAAG,UAAY,UAE1C,YAAY,CACjB,MAAO,IAAW,KAAK,KAAM,GAAM,EAAG,oBAEjC,MAAM,CACX,GAAM,GAAM,EAAS,mBAAmB,eACxC,MAAO,MAAK,OAAO,OAAO,GAAM,EAAG,UAAY,IAAO,EAAI,SAAS,EAAG,aAEjE,aAAa,CAClB,MAAO,IAAW,KAAK,MAAO,GAAM,EAAG,eAwFxC,WAAQ,SAAU,CACjB,MAAO,CACL,KAAM,YACN,KAAM,KAAK,KAAO,KAAO,KAAK,QAAQ,KAAO,IAC7C,OAAQ,KAAK,SAAW,OAAM,KAAK,UACnC,MAAO,KAAK,iBAIZ,eAAe,CACjB,MAAO,MAAK,IAAI,KAAK,SAAU,KAAK,WAKtC,WAAW,EAA0C,CACnD,MAAO,MAAK,QAAQ,OAClB,KAAK,YAAc,GAAW,GAAa,GAAK,KAAK,KAAO,KAAK,IACjE,GAIJ,OAAO,EAAwB,EAA+B,CAE5D,SAAK,EAAU,OAAO,OACjB,GADiB,CAEpB,IAAK,KAAK,QAAQ,IAClB,mBAAoB,MAGf,EAGT,OAAO,CACL,OACA,KACA,cAKC,CAKD,MAAI,CADO,GAAY,GACd,GAAK,EAAS,QAAQ,iBAC7B,GAAK,EAAG,WAEH,EACJ,KAAK,CACJ,QAAS,EAAS,YAAY,eAC9B,YAAa,EAAS,YAAY,iBAEnC,OAAO,GAGZ,UAAW,CACT,MAAO,MAAK,OAhKT,MACmB,AADnB,GACmB,OAAsB,GAqC9B,AAtCX,GAsCW,MAAQ,GAAI,IAAU,QAAS,KAAM,KAAM,GAAK,IAChD,AAvCX,GAuCW,MAAQ,GAAI,IAAU,QAAS,KAAM,KAAM,GAAK,IAGhD,AA1CX,GA0CW,IAAM,GAAI,IAAU,QAAS,KAAM,KAAM,IAGzC,AA7CX,GA6CW,IAAM,GAAI,IAAU,MAAO,KAAM,KAAM,IAIvC,AAjDX,GAiDW,IAAM,GAAI,IAAU,MAAO,KAAM,KAAM,IAOvC,AAxDX,GAwDW,GAAK,GAAI,IAAU,KAAM,KAAM,IAAK,IAIpC,AA5DX,GA4DW,KAAO,GAAI,IAAU,OAAQ,IAAK,IAAK,IAGvC,AA/DX,GA+DW,KAAO,GAAI,IAAU,OAAQ,IAAK,IAAK,IAGvC,AAlEX,GAkEW,MAAQ,GAAI,IAAU,QAAS,IAAK,IAAK,IAczC,AAhFX,GAgFW,KAAO,GAAI,IAAU,OAAQ,IAAK,IAAK,IACvC,AAjFX,GAiFW,KAAO,GAAI,IAAU,OAAQ,IAAK,IAAK,IACvC,AAlFX,GAkFW,KAAO,GAAI,IAAU,OAAQ,IAAK,IAAK,IACvC,AAnFX,GAmFW,IAAM,GAAI,IAAU,MAAO,GAAI,GAAI,IIrJrD,GAAM,IAAS,EAAS,UAexB,GAAM,IAAa,CAAC,MACd,GAAgB,CAAC,KAAM,KAEvB,GAAa,CAAC,KAAM,KAGpB,GAAoB,CAAC,KAAM,IAAK,MAGtC,kBAAgC,EAAmC,CACjE,GAAM,GAAQ,KAAK,MAEb,EAAS,KAAM,IAAW,GAChC,GAAI,GAAU,KACZ,MAAO,IAAO,MACZ,qBACE,EACA,wBACA,GACA,IAIN,GAAM,GAAS,GAAU,aAAa,WAAW,GAE3C,EAA0B,GAEhC,AAAI,GAAU,MAAQ,EAAI,GAAY,GAAU,GAAY,IAC1D,IAAO,MAAM,mCACb,EAAc,KAAK,OAGrB,GAAM,GAAM,KAAM,MACZ,EAAO,CACX,GAAG,GACH,GAAG,GACH,GAAG,GACH,GAAG,EACH,GAAG,GACH,GAAG,EAAS,aAAa,OACzB,EAAI,YAEA,EAAU,EAAI,EACd,EAAO,CACX,SAAU,SACV,UACA,UAAW,IAAM,IAEnB,GAAO,MAAM,cAAe,CAAE,MAAK,OAAM,SACzC,GAAM,GAAY,KAAM,IAAS,EAAK,EAAM,EAAS,GAC/C,EAAQ,KAAO,IAAa,CAChC,AACI,KAAM,IACN,EAAU,OACV,QACA,gBAAkB,EAAM,KAAO,GAAW,EAAK,EAAI,cAGrD,GAAO,MAAM,uCAAyC,EAAK,GAE7D,EAAU,KAAK,WAEjB,EAAU,GAAG,QAAS,GACtB,EAAU,OAAQ,GAAG,OAAQ,GAG7B,GAAM,GAAoB,GAAa,KAAM,GAAI,QAAU,EAErD,EAAM,GAAI,IACd,CAAE,KAAM,EAAI,WAAY,GAAI,wBAC5B,EACA,IAAM,KAAK,MAAQ,GAGrB,SAAU,GAAG,QAAS,IAAM,EAAI,OAEzB,EAAU,OC9GnB,GAAO,IAAgB,iBAgCjB,GAAS,EAAS,iBAWxB,kBACE,EACA,EACA,EACA,EACyB,CACzB,GAAM,GAAM,IAAO,GACnB,GAAI,CAAE,aAAe,KAAc,OAGnC,GAAM,GAAW,EAAO,MAAQ,EAAO,OAAS,GAChD,GAAI,EAAI,iBAAmB,MAAQ,EAAI,gBAAkB,EAAU,CACjE,GAAO,MAAM,wCAA0C,EAAK,CAC1D,WACA,QAEF,OAGF,GAAM,GAAM,KAAM,IAAsB,EAAK,GACvC,EAAM,KAAM,GAAI,EAAK,IAG3B,MAAO,IAAO,IAAI,CAChB,IAAK,gBACL,KAAM,CACJ,IAAK,EAAI,oBACT,MACA,MACA,UAEF,OAAQ,GAAO,MAAQ,GAAO,EAAQ,GAAO,EAAM,SAMvD,GAAM,IAAa,EAAK,IAAM,CAC5B,GAAM,KAAK,EAAS,WAAW,gBAC/B,GAAM,MAAM,EAAS,gBAAgB,gBACrC,GAAM,YAAY,QAMb,YACL,EACA,EACA,EAAiB,GACQ,CACzB,MAAO,IAAK,oBAAoB,EAAI,IAAI,gBAAiB,IACvD,GAAe,EAAK,EAAQ,IAIhC,kBACE,EACA,EACA,EAAiB,GACQ,CACzB,KAEA,GAAM,GAAI,KAAM,IAAY,EADJ,CAAC,GAEnB,EAAK,GAAG,SACd,GAAI,GAAK,MAAQ,EAAM,GACrB,KAAM,IAAI,OAAM,EAAM,wCAExB,GAAI,GAAe,IAAO,CAAE,KAAM,MAAoB,CACpD,GAAO,KAAK,0DAA2D,CACrE,IAAK,EAAI,WACT,SAAU,EACV,WAEF,OAEF,GAAI,GAAgB,IAAO,CAAE,KAAM,MAAqB,CACtD,GAAO,KAAK,4DAA6D,CACvE,IAAK,EAAI,WACT,SAAU,EACV,WAEF,OAGF,GAAM,GAAsC,GAKtC,EAAM,GAAgB,GACtB,EAAK,GACT,EACA,EACA,GAAiB,GAAM,KAAM,IAAQ,GAAO,QAE9C,GAAI,GAAM,KAAM,CACd,GAAM,GAAM,EAAO,EAAQ,CACzB,MAAO,EAAG,WAAW,MAAQ,IAC7B,OAAQ,EAAG,WAAW,OAAS,MAIjC,GACE,AAHoB,GAAY,GAGhB,IACf,IAAkB,GAAO,MAAQ,IAAQ,IAC1C,CAAC,GAAgB,GACjB,CACA,GAAM,GAAgB,EAAS,iBAAiB,eAChD,AAAI,GAAU,MAAQ,GAAY,GAAU,GAC1C,EAAc,QAAQ,GAAG,EAAS,mBAAmB,QAEvD,EAAW,KACT,GAAG,EAAc,IAAI,GAAM,IAAM,GAAY,EAAK,EAAG,EAAW,MAKtE,AAAI,GAAe,IACb,KACF,EAAW,KAAK,IAAM,GAAU,IAElC,EAAW,KAAK,IAAM,GAAU,KAG9B,GAAgB,IAClB,EAAW,KAAK,SAAY,GAG1B,GAAM,MAAQ,GAAiB,IACjC,EAAW,KAAK,IACd,IAAO,KAAK,6BAA8B,CACxC,IAAK,EAAI,WACT,WAEK,GAAe,CACpB,MACA,KAAM,QACN,OAAQ,QACR,EAAG,IAAM,GAAU,OAKrB,EAAG,WAAW,WAChB,EAAW,KAAK,IACd,GAAc,IAAM,GAAkB,EAAK,GAAK,CAAE,WAAY,KAIlE,GAAM,GAAgB,GAChB,EAAS,KAAM,IAA4B,EAAY,GAAO,CAClE,GAAO,KAAK,uBAAyB,EAAM,KAAO,GAClD,EAAK,KAAK,KAEZ,GAAI,GAAU,KACZ,KAAM,GAAO,EAAK,GAAI,GAAI,OAAM,eAAiB,EAAM,KAAO,EAAK,MAEnE,MAAO,GAQJ,YACL,EACA,EACyB,CACzB,GAAM,GAAS,EAAI,cAAc,SAAS,QAAU,QAAU,OAC9D,MAAO,GAAQ,GAAc,EAAK,EAAK,GAAS,GAC9C,EAAK,cAAc,KAAM,IAAO,CAC9B,GAAI,CACF,MAAO,MAAM,IAAiB,EAAK,EAAI,WAAY,EAAI,kBAChD,EAAP,CACA,GAAO,KACL,8BACE,EACA,SACA,EAAI,WACJ,KACA,GAEJ,WChNR,GAAO,IAAgB,iBAEjB,GAAS,EAAK,IAAM,EAAS,cAE7B,GAAQ,EAAK,IAAM,GAAI,IAAyB,KAAM,IAE5D,EAAM,IAAM,EAAa,IAAM,GAAM,SAAS,UAE9C,EAAM,IACJ,GAAc,GACZ,EAAI,GACD,QAAQ,GAAM,CACb,GAAM,SAAS,OAAO,KAEvB,OAAO,IAAM,CACZ,GAAM,SAAS,YAKvB,GAAM,IAA2B,EAAK,IACpC,GAAa,EAAS,yBAAyB,OAAQ,MAGlD,YAAoC,EAAU,CACnD,MAAO,MAAS,IAAI,CAClB,IAAK,6BACL,OAAQ,KAA2B,KAAK,GAAS,KAAS,OAe9D,kBAAgC,EAA+C,CAC7E,GAEG,KAAM,OAEN,CAAC,EAAS,mBAAmB,gBAC5B,CAAC,EAAS,eAAe,eAC3B,CACA,KAAS,MAAM,qBAAuB,EAAY,CAChD,mBAAoB,EAAS,mBAAmB,eAChD,eAAgB,EAAS,eAAe,iBAE1C,OAEF,MAAO,IAAqB,EAAY,GAAY,MAGtD,kBAA0B,EAAgC,CACxD,GAAM,GAAM,EAAU,IAAI,GAG1B,GAAI,CACF,GAAM,GAAK,KAAM,IAAS,GAC1B,GAAI,GAAM,KACR,KAAM,IAAI,OAAM,gCAElB,GAAI,GAAgB,GAClB,AAAI,EAAS,eAAe,gBAC1B,MAAS,MAAM,cAAgB,GAC/B,KAAM,IAAW,EAAK,YAEf,EAAG,WAAW,WACvB,GAAI,IAAO,cACT,GAAI,EAAS,mBAAmB,eAC9B,MAAO,MAAM,IAAU,WAEhB,EAAS,kBAAkB,eAAgB,CACpD,GAAM,GAAK,KAAM,IAAc,GAC/B,GAAI,GAAM,KACR,KAAM,IAAI,OAAM,eAElB,KAAM,IAAM,EAAG,WAAY,CAAE,YAAa,KAAQ,OAAO,gBAG3D,MAAM,IAAI,OAAM,yBAA2B,SAEtC,EAAP,CACA,KAAM,IAAI,IAAa,CACrB,QACA,QAAS,gBAAkB,EAC3B,UAAW,GACX,UAAW,GACX,UAAW,MC5FjB,GAAM,IAAS,EAAK,IAAM,EAAS,WAG7B,GAAgB,EAAK,IAAM,GAAM,EAAG,EAAG,GAAM,KAAY,KAIzD,GAAY,wBAEL,GAAgB,EAAK,SAAY,CAC5C,GAAI,CACF,GAAM,GAAS,KAAM,IACnB,EAAS,WAAW,eACpB,CAAC,YACD,CACE,QAAS,EACT,aAAc,GACd,iBAAkB,IAAM,KAGtB,EAAyB,GAAU,KAAK,EAAO,UAAU,GAC/D,YAAS,KAAK,gBAAiB,CAC7B,UACA,KAAM,EAAO,KACb,OAAQ,EAAO,OAAO,MAAM;AAAA,EAAM,GAAG,KAEhC,EAAO,OAAS,GAAK,EAAS,GAAW,EAAU,aACnD,EAAP,CACA,UAIS,GAA2B,EAAK,IAC3C,GACE,KACA,GAAO,WAAa,EACpB,IAAM,gBAGV,EAAM,IAAM,EAAa,IAAM,GAAc,UAE7C,mBAA2C,CACzC,MAAO,IAAW,GAAc,QAAS,IAAM,GAAc,WAG/D,mBAA0C,CAExC,MAAQ,MAAM,OAAoB,KA2CpC,kBAAkC,EAM/B,CACD,MAAK,MAAM,GAAK,KAAK,UAAc,KAAM,GAAK,KAAK,WACjD,KAAM,GAAK,KAAK,SAGX,GACL,EAAS,WAAW,eACpB,EAAQ,CACN,YACA,QACA,KACA,EAAK,IAAI,WACT,GAAI,GAAS,EAAK,WAAY,GAAM,CAAC,MAAO,EAAG,QAAQ,MAAQ,GAC/D,WACA,IAQA,KACA,aACA,KACA,EAAK,KAAK,aAEZ,CACE,QAAS,EACT,iBAAkB,KAmDxB,kBAAuC,EAAuC,CAC5E,MAAO,MAAS,IAAI,CAClB,IAAK,mBACL,KAAM,CAAE,IAAK,EAAI,YACjB,OAAQ,KAAM,IACZ,EAAS,WAAW,eAGpB,CACE,KACA,QACA,WACA,WACA,EAAI,MACJ,KACA,EAAI,WACJ,KACA,OACA,KAEF,CACE,QAAS,EAAO,KAAM,IAAyB,GAAM,EAAI,GACzD,iBAAkB,GAClB,eAAgB,GAChB,MAAO,OC9Nf,OAAqB,mBA0BrB,GAAM,IAAS,EAAK,IAAM,EAAS,QAE5B,aAAiC,CACtC,MAAO,IACL,KAAU,MAAM,IAAG,IACnB,GAAO,WAAa,EAAI,QACxB,IAAM,eAIV,GAAM,IAAY,0CASZ,GAAiB,CACrB,eACA,eACA,eACA,WAGW,GAAU,EAA4B,IAAM,MAEzD,EAAM,IAAM,EAAa,IAAM,GAAQ,UAEvC,mBAAqC,CACnC,MAAO,IAAW,GAAQ,QAAS,IAAM,GAAQ,WAGnD,mBAAuC,CAErC,MACE,CAAC,IACA,KAAM,IACL,KACA,GAAM,EAAG,SAAW,KACpB,IAAM,IAKL,aAAmB,CACxB,MAAO,GAAQ,KAAW,GAAO,EAAG,SAAW,KAAO,OAAY,EAAG,MAGvE,kBAA4B,EAAoC,CAC9D,MAAO,GACL,GACE,EAEA,CAAC,GAAG,GAAgB,aACpB,CACE,QAAS,EAGT,aAAc,GACd,MAAO,GACP,iBAAkB,IAAM,KAG5B,GACE,EAAI,EAAO,QACR,OAAO,GACP,IAAI,GAAM,EAAG,QACb,QAAQ,GAAM,GAAU,KAAK,IAC7B,QAAQ,GAAM,EAAG,IACjB,OAIT,YAAoB,EAAoC,CAGtD,MAAO,GACL,GAAW,WACR,QACC,mBAAmB,GAAU,8BAC7B,GAAM,GAEP,MAAM,GAAO,CACZ,KAAS,KAAK,6BAA+B,EAAO,KAAO,KAG/D,GAAU,GAAO,EAAO,SAI5B,mBAAiD,CAC/C,GAAM,GAAgC,GACtC,cAAgB,EAAe,CAC7B,EAAM,KAAK,EAAU,IAAI,YAAK,GAAG,KAOnC,GALI,EAAC,GAAS,EAAS,QAAQ,aAG7B,EAAM,KAAK,EAAS,QAAQ,gBAE1B,GAAO,CACT,GAAM,GAAU,2CAChB,EAAY,GAAO,QAAS,GAAM,EAAI,EAAK,IAC3C,EAAI,GAEN,GAAI,EAAO,CACT,GAAM,GAAU,CAAC,WAAY,MAAO,WACpC,EAAY,GAAO,gBAAiB,GAAM,CACxC,EAAI,EAAI,OAAQ,GAAG,KAErB,EAAY,GAAO,gBAAiB,GAAM,CACxC,EAAI,EAAI,GAAG,KAEb,EAAY,GAAO,qBAAsB,GAAM,CAC7C,EAAI,EAAI,GAAG,KAIf,OAAW,KAAc,GACvB,GAAI,CACF,GACE,YAAsB,IACrB,KAAM,GAAW,QAAQ,YAE1B,SAEF,GAAM,GAAO,EAAW,WAClB,EAAU,KAAO,GAAQ,GAAW,GAAQ,GAAa,IAC/D,GAAI,EAAM,GAAU,CAClB,KAAS,KAAK,uCAAyC,GACvD,aAEA,OAAO,IAAI,CAAE,OAAM,WAAW,GAC5B,KAAS,KAAK,YAAa,UAGxB,EAAP,CACA,KAAS,KAAK,kBAAoB,EAAK,CAAE,KAAM,KAOrD,kBAA+B,EAM5B,CACD,GAAM,GAAM,KAAM,MAClB,GAAI,EAAM,GACR,MAAO,MAAS,MAAM,4BAA6B,OAC9C,GAD8C,CAEjD,UAAW,MAGf,GAAM,GAAS,GAAY,EAAK,KAAK,IAAK,KAAK,cAC/C,GAAI,CAAC,CAAC,MAAO,OAAO,SAAS,GAC3B,MAAO,MAAS,MACd,4CAA8C,GAC9C,CAAE,SAAQ,SAGd,GAAM,GAAY,EAAK,YAAc,EAC/B,EAAW,EAAY,EACvB,EAAS,KAAM,IACnB,EACA,EAAQ,CAEN,GAAG,GACH,oBACA,uBACA,kBAAoB,EACpB,kBAGA,oBAOA,gBAAkB,EAAK,KAAK,IAC5B,kBAAoB,EAAK,KAAK,KAC9B,gBAAkB,EAAU,QAAQ,GACpC,eAAiB,EAAS,QAAQ,GAClC,EAAK,IAAI,WACT,eAEF,CACE,QAAS,EACT,aAAc,KAUlB,GADA,EAAK,KAAK,QACN,EAAI,EAAO,MACb,KAAM,IAAI,OAAM,eAAiB,EAAU,IAE7C,MAAO,G3C7LF,GAAM,IAA4B,EAAK,SAC5C,kBAAa,GAAK,IAAO,KAAY,GAAM,KAAM,MAAuB,EAAI,GAG9E,kBAA0C,EAGjB,CACvB,MAAQ,MAAM,IACZ,IACE,EAAO,GAAM,eAAiB,CAAC,GAC3B,OACA,EAAQ,KAAsB,GAAM,EAClC,GAAI,GACJ,IAAK,UAAY,KAEzB,IACE,EAAO,GAAM,WACT,OACA,EAAQ,KAAgB,GAAM,EAAE,GAAI,GAAM,IAAK,OAAS,EAAE,WAChE,IAAO,EAAE,GAAI,GAAO,IAAK,iCAItB,GAAM,IAAmB,EAC9B,SAAa,MAAM,OAAuB,IAG5C,EAAM,IAAM,EAAa,IAAM,GAAiB,UA2ChD,kBACE,EACA,EACA,EAIA,CACA,GAAI,CAAC,GAAgB,GAAW,OAEhC,GAAM,GAAY,EAAO,GAAW,QAChC,GACA,EAAO,KAAM,IAAW,GAAW,UAAW,IAAM,OAClD,EACJ,CAAC,GACD,EAAO,KAAM,IAAW,GAAW,OAAQ,IAAM,OACnD,GAAI,CAAC,GAAa,CAAC,EAAQ,OAE3B,GAAM,GAAM,EAAS,+BAAiC,EAAM,KAKtD,EAAO,KAAM,IAAc,EAAK,QAAS,QAC/C,EAAI,MAAM,oBAAqB,CAAE,KAAM,EAAK,WAAY,aAExD,GAAM,GAAW,KAAM,GAAI,UAC3B,GAAI,GAAY,KACd,MAAO,GAAI,MAAM,cAGnB,GAAM,GAAU,KAAM,IAAY,GAClC,GAAI,GAAW,KACb,MAAO,GAAI,MAAM,WAEnB,GAAM,GAAM,GAAgB,GAC5B,EAAI,MAAM,qBAAuB,GAGjC,GAAM,GAAS,GAAgB,EAAS,IAAM,WAExC,EAAW,KAAM,GAAK,OAEtB,EAAU,GAAY,KAAO,OAAY,KAAM,IAAW,GAEhE,GACE,GAAY,MACZ,EAAS,QAAU,GACnB,GAAW,MACV,IAAU,MACR,EAAQ,SAAW,EAAO,QAAU,EAAQ,QAAU,EAAO,OAEhE,SAAI,MAAM,eAAiB,EAAO,oBAAqB,CAAE,SAAQ,YAC1D,EAET,GAAM,GAAW,GAAmB,GAC9B,EAAa,KAAK,IACtB,GAAY,EACZ,EAAS,gBAAgB,gBAE3B,SAAI,KAAK,qBAAsB,CAC7B,aACA,aAGF,KAAM,GAAK,SAAS,KAAM,KAAW,CACnC,GAAM,IAAO,GACX,MACA,KAAM,GACN,cACG,GAGL,KAAO,GAAY,GAAY,IAAQ,GAAS,KAEhD,KAAM,IAAc,IAEhB,GAAU,GAAO,MAAQ,IAAQ,GACnC,GAAI,KAAK,uBAAyB,GAAS,CAAE,QAC7C,KAAM,IAAc,GAAS,MAG1B,EA4JT,kBAAiC,EAAgB,EAAkB,CACjE,GAAM,GAAM,EAAS,wBAA0B,EAAM,KAKrD,GAHI,AADM,KAAM,IAAkB,EAAK,IAC9B,MACP,EAAI,MAAM,mCAER,KAAM,MACR,MAAO,IAAiB,G4CzW5B,OAAqB,oBCDrB,OAAiD,gCACjD,GAAiD,oBCDjD,OAAyB,oBAOlB,GAAM,IAAmB,GAEnB,GAAuB,EAAK,IAAM,YAAS,QAAQ,OAAQ,IAEjE,YAAwB,EAAyC,CAEtE,MADI,IAAmB,MACnB,KAAK,IAAI,GAAmB,GAAmB,GAAW,GAGvD,IAAoB,EAAI,OAA2B,EAAI,GChBhE,OAA6B,gCAiB7B,GAAM,IAAK,+CACJ,QAAmB,CAyDhB,YACG,EACA,EACA,EACA,EAAQ,EACR,EAAS,EAClB,CALS,aACA,cACA,WACA,aACA,cA0CF,iBAAc,KAAK,SAAS,KAAK,MAxCxC,KAAK,KAAO,GAAQ,KAAK,QACzB,KAAK,MAAQ,GAAS,KAAK,QAC3B,KAAK,IAAM,GAAO,KAAK,cAjElB,SAAQ,EAAgC,CAC7C,EAAI,EAAI,GAAG,OACX,GAAM,GAAI,GAAG,KAAK,GAClB,GAAI,GAAK,KACP,OAEF,GAAM,GAAQ,gBAAa,QAAQ,EAAE,IAC/B,EAAM,gBAAa,QAAQ,EAAE,IAC7B,EAAQ,EAAM,EAAE,IAChB,EAAQ,EAAM,EAAE,IACtB,MAAO,MAAK,IAAI,EAAO,EAAK,EAAO,SAG9B,KACL,EACA,EACA,EAAQ,EACR,EAAS,EACY,CACrB,GAAI,CAAC,GAAU,IAAU,CAAC,GAAU,GAAM,OAC1C,GAAM,GAAW,GAAe,GAC1B,EAAS,GAAe,GAC9B,GAAI,GAAY,MAAQ,GAAU,KAAM,OACxC,EAAS,GAAM,EAAG,IAAM,EAAM,EAAQ,CAAE,aAAc,KACtD,EAAQ,GAAM,EAAG,EAAS,EAAG,EAAM,EAAO,CAAE,aAAc,KAC1D,GAAM,GAAS,EACb,EACG,aACA,MAAM,EAAO,cACb,cAAc,EAAS,GAAG,GAC7B,GAAK,EAAE,KAET,GAAI,GAAU,KAWd,MAAO,IAAI,IACT,EACA,GAAe,EAAQ,EAAO,EAAS,KAAM,EAAO,OACpD,EACA,EACA,MAoBA,aAAa,CACf,MAAO,MAAK,IAAI,SAAS,UAAY,KAAK,MAAM,SAAS,UAG3D,UAAW,CACT,MAAO,MAAK,MAAM,aAAa,MAAM,KAAK,IAAI,cAGhD,QAAS,CACP,MAAO,MAAK,OAAO,YAGjB,OAAO,CACT,MAAO,GAAO,KAAK,MAAM,KAAM,KAAK,IAAI,SAGtC,WAAW,CACb,MAAO,IAAQ,KAAK,QAAU,GAAQ,KAAK,KAM7C,SAAS,EAAgB,GAAc,CACrC,MACE,GAAG,GAAW,KAAK,MAAO,MAAkB,GAC1C,KAAK,IACL,KAED,MAAK,QAAU,GAAK,KAAK,SAAW,EACjC,GACA,IAAI,KAAK,SAAS,KAAK,UAM/B,SAAS,EAA0B,CACjC,GAAI,GAAK,KAAM,MAAO,GACtB,GAAM,GAAM,GAAe,GAC3B,MAAI,IAAO,KACF,KAAK,WAAW,SAAS,EAAI,cAGlC,KAAK,OAAS,GAAQ,IACtB,KAAK,QAAU,GAAS,IACxB,KAAK,MAAQ,GAAO,KFnG5B,YAAa,EAAY,EAAoB,EAAW,CACtD,MAAO,IAAK,KAAO,GAAK,GAAQ,EAAG,EAAW,KAGzC,YAAmB,EAAoB,CAC5C,GAAI,GAAK,MAAQ,MAAO,IAAM,UAAY,IAAM,EAAG,MAAO,GAC1D,GAAM,GAAK,GAAc,GAEzB,MADI,IAAM,MAAQ,IAAO,GACrB,CAAC,GAAS,GAAQ,GAAI,GAAS,GAAI,GAAO,IAAY,GACnD,GAAQ,GACX,EACE,GAAW,GACX,GAAM,EAAG,QACT,IAAM,IAER,GAGC,YACL,EACA,EACU,CACV,MAAO,IAAU,GAAO,EAAE,GAAO,OAGnC,GAAM,IAAU,EAAK,IAAM,EAAS,aAAa,eAAgB,IAC3D,GAAU,EAAK,IAAM,GAAI,MAAK,KAAK,MAAQ,IAAO,cAAe,IACjE,GAAW,EAAK,IAAM,GAAI,MAAK,KAAK,MAAQ,IAAO,WAAa,EAAG,IAEzE,EAAM,IACJ,EAAa,IAAM,CACjB,GAAQ,QACR,GAAQ,QACR,GAAS,WAIN,YAAmB,EAAqB,CAC7C,MAAO,IAAO,KAAW,KAAW,GAG/B,YAAoB,EAAsB,EAAe,CAC9D,MAAO,IAAI,EAAM,OAAc,GAAG,EAAO,MACrC,GACA,GAAO,EAAG,GAAI,GAMb,YACL,EACA,EACA,EACA,CAEA,MAAO,IAAO,MAAQ,YAAS,WAAW,CAAE,OAAM,QAAO,QAAO,QAG3D,YAAkB,EAAe,EAAgB,EAAc,CACpE,MACE,IAAU,IACT,IAAS,MACP,GAAW,EAAO,IAAU,IAAO,MAAQ,GAAS,EAAM,EAAO,KAIjE,YAAgB,CACrB,YACW,EACA,EACA,EACT,CAHS,YACA,aACA,iBAGJ,KAAI,EAAc,EAAgB,EAAgC,CACvE,MAAO,IAAS,EAAM,EAAO,GACzB,GAAI,IAAU,EAAM,EAAO,GAC3B,aAGC,aAAa,CAClB,MAAO,IAAY,GAAI,OAGzB,UAAW,CACT,MAAO,GAAQ,CAAC,KAAK,KAAM,KAAK,MAAO,KAAK,MACzC,IAAI,GAAM,GAAI,IACd,KAAK,KAGV,aAAc,CACZ,MAAO,MAAK,WAGd,YAAa,CACX,MAAO,aAAS,WAAW,QAQ/B,QAAa,CACX,YACW,EACA,EACA,EACA,EACA,EACT,CALS,qBACA,UACA,iBACA,kBACA,gBAEX,MAAM,EAAsC,CAC1C,GAAM,GAAM,KAAK,GAAG,KAAK,GACzB,GAAI,GAAO,KAAM,CACf,GAAM,GAAO,SAAS,EAAI,KAAK,WAAY,IACrC,EAAQ,KAAK,MAAM,GACnB,EACJ,KAAK,UAAY,KAAO,OAAY,SAAS,EAAI,KAAK,UAAW,IACnE,MAAO,IAAU,IAAI,EAAM,EAAO,OAElC,QAII,MAAM,EAAwC,CACpD,GAAI,KAAK,YAAc,KACrB,OAEF,GAAM,GAAI,EAAO,KAAK,YAAY,cAClC,MAAI,MAAK,cAAc,IAAI,GAClB,KAAK,cAAc,IAAI,GAEvB,EAAM,KAKb,GAAS,sBACT,GAAU,kBACV,GAAa,mBACb,GAAQ,sBACR,GAAW,uBACX,GAAS,yBAET,GAAM,eACN,GAAW,GACX,GAAW,GAEX,GAAO,mBACP,GAAU,GAAO,IAEjB,GAAW,mBAGX,GAAa,kDAEb,GAAO,GAAI,QAAO,aAAe,GAAY,KAE5C,YAA4B,EAA4B,CAG7D,MAAO,GAAI,GAAK,KAAK,GAAM,GAAM,GAAuB,EAAG,MAAM,KAMnE,YACE,EACA,EACe,CACf,GAAI,EAAQ,GAAM,MAAO,GACzB,GAAM,CAAC,EAAM,GAAQ,EAAI,OAAO,EAAG,GAC7B,CAAC,EAAY,GAAa,EAAI,OAAO,EAAG,GAAG,IAAI,GAAM,EAAM,IACjE,MAAI,IAAiB,CAAC,IAAK,OAAQ,GAAc,EAC7C,GAAc,CAAC,EAAM,EAAY,IAC5B,EACD,KAAS,IAAM,GAAK,GAAM,GAAc,GAAK,GAWhD,YAAuB,EAAkC,CAC9D,MAAO,GAAY,EAAK,GACtB,GACE,CAAC,IAAM,gBAAa,SAAS,GAAI,IAAM,GAAkB,IACzD,GAAK,GAAU,KAKrB,GAAM,IAAS,EAAK,IAAM,EAAS,cAK5B,YACL,EACA,EAAqB,GACP,CACd,GAAI,GAAM,GACV,OAAW,CAAE,OAAM,MAAO,CACxB,CAAE,KAAM,uBAAwB,EAAG,IAAM,GAAa,QAAQ,IAC9D,CAAE,KAAM,gBAAiB,EAAG,IAAM,GAAc,IAChD,CACE,KAAM,6BACN,EAAG,IAAM,YAAS,WAAW,EAAG,qBAElC,CACE,KAAM,6BACN,EAAG,IAAM,YAAS,WAAW,EAAG,gBAGlC,CACE,KAAM,oCACN,EAAG,IAAM,YAAS,WAAW,EAAG,iBAElC,CAAE,KAAM,oBAAqB,EAAG,IAAM,YAAS,SAAS,IACxD,CAAE,KAAM,qBAAsB,EAAG,IAAM,KAAY,SAAS,IAC5D,CACE,KAAM,aACN,EAAG,IAAO,EAAqB,GAAI,MAAK,GAAK,SAE9C,CACD,GAAM,GAAS,IACf,GAAI,GAAU,GAAS,CACrB,GAAM,GAAkB,GAAmB,GAC3C,MAAI,IAAmB,MACrB,GAAO,gBAAqB,GAEvB,KAAS,IAAI,CAClB,IAAK,eACL,SACA,KAAM,CACJ,IACA,OACA,uBAQH,YAAsB,CAM3B,YAAqB,EAAiB,CAAjB,cALJ,mBAAqC,GAAI,KACzC,iBAAwB,GACxB,gBAAuB,GACvB,eAAsB,GAGrC,KAAK,QAGP,SAAS,EAAiC,CACxC,MAAO,IAAM,KAAK,YAAa,GAAK,EAAE,MAAM,IAGtC,UACN,EACA,EACA,EACA,EACA,CACA,GAAM,GAAI,GAAI,IACZ,KAAK,cAEL,GAAI,QAAO,EAAK,eAAgB,KAChC,EACA,EACA,GAEF,AAAI,GAAY,MAAQ,GAAc,KACpC,KAAK,YAAY,KAAK,GACjB,AACL,EAAS,iBAAiB,gBAC1B,GAAY,MACZ,GAAc,KAEd,KAAK,WAAW,KAAK,GAErB,EAAS,iBAAiB,gBAC1B,GAAY,MACZ,GAAc,MAEd,KAAK,UAAU,KAAK,GAIhB,OAAQ,CAEd,GAAM,GAAoB,CAAC,QAAS,QACpC,OAAW,KAAU,GAAK,CAAC,KAAK,OAAQ,UACtC,OAAW,KAAoB,GAAmB,CAChD,GAAM,GAAM,GAAI,MAAK,eAAe,EAAQ,CAC1C,MAAO,IAET,GAAM,GAAI,GAAK,CACb,GAAM,GAAY,EAAI,OAAO,GAAI,MAAK,KAAM,IAC5C,KAAK,cAAc,IAAI,EAAU,cAAe,EAAI,KAK1D,GAAM,GAAY,IAAM,GAAK,CAAC,GAAG,KAAK,cAAc,SAAS,KAAK,KAAO,IAKzE,KAAK,UAAU,GAAS,GAAO,GAAa,MAAQ,GAAU,EAAG,EAAG,GAGpE,KAAK,UAAU,GAAS,GAAU,GAAU,MAAQ,GAAO,EAAG,EAAG,GAGjE,KAAK,UAAU,GAAS,GAAU,EAAY,MAAQ,GAAU,EAAG,EAAG,GAGtE,KAAK,UAAU,EAAY,GAAU,GAAW,QAAU,GAAQ,EAAG,EAAG,GAGxE,KAAK,UAAU,GAAW,GAAU,EAAY,QAAU,GAAQ,EAAG,EAAG,GAGpE,EAAS,iBAAiB,gBAE5B,MAAK,UAAU,EAAY,GAAO,GAAQ,EAAG,GAG7C,KAAK,UAAU,GAAS,GAAO,EAAW,EAAG,IAG/C,KAAK,UAAU,GAAQ,GAGzB,oBAAoB,EAAkC,CACpD,GAAI,CAAC,EAAS,qBAAqB,eAAgB,OAGnD,GAAkB,QAAQ,GAAM,CAC9B,AAAI,GAAW,EAAM,IACnB,EAAK,OAAO,EAAG,EAAG,UAGtB,EAAO,EAAK,OAEV,GAAM,EAAS,IAAO,EAAK,GAAG,MAAM,KAAiB,MAGvD,GAAM,GAAc,CAAC,GAAG,GAAM,UAE9B,MAAO,IAEL,IAAM,GAAM,EAAa,GAAM,KAAK,SAAS,IAE7C,IAAM,KAAK,SAAS,EAAY,MAAM,EAAG,GAAG,KAAK,MACjD,IAAM,KAAK,SAAS,EAAK,MAAM,EAAG,GAAG,KAAK,MAC1C,GAAI,AAAC,EAAS,iBAAiB,eAE3B,CACE,IACE,GAAM,KAAK,WAAY,GACrB,GAAM,EAAa,GAAM,EAAO,MAAM,KAE1C,IACE,GAAM,KAAK,WAAY,GAAU,EAAO,MAAM,EAAK,KAAK,OAC1D,IACE,GAAM,KAAK,UAAW,GACpB,GAAM,EAAY,MAAM,GAAI,GAAM,EAAO,MAAM,MAVrD,MAiBJ,GAAe,+DAEf,GAA4B,EAAK,IAAM,CAC3C,EAAS,iBAAiB,YAAY,IAAM,GAAU,SACtD,EAAS,iBAAiB,YAAY,IAAM,GAAU,SACtD,EAAS,qBAAqB,YAAY,IAAM,GAAU,WAGtD,GAAY,EAAK,IACrB,MACO,GAAI,IAAgB,UAGvB,GAAgC,GAW/B,YAA6B,EAAkC,CACpE,MAAO,MAAY,oBAAoB,GAGlC,YAAkB,EAA6B,CACpD,MAAO,MAAY,SAAS,GAevB,YAAiB,EAAoB,CAI1C,MACE,IAAK,MACJ,aAAa,KACZ,YAAa,cACb,YAAa,kBACb,YAAa,OACb,YAAa,KACb,YAAa,cACb,GAAW,CAAC,EAAE,KAAM,EAAE,MAAO,EAAE,OAI9B,YAAiB,EAAyB,CAC/C,MAAO,GAAI,EAAG,GAAO,YAAc,MAAO,EAAG,cAAgB,EAAG,MAM3D,YAAkB,EAAyB,CAChD,MAAO,GAAI,EAAG,GAAO,YAAc,MAAO,EAAG,WAAa,EAAI,EAAG,OAG5D,YAAgB,EAAyB,CAC9C,MAAO,GAAI,EAAG,GAAO,YAAc,MAAO,EAAG,UAAY,EAAG,KAGvD,YAAiB,EAAyB,CAC/C,MAAO,IAAQ,GAAM,YAAa,MAAO,EAAE,WAAa,EAAE,KAAQ,OAG7D,YAAmB,EAAyB,CACjD,MAAO,IAAQ,GACX,YAAa,MACX,EAAE,aACF,EAAE,OACJ,OAGC,YAAmB,EAAyB,CACjD,MAAO,IAAQ,GACX,YAAa,MACX,EAAE,aACF,EAAE,OACJ,OAGC,YAAwB,EAAyB,CACtD,MAAO,IAAQ,GACX,YAAa,MACX,EAAE,kBACF,EAAE,YACJ,OAGC,YAAoB,EAAmB,CAC5C,MACE,IAAQ,IACP,GAAI,GAAU,KAAO,EAAI,GAAU,KAAO,EAAI,GAAe,KAoB3D,YACL,EACA,EAAmB,GACJ,CACf,GAAI,GAAiB,KAAM,OAC3B,GAAI,IAAkB,EAAG,MAAO,GAAmB,MAAQ,GAC3D,GAAM,GAAO,EAAgB,EAAI,IAAM,IAEjC,EAAU,GAAM,EAAgB,IAAM,GACtC,EAAM,KAAK,IAAI,GACf,EAAQ,KAAK,MAAM,EAAM,IACzB,EAAU,KAAK,MAAM,KAAK,IAAI,EAAM,KAC1C,MAAO,GAAG,EAAmB,MAAQ,KAAK,IAAO,GAAI,MAAU,GAAI,KAG9D,YAAiB,EAAmB,CACzC,MAAI,aAAa,iBACR,EAAE,SAAW,GAAe,EAAE,iBAC5B,YAAa,aACf,EAAE,MAAQ,MAAQ,EAAE,KAAK,OAAS,QAElC,GAKJ,YAAqB,EAAyB,CACnD,MAAI,aAAa,aACR,EAAI,EAAE,KAAM,GAAM,EAAG,MACnB,YAAa,iBACf,EAAE,KAGT,OAIG,YACL,EACA,EAAa,GACQ,CACrB,GAAM,GAAI,EAAG,KAAK,GAClB,GAAI,GAAK,KACP,OAEF,GAAM,GAAS,CAAC,GAAG,EAAE,MAAM,IACrB,CAAC,EAAM,EAAO,EAAK,EAAM,EAAQ,GAAU,EAC9C,OAAO,EAAG,GACV,IAAI,GAAM,EAAM,IAKnB,GAHI,GAAQ,MAAQ,GAAS,MAAQ,GAAO,MAI1C,CAAC,EAAS,iBAAiB,gBAC1B,IAAQ,MAAQ,GAAU,MAE3B,OAGF,GAAM,GAAc,GAClB,EACA,IACA,GAAQ,EAAO,QAAS,CAAE,aAAc,IAAQ,KAE5C,EAAS,GAAuB,GAChC,EAAO,GAAiB,GACxB,EAAK,YAAS,WAAW,CAC7B,OACA,QACA,MACA,OACA,SACA,SACA,cACA,SAEF,MAAO,GAAG,QAAU,GAAe,EAAI,GAAQ,OAGjD,GAAM,IAAM,UAEN,GAAgB,GAAI,QACxB,CAAC,GAAQ,GAAS,GAAO,GAAQ,GAAU,GAAU,IAAU,KAAK,IAClE,GACA,IACF,KAOK,YAAoB,EAAkC,CAC3D,GAAI,YAAa,aAAU,MAAO,GAClC,GAAI,YAAa,iBAAc,MAAO,GAAE,aACxC,GAAI,YAAa,IAAc,MAAO,GAAE,OAAO,aAC/C,GAAI,YAAa,MAAM,MAAO,aAAS,WAAW,GAU7C,YACL,EACA,EACqB,CACrB,GAAI,GAAK,MAAQ,CAAC,GAAQ,GAAI,OAC9B,GAAI,YAAa,aACf,MAAO,iBAAa,aAAa,GAEnC,GAAM,GAAK,GAAc,GACzB,GAAI,GAAM,KAAM,OAEhB,GAAM,GAAkB,AAAC,EAAM,GAE3B,GAAQ,GACR,GAAY,GACZ,OAHA,EAKE,EAAS,EAAY,EAAiB,GAAM,GAAa,EAAI,IACnE,GAAI,GAAY,MAAQ,GAAU,KAChC,OAEF,GAAM,GAAS,EAAI,GAAQ,GAAI,GAC7B,EAAI,GAAS,GAAI,GACf,EAAI,GAAO,GAAI,GACb,EACE,GAAQ,GACR,GACE,GAAI,iBACF,EACA,EACA,EACA,EACA,EAAO,GAAU,GAAI,GACrB,EAAO,GAAU,GAAI,GACrB,GAAe,GACf,EACC,EAAU,cAMvB,MAAO,IAAU,GAAU,EAAS,OAG/B,YAAgB,EAA8B,CACnD,GAAI,GAAK,KAAM,OACf,GAAI,MAAO,IAAM,SACf,MAAO,IAAI,MAAK,GAElB,GAAI,YAAa,MACf,MAAO,GAET,GAAI,YAAa,aACf,MAAO,GAAE,WAEX,GAAI,AAAQ,EAAE,QAAV,KACF,MAAO,GAAE,SAEX,GAAI,EAAI,EAAE,OAAS,EAAI,EAAE,QAAU,EAAI,EAAE,KAIvC,MAAO,IAAI,MAAK,EAAE,KAAM,EAAO,EAAE,MAAO,GAAK,EAAG,EAAE,IAAK,IAEzD,GAAM,GAAI,EAAI,GACd,GAAI,EAAS,GAAI,MAAO,GAAI,GAAQ,GAAW,IAI1C,YACL,EACe,CACf,GAAI,KAAK,MAAQ,GAAS,IAC1B,MAAI,IAAS,GAAW,EACpB,YAAa,MAAa,EAAE,UAC5B,YAAa,aAAiB,EAAE,WAC7B,EAAI,GAAO,GAAI,GAAM,EAAG,WAG1B,YAAsB,EAAkD,CAC7E,GAAI,KAAK,MAAQ,GAAS,IAC1B,MAAI,IAAS,GAAW,GAAU,GAC9B,YAAa,kBAAgB,YAAa,aAAiB,GAAU,GACrE,YAAa,MAAa,GAAU,EAAE,WACnC,EAAI,GAAc,GAAI,IAGxB,YAAmB,EAA2C,CACnE,MACE,UACE,CAAC,EAAE,KAAM,EAAE,MAAO,EAAE,IAAK,EAAE,KAAM,EAAE,OAAQ,EAAE,QAC1C,IAAI,GAAM,GAAK,IACf,KAAK,IAAM,MACZ,GAAoB,EAAE,aAAe,GAItC,YAA8B,EAAgC,CACnE,MAAO,GAAI,EAAG,GACZ,YAAc,iBACV,EAAG,gBACH,YAAc,aACd,EAAG,OACH,QAID,YAA4B,EAAgC,CACjE,MAAO,GAAI,EAAG,GACZ,YAAc,cAAY,YAAc,kBAAgB,YAAc,MAClE,EACA,YAAc,aACd,GACA,YAAc,IACd,EAAG,WACH,QAID,YACL,EACA,EAAgB,GACD,CACf,GAAI,GAAK,KAAM,OACf,GAAI,YAAa,IAAc,MAAO,GAAE,SAAS,GACjD,GAAM,GAAK,GAAS,GAAK,GAAI,MAAK,GAAK,EACvC,MAAK,IAAQ,GACN,EAAI,GAAe,GAAK,GAAO,EAAI,YAAY,CAAE,mBAD/B,GAAW,GAI/B,YACL,EACA,EAC2C,CAC3C,MAAO,OAAO,IAAQ,UAAY,EAAM,GACpC,OAEA,EACE,gBAAa,QAAQ,EAAK,IAEzB,OAAO,IAAM,YAAS,QAAQ,IAC9B,OAAO,IAAM,YAAS,SAAS,IAC/B,MAGF,YAAoB,EAAU,EAAY,IAAa,CAC5D,MAAO,GAAQ,CAAC,GAAQ,GAAI,GAAS,GAAI,GAAO,KAC7C,IAAI,GAAM,GAAI,IACd,KAAK,GAGH,YAAqB,EAAmC,CAC7D,MAAO,GAAI,EAAG,GACZ,EAAI,GAAQ,GAAK,GAAK,GAAI,IAAU,EAAG,GAAS,GAAK,GAAO,MAIzD,YAAiB,EAAmB,EAA4B,CACrE,MAAO,IAAI,GAAW,EAAK,GAAM,IAG5B,YAAoB,EAAiB,EAAgC,CAC1E,GAAM,CAAC,EAAK,GAAO,CAAC,EAAG,GAAG,IAAI,IAC9B,MAAO,IAAO,MAAQ,GAAO,KAAO,OAAY,EAAM,EA6CjD,YAAiB,EAAsD,CAC5E,MAAO,aAAa,OAAQ,YAAa,kBAAgB,YAAa,aAMjE,YACL,EACA,EACe,CACf,GAAM,GAAI,QAAK,cAAc,GAC7B,MAAO,GAAE,QAAW,EAAU,OAAO,GAAM,OAGtC,YACL,EACA,EACgC,CAChC,MAAI,aAAe,aACV,EAAI,QAAQ,EAAM,CAAE,cAAe,KAErC,GAAe,EAAK,GG52BtB,YAAyB,OACvB,MAAS,EAAsC,CACpD,MAAO,IAAK,cAAc,GAAW,CACnC,MAAM,EAAmB,CACvB,MAAO,GAAE,KAOf,IAAI,EAA4B,CAC9B,MAAO,IAAO,KAAK,AAAC,GAAY,KAAK,MAAM,IAAS,EAAK,MAAM,IAGjE,GAAG,EAA4B,CAC7B,MAAO,IAAO,KAAK,AAAC,GAAY,KAAK,MAAM,IAAS,EAAK,MAAM,IAGjE,OAAO,EAA2B,CAChC,MAAO,GAAM,OAAO,GAAM,KAAK,MAAM,IAGvC,SAA0B,CACxB,MAAO,IAAY,KAAK,AAAC,GAAY,QAAQ,QAAQ,KAAK,MAAM,OAOvD,IAAgB,GAAO,KAAU,IAEjC,IAAa,GAAO,KAAU,IAAM,ICf1C,YAAyC,EAA6B,CAC3E,MAAO,IAAO,KAAK,AAAC,GAAY,GAAU,GAAM,IAAK,IAGhD,GAAM,KAAmB,GAAU,GAAS,2BACtC,IAAiB,GAAU,GAAS,OACpC,GAAgB,GAAU,GAAS,WCUhD,GAAM,IAAS,EAAK,IAAM,EAAS,iBAkBnC,kBACE,EACA,EACe,CACf,GAAI,EAAS,EAAK,OAAS,EAAS,EAAK,OACvC,OAGF,GACE,EAAM,EAAK,OACV,GAAI,EAAK,oBAAsB,EAAK,EAAa,iBAAiB,SACjE,SAEF,CACA,EAAK,KAAO,QAEZ,OAKF,GAAM,GAAS,GAAM,GACf,EAAO,KAAM,IAAgB,GACnC,GAAI,GAAQ,KAAM,OAClB,GAAM,GAAW,EAAQ,GAAQ,GAAI,EAAK,QAAS,EAAK,SACrD,MAAM,EAAG,IAET,OAAO,GAAM,GAAU,GAAM,GAAK,GAAU,IAE5C,MAAM,EAAG,IAEZ,KAAS,KACP,qBAAuB,EAAI,gCAC3B,EAAS,IAAI,GAAM,EAAG,OAGxB,OAAW,KAAW,GAAU,CAC9B,GAAM,GAAI,KAAM,IAAY,GAC5B,GAAI,GAAK,MAAQ,GAAY,EAAE,KAAM,EAAE,OAAQ,CAC7C,KAAS,KAAK,qBAAuB,EAAI,IAAK,CAC5C,QAAS,EAAQ,KACjB,KAAM,EAAE,KACR,MAAO,EAAE,QAEX,EAAK,KAAO,EAAE,KACd,EAAK,MAAQ,EAAE,MACf,SAKN,kBACE,EAC4C,CAC5C,MAAO,GACL,GAAsB,GACtB,CAAC,CAAE,SAAQ,QAAO,QAAO,WAAY,CACnC,GAAI,CAAC,GAAQ,EAAO,KAAM,EAAM,MAAO,CAGrC,KAAS,MACP,yDACA,CACE,KAAM,EAAK,WACX,OAAQ,EAAI,GACZ,MAAO,EAAI,KAGf,OAGF,MAAO,GACL,GAAa,IAAI,EAAO,KAAM,EAAM,KAAM,EAAO,GACjD,GAAS,EACP,OACA,IAAK,UAAU,EAAO,aAAa,EAAM,WAOnD,kBACE,EACA,EAAa,EAC8C,CAC3D,MAAO,IAAW,EAAI,GAAK,MAAM,EAAG,GAAa,CAAC,EAAK,IACrD,EAAQ,GAAY,GAAM,GACxB,EAAQ,GAAmB,GAAI,GAAO,OAAK,GAAL,CAAS,aAKrD,kBACE,EACA,EAAa,EACsC,CACnD,MAAO,IAAW,EAAI,MAAM,EAAG,GAAa,CAAC,EAAK,IAChD,EAAQ,GAAY,GAAM,GACxB,EAAQ,GAAmB,GAAI,GAC7B,EAAI,GACD,OAAO,GAAM,GAAQ,EAAG,OACxB,QAAQ,GAAM,GAAY,EAAG,OAC7B,IAAI,GAAa,EAAE,WAAU,WAC7B,SAaX,EAAM,IAAM,EAAa,IAAM,GAAU,SAAS,UAElD,GAAM,IAAY,EAAK,IAAM,GAAI,IAA6B,OAE9D,YAA+B,EAAoC,CACjE,MAAO,MAAY,SAAS,EAAK,WAAY,SAAY,CACvD,GAAM,GAAO,KAAM,IAAgB,GAC7B,EAAS,KAAM,IAAoB,GAAM,SACzC,EAAQ,KAAM,IAAoB,GAAM,OAC9C,MAAO,IAAU,MAAQ,GAAS,KAC9B,OACA,CACE,SACA,QACA,MAAO,EAAO,MACd,MAAO,EAAO,MAAQ,EAAM,MAAQ,KAK9C,EAAM,IAAM,EAAa,IAAM,GAAW,SAAS,UAEnD,GAAM,IAAa,EAAK,IAAM,GAAI,IAAkB,KAAM,IAMnD,YAAe,EAAgC,CACpD,GAAI,GAAO,GAAS,GAAK,EAAI,EAAE,KAC/B,MAAO,MAAa,SAAS,EAAM,IACjC,GAAI,qBAAqB,KAAK,GAAO,GAAM,EAAO,EAAE,IAGpD,EACE,gFAAgF,KAC9E,GAEF,GAAM,EAAO,EAAE,IAIf,EAYG,QAAQ,iCAAkC,IAQ1C,QAAQ,2CAA4C,IAGpD,QAAQ,YAAa,IAErB,QAAQ,qBAAsB,IAC9B,QAAQ,WAAY,IAEpB,cACA,cAKT,GAAM,IAAgB,GAAU,GAAS,WAYzC,kBACE,EACA,EAAY,EACmB,CAC/B,GAAM,GAAU,KAAM,GACnB,SACA,sBACC,GACE,EAAG,UACH,CAAC,EAAG,KAAK,WAAW,MACpB,CAAC,GAAa,EAAG,MACjB,GAAc,MAAM,IAE1B,GAAI,GAAW,KAAM,CACnB,KAAS,KAAK,4CAA8C,EAAE,UAC9D,OAEF,GAAM,GAAQ,KAAM,GAAE,YACtB,GAAI,EAAQ,GAAQ,CAClB,KAAS,KAAK,+CAAiD,GAC/D,OAGF,GAAM,GAAS,GAAO,EAAS,GAAM,GAAM,IACrC,EAAU,EAAO,UAAU,GAAM,EAAG,OAAS,EAAE,MACrD,GAAI,EAAU,EAAG,CACf,KAAS,KAAK,mDAAqD,GACnE,OAGF,GAAM,CAAC,EAAW,GAAW,CAC3B,EAAO,MAAM,EAAU,EAAY,EAAG,GACtC,EAAO,MAAM,EAAU,EAAG,EAAU,EAAI,EAAY,IAGhD,EAAuB,GACvB,EAAqB,GAE3B,KAAO,EAAW,IAAc,EAAQ,OAAS,GAAW,CAC1D,GAAM,GAAK,EAAU,kBAAkB,EAAU,OACjD,AAAI,KAAM,IAAY,EAAG,IACvB,EAAQ,KAAK,GAGjB,KAAO,EAAW,IAAY,EAAM,OAAS,GAAW,CACtD,GAAM,GAAK,EAAU,kBAAkB,EAAQ,SAC/C,AAAI,KAAM,IAAY,EAAG,IACvB,EAAM,KAAK,GAIf,MAAO,CACL,UACA,SAiBJ,YAAqB,EAAc,EAAc,EAAY,EAAI,GAAO,CACtE,GAAM,GAAS,GAAW,GAAS,EAAE,MAAO,GAAS,EAAE,OACvD,MAAI,IAAU,MAAQ,KAAK,IAAI,GAAU,EAAkB,GACpD,EAAE,aAAa,EAAG,GAG3B,kBACE,EACsB,CACtB,GAAM,GAAO,KAAM,IAAgB,GAC7B,EAAS,GAAQ,EAAI,GAAM,SAAU,EAAI,GAAM,QAAQ,MAAM,EAAG,IACtE,MAAO,MAAS,IAAI,CAClB,IAAK,0BAA4B,EAAI,IACrC,OAAQ,KAAM,GACZ,GAA4B,GAC5B,GAAM,EAAG,UAEX,KAAM,CACJ,YASN,kBACE,EACmD,CACnD,GAAM,GAAW,GAAc,GAAM,IAC/B,EAAa,EAAI,EAAU,IAEjC,GAAI,GAAY,MAAQ,GAAc,KAAM,CAC1C,KAAS,MAAM,uCAAwC,CACrD,MAAO,GAAM,GACb,WACA,eAEF,OAGF,GAAM,GAAO,KAAM,GAAE,OACrB,GAAI,GAAQ,KAAM,CAChB,KAAS,MAAM,6BAA8B,CAAE,WAAU,eACzD,OAGF,MAAO,MAAS,IAAI,CAClB,IAAK,qBACL,OAAQ,GAAM,CAAC,cAAe,UAAW,UAAW,WAAY,GAC9D,KAAK,IAAI,EAAK,GAAO,GAAc,GAC/B,CAAE,MAAK,KAAM,GACb,QAEN,KAAM,CAAE,WAAU,aAAY,UNrVlC,GAAM,IAAS,EAAK,IAAM,EAAS,eAE5B,YAA+B,EAAsB,CAC1D,MAAO,GAAI,GAAK,cAAc,WAAW,QAGpC,YAAiB,CACtB,YACW,EACA,EACA,EACA,EACA,EACT,CALS,kBACA,YACA,WACA,aACA,mBAQF,iBAAc,EAAK,IAAM,GAAW,KAAK,OALlD,OAAO,EAAoC,CACzC,GAAM,GAAI,OAAK,MAAS,GACxB,MAAO,IAAI,IAAW,EAAE,WAAY,EAAE,KAAM,EAAE,IAAK,EAAE,OAKvD,SAAU,CAER,MAAO,IAAa,KAAK,MAG3B,UAAW,CACT,MAAO,IAAqB,KAAK,SAG/B,aAAa,CACf,MAAO,IAAsB,KAAK,KAGpC,eAAgB,CACd,MAAO,GAAO,KAAK,YAAa,IAAM,GAAmB,KAAK,OAGhE,UAAW,CACT,MAAO,GAAU,CACf,WAAY,KAAK,WACjB,KAAM,KAAK,cACX,IAAK,KAAK,IACV,MAAO,KAAK,QAIhB,OAAQ,CACN,MAAO,IAAQ,KAAK,MAGtB,SAAU,CACR,MAAO,IAAQ,KAAK,QA4CxB,kBACE,EACA,EACA,EACA,EACqB,CACrB,GAAM,GAAQ,KAAM,GACpB,GAAI,EAAC,GAAU,GACf,MAAI,IAAQ,GAAe,EAEvB,GAAQ,MAAQ,EAAK,IAAM,MAAQ,QAAK,gBAAgB,EAAK,IACxD,GAAQ,EAAO,EAAK,IAEpB,EAAgB,EAAQ,GAAc,EAAG,GAIpD,kBACE,EACA,EACqB,CACrB,GAAI,CAAC,GAAU,GAAI,OACnB,GAAI,GAAQ,GAAI,MAAO,GACvB,GAAM,GAAQ,KAAM,IAAuB,GAC3C,GAAI,GAAS,KAAM,CACjB,GAAM,GAAM,GAAe,EAAG,GAC9B,GAAI,GAAU,GAAM,MAAO,GAE7B,MAAO,GAGT,YAA+B,EAAc,EAAiC,CAC5E,MACE,IAAK,MACL,GACA,CAAC,EAAS,qBAAqB,gBAC9B,CAAC,EAAS,4BAA4B,gBACrC,GAAsB,EAAE,WAAY,EAAS,YAAY,OAU/D,kBACE,EACA,EACA,EAC4B,CAC5B,GAAM,GAAQ,KAAM,GAAE,QAEhB,EAAO,MACX,EACA,IAIO,EAAQ,EAAQ,GACrB,EACE,GAAY,EAAG,EAAM,EAAE,KAAM,GAC7B,GACE,GAAI,IACF,EAAE,WACF,EACA,EAAc,CAAC,EAAK,EAAE,MAAM,KAAK,KACjC,EACA,EAAE,eAMZ,MAAO,IACL,IAAM,EAAK,OAAQ,GAAmB,IACtC,IAAM,EAAK,aAAc,GAAiB,IAC1C,IACE,EACI,OACA,EAAK,WAAY,GAA4B,IACnD,IACE,GAAiB,CAAC,EAAS,qBAAqB,eAC5C,OACA,EACE,QACA,EAAI,GAAW,GAAM,IAAK,GAAS,EACjC,OACA,IAAK,GACL,YAAa,GAAI,CAAC,GAAmB,GAAO,QAGtD,IACE,GAAsB,EAAG,GACrB,OACA,EACE,OACA,EAAI,GAAoB,EAAE,uBAAwB,GAAS,EACzD,IAAK,GACL,WAGV,IACE,AAAC,EAAS,oBAAoB,eAE1B,EACE,OACA,EAAQ,EAAE,cAAe,GAAS,EAAE,IAAK,GAAI,WAH/C,QAQV,GAAM,IAAiB,CASrB,yBACA,mBACA,sBACA,wBAEA,mBAGA,yBAEA,aACA,kBACA,cACA,oBACA,kBAEA,WAGA,aACA,aAMA,kBAOF,YACE,EACA,EACqC,CACrC,MAAO,IAAa,EAAE,GAAa,GAAS,EAC1C,MACA,UAIG,YACL,EACqC,CACrC,GAAI,GAAa,KAAM,OAEvB,GAAM,GAAS,EACb,GAAe,IAAI,GAAQ,EACzB,KAAM,EAAU,GAChB,MACA,GAAI,EAAI,GAAc,EAAU,IAAO,GAAM,KAAK,MAAM,EAAK,UAI3D,EAAW,EAAO,OAAO,GAAM,GAAU,EAAG,OAAS,EAAG,IAAM,MAEpE,UAAM,GAAU,MAAO,IAAM,CAC3B,KAAS,MAAM,uBAAwB,CAAE,SAAQ,eAK5C,GACL,IACE,GAAW,EAAU,GACnB,EAAI,GAAa,EAAG,IAAM,GAAO,CAC/B,CAAC,KAAK,MAAM,EAAM,KAClB,GAAQ,EAAG,MAAQ,EAAI,EACvB,GAAW,EAAG,MAAQ,EAAI,EAC1B,GAAQ,EAAG,MAAQ,EAAI,EACvB,CAAC,GAAe,QAAQ,EAAG,QAKjC,IAAM,GAAY,EAAW,eAM7B,IAAM,GAAY,EAAW,gBOlVjC,GAAM,IAAS,EAAS,oBAEjB,YAAiC,EAAkC,CACxE,GAAM,GAAmB,CACvB,YAAa,EAAE,YACf,IAAK,GAAa,EAAE,IAAK,EAAE,SAAU,EAAE,SACvC,SAAU,GACR,EAAE,QACF,EAAE,QACF,EAAE,cACF,EAAE,aAEJ,aAAc,GACZ,EAAE,aACF,EAAE,aACF,EAAE,mBAGN,UAAO,MAAM,kBAAoB,EAAE,SAAU,CAAE,qBACxC,GAAgB,GCClB,YAAmB,EAAW,EAAgC,CACnE,GAAM,GAAM,KAAK,IAAI,EAAG,GAClB,EAAmB,GACzB,KAAO,EAAI,GACT,EAAO,QAAQ,EAAI,GACnB,EAAI,KAAK,MAAM,EAAI,GAErB,MAAO,GAgBF,YAAgB,EAAuB,CAC5C,EAAE,KAAK,QAAQ,GAAQ,EAAI,MAAQ,GAAM,EAAI,IAAK,EAAI,IAAK,EAAI,QAE/D,GAAI,GAAS,EAEb,OAAS,GAAM,EAAG,EAAM,EAAE,SAAU,IAAO,CACzC,GAAU,EACV,GAAM,GAAO,EAAM,EAAE,KAAK,OACpB,EAAI,EAAE,KAAK,GACX,EAAM,GAAI,CAAC,EAAE,IAAK,EAAE,MAC1B,AAAI,EAAE,MAAQ,EACZ,IAAU,EACV,EAAE,IAAM,GAER,EAAE,IAAM,EAGZ,MAAO,GAQF,YAAkB,EAAW,EAAkC,CACpE,GAAI,EAAE,SAAW,IAAM,EAAE,SAAW,EAAG,OACvC,GAAM,GAAU,GAAQ,GACxB,OAAS,GAAM,EAAG,EAAM,EAAE,SAAU,IAAO,CACzC,GAAM,GAAO,EAAM,EAAE,KAAK,OACpB,EAAI,EAAE,KAAK,GACX,EAAM,GAAI,CAAC,EAAE,IAAK,EAAE,MAC1B,AAAI,EAAQ,SAAS,EAAE,SAAW,EAAM,GACtC,EAAE,IAAM,EAER,EAAE,IAAM,EAGZ,MAAO,GAAE,KAAK,IAAI,GAAK,GAAI,CAAC,EAAE,IAAK,EAAE,OAIhC,YAAiB,EAAqB,CAC3C,MAAO,GACJ,SAAS,GACT,MAAM,IACN,UACA,IAAI,CAAC,EAAI,IAAS,IAAO,IAAM,EAAM,IACrC,OAAO,GAAM,IAAO,ICnFzB,GAAM,IAAkB,GAExB,YAA2B,EAAkB,CAC3C,MAAO,MAAK,MAAM,EAAW,GAAK,EAG7B,YAAkB,EAAkC,CACzD,MAAO,IAAS,IAAa,IAAa,GAAK,GAAO,IAAK,GAAI,GAG1D,YAAkB,EAAmC,CAC1D,MAAO,IAAS,IAAc,IAAc,GAAK,GAAO,KAAM,IAAK,GAG9D,YACL,EACA,EACS,CACT,MAAO,IAAS,IAAa,GAAS,GAqBjC,YAA6B,EAAmB,EAAoB,CACzE,MAAO,IAAe,EAAU,EAAW,IAGtC,YACL,EACA,EACA,EAAW,GACI,CACf,MAAO,AAAC,IAAY,EAAU,GAE1B,GAAO,CAEL,KAAM,CACJ,CACE,IAAK,KACL,MAAO,EACP,IAAK,KAEP,CACE,IAAK,IACL,MAAO,EACP,IAAK,KAGT,SAAU,GAAkB,KAf9B,OCcN,YAAwB,EAAgD,CACtE,MAAO,IAAO,GAAI,UAAW,GAAM,GAAa,GAAI,MAAK,EAAK,KAAO,GAAK,IAM5E,kBACE,EAC+B,CAC/B,MAAO,GAAQ,EAAS,SAAc,QAAS,GACtC,GAAc,CACnB,MAAO,GAAW,EAAE,OACpB,YAAa,GAAW,EAAE,aAC1B,YAAa,GAAM,CAAC,GAAG,SAAS,SAAU,GAAG,SAAS,UAAW,GAC/D,GAAS,GAAO,EAAM,QAExB,aAAc,GAAM,CAAC,GAAG,SAAS,UAAW,GAAG,SAAS,WAAY,GAClE,GAAS,GAAO,EAAM,QAExB,YAAa,GAAM,CAAC,GAAG,SAAS,SAAU,GAAG,SAAS,UAAW,GAC/D,GAAS,GAAO,EAAM,QAExB,UAAW,EAAE,WAAa,KAAO,OAAY,EAAO,EAAE,WACtD,YAAa,GACX,CAAC,GAAG,EAAI,EAAE,QAAS,GAAG,EAAI,EAAE,SAC5B,AAAC,GAAe,EAAc,EAAI,IAAI,GAAM,EAAG,QAEjD,aAAc,GAAe,EAAE,cAC/B,iBAAkB,GAAe,EAAE,kBACnC,eAAgB,GAAe,EAAE,gBACjC,WAAY,GAAO,EAAE,WAAY,GAAK,MCpG5C,YAAoB,EAAW,EAAY,EAAc,GAAY,CACnE,GAAM,GAAM,EAAE,QAAQ,EAAI,GAC1B,MAAO,KAAQ,EAAI,EAAI,GAAW,EAAK,EAAI,GAG7C,GAAM,IAAgB,CACpB,OACA,QACA,MACA,KACA,MACA,UACA,OACA,WAEI,GAAc,GAAI,KAAI,GAAc,IAAI,GAAM,CAAC,EAAG,cAAe,KAEhE,YAAsB,EAAqB,CAChD,GAAM,GAAI,EAAI,OACR,EAAI,GAAY,IAAI,EAAE,eAC5B,MAAO,IAEH,GAAE,OAAS,EACX,EACA,EAAE,cAAc,QAAQ,gBAAiB,GAAK,EAAE,gBAKtD,YAAgB,CAAhB,aAvCA,CAwCW,gBAAa,CACpB,KACA,SACA,KACA,UACA,WACA,OACA,cACA,UACA,OACA,WACA,cACA,cACA,SACA,OACA,QACA,UACA,MACA,gBACA,MACA,UACA,QACA,WACA,eACA,aACA,WACA,KAAK,KAEE,kBAAe,eAEf,2BAAwB,GAAI,QACnC,GAAG,KAAK,kBAAkB,KAAK,cAAc,KAAK,gBAClD,KAGO,4BAAyB,CAEhC,kBAEA,oBAEA,oBAKO,qBAAkC,CACzC,CAAC,UAAW,SACZ,CACE,2EACA,aAEF,CAAC,qBAAsB,oBACvB,CAAC,oBAAqB,aACtB,CAAC,YAAa,oBACd,CAAC,aAAc,aACf,CAAC,WAAY,aACb,CAAC,cAAe,aAChB,CAAC,WAAY,cACb,CAAC,cAAe,aAChB,CAAC,cAAe,kBAChB,CAAC,WAAY,mBACb,CAAC,cAAe,aAChB,CAAC,cAAe,kBAChB,CAAC,WAAY,aACb,CAAC,WAAY,cACb,CAAC,WAAY,aACb,CAAC,WAAY,cACb,CAAC,WAAY,eACb,CAAC,+BAAgC,cACjC,CAAC,6BAA8B,eAC/B,CAAC,cAAe,cAChB,CAAC,cAAe,eAChB,CAAC,WAAY,oBACb,CAAC,cAAe,aAChB,CAAC,WAAY,iBACb,CAAC,WAAY,iBACb,CAAC,WAAY,iBACb,CAAC,WAAY,iBACb,CAAC,WAAY,kBAGN,gBAA6B,CAEpC,CAAC,gCAAiC,MAClC,CAAC,6BAA8B,MAC/B,CAAC,+BAAgC,MACjC,CAAC,8CAA+C,MAChD,CAAC,oCAAqC,MACtC,CAAC,cAAe,OAGT,qBAAkC,CAEzC,CAAC,QAAS,OACV,CAAC,SAAU,KACX,CAAC,UAAW,KACZ,CAAC,UAAW,QACZ,CAAC,UAAW,KACZ,CAAC,SAAU,KACX,CAAC,SAAU,MACX,CAAC,SAAU,KACX,CAAC,SAAU,MACX,CAAC,UAAW,KACZ,CAAC,aAAc,SACf,CAAC,UAAW,MACZ,CAAC,aAAc,WAGR,uBAA4C,CACnD,QAAS,KAAK,gBACd,GAAI,KAAK,WACT,QAAS,KAAK,mBAIZ,GAAI,EAAK,IAAM,GAAI,KAElB,YAAc,EAAiC,CACpD,MAAO,GAAY,EAAS,GAC1B,GAAI,GAAY,GAChB,EAAI,GAAW,EAAG,KAAI,uBACtB,EAAI,EAAE,QAAQ,4BAA6B,IAC3C,EAAI,EAAE,QAAQ,UAAW,MACzB,EAAI,GAAa,GACV,IAMX,GAAM,IAAsB,gBAErB,YACL,EACA,EACoB,CACpB,GAAI,EAAM,IAAc,EAAM,GAC5B,OAGF,GAAI,GAAI,GAAY,GAEpB,GAAI,IAAc,UAAW,CAC3B,GAAM,GAAQ,GAAoB,KAAK,GACvC,AAAI,GAAS,MACX,GAAI,EAAM,IAId,GAAM,GAAa,EACjB,KAAI,kBAAkB,GACtB,AAAC,GAAwB,EAAI,KAAK,CAAC,CAAC,KAAQ,EAAG,MAAM,IAAO,OAG9D,GAAI,GAAc,KAChB,MAAO,GAAW,GAAG,OAGvB,AAAI,IAAc,QAChB,GAAI,EACD,QAAQ,8BAA+B,UACvC,QAAQ,OAAQ,MAChB,QAAQ,MAAO,OACf,QAAQ,MAAO,QACf,QAAQ,MAAO,OACf,QAAQ,MAAO,MACf,QAAQ,MAAO,OACf,QAAQ,MAAO,QACf,QAAQ,MAAO,SACf,QAAQ,MAAO,OACf,QAAQ,OAAQ,MAChB,QAAQ,OAAQ,QAGjB,IAAc,WAEhB,GAAI,EACF,uBAAuB,KAAK,GAC5B,GAAS,GAAG,EAAM,WAAW,EAAM,KACnC,IAAM,IAIN,IAAc,SAEhB,GAAI,EAAE,QAAQ,cAAe,IAAI,QAAQ,aAAc,cAGzD,OAAW,KAAM,MAAI,uBACnB,EAAI,GAAW,EAAI,GAAI,OAIzB,SAAI,EAAE,QAAQ,GAAI,QAAO,IAAI,GAAa,SAAkB,KAAM,IAGhE,EAAW,MAAM,0BAA4B,MAC7C,EAAE,MAAM,WAAa,MAGrB,GAAI,EAAE,MAAM,GAAG,QAEV,ECtOT,GAAM,IAAY,sBAElB,YAAkB,EAAgC,CAChD,MAAO,GAAI,OAAO,GACT,EAAS,IAAO,GAAU,KAAK,IAAO,MAUjD,GAAM,IAAS,EAAK,IAAM,EAAS,kBAE5B,YAA8B,EAQjB,CAClB,GAAM,GAAW,GAAK,EAAE,UAClB,EAAO,GAAK,EAAE,MACd,EAAQ,GAAS,CAAC,EAAU,EAAE,SAAU,EAAM,EAAE,OAEhD,EAAe,AAAC,GACpB,GAAQ,GAAoB,GACrB,EAAM,OACX,CAAC,EAAM,IAAS,GAAsB,EAAM,GAAM,OAClD,IAgBE,EAAW,GACf,CAAC,EAAE,SAAU,EAAE,SAAU,EAAE,UAAW,EAAE,QACxC,IAGI,EAAa,EAAQ,CAAC,EAAE,OAAQ,EAAE,UAAW,EAAE,SAAU,EAAE,WAEjE,KAAS,MAAM,uBAAwB,CAAE,WAAU,WAAU,eAE7D,OAAW,KAAa,GAAY,CAClC,GAAM,GAAuB,GAAsB,IAAc,KAGjE,GAFA,KAAS,MAAM,uBAAwB,CAAE,YAAW,yBAEhD,EAAC,EACL,IAAI,EAAS,GACX,MAAO,CACL,WACA,UAAW,EAAa,GACxB,YAIJ,GAAI,EAAU,cAAc,SAAS,UACnC,MAAO,CACL,SAAU,QACV,UAAW,EAAa,GACxB,YAGJ,OAAW,KAAO,GAAc,CAC9B,EACA,EACA,GAAG,EAAS,UAAU,SAEtB,GAAI,EAAU,cAAc,SAAS,EAAI,eACvC,SAAM,QAAQ,GACP,CACL,SAAU,EACV,UAAW,EAAa,GACxB,cASH,YAA+B,EAAiC,CACrE,GAAI,EAAM,IAAM,EAAI,GAAG,cAAc,SAAS,WAAY,OAC1D,GAAM,GAAQ,GACZ,EAAE,QAAQ,yDAA0D,KAEhE,EAAS,YAAY,KAAK,KAAS,GACnC,EAAW,aAAa,KAAK,KAAS,GAC5C,GAAI,MAAW,OAAS,IAAa,OACrC,MAAO,IAAK,EAAQ,EAAU,CAAC,EAAG,IAAM,GAAG,KAAK,KAG3C,YAA6B,EAAW,EAAc,EAAW,CACtE,MAAO,GAAE,QAAQ,YAAa,GAC5B,EAAM,GAAQ,GAAI,GAAM,OAAO,GAAQ,EAAI,IAAe,IAIvD,YAA4B,EAAuB,CACxD,MAAO,IAAoB,GACxB,QAAQ,eAAgB,CAAC,EAAG,EAAI,IAAO,GAAG,KAAM,KAChD,QAAQ,cAAe,CAAC,EAAG,IAAO,EAAK,MACvC,QAAQ,eAAgB,CAAC,EAAG,IAAO,MAAQ,GC3HzC,YAAiC,EAAwB,CAQ9D,GAAM,GAAM,EAAK,CACf,yBACA,EAAE,aACF,EAAE,cACF,EAAE,MACF,EAAE,KACF,EAAE,WACD,IAAI,GAAM,EAAY,EAAI,GAAK,EAAE,OAAO,cAAc,cAEnD,EAAQ,IAAI,IAA8C,CAC9D,OAAW,KAAa,GAAY,CAClC,GAAM,GAAI,EAAI,EAAE,IAAY,OAC5B,GAAI,EAAS,IAAM,CAAC,EAAI,SAAS,EAAE,cAAc,aAC/C,MAAO,KAMb,MAAO,IAAc,CACnB,MAAO,EAAM,UAAW,QAAS,cACjC,YAAa,EACX,YACA,cACA,mBACA,sB5DgBN,GAAM,IAAS,EAAK,IAAM,EAAS,aAE/B,GAAwB,GAuD5B,aAAoB,CAClB,MAAO,GAAS,sBAAsB,OAAU,MAAY,EAAI,EAAI,GAGtE,GAAM,IAAY,EAAK,IACd,GAAI,IACT,WACA,GAAI,aAAS,CACX,OAAQ,IAAM,EAAS,YACvB,SAAU,KAEV,oBAAqB,EAAI,EACzB,mBAAoB,EAAS,mBAAmB,eAChD,kBAAmB,KAGrB,EAAa,QACb,IACA,GAGG,aAAoB,CACzB,GAAM,GAAK,KACX,MAAO,GAAG,MAAQ,GAAU,UAAY,EAYnC,aAAgC,CACrC,MAAO,GAAI,GAAU,QAAS,GAC5B,EAAG,MACC,OACA,GAAc,EAAG,UAAW,EAAc,IAAM,CAC9C,KAAM,IAAI,OAAM,yBAU1B,GAAa,CAAC,EAAuB,IACnC,EAAQ,GAAW,GAAgB,GAAQ,CACzC,GAAM,GAAO,EAAU,IAAI,GAC3B,MAAO,IAAU,cAAc,EAAK,WAAY,IAC9C,QAAQ,QAAQ,OACX,GADW,CAEd,WAAY,EAAK,WACjB,SAAU,EAAK,KACf,UAAW,EAAK,WASjB,YACL,EACA,EACA,EACe,CACf,MAAO,MAAW,iBAAiB,EAAS,EAAK,GAGnD,GAAM,IAAY,GAAI,IAAgC,CACpD,QAAS,IACT,UAAW,IAIA,GAAe,GAAI,IAAiC,CAC/D,QAAS,IACT,UAAW,IAGN,aAA0B,CAC/B,GAAU,QACV,GAAa,QAGf,EAAM,IAAM,EAAa,KAEzB,GAAc,GAAQ,CACpB,AAAI,EAAM,GACR,KAEA,IAAU,SAAS,GAAO,EAAI,WAAW,IACzC,GAAa,SAAS,GAAO,EAAI,WAAW,OAIhD,GAAM,IAAuB,CAC3B,YACA,iBACA,sBACA,iBACA,WACA,kBACA,WACA,WACA,oBACA,WACA,aACA,cAGF,kBAAiC,EAAc,EAAgC,CAC7E,GAAM,GAAc,AAAC,GACnB,EAAQ,GAAY,EAAG,IAAQ,GAAM,GAAK,EAAI,GAAG,KAEnD,MACG,MAAM,IAAS,EAAE,QAAQ,MAAO,EAAE,QAAQ,QAC1C,KAAM,IAAS,EAAY,GAAI,EAAY,IAQhD,kBACE,EACwB,CACxB,GAAI,GAAc,KAAM,OACxB,GAAM,GAAI,EAAU,IAAI,GACxB,GAAK,OAAM,GAAE,WAAe,KAAM,GAAE,iBACpC,MAAO,IAAK,gBAAiB,SAC3B,EAAQ,GAAY,GAAI,GAAM,GAAU,EAAG,KAI/C,kBACE,EACwB,CACxB,MAAO,IAAU,IAAI,OAAO,IAW9B,kBACE,EACsB,CACtB,GAAI,EAAM,GAAa,OACvB,GAAM,GAAI,EAAU,IAAI,GACxB,MAAO,IACL,IAAM,EAAQ,GAAa,IAAI,EAAE,YAAa,GAAM,EAAG,UACvD,IAAM,EAAQ,GAAW,GAAI,GAAM,EAAG,UACtC,IACE,EAAQ,GAAa,EAAE,YAAa,GAElC,EAAG,OAAS,aAAe,OAAY,EAAG,MAG9C,IACE,GAAU,EAAE,KACR,EAAQ,GAAY,EAAG,IAAQ,GAAM,EAAG,UACxC,QAuBV,kBACE,EACA,EACwB,CACxB,GAAM,GAAI,EAAU,IAAI,GAGlB,EACJ,GAAe,MAAQ,EAAM,EAAY,aACrC,KAAM,IAAY,GAClB,EACN,GAAI,GAAK,KAAM,OAIf,GAAM,GAAM,EAAO,GAAgB,GAAc,IAAM,GAAgB,IAGjE,EAAK,GAAiB,EAAE,UAC1B,KAAM,IAAQ,GAAG,MAAM,GAAO,CAC5B,KAAS,KAAK,0BAA2B,CACvC,KAAM,EAAE,WACR,IAAK,GAAS,OAIlB,OAEE,EAAK,GAAgB,EAAG,EAAK,GACnC,GAAI,GAAM,KAAM,MAAO,GAEvB,GAAI,GAAgB,EAAE,UACpB,MAAO,GAAQ,GAAkB,EAAG,EAAE,UAAY,GAAM,GAAS,EAAI,IAmBzE,kBAAoC,EAAgB,CAClD,KAAM,MAAW,cAAc,EAAI,YACnC,KAAM,GAAI,QAAQ,EAAI,KAAO,aAAa,OAAO,SAmCnD,kBACE,EACA,EAAkB,GACsB,CACxC,GAAM,GAAK,EAAU,IAAI,GACzB,GAAI,EAAE,KAAM,GAAG,SAEf,MAAO,IAAK,mBAAoB,SAAY,CAC1C,GAAM,GAAW,KAAM,IAAa,EAAG,YACvC,GAAI,GAAY,MAAQ,CAAC,EAAiB,MAAO,GAEjD,GAAM,GAAY,GAAoB,EAAG,eAAgB,IACnD,EAAe,GAAoB,EAAG,WAAY,GACtD,GAAa,EAAG,aAGZ,EAAmC,KACpC,GAGL,OAAW,CAAC,EAAa,IAAY,CACnC,GAAI,KAAM,GACV,GAAI,KAAM,IACT,CACD,GAAM,GAAW,GAAK,EAAa,GAAG,IACtC,AAAI,EAAW,GAAO,IAClB,IAAO,UAAP,GAAO,SAAa,KAAI,KAAK,EAAQ,MACvC,GAAa,EAAQ,GACrB,KAAS,MAAM,mCAAoC,CACjD,QAAS,EAAQ,KACjB,cAGF,KAAS,MAAM,kCAAmC,CAChD,QAAS,EAAQ,OAIvB,MAAO,KAMX,GAAM,IAAe,GAAI,IACnB,GAAgB,GAAI,IAE1B,AAAK,GACE,IAAa,UACb,GAAc,WAMrB,kBAA4B,EAAoB,CAG9C,MAAO,IAAa,cAAc,EAAY,SAAY,CACxD,KAAS,MAAM,gBAAkB,EAAa,8BAE9C,GAAM,GAAW,GAAa,QAC9B,AAAI,EACG,GAAa,UAElB,KAAM,IAAc,QAKtB,GAAM,GAAO,GAAW,eAAQ,IAAe,GAAK,OAE9C,EAAS,KAAM,IAAK,kBAAmB,IAC3C,GACE,GACE,KACG,KAAK,EAAY,GACjB,MAAM,GAAO,CACZ,KAAS,KAAK,kBAAoB,EAAY,MAIpD,IAGJ,MAAI,IACG,GAAc,UAEd,EAAI,EAAQ,GACjB,MAAS,MACP,gBAAkB,EAAa,QAAU,EAAG,UAAY,MAEnD,EAAI,EAAG,OAAQ,GAAK,CAEzB,OAAW,KAAO,IAAK,GAAI,CACzB,GAAM,GAAI,EAAE,GACZ,GAAI,MAAO,IAAM,SAAU,CACzB,GAAM,GAAK,GAAiB,GAC5B,AAAI,GAAM,MAAM,GAAE,GAAO,IAG7B,GAAM,GAAW,EACf,CAAC,EAAE,MAAO,GAAG,EAAO,EAAE,OAAQ,IAAK,EAAE,SAAS,IAAI,IAEpD,MAAI,GAAW,IACb,GAAE,SAAc,GAElB,EAAE,WAAgB,EAAG,UACjB,IAAuB,GAAE,SAAc,MACpC,QASf,kBACE,EACA,EACwB,CACxB,GAAI,GAAK,KAAM,OAEf,GAAM,GAAI,EAAE,SACN,EAAa,EAAE,WAErB,GAAI,EAAM,GAAI,CACZ,KAAS,MAAM,mBAAqB,GACpC,OAGF,GAAM,GACJ,EAAE,WAAW,WAAW,EAAS,SAAS,iBAC1C,EAAE,UAAU,SAAS,mBAEvB,AAAK,GACH,KAAM,IAAkB,EAAG,GAK7B,GAAM,GAAI,EAKV,EAAE,aAAe,EAAE,KACnB,EAAE,cAAgB,EAAE,MAEpB,EAAE,KAAO,GAAK,EAAE,MAChB,EAAE,MAAQ,GAAM,EAAE,KAAM,EAAE,OAE1B,GAAM,GAAgB,GAAqB,GAErC,EAAc,KAAM,IAAkB,EAAG,EAAG,GAClD,GAAI,GAAe,KAAM,CACvB,KAAS,KAAK,qBAAuB,GACrC,OAEF,GAAM,GAAmB,GAAwB,GAE3C,EAAK,KAAM,IAAS,EAAG,GAC7B,GAAI,GAAM,KAAM,CACd,KAAS,KAAK,oBAAsB,GACpC,OAGF,GAAM,GAAW,EAAE,WAAW,UAAY,GAAmB,GAAK,OAE5D,EAAM,SACV,SAAU,EACV,oBACG,GAAwB,IACxB,GACA,GALO,CAMV,WACA,WAAY,EAEZ,GAAI,EAAE,KAGR,YAAS,MAAM,aAAc,KAC3B,cACG,GAFwB,CAI3B,WAAY,EAAI,EAAa,GAAO,EAClC,KAAM,EAAG,KACT,IAAK,EAAG,UAIL,OACF,GACA,G6DhlBP,OAAwC,uBASxC,kBACE,EACA,EAAmB,EACnB,EACA,CACA,GAAI,GAAK,GACT,GAAI,CACF,GAAM,GAAS,KAAM,GACnB,EACA,IAAM,EAAQ,YAAK,GAAa,GAAM,EAAG,KAAO,IAE5C,EAAI,OAAO,MAAM,GACvB,SAAK,KAAM,YAAK,EAAY,KACrB,KAAM,YAAK,EAAI,EAAG,EAAG,EAAQ,UACpC,CACA,KAAM,IAAQ,EAAI,W9DRtB,EAAM,IAAM,CACV,EAAa,IAAM,GAAM,SAAS,SAClC,GAAc,GACZ,GAAM,KAAO,GAAM,SAAS,QAAU,GAAM,SAAS,OAAO,MAIhE,GAAM,IAAQ,EACZ,IAAM,GAAI,IAAwC,IAAK,EAAI,IAG7D,kBACE,EAC8B,CAE9B,MAAO,MAAQ,SAAS,EAAY,SAAY,CAE9C,GAAM,CAAE,UAAW,KAAM,IAAa,EAAY,EAAG,KACrD,MAAO,IAAQ,kBAAW,IACvB,OAAO,GAAM,EAAG,OAAS,cACzB,OAAO,IACN,GAAQ,GAAS,YAAK,KACnB,OAAO,GAAM,GACb,QAAQ,IAAM,KAAW,QAAQ,EAAY,CAAC,eAC9C,QAAQ,GAAK,EAAE,UACf,OAAO,GACP,IACC,GAAS,EAAE,IAAK,GAAW,GAAa,UAEzC,OAEJ,QAIP,YAAoB,EAAoB,CACtC,MAAO,IAAY,eAAQ,GAAa,K+D7B1C,GAAM,KAAgB,iBAEhB,GAAS,EAAK,IAAM,EAAS,aAEtB,GAAe,WAM5B,mBAAoC,CAClC,MAAO,MACJ,KAAK,IACL,UACA,MAAM,GAAO,CACZ,EAAQ,sCAAwC,GAAgB,KAetE,kBACE,EACA,EACA,EACoB,CACpB,GAAM,GAAO,KAAM,GAAI,OACvB,GAAI,GAAQ,KACV,KAAM,IAAI,OAAM,iBAAiB,kBAEnC,GAAM,GAAM,KAAM,MAClB,GAAI,GAAO,KAAM,KAAM,IAAI,OAAM,2BAKjC,GAAM,GAAK,KAAM,IAAa,EAAI,YAClC,GAAI,GAAM,KAAM,KAAM,IAAI,OAAM,4BAA8B,GAS9D,GAAM,GAAM,GACV,EAAU,CACR,SAAU,EAAI,KAAK,cACnB,SAAU,EAAG,KACb,KAAM,EAAK,QAIf,EAAM,GAAa,EAAK,KAExB,GAAM,GAAS,EAAI,KAAK,GAAG,GAAW,EAAI,MAAM,EAAG,IAAK,EAAG,GAAI,EAAO,GACtE,GAAI,AAAS,KAAM,GAAO,SAAS,UAA/B,KACF,KAAM,IAAI,OAAM,yBAA2B,EAAO,UAEpD,YAAS,MAAM,iBAAmB,EAAI,oBAAsB,IAAK,CAC/D,OACA,MACA,WAEK,EAST,kBAAqC,CACnC,MACA,OACA,SACA,KAM0B,CAC1B,GAAI,CACF,MAAO,MAAM,GAAQ,GAAc,EAAK,EAAM,GAAS,GACrD,EAAK,cAAc,KAAM,IACvB,EAAQ,IAAK,GAAY,EAAI,aAAa,YAGvC,EAAP,CACA,KAAM,IAAI,IAAa,CAAE,QAAO,QAAS,6BCnH7C,kBACE,EACA,EACY,CACZ,GAAM,GAAQ,KAAK,MACf,EAAU,EACR,EAAY,EAAQ,EAAS,YAAY,eAC/C,KAAO,KAAK,MAAQ,GAClB,GAAI,CACF,MAAO,MAAM,WACN,EAAP,CACA,GAAI,CAAC,GAAkB,IAAQ,KAAK,OAAS,EAC3C,KAAM,GAEN,MAEA,KAAM,IAAM,GAAU,IAAK,MAAQ,EAAE,GAI3C,KAAM,IAAI,OACR,oCACE,EAAS,YAAY,eACrB,MAIC,YAAgC,EAAY,EAAY,GAAO,CACpE,GAAI,GACJ,OAAS,GAAQ,EAAG,EAAQ,EAAW,IACrC,GAAI,CACF,MAAO,WACA,EAAP,CAEA,GADA,EAAY,EACR,CAAC,GAAkB,GACrB,KAAM,GAIZ,KAAM,GC5CR,GAAM,IAAS,EAAK,IAAM,EAAS,gBAEzB,GAAV,UAAU,EAAV,CACS,AAAM,YAAY,MAAO,EAAe,IAC7C,MAAS,KAAK,0BAA2B,CAAE,QAAO,SAC3C,MAHD,aAOH,GAAM,IAA+B,GCF5C,GAAI,IAAkC,GAE/B,YAAwB,EAAgB,CAC7C,GAAqB,EAGhB,YAA+B,EAAgB,CACpD,AAAI,KAAuB,IAAiB,IAAqB,GAG5D,YAAmB,EAAc,EAAY,CAClD,GAAmB,UAAU,EAAO,GCtBtC,OAAiC,uBACjC,GAAyB,iBACzB,GAAoB,sBAiDb,GAAM,IAAwB,EAAK,SAAY,CACpD,GAAI,EAAS,UAAU,eAAgB,CACrC,GAAM,GAAM,KACZ,AAAI,GAAO,MACT,KAAM,IACJ,SACE,QAAQ,IAAI,EAAI,KAAM,IAAc,IAAM,IAAI,GAAM,EAAG,WACzD,EAAI,MAMC,GAAU,GAKvB,YAAqB,EAAuB,CAC1C,MAAO,GAAI,EAAK,GAAM,EAAG,KAAK,cAIzB,YAAuB,EAAuB,CAGnD,MAAO,AAFK,IAAY,IAEZ,QAAQ,SAAS,GAAM,EAAG,MAAQ,SAGhD,mBAAoC,CAClC,MAAO,GACL,KACA,KAAM,IACJ,GACE,GAAwB,GACxB,KACA,WACA,OAEJ,SAAY,IAIT,GAAM,IAAe,EAAK,SAAa,EAC5C,SAAU,kBACV,cAGW,GAA0B,GACrC,AAAC,GAAmB,GAAyB,GAC7C,CACE,QAAS,EACT,UAAW,EAEX,aAAc,GAAU,EAAI,EAAU,KAI1C,kBAAwC,EAAgB,CACtD,KAAM,MACN,GAAM,GAAe,CAAC,KAChB,EAAI,EAAS,2BAA6B,EAAM,KAChD,EAAe,kBACf,EAAW,KAAM,IAAc,GACrC,GAAI,EAAQ,GAAW,CACrB,EAAE,KAAK,6BACP,OAEF,GAAM,GAAQ,KAAM,IAClB,EAAS,IAAI,KAAM,KAAQ,CACzB,GAAM,IAAO,KAAM,IAAK,WACxB,GACE,GACA,IAAQ,MACR,AAAU,KAAM,IAAK,gBAAgB,KAAK,MAAO,KAAjD,GACA,CACA,EAAE,KAAK,kCAAoC,IAC3C,KAAM,IAAK,OAAO,SAClB,WAEA,OAAO,IAAE,SAAS,OAKxB,EAAE,MAAM,OAAQ,CAAE,UAElB,GAAM,GAAe,KAAK,MAAQ,GAE5B,CAAC,EAAY,GAAc,GAC/B,EACA,IAAM,GAAG,UAAY,GAEvB,AAAI,GAAgB,EAAW,IAC7B,GAAE,MAAM,qCAAsC,CAC5C,eACA,eAEF,KAAM,SAAQ,IAAI,EAAW,IAAI,IAAM,GAAG,MAAM,OAAO,YAGzD,GAAM,CAAC,EAAY,GAAiB,GAClC,EACA,IAAM,GAAG,WAAa,GAGlB,EAAY,EAAW,IAAI,IAAM,GAAG,KAGpC,EAAY,EAAO,KAAM,IAAa,GAAY,GAElD,CAAC,EAAiB,GAAoB,GAAU,EAAY,IAChE,EAAU,SAAS,GAAG,MAGxB,AAAI,GAAgB,EAAW,IAC7B,GAAE,MAAM,oCAAqC,GAC7C,KAAM,SAAQ,IAAI,EAAiB,IAAI,IAAM,GAAG,MAAM,YAGxD,GAAM,IAAa,CAAC,GAAG,EAAiB,GAAG,GAC3C,GAAI,EAAQ,IAAa,CACvB,EAAE,MAAM,6BACR,OAGF,GAAM,IAAe,GAAQ,GAAY,IAAM,GAAG,WAC5C,GAAmB,GAAW,OAClC,IAAM,GAAG,YAAc,GAAa,WAGhC,EAAS,GAAQ,GAAkB,IAAM,CAC7C,GAAiB,GAAG,aACpB,EAAO,GAAG,UAAW,IAAM,KAAK,SAElC,MAAO,GAAE,IAAI,CAAE,IAAK,0BAA2B,MAAO,OAAQ,WAGhE,EAAa,IAAM,GAAwB,SAepC,oBAAyB,GAAe,CAU7C,YAAqB,EAAgB,CACnC,MAAM,eAAgB,IAAM,KAAK,QAAS,EAAa,QADpC,WATJ,eAAY,KAAK,MAGjB,cAAwB,GAChC,gBAAa,GAAU,EA2CvB,UAAO,EAAK,IACnB,KAAK,IAAI,KAAK,GAAiB,kBAAY,GAAK,IAAM,OAAM,UAIrD,UAAO,EACd,SAAa,GACX,YAAa,KACb,UAAW,KAAK,UAChB,UAAW,KAAK,OACZ,KAAM,OAEZ,KAAK,WAAa,GAGX,YAAS,EAAK,SAAY,CACjC,GAAM,GAAO,KAAM,MAAK,OACxB,KAAM,MAAK,OAAO,WAAW,GAC7B,GAAwB,SACvB,KAAK,WAAa,GAGZ,WAAQ,EAAK,SAAY,CAEhC,GADA,KAAM,MAAK,SACP,KACF,OAAW,KAAK,MAAK,OAAO,eAAe,GACzC,GAAI,CAEF,GAAM,GAAI,aACR,EAAE,WACF,CAAE,WAAY,GAAO,UAAW,IAChC,IAAM,KAAK,UAAU,WACrB,GAAG,QAAS,GACZ,MAAK,OAAO,KAAK,qBAAsB,GAChC,KAAK,UAAU,YAExB,KAAK,SAAS,KAAK,SACZ,EAAP,CACA,KAAK,OAAO,KAAK,yBAA0B,CAAE,EAAG,EAAE,WAAY,WAM7D,eAAY,EAAK,SAAY,CACpC,GAAI,KACJ,YAAM,MAAK,QACJ,GAAwB,KAAK,MACnC,EAAI,GApFL,KAAK,IAAM,EAAI,KAAK,aAGpB,KAAK,MAAQ,GAAiB,IAAM,KAAK,SAAU,KAAK,YAG1D,OAAQ,CACN,KAAK,KAAK,QACV,KAAK,KAAK,QACV,KAAK,UAAU,QACf,KAAK,OAAO,QAGd,UAAW,CACT,YAAK,QACE,KAAK,cAGA,QAAQ,CACpB,KAAK,SAAS,QAAQ,GAAM,EAAG,SAC/B,KAAK,SAAS,OAAS,EACvB,EAAI,KAAK,MAAO,eAChB,KAAK,MAAQ,OACb,KAAM,MAAK,OAAO,cAGd,gBAAe,EAAY,GAAO,CACtC,AAAI,EACF,KAAM,MAAK,IAAI,OAEf,KAAM,MAAK,IAAI,iBAAiB,GAC9B,EAAG,IAAI,KAAK,QAAU,OAAY,EAAG,eAuDrC,cAAgC,CAEpC,MAAO,IAAe,KAAK,YAAa,KAAgB,WAAY,YAGhE,oBAAmB,EAAW,CAClC,KAAK,OAAO,MAAM,qBAAsB,CAAE,SAE1C,GAAM,GAAK,KAAM,MAAK,YAGtB,GAFA,KAAK,OAAO,MAAM,qBAAsB,CAAE,OAAM,UAAW,IAEvD,GAAM,KAAM,OAEhB,GAAM,GAAO,KAAM,MAAK,OAGxB,GAFA,KAAK,OAAO,MAAM,qBAAsB,CAAE,OAAM,SAE5C,GAAM,MAAQ,EAAG,WAAa,EAAK,SACrC,WAAK,OAAO,KAAK,yBAA0B,CAAE,UAAW,EAAI,SACtD,GAAI,OACR,gCAAgC,EAAG,aAAa,EAAG,eAAe,EAAG,QAAQ,IAG1E,MAAiB,GAAK,IACvB,GACA,MCtUV,OAAgB,kBCAhB,OAAoB,sBCApB,OAAyB,iBACzB,GAAoB,sBAKpB,GAAI,IAAI,EAEF,GAAY,EAChB,IAAM,GAAe,kBAAa,OAAO,aAAa,IAAM,QAAO,KAW9D,aAAuB,CAC5B,MAAO,MAAc,GAAS,OAAO,EAAE,ICrBzC,OAAwB,mBAWjB,YAAyB,CAK9B,YACW,EACA,EACA,EACA,EACT,CAJS,UACA,cACA,cACA,aAPF,WAAQ,KAAK,MASpB,KAAK,KAAO,uBAAyB,EAAS,KAAO,EACrD,KAAK,EAAI,GAAI,IAAY,KAAK,OAG/B,WAAQ,SAAU,CACjB,MAAO,CACL,KAAM,kBACN,GAAI,KAAK,GACT,OAAQ,KAAK,OACb,OAAQ,KAAK,OACb,SAAU,KAAK,MAIf,UAAmB,CACrB,MAAO,MAAK,EAAE,QAGhB,WAAW,EAAmB,CAC5B,KAAK,EAAE,WAAW,GAGpB,QAAQ,EAAS,CACf,AAAI,KAAK,EAAE,SACT,MAAK,EAAE,QAAQ,GACf,EAAI,KAAK,EAAE,UAAW,GAAM,KAAK,MAAM,KAAK,KAAK,OAAQ,KAI7D,OAAO,EAAc,CACnB,MAAO,MAAK,EAAE,OAAO,MAGnB,WAAoB,CACtB,MAAO,MAAK,EAAE,YAGZ,WAAuB,CACzB,MAAO,MAAK,EAAE,UFnClB,GAAM,IAAqB,IAAS,EAAI,IAAM,EACxC,GAA6B,GAAS,IAAM,EAAI,EAShD,GAA0B,CAC9B,WAAY,GACZ,kBAAmB,EACnB,oBAAqB,GACrB,mBAAoB,IAIlB,GAAgB,EAKb,gBAAqB,GAAe,CAQzC,YACE,EACS,EACT,EAA4B,GAC5B,CACA,MACE,cAAgB,EAAO,IAAM,KAAkB,IAC/C,IAAM,KAAK,QACX,EAAa,OANN,qBARF,kBAAe,GAAI,IAAK,GAChB,aAAU,GAAI,KACtB,WAAQ,GAAI,IAEZ,qBAAiC,CAAC,IAAM,KAAK,aAAa,WA+C1D,YAAS,EAA2B,SAAY,CACvD,GAAI,CACF,GAAI,KAAK,SACP,MAAO,MAAK,QACV,+CACE,KAAK,aAAa,gBAClB,KAGN,GAAM,GAAI,KAAM,MAAK,gBACrB,MAAI,IAAK,KACA,KAAK,QAAQ,iCAEtB,MAAK,gBAAgB,QAAQ,GAAM,KACnC,EAAE,GAAG,MAAO,AAAC,GAAa,KAAK,SAAS,UAAW,IACnD,EAAE,GAAG,QAAS,AAAC,GAAa,KAAK,SAAS,YAAa,IACvD,EAAE,GAAG,QAAS,GAAO,KAAK,QAAQ,eAAgB,IAC7C,GAAc,EAAG;AAAA,EAAM,GAAO,KAAK,OAAO,IACxC,SACA,EAAP,CACA,MAAO,MAAK,QAAQ,0BAA2B,MAI1C,UAAO,EACd,IAAM,KAAK,QAAQ,OAAQ,CAAE,YAAa,KAAe,aACzD,KA7DA,KAAK,KAAO,OAAK,IAAgB,GAE5B,KAAK,SAGJ,OAAQ,CACd,YAAK,OAAO,KAAK,QAAS,CACxB,OAAQ,IACR,QAAS,KAAK,MAAM,SACpB,YAAa,KAAK,QAAQ,OAE5B,KAAK,QAAQ,QACN,KAAK,QAGd,kBAAkB,EAAqB,CACrC,KAAK,gBAAgB,KAAK,MAGxB,WAAW,CACb,MAAO,MAAK,OAAO,IAAI,CACrB,MAAO,GAAS,QAAU,QAC1B,IAAK,aACL,OAEE,KAAK,aAAa,iBAAmB,KAAK,KAAK,qBAE/C,GAAG,KAAK,aAAa,gBAAiB,GACxC,KAAM,CACJ,kBAAmB,KAAK,aAAa,iBACrC,mBAAoB,KAAK,aAAa,mBAqC5C,UAAU,EAAc,EAAW,CACjC,MAAO,MAAK,QAAQ,YAAa,CAAE,QAAO,SAG5C,gBAAiB,CACf,MAAO,MAAK,QAAQ,uBAOhB,QAA0B,CAC9B,MAAI,MAAK,MACP,MAAK,OAAO,MAAM,0BACX,IAEF,AAAS,KAAM,MAAK,UAApB,UAMH,SAAQ,EAAgB,EAA4B,CACxD,GAAI,KAAK,MAAO,CACd,GAAI,IAAU,OACT,KAAM,IAAI,OAAM,oBAEvB,GAAI,EAAM,GACR,KAAM,IAAI,OAAM,0BAElB,MAAO,MAAK,OAAO,EAAQ,QAWf,QAAO,EAAgB,EAAc,CACjD,GAAM,GAAI,KAAM,MAAK,SACrB,GAAI,GAAK,KACP,MAAO,MAAK,QAAQ,UAAY,EAAS,uBAE3C,GAAM,GAAK,KACL,EAAK,GAAI,IAAgB,EAAI,EAAQ,EAAQ,KAAK,OACxD,SAAG,WAAW,KAAK,KAAK,YACxB,KAAK,QAAQ,IAAI,EAAI,GACrB,EAAG,EAAE,QAAQ,IAAM,KAAK,QAAQ,OAAO,IACvC,KAAK,OAAO,IAAI,GAAS,QAAU,QAAS,kBAAmB,CAC7D,KACA,SACA,WAEF,EAAE,MACA,EAAU,CACR,KACA,SACA,WACG;AAAA,GAEA,EAAG,SAOZ,OAAQ,CACN,YAAK,OAAO,KAAK,UAAW,CAAE,MAAO,KAAK,QACnC,EAAQ,KAAK,OAAO,QAAS,IAG9B,OAAO,EAAa,CAC1B,GAAI,GAAM,GAGV,GAAI,CACF,KAAK,OAAO,IAAI,GAAS,QAAU,QAAS,WAAY,CAAE,QAC1D,GAAM,GAAO,KAAK,MAAM,GACxB,GAAI,EAAM,EAAK,KACb,KAAM,IAAI,OAAM,iCAElB,GAAI,KAAK,MAAQ,EAAK,KAChB,MAAK,KAAO,MACd,MAAK,OAAO,KAAK,oBAAqB,CACpC,SAAU,KAAK,IACf,OAAQ,EAAK,MAEf,GAAa,KAAK,oBAEpB,KAAK,IAAM,EAAK,IACZ,KAAU,OAEhB,GAAI,EAAK,IAAM,KACb,GAAI,EAAS,EAAK,OAAQ,CAGxB,KAAK,OAAO,MAAM,wBAAyB,GAC3C,GAAa,KAAK,EAAK,MAAO,EAAK,MACnC,WAEA,MAAM,IAAI,OAAM,oCAGpB,GAAM,GAAK,KAAK,QAAQ,IAAI,EAAK,IACjC,KAAK,QAAQ,OAAO,EAAK,IACzB,AAAI,GAAM,KACR,KAAK,OAAO,KAAK,8BAA+B,CAC9C,OACA,WAAY,CAAC,GAAG,KAAK,QAAQ,UAG/B,AAAI,EAAK,OAAS,KAChB,GAAG,OAAO,EAAK,OACf,KAAK,OAAO,KAAK,WAAY,CAAE,OAAM,QAErC,GAAG,QAAQ,EAAK,QAChB,KAAK,OAAO,MAAM,WAAY,EAAK,eAKhC,EAAP,CACA,KAAK,OAAO,KAAK,kBAAoB,EAAK,SAKhC,SAAQ,EAAgB,EAAW,CAC/C,YAAK,OAAO,KACV,EAAS,eAAiB,EAAI,EAAK,GAAM,EAAO,EAAG,MAAO,KAErD,KAAK,eAGR,UAAgC,CAQpC,GAPA,KAAK,OAAO,KAAK,YAAa,CAC5B,MAAO,KAAK,MACZ,SAAU,KAAK,WAGjB,KAAM,MAAK,QAEP,KAAK,OAAS,IAAU,CAC1B,KAAK,OAAO,KAAK,gDACjB,OAGF,GAAI,KAAK,SAAU,CACjB,KAAK,OAAO,KACV,2EACA,CAAE,UAAW,KAAK,aAAa,kBAEjC,OAGF,GAAM,GAAS,KAAM,MAAK,SAE1B,GAAI,AAAQ,GAAR,KAAgB,CAClB,GAAM,GAAU,CAAC,GAAG,KAAK,QAAQ,UACjC,YAAK,QAAQ,QACb,KAAK,OAAO,KACV,6CACE,EAAQ,OACR,cAEJ,EAAQ,QAAQ,GAAM,EAAG,OAAO,aAAe,KACxC,MACF,CACL,KAAK,OAAO,KAAK,qCACjB,QAII,SAAS,EAAgB,EAAY,CAC3C,GAAI,KAAK,MAAO,OAEhB,GAAM,GAAa,GAAS,MAAQ,IAAU,GAC9C,YAAK,OAAO,KAAK,WAAY,CAAE,SAAQ,QAAO,eACvC,EAAa,KAAK,UAAY,KAAK,QAAQ,EAAQ,KD5S9D,GAAM,IAAS,EAAS,aAExB,YAAiB,EAAmC,CAClD,GAAM,GAAI,GAAI,IACR,EAAS,GAAI,YAAI,OACvB,SAAO,GAAG,QAAS,GAAO,EAAE,OAAO,IACnC,EAAO,QAAQ,EAAM,YAAa,IAAM,CACtC,GAAO,MAAM,gBAAkB,GAC1B,EAAE,YAEF,EAAE,KAAK,IAAM,GAWf,GAAM,IAAY,EAAgC,IAAM,CAC7D,GAAI,KAAe,OACnB,GAAM,GAAO,EAAS,QAAQ,eAC9B,GAAO,MAAM,8BAAgC,GAC7C,GAAM,GAAI,GAAI,IAAO,gBAAkB,EAAM,IAAM,GAAQ,IAG3D,SAAE,kBAAkB,IAAM,GAAe,SAClC,IAMI,GAAiB,EAAK,SAAY,CAC7C,GAAI,CACF,GAAI,KAAe,MAAO,GAC1B,GAAM,GAAO,KAAM,IACjB,EAAI,KAAa,GAAM,EAAG,QAC1B,GAEF,MAAO,GAAS,SACT,EAAP,CACA,UAAO,KAAK,gCAAiC,GACtC,KAER,GInDH,GAAI,IAEE,GAAS,EAAK,IAAM,EAAS,WAE5B,YAAqB,EAAS,CACnC,MAAO,IAAM,MAAQ,EAAG,SAAW,SAC/B,EAAO,IAEP,GAGN,GAAM,IAAe,KAAO,IAAmB,CAC7C,AAAI,MAAO,IAAU,WACnB,KAAS,MAAM,gCAAiC,CAAE,UAEpD,KAAS,MAAM,iBAAkB,CAAE,UACnC,GAAa,GAGf,GAAY,IAEZ,mBAA6C,CAC3C,MAAO,GAAQ,MAAa,QAAQ,eAAgB,GAClD,MAAS,KAAK,4CAA6C,CAAE,UACtD,EAAI,EAAO,MAItB,kBAAyC,EAAsC,CAC7E,GAAI,CAAE,KAAM,MAAgB,CAC1B,KAAS,KAAK,qDACd,OAEF,KAAS,KAAK,yBACd,GAAI,CACF,UAAa,GACb,GAAU,YAAa,IAChB,KAAM,YACb,CACA,GAAa,GACb,GAAU,YAAa,IACvB,KAAS,KAAK,wBCpClB,GAAM,IAAS,EAAK,IAAM,EAAS,iBAE7B,GAAqB,EACrB,GAAa,GAEf,GAAgB,GAEpB,kBACE,EACA,EACA,EAAwB,GACxB,EAA2B,GACf,CACZ,GAAI,EAAG,IAAM,KAAM,KAAM,IAAI,OAAM,iBACnC,GAAI,CACF,MAAI,IAAc,IAAgB,IAE9B,CAAC,GAAmB,GAAY,IAEhC,AACC,KAAM,IAAU,IAAM,CAAC,GAAY,GAAK,CACvC,UAAW,MAFb,MAKA,KAAS,MAAM,yDAIZ,KAAM,IACX,SACS,EAAG,cACN,EAAE,EAAG,IACL,GACE,IACE,EACG,GAAI,YAAY,IAAM,EAAE,EAAG,KAE3B,WACL,EAAG,SAGX,CACE,WAAY,GACZ,iBAAkB,KAAM,IAClB,GAAgB,GAAsB,GAC1C,MAAS,KAAK,qBAAsB,GAChC,GAAkB,IAAQ,GAA0B,GAEtD,GAAG,UACH,KAAS,KAAK,2BAA6B,EAAG,QACvC,IAEF,IAET,UAAW,EAAS,YAAY,eAAiB,GACjD,iBAAkB,GAAc,CAC9B,GAAM,GAAU,GACd,GACA,EAAS,YAAY,eAAkB,IAAa,IAEtD,YAAS,KAAK,qBAAsB,CAAE,aAAY,YAC3C,GAAM,YAIZ,EAAP,CACA,GAAI,GAAgB,GAClB,OAEA,WAAS,KAAK,eAAgB,GACxB,SAER,CACA,AAAI,GAAc,IAAgB,KC1FtC,OAAgD,oBAqBzC,YACL,EACA,EAEA,EAA8B,YAAS,aACvC,CACA,MAAO,IAAa,EAAU,GAC5B,GAAY,EAAQ,GAAO,EAAK,EAAG,UAAU,IACtC,EAAG,eAAe,KAI7B,GAAM,IAAU,gBAET,YAAuB,EAAqC,CACjE,GAAI,GAAM,GACV,MAAO,GACL,YAAS,QACP,EAAI,QAAQ,GAAS,CAAC,EAAG,IAAM,GAC/B,CAAE,QAAS,MAGZ,OAAO,GAAM,EAAG,SAChB,OAAO,IAAM,EAAI,GAAa,QAAQ,GAAM,GAAM,EAAG,OAAO,eAC5D,MAGL,GAAM,IAAa,GAAI,KAEhB,YAAsB,EAAmB,EAAS,QAAiB,CACxE,MAAO,IACL,GACA,EACA,IACE,GAAI,MAAK,eAAe,EAAQ,CAC9B,QAAS,OACT,KAAM,UACN,MAAO,OACP,IAAK,UACL,KAAM,UACN,OAAQ,aAEZ,OAAO,GAAc,IAsBlB,YAAoB,EAAmC,CAC5D,MAAO,GAAI,GAAc,GAAM,IAGjC,GAAM,IAAW,wBAEV,YAA0B,EAAmC,CAClE,MAAO,GAAY,EAAK,GACtB,GACE,IAAM,EAAI,GAAa,QAAQ,GAAI,GAAM,EAAG,YAC5C,IACE,EAAI,EAAE,MAAM,KACT,QAAQ,IAAM,YAAS,QAAQ,IAC/B,OAAO,IACP,IAAI,IAAM,IACV,MACL,IACE,EAAI,YAAS,QAAQ,IAClB,OAAO,IACP,IAAI,IAAM,GACV,QC3FJ,YAAe,EAA0B,CAC9C,GAAM,GAAI,EACV,MAAO,IAAK,KACR,OACA,EAAI,GACJ,EACA,GAAG,EAAE,GAAI,KACT,EAAE,GACF,EAAI,EAAE,SACN,EAAE,QACF,GAAK,EAAE,OACP,EAAE,MACF,OAQC,YAAe,EAAU,EAAmB,CACjD,MAAO,IACL,GAAM,GACN,GAAM,GACN,CAAC,EAAG,IAAM,IAAM,EAChB,IAAM,IC7BH,YAAgB,CAarB,YAAY,EAAW,EAAgB,GAAI,CALlC,WAAgB,GAQvB,GAFA,KAAK,MAAQ,EACb,KAAK,QAAU,GAAM,GACjB,KAAK,SAAW,KAClB,KAAM,IAAI,OAAM,iCAAmC,EAAU,CAAE,cAd5D,YAAY,CACjB,KAAK,eAAiB,KAiBpB,QAAQ,CAEV,MAAO,MAAK,SAAW,MAAQ,KAAK,SAAW,EAGjD,UAAW,CACT,MAAO,MAAK,MAAQ,GAAK,UAAU,KAAK,UAAU,KAAK,QAGzD,WAAY,CACV,MAAO,MAAK,MACR,GACA,CACE,KAAM,KAAK,YAOnB,QAAQ,EAA0B,EAAe,CAE/C,MAAO,QAAQ,KAAK,WAAW,KAAe,IAAQ,KAAK,QAK7D,cAAc,EAAsB,CAElC,MAAO,QAAQ,EAAQ,CAAC,KAAK,QAAS,IAAc,KAAK,cACvD,KAAK,QAIT,UAAU,EAAqB,CAC7B,MAAO,UAAU,KAAK,WAAW,IAAc,KAAK,QAGtD,WAAW,EAAoB,EAAgB,IAAK,CAClD,MAAO,QACF,KAAK,SAAS,KAAM,GAAU,IAD5B,CAIL,MAAO,IAAO,IAAM,OAAS,IAAO,IAAM,QAAU,UAIxD,SACE,EACA,EACA,EACA,EACA,CACA,GAAI,KAAK,MACP,MAAO,CAAE,IAAK,wBAEhB,GAAM,GAAQ,KAAK,IAAI,GAAG,GACpB,EAAsB,CAAE,MAAO,EAAI,IACnC,EAAM,KAAK,QAAQ,EAAS,GAClC,GAAU,iBACV,EAAW,EAAO,EAAU,IAAM,GAAU,eAAiB,IAE7D,AAAI,EACF,GAAM,IAAM,uBACZ,EAAM,YAAc,GAEpB,EAAM,IAAM,EAMV,IAAY,GAAa,IAE3B,GAAM,OAAS,EAAI,IAErB,GAAM,GAAY,EAAO,IAAI,GAAK,GAAS,KAAK,QAAQ,EAAS,GAAI,IACrE,SAAI,EAAI,GAAM,EAAU,KAAK,GAAS,KAAK,gBAAiB,EAAG,SAC/D,EAAO,GAAW,QAAU,IAAM,UAAY,EAAU,KAAK,KACtD,IApGJ,MACU,AADV,GACU,eAAiB,EAuGlC,YAAkB,EAAa,EAAe,CAC5C,MAAO,GAAM,IAAM,EAAQ,IC3GtB,GAAM,IAAkB,IAElB,GAAyB,EAwG/B,GAAM,IAAW,OAAO,OAAO,CACpC,KAAM,OACN,IAAK,MACL,MAAO,QACP,KAAM,OACN,OAAQ,SACR,KAAM,OACN,OAAQ,SACR,SAAU,WACV,KAAM,OACN,GAAI,OAGO,IAAmB,CAC9B,GAAS,KACT,GAAS,OACT,GAAS,KACT,GAAS,KACT,GAAS,ICnHX,GAAM,IAAM,EACV,SACE,GAAI,MAAK,eAAe,KAAM,MAAU,CACtC,MAAO,WAIP,GAAS,EAAK,SAAY,CAC9B,GAAM,GAAI,KAAM,MAGhB,MAAO,IAAM,EAAG,GAAI,GAAK,EAAE,OAAO,GAAI,MAAK,KAAM,EAAG,KAAK,IAAI,GAE3D,GAAY,EAAI,QAIpB,EAAa,IAAM,CACjB,GAAI,QACJ,GAAO,UAGF,YAAuB,EAAsB,CAElD,MAAO,KAAQ,EAGV,YAAwB,EAAiC,CAC9D,MAAO,IAAK,EAGP,YAAwB,EAAiC,CAC9D,MAAO,IAAK,EAGP,YAAsB,EAAiC,CAC5D,MAAO,IAAK,EAGP,YAAoB,EAA6B,CACtD,MAAO,IAAO,EAAM,GAAO,EAAE,KAAM,EAAI,GAAK,QAAS,GAAc,MAGrE,kBACE,EACsB,CACtB,GAAI,EAAC,GAAO,EAAG,GAAI,GACnB,MAAO,GAAK,MAAM,OAAU,EAAkB,GAAI,GAE/C,EACC,KAAM,OAAO,GACb,YAAa,EACb,QAAS,GAAe,MAKvB,YAAmB,EAAmC,CAC3D,MAAO,IAAO,EAAK,GAAO,EAAE,KAAM,EAAI,GAAK,QAAS,GAAa,MAGnE,kBAA8B,EAA2C,CACvE,GAAM,GAAI,EAAI,EAAS,OAAO,gBAAgB,cAE9C,GAAI,GAAQ,MAAQ,IAAM,IAAM,IAAM,OAAS,EAAE,WAAW,WAAY,OAGxE,GAAM,GAAkB,CAAC,GAAS,MAElC,GAAI,EAAE,WAAW,KAAM,CACrB,GAAM,GAAI,EAAI,GAAQ,GAAO,IAC7B,GAAI,GAAK,KAAM,OACf,EAAO,KAAK,GAEd,GAAI,EAAE,WAAW,MAAO,CACtB,GAAM,GAAI,KAAM,GAAI,GAAS,GAAO,IACpC,GAAI,GAAK,KAAM,MAAO,GACtB,EAAO,KAAK,GAEd,GAAI,EAAE,WAAW,OAAQ,CACvB,GAAM,GAAI,EAAI,GAAO,GAAO,IAC5B,GAAI,GAAK,KAAM,MAAO,GACtB,EAAO,KAAK,GAEd,MAAO,GCnFT,GAAM,KAAS,EAAK,IAAM,EAAS,UCAnC,GAAM,KAAS,EAAS,aCLjB,GAAM,IAAS,OAAO,aAAa,IAE7B,GAAU,UAEV,GAAkB,CAC7B,CAAE,KAAM,GAAS,KAAM,QAAS,GAChC,CAAE,KAAM,GAAS,OAAQ,QAAS,GAClC,CAAE,KAAM,GAAS,GAAI,QAAS,GAC9B,CAAE,KAAM,GAAS,IAAK,QAAS,GAG/B,CAAE,KAAM,GAAS,OAAQ,QAAS,GAClC,CAAE,KAAM,GAAS,KAAM,QAAS,GAChC,CAAE,KAAM,GAAS,SAAU,QAAS,GACpC,CAAE,KAAM,GAAS,KAAM,QAAS,IA8C3B,YAAmB,EAAwC,CAChE,MAAO,GAAI,EAAQ,GAAM,EAAO,EAAG,KAAS,EAAI,KAG3C,YAA8B,EAAyB,CAC5D,MAAO,GAAK,IAAI,IAGX,YAAqB,EAAa,EAAO,GAAgB,CAC9D,MAAO,IAAqB,GAAI,KAAK,GAAS,KAAS,GAAS,EAAO,IAGlE,YAA+B,EAAc,CAClD,MAAO,IAAK,GAAa,IAGpB,YAAsB,EAAc,EAAO,GAAkB,CAGlE,MAAO,GAAI,GAAM,MAAM,GAAM,OAAO,GAG/B,YAA0B,EAAsB,CACrD,MAAO,IAAY,GAAa,IC/FlC,OAAwB,mBCuBxB,GAAM,IAAS,EAAK,IAAM,EAAS,oBAI7B,GAAiB,CACrB,GACA,OACA,GACA,IAYK,YAAkB,EAAuC,CAC9D,MAAO,GAAI,EAAG,GACZ,GAAY,EAAG,MAAO,EAAG,OAAQ,CAAC,EAAG,IAAM,GAAU,EAAI,KAItD,YAAmB,EAAW,CAGnC,MAAO,MAAK,MACV,KAAK,IAAI,EAAG,EAAS,yBAAyB,iBAI3C,YAAoB,EAAoB,CAC7C,MAAO,MAAK,MAAM,EAAM,GAAI,IA2BvB,YACL,EACY,CAGZ,OAAW,KAAO,GAAK,EAAM,IAAI,GAAM,EAAG,MAAO,CAC/C,GAAM,GAAU,EAAM,OAAO,GAAM,EAAG,MAAQ,GACxC,EAAW,KAAK,IAAI,GAAG,EAAQ,EAAQ,IAAI,GAAM,EAAG,SAC1D,EAAQ,QAAQ,GAAO,EAAG,MAAQ,GAGpC,GAAM,GAAW,EACf,EAAM,IAAI,GACR,EAAI,GAA0B,GAAI,GAChC,EAAI,GAAe,GAAO,GAAS,EAAE,IAAG,OAAM,aAI9C,EAAS,GAAO,EAAU,CAAC,CAAE,UAAW,GAC9C,MAAO,IAAY,EAAQ,GAAO,EAAI,IAAI,GAAM,EAAG,IAG9C,YAAmC,EAAuB,CAC/D,GAAM,GAAa,GAAS,GAEtB,EAAY,GAAI,MAAM,EAAG,KAE/B,GAAI,EAAM,EAAU,SAAW,EAAM,EAAU,OAAS,EAAG,OAAS,KAAM,CACxE,KAAS,MAAM,wCAAyC,CACtD,KACA,cAEF,OAGF,GAAM,GAAY,GAAe,QAAQ,EAAU,QACnD,GAAI,IAAc,GAAI,CACpB,KAAS,MAAM,wCAAyC,CACtD,KACA,YACA,cAEF,OAGF,GAAM,GAAa,GAAe,EAAU,MAGtC,EAAU,EAAW,KAAK,cAAc,SAAS,SACjD,EAAqB,GAA+B,EAAW,KAC/D,EAAQ,EAAO,GAAc,EAAW,MAAO,GAI/C,EAAQ,GAAW,EAAG,OACtB,EAAW,GAAW,EAAG,SAAU,IACnC,EAAS,CACb,aACA,QACA,YACA,WACA,UACA,QACA,sBAEI,EAAc,GACpB,OAAW,KAAS,GAAS,oBAAoB,OAC/C,EAAI,EAAO,GAAQ,GAAO,EAAO,GAAS,GAE5C,SAAO,IAAM,EAAG,IACT,EAGT,YAAwB,EAA+B,CACrD,GAAM,GAAI,GAAO,GACjB,GAAI,EAAE,KAAK,GAAM,GAAM,MAAO,CAC5B,KAAS,MAAM,6BAA8B,CAAE,SAC/C,WAEA,OAAO,GC3JJ,YACL,EACA,EACA,EAC2B,CAE3B,GAAM,GAAe,AADP,GAAU,MAErB,IAAI,GAAM,CAAC,EAAG,WAAW,GAAM,IAC/B,OAAO,CAAC,CAAC,KAAU,GAAQ,MAE1B,EAAc,EAElB,WAAc,EAAe,EAAa,CACxC,GAAM,GAAW,GAAY,GAAe,GAAY,GAIlD,EACJ,AAFA,IAAQ,GAAM,KAAa,cAAgB,EAAI,KAG/C,EAAW,GACX,GAAY,GAAK,GAAY,GAAe,IAE9C,MAAI,IAAQ,GAAc,GACnB,EAGT,MAAO,GAAa,OAAO,CAAC,CAAC,GAAO,IAAQ,EAAK,EAAM,IAGzD,YAAiB,EAAW,CAG1B,MAAI,KAAM,MAAc,OACpB,IAAM,MAAc,QACjB,EAGF,YACL,EACA,EACS,CACT,MAAO,IACL,EAAc,GAAQ,IAAI,IAC1B,EAAc,GAAQ,IAAI,KCrD9B,OAAkB,oBAalB,GAAM,IAAS,EAAK,IAAM,EAAS,UAEnC,kBAAiC,EAAsC,CACrE,GAAI,CACF,GAAM,CAAE,OAAM,QAAS,KAAM,GAAE,MAAM,SAAS,CAAE,kBAAmB,KACnE,MAAO,IAAmB,EAAM,SACzB,EAAP,CACA,YAAS,KAAK,+BAAgC,GACvC,EAAE,SAIN,YACL,EACA,EACA,CACA,MAAO,eAAM,EAAG,CACd,IAAK,IC9BT,GAAO,KAAgB,iBAUjB,GAAmB,EAAK,SAAY,CACxC,GAAM,GAAO,EAAU,IAAI,GAAY,OACjC,EAAuB,GAC7B,OAAW,KAAW,GAAS,mBAAmB,eAAgB,CAChE,GAAM,CAAC,EAAK,GAAY,EAAQ,MAAM,KAChC,EAAM,EAAK,KAAK,GACtB,AAAI,KAAM,GAAI,iBACZ,EAAO,GAAO,EAAI,WAElB,EAAS,mBAAmB,KAC1B,4DAA8D,GAIpE,MAAO,QAAO,OAAO,KAGvB,kBAA2C,EAAe,EAAgB,CAGxE,GAAM,GAAI,AADA,MAAM,IAAY,EADP,MAER,mBACb,GAAI,CAAC,EAAM,GAAI,CACb,GAAM,GAAI,KAAM,MAChB,OAAW,KAAK,IAAK,GACnB,GAAI,EAAE,SAAS,GACb,MAAO,GAAE,aAAa,CAAE,IAAK,EAAE,KAIrC,MAAO,GAAE,aAAa,QJvCxB,GAAO,IAAgB,iBAuChB,QAA0B,CAG/B,YACW,EACA,EACT,CAFS,UACA,kBAHH,aAAU,GAAI,IAAe,EAAI,GAKvC,KAAK,OAAS,EAAS,uBAAyB,EAAG,QAAU,MAG9D,WAAQ,SAAU,CACjB,MAAO,CACL,KAAM,sBACN,QAAS,KAAK,GAAG,QACjB,WAAY,KAAK,YAQrB,OAAO,EAGuB,CAC5B,MAAO,IAAK,kCAAmC,SAAY,CACzD,GAAM,GAAM,EAAQ,KAAM,IAAe,KAAM,MAAK,aAKpD,IAJA,KAAK,OAAO,KACV,mCACA,EAAI,IAAI,GAAM,EAAG,KAAK,WAEjB,EAAW,IAAM,CACtB,GAAM,GAAO,EAAI,MACX,EAAK,KAAM,GAAU,OAAO,EAAK,KACvC,GAAI,GAAM,KAAM,SAChB,GAAM,GAAM,KAAM,GAAG,MACrB,GAAI,KAAO,MAAQ,KAAK,QAAQ,IAAI,IACpC,GAAI,CAEF,MADe,MAAM,MAAK,OAAO,EAAI,EAAM,SAEpC,EAAP,CACA,KAAK,QAAQ,IAAI,GACjB,KAAK,OAAO,KAAK,+BAAiC,EAAM,GAAS,KAGrE,MAAO,MAAK,OAAO,MACjB,8BACA,CAAE,UAAW,GAAM,UAAW,YAKtB,QACZ,EACA,EACA,EACA,CACA,KAAK,OAAO,KAAK,UAAY,EAAK,IAAK,CAAE,IAAK,EAAK,MAE/C,EAAO,EAAK,WACd,KAAM,IAAU,GAGlB,GAAM,GAAW,KAAM,GAAG,OACpB,EAAQ,KAAM,GAAG,2BAEvB,GADA,KAAK,OAAO,MAAM,SAAU,CAAE,WAAU,QAAO,SAC3C,GAAY,MAAQ,GAAS,KAC/B,MAAO,MAAK,OAAO,MAAM,2CAA4C,CACnE,UAAW,GACX,SAIJ,GACE,EAAK,OAAS,MACd,EAAK,QAAU,MACf,EAAK,UAAY,MACjB,EAAK,KAAO,KAEZ,MAAO,MAAK,OAAO,MACjB,4CAA8C,EAC9C,CAAE,UAAW,GAAM,SAIvB,GAAM,GAAO,GAAS,EAAoB,EAAK,SAAU,EAAK,UAExD,EAAyB,KAC7B,YAAa,EAAK,IACd,GACF,EACA,UACA,MACA,QACA,SACA,WACA,MACA,aAV2B,CAY7B,KAAM,EAAG,WACT,QACA,WACA,SAAU,EAAK,IAAI,CAAC,CAAC,CAAE,KAAQ,EAAG,MAAM,KAAK,OAI/C,GAAI,EAAK,QAAU,IAAQ,CAAC,EAAS,UAAU,eAAgB,CAE7D,GAAM,GAAY,KAAM,MAAK,GAAG,SAAS,UACzC,GAAI,GAAa,KAAM,CACrB,GAAI,EAAU,UAAY,EAAK,QAC7B,KAAM,IAAI,OACR,wCACE,EACA,KACA,EAAU,CAAE,YAAW,UAG7B,GAAM,IAAY,EAAU,SAAS,MAAM,KACrC,GAAW,EAAK,SAAS,MAAM,KAErC,GACE,EAAU,KAAO,MACjB,EAAU,MAAQ,EAAK,KACvB,EAAU,WAAa,EAAK,UAC5B,GAAmB,GAAW,IAC9B,CAMA,GAAM,IAAY,GAAK,GAAW,IAClC,GAAI,EAAW,IAAY,CACzB,KAAK,OAAO,KACV,2DACA,CAAE,eAEJ,OAAW,MAAW,IAAW,CAC/B,GAAM,IAAU,EAAK,KAAK,CAAC,CAAC,CAAE,MAAQ,GAAG,OAAS,IAClD,GAAI,IAAW,KACb,KAAK,OAAO,KACV,gDACA,CAAE,WAAS,aAER,CACL,GAAM,IAAS,KAAK,GAAG,aACrB,GAAQ,GAAG,QAAQ,KACnB,GAAQ,GAAG,OAEb,KAAK,OAAO,MACV,uCAAyC,GACzC,CAAE,aAEJ,KAAM,IAAO,OAAO,UAK1B,YAAK,OAAO,MACV,uDACA,CACE,OACA,cAGJ,KAAM,MAAK,GAAG,UAAU,GACjB,IAQb,GAAM,GAAK,GAAI,IACb,CAAE,KAAM,EAAG,WAAY,GAAI,yBAC3B,GAAU,KAAK,OAAS,GAAU,MAAM,QAS1C,GANA,KAAK,OAAO,MAAM,gCAAkC,EAAK,IAAK,CAC5D,QAAS,EAAK,QACd,OACA,SAGE,AAAS,KAAM,MAAK,GAAG,OAAO,UAA9B,KACF,KAAM,IAAI,OACR,iDACE,KAAK,GAAG,OACR,QACA,GAON,GAAM,GAAqB,KAAM,MAAK,GAAG,gBAEnC,EAAgB,KAAM,IAAc,EAAI,GAAU,aAAa,KACrE,GAAI,GAAiB,KACnB,KAAM,IAAI,IAAa,CACrB,QACE,gCACA,EAAK,IACL,KACA,EAAG,WACH,8BACF,UAAW,KAIf,GAAM,GAAY,KAAM,IACtB,EACA,GAAM,EAAc,aAItB,AACE,EAAK,SAAS,WAAW,WACzB,CAAC,GAAe,EAAK,WACrB,EAAK,UAAY,MACjB,EAAK,WAAa,GAElB,GAAU,OAAO,EAAK,UACtB,KAAK,OAAO,MAAM,qBAAuB,EAAK,SAAW,SAGvD,EAAc,KAAK,cAAc,SAAS,cAE5C,GAAI,IAAM,EAAU,KAAK,IAG3B,GAAM,GAAqB,GACvB,EACA,EAGE,GAAM,GAAU,YAChB,GAAmB,GAAQ,EAAM,CAAC,CAAC,EAAY,MACnD,EAAI,GAAI,WAAW,GAAa,IAAM,GAAI,iBACxC,GAAG,KAED,GAAU,GAAK,EAAM,QAAS,UACpC,CACE,GAAI,GAAW,EAAU,QACrB,GAAS,GAEb,OAAW,CAAC,GAAY,KAAQ,GAAM,CACpC,GAAM,IAAQ,KAAK,MACb,GAAW,GACX,GAAO,KAAK,GACf,aAAa,GAAI,QAAQ,KAAM,GAAW,OAC1C,MACH,EAAW,GAAI,OAAO,GAAY,GAClC,GAAS,GAEL,GAAI,OAAS,IACf,GAAU,EAAS,QACnB,EAAQ,IAGV,KAAM,IAAI,OAAO,CACf,KAAM,GAAK,WACX,GAAI,EACJ,gBAEF,EAAG,aAEH,KAAK,OAAO,MACV,UACE,GAAI,KACJ,KACA,GAAO,IACP,OACA,GAAO,IACP,OACC,MAAK,MAAQ,IACd,OAEJ,EAAM,KAAK,KAKf,CACE,AAAI,GAAW,KACb,MAAK,OAAO,MAAM,iCAAkC,CAClD,WACA,sBAEF,EAAU,EACV,EAAQ,IAER,KAAK,OAAO,MAAM,6BAA8B,CAC9C,QACA,sBAIJ,GAAI,GAAa,GAIjB,OAAW,MAAM,IAAU,KAAM,CAC/B,GAAM,IAAQ,KAAK,MACb,GAAW,EACX,GAAa,GAAG,WAAW,EAAO,EAAO,KAC/C,GAAI,IAAc,KAAM,CACtB,KAAK,OAAO,MAAM,8BAAgC,GAAG,KACrD,SAKF,AAAK,GACH,IAAW,SAAW,EAAS,oBAAoB,eACnD,EAAa,IAGf,KAAK,OAAO,MAAM,YAAa,CAAE,gBAEjC,GAAM,IAAO,KAAK,GACf,aAAa,GAAG,QAAQ,KAAM,GAAW,OACzC,MAEH,GAAG,OAAO,GAAY,GAClB,GAAW,UAAY,MAGzB,MAAK,OAAO,MAAM,kDAAmD,CACnE,gBAEF,EAAU,KAAM,IAAW,IAE7B,EAAQ,GACR,KAAM,IAAG,OAAO,CACd,KAAM,GAAK,WACX,GAAI,EACJ,gBAEF,EAAG,aACH,EAAM,KAAK,IACX,KAAK,OAAO,MACV,UACE,GAAG,KACH,KACA,GAAO,IACP,OACA,GAAO,IACP,OACC,MAAK,MAAQ,IACd,QAKR,GAAI,CAEF,KAAM,SAAQ,IAAI,EAAmB,IAAI,GAAM,EAAG,WAClD,KAAM,SAAQ,IAAI,EAAM,IAAI,GAAM,EAAG,WACrC,KAAM,MAAK,GAAG,UAAU,GACxB,KAAK,OAAO,MAAM,qCAAsC,CAAE,eACnD,EAAP,CACA,WAAM,IAAY,EAAO,IAAM,GAAG,UAC5B,GAAI,IAAa,CACrB,MAAO,EACP,MAAO,GACP,QAAS,kCAAoC,IAGjD,MAAO,KKrYX,GAAM,IAAS,EAAS,sBAEjB,YACL,EACA,EACoB,CACpB,GAAM,GAAM,EAAK,cAAc,GAAc,QAAQ,MAAO,IAAI,MAAM,KAChE,EAAU,EAAM,EAAI,IACpB,EAAI,EAAI,GACR,EAAU,GAAa,YAAY,EAAG,QACtC,EAAQ,GAAW,EAAI,IAC7B,GAAK,EAAI,GAWP,MAAO,CAAE,OAAM,UAAS,UAAS,SAVjC,GAAO,KAAK,iCAAkC,CAC5C,OACA,eACA,MACA,UACA,UACA,UAQN,kBACE,EACA,EAC4B,CAC5B,MAAO,IAAK,EAAG,QAAS,EAAG,MAAO,CAAC,EAAS,IAC1C,EAAQ,GAAW,EAAG,MAAO,GAAK,CAChC,GAAM,GAAO,GAAU,GACjB,EAAO,GAAY,EAAU,GAAQ,IAC3C,MAAO,CACL,OACA,SAAU,GAAG,KAAQ,IAAO,EAAG,KAAK,MACpC,MAAO,GAAoB,EAAG,KAAM,EAAM,QAAS,GACnD,YAAa,YAAY,IACzB,QAAS,IAAI,GAAO,MAAM,EAAG,KAAK,OAClC,KAAM,GAAI,IAAU,GAAS,QAAQ,GAAa,IAAK,OAMxD,YACL,EACA,EACA,EACA,EACQ,CACR,MAAO,YAAY,KAAK,EAAE,OAAO,MAAiB,GAAO,MC1DpD,GAAM,KAAgB,GAAI,IAoB1B,QAAoB,CAOzB,YACW,EACT,EACS,EACT,CAHS,oBAEA,WAiFF,cAAW,EAAqC,IAEvD,KAAK,WAAW,SAAS,UAjFzB,KAAK,OAAS,EAAS,yBAA2B,GAAM,GAAM,KAC9D,KAAK,QAAU,GAAM,GACrB,KAAK,KAAO,GAAI,IAAU,GAsB1B,GAAM,GAAW,GAAQ,KAAK,QAAS,EAAG,KACpC,EAAY,GAAW,EAAU,GAGvC,KAAK,SAAW,EAAU,MAAQ,IAClC,KAAK,OAAS,EAAa,KAAK,GAAG,GAGrC,eAAgB,CACd,MAAO,IACL,KAAK,OAAO,WAAW,GAAM,EAAG,KAAK,WAAW,KAAK,WACrD,IAAM,IAIV,cAAe,CACb,MAAO,IACL,KAAK,OAAO,WACV,GAAM,EAAG,KAAK,WAAW,KAAK,WAAa,EAAG,MAAQ,QAExD,IAAM,SAKJ,WAAmC,CACvC,GAAM,GAAM,KAAM,MAAK,gBACvB,MAAO,IACL,EAAQ,EAAI,IAAI,GAAM,GAAmB,KAAK,aAAc,KAC5D,GAAM,GAAI,KAAK,aAIb,YAAY,CAChB,KAAK,OAAO,QACZ,GAAM,GAAM,KAAM,MAAK,gBACvB,GAAI,EAAI,OAAS,GACf,KAAM,IAAI,OAAM,iDAElB,YAAM,SAAQ,IAAI,EAAI,IAAI,GAAM,EAAG,WAC5B,EAGT,KAAK,EAA2B,CAC9B,MAAO,MAAK,OAAO,KAAK,KAAK,SAAW,GAG1C,KAAiB,CACf,MAAO,MAAK,KAAK,aAGnB,UAAsB,CACpB,MAAO,MAAK,KAAK,aAQnB,UAAU,EAAwB,CAChC,YAAK,SAAS,QAEP,KAAK,WAAW,eAAe,EAAM,CAAE,OAAQ,IAGxD,aAAa,EAAsB,EAA0B,CAC3D,MAAO,MAAK,KAAK,EAAU,KAAO,EAAQ,QAG5C,gBAAgB,EAA4C,CAC1D,GAAM,GAAS,KAAK,SAAW,EAAU,IACzC,MAAO,MAAK,gBAAgB,KAAK,GAC/B,EAAI,OAAO,GAAM,EAAG,KAAK,WAAW,UAIlC,wBAAuB,EAA+C,CAC1E,MAAO,IAAQ,KAAM,MAAK,gBAAgB,GAAU,GAClD,EACE,EAAI,GAAmB,KAAK,aAAc,GAAI,GAAM,EAAG,OACvD,SAKA,uBAAsB,EAA+C,CACzE,MAAO,IAAW,KAAM,MAAK,gBAAgB,GAAU,GACrD,EACE,EAAI,GAAmB,KAAK,aAAc,GAAI,GAAM,EAAG,OACvD,SAKA,QAAO,EAAyC,CACpD,GAAM,GAAQ,KAAM,MAAK,gBAAgB,GACzC,MAAO,IACL,EACE,EAAM,IAAI,GACR,EAAI,GAAmB,KAAK,aAAc,GAAI,GAAM,EAAG,eAMzD,aAA8B,CAClC,GAAM,GAAS,KAAM,MAAK,OAAO,GAAa,KAC9C,MAAO,MAAK,KAAK,QAAQ,GAAa,IAAK,KAAK,IAAI,GAAG,SAMnD,UACJ,EACA,EAAO,GACP,EAAS,GACc,CACvB,GAAI,CAAC,GAAQ,IAAY,GAAa,GACpC,MAAO,MAAK,KAAK,WAAW,GACvB,CACL,GAAM,GACJ,IAAY,GAAa,IAAM,KAAM,MAAK,WAAa,OACzD,MAAO,MAAK,KAAK,SACf,EACA,KAAM,MAAK,OAAO,GAClB,EACA,MChMD,YAAe,CAEpB,YAAqB,EAA0B,EAA2B,CAArD,YAA0B,WAD9B,WAAQ,GAAI,IAAyB,UAGhD,QAAO,EAKV,CACD,MAAO,MAAK,IAAI,EAAK,QAAS,EAAK,YAAY,OAAO,GAGxD,IAAI,EAAiB,EAAqD,CACxE,MAAO,IAAI,IAAoB,KAAK,GAAG,GAAU,GAGnD,GAAG,EAAsB,CAEvB,GAAM,GAAM,EAAI,GAAM,IAChB,EAAQ,KAAK,MAAM,IAAI,GAC7B,GAAI,GAAS,MAAQ,GAAM,EAAS,EAAM,SACxC,MAAO,GACF,CACL,GAAM,GAAK,GAAI,IAAc,KAAK,KAAM,EAAS,KAAK,KACtD,MAAI,IAAS,IAIX,KAAK,MAAM,IAAI,EAAK,GACb,GAKb,aAAa,EAAiB,CAC5B,KAAK,MAAM,OAAO,EAAI,MC7C1B,OAAiB,0BAwCjB,GAAM,IAAS,EAAS,cAElB,GAAW,gBAEV,aAA8B,CACnC,MAAO,GAAU,IAAI,MAAY,KAAK,IAGjC,YAA6B,EAA6B,CAC/D,MAAO,IAAM,CAAC,EAAa,EAAS,YAAY,OAAQ,GACtD,EAAY,EAAI,GAAM,EAAI,GAAe,GAAK,GAAK,EAAE,KAAK,OAI9D,mBAAuC,CACrC,AAAI,EAAO,EAAS,eAAe,QACjC,GAAS,eAAe,MAAQ,GAChC,EAAS,UAAU,KAAK,KAAM,QAKlC,kBACE,EAAyB,KACzB,CACA,GAAM,GAAW,KAAM,IAAW,GAAmB,GAAe,IAAM,IAC1E,YAAM,MACN,GAAmB,QACZ,EAcT,mBAAoE,CAClE,MAAO,IAAoB,MAG7B,kBACE,EACsB,CACtB,MAAO,GAAI,GAAoB,GAAc,GAAM,GAAoB,IAGlE,GAAM,IAAqB,EAChC,IAAM,KACN,IAEF,EAAM,IAAM,CACV,EAAa,IAAM,GAAmB,SACtC,EAAS,YAAY,YAAY,IAAM,GAAmB,WAIrD,YAA6B,EAA+B,CACjE,GAAM,GAAM,GAAoB,GAChC,MAAO,IAAO,IAAI,CAChB,IAAK,sBACL,OAAQ,EAAO,GAAK,QAAQ,aAAc,IAC1C,MAAO,OACP,KAAM,CACJ,cACA,SAAU,EAAS,YAAY,MAC/B,oBAAqB,GAAK,cAKhC,GAAM,IAAgB,gDAEtB,kBAAmC,EAAsC,CACvE,MAAO,GAAQ,EAAK,kBAAkB,IAAgB,GAAK,EAAE,IAG/D,GAAM,IAAe,CAAE,WAAY,GAAI,OAAQ,MAE/C,kBAA8B,EAAgB,EAA0B,CACtE,GAAM,GAAM,KAAM,GAAK,QAAQ,aACzB,EAAO,EAAM,KAAM,GAAK,MAAQ,EACtC,KAAM,IAAU,EAAM,EAAU,GAChC,GAAO,KAAK,mCAAoC,CAC9C,OACA,OACA,YAAa,EACV,OAAO,GAAM,EAAG,YAChB,IAAI,GAAO,EACV,KAAM,EAAG,KACT,MAAO,EAAG,WAIZ,GACE,MAAM,IAAQ,GAAS,GAAK,GAAO,GAAK,MAC1C,IAAO,KAAK,sCAAuC,CAAE,OAAM,SAC3D,KAAM,GAAK,cAAc,QAE3B,KAAM,GAAK,UAQR,GAAM,IAAqB,EAAK,IAAM,IAE7C,kBACE,EACA,EACA,EACe,CACf,GAAM,GAAc,EAAO,KAAM,IAAK,GAAM,IACtC,EAAQ,GACZ,CACE,GACA,SACA,GACA,aAAa,EAAS,GAAG,4CACzB,GACA,+DACA,GACA,4CACA,GACA,0EACA,4EACA,kBACA,GACA,yEACA,sBACA,GACA,gNACA,GACA,MACA,GAEA,mBAAqB,MACrB,IAAI,GAAK,GAAK,EAAG,MAGrB,EAAM,KAAK,GAAI,IAEf,GAAI,GAAW,GACf,EAAS,QAAQ,GAAW,CAC1B,GAAM,GAAM,GAAG,GACb,EAAQ,iBACL,EAAQ,SAAS,gBAEtB,AAAI,IAAQ,GACV,GAAW,EACX,EAAM,KACJ,GACA,GAAQ,IAAK,IACb,IACA,kBAAoB,EAAM,IAC1B,IACA,GACA,KAIJ,GAAM,GAAS,MAAQ,GAAQ,IAAK,EAAQ,KAAK,OAAS,GAAK,IAEzD,EAAQ,GAAQ,KACpB,IAAK,EAAQ,KACV,GAAY,EAAQ,KAAK,WAAY,GAAO,EAC7C,cAAe,MAEd,EAAQ,cAEV,IAAI,CAAC,CAAC,EAAG,KAAO,GAAG,MAAM,EAAU,MACnC,KAAK,MAER,EAAM,KACJ,GAAG,GACD,CACE,EACA,MAAQ,EAAQ,KAAO,MACvB,EACA,GACA,GAAG,EAAQ,KAAK,YAAY,QAAQ,MAAO;AAAA;AAAA,KAC3C,IAAI,KACJ,IACA,KAAK;AAAA,GACP,KAIJ,GAAM,GAAQ,EAAY,EAAQ,MAC5B,EAAI,GACJ,EAAI,EAAQ,eAAe,GACjC,AAAI,GAAK,KACP,GAAE,EAAQ,MAAQ,EAClB,EAAM,KAAK,GAAG,GAAc,KAE5B,GAAE,EAAQ,MAAQ,EAAQ,aAC1B,EAAM,KAAK,GAAG,GAAc,GAAG,IAAI,GAAM,KAAO,KAElD,EAAM,KAAK,GAAI,MAGjB,KAAM,GAAK,UACT;AAAA,EAAO,EAAM,IAAI,GAAM,EAAG,aAAa,KAAK;AAAA,GAAQ;AAAA;AAAA,GAEtD,KAGK,YAAuB,EAAW,CACvC,MAAO,IACL,GAAG,GAAQ,GAAK,IACd,CAAC,CAAC,EAAG,KAEH,EAAI,MAAQ,EAAU,EAAG,OAAW,KAK5C,kBACE,EAAiB,KACjB,CACA,MAAO,IAAe,EAAM,MAG9B,kBAA0C,EAAsB,CAC9D,MAAO,GAAI,GAAoB,GAAc,GAAM,GAAmB,IAMxE,kBAA2C,EAAsB,CAC/D,KAAM,IACJ,GAAc,EAAa,EAAS,YAAY,QAElD,GAAM,GAAO,GAAoB,GACjC,UAAO,KAAK,wBAA0B,EAAO,KAC7C,KAAM,GAAI,EAAM,GAAK,GAAe,EAAG,OACvC,GAAmB,QACZ,EAGT,kBAAoB,EAA4C,CAC9D,MAAO,GAAQ,EAAK,WAAY,GAC9B,GAAO,IAAI,CACT,IAAK,QAAQ,KACb,OAAQ,WAAK,MAAM,GAAU,EAAI,gBAKvC,kBAAkC,EAA2C,CAC3E,GAAM,GAAM,EAAS,iCAAmC,EAAE,WAAa,KACvE,GAAI,CACF,GAAM,GAAU,KAAM,IAAK,GAC3B,GAAI,GAAW,KAAM,CACnB,GAAI,KAAM,GAAE,aAAc,KAAM,IAAI,OAAM,kBAAoB,GACzD,MAAO,GAEd,GAAM,GAAW,GAAI,KACnB,GAAQ,GACL,OAAO,CAAC,CAAC,CAAE,KAAO,YAAa,KAAW,CAAC,EAAE,WAC7C,IAAI,CAAC,CAAC,EAAG,KAAO,CAAC,EAAE,cAAe,KAEjC,EAAW,EACf,GAAQ,GAAS,IAAI,CAAC,CAAC,EAAK,KAAW,CACrC,GAAM,GAAI,EAAS,IAAI,EAAI,GAAK,eAChC,MAAI,IAAK,KACP,EAAI,KAAK,+CAAgD,CACvD,QAGF,EAAE,eAAe,GAEZ,KAGX,SAAI,KAAK,SAAU,CACjB,UACA,SAAU,EAAS,IAAI,GAAK,GAAK,EAAG,OAAQ,QAAS,cAEhD,QACA,EAAP,CACA,EAAI,MAAM,cAAgB,GAAe,IACzC,QAIJ,GAAM,KAAsB,EAC1B,IACE,GAAI,KACF,CACE,EAAS,SACT,EAAS,SACT,EAAS,QACT,EAAS,SACT,IAAI,GAAM,EAAG,OCrVrB,OAAoB,sBADpB,GAAO,IAAc,eA+Bf,GAAS,EAAS,cAmBlB,GAAgB,CAAC,CACrB,SACA,UASA,GAAY,EAAO,YAAa,GAAM,CACpC,AAAI,EAAM,EAAK,cACb,GAAK,YAAc,KAGvB,GAAO,EAAO,IAAK,GAAM,CACvB,AAAI,EAAM,EAAK,MACb,GAAK,IAAM,KAGR,WAAW,EAAK,eACrB,EAAK,YACE,QAAiB,aAAU,GAAI,SAGnC,QAAuB,CAC5B,YAAqB,EAAoB,CAApB,cAIrB,UAAW,CACT,MAAO,GAAM,KAAK,aACd,GAAW,KAAK,QAChB,GAAG,KAAK,eAAe,KAAK,QAY7B,QAA6C,CAclD,YAAqB,EAAuB,EAAiB,GAAM,CAA9C,YAAuB,aAZpC,YAAS,GAEA,YAAS,GAAI,IACb,iBAAkC,GAClC,aAAU,IAAM,KAAK,UAAU,SAC/B,cAAW,IAAM,KAAK,UAAU,UACxC,cAAW,GAAI,KACf,SAAM,EAAK,IAAM,GAAQ,YAAY,KA8CrC,WAAQ,GAAS,SAAY,CACpC,GAAI,MAAK,MACT,UAAO,MAAM,SAAW,KAAK,KAAO,KACpC,KAAK,OAAS,GAAI,aAAa,KAAK,UAAU,KAAK,OACnD,KAAK,OAAO,GAAG,YAAa,IAAM,CAChC,GAAO,KAAK,gBAAkB,KAAK,MAC9B,KAAK,OAAO,YAEnB,KAAK,OAAO,GAAG,QAAS,KAAM,IAAO,CACnC,GAAO,KAAK,0BACP,KAAK,OAAO,SACjB,KAAM,MAAK,QAAQ,eAAiB,GAAgB,KAEtD,KAAK,OAAO,OACV,KAAK,KACL,EAAS,yBAAyB,eAAiB,OAAY,aAE7D,KAAK,OACP,KAAK,OAAO,QAEP,KAAK,OAAO,SAClB,KA+CM,SAAM,EAAK,SAAY,CAC9B,KAAK,OAAS,GACd,GAAa,eAAe,QAAS,KAAK,SAC1C,GAAa,eAAe,SAAU,KAAK,UAC3C,KAAM,MAAK,sBACX,KAAM,IAAY,KAAK,UAjHvB,KAAK,KAAO,UAAY,EACxB,KAAK,WAAW,OAAQ,IACxB,KAAK,iBAAiB,YAAa,GACjC,IAAa,KAAK,EAAG,MAAO,EAAG,MACxB,KAAK,UAAU,EAAG,MAAO,EAAG,QAErC,GAAQ,KAAK,SACb,GAAS,KAAK,UACd,GAAgB,MAChB,GAAe,SAGb,kBAAkB,CACpB,MAAO,MAAK,YAAY,YAGpB,WAAU,EAA6B,CAC3C,MAAO,GAAU,GAAE,IAAK,KAAK,OAAU,IAAU;AAAA,EAGnD,WAAW,EAAgB,EAAkB,CAC3C,GAAM,GAAQ,KAAK,SAAS,IAAI,GAChC,AAAI,GAAS,MACX,GAAO,KAAK,4BAA6B,CACvC,SACA,QACA,WAAY,IAGhB,KAAK,SAAS,IAAI,EAAQ,GAG5B,iBAAiB,EAAgB,EAAwB,CACvD,KAAK,WAAW,EAAQ,CAAC,CAAE,YAAa,EAAQ,IAGlD,kBAAkB,EAA0B,CAC1C,GAAQ,GAAU,QAAQ,CAAC,CAAC,EAAG,KAAO,KAAK,iBAAiB,EAAG,OA0B7D,QAAQ,CACV,MAAO,MAAK,QAAU,OAGpB,QAAuB,CACzB,MAAO,MAAK,OAAO,QAGrB,qBAAsB,CACpB,GAAM,GAAI,KAAK,YAAY,IAAI,GAAM,GAAU,EAAG,SAClD,YAAK,YAAY,OAAS,EACnB,QAAQ,IAAI,GAOrB,UAAU,EAAe,EAA8B,CACrD,MAAO,MAAK,QAAQ,CAAE,QAAO,cAGjB,SACZ,EACA,EAA0B,QACR,CAClB,GAAM,GAAM,KAAM,MAAK,UAAU,GAC3B,EAAU,CAAC,GAAG,KAAK,aACrB,EAAO,EAAQ,OACnB,GAAO,MAAM,YAAa,CAAE,OAAM,WAClC,OAAW,KAAM,GACf,GAAI,CACF,AAAI,EAAG,OAAO,cACZ,IAEA,EAAG,OAAO,GAAQ,EAAK,IAAM,UAE/B,CACA,IAGJ,MAAO,IAAU,IAAM,GAAQ,EAAG,CAAE,UAAW,IAYzC,UAAU,EAA0B,CAC1C,GAAO,KAAK,mBAAqB,GAAW,IACxC,KAAK,OACP,EAAO,QAET,GAAM,GAAO,GAAI,IAAiB,GAClC,KAAK,YAAY,KAAK,GACtB,EAAO,GAAG,MAAO,IAAM,CACrB,GAAO,KAAK,2BAA6B,GAAW,IACpD,GAAc,KAAK,YAAa,GAAM,EAAG,SAAW,KAEtD,EAAO,GAAG,QAAS,KAAM,IAAO,CAC9B,GAAO,KAAK,iBAAmB,GAAW,GAAU,KAAO,GAC3D,KAAM,MAAK,QAAQ,SAAU,GAC7B,EAAO,QAET,GAAI,CACF,AAAK,GAAc,EAAQ;AAAA,EAAM,GAAM,KAAK,UAAU,EAAI,UACnD,EAAP,CACA,GAAO,KAAK,qBAAuB,GAAW,GAAU,KAAO,GAC/D,EAAO,YAIG,WAAU,EAAc,EAAwB,CAE5D,GADA,GAAO,MAAM,cAAe,GACxB,EAAM,GACR,OAEF,GAAI,GAAa,UACb,EAAiB,UACrB,GAAI,CACF,GAAM,GAAM,KAAK,MAAM,GACvB,SAAY,EAAI,GAAI,GAAO,EAAK,GAChC,EAAY,EAAI,OAAQ,GAAO,EAAS,GAEjC,KAAM,IAAK,OAAS,EAAQ,IACjC,KAAK,OAAO,EAAI,EAAQ,EAAI,OAAQ,UAE/B,EAAP,CACA,GAAO,KAAK,kBAAmB,CAAE,OAAM,UACvC,EAAK,OAAO,MACV,KAAM,MAAK,UAAU,CACnB,KACA,MAAO,EAAO,EAAM,QAAS,IAAM,EAAI,aAMjC,QACZ,EACA,EACA,EACA,EACA,CACA,GAAM,GAAU,KAAK,SAAS,IAAI,GAClC,GAAI,GAAW,KACb,SAAO,KAAK,sBAAuB,CACjC,SACA,SACA,UAAW,GAAK,KAAK,YAIjB,GAAI,OAAM,kBAAoB,GAEtC,GAAM,CAAE,YAAW,UAAW,KAAM,IAAa,IAC/C,EAAQ,CAAE,KAAI,SAAQ,SAAQ,UAEhC,GAAO,IAAI,GAAS,EAAW,GAAW,WAAY,CACpD,SACA,KAAM,EAAI,GACV,YACA,KACA,SACA,WAEF,EAAK,OAAO,MAAM,KAAM,MAAK,UAAU,CAAE,KAAI,iBAIjC,SAAQ,EAAgB,EAAW,CAC/C,AAAK,KAAK,OAAO,EAAQ,EAAQ,KC7RrC,GAAI,IAAS,GAEN,aAA6B,CAClC,MAAO,IAGF,aAAuB,CAC5B,AAAK,IACH,IAAS,GACT,MAIG,aAAwB,CAC7B,AAAI,IACF,IAAS,GACT,KACA,MC1CJ,OAAoB,sBCApB,OAA4B,sBAKrB,aAA4B,CACjC,GAAM,GAAM,qBAEZ,MAAO,IAAI,CAAC,EAAI,SAAU,EAAI,SAAU,EAAI,eAGvC,aAAyB,CAC9B,MAAO,IAAQ,KAAqB,GAAI,GAGnC,aAA+B,CACpC,MAAO,qBAAc,IAGhB,aAA4B,CACjC,MAAO,IAAQ,KAAwB,GAAI,GCU7C,GAAM,IAAY,EAChB,IACE,GAAI,IACF,sBACA,IAAM,CACJ,GAAM,GAAI,EAAS,gBACb,EAAK,KACX,EAAE,IAAI,GAAQ,GAAM,OAAS,OAAQ,sBAAuB,IAE9D,EAAa,UAIZ,aAAmD,CACxD,KACA,GAAM,GAAe,GACf,EAAiB,GACjB,EAAgB,GAEtB,WAAe,EAAmB,EAAe,EAAc,CAC7D,GAAI,CAAC,EAAI,GACP,MAAO,GACL,qCACE,EAAU,CAAE,YAAW,SACvB,IAGN,GAAM,GAAS,EAAY,GACrB,EAAO,WAAW,SAAkB,GAAS,EAAW,MAE9D,AAAI,GAAU,EACZ,EAAI,KAAK,GAAG,KAAQ,aACf,AAAI,GAAU,EAAQ,GAC3B,EAAK,KAAK,GAAG,KAAQ,aAErB,EAAG,KAAK,GAAG,KAAQ,WAKvB,SAAM,KAAoB,EAAS,YAAY,eAAgB,eAC/D,EACE,KACA,EAAS,eAAe,eACxB,cAEK,CACL,KACA,OACA,OAQG,aAAyD,CAC9D,MACE,CAAC,IACD,CAAC,EAAS,cAAc,gBACxB,EAAQ,EAAS,UAAU,QAEpB,CACL,KAAM,CAAC,oEAGF,GAIX,mBAAqC,CACnC,GAAI,CAEF,MAAO,IAAmB,KAAM,MAAuB,YAChD,EAAP,CACA,MAAO,IAAO,CACZ,KAAM,CAAC,GAAW,GAAS,GAAM,2BASvC,mBAAiC,CAC/B,GAAI,MAAc,IAAU,MAAO,GACnC,GAAM,GAAK,KAAM,MACjB,MACE,IAAM,MACN,EAAW,EAAG,OACd,EAAW,EAAG,MACd,EAAW,EAAG,MC1HlB,OAAwB,mBCDxB,OAAyB,mBAMlB,GAAM,IAAO,eAAG,CAAE,OAAQ,UAAW,iBAAkB,KCHvD,GAAM,IAAY,WAElB,YAAsC,EAAY,EAAmB,CAC1E,MAAO,GAAQ,KAAK,EAAQ,KAAO,ICArC,GAAI,IAGS,GAAU,IAAM,GAEtB,YAAoB,EAAQ,CACjC,GAAW,EAGN,aAA8B,CACnC,MAAO,GAAI,KAAkB,GAAO,GAAS,EAAK,WCNpD,GAAM,IAAa,GAAI,KAEhB,YAAuB,EAAqB,CACjD,GAAW,IAAI,EAAG,MAAO,GAK3B,GAAM,IAAY,CAAC,CAAC,EAAG,KAAc,GAAK,MAAQ,GAAK,KAKhD,YAAmC,EAAuB,EAAc,CAC7E,GAAI,GAAQ,KACV,KAAM,IAAI,OAAM,gBASlB,GANE,GAAU,MACV,EAAS,EAAO,QAChB,CAAC,GAAW,IAAI,EAAO,QAEvB,GAAc,GAEZ,YAAgB,GAClB,MAAO,GAGT,GAAM,GAAK,EAAI,EAAK,OACjB,QAAQ,GAAM,GAAW,IAAI,IAC7B,UAAU,IAAM,GACnB,GAAI,YAAgB,GAAI,MAAO,GAC/B,GAAM,GAAI,GAAI,GACd,MAAI,IAAQ,KAAa,EAClB,GACL,EACA,EACA,EAAK,CAAC,EAAO,UAAY,IAAK,EAAG,UAAY,OAI1C,YACL,EACA,EACA,EAA0B,GACvB,CACH,GAAM,GAAK,EAAE,QAab,MAZgB,IAAK,GAClB,OAAO,GAAO,IAAQ,SACtB,OAAO,GAAO,EAAK,IAAQ,MAC3B,IAAI,GAAO,CACV,GAAM,GAAQ,EAAK,GAEnB,MADA,GAAc,QAAQ,GAAO,EAAM,GAAY,EAAK,IAChD,GAAS,EAAG,cAAe,GACtB,CAAC,EAAK,EAAO,IAEf,CAAC,EAAK,KAEd,OAAO,IACF,QAAQ,CAAC,CAAC,EAAG,KAAQ,EAAE,GAAK,GAC7B,ECzDF,YAAmB,EAA0B,CAClD,MAAO,KAAQ,MAAQ,GAAS,CAAC,SAAU,UAAW,MAAO,IAGxD,YAAoB,EAA2B,CACpD,MAAO,IAAO,MAAQ,MAAM,QAAQ,GAChC,EAAI,MAAM,IACV,GAAQ,GAAK,MAAM,CAAC,CAAC,CAAE,KAAW,GAAU,IAG3C,YAAoB,EAAoB,CAC7C,MAAO,IAAU,EAAK,CAAC,EAAK,IAAU,CACpC,GAAI,GAAI,WAAW,KACnB,IAAI,MAAO,IAAU,UAAW,MAAO,CAAC,EAAK,EAAQ,EAAI,GACzD,GAAI,GAAU,GAAQ,MAAO,CAAC,EAAK,GACnC,GAAI,GAAQ,GAAQ,MAAO,CAAC,EAAK,GAAc,OChB5C,YAAoB,EAA2B,CACpD,MACE,IAAO,MACP,GAAS,EAAI,MACZ,GAAI,UAAY,MAAQ,GAAW,EAAI,WAWrC,YAAoB,EAAyB,CAClD,GAAI,GAAO,KAAM,KAAM,IAAI,OAAM,YACjC,GAAI,GAAW,GAAM,MAAO,GAC5B,GAAI,GAAS,GACX,MAAO,CAAE,OACJ,GAAI,GAAW,EAAI,OACxB,MAAQ,IAAK,EAAI,QAAS,kBAE1B,KAAM,IAAI,OAAM,iBAAmB,EAAU,IAwC1C,YAAqB,EAAW,CACrC,MAAO,GACJ,QAAQ,cAAe,IACvB,MAAM,KACN,IAAI,GAAK,EAAE,QAAQ,OAAQ,KAAK,QAChC,OAAO,GCxDL,GAAM,IAAe,GAAS,GAAK,IAEpC,GAAS,EAAK,IAAM,EAAS,cAE5B,QAAgB,CAErB,YAAqB,EAA+B,EAAuB,CAAtD,UAA+B,iBADnC,sBAAmB,GAAI,IAAqB,KAG7D,IAAK,CACH,MAAO,IAAK,KAAK,WAGX,KACN,EACA,EACA,EAAQ,GAC2B,CACnC,GAAM,GAAK,GAAW,GAEtB,GAAI,CACF,GAAM,GAAO,KAAK,iBAAiB,SAChC,KAAU,GAAO,SAAW,IAAM,EAAG,IACtC,IAAM,CACJ,GAAM,GAAS,EAAG,QAAQ,EAAG,KAC7B,MAAO,KAAU,GAAO,EAAO,QAAU,IAG7C,MAAK,GAAK,SAAS,KAIV,CACL,KACA,QALF,MAAK,iBAAiB,QACf,KAAK,KAAK,EAAI,EAAG,UAOnB,EAAP,CACA,MAAO,MAAS,MAAM,gBAAiB,CACrC,QACA,SAAU,EACV,UAAW,WAcH,MAAK,CACjB,IACA,QACA,KAKC,CACD,GAAI,CAGF,MAAO,MAAM,IAAG,KAAK,KAAM,GAAM,CAC/B,GAAM,CAAE,KAAI,QAAS,KAAK,KAAK,EAAI,EAAG,GAOhC,EAAO,EAAK,GAAG,KAAK,GAE1B,MAAO,GAAG,UAAY,KAAO,IAAS,EAAK,EAAG,kBAEzC,EAAP,CACA,GAAI,OAAO,EAAI,SAAS,SAAS,gBAE/B,KAAM,GAEN,KAAS,MAAM,EAAK,GAAE,OAAQ,GAAM,GAAW,MAKrD,IAAI,EAAiC,CACnC,MAAO,MAAK,KAAK,CAAE,IAAG,EAAG,aAGrB,WAAU,EAAiB,EAAoB,GAAI,CACvD,GAAM,GAAI,GAAU,eAEpB,OAAW,KAAO,GAAO,CACvB,GAAI,EAAM,IAAQ,EAAI,OAAO,WAAW,MAAO,SAC/C,KAAM,MAAK,IAAI,CAAE,QAGjB,GAAM,GAAM,GAAW,GAAU,EAAK,IAAK,EAAW,IACtD,EAAE,QAAQ,IAId,OAAO,EAA2C,CAChD,MAAO,IAAG,KAAK,KAAM,GACnB,EAAQ,IAAI,GAAK,CACf,GAAM,CAAE,KAAI,QAAS,KAAK,KAAK,EAAI,GACnC,MAAO,GACL,EAAG,SACH,GAAK,EAAK,IAAI,GACd,IAAM,EAAK,UAMnB,KAAK,EAAoE,CACvE,MAAO,MAAK,KAAK,CAAE,EAAG,EAAE,KAAK,MAAO,EAAG,QAGzC,eACE,EACoB,CACpB,GAAM,GAAI,GAAW,EAAE,KAAK,OAC5B,SAAE,IAAM,EAAE,IAAI,QAAQ,WAAY,qBAC3B,KAAK,KAAK,CAAE,IAAG,EAAG,QAG3B,MAAM,EAAgC,CACpC,MAAO,MAAK,KAAK,CAAE,IAAG,EAAG,QAG3B,OAAO,EAAmE,CACxE,MAAO,MAAK,KAAK,CAAE,EAAG,EAAE,KAAK,MAAO,EAAG,QAGzC,OAAO,EAA0C,CAC/C,MAAO,IAAG,KAAK,KAAM,GACnB,GACE,EAAQ,IAAI,GAAK,CACf,GAAM,CAAE,KAAI,QAAS,KAAK,KAAK,EAAI,GACnC,MAAO,GACL,EAAG,SACH,GAAK,EAAK,IAAI,GACd,IAAM,EAAK,WAOrB,IAAI,EAAkC,CACpC,MAAO,MAAK,KAAK,CAAE,IAAG,EAAG,QAG3B,KAAK,EAAqE,CACxE,MAAO,MAAK,KAAK,CAAE,EAAG,EAAE,KAAK,MAAO,EAAG,aAGnC,SAAW,EAGd,CACD,GAAI,GACJ,EACE,GAAQ,KAAM,MAAK,KAAK,CACtB,EAAG,EAAK,GAAG,KAAK,KAAM,GAAO,MAAM,IACnC,EAAG,QAED,EAAW,IACb,KAAM,GAAK,UAAU,SAEhB,EAAW,IAAU,CAAC,KAGjC,WAAwB,EAAyB,CAC/C,MAAO,MAAK,KAAK,CAAE,IAAG,MAAO,GAAM,EAAG,QAGxC,YACE,EACY,CACZ,MAAO,MAAK,KAAK,CAAE,EAAG,EAAE,KAAK,MAAO,MAAO,GAAM,EAAG,QAGtD,SAAsB,EAA2B,CAC/C,MAAO,MAAK,KAAK,CAAE,IAAG,MAAO,GAAM,EAAG,QAGxC,UACE,EACc,CACd,MAAO,MAAK,KAAK,CAAE,EAAG,EAAE,KAAK,MAAO,MAAO,GAAM,EAAG,aAGhD,cAAwC,EAG3C,CACD,GAAI,GACJ,EACE,GAAQ,KAAM,MAAK,KAAK,CACtB,EAAG,EAAK,GAAG,KAAK,KAAM,GAAO,MAAM,IACnC,MAAO,GACP,EAAG,QAED,EAAW,IACb,KAAM,GAAK,UAAU,SAEhB,EAAW,MCzMjB,YAAgC,CAIrC,YAAqB,EAA+B,EAAc,CAA7C,aAA+B,UAc3C,iBAAc,EAAwB,IAC7C,GAAoB,IAClB,KAAK,KACF,OAAO,cAAc,KAAK,cAC1B,IAAI,AAAC,GAAY,EAAG,QAjBzB,KAAK,OAAS,EAAS,YAAY,EAAM,cACzC,GAAc,GACd,KAAK,IAAM,GAAI,IAAU,KAAK,GAAI,EAAM,cAGtC,SAAkB,CACpB,MAAO,GACL,KAAK,KACL,GAAM,EAAG,KACT,IAAM,OAYE,YAAuB,CACjC,MAAO,MAAK,MAAM,UAGpB,OAAQ,CACN,MAAO,MAAK,MAAM,aAGd,YAAW,EAAyB,CACxC,GAAM,GAAI,KAAK,MAAM,SAAS,GACxB,EAAM,GAAW,GACvB,MAAO,IAAK,EAAK,GAAI,KAAM,MAAK,eAG1B,IAAI,EAAc,CACxB,MAAO,MAAK,IAAI,IAAI,GAGtB,SAAS,EAAmC,CAC1C,MAAO,GAAQ,EAAM,GAAM,KAAK,MAAM,SAAS,SAG3C,WAAU,EAA8C,CAG5D,MADe,AADH,MAAM,IAAY,IACX,IAAI,GAAM,KAAK,MAAM,SAAS,IAInD,MAAM,EAAwC,CAC5C,MAAO,MAAK,SAAS,KAAK,IAAI,MAAM,IAGtC,OAAO,EAAkE,CACvE,MAAO,MAAK,MAAM,EAAE,KAAK,UAG3B,IAAI,EAAe,KAAK,QAAuB,CAC7C,MAAO,MAAK,UAAU,KAAK,IAAI,IAAI,IAGrC,KAAK,EAA+D,CAClE,MAAO,MAAK,IAAI,EAAE,KAAK,UAGzB,QAAQ,EAAwC,CAC9C,MAAO,MAAK,SAAS,KAAK,IAAI,MAAM,IAGtC,UAAU,EAA6C,CACrD,MAAO,MAAK,QAAQ,KAAK,MAAM,QAAQ,MAAM,IAG/C,SAAS,EAAY,EAA8C,CACjE,MAAO,MAAK,UAAU,OAAK,GAAL,CAAiB,aAGnC,WAAU,EAA6B,CAC3C,GAAM,GAAU,KAAM,IAAG,KAAK,KAAM,SAClC,GACE,GACE,EAAI,GAAK,OAAO,GAChB,EAAS,kBAAkB,gBAE7B,GAAO,KAAK,IAAI,IAAI,KAAK,QAAQ,QAAQ,KAAM,MAGnD,MAAO,IAAO,KAAM,MAAK,UAAU,GAAQ,IAAW,GACpD,EAAI,QAAQ,EAAG,KAInB,OAAO,EAA0C,CAC/C,MAAO,MAAK,IAAI,KAAK,MAAM,QAAQ,IAGrC,YAA+B,EAAW,EAA8B,CACtE,MAAO,MAAK,IAAI,KAAK,MAAM,QAAQ,QAAQ,EAAQ,IAGrD,KAAK,EAAyC,CAC5C,MAAO,MAAK,MAAM,EAAO,EAAI,IAAM,KAAK,MAAM,UAMhD,MAAM,EAAwC,CAC5C,MAAO,IACL,KAAK,IAAI,WAAW,EAAG,SACvB,IAAM,GAIV,OAAO,EAAkE,CACvE,MAAO,MAAK,MAAM,EAAE,KAAK,eAGrB,QAAO,EAA2C,CACtD,MAAO,IAAG,KAAK,MAAM,KAAM,IAAM,GAAY,EAAK,GAAM,KAAK,UAAU,UAGnE,WAAU,EAAuB,CACrC,MAAO,MAAK,oBACP,MAAM,MAAK,OAAO,CAAC,KAAM,GAC1B,EAAE,IAAM,KACR,KAAK,UAAU,GACf,KAAK,UAAU,QAGf,WAAU,EAAmC,CACjD,GAAI,EAAE,IAAM,KACV,KAAM,IAAI,OACR,qBAAuB,EAAU,GAAK,IAG1C,GAAM,GAAI,KAAK,MAAM,SAAS,GAC9B,EAAE,gBACF,GAAM,GAAS,EAAE,UAAU,KAAM,MAAK,eAChC,EAAU,KAAM,MAAK,IAAI,KAAK,GAAK,EAAE,OAAO,IAC5C,EAAU,KAAM,IACpB,EAAM,EAAQ,iBACd,GAAM,KAAK,SAAS,GACpB,IAAM,CACJ,KAAK,OAAO,MAAM,oDAAqD,CACrE,cAIN,MAAI,aAAa,MAAK,OACpB,GAAe,EAAG,GAEb,OAGH,WAAU,EAAmC,CACjD,GAAI,EAAE,IAAM,KACV,KAAM,IAAI,OACR,qBAAuB,EAAU,GAAK,IAG1C,GAAM,GAAI,KAAK,MAAM,SAAS,GAC9B,EAAE,gBACF,GAAM,GAAS,EAAE,UAAU,KAAM,MAAK,eACtC,YAAM,MAAK,IAAI,KAAK,GAAK,EAAE,MAAM,CAAE,GAAI,EAAE,KAAM,OAAO,IAC/C,KAML,MAAc,CAChB,MAAO,MAAK,MAAM,oBAGhB,gBAA0B,CAC5B,MAAO,GAAO,KAAK,IAAK,MAAM,MAAM,QAGlC,sBAAsB,CACxB,MAAO,MAAK,KAAO,MAAQ,KAAK,MAAQ,QAGtC,gBAAwB,CAC1B,MAAO,IAAI,KAAK,OAGlB,iBAAiB,EAAgB,CAC/B,GAAM,GAAgB,CAAC,GAAG,KAAK,IAAI,MAAM,KAAM,KAAM,aAC/C,EAAW,EACd,OAAO,GAAM,CAAC,EAAc,SAAS,IACrC,OACA,IAAI,GAAM,GAAG,cAAe,KAC5B,KAAK,KAEF,EAAgB,CAAC,cAAe,KAAK,eAC3C,MAAI,GAAM,GACR,EAAc,KAAK,cAEnB,EAAc,KAAK,gBAAiB,GAE/B,EAAc,KAAK,UAGd,cAAa,EAAmC,CAC5D,GAAM,GAAS,KAAK,QAAQ,OAAO,GAAO,QACpC,EAAU,GAAI,KACpB,OAAW,KAAQ,GACjB,OAAW,KAAO,IAAK,GACrB,EAAQ,IAAI,GAGhB,GAAM,GAAS,CACb,IAAK,GAAG,EAAO,OAAO,KAAK,iBAAiB,CAAC,GAAG,EAAQ,aACxD,SAAU,EAAO,UAInB,KAAM,MAAK,IAAI,GAGT,aAAa,EAA0B,CAC7C,MAAO,IAAK,EAAG,GAAI,KAAK,oBAGpB,QAAO,EAAwB,CAEnC,YAAM,IAAY,EAAK,KAAM,IAC3B,EAAQ,KAAK,UAAU,KAAK,aAAa,IAAK,GAC5C,GAAe,EAAG,KAGf,OAGH,QAAO,EAA6B,EAAa,GAAqB,CAC1E,GAAI,KAAK,oBAAqB,CAC5B,GAAM,GAAO,KAAM,MAAK,cAClB,EAAS,KAAM,IAAG,KAAK,KAAM,SACjC,GACE,EAAI,GACJ,EAAS,kBAAkB,eAC3B,KAAM,IAAY,CAChB,GAAM,GAAS,EAAS,IAAI,GAAM,KAAK,MAAM,SAAS,IACtD,SAAO,QAAQ,GAAM,EAAG,iBACxB,KAAM,MAAK,aAAa,EAAO,IAAI,GAAM,EAAG,UAAU,KAC/C,KAIb,MAAO,GAAa,EAAS,KAAK,OAAO,OAEzC,OAAO,IAAG,KAAK,KAAM,IAAM,GAAY,EAAK,GAAM,KAAK,UAAU,UAI/D,QAAO,EAAwC,CACnD,MAAO,IAAY,EAAI,OAAO,GAAM,GAClC,KAAK,IAAI,KAAK,MAAM,QAAQ,SAAS,QAAQ,KAAM,UAOjD,SAAQ,EAGX,CACD,GAAM,GAAQ,EAAS,kBAAkB,eACrC,EACA,EACJ,EACE,GAAQ,KAAM,MAAK,KAAK,GACtB,GAAI,EAAK,GAAG,GACR,GAAS,MAAM,GAAI,EAAE,SAAS,KAAM,IAAK,IACtC,EAAE,QAAQ,KAAM,OAAO,MAAM,KAElC,EAAW,IACb,GAAQ,KAAK,IAAI,GAAG,EAAM,IAAI,GAAM,EAAG,KACvC,KAAM,GAAK,UAAU,UAEhB,EAAW,MRlRjB,YAAsC,WAOhC,QAAQ,CACjB,MAAO,MAAK,OAAS,IAAM,KAAK,gBAI3B,SAAS,CACd,MAAI,MAAK,SAAW,MAAM,MAAK,QAAU,EAAS,KAAK,YAChD,KAAK,cAGP,QAAQ,CACb,MAAO,IAAK,KAAK,iBAGZ,SAEL,EACA,CACA,MAAO,MAAK,QAAQ,MAAM,SAGrB,YAEL,EACA,CACA,MAAO,MAAK,QAAQ,SAKf,MAAwD,CAC7D,MAAI,MAAK,MAAW,MAClB,MAAK,KAAU,GAAI,IAAS,KAAa,KAAK,KAEzC,KAAK,eAGH,MAAiB,CAC1B,MAAO,MAAK,MAAM,gBAGP,MAEX,EACY,CACZ,MAAO,IAAG,KAAK,KAAM,IAAM,EAAE,KAAK,oBAGvB,IAEX,EACA,EAAwB,GACZ,CACZ,MAAO,IAAG,KAAK,KAAM,IAAM,EAAE,KAAK,KAAM,SAGnC,OAAwB,CAC7B,MAAO,MAAK,MAAM,aAGb,WAAW,CAChB,GAAI,GACF,KAAM,IAAI,OAAM,yCAElB,MAAO,MAAK,IAAI,IAAI,eAAiB,KAAK,WAG5C,MAAO,CACL,MAAO,MAAK,QAAQ,MAOtB,OAA+C,CAC7C,MAAO,MAAK,YAGd,KAAc,CACZ,MAAO,GAAI,KAAK,IAGlB,MAAgB,CACd,MAAO,MAAK,KAAK,QAAQ,kBAG3B,YAAqB,CACnB,MAAO,MAAK,QAAQ,UAGtB,MAAe,CACb,MAAO,GAAG,KAAK,gBAAgB,EAC7B,KAAK,GACL,KAAK,KAAK,QAAQ,sBAIZ,QAAiB,CACzB,MAAO,GAAS,EAAI,KAAK,aAG1B,WAAQ,SAAU,CACjB,MAAO,MAAK,iBAGd,UAAmB,CACjB,MAAO,MAAK,OAKd,SAAkB,CAChB,MAAO,MAAK,aAMP,UAEL,EACG,CACH,MAAO,IAAS,KAAuB,SAGlC,QAEL,EACU,CACV,MAAO,MAAK,SAAS,GAAG,SAG1B,gBAAiB,CACf,MAAO,MAAK,SAAS,GAGvB,UAAU,EAAkD,CAC1D,GAAM,GAAS,KAAK,SAAS,GAAW,IACxC,MAAO,GAAS,GAAY,GAAK,EAAQ,GAAG,GAAa,EAI3D,QAA4B,CAG1B,MAAO,MAAK,SAAS,GAGvB,SAAS,EAA6B,EAAc,GAAyB,CAC3E,GAAM,GAAK,KAAK,QAChB,MAAO,IACL,KACA,CAAC,EAAK,IAAU,CACd,GAAI,KAAS,MAAQ,CAAC,GAAY,IAGlC,MAAI,IAAS,EAAG,cAAe,GACtB,CAAC,EAAK,EAAW,IAEnB,CAAC,EAAK,IAEf,EAAc,CAAE,MAAO,EAAG,OAAU,IAIxC,OAAO,EAA0B,CAC/B,MAAI,IAAQ,MAAM,GAAe,KAAM,GAChC,KAAK,QAAQ,MAAM,UAAU,MAGtC,eAAgB,OAIV,SAAS,CACb,MAAO,GAAQ,KAAK,QAAQ,MAAM,SAAS,KAAK,IAAM,GACpD,GAAe,KAAM,IAIzB,QAAS,CACP,MAAO,GAAI,KAAK,GAAI,GAAM,KAAK,QAAQ,MAAM,OAAO,CAAC,OA3LvC,AAFX,GAEW,OAAiB,SACjB,AAHX,GAGW,GAAK,GSzChB,oBAA+B,GAAM,OACnC,OAAM,EAAe,CAC1B,MAAO,IAAY,EAAI,GAAK,OAAO,GAAM,GACvC,KAAK,IAAI,KAAK,GAAK,EAAE,QAAQ,KAAM,GAAK,OAAO,YAAa,KAAK,SAOrE,MAAO,CACL,MAAI,eAAiB,OACjB,MAAa,YAAiB,GAAS,KAAK,YAAgB,GAAM,EAAI,IAEnE,GAAK,SAGV,gBAAgB,CAClB,MAAO,IAAO,KAAK,UAAW,GAAM,GAAI,MAAK,OAG3C,gBAAgB,CAClB,MAAO,IAAO,KAAK,UAAW,GAAM,GAAI,MAAK,IAG/C,eAAgB,CAKd,GAJI,KAAK,WAAa,MACpB,MAAK,UAAY,KAAK,OAExB,KAAK,UAAY,KAAK,MAClB,eAAiB,MAAM,CACzB,GAAM,GAAM,KACZ,EAAI,YAAc,GAAS,EAAI,YAAa,GAAM,EAAK,EAAG,MAUzD,YAAc,EAAkC,CACrD,MAAO,GAAI,EAAK,GAAO,EACrB,GAAI,EAAG,GACP,EAAG,GAAU,EAAG,YAAgB,MClD7B,oBAAwB,GAAiB,OAMvC,MAAK,EAAe,OAAQ,CACjC,MAAO,IAAU,MAAM,UAAU,CAAE,qBAGxB,YAAW,EAAe,CACrC,GAAM,GAAQ,KAAK,MACnB,GAAI,CACF,GAAI,GAAU,MAAQ,KAAM,KAAM,IAAI,OAAM,mBAC5C,GAAM,GAAY,KAAM,MAAK,KAAK,GAIlC,GAHA,KAAK,SAAS,MAAM,eAAgB,CAClC,cAEE,KAAK,IAAI,EAAQ,EAAU,WAAc,GAAK,EAChD,KAAM,IAAI,OAAM,4CAEX,EAAP,CACA,KAAM,IAAI,IAAa,CACrB,MAAO,EACP,QAAS,+CAxBV,MACW,AADX,GACW,UAAY,YACZ,AAFX,GAEW,iBAAmB,OCJrC,GAAI,IAAyB,EAUtB,aAAiC,CACtC,MAAO,MAAK,OAAS,Gd4BvB,GAAM,IAAS,EAAS,uBAEX,GAAsB,EACjC,IAAM,KACN,GAAK,GAGP,aAAiB,CACf,GAA4B,QAC5B,GAAoB,QAGtB,aAAmB,CACjB,YACO,GAAoB,UAG7B,EAAM,IAAM,CACV,EAAS,YAAY,YAAY,IACjC,GAAiB,IACjB,GAAkB,IAClB,GAAW,MAGb,mBAA2E,CACzE,GAAI,KACF,MAAO,CAAE,GAAI,CAAC,qCAGhB,GAAI,CAAC,EAAS,YAAY,YAAc,CAAC,KACvC,MAAO,CAAE,GAAI,CAAC,6BAGhB,GAAM,GAAI,GAAQ,WAClB,GAAI,GAAK,KAEP,MAAO,MACH,CAAE,KAAM,CAAC,sBAAwB,EAAS,YAAY,QACtD,GAGN,GAAI,EAAE,eAAgB,CAEpB,AAAK,EAAE,MAAM,KAAK,IAAM,GAAoB,SAC5C,GAAM,GAAY,KAAK,MAAQ,EAAE,MACjC,MAAI,GAAY,EACP,CAAE,GAAI,CAAC,6BACL,EAAY,EAAI,EAClB,CAAE,KAAM,CAAC,+CAET,CAAE,KAAM,CAAC,8CAGlB,IAAI,CACF,KAAM,GAAE,YACD,EAAP,CACA,MAAO,CAAE,KAAM,CAAC,yBAA2B,GAAmB,KAOlE,GAAM,GAAe,GACf,EAAiB,GACjB,EAAgB,GAChB,EAAiB,GACjB,EAAkB,GAElB,EAAO,KAAU,IAA4B,CACjD,GAAI,CACF,MAAO,MAAM,WACN,EAAP,CACA,EAAO,KAAK,GACZ,GAAO,KACL,yBAA2B,EAAE,KAAO,KAAO,GAAe,IAE5D,EAAK,KAAK,GAAmB,IAC7B,SAuBJ,GAnBA,KAAM,GAAK,IAAM,EAAE,WAAW,mBAAmB,2BAE7C,EAAS,oBAAoB,gBAC/B,KAAM,GAAK,IAAM,MAGf,EAAS,6BAA6B,gBAExC,KAAM,GAAK,IACT,KAA8B,MAAM,GAAO,CACzC,KAAM,IAAI,IAAa,CACrB,MAAO,EACP,QAAS,mBAAqB,KAC9B,MAAO,QAMX,EACF,GAAI,CACF,GAAM,GAAU,KAAM,IAAW,WAAW,UAC5C,AAAI,EAAM,IACR,EAAK,KAAK,uDAEL,EAAP,CACA,EAAO,KAAK,GACZ,EAAK,KAAK,6BAA6B,GAAmB,QAM9D,GACE,EAAS,qBAAqB,gBAC9B,EAAS,mBAAmB,eAC5B,CACA,GAAM,GAAwB,KAAM,GAAK,IAAM,MAG/C,GAAI,EAAQ,GACV,EAAK,KAAK,iCAAmC,YACpC,EAAS,qBAAqB,eACvC,OAAW,KAAW,MAAM,GAAE,gBAC5B,GAAI,CACF,GAAM,GAAO,KAAM,GAAQ,OAC3B,GAAI,GAAQ,KAAM,SAElB,GADA,EAAK,QACD,EAAQ,OAAS,CAAE,KAAM,GAAK,cAChC,EAAK,KAAK,GAAG,EAAQ,SAAS,gBAAqB,YAC1C,EAAW,GAAO,CAC3B,GAAM,GAAM,GAAW,EAAM,EAAK,YAClC,GAAO,MAAM,aAAc,CACzB,IAAK,EAAK,WACV,KAAM,EAAQ,KACd,WAAY,EACZ,KAAM,EAAK,IAAI,GAAM,EAAG,cAE1B,AAAI,GAAO,KACT,AAAI,EAAK,MACP,EAAK,KACH,GAAG,EAAQ,SAAS,oGAGtB,EAAK,KACH,GAAG,EAAQ,SAAS,6CAIxB,EAAI,UACJ,EAAS,cAAc,eAAiB,IAIxC,EAAK,KACH,QAAQ,GAAS,EAAI,+BACnB,EAAI,sBAKL,EAAP,CACA,EAAO,KAAK,GACZ,EAAK,KACH,mBAAqB,EAAQ,KAAO,KAAO,GAAmB,KAOxE,MAAI,GAAQ,IAAS,EAAQ,IAC3B,EAAG,KAAK,0CAEN,EAAS,OAAI,YACf,EAAK,QAAQ,GAAG,OAAI,UAAU,MAAM,MAElC,EAAS,OAAI,YACf,EAAK,QAAQ,GAAG,OAAI,UAAU,MAAM,MAGlC,EAAS,cAAc,gBACzB,KAAM,GAAK,IAAM,GAAU,cAM7B,EAAK,IAAI,GAAM,EAAQ,EAAK,KAGrB,GAAmB,CAAE,KAAI,OAAM,MAAK,QAAQ,MAGrD,GAAM,IAA8B,EAClC,SAAY,GAA6B,MACzC,IAGF,kBACE,EACe,CACf,GAAI,GAAW,KACb,MAAO,IAAO,MAAM,qDAEtB,GAAM,GAAM,EACV,KAAM,IAAS,IAAI,GAAY,UAAU,KAAK,UAAU,YACxD,KAAK,GAAM,EAAG,KAAK,WAAW,WAChC,GAAI,GAAO,KACT,MAAO,IAAO,MACZ,4DAGJ,EAAU,GAAS,IAAI,GACvB,GAAM,GAAU,EAAQ,KAAK,QAAU,GAAY,IAC7C,EAAO,EAAQ,KAAK,aAAe,EAAI,KAC7C,GAAI,CACF,KAAM,GAAI,UAAU,GACpB,GAAM,GAAS,KAAM,GAAI,MACnB,EAAU,KAAM,GAAK,MAC3B,GAAI,IAAW,EACb,MAAO,IAAO,MACZ,6CAA+C,EAAU,aACzD,CAAE,UAAW,KAGjB,GAAO,MAAM,2BAA2B,yBACxC,CACA,KAAM,GAAQ,KAAK,UetQvB,GAAM,IAAS,EAAK,IAAM,EAAS,uBAEtB,GAAqB,EAAK,IAAO,EAC5C,YAAa,IAAM,EAAS,YAAY,MACxC,aAAc,IAAM,KACpB,YAAa,IACX,KAAS,IAAI,CAAE,IAAK,cAAe,OAAQ,OAC7C,YAAa,IAAM,KACnB,QAAS,IAAM,KACf,OAAQ,IAAM,QCXhB,GAAM,IAAS,EAAK,IAAM,EAAS,cACtB,GAAY,EAAK,SAAY,CACxC,GAAI,CAAE,KAAM,MAAgB,OAC5B,KAAS,KAAK,qBACd,GAAM,GAAO,EAAS,QAAQ,eACxB,EAAQ,GACR,EAAI,GAAI,IAAO,EAAM,GAC3B,SAAE,kBAAkB,MACpB,KAAM,GAAE,QAER,KAAS,KAAK,4BAA8B,EAAE,MACvC,ICZF,GAAM,IAA+B,CAC1C,UAAW,CAAC,EAAc,IACxB,GACE,KACA,GAAM,EAAG,UAAU,EAAO,GAC1B,IAAM,EAAQ,KAAa,GAAM,EAAG,UAAU,EAAO,MCCpD,GAAM,KAAwB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUnC,QAAQ,MAAO,KAEV,gBAA2B,GAAM,OAS/B,QAAO,EAAU,GAAK,EAAU,CACrC,MAAO,MAAK,IAAI,KAAK,GACnB,EAAE,MAAM,YAAa,KAAM,KAAK,MAAQ,GAAS,sBAIxC,uBAA0C,CACrD,MAAO,MAAK,IAAI,UAAU,GACxB,EAAE,OAAO,QAAQ,MAAM,CAAE,SAAU,iBAI1B,WAA8B,CACzC,MAAO,MAAK,IAAI,UAAU,GAAK,EAAE,OAAO,qBAG7B,WAAa,CACxB,YACA,IACA,aAKyC,CACzC,GAAM,GAAQ,KAAK,MACb,EAAuC,GACvC,EAAS,KACf,KAAK,SAAS,MAAM,cAAe,CAAE,YAAW,WAChD,GAAM,GAAa,EAAM,MAAQ,EAAU,IAAI,GAAS,EACtD,OACA,SACA,SAAU,EACV,UAAW,KAAK,SAElB,KAAM,MAAK,GAAG,GAAM,EAAG,KAAK,GAAK,EAAE,OAAO,KAC1C,GAAM,GAAO,EAAK,IAAM,KAAK,SAAS,KAAK,qBAAsB,IACjE,GAAI,CACF,GAAM,GAAW,KAAM,IACrB,SAAY,CACV,GAAM,GAAe,GAEf,EAAS,KAAM,MAAK,GACxB,GAAM,EAAG,KAAK,GAAK,EAAE,MAAM,CAAE,WAAU,OAAO,CAAE,SAAU,KAC1D,GAEF,MAAI,IAAU,MAAQ,CAAC,GAAO,EAAO,EAAI,IAAW,IAC7C,GAAU,MAEnB,CAAE,YAAW,cAAe,GAAU,EAAG,OAI3C,GAFA,KAAK,SAAS,KAAK,cAAe,CAAE,YAAW,aAE3C,EAAU,CACZ,EAAM,UAAY,KAAK,MAAQ,EAC/B,GAAM,GAAI,KAAM,IAAa,SAAY,EAAE,IAC3C,EAAM,OAAS,EAAE,OACjB,EAAM,MAAQ,EAAE,kBAElB,CACA,GAAM,GAAI,KAAM,IAAa,IAC3B,GAAa,GAAG,GAAM,EAAG,KAAK,GAAK,EAAE,MAAM,CAAE,WAAU,YAEzD,EAAM,UAAY,EAAE,UACpB,EAAM,SAAW,GAEnB,MAAO,KA3EJ,MACW,AADX,GACW,UAAY,eACZ,AAFX,GAEW,iBAAmB,cA6E9B,GAAM,IAAoB,CAC/B,EACA,IAEA,GAAa,UAAU,CAAE,YAAW,IAAG,UAAW,IAAY,KAC5D,GAAK,EAAE,QAGE,GAA+C,CAC1D,sBC1GK,YAAiB,EAAa,EAAuB,CAC1D,MAAO,GAAE,IAAI,CAAC,EAAG,IAAQ,EAAI,EAAE,IAG1B,YAAiB,EAAoB,EAA4B,CACtE,MAAO,GAAO,IAAI,CAAC,EAAK,IAAW,CACjC,GAAI,EAAI,SAAW,EAAO,OACxB,KAAM,IAAI,OAAM,2BAA6B,GAE/C,MAAO,IAAI,EAAI,IAAI,CAAC,EAAK,IAAW,EAAM,EAAO,OCLrD,GAAM,IAAW,CACf,CAAC,SAAW,SAAW,UACvB,CAAC,SAAW,SAAW,SACvB,CAAC,SAAW,QAAU,WAgDjB,YAAiB,EAAuB,CAC7C,MAAO,IAAQ,GAAQ,IAOlB,YAAkB,EAAuB,CAC9C,MAEE,CAAC,EAAI,GAAI,EAAI,GAAI,EAAI,IAElB,IAAI,GAAM,GAAM,EAAG,IAAK,IAgBxB,YAAiB,EAAuB,CAE7C,GAAM,GAAO,GAAS,GACnB,IAAI,GAAM,EAAK,KACf,IAAI,GACH,EAAK,OAAU,KAAK,IAAK,GAAK,MAAS,MAAO,KAAO,EAAK,OAE9D,MAAO,IAAQ,GAAU,GAK3B,GAAM,IAAW,CACf,EAAG,OACH,EAAG,EACH,EAAG,SAKC,GAAU,IAAM,MAChB,GAAQ,MAAQ,GAEf,YAAiB,EAAuB,CAC7C,GAAM,CAAC,EAAI,EAAI,GAAM,GAAQ,EAAK,CAChC,EAAI,GAAS,EACb,EAAI,GAAS,EACb,EAAI,GAAS,IACZ,IAAI,GAAM,EAAI,GAAU,KAAK,IAAI,EAAG,EAAI,GAAM,IAAQ,EAAI,IAAM,KAEnE,MAAO,CAAC,IAAM,EAAK,GAAI,IAAO,GAAK,GAAK,IAAO,GAAK,IAgC/C,YAAiB,EAAc,EAAiC,CACrE,MAAO,IAAO,CACZ,KAAM,CACJ,CAAE,MAAO,EAAI,GAAI,IAAK,EAAG,IAAK,KAC9B,CAAE,MAAO,EAAI,GAAI,IAAK,IAAK,IAAK,IAChC,CAAE,MAAO,EAAI,GAAI,IAAK,IAAK,IAAK,KAElC,aAIG,YAAmB,EAAc,EAAkC,CACxE,MAAO,IAAS,EAAM,CACpB,KAAM,CACJ,CAAE,IAAK,EAAG,IAAK,KACf,CAAE,IAAK,IAAK,IAAK,IACjB,CAAE,IAAK,IAAK,IAAK,KAEnB,aC1KJ,GAAO,IAAgB,iBAoDV,GAAW,GAsBX,GAAY,EAUzB,GAAM,IAAS,EAAS,aAElB,GAAuB,IAEvB,GAAQ,GAAI,IAAmC,IAErD,EAAa,IAAM,GAAM,SACzB,GAAc,GAAS,EAAS,GAAQ,GAAM,OAAO,GAAQ,GAAM,SAEnE,GAAa,CAAC,EAAuB,IACnC,EAAI,GAAM,IAAI,GAAgB,GACrB,GAAM,SAAS,EAAgB,IAAM,KAiBzC,GAAM,IAAU,EAWV,GAAU,CACrB,MAAO,GACP,OAAQ,IAGV,YAAmB,EAAqB,CACtC,MAAO,IAAU,OAAO,MAAQ,EAAE,IAAI,GAAO,IAAO,EAAI,EAAI,GAAI,KAAK,MAGvE,YAAkB,EAA6C,CAC7D,GAAM,GAAsC,CAAC,GAAI,GAAI,IACrD,OAAS,GAAI,EAAG,EAAI,EAAI,OAAQ,GAAK,EAAG,CACtC,GAAM,GAAI,GAAQ,CAAC,EAAI,GAAI,EAAI,EAAI,GAAI,EAAI,EAAI,KAC/C,EAAI,GAAG,KAAK,EAAE,IACd,EAAI,GAAG,KAAK,EAAE,IACd,EAAI,GAAG,KAAK,EAAE,IAEhB,MAAO,GAMT,YAA0B,EAAiB,CACzC,GAAM,GAAS,EAAS,wBAAwB,eAChD,OAAW,KAAM,GACf,GAAI,KAAK,IAAI,EAAG,IAAM,GAAU,KAAK,IAAI,EAAG,IAAM,EAAQ,MAAO,GAEnE,MAAO,GAsBT,YAAgB,EAAe,CAC7B,MAAO,GAAI,EAAI,GAAI,GAAQ,GAAI,CAAC,GAAI,GAAM,GAAK,KAGjD,kBAA0B,EAA4C,CACpE,GAAM,GAAI,EAAS,aAAe,EAAO,KAEzC,GAAI,CAEF,GAAM,GAAW,KAAM,IAAc,EAAM,GADpB,IAEvB,GAAI,GAAY,KAAM,CACpB,EAAE,KAAK,gCACP,OAKF,GAAI,AADY,KAAM,IAAW,IAClB,KAAM,CACnB,EAAE,KAAK,4BACP,OAIF,GAAI,GAAK,GAAM,EAAS,YAErB,cAEH,AACE,EAAS,eAAe,KAAM,QAC9B,GAAG,KAAM,GAAS,OAAQ,EAAI,KAI9B,GAAK,EAAG,KAAK,IAMf,EAAK,EAAG,OAAO,OACV,IADU,CAMb,IAAK,GAAM,IAAI,KAKf,OAAQ,GAAM,OAAO,SACrB,iBAAkB,GAClB,mBAAoB,MAgBtB,GAAM,CAAE,KAAM,EAAM,KAAM,GAAY,KAAM,GACzC,MACA,SAAS,CAAE,kBAAmB,KAG3B,EAAS,GAAU,EAAG,EAAK,OAAQ,EAAG,GAC1C,GAAQ,CAAC,EAAK,GAAI,EAAK,EAAI,GAAI,EAAK,EAAI,MAEpC,EAAc,GAAiB,GAEjC,EAAW,GACb,EAAO,IAAI,GAAM,GAAQ,EAAI,KAC7B,IAGF,GAAI,CAAC,GAAe,EAAS,0BAA0B,eAAgB,CACrE,GAAM,GAAQ,KAAM,IAClB,uBAAuB,EAAK,IAAI,gBAChC,IAAM,EAAG,SAEL,GAAW,GACf,GAAQ,CAAC,EAAM,SAAS,EAAG,EAAM,SAAS,EAAG,EAAM,SAAS,IAC5D,IAEF,EAAW,EAAK,CAAC,GAAU,GAAG,IAAW,MAAM,EAAG,IAKpD,GAAM,GAAK,GAAM,EAAM,CACrB,IAAK,OAAK,GAAL,CAAc,SAAU,MAC5B,OAAO,CACR,MAAO,GACP,OAAQ,KAUJ,CAAE,KAAM,GAAS,KAAM,GAAG,MAAM,SAAS,CAAE,kBAAmB,KAM9D,EAAO,GAAS,GAgBhB,EAAW,EACb,CAAC,GAAO,EAAK,IAAK,EAAG,GACrB,GAAM,EAAG,GAAW,GAAO,EAAK,KAoB9B,GAAW,AAJD,GAAc,CAAC,EAAK,IAAM,GAIjB,IAAI,CAAC,EAAG,KAAM,CACrC,GAAM,IAAO,EAAS,IACtB,MAAO,GAAE,IAAI,IAAO,IAAM,GAAO,EAAI,KAQvC,GAAI,EAAa,CACf,GAAM,GAAQ,GAAM,GAAU,GAAS,IAAM,GAC7C,GAAS,KAAK,EAAO,GAkBvB,MAAO,CACL,SAXe,GAAU,GAAQ,KAajC,cAEA,MAAO,SAEF,EAAP,CACA,EAAE,KAAK,uBAAyB,EAAK,WAAa,IAAK,GACvD,QAgBJ,kBAAgC,EAA4C,CAC1E,MAAO,IAAM,SAAS,EAAK,WAAY,IACrC,GAAa,IACX,GAAK,gBAAgB,EAAK,IAAI,gBAAiB,IAAM,GAAW,KAChE,KAAK,CAAC,CAAE,YAAW,YACZ,GAAO,IAAI,CAChB,MAAO,GAAS,EAAW,EAAI,GAC/B,IAAK,cACL,SACA,KAAM,CACJ,KAAM,EAAK,WACX,iBC/VV,GAAM,IAAS,EAAK,IAAM,EAAS,eAE7B,GAAU,GAAI,QAClB,KAAK,GAAa,oBAIP,GAA2B,AAAC,GACvC,EAAI,GACD,OAAO,IACP,QAAQ,GAAM,GAAQ,KAAK,IAC3B,IAAI,GAAK,EAAE,GAAG,cAAgB,EAAE,IAChC,UAAU,IAAM,GAErB,YAAmB,EAAkB,EAAO,GAAqB,CAC/D,MAAO,IAAU,EAAU,GAAM,IAAI,GAAM,GAAU,EAAI,IAGpD,YAAwB,EAAkB,EAA8B,CAC7E,MAAO,IAAO,EAAU,IACtB,EAAI,GAAU,EAAU,GAAG,GAAQ,GAAM,GAAQ,EAAI,MAIlD,YAAyB,EAAsB,CACpD,MAAO,GAAK,SAAS,IAAU,EAAO,EAAO,GAG/C,YAAmB,EAAc,EAAkB,CACjD,AAAI,EAAQ,IACV,KAAS,KAAK,4BAA6B,CAAE,WAE/C,WAAa,EAAa,CACxB,MAAO,GAAG,QAAQ,GAAK,MAGzB,GAAM,GAAU,GAAI,KAClB,EACG,QACC,0CAA4C,EAAO,KAAK,KAAO,KAEhE,MACA,IAAI,CAAC,CAAE,KAAI,WAAY,CAAC,EAAI,KAE3B,EAAM,GACV,EAAO,IAAI,GAAM,CACf,GAAM,GAAO,EAAQ,IAAI,GACzB,MAAO,CAAE,KAAI,OAAM,KAAM,GAAsB,MAEjD,GAAM,CAAC,EAAG,KAAM,EAAG,OAIrB,EAAI,UAEJ,KAAS,KAAK,cAAe,CAAE,QAC/B,GAAM,GAAS,EAAI,GACb,EAAW,EAAO,GACxB,GAAI,EAAQ,IAAQ,CAAC,EAAI,GAAW,CAClC,KAAS,KAAK,8CAA+C,CAC3D,MACA,SACA,aAEF,OAEF,GAAM,GAAS,EAAI,MAAM,GAEzB,GAAI,EAAW,GAAS,CACtB,GAAM,GAAW,EAAO,IAAI,GAAM,EAAG,IAAI,KAAK,KAC9C,EACE,yCAAyC,qBAA4B,MAEvE,EACE,uCAAuC,wBAA+B,MAExE,EACE,uCAAuC,wBAA+B,MAExE,EAAI,wCAAwC,MAC5C,EAAI,gCAAgC,MAGtC,GAAM,GAAa,EAChB,QAAQ,wCACR,IAAI,CAAE,GAAI,IAAY,MAEnB,EAAe,GAAa,GAE5B,EAAW,EACd,QACC,qFAED,IAAI,CACH,WACA,KAAM,GAAa,EAAY,IAAU,IACzC,eAGJ,OAAW,KAAM,GAAU,CACzB,GAAM,GAAU,GAAY,CAC1B,GAAG,EACH,GAAG,GAAa,GAAsB,EAAG,MAAO,MAElD,AAAI,EAAG,QAAU,GACf,MAAS,KAAK,kCAAmC,CAAE,KAAI,YACvD,EAAG,QAED,iFACA,IAAI,CACJ,GAAI,EAAG,GACP,UAAW,KAAK,MAChB,KAAM,KAKZ,MAAO,MAAS,IAAI,CAClB,IAAK,cACL,MAAO,OACP,OAAQ,CAAE,SAAQ,UAClB,KAAM,CAAE,SAAQ,gBAIb,YAAoB,EAAc,CACvC,GAAM,GAAO,EACV,QACC,CACE,SACA,kCACA,mBACA,0BACA,WACA,gBACA,iBACA,kBACA,KAAK,MAER,MAEH,OAAW,KAAO,GAChB,EAAI,IAAM,EACR,EAAI,EAAI,KACL,MAAM,KACN,IAAI,GAAM,EAAM,KAKvB,UAAc,EAAM,GAAM,EAAG,MAAM,UAE5B,KAAS,IAAI,CAClB,IAAK,eACL,OAAQ,EAAK,IAAI,GAAM,GAAU,EAAI,EAAG,MACxC,KAAM,CAAE,UAWL,GAAM,IAAa,CACxB,yBAA0B,AAAC,GAAiB,CAC1C,EAAG,SACD,2BACA,CAAE,cAAe,IACjB,IAEF,EAAG,YAAY,IAAM,CACnB,EAAG,KAAK,0CACR,EAAG,KAAK,4DACR,EAAG,KAAK,gEAIZ,qBAAsB,SAAY,CAChC,GAAI,CAGF,KAAM,MACN,GAAM,GAAa,EAAS,cAAc,MAC1C,AAAI,IAAe,UACjB,GAAS,cAAc,MAAQ,SAC/B,KAAM,MACN,KAAS,KAAK,8CAA+C,CAC3D,sBAGG,EAAP,CACA,KAAS,MAAM,mCAAqC,KAIxD,oBAAqB,AAAC,GAAiB,CACrC,EAAG,SAAS,aAAc,CAAE,cAAe,IAAQ,IACnD,EAAG,SACD,qBACA,CAAE,cAAe,IACjB,IAEF,EAAG,SAAS,mBAAoB,CAAE,cAAe,IAAQ,IACzD,EAAG,YAAY,IAAM,CACnB,EAAG,KAAK,2DACR,EAAG,KAAK,6DACR,EAAG,KAAK,kEACR,EAAG,KACD,oEAEF,EAAG,KACD,6EAEF,EAAG,KACD,gFAEF,EAAG,KAAK,4CACR,EAAG,KAAK,oCACR,EAAG,KACD,iFAKN,aAAc,AAAC,GAAiB,CAC9B,EAAG,SAAS,iBAAkB,CAAE,cAAe,IAAQ,IAEvD,EAAG,YAAY,IAAM,CACnB,GAAM,GAAW,GACf,EAAG,KAAK,wCAA6C,cAEvD,EAAG,KACD,wBACE,GACE,GACA,GAAK,OAAO,+BAA+B,MAC3C,KAAK,YAKf,0BAA2B,AAAC,GAAiB,CAC3C,EAAG,SAAS,eAAgB,CAAE,cAAe,IAAQ,IACrD,EAAG,YAAY,IAAM,CACnB,GAAM,GAAO,EACV,QACC,0HAED,MACG,EAAW,GACjB,OAAW,KAAO,GAAM,CACtB,GAAM,GAAM,EAAI,EAAI,KAAK,MAAM,KACzB,EAAM,EACT,QACC,oEACE,EAAI,KAAK,KACT,KAEH,MACG,EAAS,GAAW,EAAK,GAAM,CACnC,EAAG,MACH,EAAG,QACH,EAAG,YAEC,EAAS,EAAI,OAAO,GAAM,EAAG,KAAO,EAAO,IACjD,EAAS,KAAK,GAAG,EAAO,IAAI,GAAM,EAAG,KAEvC,OAAW,KAAO,IAAQ,EAAU,KAClC,EAAG,KAAK,sCAAwC,EAAI,KAAK,KAAO,KAElE,EAAG,KAAK,qDAIZ,iBAAkB,AAAC,GAAiB,CAClC,EAAG,YAAY,IAAM,GAAW,OAGlC,iBAAkB,AAAC,GACjB,GAAG,SAAS,kBAAmB,CAAE,cAAe,IAAQ,IACjD,EAAG,YAAY,IAAM,CAC1B,GAAW,GACX,EAAG,KAAK,sDAKZ,oBAAqB,AAAC,GAAiB,CACrC,GAAM,GAAU,EACb,QACC,iFAED,MACH,KAAS,KAAK,yBAA0B,CAAE,YAC1C,OAAW,KAAO,GAAS,CACzB,GAAM,GAAc,GAAiB,EAAI,OACzC,GACE,EACA,EAAQ,CACN,EAAI,GACJ,GAAG,EACA,QAAQ,sCACR,QACA,IAAI,QAMf,eAAgB,AAAC,GAAiB,CAChC,GAAM,GAAK,qCACL,EAAS,EACZ,QAAQ,qDACR,QACA,MACG,EAAU,EAAO,OAAO,GAAM,EAAG,KAAK,IAAO,MACnD,KAAS,KAAK,mBAAoB,CAAE,SAAQ,YAC5C,OAAW,KAAM,GACf,EAAG,KAAK,cAAgB,KCxV9B,GAAM,IAAkB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAYxB,YAAwC,EAAyB,CAC/D,MAAO,GAAc,KAAK,SAAS,SAG9B,YAAgB,CAGrB,YACmB,EACT,EACR,EACA,CAHiB,qBACT,UAiBD,kBAAe,EAAK,IAC3B,KAAK,cAAc,SAAS,GAAK,EAAE,MAAQ,SAGpC,0BAAuB,EAAK,IACnC,KAAK,GAAG,QAAQ,+BAA+B,QAAQ,OAGhD,2BAAwB,EAAK,IAAM,CAE1C,GAAI,CAAC,GAAU,OAIf,GAAM,GAAoB,KAAK,uBAAuB,OACpD,GAAiB,CACf,GAAM,CAAC,EAAG,EAAG,GAAK,CAChB,EAAc,MAAM,EAAG,GACvB,EAAc,MAAM,EAAG,GACvB,EAAc,MAAM,EAAG,IACvB,IAAI,GAAK,EAAM,IACX,EAAgB,GAAI,MAAK,EAAG,EAAI,EAAG,GACzC,YAAK,OAAO,MAAM,mBAAoB,CACpC,gBACA,gBACA,aAMK,GAAQ,UAAY,EAAc,YAI7C,GAAI,EAAW,GACb,KAAM,IAAI,IAAa,CACrB,MAAO,GACP,UAAW,GACX,QACE,qGACF,MAAO,GAAI,OAAM,uBAAyB,EAAkB,KAAK,UAvDrE,KAAK,OAAS,EACZ,aACE,EAAU,CACR,OAAQ,EAAc,KACtB,GAAI,EAAO,aAEb,KAEJ,EAAG,KAAK,IACR,KAAK,iBAAmB,EAAG,QACzB,oEAkDE,OAAM,EAA6D,CACvE,KAAK,wBAEL,GAAM,GAAiB,KAAM,MAAK,eAClC,GAAI,GAAkB,KACpB,KAAM,IAAI,OAAM,gCAAkC,KAAK,eAEzD,GAAM,GAA8B,GAC9B,EAAuB,KAAK,uBAElC,OAAW,KAAiB,GAC1B,AAAI,EAAqB,SAAS,EAAc,MAC9C,KAAK,OAAO,MAAM,6BAA+B,EAAc,MAE/D,MAAM,GAAI,EAAiB,GAAM,EAAG,IACpC,KAAM,IACJ,KAAK,eAAe,GACpB,EAAI,EACJ,IAAM,CACJ,KAAM,IAAI,IAAa,CACrB,MAAO,GACP,UAAW,GACX,QAAS,aAAe,EAAc,KAAO,kBAInD,EAAkB,KAAK,EAAc,OAGzC,YAAK,OAAO,KAAK,gBAAiB,CAAE,sBAC7B,OAQH,gBAAe,EAAa,CAEhC,GAAc,EAAE,MAEhB,GAAI,CACF,GAAM,GAAQ,KAAK,MACb,EAAY,MAAM,GAAE,aAAc,OACtC,GAAM,EAAM,IAAO,EAAG,OAAO,WAAW,OAEpC,EAAI,GAAW,EAAE,KAAK,QAAQ,WAAY,KAC1C,EAAgB,GAAW,GACjC,GAAI,EAAQ,IAAa,EACvB,KAAM,IAAI,IAAa,CACrB,QAAS,mBAAqB,EAAE,KAChC,MAAO,KAGX,MAAI,GACF,KAAM,GAAE,KAAK,IAAY,KAAK,IAE9B,KAAM,MAAK,kBAAkB,GAE/B,KAAK,OAAO,MAAM,6BAA8B,CAC9C,UAAW,KAAK,MAAQ,EACxB,gBACA,UAAW,EAAE,iBAER,KAAK,GAAG,YAAY,IAAM,CAC/B,KAAK,iBAAiB,IAAI,EAAE,KAAM,KAAK,iBAElC,EAAP,CACA,MAAO,MAAK,OAAO,MACjB,6BAA+B,EAAE,eACjC,GAAe,UAKP,mBAAkB,EAAa,CAC3C,GAAM,GAAqB,GAA+B,GAC1D,GAAI,CACF,GAAM,GAAM,EAAI,KAAM,GAAE,YACxB,GAAI,EAAM,GAAM,CACd,KAAK,OAAO,MAAM,oBAAsB,GACxC,OAEF,AAAI,GAEF,KAAK,GAAG,OAAO,sBAOjB,OAAW,KAAM,GAAc,EAAI,MAAM,MACvC,GAAI,CACF,KAAK,GAAG,KAAK,SACN,EAAP,CACA,KAAM,IAAI,IAAa,CACrB,QACA,MAAO,GACP,QAAS,oBAAoB,MAInC,GAAI,EAAoB,CACtB,GAAM,GAAS,KAAK,GAAG,OAAO,qBAC9B,GAAI,EAAW,GACb,WAAK,OAAO,MAAM,2BAA4B,GACxC,GAAI,OACR,8CAAgD,EAAE,cAIxD,CACA,AAAI,GACF,KAAK,GAAG,OAAO,wBC1NvB,OAAoB,mBCDpB,OAA+B,uBAKxB,YAAuB,EAA0C,CACtE,GAAI,CACF,MAAO,GAAI,GACR,OAAO,GACP,QAAQ,aACR,QAAQ,GAAM,OAAO,EAAG,OACxB,WACH,CACA,QDDJ,GAAO,IAAa,0BAEb,YACL,EACA,EAAY,EAAS,YAAY,eACvB,CACV,GAAI,GACJ,GAAI,EAAS,OAAO,eAAgB,CAClC,GAAM,GAAS,EACb,UAAY,EAAW,MAAM,QAAK,MAAM,IAAI,KAAK,QAAO,KAEpD,EAAK,KACX,EAAU,AAAC,GAAgB,EAAO,IAAI,EAAI,EAAI,QAAQ,UAAW,MAEnE,SAAI,GAAc,GAAa,GAAc,CAC3C,EAAS,cAAc,SAAW,KAAK,IACrC,EAAS,cAAc,eACvB,KAAK,KAAM,IAAM,EAAc,KAEjC,EACE,QAAU,EAAa,KACvB,KACA,sCAAwC,EAAS,cAAc,MAC/D,CAAE,iBAGC,GACL,GAAI,IAAG,EAAY,CACjB,cAAe,GACf,SAAU,GACV,QAAS,EACT,aAKC,YAAoB,EAAwB,CACjD,GAAM,GAAU,CAId,qBAMA,aAAe,GAAM,EAAG,EAAG,MAG3B,oBAGA,eAAiB,GAAK,GAQtB,qBAQA,iBAAoB,EAAS,cAAc,eAAiB,GAAO,KAGnE,wBAGA,qBAGA,kBAAoB,EAAS,YAAY,eAazC,uBASA,sBAGF,UAAoB,IAAM,CACxB,OAAW,KAAU,GACnB,EAAG,OAAO,KAGP,EEpGF,GAAM,IAAiB,CAAC,OAAQ,YCdvC,GAAM,KAAS,EAAK,IAAM,EAAS,gBAK5B,YAAqB,EAA8B,CACxD,MAAO,CACL,EACA,GAAG,GAAe,IAAI,GAAM,EAAO,QAAQ,EAAO,KAAO,KACzD,OAAO,GAAM,EAAG,QAAQ,cCTrB,YACL,EACA,EACA,EAAY,EAAS,YAAY,eAC9B,CACH,GAAM,GAAI,GAAK,EAAI,GAAS,GAC5B,GAAI,CACF,MAAO,GAAE,UACT,CACA,EAAE,SAIN,kBACE,EACA,EACA,EAAY,EAAS,YAAY,eACrB,CACZ,GAAM,GAAI,GAAK,EAAI,GAAS,GAC5B,GAAI,CACF,MAAO,MAAM,GAAE,UACf,CACA,EAAE,SCJN,GAAO,KAAa,0BAEd,GAAS,EAAS,UAuCxB,kBAAoC,EAAiB,EAAkB,CACrE,GAAI,CACF,KAAM,GAAO,SAAS,UACtB,GAAM,GAAM,GAAI,IACd,CAAE,KAAM,EAAI,GAAQ,GAAI,cACxB,KAEF,KAAM,IACJ,EACA,GACE,EAAG,OAAO,EAAI,GAAS,CACrB,SAAS,CAAE,WAAY,EAAG,eAAgB,GAAK,CAC7C,SAAI,WAAa,GAAI,GAAK,EAAK,KACxB,OAGb,SAEK,EAAP,CACA,KAAM,IAAI,IAAa,CACrB,MAAO,EACP,MAAO,GACP,QAAS,wBAAwB,QAAY,OAKnD,GAAM,IAAK,CAAC,CAAE,gBAAiB,OAExB,YAAmB,EAAoB,CAC5C,GAAI,CACF,GAAM,GAAI,EAAG,OAAO,mBACpB,GAAI,GAAI,EAAG,IACT,UAAO,KAAK,YAAc,EAAG,KAAO,SAC7B,GAEP,KAAM,IAAI,OAAM,EAAU,UAErB,EAAP,CACA,KAAM,IAAI,IAAa,CACrB,QACA,MAAO,GACP,UAAW,GACX,QAAS,YAAc,EAAG,KAAO,cAKhC,YAAkB,EAAuB,CAC9C,GAAI,CACF,MAAO,IAAU,QACjB,CACA,MAAO,IAOJ,YAAuB,EAAiC,CAC7D,MAAO,IAAW,EAAQ,GAAW,GAGvC,GAAM,IAAkB,CAEtB,0BAKA,YAEK,YAAoB,EAAc,CACvC,GAAO,KAAK,2BAA4B,EAAG,MAC3C,OAAW,KAAU,IACnB,EAAG,OAAO,GAEZ,GAAO,KAAK,0BAWd,kBACE,EACA,EAAyB,UACzB,EAAQ,GACR,CAEA,GAAM,GAAO,AADG,MAAM,GAAM,SAAS,KAAK,GAAI,eACzB,KAAK,EAAM,MAChC,GAAO,KAAK,iBAAiB,QAAY,MACzC,GAAI,CACF,GAAM,GAAM,KAAM,MACZ,EAAO,EAAI,GAAM,KAAM,GAAM,OAAW,KACxC,EAAY,GAAK,EACjB,EAAM,GAAI,IACd,CAAE,KAAM,EAAI,GAAQ,GAAI,gBACxB,GAEI,EAAI,GAAI,IAER,EAAO,GAAS,EAAK,CAAC,EAAM,WAAY,IAAM,GAAK,EAAI,EAAU,CACrE,SAAU,SACV,cAEF,EAAK,OAAQ,GAAG,QAAS,GACvB,EACE,UAAY,EAAK,eAAiB,EAClC,GAAI,IAAa,CAAE,QAAO,YAG9B,GAAM,GAAO,GAAS,EAAK,CAAC,EAAK,YAAa,EAAI,EAAU,CAC1D,SAAU,SACV,cAEF,EAAK,GAAG,OAAQ,IAAM,EAAE,WACxB,EAAK,OAAQ,GAAG,MAAO,IAAM,CAC3B,EAAK,MAAO,IACV,GAAgB,IAAI,GAAM,UAAY,EAAK,KAAK,KAAK;AAAA,MAGzD,EAAK,OAAQ,GAAG,OAAQ,GAAO,CAC7B,GAAM,GAAO,EAAwB,OACrC,EAAI,aAAa,GACjB,EAAK,MAAO,MAAM,KAGpB,KAAM,GAEN,KAAM,IAAc,GACpB,GAAO,KAAK,oBAAoB,iCAChC,GAAM,GAAS,KAAM,IAAY,GAAY,GAAQ,GACnD,EAAG,cAAc,kBAEnB,YAAM,IAAY,GAAY,GAAO,GAAM,EAAG,IAAI,EAAM,WAEjD,EAAO,KAAK,GAAM,EAAG,MAAQ,OAAS,EAAG,IAAI,WAAW,kBACxD,EAAP,CACA,MAAO,IAAO,MACZ,kHACE,GACF,IASN,kBAAyC,EAAqB,CAC5D,GAAI,KAAM,GAAU,YAAa,OACjC,GAAM,GAAU,KAAM,GAAU,SAAS,KAAK,kBAAkB,SAC1D,EAAQ,KAAM,IAAS,sBAAsB,GACnD,GAAI,GAAW,MAAQ,GAAS,KAAM,MAAO,GAC7C,GAAM,GAAO,EAAQ,KAAK,KAAc,IAAM,EAAU,MACxD,YAAM,IAAc,EAAW,GACxB,EAST,kBAAoC,EAAqB,EAAmB,CAC1E,GAAO,KAAK,2BAA6B,EAAY,OAAS,GAC9D,GAAM,GAAW,GAAY,GAAW,OAAO,GAAM,CAAC,EAAG,IAAI,IAC7D,KAAM,GAAU,UAAU,GAE1B,KAAM,IAAY,EAAU,GAAM,EAAG,UAAU,IAAU,MAAM,GAC7D,GAAO,KAAK,8BAA+B,ICpNxC,oBAAiB,GAAe,CAOrC,YACW,EACA,EACA,EAA0B,IAAG,GACtC,CACA,MAAM,MAAQ,EAAS,IAAK,IAAM,KAAK,UAAW,EAAa,IAJtD,cACA,gBACA,oBARF,kBAAe,EAiEf,aAAU,EAAK,SAAY,CAClC,GAAM,GAAO,KAAK,OAClB,GAAI,KAAK,IAAM,MAAQ,GAAQ,KAC7B,KAAM,IAAI,OAAM,uCAElB,KAAM,MAAK,cAGX,GAAM,GAAkB,EAAK,SAC3B,MAAK,eACE,GAAmB,KAEtB,EAAY,GAAI,IACpB,GAAS,IAAI,GAAY,cAAc,KAAK,KAAK,QACjD,KAAK,GACL,GAGF,MAAO,CAAE,kBADiB,KAAM,GAAU,MAAM,GACpB,eAmCrB,aAAU,EACjB,IAAM,KAAK,UACX,EAAS,YAAY,eAAiB,MA3GpC,UAAU,CACZ,MAAO,GAAO,KAAK,SAAU,SAG3B,SAAS,CACX,MAAO,IAAS,KAAK,QAAS,KAAK,WAGjC,OAAO,CACT,MAAO,MAAK,KAAO,MAAQ,KAAK,IAAI,QAGlC,gBAAgB,CAClB,MAAO,MAAK,MAAQ,AAAS,KAAK,KAAK,gBAAnB,GAGtB,QAAQ,EAAgB,CACtB,MAAO,MAAK,GAAI,QAAQ,GAG1B,OAAO,EAAgB,EAAqC,CAC1D,MAAO,MAAK,GAAI,OAAO,EAAQ,MAG7B,KAAK,CACP,GAAM,GAAe,KAAK,KAAO,KACjC,GAAI,CAAC,KAAK,KAAM,CACd,KAAK,OAAO,KAAK,mCAAqC,KAAK,OAAQ,CACjE,iBAEF,GAAI,CACF,KAAK,OAAO,SAAS,cACrB,KAAK,IAAM,GAAK,KAAK,OAAO,YAC5B,GAAM,GAAoB,KAAK,IAAI,OAAO,cAAe,CACvD,OAAQ,KAEV,GAAI,IAAc,KAChB,KAAM,IAAI,OACR,iCAAmC,EAAY,UAG5C,EAAP,CACA,KAAM,IAAI,IAAa,CACrB,QACA,MAAO,GACP,QAAS,oBAAsB,KAAK,UAI1C,MAAO,MAAK,IAwBd,SAAU,CACR,GAAI,CACF,AAAI,AAAS,KAAK,KAAK,OAAnB,IACF,MAAK,OAAO,KAAK,aAAc,KAAK,KACpC,KAAK,KAAK,eAEL,EAAP,CACA,KAAK,OAAO,KAAK,6BAA8B,GAEjD,KAAK,IAAM,YAGP,cAAc,CAClB,GAAI,GAAc,GAClB,GAAI,CAEF,EAAc,GAAS,KAAK,SAC5B,CACA,EAAc,GAEhB,AAAK,GACH,MAAK,OAAO,KACV,gFAEF,KAAM,MAAK,gBAIT,SAAS,CACb,KAAM,IAAgB,IAAM,KAAK,gBAQrB,UAAU,CACtB,GAAI,CACF,KAAM,IAAgB,IAAM,CAC1B,GAAW,KAAK,IAChB,KAAK,GAAG,KAAK,WACZ,KAAK,eACD,EAAP,CACA,KAAK,OAAO,KACV,0DACA,GAEF,KAAM,MAAK,gBAID,UAAU,CACtB,KAAK,OAAO,KAAK,mCAAqC,KAAK,QAC3D,KAAK,UACL,KAAM,IAAgB,IAAM,GAAc,KAAK,SAC/C,KAAK,OAAO,KAAK,qDChKd,YAAgB,CACrB,YACW,EACA,EACA,EACA,EAAgB,KACzB,CAJS,WACA,WACA,YACA,aAGX,SAAkB,CAChB,MAAO,MAAK,aAGd,YAAqB,CACnB,MAAO,CAAC,KAAK,MAAO,MAAQ,KAAK,IAAK,MAAQ,KAAK,IAAK,KAAK,MAAM,KAAK,KAG1E,OAAO,EAA0B,CAC/B,MAAO,GAAK,KAAK,KAAK,oBAKjB,UAAS,EAAiC,CAC/C,MAAO,MAAK,aAAa,EAAE,YAGtB,cAAa,EAAgC,CAClD,MAAO,GACL,KAAK,QAAQ,KAAK,GAClB,GACE,GAAI,IACF,SAAS,EAAE,GAAI,IACf,SAAS,EAAE,GAAI,IACf,EAAE,GACF,EAAE,OAlCL,MAoBmB,AApBnB,GAoBmB,QAAU,sCA4B7B,YAAY,CAeT,YACG,EACA,EACD,EACR,CAHS,WACA,YACD,WAGD,UAAO,EAAK,IAAM,GAAM,KAAK,KAAM,GAAK,KAAK,IAAI,EAAG,IAAI,uBApBpD,KAAI,EAAe,EAAc,CAC5C,MAAO,IAAI,IAAM,EAAK,EAAM,EAAO,KAAM,IAAM,OAAO,GAAM,iBAGjD,QAAO,EAAe,CACjC,MAAO,IAAI,CACT,GAAG,EACD,KAAM,GAAQ,EAAI,aAAc,GAC9B,EAAI,IAAI,GAAM,GAAU,aAAa,IAAK,SAc1C,IAAI,EAAqB,CAC/B,MAAO,MAAK,KAAO,KAAK,OAAO,UAAU,GAAK,EAAM,GAAM,GAG5D,KAAK,EAAyB,CAE5B,GAAM,GAAM,EAAE,KAAK,IACnB,MAAO,IAAI,IAAU,EAAK,KAAK,IAAI,GAAM,QAGrC,aAAmC,CACvC,GAAM,GAAa,KAAM,MAAK,IAAI,QAAQ,aAC1C,MAAO,GAAQ,GAAY,IAAI,GAAM,GAAU,aAAa,UAMxD,iBAAgB,EAA2C,CAE/D,GAAM,GAAM,KAAM,IAAW,EAAO,IAAM,KAAK,cACzC,EAAQ,GAAQ,EAAK,GAAM,EAAG,KAC9B,EAAqB,GAC3B,OAAW,KAAO,GAAM,OACtB,EACE,GAAW,EAAM,IAAI,GAAO,GAAM,EAAG,KACrC,GAAQ,EAAM,KAAK,IAGvB,MAAO,QAMH,iBAAgB,EAA2C,CAE/D,GAAM,GAAM,KAAM,IAAW,EAAO,IAAM,KAAK,cAEzC,EAAY,AADJ,MAAM,MAAK,gBAAgB,IACjB,IAAI,GAAM,EAAG,KACrC,MAAO,GAAI,OAAO,GAAM,CAAC,EAAU,SAAS,EAAG,WAG3C,aAAkC,CACtC,MAAO,MAAK,kBAAkB,KAAK,GACjC,EAAM,IAAI,GAAM,EAAG,OAAO,KAAK,SClIrC,OAAuB,sBAEhB,aAAuB,CAC5B,MAAO,YAAU,MAAQ,UAAO,WAAa,UAAO,cAG/C,YAAoB,KAAgB,EAAuB,CAChE,AAAI,MACJ,QAAQ,IAAI,EAAK,GAAG,GCgBf,GAAM,KAA2B,EAAI,GAOrC,oBAAuB,GAAgB,CAW5C,YACW,EACA,EACA,EACA,EACA,EACA,EAA0B,IAAG,GAC7B,EAA8B,IAAG,GAC1C,CACA,MAAM,CACJ,KAAM,YAAc,EAAY,IAChC,SAAU,IAAM,KAAK,SACrB,WAAY,EAAS,wBAAwB,eAAiB,EAC9D,KAAM,EAAa,QAZZ,UACA,mBACA,iBACA,kBACA,kBACA,oBACA,wBAjBF,kBAAe,EACP,WAAQ,GAAI,IA6CZ,WAAQ,EAAK,IAC5B,GAAM,IAAI,KAAK,WAAY,EAAS,eAAe,iBAtBnD,AAAK,MACH,KAAK,OAAO,KAAK,SAAY,CAC3B,KAAM,MAAK,MAAM,OAAO,iBAAkB,SAAY,CACpD,AAAI,MACF,GAAW,0BAA4B,EAAG,OAAS,OACrD,KAAM,MAAK,QAAQ,IACf,MACF,GACE,mDACE,EACA,SAON,QAAS,CACf,MAAO,MAAK,MAAM,SAAS,oBAAqB,IAAM,KAAK,gBAO/C,SAAQ,EAAQ,KAAK,MAAO,CACxC,GAAI,CAAE,KAAM,MAAK,cAAgB,CAC/B,KAAK,OAAO,KAAK,oCACjB,OAEF,GAAI,CAAC,GAAS,CAAC,KAAK,GAAG,KAAM,CAC3B,KAAK,OAAO,KAAK,kCAAmC,KAAK,GAAG,MAC5D,OAGF,GAAI,KAAM,MAAK,UAAU,QAAQ,UAAW,CAC1C,KAAK,OAAO,KAAK,2BAA4B,KAAK,UAAU,YAC5D,OAEF,GAAI,CACF,KAAK,OAAO,KAAK,4BAA6B,CAC5C,MAAO,KAAK,UAAU,WACtB,WAAY,KAAK,WAAW,aAG9B,KAAM,MAAK,eAEP,GAAS,KAAK,GAAG,MACnB,MAAK,OAAO,KAAK,yCACjB,KAAM,MAAK,GAAG,WAMhB,GAAM,GAAkB,KAAK,UAC1B,SACA,KAAK,SAAU,KAAK,UAAU,MAEjC,KAAK,OAAO,KAAK,gCAAkC,GACnD,KAAM,IAAc,KAAK,UAAW,GAEpC,KAAK,OAAO,KAAK,qCAAuC,GACxD,KAAM,IAAc,GAEhB,KAAK,YAAc,MAErB,MAAK,OAAO,KAAK,wBAA0B,KAAK,YAChD,KAAM,IAAc,EAAiB,KAAK,aAG5C,GAAM,GAAU,KAAM,IAAY,GAC5B,EAAQ,KAAM,MAAK,QAEnB,EAAc,AADT,EAAM,KAAK,IACC,aACvB,KAAK,OAAO,KACV,+BAAiC,KAAK,WAAW,KAAK,IAExD,OAAW,KAAU,GACnB,KAAM,GAAO,IAAI,KAAK,WAAW,KAAK,EAAc,EAAO,MAAO,CAChE,UAAW,KAGf,OAAW,KAAK,MAAM,GAAM,aAC1B,KAAK,OAAO,KAAK,mCAAqC,GACtD,KAAM,GAAE,SAEV,KAAK,OAAO,KAAK,mCACjB,KAAM,MAAK,yBACJ,EAAP,CACA,KAAK,OAAO,MAAM,EAAO,CACvB,KAAM,4BACN,MAAO,GACP,MAAO,KAAK,UAAU,gBCnJvB,GAAM,IAAa,EAAK,SAAY,CACzC,GAAM,GAAU,KAAW,KAAK,YAChC,YAAM,GAAQ,KAAK,cAAc,UAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,iFAOpC,ICVF,GAAM,IAAe,EACf,GAAY,EAEZ,GAAY,IAAgB,GAElC,aAA4B,CACjC,MAAO,IAAU,EAAG,ICaf,YACL,EACA,EACA,EACQ,CACR,GAAM,CAAC,EAAG,EAAG,EAAG,EAAG,GAAK,GAAQ,GAC1B,EAAI,EACJ,EAAI,IAAI,KAAK,KAAK,KAAK,KAAK,MAAM,IAClC,EAAI,IAAI,KAAK,KAAK,MAAM,IAC9B,MAAO,KAAK,OAAO,MAAM,MAAM,IAW1B,GAAM,IAAS,CACpB,CAAC,UAAW,UAAW,UAAW,WAClC,CAAC,QAAS,QAAS,QAAS,SAC5B,CAAC,UAAW,UAAW,UAAW,WAClC,CAAC,QAAS,QAAS,QAAS,SAC5B,CAAC,UAAW,UAAW,UAAW,WAClC,CAAC,QAAS,QAAS,QAAS,SAC5B,CAAC,UAAW,UAAW,UAAW,WAClC,CAAC,QAAS,QAAS,QAAS,UAKjB,GAAW,CACtB,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,SAGK,YAAoB,EAAc,CAEvC,MAAO,AADS,IAAa,GAAc,EAAM,IAClC,IAAI,CAAC,EAAI,IAAQ,GAAO,GAAK,IAGvC,GAAM,IAAU,GACrB,AAAC,GAAiB,CAChB,GAAM,CAAC,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAK,GAAW,EAAO,IAC7C,EAAS,CAAC,EAAI,EAAG,EAAI,EAAG,EAAI,EAAG,EAAI,GAAG,IAAI,GAAM,GAAQ,EAAI,IAClE,SAAO,KAAK,GAAS,EAAO,GAAS,SAC9B,GAET,CAAE,QAAS,IAAK,MAAO,IC9FlB,YAAc,CAInB,YAAqB,EAAY,CAAZ,UAErB,eAAe,EAAqB,CAClC,GAAM,GAAS,GACf,SAAI,EAAc,GAAO,EAAE,aAAe,EAAG,WACtC,GAAY,gBAAgB,KAAK,KAAM,KCJ3C,oBAAuB,GAAM,CAIlC,KAAM,CACJ,MAAO,CACL,EAAO,KAAK,QAAS,IAAM,EAAI,KAAK,MAAO,GAAM,EAAG,KACpD,EAAO,KAAK,MAAO,IAAM,EAAI,KAAK,IAAK,GAAM,EAAG,MAChD,KAAK,WASF,gBAAe,EAAiB,EAAkB,CACvD,GAAM,GAAc,GAAG,GACvB,GAAI,GAAe,KAAM,CACvB,KAAK,SAAS,KAAK,sCACnB,OAEF,GAAM,GAAa,EAAQ,EAAO,IAAI,KACtC,GAAI,EAAQ,GAAa,CACvB,KAAK,SAAS,KAAK,8BAA+B,CAAE,UAAS,WAC7D,OAEF,GAAM,GACJ,wDACA,EAAW,IAAI,GAAS,IAAI,KAAe,MAAU,KAAK,KAC5D,MAAO,MAAK,IAAI,IAAI,SAGf,qBAAoB,EAAiB,EAAkB,CAC5D,EAAS,EAAQ,GACjB,GAAM,GAAI,KAAK,QACZ,QAAQ,QAAS,GACjB,SAAS,CAAE,YACX,SACH,MAAO,MAAK,IAAI,IAAI,KAvCf,AADF,GACE,UAAuB,WACd,AAFX,GAEW,iBAAmB,gBCcrC,YAAoB,EAAU,CAC5B,MAAO,CAAE,GAAI,EAAE,GAAI,GAAI,EAAE,iBAGpB,YAAwB,CAG7B,YACW,EACA,EACA,EACA,EACT,CAJS,YACA,cACA,aACA,aANF,YAAS,IAAM,EAAS,qBAAuB,KAAK,WAAa,KAQxE,KAAK,SAAS,KAAK,MAAO,KAAK,UAGjC,QAAS,CACP,GAAc,KAAK,OAAQ,AAAC,GAAa,CAAC,CAAC,EAAE,gBAAiB,CAAC,EAAE,KACjE,GAAa,KAAK,OAAQ,KAAK,OAC/B,GAAc,KAAK,MAAO,AAAC,GAAa,CAAC,CAAC,EAAE,gBAAiB,CAAC,EAAE,KAChE,GAAY,KAAK,MAAO,KAAK,OAG/B,UAAW,CACT,MAAO,MAAK,KAAK,IAAI,GAAM,EAAG,KAAK,KAAK,MAAM,KAAK,KAGrD,SAAU,CACR,MAAO,MAAK,cAGV,SAAS,CACX,MAAO,GAAI,KAAK,QAAQ,OAAS,EAAI,KAAK,OAAO,OAGnD,QAAQ,EAAiB,CACvB,MAAO,CACL,GAAG,GAAM,KAAK,MAAQ,EAAI,OAAQ,GAAO,EAAE,GAAI,CAAE,GAAK,GAAI,EAAG,KAC7D,GAAG,GAIP,SAAS,EAAiB,CACxB,MAAO,CACL,GAAG,EACH,GAAG,GAAM,KAAK,MAAQ,EAAI,OAAQ,GAAO,EACvC,GAAI,CAAE,GAAK,KAAK,MAAQ,GACxB,EAAG,MAKT,QAAS,CACP,MAAO,CACL,KAAM,KAAK,KAAK,IAAI,GAAO,EAAI,YAC/B,cAAe,KAAK,MAAM,IAAI,IAC9B,eAAgB,KAAK,OAAO,IAAI,KAIpC,UAAU,EAAwB,CAOhC,GAAW,KAAK,KAAM,EAAI,KAAM,GAAM,EAAG,MAGzC,GAAW,KAAK,OAAQ,EAAI,OAAQ,GAAM,EAAG,IAG7C,GAAW,KAAK,MAAO,EAAI,MAAO,GAAM,EAAG,IAC3C,KAAK,SAAS,MAAM,uBAAwB,CAC1C,IAAK,EAAI,SACT,KAAM,KAAK,KAAK,IAAI,GAAM,EAAG,MAC7B,UAAW,KAAK,OAAO,IAAI,IAC3B,SAAU,KAAK,MAAM,IAAI,WAIvB,QAAiC,CACrC,YAAK,SACE,KAAK,SAAS,IAAI,CACvB,IAAK,UACL,OAAQ,CACN,KAAM,KAAM,IAAY,KAAK,KAAM,GAAM,EAAG,YAC5C,cAAe,KAAK,QAAQ,KAAK,MAAM,IAAI,GAAM,EAAG,SACpD,eAAgB,KAAK,SAAS,KAAK,OAAO,IAAI,GAAM,EAAG,YAK7D,YAAY,EAAwB,CAClC,MAAO,MAAK,SAAS,IAAI,CACvB,IAAK,cACL,KAAM,CACJ,KAAM,KAAK,KAAK,IAAI,GAAM,EAAG,MAC7B,IAAK,EAAI,KAAK,IAAI,GAAM,EAAG,OAE7B,OAAQ,GACN,CAAC,GAAG,KAAK,OAAQ,GAAG,KAAK,OACzB,CAAC,GAAG,EAAI,OAAQ,GAAG,EAAI,OACvB,GAAM,EAAG,QAMV,YACL,EACqB,CACrB,GAAM,GAAgB,EAAS,iBAAiB,eAAiB,IAC3D,EAA8B,GAC9B,EAAY,EAAQ,OAAO,GAAM,EAAG,OAAS,GACnD,OAAW,KAAU,GAAW,CAC9B,GAAM,GAAU,GAAW,EAAQ,GACjC,GAAS,EAAG,YAAY,GAAS,IAEnC,AAAI,GAAW,KACb,EAAO,KAAK,GAEZ,EAAQ,UAAU,GAGtB,MAAO,GC5GT,YAAiB,EAA4B,CAC3C,MAAO,GAAQ,WAAW,2CAG5B,EAAa,IAAM,GAAI,SAEvB,kBAAwB,EAA6C,CACnE,GAAM,GAAI,KAAM,GAChB,MAAI,IAAK,MAAM,GAAI,SAAS,GACrB,EAGF,oBAAkB,GAAiB,CAAnC,aAtDP,CAsDO,oBAsMI,UAAO,EAAK,IAAM,GAAI,IAAQ,KAAK,KAiFnC,iBAAgD,EAAK,SAAY,CACxE,GAAM,GAAI,KAAM,MAAK,YACrB,MAAO,CAAC,GAAI,GAAK,KAAO,GAAK,KAAM,IAAG,cAAgB,KAAK,eAyFpD,mBAAgB,EAAK,SACrB,GAAI,IAAI,SAAS,CACtB,IAAK,GACH,sCACA,oBACA,UACA,kBACA,0BACA,wCACA,IACA,aACA,mBACA,sBAEF,SAAU,CAAE,MAAO,KAAK,MAEzB,EAAI,GA2GE,iBAAc,EAAK,SACtB,KAAK,WAAa,GAAK,KAAK,UAAY,KAAa,GAClD,GAAI,IAAI,SAAS,CACtB,IAAK,GACH,CACE,oCACA,oBACA,UACA,wBACA,wBACA,gCACA,IACA,YACA,WACA,4BACA,yBACA,uBACA,KAAK,MAET,SAAU,CAAE,MAAO,KAAK,aA7erB,QAAQ,CACb,KAAK,KAAK,QACV,KAAK,MAAM,QACX,KAAK,oBAAoB,QACzB,KAAK,iBAAiB,QACtB,KAAK,QAAQ,cAIR,WAAU,EAAY,CAC3B,MAAO,GAAI,IAAI,GAAM,KAAK,SAAS,UAG9B,UAAS,EAA6B,CAC3C,MAAI,IAAO,MAAM,KAAK,iBAAiB,IAAI,EAAI,MAAO,QAAQ,QAAQ,IAClE,GAAK,IAAM,MAAM,KAAK,QAAQ,IAAI,EAAI,GAAI,QAAQ,QAAQ,IACvD,QA+CF,QAAO,EAAuB,CACnC,GAAM,GAAI,GAAI,IACd,EAAE,MAAQ,GAAY,GACtB,GAAM,GAAI,EAAQ,EAAQ,OAAS,GACnC,MAAI,IAAK,MAAQ,GAAS,IACxB,GAAI,EAAE,YAAa,GAAO,EAAE,aAAe,GAC3C,EAAI,EAAE,QAAS,GAAO,EAAE,QAAU,GAClC,EAAI,EAAE,YAAa,GAAO,EAAE,YAAc,GAC1C,EAAI,EAAE,WAAY,GAAO,EAAE,WAAa,IAEnC,QAGF,gBAAe,EAAsB,EAAmB,CAC7D,MAAO,KAAU,EACb,GAAI,OACJ,EAAI,GACJ,KAAK,SAAS,GACd,KAAK,WAAW,SAGf,UAAS,EAAe,CAC7B,MAAO,KAAU,EACb,GAAI,OACJ,GAAI,QAAQ,SAAS,EAAO,IAAM,GAAS,KAAK,MAAM,SAAS,iBAGxD,YAAW,EAAqC,CAC3D,GAAM,GAAQ,GAAY,GAC1B,MAAO,GAAM,GACT,GAAI,OACJ,GAAI,iBAAiB,SAAS,EAAO,IACnC,EAEE,KAAK,MAAM,OAAO,GAAK,EAAE,MAAM,QAAS,OAAQ,IAChD,GAAM,GAAI,SAAS,WAKtB,gBAAe,EAAe,EAAyB,CAC5D,GAAM,GAAI,GAAI,IACd,SAAE,GAAK,EACA,EAAE,iBAAiB,eAGf,cAAa,EAAgC,CACxD,GAAI,EAAQ,GACV,KAAM,IAAI,OAAM,iBAElB,GAAM,GAAO,GAAY,EAAS,KAC5B,EAAS,KAAM,MAAK,WAAW,GAErC,GADA,KAAK,SAAS,MAAM,iBAAmB,EAAO,IAAK,CAAE,UACjD,GAAS,KACX,MAAO,GAGT,GAAM,GAAS,KAAK,OAAO,GACrB,EACJ,EAAO,OAAS,EACZ,OACA,KAAM,MAAK,aAAa,EAAQ,MAAM,EAAG,KAC/C,EAAI,EAAQ,GAAM,EAAO,SAAW,EAAE,IACtC,GAAM,GAAU,KAAM,IAAS,KAAK,MAAM,UAAU,IACpD,YAAK,SAAS,MAAM,iBAAmB,EAAO,aAAc,CAC1D,SACA,SACA,WAEK,EAmCT,OAAQ,CACN,YAAK,OAAS,OACd,KAAK,KAAO,OACZ,KAAK,SAAW,OAChB,KAAK,UAAY,OACjB,KAAK,OAAS,OACd,KAAK,cAAgB,OACrB,KAAK,YAAY,QACjB,KAAK,cAAc,QACZ,KAKT,YAAY,EAAc,CACxB,MAAO,IAAY,CAAC,GAAG,KAAK,WAAY,SAGpC,YAAW,EAAc,CAC7B,MAAO,MAAK,WAAW,KAAK,YAAY,IAG1C,uBAAuB,EAA4B,CACjD,MAAO,GAAM,IAAgB,IAAgB,KAAK,aAC9C,OACA,KAAK,OAAO,CAAE,aAAc,SAG5B,YAAW,EAAiB,EAAe,GAAM,CACrD,GAAM,GAAY,KAAK,MAGjB,EAAkB,KAAM,IAAI,WAAW,GAAa,IAE1D,KAAK,SAAS,KAAK,iBAAkB,CACnC,YACA,UACA,oBAGF,GAAI,CACF,AAAI,GAAmB,KACrB,MAAM,IAAI,GAAG,SAAY,CACvB,KAAM,IAAI,IAAI,KAAK,GACjB,EAAE,MAAM,QAAS,OAAQ,EAAY,KAAK,OAAO,CAC/C,UAAW,KAAK,MAChB,MAAO,GAAK,IAAI,uBAAwB,CAAC,EAAW,SAI1D,KAAK,MAAQ,GAGb,GAAU,EAAgB,MAC1B,KAAK,SAAS,KAAK,uCAAwC,GAG3D,KAAM,IAAS,IAAI,eAAe,GAChC,EAAE,MAAM,CAAE,MAAO,KAAK,KAAM,OAAO,CAAE,MAAO,EAAgB,MAE9D,KAAM,IAAS,IAAI,KAAK,GAAK,EAAE,MAAM,CAAE,MAAO,KAAK,KAAM,UAGzD,KAAM,IAAY,KAAK,cAAe,GACpC,EAAG,WAAW,GAAY,CAAC,GAAG,EAAgB,KAAM,EAAG,OAAQ,KAIjE,KAAM,IAAI,IAAI,KAAK,GACjB,EACG,MAAM,CAAE,SAAU,KAAK,KACvB,OAAO,CAAE,SAAU,EAAgB,MAExC,KAAM,MAAK,iBAEb,CACA,AAAI,GAAc,GAAI,YAItB,OAAe,CACjB,GAAM,GAAI,KAAK,KACf,MAAO,GAAE,EAAE,OAAS,MAGlB,OAAiB,CACnB,MAAO,IAAa,KAAK,UAGvB,cAAc,CAChB,MAAO,GAAS,KAAK,cAAgB,KAAK,aAAe,KAAK,QAQ5D,SAAkB,CACpB,MAAO,MAAK,KAAO,KAGjB,QAAgB,CAClB,MAAO,MAAK,KAAK,UAGf,aAAuB,CACzB,MAAO,MAAK,KAAK,MAAM,EAAG,OAGxB,SAAS,CACX,MAAO,CACL,KAAK,SAAW,KAAO,GAAK,GAAK,KAAK,QACtC,KAAK,KAAK,IAAI,GAAM,EAAG,gBAI3B,gBAAiB,CACf,MAAO,IAAQ,GAAI,QAAQ,MAAM,CAAE,SAAU,KAAK,MAGpD,cAAe,CACb,MAAO,IAAM,QACV,QAAQ,WACR,KAAK,WAAY,mBAAoB,YACrC,MAAM,CAAE,MAAO,KAAK,KACpB,SAAS,cAAe,GACxB,SAAS,eAAgB,GACzB,SAAS,iBAAkB,GAGhC,aAAa,EAAU,CACrB,KAAK,UAAY,EACjB,KAAK,OAAS,EAAE,EAAE,OAAS,GAC3B,EAAI,KAAK,OAAQ,GAAK,EAAE,aAAa,EAAE,MAAM,EAAG,WAG5C,oBAAwC,CAC5C,MAAO,IAAY,KAAK,sBAAuB,GAAO,EACpD,QAAS,EAAG,KACZ,YAAa,EAAG,oBAId,WAA4B,CAChC,MAAO,CACL,MAAO,KAAK,GACZ,QAAS,KAAK,KACd,YAAa,KAAM,MAAK,cACxB,YAAa,KAAK,YAClB,WAAY,KAAK,WACjB,eAAgB,KAAK,gBAIzB,YAAa,CACX,MAAO,OAAS,KAAK,KAAK,KAAK,KAAO,SAGlC,YAAY,CAChB,GAAI,MAAK,OACT,MAAI,MAAK,UAAY,MAAQ,KAAK,QAAU,KAClC,KAAK,OAAS,KAAM,IAAI,SAAS,KAAK,UAEvC,KAAK,YAIV,kBAAiB,EAAwB,CAC7C,GAAI,KAAK,KAAO,EAAG,CACjB,GAAM,GAAQ,EAAO,EAAK,OAAQ,GAC5B,EAAM,EAAQ,EAAO,EAAK,MAAO,KAAK,SAAU,QACtD,MAAO,CAAC,GAAG,KAAK,UAAW,MAAM,EAAO,GAE1C,GAAM,GAAI,KAAK,iBACf,GAAO,EAAK,OAAQ,GAAU,CAC5B,AAAK,EAAE,OAAO,KAEhB,GAAO,EAAK,MAAO,GAAS,IAAK,GAAE,MAAM,IACzC,GAAM,GAAS,KAAM,IAAI,MAAM,IAAI,GACnC,OAAW,KAAM,GAAQ,GAAI,SAAS,GACtC,MAAO,QAqBH,iBAAiB,CACrB,MAAO,IAAI,MAAM,IAAI,CACnB,IAAK,GACH,sCACA,oBACA,UACA,kBACA,0BACA,wCACA,IACA,eACA,WACA,8BACA,0BAEF,SAAU,CAAE,MAAO,KAAK,WAItB,mBAAmB,CACvB,MAAO,MAAK,UAAY,KACpB,KAAK,SAAS,OACb,GAAI,IAAI,YAAY,GAClB,MAAK,OACF,EAAE,UAAU,YACZ,EAAE,MAAM,CAAE,SAAU,KAAK,MAC3B,cAIJ,cAAc,CAClB,YAAK,SAAW,KAAM,IAAI,MAAM,IAAI,KAAK,kBACzC,KAAK,SAAS,QAAQ,GAAY,CAChC,EAAS,OAAS,OAEb,KAAK,SAGd,MAAe,CACb,MAAO,QAAU,KAAK,KAAK,IAAI,oBAAoB,KAAK,QAGtD,WAAW,CACb,MAAO,MAAK,KAAK,MAGf,mBAAmB,CACrB,MAAO,CAAC,GAAG,KAAK,UAAY,WAMxB,eAAe,CACnB,GAAI,KAAK,WAAa,KAAM,CAC1B,GAAM,GAAgB,GAAS,KAAK,YAAY,IAAI,GAAM,GAAY,IAChE,EAAkB,KAAM,SAAQ,IACpC,EAAc,IAAI,GAAM,GAAI,iBAAiB,IAAI,KAEnD,GAAI,EAAgB,MAAM,GAAM,GAAM,MACpC,MAAQ,MAAK,UAAY,EAE3B,GAAM,GAAI,GAAI,QAAQ,QAAQ,QAAS,GAAe,QAAQ,SAC9D,KAAK,UAAY,KAAM,IAAI,MAAM,IAAI,GACrC,GAAI,UAAU,KAAK,WAEnB,KAAK,OAAS,EACZ,KAAK,OACL,KAAK,UAAU,KAAK,UAAU,OAAS,IAG3C,MAAO,MAAK,eAGR,sBAAsB,CAC1B,MAAO,CAAC,GAAI,KAAM,MAAK,eAAiB,WAOpC,gBAAgB,CACpB,MAAI,MAAK,WAAa,GAAK,KAAK,UAAY,KAAa,GAClD,GAAI,MAAM,IAAI,CACnB,IAAK,GACH,CACE,oCACA,oBACA,UACA,wBACA,wBACA,gCACA,IACA,eACA,WACA,4BACA,yBACA,2BACA,KAAK,MAET,SAAU,CAAE,MAAO,KAAK,MA2B5B,iBAAiB,EAA6C,CAC5D,GAAI,GAAI,KAAK,eAAe,OAC1B,sBACA,4CAGE,EAAgB,OAEpB,UAAQ,EAAK,aAAc,GAAM,CAC/B,EAAI,EAAE,MAAM,kBAAmB,IAAK,KAEtC,GAAQ,EAAK,aAAc,GAAM,CAC/B,EAAI,EAAE,MAAM,kBAAmB,IAAK,GACpC,EAAgB,QAElB,GAAQ,EAAK,MAAO,GAAS,CAC3B,EAAI,EAAE,MAAM,KAEd,EAAI,EAAE,QAAQ,kBAAmB,GACzB,GAAM,IAAI,IAAI,GAGxB,WAAY,CAEV,GAAM,GAAS,KAAK,eAAe,QAAQ,kBAAmB,QAC9D,MAAO,IAAM,MAAM,IAAI,QAGnB,gBAAe,EAAkB,CACrC,GAAM,GAAa,KAAK,WACxB,MACG,IAAc,MACf,GAAU,MACV,EAAO,SAAW,GAClB,EAAO,SAAW,EACd,GACA,GAAI,EAAO,QAAU,QAAU,GAAK,EAAa,SAmDzD,kBAAkB,EAAc,EAAe,EAAqB,CAClE,GAAI,GACF,KAAK,KAAK,KAAO,GAAS,KACtB,GAAM,gBACN,KAAK,eAOX,MANA,GAAK,EACF,WACA,MAAM,kBAAmB,EAAI,EAAM,iBACnC,YAAY,WAAY,EAAM,IAC9B,MAAM,IAAO,IAAM,EAAQ,EAAI,GAE9B,IAAO,IACF,EAAG,WAAW,gBAAgB,EAAM,OAEpC,EAAG,QAAQ,CAChB,CAAE,OAAQ,kBAAmB,MAAO,IAAO,IAAM,MAAQ,QACzD,kBAKA,gBACJ,EACA,EAC4B,CAC5B,EAAQ,EAAI,GAAS,EAAQ,GAC7B,GAAM,CAAC,EAAQ,EAAM,GAAS,KAAM,IAAY,CAAC,IAAK,IAAK,KAAM,GAC/D,GAAM,MAAM,IAAI,KAAK,kBAAkB,EAAO,EAAO,KAEvD,OAAW,KAAM,GACf,AAAI,EAAG,GAAM,EAAM,GACjB,EAAO,KAAK,GAEZ,EAAM,KAAK,GAGf,MAAO,IAAI,IAAkB,CAAC,MAAO,EAAQ,EAAM,UAAW,QAG1D,oBAAmB,EAAc,EAAgB,GAAiB,CACtE,GAAM,GAAM,KAAK,IAAI,IAAK,KAAM,OAC1B,EAAY,KAAM,IAAS,IAAI,KAAK,GACxC,EACG,OACC,sBACA,4CAED,WACA,KAAK,QAAS,WAAY,oBAC1B,KAAK,MAAO,SAAU,kBAGtB,MAAM,QAAS,OAAQ,KAAK,MAAQ,KACpC,SAAS,cAAe,GACxB,SAAS,iBAAkB,GAC3B,SAAS,eAAgB,GACzB,WACC,GAAkB,EAAO,EAAO,KAAK,GAAI,GAAI,WAAY,IAE1D,MAAM,IAGX,YAAK,SAAS,MACZ,KAAK,KAAO,WAAa,EAAQ,OAAS,kBAC1C,GAEK,KAGL,QAAgC,CAClC,MAAO,CAAE,KAAM,KAAK,OAAQ,MAAO,KAAK,QAjqBrC,MACE,AADF,GACE,UAAuB,MACd,AAFX,GAEW,iBAAmB,QAIX,AANnB,GAMmB,iBAAmB,GAAI,IAC7C,KAEsB,AATnB,GASmB,QAAU,GAAI,IACpC,IACA,GAEc,AAbX,GAaW,IAAM,CAAC,EAAQ,IAC7B,GACE,CAAC,EAAO,EAAE,QAAS,OAAO,kBAAmB,GAAG,EAAE,MAClD,CAAC,EAAO,EAAE,QAAS,OAAO,kBAAmB,GAAG,EAAE,OAsBtC,AAtCX,GAsCW,KAAO,EAAK,SAAY,CACtC,GAAM,GAAO,GAAI,IACjB,SAAK,GAAK,EAEV,EAAK,MAAQ,GACb,EAAK,SAAW,OAChB,EAAK,SAAY,MAAM,IAAI,SAAS,OAClC,GAAM,CAAC,GAAiB,EAAS,eAAe,eAAgB,EAAG,OAErE,EAAK,UAAY,GACjB,EAAK,WAAa,KAAM,IAAM,mBAC9B,EAAK,OAAS,IAAM,CAClB,KAAM,IAAI,OAAM,iCAEX,GACN,EAAI,GAEiB,AAvDnB,GAuDmB,oBAAsB,EAAK,IACjD,GAAI,MAAM,OACR,GAAM,IACJ,GACG,EACC,MAAO,GAAY,CAAC,EAAG,OACvB,QAAS,EAAG,aAON,AApEX,GAoEW,MAAQ,EAAqB,SAAY,CACvD,KAAM,IAAI,sBAEV,GAAM,GAAO,KAAM,IAAI,MAAM,IAAI,GAAQ,GAAI,QAAQ,UAAU,cAE/D,SAAK,QAAQ,GAAM,CACjB,EAAG,SAAW,OACd,EAAG,UAAY,GACf,GAAI,SAAS,KAGR,IAslBX,GAAM,IAAa,EACjB,IAAM,GAAM,IAAI,YAAoB,GAAK,EAAE,SAC3C,GC5sBF,GAAM,IAAY,IAAI,GAAS,oBACzB,GAAY,GAAY,sBACxB,GAAa,GAAY,sBACzB,GAAW,GAAa,sBAExB,GAAS,EAAK,IAAM,EAAS,sBAEnC,mBAAqC,CACnC,MAAO,IAAI,MAAM,KACf,GACE,EACG,aAAa,WACb,YACC,cAAgB,GAAa,uBAAyB,IAEvD,MAAM,IAAM,KAIrB,mBAA0C,CACxC,KAAM,IAAI,GAAG,SAAY,GAAY,KAAgB,KAGvD,kBAAwC,EAAU,CAChD,GAAM,GAAS,KAAM,IAAO,EAAI,QAAS,GACvC,GAAY,GAAe,KAE7B,AAAI,GAAU,KACZ,KAAS,KAAK,qCAAsC,CAAE,IAC7C,EAAO,OAAS,EAAI,MAC7B,MAAS,KAAK,oBAAqB,CAAE,SAAQ,QAC7C,KAAM,GAAI,WAAW,EAAO,OAE9B,KAAM,GAAI,uBAAuB,GAAQ,aClD3C,OAAyB,iBACzB,GAAoB,sBCSb,GAAM,IAAiB,GAC5B,iBACA,mBACA,0BACA,sBACA,kBAIK,gBAAwB,GAAiB,OAQvC,aAAa,CAClB,MAAO,MAAK,MAAM,KAAK,GACrB,EAAE,QAAQ,KAAM,GACd,EAAG,MAAM,GAAU,WAAW,IAAI,MAAM,UAAU,6BAK3C,mBAAkB,EAA+B,CAC5D,MAAO,MAAK,SAAS,IAAI,CACvB,IAAK,oBACL,MAAO,OACP,OAAQ,KAAM,MAAK,MAAM,OAAO,GAAK,CAEnC,GAAM,GAAS,EAAE,UAAU,eAAe,QAAQ,YAAa,OAC/D,MAAO,IAAQ,KAAO,EAAO,SAAS,GAAQ,IAEhD,KAAM,CAAE,gBAIL,iBAAgB,EAAsD,CAC3E,MAAI,GAAM,GAAO,MACR,KAAK,SAAS,MAAM,+BAAgC,CAAE,UACxD,KAAK,IAAI,KAAK,GACnB,EACG,UAAU,eACV,SAAS,GACT,OAAO,CAAE,YAAa,KAAK,qBAIrB,WACX,EACA,EACA,EAAmD,GAClC,CACjB,GAAM,GAAQ,KAAM,MAAK,MAAM,OAAO,GACpC,EAAG,EAAE,aAAa,eAAe,SAAS,KAE5C,GAAI,GAAS,KAAM,CACjB,KAAK,SAAS,KAAK,4BAA6B,CAAE,UAClD,OAEF,GAAM,GAAK,KAAM,MAAK,MAAM,UAAU,GAChC,EAAS,KAAM,GAAE,GACvB,MAAK,MACH,KAAM,GAAG,OAAO,CAAE,YAAa,KAAK,QAE/B,IAzDJ,MACW,AADX,GACW,UAAY,YACZ,AAFX,GAEW,iBAAmB,KClB9B,GAAM,IAAoB,GAC/B,uBACA,wBACA,yBACA,qBACA,sBACA,uBAIK,gBAA2B,GAAiB,GACjC,AADX,GACW,UAAY,eACZ,AAFX,GAEW,iBAAmB,kBFe9B,GAAM,IAAiB,EAAK,IAAM,EAAY,OAAa,EAAI,EAAI,MAUpE,GAAiB,GAAmB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GA4BpC,GAAoB,GAAmB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GA4BtC,gBACG,GAC4B,aAevB,QAAO,EAAU,GAAK,GAAO,CAGxC,KAAM,IAAa,IAAI,KAAK,GAC1B,EACG,QAAQ,aAAc,GACrB,EACG,MAAM,YACN,OAAO,MACP,MAAM,YAAa,KAAM,KAAK,MAAQ,IAE1C,UAEL,KAAM,MAAK,IAAI,KAAK,GAClB,EAAE,MAAM,YAAa,KAAM,KAAK,MAAQ,GAAS,sBAIxC,eAAe,CAC1B,GAAM,GAAK,KAAM,IAAU,kBAAkB,CAC3C,KAAM,GAAe,mBAEvB,MAAO,IAAS,SAAS,IAAI,CAC3B,IAAK,eACL,MAAO,OACP,OAAQ,EAAO,GAAI,UAAW,GAC9B,KAAM,CAAE,oBAIC,QAAkC,CAC7C,GAAM,GAAe,KAAM,MAAK,eAChC,MAAO,MAAK,IAAI,IAAI,CAClB,IAAK,GACL,SAAU,CAAE,8BAIH,eAAc,EAExB,CACD,MAAO,IAAY,EAAI,KAAM,GAAK,YAAa,GACzC,GAAG,QAAU,QAAU,EAAG,aAAe,MAC3C,MAAK,SAAS,KACZ,2DACA,MAEF,EAAG,YAAc,KAAK,OAEpB,EAAG,IAAM,KACJ,KAAK,SAAS,MACnB,EAAK,KAAU,gCACf,GAGG,EAAG,uBAID,WAAU,EAAa,EAAgB,CAClD,MAAO,MAAK,MAAM,UAAU,CAC1B,MACA,SACA,WACA,SAAU,oBAOd,aAA4B,CAC1B,MAAO,CACL,GAAI,KAAK,GACT,IAAK,KAAK,IACV,OAAQ,KAAK,OACb,MAAO,KAAK,MACZ,IAAK,KAAK,IACV,IAAK,KAAK,IACV,YAAa,KAAK,YAClB,cAAe,KAAK,cACpB,YAAa,KAAK,gBAIlB,MAAgB,CAClB,MAAO,GACL,EAAY,KAAK,QAAS,IAAM,EAAc,KAAK,MAAM,KAAK,WAC9D,IAAM,OAIN,KAAI,EAAe,CACrB,KAAK,QAAU,EAAU,EAAc,IAGzC,eAAe,EAA6C,CAC1D,MAAO,IAAe,KAAM,GAG9B,aAAc,CACZ,MAAO,IAAa,MAAM,KAAK,GAC7B,EAAE,MAAM,CAAE,WAAY,KAAK,KAAO,QAAQ,mBAIxC,UAAU,CACd,MAAO,IAAa,MAAM,IAAI,CAC5B,IAAK,GACL,SAAU,CACR,aAAc,KAAM,IAAS,eAC7B,IAAK,KAAK,IACV,SAAU,KAAK,YAKrB,QAAQ,EAAwB,EAAe,CAC7C,MAAO,IAAa,MAAM,UAAU,CAAE,WAAY,KAAK,GAAI,OAAM,eAG7D,kBAA6D,CACjE,MAAO,IAAa,MAAM,MAAK,WAAW,IAAI,GAAM,CAAC,EAAG,KAAM,EAAG,WA3I9D,MAGE,AAHF,GAGE,UAAuB,WGlGhC,OAAoB,mBC0Bb,GAAM,KAAY,GAAY,KAAK,AAAC,GAAoB,EAAK,UAEvD,IAAe,GAAY,KAAK,AAAC,GACrC,EAAK,cAGd,YAAqB,EAAoD,CACvE,MAAO,IAAY,KAAK,KAAO,IAC7B,GAAU,GAAY,EAAM,IAAQ,EAAG,IAAM,KAI1C,YACL,EACwB,CACxB,MAAO,IAAY,AAAC,GAClB,GAAY,GAAG,EAAiB,IAAI,GAAM,EAAE,MAIzC,GAAM,IAAsB,GAAY,KAAK,KAAO,IAAiB,CAC1E,GAAM,GAAI,KAAM,IAAS,GACzB,GAAI,GAAK,MAAS,CAAC,EAAE,WAAW,WAAa,CAAC,EAAE,WAAW,UACzD,MAAO,GACT,GAAM,GAAM,EAAE,WAAW,UACrB,EAAS,kBAAkB,eAC3B,EAAS,kBAAkB,eAC/B,MAAO,IACL,GAAS,GACT,GAAO,GAAI,EAAI,WAAY,IAAQ,GAAI,EAAI,YAAa,GACxD,IAAM,MAIG,GAAyB,GAAY,KAAK,KAAO,IAAiB,CAC7E,GAAM,GAAI,KAAM,IAAS,GACzB,GAAI,GAAK,KAAM,MAAO,GACtB,GAAI,CAAC,EAAE,WAAW,UAAW,MAAO,GACpC,GAAM,GAAI,KAAM,IAAY,EAAG,IAC/B,MAAI,IAAK,KAAa,GACf,GAAI,GAAmB,GAAI,EAAS,oBAAoB,kBAGpD,GAAc,GAAmB,CAAC,aAClC,GAAkB,GAAmB,CAAC,OAAQ,UAG9C,GAAc,GACzB,AAAC,GAAY,EAAM,EAAE,OAAQ,CAAE,aAAc,KAAS,GAG3C,IAAwB,GAAY,AAAC,GAChD,GAAS,CAAC,aAAc,aAAc,EAAI,EAAE,YAGjC,GAAc,GAAY,AAAC,GAC/B,EAAI,EAAE,UAAU,WAAW,WAGvB,GAAc,GAAY,AAAC,GAC/B,EAAI,EAAE,UAAU,WAAW,WAG9B,GAAuB,GAAY,IAAI,IAAiB,GAAG,IAEjE,kBAAiC,EAAqB,CACpD,MACE,CAAC,EAAM,IACN,IAAgB,IACf,GAAiB,IAChB,GAAgB,IAAU,KAAM,OAChC,GAAe,IAAU,KAAM,OAI/B,GAAM,IAA0B,GAAY,KACjD,KAAO,IACL,GAAU,GAAS,EAAK,YAAa,GAAmB,IAAM,KAGrD,GAAiB,GAAY,KACxC,KAAO,IAAqB,CAAC,GAAc,EAAK,aAGrC,GAAgB,GAAY,KAAK,KAAO,IACnD,GAAQ,GAAW,KAeR,GAAiB,GAAY,KAAK,KAAO,IACpD,GACE,EAAK,OACL,GACE,GACE,EAAS,sBAAsB,eAC/B,EAAS,sBAAsB,eAC/B,GAEJ,IAAM,KAIG,GAAmB,GAAY,UAC1C,EAAS,oBACT,CAAE,kBACF,CAAE,oBAGS,IAAkB,GAAY,UACzC,EAAS,mBACT,CAAE,kBACF,CAAE,mBACF,CAAE,kBACF,CAAE,oBAGS,GAAuB,EAClC,IACE,EAAQ,CACN,CAAE,kBACF,CAAE,mBACF,CAAE,mBACF,CAAE,kBACF,CAAE,gBACF,CAAE,4BACF,EAAS,iBAAiB,eACtB,CAAE,yBACF,OACJ,CAAE,gBACF,CAAE,wBACF,EAAS,oBAAoB,eAAiB,EAC1C,CAAE,2BACF,UAIG,GAAsB,EAAK,IACtC,GAAY,UACV,EAAS,uBACT,GAAG,OAIM,IAAU,GAAY,KAAK,KAAO,IAC7C,EAAM,EAAK,MAGA,IAAkB,GAAY,KAAK,KAAO,IACrD,EAAK,eCxFA,YACL,EACA,EACe,CACf,OAAW,KAAM,GAAU,CACzB,GAAM,GAAI,EAAE,GACZ,GAAI,EAAS,GAAI,MAAO,GAAK,IAAM,EAAI,GAAG,QAKvC,YAAkB,EAAwB,CAC/C,MAAO,IAAiB,EAAG,CACzB,eACA,qBACA,mBACA,yBAIG,YAAgB,EAAS,CAC9B,CACE,GAAM,GAAK,GAAiB,EAAG,CAAC,mBAAoB,WACpD,GAAI,GAAM,KAAM,MAAO,GAEzB,MAAO,GACL,GAAqB,GACrB,CAAC,CAAE,WAAU,eACX,GAAG,EAAS,iBAAiB,EAAU,iBAItC,YAAiB,EAAiC,CACvD,MAAO,IAAiB,EAAG,CAEzB,YACA,cACA,eACA,iBClIJ,GAAM,IAAQ,CACZ,CAAE,GAAI,GAAQ,EAAG,OAAQ,EAAG,SAC5B,CAAE,GAAI,KAAO,GAAO,EAAG,QAAS,EAAG,UACnC,CAAE,GAAI,GAAQ,EAAG,OAAQ,EAAG,SAC5B,CAAE,GAAI,GAAO,EAAG,MAAO,EAAG,QAC1B,CAAE,GAAI,GAAQ,EAAG,OAAQ,EAAG,SAC5B,CAAE,GAAI,EAAU,EAAG,SAAU,EAAG,WAChC,CAAE,GAAI,EAAU,EAAG,SAAU,EAAG,YAG3B,YACL,EACA,EAAgB,EAChB,EACQ,CACR,GAAI,CAAC,GAAK,GACR,MAAO,AAAC,IAAS,GAAW,IAAM,GAAY,KAAK,IAAI,GAAK,GAArC,GAEzB,GAAM,GAAmB,GAAM,UAAU,GAAM,EAAG,IAAM,GACxD,GAAI,IAAqB,GAAI,MAAO,GACpC,GAAI,GAAY,EACV,EAAS,EACb,GAAM,MAAM,EAAkB,EAAmB,GAAO,IAAI,GAAQ,CAClE,GAAI,IAAK,GAAK,GAEP,CACL,GAAM,GAAI,KAAK,MAAM,EAAY,EAAK,IACtC,UAAa,EAAI,EAAK,GACf,CAAE,IAAG,EAAG,GAAK,EAAG,EAAK,EAAG,EAAK,QAI1C,MAAI,GAAQ,GAAgB,GAE1B,EAAO,IAAI,GAAM,EAAG,GAAG,KAAK,MAC5B,EACE,EACA,GAAM,IAAO,GAAO,EAAO,OAAS,GAAG,IAAM,EAAI,EAAG,SAAW,EAAG,QAClE,IClCN,GAAM,KAAS,EAAK,IAAM,EAAS,mBAc5B,YAAsB,EAA0B,CACrD,GAAM,GAAM,GAAM,GACZ,EAAY,EAAI,SAAW,GAAsB,GAAU,EAAI,UAE/D,EAAO,EAAI,KAAK,MAAM,KAAK,MAAM,EAAG,IAC1C,MAAO,GAAc,CAAC,GAAS,GAAI,EAAW,GAAG,IAYnD,kBAA4C,EAAiB,EAAgB,CAC3E,MAAO,IAAM,QAAQ,EAAS,EAAK,IAAI,KJwBlC,oBACG,GAKW,CANd,aAlEP,CAkEO,oBA0iBI,eAAY,EAAK,IAAM,EAAU,OAAO,KAAK,IAAK,KAAK,yBAthBnD,yBACX,EACA,EACA,EAAQ,GACW,CACnB,GAAM,GAAQ,KAAK,MAAQ,EACvB,EAAI,KAAK,QACV,SAAS,qBACT,KAAK,QAAS,WAAY,qBAC1B,MAAM,sBAAuB,IAAK,GAClC,SAAS,cAAe,GACxB,SAAS,eAAgB,GAE5B,MAAI,GAAS,IACX,GAAI,EAAE,SAAS,gBAAiB,OAAQ,EAAU,MAGpD,EAAI,EAAE,QAAQ,sBAAuB,QAAQ,MAAM,GAEnD,KAAK,SAAS,MAAM,0BAA2B,EAAE,SAC1C,KAAK,IAAI,SAAS,SAGpB,sBACL,EACgD,CAChD,GAAI,GAAI,KAAK,QACV,OAAO,GAAK,IAAI,gCAChB,KAAK,QAAS,WAAY,qBAC1B,MAAM,cAAe,GACrB,SAAS,eAAgB,GACzB,SAAS,iBAAkB,GAC9B,MAAI,GAAS,IACX,GAAI,EAAE,SAAS,MAAO,OAAQ,EAAU,MAE1C,EAAI,EAAE,QAAQ,YAAY,QAAQ,YAC3B,KAAK,IAAI,IAAI,eAMT,0BACX,EACoD,CACpD,GAAM,GAAM,KAAM,MAAK,qBAAqB,GAE5C,MAAO,AADO,IAAK,EAAK,EAAI,IAAI,GAAM,EAAG,SAAS,MAAM,KAAK,MAChD,IAAI,GAAiB,EAChC,eACA,MAAO,GAAI,EAAK,GACd,EAAG,SAAS,WAAW,EAAe,KAAO,EAAG,MAAQ,YAKvD,UACL,EACA,EACA,CACA,GAAM,GAAK,KAAK,QAEb,MAAM,MAAO,OAAQ,EAAY,MACjC,SAAS,MAAO,SAAU,IAAI,GAAa,cAC9C,MAAO,MAAK,MAAM,IAChB,EACE,EACA,GAAM,EAAG,GACT,IAAM,OA+BR,qBAAqB,CACvB,MAAO,IAAgB,KAAK,gBAAiB,KAAK,kBAGpD,iBAAiB,EAAiB,CAChC,MAAO,IAAY,KAAK,mBAAoB,SAmD/B,eAAc,EAA+B,CAC1D,GAAM,GAAK,KAAK,QACb,MAAM,UAAW,IAAK,IACtB,QAAQ,MACX,MAAO,GAAQ,GACX,EACA,EAAG,SAAS,GACV,EAAE,QAAQ,aAAc,GAAc,YAAY,2BAI7C,cACX,EAAkD,GAClD,CACA,MAAO,MAAK,MAAM,QAAQ,EAAE,KAAK,cAAc,KAAM,qBAG1C,eACX,EAAkD,GACjC,CACjB,GAAM,GAAK,KAAK,cAAc,KAAM,OACpC,MAAO,MAAK,IAAI,WAAW,EAAE,EAAG,MAAM,oBAG3B,UAAS,EAAkB,EAAsB,CAE5D,GADA,KAAK,SAAS,KAAK,aAAc,CAAE,UAAS,gBACxC,CAAC,EAAI,IAAY,CAAC,EAAI,GACxB,KAAM,IAAI,OACR,4BAA8B,EAAU,CAAE,UAAS,iBAKvD,KAAM,MAAK,IAAI,KAAK,GAAK,EAAE,OAAO,QAAS,GAAG,MAAM,UAAW,IAE/D,GAAM,GAAM,CACV,mBACA,2DACA,yBACA,4BACA,KAAK,KAED,EAAW,CAAE,UAAS,cAAa,UAAW,KAAK,OACzD,MAAO,MAAK,IAAI,IAAI,CAAE,MAAK,yBAGhB,aACX,EACA,EACA,CACA,GAAM,GAAI,KAAK,QAAQ,OAAO,eAE9B,MAAK,GAAI,GAAc,GAAmB,GACxC,EACG,KAAK,QAAS,WAAY,qBAC1B,MAAM,GAAU,EAAI,CAAC,EAAG,IAAM,CAAC,SAAW,EAAG,MAG7C,EAAI,GAAc,GAAuB,GAC5C,EAAE,MAAM,GAAU,EAAI,CAAC,EAAG,IAAM,CAAC,aAAe,EAAG,MAG9C,KAAK,MAAM,IAAI,MAGpB,QAAQ,CACV,MAAO,GAAQ,GAAM,GAAW,GAAK,KAAK,OAAS,QAGjD,OAAM,EAAe,CACvB,GAAM,GAAW,GAAM,KAAK,OAAS,GAAK,EAAI,SAG1C,aAAY,EAAoC,CACpD,GACE,KAAK,SAAW,MAChB,KAAK,QAAU,IACf,EAAS,UAAU,eAEnB,MAAO,GAGT,GAAM,GAAK,KAAM,MAAK,WAAW,GACjC,MAAO,IAAU,EAAI,MAGvB,WAAW,EAAkB,CAC3B,MAAO,IAAQ,GACZ,OAAO,IAAM,KAAK,aAClB,OAAO,GAAM,EAAG,UAChB,QAAQ,KAAM,IAAM,EACnB,IAAK,KAAM,GAAE,MACb,SAAU,KAAM,GAAE,OAClB,MAAO,KAAM,GAAE,8BAEhB,OAAO,IACP,MAGL,mBAAoB,CAClB,MAAO,IAAI,KAAK,QAAS,SAGrB,eAAgC,CACpC,MAAO,IAAU,IAAI,YAAoB,GACvC,EAAE,QAAQ,MAAM,CAAE,QAAS,KAAK,UAAW,YAAY,CAAE,GAAI,KAAK,WAIhE,iBAAqC,CACzC,GAAM,GAAS,EAAS,UAAU,eAClC,GAAK,KAAM,MAAK,eAAkB,EAAI,KAAK,KAAO,CAAC,EACjD,MAAO,MAAK,SAEd,GAAI,KAAM,MAAK,gBAAiB,CAC9B,KAAK,QAAU,GACf,KAAM,MAAK,SACX,OAEF,GAAI,MAAM,MAAK,YACf,MAAO,GAAQ,KAAK,iBAAkB,IAAM,KAAK,eAG7C,kBAAiB,EAAyB,CAC9C,MAAO,GAAQ,KAAK,WAAW,GAAO,GAAM,GAAa,KAAM,SAM3D,gBAAe,EAAsC,CACzD,GAAM,GAAQ,KAAK,MACb,EAAI,KAAK,SAAS,WAAW,qBAEnC,GADA,EAAE,MAAM,SAAU,MACd,KAAK,IAAM,MAAS,KAAM,MAAK,YAAY,GAAQ,CACrD,EAAE,KACA,sFAEF,OASF,GAPI,GAAQ,MACV,KAAM,MAAK,QAAQ,GAEjB,GAAQ,MACV,GAAO,KAAM,MAAK,aAGhB,GAAQ,MAAS,KAAM,GAAK,YAAc,CAC5C,EAAE,KAAK,UAAY,EAAO,eAC1B,OAOF,GAJI,KAAK,YAAc,MACrB,KAAM,GAAQ,EAAK,aAAc,GAAO,KAAK,WAAa,EAAG,YAG3D,AAAS,KAAM,MAAK,iBAAiB,IAArC,KAA6C,CAC/C,EAAE,KAAK,4BAA6B,CAClC,GAAI,KAAK,GACT,IAAK,KAAK,MAEZ,OAGF,GAAM,GAAO,EAAK,MAWZ,EAAwB,GAExB,EAAI,KAAM,IAAS,GACzB,GAAI,GAAK,KAAM,CACb,EAAE,MAAM,oBAAsB,GAC9B,OAEF,GAAI,EAAM,EAAE,UAAW,CACrB,EAAE,MAAM,wBAA0B,GAClC,OAEF,EAAG,SAAW,EAAE,SAEhB,GAAM,GAAI,EAAE,WACN,EAAkB,EAAE,UAC1B,GAAI,GAAmB,KACrB,MAAO,GAAE,MAAM,iBAAkB,GAEnC,EAAG,gBAAkB,EACrB,EAAG,iBAAmB,EAAE,WACxB,EAAG,sBAAwB,EAAE,gBAC7B,EAAG,cAAgB,EAAE,IAErB,EAAI,EAAE,iBAAkB,GAAO,CAC7B,EAAG,YAAc,EAAI,YACrB,EAAG,SAAW,EAAI,SAClB,EAAG,aAAe,EAAI,aACtB,EAAG,IAAM,EAAI,MAGf,GAAM,GAAO,EAAE,WAcf,GAbA,EAAG,MAAQ,EAAK,MAChB,EAAG,OAAS,EAAK,OACjB,EAAG,SAAW,EAAE,SAChB,EAAG,KAAO,EAAE,KACZ,EAAG,MAAQ,EAAE,MACb,EAAG,SAAW,GAAS,GACvB,EAAG,QAAU,EAAI,GAAQ,GAAI,GAC7B,EAAG,OAAS,GAAO,GACnB,EAAG,QAAU,GAAoB,EAAE,YAAa,EAAE,cAClD,EAAG,WAAa,EAAI,EAAE,SAAU,GAAM,KAAK,MAAM,EAAK,MACtD,EAAG,IAAM,EAAI,GAAQ,EAAE,gBAAiB,IAExC,EAAG,IAAM,KAAM,GACX,EAAG,KAAO,KAAM,CAClB,EAAE,KAAK,oCAAqC,CAC1C,GAAI,KAAK,GACT,IAAK,KAAK,MAEZ,OAGF,AACE,GAAS,eAAe,gBACxB,EAAS,eAAe,iBAExB,KAAM,GAAQ,GAAU,GAAO,GAAM,CACnC,EAAG,SAAW,EAAG,SAGjB,EAAG,MAAQ,EAAG,QAIlB,GAAa,KAAM,GAUnB,KAAK,QAAU,GACf,GAAM,GAAU,KAAK,MAAQ,EAC7B,SAAE,IACA,EAAU,EAAW,OAAS,QAC9B,UAAY,EAAU,MACtB,MAEK,UAGH,sBAAqB,EAAoB,CAE7C,MADA,MAAK,SAAS,MAAM,uBAAwB,GACxC,KAAK,oBAA4B,KAEnC,EAAQ,KAAO,MACf,CAAC,EAAQ,qBACR,KAAK,KAAO,MAAQ,EAAQ,MAAQ,KAAK,IAEnC,KAAK,SAAS,MAAM,0CAA2C,CACpE,KAAM,KACN,YAGJ,IACE,KACA,GACE,EACA,KACA,YACA,QACA,QACA,MACA,QACA,WACA,aACA,YACA,cAGG,WAGH,WAAW,CACf,MAAI,MAAK,SAAW,MAAQ,KAAK,OAAS,KAAa,KAAK,MACpD,KAAK,MAAQ,KAAM,IAAM,MAAM,SAAS,KAAK,cAGjD,SAA2B,CAC/B,MAAO,IACL,KAAK,YACL,GAAM,EAAG,SACT,IAAM,SAOJ,YAA8B,CAClC,MAAO,IAAQ,KAAK,eAMhB,gBAAkC,CACtC,MAAO,IACL,KAAK,YACL,GAAM,EAAG,UAAU,KAAK,KACxB,IAAM,SAQJ,aAA+B,CACnC,MACE,IAAQ,KAAK,aAEV,OAAO,GAAK,EAAE,UACd,QAAQ,GAAK,KAAsB,MAAM,IAEzC,IAAI,GAAM,CAAC,GAEX,UAAU,IAAM,SAIjB,aAA+B,CACnC,MAAO,IACL,KAAK,YACL,GAAK,EAAE,aACP,IAAM,SAIJ,SAAQ,EAAiB,CAC7B,GAAM,GAAM,KAAM,GAAK,MACvB,GAAI,GAAO,KACT,MAAO,MAAK,SAAS,MAAM,yBAA2B,GAExD,GAAM,GAAa,KAAM,GAAK,aAC9B,GAAI,GAAc,KAChB,MAAO,MAAK,SAAS,MAAM,gCAAkC,GAG/D,GAAI,KAAK,KAAO,MAEV,CAAE,KAAM,IAAgB,EAAK,KAAK,KACpC,MAAO,MAAK,SAAS,MACnB,gDACA,CAAE,MAAO,KAAK,IAAK,IAAK,EAAK,KAAM,EAAK,aAM9C,GAAI,AADW,KAAM,GAAK,aACZ,KACZ,WAAK,SAAS,MAAM,qCAAsC,GACpD,GAAI,OAAM,cAAgB,GAGlC,YAAK,IAAM,EACX,KAAK,WAAa,EAAW,WAExB,KAAK,UAAU,IAAI,QAAQ,QAAQ,IACjC,EAKT,YAAa,CACX,MAAO,GAAQ,KAAK,YAAa,GAAM,EAAG,YAG5C,cAA8C,CAC5C,MAAO,GACL,GAAgB,KAAK,gBAAiB,KAAK,kBAC3C,GACE,EACE,KAAK,YACL,GACE,GAAI,IACF,EAAG,WACH,EACA,KAAK,cACL,GAAI,MAAK,KAAK,OACd,KAAK,8BAMX,eACJ,EACA,EACyB,CACzB,GAAI,CACF,GAAM,GAAI,KAAM,MAAK,YACrB,GAAI,GAAK,KAAM,MAAO,GAEtB,GAAM,GAAK,EAAS,GAAG,KAAK,SAItB,EAAyB,GAqB/B,GApBI,KAAM,GAAE,cACV,EAAO,KAAK,CACV,KAAM,OAAO,KAAK,WAAW,KAAK,KAClC,KAAM,WACN,MAAO,GACL,EACA,WACA,KAAK,QAAU,QAAU,QACzB,CAAE,MAAO,KAAK,MAAO,OAAQ,KAAK,SAEpC,SAAU,EAAE,KACZ,YAAa,oBACb,QAAS,IAAI,GAAO,SAAS,EAAE,SAI/B,KAAK,SAIL,CAFU,GAAO,KAAK,QAAU,KAAK,MAAQ,GAErC,MAAO,GAEnB,GAAM,GAAM,EACV,KAAM,SAAQ,IACZ,CAAC,GAAI,KAAM,GAAG,YACX,UACA,OAAO,GAAM,EAAG,UAAY,GAAa,KACzC,IAAI,GAAM,GAAsB,EAAE,KAAM,MAI/C,SAAO,KACL,GAAG,GACD,EAEA,GAAM,EAAG,OAGN,QACA,EAAP,CACA,SAAQ,iCAAkC,EAAK,CAAE,QAAS,OACnD,SAIL,WAA4C,CAChD,GAAI,CACF,GAAM,GAAI,GAAI,MAAM,KAAK,KACnB,EAAa,KAAM,IAAe,EAAG,KAAK,YAChD,GAAI,GAAc,KAAM,CACtB,KAAK,SAAS,KAAK,yCAA0C,CAC3D,IAAK,KAAK,MAEZ,OAIF,GAAM,GAAS,EAAE,OAEX,EAAmB,GAAY,EAAY,GAAQ,MAAM,QACzD,EAAiB,EAAiB,MAClC,EAA4B,EAAO,MAAM,QAMzC,EAAU,GAAa,GACvB,EAAM,KAAM,IAAI,WAAW,GACjC,GAAI,GAAO,KAAM,CACf,KAAK,SAAS,KAAK,0CAA2C,CAC5D,YAEF,OAGF,GAAM,GAAe,KAAM,GAAI,oBAE/B,KAAK,SAAS,KAAK,aAAc,CAC/B,IAAK,KAAK,IACV,SACA,aACA,mBACA,4BACA,iBACA,SAAU,EAAI,KACd,iBAIF,EAAa,QAIb,AAAI,EAAM,GACR,EAAa,QAEb,EAAa,GAAG,YAAc,EAKhC,EAA0B,OAAO,EAAG,EAAa,QAEjD,GAAM,GAAS,CACb,aACA,oBAAqB,GAAQ,EAAiB,KAAK,QAAO,QAC1D,eACA,iBAAkB,EAA0B,KAAK,QACjD,QAAS,OACT,OAAQ,KAAM,MAAK,UAErB,YAAK,SAAS,KAAK,aAAc,CAAE,WAC5B,QACA,EAAP,CACA,KAAK,SAAS,KAAK,qBAAsB,GACzC,aAIE,OACJ,EACA,EAC4B,CAC5B,MAAO,GAAQ,KAAK,WAAY,KAAM,IACpC,GAAgB,KACd,QAAS,KAAK,QACd,YAAa,KAAK,IACf,GAHW,CAId,SAAU,KAAK,SACf,MAAO,EAAO,KAAK,OACnB,MAAO,KAAK,MACZ,OAAQ,KAAK,OACb,SAAU,EAAO,KAAK,SAAU,GAChC,SAAU,KAAK,SACf,MAAO,KAAK,MACZ,cAAe,KAAM,MAAK,cAAc,EAAU,GAClD,gBAAiB,GAAU,KAAK,WAChC,gBAAiB,GAAU,KAAK,kBAKlC,UAAmB,CACrB,MAAO,IAAgB,KAAK,YA/tBzB,MA4FE,AA5FF,GA4FE,UAAuB,YACd,AA7FX,GA6FW,iBAAmB,MACnB,AA9FX,GA8FW,cAAgB,CAAC,SAqoBnC,YAAmB,EAAkC,CACnD,MAAO,GAAI,EAAI,GAAM,GAAY,KAAK,MAAQ,EAAI,GAAK,QK/wBzD,GAAM,IAAS,EAAK,IAAM,EAAS,WAE/B,GAEE,GAAM,EAAK,IAAM,GAAI,IAAU,GAAS,QAEjC,GAAoB,EAAK,SAAY,CAChD,GAAI,IAAU,KAAK,MAAQ,GAAQ,GAAK,EAAU,OAClD,KAAM,MAEN,GAAM,GAAS,KAAM,MAAM,WAAmB,CAC5C,IAAK,oCAGP,AADA,KAAS,KAAK,oBAAqB,CAAE,SAAQ,aACzC,IAAW,IACf,IAAU,EACV,KAAM,IAAK,qBAAsB,IAAM,QACtC,EAAI,GAEA,YAA2B,EAAM,GAAY,GAAI,CAEtD,GAAM,GAAK,WAAW,IAEhB,EAAM,YAAY,IAElB,EAAK,mBAAmB,IAE9B,MAAO,IAAY;AAAA,eACN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,eAQA,YAAa,EAAG,QAAQ,UAAW;AAAA;AAAA,eAEnC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,eAcA,YAAc,EAAI,QAC7B,UACA;AAAA;AAAA,eAGW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAMX;AAAA,SACK;AAAA;AAAA;AAAA;AAAA,eAIM,YAAa,EAAG,QAAQ,UAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAY3C;AAAA;AAAA;AAAA;AAAA;AAAA,uBAKgB;AAAA,uBACA;AAAA,uBACA;AAAA,aACV;AAAA,aACA;AAAA,aACA;AAAA,GAIb,mBAAiC,CAC/B,AAAI,KAAM,MAAQ,MAChB,KAAS,MAAM,sCAAuC,CAAE,UAAW,KAErE,GAAI,CACF,GAAM,GAAM,GAAY,GAClB,EAAY,IAAM,EAClB,EAAI,KAAM,IACd,KAAM,UAAU,GAAkB,GAAM,IAEpC,EAAS,GAAM,EAAI,EAAU,EAAI,EAAU,EAAE,UAAY,IAC/D,KAAS,KAAK,qBAAsB,CAAE,UAAW,EAAE,UAAW,WAC9D,GAAkB,OAAO,GACzB,KAAM,YACC,EAAP,CACA,KAAS,KAAK,8BAA+B,IAIjD,kBAAgC,EAAe,KAAK,MAAQ,GAAK,EAAU,CACzE,GAAI,GAAQ,CAAC,IACb,OAAW,KAAK,IAAM,EAAG,GAAI,CAC3B,GAAM,GAAO,KAAM,IAAe,GAClC,GAAI,EAAQ,IAAS,GAAI,EAAO,GAAO,OACvC,EAAQ,GAIZ,kBAA8B,EAAsB,CAClD,GAAM,GAAa,KAAM,IAAI,IAAI,UAC/B,GACE,EACG,OAAO,UACP,cAAc,WAAY,iBAAkB,UAC5C,cAAc,GAAK,IAAI,4CACvB,UAAU,oBACV,SAAS,GAAM,EAAG,UAAU,aAC5B,SAAS,GAAM,EAAG,UAAU,mBAC5B,SAAS,gBAAiB,IAAK,GAC/B,QAAQ,YAAa,QAE5B,KAAS,MAAM,mBAAoB,CAAE,eACrC,OAAW,KAAM,GACf,GAAI,CACF,KAAM,IAAI,IAAI,KAAK,GAAK,EAAE,MAAM,CAAE,GAAI,IAAM,gBACrC,EAAP,CACA,KAAS,KAAK,qCAAsC,CAAE,MAAO,EAAI,QAGrE,YAAS,KAAK,6BAA8B,CAAE,eACvC,EAGT,mBAA6C,CAC3C,GAAM,GAAM,EAAS,0BACf,EAAW,KAAM,IAAI,WAAW,CAAC,GAAS,KAChD,GAAI,GAAY,KAAM,CACpB,EAAI,KAAK,0BACT,OAGF,KAAM,GAAS,uBACb,EAAS,iBAAiB,gBAG5B,GAAM,GAAO,KAAM,MACnB,GAAI,GAAQ,KAAM,CAChB,EAAI,KAAK,kCACT,OAGF,OAAW,KAAK,MAAM,GAAS,cAAe,CAC5C,GAAI,EAAE,OAAS,GAAS,CACtB,AAAI,EAAE,UAAY,GAAG,KAAM,GAAE,OAAO,CAAE,QAAS,IAC/C,SAGF,GAAI,GACE,EAAI,EAAK,KAAK,GAAM,EAAS,EAAG,OAAS,GAAO,EAAG,QAAU,EAAE,MACrE,AAAI,GAAK,KACP,EAAc,GAAW,EAAE,MAAO,EAAE,YAEpC,EAAc,KAAM,IAAU,IAAI,YAAoB,GACpD,EACG,OAAO,cACP,MAAM,MAAO,OAAQ,YAAc,EAAE,KAAO,MAC5C,MAAM,IAGb,AAAI,GAAe,KACjB,MAAM,GAAE,uBAAuB,GAC/B,EAAI,KAAK,cAAe,CAAE,GAAI,EAAE,GAAI,KAAM,EAAE,KAAM,gBAClD,GAAI,SAEJ,EAAI,MAAM,wCAAyC,CACjD,GAAI,EAAE,GACN,KAAM,EAAE,QCpLT,YAAwC,CAyBrC,YACG,EACA,EACQ,EACjB,CAHS,eACA,mBACQ,kBAzBV,kBAAe,EA0Cf,SAAM,EAAK,IAAM,EAAI,KAAK,OAAO,MAAO,GAAM,EAAG,QAEjD,WAAQ,EAAK,SAAY,CAChC,GAAI,CACF,KAAM,MAAK,SACX,KAAK,OAAO,KAAK,wBAA0B,KAAK,GAAG,OAAO,cACnD,EAAP,CACA,KAAK,GAAG,OAAO,GACf,KAAK,OAAO,OAAO,GAEnB,KAAK,OAAO,MAAM,EAAK,CACrB,MAAO,GACP,KAAM,4BAQK,kBAAe,SAAY,CAC1C,AAAI,KAEA,CAAC,IAAU,MACb,KAAM,IAAG,KAAW,SAAY,CAC9B,KAAM,IAAa,SACnB,KAAM,IAAS,SACf,KAAM,SASK,sBAAmB,SAAY,CAC9C,AAAI,MAGW,iBAAc,EAAK,SAAY,CAC9C,KAAK,OAAO,KACV,mEAGF,KAAM,GAAQ,GADU,IACmB,GAAM,EAAG,KAAK,WAI1C,sBAAmB,SAClC,MAAoB,KAAM,MAAK,cAjE/B,KAAK,KAAO,kBAAoB,EAAU,IAC1C,KAAK,OAAS,EAAS,KAAK,MAC5B,KAAK,GAAK,GAAI,IAAS,KAAK,KAAO,OACnC,KAAK,OAAS,GAAI,IAAS,KAAK,KAAO,WACvC,KAAK,UAAY,GAAS,KAAK,QAAS,UACxC,KAAK,UAAY,KAAK,UAAU,SAAS,KAAK,UAC9C,GAAa,MACR,KAAK,oBAtBC,KACX,EACA,EACA,EAA+B,GAC/B,CACA,GAAM,GAAK,GAAI,IAAe,EAAS,EAAa,GACpD,YAAM,GAAG,QACF,KAkBL,QAAQ,CACV,MAAO,MAAK,IAAI,SAAW,UAwDf,SAAS,CAUrB,GAJE,EAAS,oBAAoB,gBAC7B,AACG,KAAM,GAAQ,GAAU,KAAK,UAAU,YAAa,GAAO,EAAI,UADlE,GAGqB,CACrB,GAAM,GAAe,KAAM,MAAK,aAChC,YAAK,eAAiB,GAAS,EAAc,UAC7C,KAAK,OAAO,KAAK,mDAAoD,CACnE,IAAK,KAAK,UAAU,WACpB,MAAO,KAAK,iBAGV,KAAM,MAAK,oBACb,MAAK,OAAO,KAAK,yCAGjB,KAAM,MAAK,eAAe,SAAS,KAAK,QAGpC,KAAM,MAAK,UAAU,QAAQ,UAG/B,MAAM,MAAK,UAAU,UAAU,KAAK,gBACpC,KAAM,MAAK,eAAe,MAAM,MAElC,KAAK,OAAO,KACV,oCAAsC,KAAK,iBAGxC,KAAK,aAAa,EAAc,KAAK,UAAU,cAEtD,OAAO,MAAK,aAAa,KAAK,cASpB,cAAa,EAAwB,EAAyB,CAC1E,GAAM,GAAY,KAAM,MAAK,UAAU,SACvC,GAAI,GAAa,KACf,KAAM,IAAI,OAAM,yCAA2C,KAAK,WAElE,GAAM,GAAK,GAAI,IAAG,SAAU,EAAc,KAAK,aACzC,EAAmB,KAAM,MAAK,mBACpC,AAAI,EACF,MAAM,GAAG,UACT,KAAK,OAAO,QACV,GAAI,IACF,EACA,KAAK,iBACL,EAAG,OACH,EACA,EACA,KAAK,aACL,KAAK,oBAIT,KAAK,OAAO,QAAQ,QAGtB,GAAW,GACX,KAAK,GAAG,QAAQ,GAEZ,GACF,MAAM,MACN,KAAM,OAGR,KAAK,OAAO,KAAK,iBAAkB,CACjC,eACA,eACA,gBC5MC,GAAM,IAAiB,EAAK,IAAM,CACvC,GAAsB,KAAgB,GAAiB,QACvD,GAAkB,KAAgB,GAAa,UAG3C,GAAiB,SACb,KAAM,MACV,EAAI,KAAa,GAAM,EAAG,QAAQ,gBAClC,OAGA,GAAa,SACT,KAAM,MACV,EAAI,KAAa,GAAM,EAAG,QAAQ,YAClC,OCnBN,GAAI,IAEG,aAAmB,CACxB,MAAO,IAGF,YAAoB,EAAW,CACpC,GAAK,ECAP,kBAAqC,EAAkB,CACrD,GAAM,GAAK,GAAI,IAAG,QAAS,GAE3B,MAAI,OACF,MAAM,GAAG,UACT,GAAI,IAAgB,CAClB,KAAM,wBACN,SAAU,IAAM,EAAG,SACnB,WAAY,GAAS,GAAK,EAAW,EAAI,EACzC,KAAM,EAAa,WAGvB,GAAW,GACJ,ECXF,YAA0B,EAAwB,CACvD,MAAO,GACJ,aACA,SAAS,EAAS,iCAAiC,gBACnD,MAAM,KAMJ,YAA0B,CAG/B,YAAqB,EAA0B,EAA2B,CAArD,YAA0B,kBAF9B,YAAiB,EAAS,uBAI3C,iBAAiB,EAAyB,CACxC,MAAO,MAAK,KAAK,KAAK,GAAG,GAAiB,SAMtC,YAAW,EAAqC,CACpD,GAAM,GAAa,KAAK,aAGxB,GAFA,KAAK,OAAO,MAAM,eAAgB,CAAE,OAAM,eAEtC,CAAC,GAAe,KAAM,MAAM,MAAO,GAEvC,GAAI,KAAM,GAAK,eAAe,KAAK,MACjC,YAAK,OAAO,MAAM,UAAY,EAAO,yBAA2B,KAAK,MAE9D,EAGT,KAAK,OAAO,MAAM,aAAe,GAEjC,GAAM,GAAI,KAAM,IAAS,GACzB,GAAI,GAAK,KACP,KAAM,IAAI,OAAM,EAAK,WAAa,mCAEpC,GAAM,GAAI,EAAI,EAAE,WAAY,GAAM,GAAY,EAAG,OACjD,GAAI,GAAK,KACP,KAAM,IAAI,OAAM,EAAK,WAAa,sBAEpC,GAAI,EAAE,MAAQ,MAAQ,EAAE,OAAS,MAAQ,EAAE,KAAO,KAChD,YAAK,OAAO,KACV,6CAA+C,EAAO,iBACtD,CACE,WAAY,EAAE,aAGX,EAGT,GAAM,GAAa,KAAK,iBAAiB,GACzC,GAAK,KAAM,GAAW,UAAa,KACjC,KAAM,IAAI,OACR,wCACE,EAAW,WACX,QACA,EAAK,YAGX,GAAM,GAAW,KAAM,GAAW,WAC5B,EAAW,KAAM,GAAK,OAEtB,EAAoB,KAAM,IAAO,EAAU,GAC/C,EAAQ,OAAO,KAAK,GAAQ,IAAS,IAEjC,EAAU,KAAM,GAAK,MAC3B,GAAI,EAAkB,OAAS,EAAG,CAChC,GAAM,GAAmB,KAAM,IAAO,EAAmB,GACvD,EAAQ,MAAM,KAAK,GAAO,IAAQ,IAEpC,GAAI,EAAiB,OAAS,EAAG,CAC/B,GAAM,GAAO,EAAiB,GAC9B,YAAK,OAAO,KAAK,EAAO,YAAc,GAC/B,KAAK,eAAe,EAAM,IAGrC,GAAM,GAAO,KAAM,GAAW,KAAK,EAAK,MAAM,aAC9C,YAAK,OAAO,KAAK,aAAc,CAC7B,IAAK,EAAK,WACV,KAAM,EAAK,aAEb,KAAM,GAAK,UAAU,GACd,KAAK,eAAe,EAAM,QAGrB,gBACZ,EACA,EACoB,CACpB,GAAM,GAAW,EAAO,KAAM,GAAI,WAAY,IAC9C,OAAW,KAAc,GACvB,KAAM,MAAK,cAAc,EAAY,GAGvC,MAAI,GAAW,IAAW,GAAgB,EAAK,YACxC,OAGK,eAAc,EAAuB,EAAiB,CAClE,OAAW,KAAe,GAAO,KAAM,GAAK,WAAY,IACtD,GAAI,KAAM,IAAW,EAAY,GAAc,CAC7C,KAAK,OAAO,KAAK,4CAA6C,CAC5D,aACA,cACA,SAGF,OAGJ,GAAM,GAAS,KAAM,GAClB,SACA,KAAK,EAAK,KAAO,EAAW,KAC5B,WAAW,CAAE,WAAY,KAC5B,MAAO,GAAW,UAAU,KCpEzB,oBAAsB,GAAkC,CA+CrD,YAAY,EAA4B,CAC9C,MAAM,WAAW,KAAY,IAAM,KAAK,QAAS,EAAa,OA/CvD,WAAQ,KAAK,MA0CL,YAAS,GAAI,IAiBb,WAAQ,EAAK,SAAY,CACxC,GAAM,GAAgB,IAAM,CAC1B,GAAI,KAAK,OAAS,IAAU,KAAM,IAAI,QAExC,GAAI,CAIF,GAHA,KAAK,OAAO,MAAM,mBAGd,CAAC,KAAsB,CACzB,GAAI,CAAC,KACH,KAAM,IAAI,OACR,cACE,KACA,qBACA,GACA,IAGN,KAAK,OAAO,KAAK,qDACjB,OAKF,KAAM,MAAK,WAAW,mBAAmB,mBAEzC,IAEA,KAAM,IAAoB,KAAK,SAC/B,KAAM,IAAoB,KAAK,QAAQ,YAEvC,GAAM,GAAe,KAAK,eAE1B,GACE,GAAgB,MAChB,AAAS,KAAM,GAAa,UAA5B,MACA,CAAE,KAAM,GAAa,iBAErB,KAAM,IAAI,OACR,qBAAqB,EAAS,aAAa,QAAQ,oCAQvD,KAAM,MAAK,aACX,KAAM,MAEN,IAEA,GAAsB,IAElB,MACE,KAAM,OACR,MAAM,MACN,MAIJ,IAEA,KAAM,MAAK,UAEX,IAEI,MACF,KAAM,MAAK,gBAEN,EAAP,CACA,AAAI,CAAC,KAAK,OAAS,CAAC,KAClB,GACE,yBAA4B,MAAiB,GAAK,IAClD,GAEG,KAAK,OAAO,OAAO,WAE1B,CACA,AAAI,KAAK,OAAO,SACd,MAAK,OAAO,KAAK,6BACZ,KAAK,OAAO,cASd,cAAW,EAAK,IAAM,GAAI,IAAW,KAAK,UAE1C,gBAAa,EAAK,IAAM,MAExB,cAAW,EAClB,IACE,GAAI,IACF,KAAK,QAAQ,KAAK,EAAS,YAAY,gBACvC,KAIG,kBAAe,EAAK,IAAM,GAAoB,KAAK,UAEnD,yBAAsB,EAAK,IAC3B,GAAI,IACT,KAAK,eACL,IAAM,EAAS,oBAAoB,iBAI9B,oBAAiB,EAAK,SAC7B,GAAe,IAAI,KAAK,QAAS,IAAM,KAAK,WAAW,gBAEhD,aAAU,EAAK,SAAa,MAAM,MAAK,kBAAkB,GAAG,SAC5D,aAAU,EAAK,SAAY,GAAe,KAAM,MAAK,eACrD,iBAAc,EAAK,IAAM,KAAK,UAAU,KAAK,GAAM,EAAG,SAgC9C,WAAQ,EAAK,SAAY,CACxC,OAAW,CAAE,KAAI,MAAO,CACtB,CAAE,GAAI,KAAK,QAAS,EAAG,GACvB,CAAE,GAAI,KAAK,eAAgB,EAAG,GAC9B,CAAE,GAAI,KAAK,SAAU,EAAG,IAExB,KAAM,GAAI,KAAM,GAAG,QAAS,GAAW,GAAI,EAAS,IAEtD,KAAK,OAAO,KAAK,wBAvKjB,KAAK,QAAU,EAAU,IAAI,GAC7B,KAAK,QAAU,GAAe,KAAK,SACnC,KAAK,OAAO,KAAK,eA/CZ,qBAAqB,CAC1B,GAAM,GAAqB,EAAI,EAAS,YAAY,MAAO,IACrD,EAAmB,EACvB,KAAK,cACL,GAAM,EAAG,QAAQ,YAEnB,MAAO,KAAuB,QAIzB,WAAW,CAChB,GAAM,GAAc,KAAK,qBACnB,EAAoB,EAAO,KAAK,eAAe,OACjD,EACJ,MAAI,IAAe,IAEjB,GAAW,GAAI,KAAK,cAAe,GACnC,KAAK,cAAgB,QAEnB,KAAK,eAAiB,MAAQ,MAChC,MAAK,cAAgB,EAAY,EAAS,YAAY,MAAO,GAC3D,GAAI,GAAI,IAAQ,GAAO,KAAM,IAC3B,MAAM,GACC,EAAG,YAIT,KAAK,oBAGP,mBAAmB,CACxB,GAAM,GAAI,GAAQ,WAClB,GAAI,GAAK,KACP,KAAM,IAAI,OAAM,uBAAyB,IAEzC,MAAO,MAeP,iBAAiB,CACnB,MAAO,MAAK,OAAO,WA2FjB,QAAQ,CACV,MAAO,MAAK,OAAO,aA+Bf,gBAA0C,CAC9C,GAAM,GAAuB,GAE7B,MAAI,MAAM,IAA8B,EAAS,SAAS,iBACxD,EAAI,KAAK,CACP,KAAM,kBACN,MAAO,GACP,KAAM,IAAM,OAIZ,KAAK,OAAO,UACd,EAAI,KACF,CAAE,KAAM,oBAAqB,MAAO,GAAM,KAAM,IAAM,KAAK,SAC3D,CACE,KAAM,mBACN,MAAO,GACP,KAAM,IAAM,EAAQ,KAAK,iBAAkB,GAAM,EAAG,YAEtD,CACE,KAAM,mCACN,MAAO,GACP,KAAM,IAAM,EAAQ,KAAK,iBAAkB,GAAM,EAAG,kBAInD,IC5NJ,oBAAoB,GAAiB,CAArC,aA7CP,CA6CO,oBAmBL,WAAQ,GAIC,UAAO,EAAK,IAAM,GAAI,IAAU,KAAK,eAUvC,eAAc,EAA2C,CAC9D,MAAO,GAAO,EAAI,IAAM,GAAM,SAAS,SAAS,CAC9C,MAAO,EACP,OAAQ,EACR,SAAU,UAuBP,aAA8B,CACnC,MAAO,MAAK,MAAM,OAAO,GAAK,EAAE,MAAM,CAAE,MAAO,EAAG,SAAU,WAG/C,gBAAgB,CAC7B,MAAO,MAAK,QACT,MAAM,UAAW,IAAK,IACtB,SAAS,CAAE,MAAO,EAAG,SAAU,UAG7B,gBAAe,EAAiB,CACrC,MAAO,IAAQ,WAAY,WAAW,GAAG,GAAS,wBAGvC,QAAO,EAAiB,CACnC,KAAK,SAAS,KAAK,kBAAoB,GACvC,KAAM,IAAS,IAAI,KAAK,GAAK,EAAE,SAAS,MAAM,CAAE,aAChD,KAAM,IAAU,IAAI,KAAK,GAAK,EAAE,SAAS,MAAM,CAAE,aACjD,KAAM,IAAM,IAAI,KAAK,GAAK,EAAE,SAAS,MAAM,CAAE,GAAI,KACjD,KAAM,IAAM,eAAe,eAGhB,SAAQ,EAAiB,CACpC,YAAK,SAAS,KAAK,mBAAqB,GACjC,CACL,SAAU,KAAM,IAAM,IAAI,KAAK,GAC7B,EAAE,OAAO,CAAE,SAAU,IAAK,MAAM,CAAE,GAAI,KAExC,gBAAiB,KAAM,IAAM,eAAe,UAIzC,cACL,EAAkD,GAClD,CACA,MAAO,MAAK,MAAM,QAAQ,EAAE,KAAK,wBAG5B,eAAc,EAAiD,CACpE,MAAO,MAAK,MAAM,IAAI,EAAE,KAAK,wBAGxB,eACL,EAAkD,GAClD,CACA,MAAO,MAAK,IAAI,WAAmB,EAAE,KAAK,iBAAiB,eAGtD,iBAAgB,EAAiD,CACtE,MAAO,MAAK,MAAM,QAChB,EACE,KAAK,QACF,OAAO,WACP,KAAK,YAAa,oBAAqB,0BAKnC,SAAQ,EAAiB,EAAqB,CACzD,GAAM,GAAe,GAAO,EAAS,OAAO,GAAa,GACvD,GAAY,IAEd,YAAK,SAAS,MAAM,YAAa,CAAE,UAAS,WAAU,iBAC/C,EAAQ,GACX,OACA,GAAM,GAAG,SAAY,CAInB,GAAM,GAAS,AAHF,MAAM,IAAY,EAAc,GAC3C,GAAI,aAAa,KAEC,IAAI,GAAM,EAAG,IACjC,MAAO,IAAS,eAAe,EAAS,iBAInC,YAAW,EAAiB,EAAqB,CAC5D,GAAI,EAAQ,GAAW,OACvB,GAAM,GAAO,KAAM,IAAY,EAAU,GAAM,GAAI,WAAW,IAC9D,YAAK,SAAS,KAAK,eAAgB,CACjC,UACA,KAAM,EAAK,IAAI,GAAM,GAAK,EAAI,KAAM,SACpC,aAEK,GAAS,oBAAoB,EAAS,EAAQ,EAAK,IAAI,GAAM,EAAG,YAGlE,kBAAkB,CACvB,MAAO,MAAK,IAAI,SAAiB;AAAA;AAAA;AAAA;AAAA;AAAA,0CAQ5B,SAAQ,EAAiB,CAC9B,MAAO,MAAK,GAAG,SAAY,CAEzB,AAAI,AADM,KAAM,IAAM,MAAM,SAAS,IAC5B,MACP,MAAM,IAAS,IAAI,KAAK,GAAK,EAAE,MAAM,CAAE,YAAW,UAClD,KAAM,IAAU,IAAI,KAAK,GAAK,EAAE,MAAM,CAAE,YAAW,UACnD,KAAM,IAAM,IAAI,KAAK,GAAK,EAAE,MAAM,CAAE,GAAI,IAAW,gBAKrD,aAAa,CACf,MAAO,IAAkB,KAAK,oBAG5B,eAAe,CACjB,MAAO,IAAU,KAAK,iBAGxB,sBAAuB,CACrB,YAAK,MAAQ,GACb,KAAK,QAAU,GACR,KAAK,SAGd,oBAAqB,CACnB,YAAK,MAAQ,GACT,KAAK,UAAY,MAAM,MAAK,SAAW,IAC3C,KAAK,QAAU,GACR,KAAK,SAGd,WAAqB,CACnB,MAAO,CACL,QAAS,KAAK,GACd,gBAAiB,KAAK,iBAY1B,cAAc,EAAiB,CAC7B,MAAO,GAAI,KAAK,aAAc,GAAM,SAAW,GAAa,EAAI,SAU5D,aAAmC,CACvC,MAAO,IAAQ,KAAK,YACjB,QAAQ,GAAM,GAAQ,IACtB,QAAQ,GAAM,GAAI,aAAa,IAC/B,QAAQ,GAAM,EAAG,YACjB,MAGL,YAAY,EAAqB,CAC/B,MAAO,IAAM,QAAQ,KAAK,GAAK,QAG3B,oBAAmB,EAAsC,CAC7D,YAAM,MAAK,WACJ,KAAK,MAAO,KAAK,GAAM,EAAG,MAAQ,QAGrC,cAAa,EAAmC,CACpD,MAAI,AAAS,MAAM,MAAK,mBAAmB,EAAG,MAA1C,MACF,MAAK,MAAO,KAAK,GACjB,EAAG,MAAQ,KACX,EAAG,QAAU,KAAK,IAEb,QAGF,SAAQ,EAAiB,CAC9B,MAAO,IAAI,MAAM,IACf,GAAI,QACD,OAAO,SACP,KAAK,WAAY,iBAAkB,UACnC,MAAM,mBAAoB,GAC1B,WAAW,0CAIZ,UAAU,CACd,MAAI,MAAK,MAAQ,MACf,MAAK,KAAO,KAAM,IAAM,QAAQ,KAAK,KAEhC,KAAK,WAMP,aAAY,EAAiB,CAClC,GAAM,GAAI,GAAI,QACX,OAAO,aACP,KAAK,WAAY,iBAAkB,UACnC,MAAM,mBAAoB,GAC1B,WAAW,oCACd,MAAO,IAAI,IAAI,SAAS,QAGpB,WAAW,CAEf,MAAO,AADM,MAAM,MAAK,WACZ,IAAI,GAAK,EAAE,KAAK,KAAK,MAAM,YAGnC,YAAW,EAA6C,CAC5D,GAAI,KAAK,SAAW,KAAM,CACxB,GAAM,GAAO,KAAM,MAAK,UACxB,KAAK,SAAS,KAAK,8BAAgC,EAAM,CAAE,UAC3D,GAAM,GAAU,KAAM,IAAY,EAAM,GACtC,EAAI,eAAe,KAAM,IAE3B,KAAK,QAAU,GAAgB,EAAQ,IAEvC,OAAW,KAAU,MAAK,QACxB,OAAW,KAAO,GAAO,KACvB,KAAM,GAAI,eAIhB,MAAO,MAAK,aAGR,mBAAmB,CAEvB,GAAM,GAAW,KAAM,IAAM,IAAI,IAC/B,GAAM,gBACH,OAAO,KAAM,eACb,SAAS,kBAAmB,KAAK,iBACjC,QAAQ,OAEb,KAAK,QAAU,EACb,EAAQ,KAAK,GAAM,EAAG,GAAM,KAAK,IACjC,IAGF,KAAK,SAAW,EACd,EAAQ,UAAU,KAAK,GAAM,EAAG,GAAM,KAAK,IAC3C,IAEF,KAAM,IAAW,KAAK,SAAU,IAAM,KAAK,eAC3C,KAAM,IAAW,KAAK,QAAS,IAAM,KAAK,mBAG9B,cAAc,CAC1B,MAAO,GACL,GAAM,IAAI,MACR,GAAM,gBACH,OAAO,KAAM,eAEb,SAAS,kBAAmB,IAAK,KAAK,iBACtC,QAAQ,CACP,CAAE,OAAQ,kBAAmB,MAAO,QAEpC,CAAE,OAAQ,KAAM,MAAO,WAG7B,GAAO,KAAK,SAAW,GAAK,SAIlB,aAAa,CACzB,MAAO,GACL,GAAM,IAAI,MACR,GAAM,gBACH,OAAO,KAAM,eAEb,SAAS,kBAAmB,IAAK,KAAK,iBACtC,QAAQ,CACP,CAAE,OAAQ,kBAAmB,MAAO,OAEpC,CAAE,OAAQ,KAAM,MAAO,UAG7B,GAAO,KAAK,QAAU,GAAK,SAIzB,cAAc,CAElB,MAAO,AADM,MAAM,MAAK,WACZ,IAAI,GAAO,EAAI,WAGvB,WAAW,CACf,GAAI,KAAK,OAAS,KAAM,MAAO,MAAK,MACpC,GAAI,KAAK,IAAM,KAAM,MAAQ,MAAK,MAAQ,GAC1C,GAAM,GAAQ,KAAM,IAAU,MAAM,OAAO,CAAE,QAAS,KAAK,KAC3D,MAAQ,MAAK,MAAQ,GACnB,EAEA,GAAM,CAAC,CAAC,EAAO,EAAG,OAAQ,CAAC,EAAG,aAI5B,UAAS,EAAqB,CAClC,MAAO,IAAU,SAAS,KAAK,GAAK,QAGhC,WAAW,CAEf,GAAI,KAAK,OAAS,KAAM,CACtB,GAAM,GAAQ,KAAK,MAAM,KAAK,GAAM,EAAO,EAAG,QAC9C,GAAI,GAAS,KAAM,MAAO,GAE5B,MAAO,GACL,GAAU,MAAM,UAAU,CAAE,QAAS,KAAK,GAAK,MAAO,IACtD,GAAM,GAAI,EAAI,GAAO,EAAG,MAAQ,YAI9B,iBAAwC,CAC5C,MAAO,IAAY,KAAK,WAAY,GAAM,EAAG,gBAG/C,MAAe,CACb,MAAO,UAAY,KAAK,GAG1B,QAAQ,EAAoB,GAAW,CACrC,MAAO,UACF,KAAK,OAAO,WAAW,IADrB,CAEL,MAAO,KAAK,kBACT,KAAK,YAIN,aAAY,EAAoB,EAAsB,EAAS,GAAO,CAG1E,GAFI,KAAK,UAAY,MACnB,MAAK,SAAW,GAAI,MAClB,KAAK,SAAS,IAAI,IAAY,KAAM,CACtC,GAAM,GAAK,EAAS,GAAG,KAAK,QAC5B,KAAM,GAAQ,EAAG,WAAY,KAAM,IAAQ,CACzC,AAAI,EAAK,SAAS,WAAW,WAC3B,MAAK,OAAS,KAAM,GAAG,gBAG3B,GAAM,GAAO,GACb,KAAK,SAAS,IAAI,EAAS,KAAM,GAAG,SAAS,EAAS,EAAM,IAE9D,MAAO,MAAK,SAAS,IAAI,QAGrB,UAAS,EAA4C,CACzD,MAAO,QACD,KAAM,MAAK,YAAY,EAAU,GAAa,MAE/C,KAAK,OAIZ,SAAmB,CACjB,GAAI,KAAK,OAAS,KAChB,KAAM,IAAI,OAAM,mCAElB,MAAO,MAAK,MAAM,KAAK,GAAM,EAAG,SAGlC,YAA4B,CAC1B,MAAO,IACL,SAAU,GACV,SAAU,GACV,OAAQ,KAAK,QACV,KAAK,OAIZ,cAAe,CACb,GAAI,KAAK,eAAiB,KACxB,KAAM,IAAI,OAAM,kDASlB,GAAM,GAAS,KAAK,cACjB,OAAO,GAAM,EAAG,SAChB,IAAI,GAAO,EACV,IAAK,KAAK,OAAO,UAAU,EAAG,IAC9B,KAAM,EAAG,YAGP,EAAa,GAAO,EAAQ,GAAM,EAAG,MAE3C,GAAI,EAAW,MAAM,GAAM,EAAG,OAAS,aAAc,CAEnD,GAAM,GAAM,KAAK,cAAc,GAC/B,EAAW,QAAQ,CACjB,IAAK,KAAK,OAAO,UAAU,EAAI,IAAO,OACtC,KAAM,cAGV,MAAO,QAGH,gBAA2C,CAC/C,GAAM,GAAM,KAAM,MAAK,WACvB,MAAO,GAAQ,KAAM,SAAQ,IAAI,EAAI,IAAI,GAAM,EAAG,oBAG9C,wBAAwB,CAC5B,MAAI,MAAK,eAAiB,MACxB,MAAK,cAAgB,KAAM,IAAY,KAAM,MAAK,WAAY,GAC5D,GACE,EAAG,YACH,GAAM,EAAG,SACT,IAAM,MAIL,KAAK,mBAGR,oBAAmB,EAAc,CACrC,GAAM,GAAM,KAAM,GAAE,MACpB,GAAI,GAAO,KAAM,OACjB,GAAM,GAAQ,EAAI,KAAM,IAAU,YAAY,CAAE,GAAI,KAAK,IAAM,CAAE,SAAQ,GACzE,MAAO,GAA+B,EAAO,SAAY,CACvD,GAAM,GAAK,GAAI,IACf,SAAG,MAAQ,KACX,EAAG,QAAU,KAAK,GAClB,KAAM,GAAG,QAAQ,GACV,IAIX,OAAQ,CACN,YAAK,cAAgB,OACrB,KAAK,MAAQ,OACb,KAAK,SAAW,OAChB,KAAK,QAAU,OACf,KAAK,KAAO,OACL,UAGH,WAAU,EAAiB,CAC/B,YAAK,OAAS,EACP,KAAK,WA1fT,MACE,AADF,GACE,UAAuB,QACvB,AAFF,GAEE,iBAAmB,KA6BV,AA/BX,GA+BW,cAAgB,CAAC,QAAS,SAAU,YAUpC,AAzCX,GAyCW,iBAAmB,EACjC,IACE,GAAM,IAAI,WACR,CACE,IAAK,GACH,SACA,6BACA,aACA,QACA,oBACA,2BACA,sBAKR,EAAI,GC/FD,aAA+B,CACpC,MAAO,IAAG,KAAW,SAAY,CAC/B,KAAM,IAAM,IAAI,KAAK,GAAK,EAAE,OAAO,CAAE,QAAS,KAC9C,KAAM,IAAU,IAAI,KAAK,GAAK,EAAE,OAAO,CAAE,QAAS,KAClD,KAAM,IAAU,IAAI,KAAK,GACvB,EACG,MAAM,CACL,KAAM,GAAe,wBACrB,QAAS,KAEV,QAAQ,CACP,KAAM,GAAe,oBACrB,QAAS,KAEV,YCrBT,OAAc,sBCAd,OAAiC,iBACjC,GAAuB,uBACvB,GAA0B,mBAC1B,GAA4B,sBAC5B,GAA2C,qBAkCpC,oBAAsB,GAAe,CAclC,aAAc,CACpB,MAAM,UAAW,IAAM,KAAK,QAAS,EAAa,QAV5C,cAAmC,GAAI,KAK9B,cAAW,GAAI,KACf,mBAAgB,GAAI,IAAe,EAAI,GACvC,WAAQ,GAAI,IAcpB,WAAQ,EAAK,SAAY,CAChC,KAAM,MACN,GAAM,GAAS,EAAS,OAAO,eAC/B,AAAI,IAAQ,QAAQ,IAAI,WAAa,EAAS,OAC9C,KAAM,cAAO,GACb,KAAK,KAAQ,KAAM,IAAe,IAAI,GACtC,KAAM,MAAK,KAAK,MAfhB,AADA,KAAK,kBAAoB,OAAM,KAAgB,IAAM,OAAM,IACvD,WAAO,kBACX,IAAkB,IAElB,KAAK,aAAe,mBAAY,IAAM,KAAK,QAAS,GAAoB,GACxE,KAAK,YAAc,mBAAY,IAAM,KAAK,OAAQ,GAClD,UAAO,GAAG,MAAO,IAAM,KAAK,OACvB,KAAK,cAYN,QAAQ,CACZ,KAAK,MAAM,MAGL,SAAS,EAAoB,CACnC,MAEE,GAAW,SAAS,SACpB,CAAC,EAAW,SAAS,KAAK,mBAItB,SAAS,EAAa,CAC5B,AAAI,KAAY,KAAK,OACrB,GAAS,KAAK,SAAU,EAAK,IAAM,CACjC,GAAM,GAAU,MAAO,IAAM,QAAQ,IAAI,uBAAyB,IAClE,GAAI,CACF,MAAO,aAAM,EAAK,CAAC,EAAe,IAChC,KAAK,cAAc,EAAO,YAAK,EAAK,WAE/B,EAAP,CACA,GAAM,GAAU,KAAM,IACpB,QAAQ,MAAM,6BAA+B,EAAK,IAEpD,eAKA,MAAK,EAAY,GAAO,CAC5B,GAAI,OAAY,KAAK,QAErB,MAAM,MAAK,KAAK,qBAAqB,KAAM,IAAM,CAC/C,AAAI,CAAC,KAAK,SAAS,EAAG,aAClB,IACF,KAAM,GAAQ,EAAG,OAAQ,GAAQ,KAAK,SAAS,IAAI,EAAG,WAAY,IAEhE,GAAO,KAAM,GAAG,YAClB,KAAK,SAAS,EAAG,QAGjB,OAAY,KAAK,QACrB,IAAI,CACF,GAAM,GAAa,YAAK,KAAK,KAAK,WAAY,GAAW,GAAI,QAC7D,KAAM,cAAO,GACb,KAAK,SAAS,SACP,EAAP,CACA,GAAM,GAAU,KAAM,IACpB,QAAQ,MAAM,kDAAmD,IAGrE,AAAI,KAAY,KAAK,OACjB,GACF,QAAQ,IAAI,sBAAwB,KAAK,KAAO,sBAItC,QAAQ,CACpB,GAAkB,IAClB,EAAI,KAAK,aAAc,kBACvB,KAAK,aAAe,OACpB,EAAI,KAAK,YAAa,kBACtB,KAAK,YAAc,OACnB,OAAW,KAAM,MAAK,SAAS,SAC7B,EAAG,QAEL,KAAK,SAAS,QACd,OAAW,KAAM,MAAK,cACpB,KAAM,MAAK,cAAc,QAAS,GAEpC,GAAI,CACF,KAAK,MAAM,GAAqB,UAChC,GAKI,MAAM,EAAiB,CAC7B,OAAW,KAAM,GACf,QAAQ,IAAI,KAAsB,eAAe,SAIvC,eAAc,EAAe,EAAkB,CAC3D,AAAI,CAAC,KAAK,SAAS,IAGnB,KAAM,MAAK,MAAM,aAAa,EAAU,SAAY,CAClD,GAAI,CACF,GAAM,GAAI,KAAM,IAAe,IAAI,GACnC,GAAI,GAAK,KAAM,CACb,GAAM,GAAU,KAAM,IACpB,QAAQ,MAAM,8BAA+B,CAAE,QAAO,cAExD,OAGF,GAAM,GAAc,KAAM,GAAE,OAC5B,GAAI,GAAe,MAAQ,GAAe,EAExC,OAEF,GAAM,GAAY,EAAO,KAAK,SAAS,IAAI,EAAE,YAAa,IAAM,GAChE,GAAI,GAAI,EAAW,GAAc,OACjC,KAAM,GACJ,GAAe,EAAG,CAAE,MAAO,EAAW,IAAK,IAC3C,GAAO,GAAe,GAAG,IAE3B,KAAK,cAAc,IAAI,EAAE,YAEzB,KAAK,SAAS,IAAI,EAAE,WAAY,SACzB,EAAP,CACA,GAAM,GAAU,KAAM,IACpB,QAAQ,MACN,kBAAoB,EAAW,KAAO,GAAe,UArJ1D,MACW,AADX,GACW,SAAW,EAAK,IACvB,KAAgB,OAAY,GAAI,KCtCpC,YAAuD,CAAvD,aAFP,CAGmB,SAAW,GACpB,aAAU,KAEd,OAAe,CACjB,MAAO,MAAK,IAAI,OAGlB,MAAM,EAA8B,CAClC,MAAO,IAAM,KAAK,IAAK,GAMzB,WAAW,EAAQ,CACjB,KAAK,IAAI,OAAO,KAAK,QAAS,EAAG,GAAG,GAMtC,QAAQ,EAAQ,CACd,KAAK,QAAQ,GAAG,GAChB,KAAK,QAAQ,EAAE,QAGjB,OAAO,EAAM,CACX,MAAO,MAAK,cAAc,GAAM,IAAO,GAMzC,cAAc,EAA2D,CACvE,GAAI,GAAU,GACd,UAAc,KAAK,IAAK,CAAC,EAAS,EAAe,IAAa,CAC5D,GAAM,GAAO,EAAW,EAAM,EAAO,GACrC,MAAK,IACH,GAAU,GACN,EAAQ,KAAK,SAAS,KAAK,WAE1B,IAET,KAAK,QAAQ,GACN,EAGT,KAAK,EAA+B,IAAM,GAAM,CAC9C,GAAI,KAAK,OAAS,EAChB,MAAO,CAAE,MAAO,OAAW,KAAM,IAEjC,OAAS,GAAI,EAAG,EAAI,KAAK,KAAM,IAAK,CAClC,GAAM,GAAQ,KAAK,IAAI,KAAK,SAI5B,GAHA,KAAK,UAGD,GAAS,MAAQ,EAAU,GAAQ,MAAO,CAAE,QAAO,KAAM,IAE/D,MAAO,CAAE,MAAO,OAAW,KAAM,IAIrC,IAAI,EAA+B,IAAM,GAAM,CAC7C,GAAI,EAAQ,KAAK,KAAM,MAAO,GAC9B,GAAM,GAAM,GACZ,OAAS,GAAI,EAAG,EAAI,KAAK,KAAM,IAAK,CAClC,GAAM,GAAQ,KAAK,IAAK,MAAK,QAAU,GAAK,KAAK,IAAI,QACrD,AAAI,EAAU,IAAQ,EAAI,KAAK,GAEjC,MAAO,GAGD,QAAQ,EAAe,EAAG,CAEhC,KAAK,QACH,KAAK,IAAI,SAAW,EAAI,EAAK,MAAK,QAAU,GAAQ,KAAK,IAAI,SCpDnE,GAAS,IAAM,MACf,GAAO,IAAM,EAAM,KAEnB,GAAM,IAAc,GAAI,IAClB,GAAY,GAAI,IAChB,GAAgB,GAAI,IAEb,IAAa,GAAI,IAAgB,CAC5C,KAAM,OACN,SAAU,GACV,WAAY,EAAI,EAChB,eAAgB,GAAK,IAGnB,GAAgC,SAAY,GAEzC,YAAyB,EAAsB,CACpD,GAAgB,EAGlB,mBAA4C,CAC1C,MACE,OACA,KACA,GAAc,OAAS,GACvB,GAAU,cAAgB,MACzB,KAAM,MAIX,GAAM,IAAY,KAAY,EAAI,IAAM,IAExC,mBAAgC,CAE9B,MAAQ,MAAM,MACV,OACA,GAAY,SAAS,YAAa,SAAY,CAC5C,GAAI,KAAM,MAAY,OACtB,GAAM,CAAE,SAAU,GAAc,KAAK,GAAM,EAAG,UAC9C,AAAI,GAAS,MACN,GACF,KAAK,EAAM,KAAM,SAAY,EAAM,UACnC,QAAQ,IAAM,IAKf,GAAc,KAAO,GAAG,EAAM,GAAgB,MAInD,YAAyB,EAA8B,CAC5D,GAAc,KAAK,GACnB,EAAM,IAGD,YAA4B,EAAuB,CACxD,MAAO,IAAc,cAAc,GAAM,EAAG,OAAS,GAGvD,mBAAkC,CAChC,MAAO,CACL,SAAU,CACR,SAAU,KACV,OAAQ,IACR,aAAc,KAAM,OAEtB,cAAe,GAAc,MAAM,IAAI,GAAM,GAAI,MACjD,sBAAuB,GACpB,IAAI,GAAM,GAAI,UACd,IAAI,GAAM,GAAI,MACjB,iBAAkB,GAAU,gBCjGhC,OAAmB,2BCgBnB,GAAM,IAAS,EAAK,IAAM,EAAS,eAEtB,GAAuB,EAOpC,YAAmB,EAAoB,CAErC,MAAO,IAAK,EAAO,eAad,YAAwC,CAAxC,aAxCP,CA0CW,UAAO,GAAS,IAAI,MAAY,KAAK,UAE9C,UAAU,EAAI,GAAI,MAAQ,CACxB,MAAO,MAAK,KAAK,QAAQ,GAG3B,MAAO,CACL,MAAO,MAAK,KAAK,OAGnB,SAAS,EAA0B,CACjC,MAAO,MAAK,UAAU,GAAI,MAAK,EAAE,UAAY,IAAW,KACtD,GAAe,EAAE,QAAS,EAAG,IAAY,cAIvC,YAAW,EAAO,GAAI,MAAQ,CAClC,MAAO,GACL,KAAM,MAAK,UAAU,GAAM,WACzB,GAAM,EAAG,MAAQ,SAAW,CAAC,EAAG,uBAKhC,oBAAmB,EAAgB,CACvC,GAAM,GACJ,EAAI,GAAO,SAAS,KACpB,EAAI,EAAM,SAAS,SAAS,IACxB,EAAmB,KAAM,MAAK,aAC9B,EACJ,EAAS,gBAAgB,eACxB,GAAa,GAAuB,GACvC,MAAO,IAAoB,OAGvB,YAAW,EAAO,GAAI,MAAQ,CAElC,MAAO,AADG,MAAM,MAAK,WAAW,IACvB,YAGL,gBAAe,EAA6B,CAChD,GAAI,IACF,YAAS,MAAM,0CAA2C,CACxD,MAAO,GAAU,KAEZ,KAET,GAAI,CACF,GAAM,GAAa,GAAkB,EAAM,SACrC,EAAmB,KAAM,MAAK,aAC9B,EACJ,EAAS,gBAAgB,eACxB,GAAa,GAAuB,GAEvC,MAAI,IAAoB,EACtB,MAAS,MACP,kEACA,CACE,mBACA,aACA,kBACA,MAAO,GAAU,KAGd,MAGH,AADS,KAAM,MAAK,WAAW,IACvB,KACV,MAAS,MACP,oEACA,CACE,MAAO,GAAU,KAGd,MAEP,MAAS,MAAM,2BAA4B,CACzC,MAAO,GAAU,GACjB,aACA,mBACA,oBAEM,SAGL,EAAP,CACA,YAAS,MACP,wFACA,GAEK,WAKL,YAAW,EAAoB,CACnC,GAAM,GAAO,KAAK,SAAS,GAC3B,MAAO,GACL,EACG,WAAW,CACV,YAAa,EAAS,gBAAgB,eACtC,WAAY,KAEb,MAAM,IAAG,IACZ,GAAM,EAAG,eAAe,MA1GvB,MACW,AADX,GACW,SAAW,EAAK,IAAM,GAAI,KCnCrC,GAAM,IAAgB,EAC3B,IACE,GAAU,kBACT,IAAU,IAAY,EAAS,aAAa,gBAGjD,EAAS,aAAa,YAAY,IAAM,GAAc,SCZtD,OAAmB,2BACnB,GAAuD,QACvD,GAAkC,iBAClC,GAAe,sBCCR,YAA6B,CAGlC,YAAqB,EAA4B,EAA2B,CAAvD,iBAA4B,eAC/C,KAAK,YAAc,GAAI,IAAY,GAGrC,SAAU,CACR,MAAO,MAAK,YAAY,MAG1B,QAAS,CACP,MAAI,MAAK,YAAY,OAAS,KAAK,WACjC,GAAY,KAAK,YAAY,MAAO,KAAK,WAEpC,KAAK,aAGF,MAAM,CAChB,MAAO,MAAK,YAAY,QAAU,KAAK,UACnC,KAAK,QAAQ,KAAK,YAAY,IAC9B,OAGN,OAAO,EAAU,CACf,GAAM,GAAM,KAAK,IACjB,OAAW,KAAM,GACf,GAAI,GAAM,KAAM,CACd,GAAM,GAAI,KAAK,QAAQ,GACvB,AAAI,GAAK,MACF,IAAI,EAAG,IAAM,KAAK,YAAY,IAAI,IAI7C,AAAI,KAAK,YAAY,QAAU,EAAI,KAAK,WAAW,KAAK,WCtC5D,OAA6C,iBAC7C,GAAqD,mBASrD,GAAM,IAAgB,KAChB,GAAe,GAAgB,EAE9B,QAAgB,CAYrB,YAAqB,EAAe,EAAqC,CAApD,SAXJ,WAA+B,GAAI,IAClD,IAKM,mBAAgB,GAChB,YAAS,GACT,aAAU,GACV,aAAU,GAGhB,KAAK,KAAO,GAAiB,EAAE,MAC/B,KAAK,WAAa,wBAAiB,EAAE,WAAY,CAAE,UAAW,KAC9D,KAAK,OAAU,GAAE,IAAI,cAAc,SAAS,OACxC,KAAK,WAAW,KAAK,uBACrB,EAAE,IAAI,cAAc,SAAS,OAC7B,KAAK,WAAW,KAAK,iCACrB,KAAK,YAEN,KAAK,GAAI,KACT,GAAG,QAAS,GAAO,CAClB,EAAa,GACb,KAAK,QAAU,KAEnB,KAAK,OAAO,GAAG,OAAQ,KAAK,OAAO,KAAK,OACxC,KAAK,OAAO,GAAG,MAAO,IAAM,CAC1B,KAAK,OAAS,KAIV,OAAO,EAAe,CAC5B,GAAM,GAAK,GAAW,GACtB,AAAI,GAAM,MACR,MAAK,MAAM,IAAI,OAAK,GAAL,CAAS,KAAM,KAAK,QACnC,KAAK,cAAgB,IAEnB,KAAK,MAAM,OAAS,IAAiB,CAAC,KAAK,SAC7C,MAAK,WAAW,QAChB,KAAK,QAAU,IAInB,UAAW,CACT,MAAO,aAAe,KAAK,EAAE,WAAa,IAG5C,cAAe,CACb,MAAO,MAAK,cAGd,WAAY,CACV,MAAO,MAAK,QAGd,OAAQ,CACN,MAAO,MAAK,QAAU,KAAK,MAAM,SAAW,EAG9C,MAAO,CACL,MAAO,MAAK,MAAM,MAAM,GAG1B,OAAQ,CACN,GAAM,GAAS,KAAK,MAAM,MAAM,QAChC,MAAI,IAAU,MAAQ,KAAK,MAAM,OAAS,IAAgB,KAAK,SAC7D,MAAK,WAAW,SAChB,KAAK,QAAU,IAEV,IClEJ,YAAwB,EAAQ,GAAK,EAAU,CACpD,GAAM,GAAW,KAAK,MAAQ,EAC9B,MAAO,GAAQ,GAAe,IAAI,EAAS,OAAO,gBAAiB,GACjE,EAAI,sBACF,KAAM,IACJ,CAAC,OAAQ,WAAW,SAAS,EAAG,MAChC,GAAI,KAAM,GAAG,UAAW,KAKhC,kBAA0C,EAAqB,GAAI,CACjE,KAAM,MAEN,GAAM,GAEF,GACF,GAAU,OAAO,IAAI,GAAY,CAC/B,EACA,GAAI,IAAoB,EAAoB,OAI1C,EAAW,KAAK,MAAQ,GACxB,EAAS,EAAS,yBAExB,YAAM,GAAQ,KAAkB,GAC9B,GAAuB,CACrB,KAAM,wBACN,OAAQ,EAAM,IAAI,GAAK,SAAY,CACjC,GAAI,CACF,GAAM,GAAkB,GAClB,EAAK,GAAI,IAAU,EAAG,GAAO,EAAO,KAAK,IAE/C,IADA,KAAM,IAAU,IAAM,EAAG,eAAgB,CAAE,UAAW,GAAK,IACpD,CAAC,EAAG,SAAW,CAAC,EAAG,aAAa,CACrC,GAAM,GAAK,EAAG,QACd,AAAI,GAAM,KAER,KAAM,IAAM,GACH,EAAG,GAAK,GACjB,EAAe,EAAG,IAAI,IAAI,GAG9B,AAAI,EAAW,IACb,GAAO,KAAK,qBAAuB,EAAG,GAEpC,EAAO,KACL,AAAC,GACC,EAAG,OAAS,eACZ,GAAS,GAAI,SAAS,4BAE1B,GAAG,KAAM,GAAE,UAAW,KAAK,MAAQ,IAEnC,GAAO,KAAK,6BAA+B,GAC3C,KAAM,GAAE,kBAGL,EAAP,CACA,EAAO,KAAK,+BAAiC,EAAG,SAOjD,AADS,GAAQ,GAAO,GAAgB,IAAI,GAAM,EAAG,WAC7C,KAAK,CAAC,EAAG,IAAM,GAAI,EAAE,GAAI,EAAE,KClF5C,OAAyB,4BACzB,GAA6B,iBAC7B,GAA8C,iBAS9C,GAAM,IAAS,EAAK,IAAM,EAAS,OAEtB,GAAK,EAAK,IAAM,CAAC,KAAU,KAAM,eAAQ,KAAK,MAE3D,aAAkB,CAChB,OAAQ,uBACD,QACH,MAAO,UACJ,SACH,MAAO,UACJ,QACH,MAAO,cAEP,MAAO,OAIb,aAAyB,CACvB,MAAO,kBAAa,IAAM,iBA2BrB,aAAuB,CAC5B,GAAI,CACF,GAAM,GAAQ,oBAAa,mBAAmB,WACxC,EAAI,GAAe,CAAE,QAAO,cAAe,KACjD,GAAI,EAAS,EAAE,aAAc,MAAO,GAAE,YAEtC,GAAM,GAAM,EAAO,EAAE,QAAS,EAAE,YAChC,MAAO,IAAO,EAAE,KAAM,EAAK,CAAC,EAAG,IAAM,EAAI,IAAM,EAAG,UAC3C,EAAP,CACA,YAAS,KAAK,kCAAmC,GAC1C,MAIX,YAAoB,EAAqB,CACvC,MAAO,GAAI,MAAM,KAAK,MAAM,EAAG,GAAG,KAAK,KAGzC,GAAM,IAAe,CACnB,OAAQ,eACR,OAAQ,OACR,OAAQ,gBACR,OAAQ,YACR,QAAS,WACT,QAAS,aACT,QAAS,SACT,QAAS,cACT,QAAS,SACT,QAAS,WACT,OAAQ,WAGJ,GAAoB,EAAK,IAC7B,gBAAS,2BAA2B,WAAW,QAGjD,YAAqB,EAAiB,KAAqB,CACzD,MAAO,IAAa,GAAW,IAG1B,YAAmB,EAAiB,KAAqB,CAC9D,GAAI,CACF,MAAO,IACL,GAAY,GACZ,GAAM,SAAS,MAAO,KACtB,UAEK,EAAP,CACA,YAAS,KAAK,+BAAgC,GACvC,MAIX,GAAM,IAAuB,CAC3B,OAAQ,KACR,MAAO,MACP,MAAO,IACP,MAAO,IACP,MAAO,QACP,MAAO,cACP,MAAO,KACP,MAAO,OACP,MAAO,KACP,MAAO,KACP,MAAO,MAGF,YAAmB,EAAI,iBAAW,CACvC,GAAM,GAAM,GAAqB,GAAW,IAC5C,MAAI,IAAO,KACF,WAAW,MAAQ,KAE1B,MAAS,KAAK,iCAAmC,GAC1C,YAAY,MAIhB,GAAM,IAAO,EAClB,IACE,GAAU,cAAO,IAAI,GAAK,EAAE,QACzB,IAAI,GAAM,GAAG,EAAG,cAAW,EAAG,KAC9B,KAAK,MACV,GJrFF,GAAM,IAAS,EAAS,UAElB,GAAiB,IAEvB,kBAAoC,EAAkB,CACpD,GAAI,CACF,MAAK,MACL,YAAO,KAAK,CAGV,IAAK,GACD,4DACA,6DACJ,gBAAiB,GAAyB,EAAQ,MAClD,QAAS,GACT,YAAa,GACb,eAAgB,GAChB,aAAc,IAAM,GACpB,WAAY,KAAc,WAC1B,aAAc,AAAC,GAAiB,EAAQ,sBAAuB,KAE1D,IAfsB,SAgBtB,EAAP,CACA,UAAO,KAAK,4BAA8B,GACnC,IAIJ,YAAsB,EAAiB,EAAe,CAC3D,AAAI,MACF,CAAI,GAAS,MAAQ,CAAC,GAAiB,GACrC,WAAO,iBAAiB,GAAW,EAAO,IAChC,GAAiB,IAC3B,WAAO,eAAe,IAKrB,GAAM,IAAc,EAAK,IAAM,GAAI,KAEnC,QAAkB,CAEvB,aAAc,CADG,gBAAa,GAAW,WAWhC,gBAAa,MACpB,EACA,IAC0B,CAC1B,GAAI,CAAC,KACH,UAAO,KAAK,yCAA0C,GAC/C,KAGT,GAAI,KAAM,MAAK,WAAW,mBAAmB,GAC3C,UAAO,KAAK,4CAA6C,GAClD,KAGT,GAAM,GAAU,GAAe,EAAO,GAEtC,GAAI,GAAiB,GACnB,UAAO,KAAK,mDAAoD,CAC9D,QACA,OACA,IAAK,IAEA,KAET,AAAI,EAAM,EAAM,UACd,GAAM,QAAU,GAAU,EAAS,MAErC,GAAM,GAAI,KAAM,IAAc,GAC9B,MAAO,MAAK,WAAW,eAAe,IArCtC,GAAW,IACX,GAAQ,IACR,GAAI,IAAe,cAAe,IAAM,KAAK,MAAO,EAAa,OAG3D,KAAM,CACZ,MAAO,GAAI,WAAO,gBAAgB,YAAa,GAAM,EAAG,MAAM,EAAI,MAmC/D,YAAwB,EAAc,EAA0B,CACrE,MAAO,GACL,GAAgB,CACd,EAAM,QACN,GAAG,EAAI,GAAoB,EAAM,WAAW,SAC5C,GAAS,GAAM,sBAEjB,KAAK,MAGF,YACL,EACiB,CACjB,MAAO,IAAY,EAAG,GAAO,EAAc,EAAI,IAAI,MAG9C,YAA4B,EAA2C,CAC5E,MAAO,IACL,EACE,CAAC,GAAG,KAAM,GAAG,OAAO,OAAO,GAAM,EAAI,GAAI,gBAAkB,UAE7D,GAAO,EAAI,KAAK,OAMpB,kBACE,EAC8B,CAC9B,GAAM,GAAQ,EAAS,MAAM,MAC7B,AAAI,EAAS,IACP,GAAM,MAAQ,MAAM,GAAM,KAAO,IACrC,EAAM,KAAK,MAAQ,GAGjB,EAAQ,EAAM,cAAc,GAAM,YAAc,KAAM,OAE1D,GAAM,GAAQ,EAAO,EAAM,MAAO,IAClC,SAAM,IAAM,WAAG,IACf,EAAM,YAAc,KACpB,EAAM,cAAgB,IACtB,EAAM,UAAY,KAAK,MAAQ,GAC/B,EAAM,QAAU,GAChB,EAAM,GAAK,KACX,EAAM,SAAW,KACjB,EAAM,YAAc,WAAG,SAAS,KAChC,EAAM,OAAS,KAAM,MACrB,EAAM,KAAO,KACb,EAAM,cAAgB,KACtB,EAAM,iBAAmB,KACzB,EAAM,aAAe,GAAS,kBAAa,MAAQ,GAAS,mBAC5D,EAAM,OAAS,KAAM,MACrB,EAAM,IAAM,KAAM,MAClB,EAAM,KAAO,EAAU,WAAG,MAE1B,EAAM,MAAQ,EAEP,GACL,UAAW,KAAK,MAAQ,GACrB,GAIP,mBAAsC,CACpC,KAAM,IAAU,yBAEhB,KAAM,IAAM,GAAoB,GAChC,GAAM,GAAU,KAAM,MACtB,MAAO,GAAQ,EAAQ,IAAI,KAGtB,YAA8B,EAAiC,CACpE,MAAO,GAAI,GAAmB,EAAG,GAAI,GAAU,EAC7C,UAAW,EAAG,GAAK,EACnB,QACA,SAAU,EAAO,EAAG,KAAM,MAC1B,QAAS,GAAa,EAAG,IAAM,KAAO,EAAG,KACzC,KAEE,MAAO,GAAG,MAAS,SACf,EAAG,KACH,CAAE,MAAO,GAAS,EAAG,MAAQ,GAAa,EAAG,MAAQ,EAAG,SAI3D,YAA4B,EAA8B,CAC/D,OAAQ,OACD,QACH,MAAO,aAAS,UACb,OACH,MAAO,aAAS,YACb,OACH,MAAO,aAAS,SACb,QACH,MAAO,aAAS,cAEhB,QHpOC,aAA6B,CAClC,MAGE,iCACA,GAAI,QAAO,cACX,GAIJ,mBAAuC,CACrC,GAAM,GAAU,KACV,EAAQ,KAAM,IAAc,CAChC,UACA,YAAa,KAAM,QAGrB,MAAI,MACF,WAAO,aAAa,GAEpB,KAAM,IAAW,WAAW,WAAW,GAElC,EQ5BT,OAAuB,sBAWhB,YAAqB,EAAU,EAAQ,KAAqB,CAEjE,AAAI,MAEJ,GAAS,eAAe,MAAM,KAAM,CAAE,MAAK,UAG3C,UAAO,MAAM,EAAU,GAAO;AAAA,GAE1B,GACF,UAAO,MAAM,GAAW;AAAA,IAIrB,GAAM,IAAW,EAAU,CAAE,MAAO,KZ4CpC,GAAM,IAAqB,EAAK,IAAM,CAC3C,GAAwB,IAAM,MAC9B,GAAS,IAAM,MACf,GAAQ,IAAM,QAoBT,QAAc,CAUnB,YAAqB,EAAsB,CAAtB,YAPb,cAAW,GACF,YAAS,GAAI,IACrB,UAAO,GAAI,IAEH,qBAA+C,GAC/C,mBAAgB,GAAI,KAoG5B,WAAQ,EAAoB,SAAY,CAC/C,KAAK,OAAO,KAAK,WACjB,GAAM,GAAc,IAAM,CAAC,KAAK,UAAY,CAAC,IAE7C,GAAI,CAIA,EAAY,GAAO,YAAc,KAAK,MAAO,GAAW,CACtD,KAAM,IAAI,IAAa,CAAE,MAAO,GAAM,cAExC,EAAY,GAAO,YAAc,KAAK,MAAO,GAAW,CACtD,EAAM,IAAM,CACV,KAAM,IAAI,IAAa,CAAE,aACxB,EAAI,KAKX,CAGE,GAAM,GACJ,KAAa,MAAK,OAAS,GAAa,KAAO,GAAK,IAAI,KAAK,QAEzD,EAAY,WAClB,GAAI,CACF,EAAK,MAAQ,OACb,GA2BJ,GAtBA,KAAM,MACF,MACF,KAAM,MAKR,KAAM,MAAK,qBAGX,KAAK,aAED,MACF,MAAM,MAAK,6BACX,KAAM,MAAK,+BAGb,KACA,GAAgB,IAChB,KAAM,MAAK,gBAGP,IAAe,CACjB,GAAM,GAAI,GAAQ,WAClB,GAAI,GAAK,MAAQ,CAAC,KAChB,KAAM,IAAI,OACR,sCAAwC,IAG5C,AAAI,GAAK,MACP,KAAM,GAAE,MAMZ,AAAK,KAEL,GAAM,GAAS,CAAC,IAChB,KAAK,OAAO,MAAM,cAAe,CAAE,WAEnC,AAAI,EACG,KAAK,OAAO,SAEZ,KAAK,OAAO,gBAEZ,EAAP,CACA,QAAQ,MAAM,GAAe,IACxB,KAAK,OAAO,OAAO,GAEnB,KAAK,KAAK,CACb,OAAQ,GACN,KAAK,KAAO,kBAAoB,GAAS,GACzC,IAEF,OAAQ,GACR,YAAa,QAgFF,mBAAgB,EAAK,IAAM,CAC1C,GAAM,GAAK,WAAE,MAAM,KAAK,GAAI,KAC5B,SAAG,GAAG,OAAQ,GAAQ,KAAK,OAAO,EAAI,KAC/B,IA5QP,GAAgB,KAAK,KAAO,KAAK,KAAK,MACtC,KACA,EAAS,OAAO,YAAY,IAAM,MAC9B,EAAS,SAAS,gBACpB,GAAQ,WAEV,KAAK,OAAS,EAAS,WAAa,KAAK,KAAO,KAEhD,KAAK,0BAKA,KAAK,KAAK,KAAK,yBAA0B,IAAM,KAAK,uBAGrD,iBAAiB,CACrB,CACE,GAAM,GAAQ,KAAM,IAClB,KAAK,QAAQ,KAAK,IAAM,IACxB,EAAS,eAAe,gBAE1B,GAAI,EAAO,GAAQ,OAErB,GAAM,GAAa,GAAc,MAAsB,YAEvD,GAAI,GAAc,KAAM,CAEtB,GAAM,GAAY,EAAa,GACzB,EAAqB,EAAa,MAAK,MAAQ,IACrD,AAAI,EAAqB,GACvB,KAAK,OAAO,KACV,yGACE,GAAM,GACR,CACE,aACA,YACA,eAAgB,EAAS,eAAe,iBAK9C,GAAM,GAAQ,KAAM,IAClB,KAAK,QAAQ,KAAK,IAAM,IACxB,GAEF,GAAI,EAAO,GAAQ,OAGrB,MAAO,MAAK,KAAK,CACf,OACE,yBACA,GAAM,KAAK,MAAQ,IACnB;AAAA,mEACF,OAAQ,GACR,YAAa,QAIb,QAAuB,CACzB,MAAO,MAAK,OAAO,WAGjB,UAAmB,CACrB,MAAO,MAAK,OAAO,YAGjB,UAAU,CACZ,MAAO,MAAK,SAGd,QAAQ,EAA4B,CAClC,KAAK,gBAAgB,KAAK,GAGpB,YAAa,CACnB,KAAK,OAAO,KAAK,UAAW,GAC1B,WACA,SACA,KAAM,WAAE,KACR,KAAM,WAAE,KACR,SAAU,WAAE,SACZ,SAAU,KACV,YACA,cACA,SAAU,WAAE,SACZ,SAAU,CACR,SAAU,EAAS,SAAS,eAC5B,SAAU,EAAS,SAAS,eAC5B,QAAS,EAAS,QAAQ,eAC1B,YAAa,EAAS,YAAY,iBAEjC,YAkGO,6BAA6B,CAEzC,AAAI,KAAa,KAAM,OACrB,KAAM,WAII,8BAA8B,CAC1C,AAAI,MAAwB,KAAa,KAAM,OAC7C,KAAM,WAII,qBAAqB,CAiCjC,GAhCA,GAAa,GAAG,QAAS,CAAC,CAAE,UAAS,WACnC,KAAK,KAAK,CACR,OAAQ,EAAU,EAAI,EAAO,GAAM,KAAO,GAAS,IACnD,OAAQ,GACR,YAAa,MAKjB,KAAK,gBAAgB,qBAAsB,IAAM,MAEjD,WAAE,GAAG,qBAAsB,GACzB,EAAI,EAAK,GAAM,EAAQ,qBAAsB,KAE/C,WAAE,GAAG,oBAAqB,GACxB,EAAI,EAAK,GAAM,EAAQ,oBAAqB,KAG9C,WAAE,GAAG,SAAU,IACb,KAAK,KAAK,CAAE,OAAQ,SAAU,OAAQ,EAAG,YAAa,MAExD,WAAE,GAAG,UAAW,IACd,KAAK,KAAK,CAAE,OAAQ,UAAW,OAAQ,EAAG,YAAa,MAGzD,WAAE,GAAG,UAAW,IAAI,IAAc,KAAK,OAAO,MAAM,mBAAoB,IAIxE,WAAE,GAAG,aAAc,IACjB,KAAK,KAAK,CAAE,OAAQ,aAAc,OAAQ,EAAG,YAAa,MAExD,MAAe,MAAmB,KACpC,KAAK,OAAO,KACV,2GAEG,CACL,GAAM,GAAc,GACpB,WAAE,MAAM,GAAG,QAAS,IAClB,KAAK,KAAK,CAAE,OAAQ,cAAe,OAAQ,EAAG,iBAGhD,WAAE,MAAM,GAAG,QAAS,GAAO,KAAK,OAAO,KAAK,gBAAkB,IAC9D,WAAE,MAAM,GAAG,aAAc,IACvB,KAAK,KAAK,CAAE,OAAQ,mBAAoB,OAAQ,EAAG,iBAErD,WAAE,OAAO,GAAG,aAAc,IACxB,KAAK,KAAK,CAAE,OAAQ,oBAAqB,OAAQ,EAAG,iBAEtD,WAAE,OAAO,GAAG,QAAS,GAAO,KAAK,OAAO,KAAK,iBAAmB,IAChE,WAAE,OAAO,GAAG,aAAc,IACxB,KAAK,KAAK,CAAE,OAAQ,oBAAqB,OAAQ,EAAG,iBAEtD,WAAE,OAAO,GAAG,QAAS,GAAO,KAAK,OAAO,KAAK,iBAAmB,IAGlE,KAAM,IAAc,WAWhB,MAAK,CACT,SACA,SACA,eAKC,CA+BD,GA3BA,KAAK,SAAW,GAChB,KAAK,OAAO,KAAK,SAAU,CACzB,SACA,SACA,cACA,OAAQ,MAGN,GAEF,MAAM,IAAM,KACZ,KAAM,IACJ,IACE,MAAK,OAAO,KAAK,mDAAoD,CACnE,aAAc,KAAK,KAAK,iBAEnB,KAAK,KAAK,SAEnB,CACE,UAAW,OACX,cAAe,IAInB,KAAK,OAAO,KAAK,oCAGf,IAAW,EAAG,CAChB,KAAM,SAAQ,IAAI,KAAK,gBAAgB,IAAI,GAAK,EAAE,KAClD,GAAM,GAAY,CAChB,MAAO,GACP,KAAM,GACN,SACA,IAAK,WAAE,IACP,KAAM,WAAE,MAEV,EAAI,MAAW,EACf,GAAI,IAAM,GAAY,EAAK,KAE7B,YAAM,MAGC,WAAE,KAAK,GAGhB,gBAAgB,EAAiB,EAA2B,CAC1D,KAAK,cAAc,IAAI,EAAQ,OAAO,cAAe,GAG/C,yBAA0B,CAChC,KAAK,gBAAgB,YAAa,SAAY,CAC5C,GAAY,CAAE,eAEhB,KAAK,gBAAgB,WAAY,SAAY,CAC3C,GAAM,GAAK,KAAM,MACjB,YAAK,OAAO,MAAM,WAAY,GACvB,GAAY,CAAE,aAAc,MAMnC,KAAK,gBAAgB,SAAU,IAE7B,EAAM,IACJ,KAAK,KAAK,CACR,OAAQ,oBACR,OAAQ,EACR,YAAa,OAInB,KAAK,gBAAgB,GAAyB,IAE5C,EAAM,IACJ,KAAK,KAAK,CACR,OAAQ,GAA0B,cAClC,OAAQ,EACR,YAAa,OAKrB,KAAK,gBAAgB,UAAW,IAC9B,MACO,GAAY,CAAE,OAAQ,MAAc,MAE7C,KAAK,gBAAgB,WAAY,IAC/B,MACO,GAAY,CAAE,OAAQ,MAAc,MAKvC,OAAO,EAAc,CAC3B,YAAK,OAAO,MAAM,WAAY,CAAE,OAAM,OAAQ,KAAK,UAAY,MACxD,KAAK,KAAK,OAAO,kBAAoB,EAAO,IAAK,SAAY,CAElE,GADA,KAAM,MAAK,QACP,EAAK,OAAO,WAAW,MAAO,CAChC,GAAM,GAAM,EAAK,MAAM,IAAK,GAAG,GACzB,EAAI,KAAK,cAAc,IAAI,GACjC,AAAI,GAAK,KACP,MAAK,OAAO,MAAM,4BAA6B,CAAE,SACjD,QAAQ,KAAK,mBAAqB,IAElC,KAAM,GAAE,EAAK,OAAO,EAAI,QAAQ,YAGlC,IAAI,CACF,KAAM,GAAI,KAAK,KAAK,cAAe,GAAK,EAAE,UACnC,EAAP,CACA,KAAK,OAAO,MAAM,8BAA+B,CAAE,OAAM,ealfnE,OAAqB,4BCgBd,YAAuB,EAAoC,CAChE,MAAO,IAAO,MAAQ,EAAS,EAAI,OAAS,EAAS,EAAI,OAGpD,YAAyB,EAAsC,CACpE,MACE,IAAO,MACP,CAAC,GAAc,IACf,EAAS,EAAI,OACb,EAAI,EAAI,UACR,EAAI,EAAI,aDfL,oBAAmC,QAAmB,CAG3D,YAAqB,EAAoB,CACvC,MAAM,EAAU,CAAE,KAAM,IAAe,GAAS,KAAK,MAAM,IADxC,kBAEnB,KAAK,KAAO,cAAc,KAG5B,UAAW,CACT,MAAO,MAAK,KAMN,MAAM,EAA6B,CACzC,OAAW,KAAQ,GAAc,EAAI,GAAO,MAAM;AAAA,IAAO,UAAW,CAClE,GAAM,GAAM,KAAK,MAAM,GACvB,GAAI,GAAc,IAAQ,GAAgB,GAAM,MAAO,GAEzD,MAAO,CACL,KAAM,KAAK,WACX,MAAO,8CEjCb,OAAqB,4BCwBd,YAA6B,EAAoC,CACtE,MAAO,IAAO,MAAQ,EAAI,EAAI,KAAO,EAAS,EAAI,OAG7C,YAA+B,EAAsC,CAC1E,MAAO,CAAC,GAAoB,IAAQ,GAAO,MAAQ,EAAI,EAAI,IDGtD,oBAAyB,QAAmB,CAIjD,YAAqB,EAAoB,CACvC,MAAM,EAAU,GAAM,GAAS,KAAK,MAAM,IADvB,WAEnB,KAAK,KAAO,cAAc,EAAU,MACpC,KAAK,GAAK,GACR,EAAI,cACJ,EAAI,kBACJ,EAAI,sBAIR,UAAW,CACT,MAAO,MAAK,KAGN,MAAM,EAA6B,CACzC,OAAW,KAAQ,GAAc,EAAI,GAAO,MAAM;AAAA,IAAO,UAAW,CAClE,GAAM,GAAM,GAAW,GACvB,GAAI,GAAoB,IAAQ,GAAsB,GAAM,MAAO,GAErE,MAAO,CACL,GAAI,KAAK,GACT,MAAO,6CAA+C,KE/CrD,YAAU,CAAV,aAVP,CAWmB,iBAAc,GAAI,IAAQ,IAC1B,YAAS,EAAS,OAEnC,KAAK,EAAmB,CACtB,GAAO,EAAI,GAAM,KAAK,YAAY,KAAK,IAGzC,OAAQ,CACN,KAAK,YAAY,QAGnB,KAAM,CACJ,MAAO,IACL,EAAQ,CAAC,KAAK,YAAY,kBAAmB,KAAK,YAAY,cAIlE,YAAY,EAAQ,EAAkB,CACpC,MAAO,IAAO,KAAK,MAAO,GAAM,CAC9B,GAAM,GAAM,EAAK,EACjB,GAAI,EAAM,EACR,MAAO,6BAET,GAEE,EAAM,IAGN,GAAG,KAAK,YAAY,aAAc,EAAK,GAEvC,MACE,SACA,GAAY,EAAK,EAAG,CAAE,OAAQ,UAAW,SAAU,WAGrD,KAAK,OAAO,MACV,uDACA,GACE,IAAK,GACF,KAAK,YAAY,cChDzB,GAAM,KAAe,GAAQ,aAAc,SAAU,QA8CrD,GAAM,IAAgB,gBCzBtB,oBAAuC,GAA+B,CAO3E,YAAqB,EAA0B,CAC7C,MAAM,qBAAsB,IAAM,KAAM,EAAa,OADlC,qBANZ,WAAQ,KAAK,MACL,UAAO,GAAI,IACnB,WAAQ,GAAI,IAsBZ,eAAY,EACnB,IACE,GAAW,KAAK,cAAe,IAC7B,GAAS,UAAU,GAAe,eAnBtC,AAAK,KAAK,MAAM,eACd,GAAU,UACR,CAAE,KAAM,iBAAkB,MAAO,GAAS,GAAI,QAAS,GACvD,IAAM,KAAK,SAKjB,MAAO,CACL,MAAO,CAAC,KAAK,MAAM,QAGrB,aAAc,CACZ,MAAO,MAAK,MAAM,aAWd,WAAW,CACf,GAAI,KAAK,OACP,MAAQ,MAAM,MAAK,aAAa,eAAe,CAC7C,MAAO,OACP,IAAK,6CACL,IAAK,GACL,YAAa,IACb,cAAe,EACf,YAAa,IAIjB,GAAI,AADQ,KAAK,OACN,MAAQ,KAAK,WAAa,MAAQ,KAAK,WAAa,KAAM,OAErE,GAAM,GAAI,KAAM,MAAK,YAEf,EAAW,KAAK,UAAa,MAAK,UAAY,KAAK,WACnD,EAAc,GAAQ,IAAM,EAAU,GACtC,EAAM,KAAK,KAAK,cAChB,EACJ,UAAU,GAAS,0BACnB,GAAc,EAAK,GAAM,KAAO,EAAI,UACtC,MAAO,GAAE,eAAe,CACtB,MAAO,aACP,MACA,IAAK,CACH,UAAU,GAAI,KAAK,oBAAoB,GAAI,KAAK,sBAElD,cACA,cAAe,IAAM,EACrB,YAAa,IAIjB,KAAM,CACJ,GACE,KAAK,WAAa,MAClB,KAAK,WAAa,MAClB,KAAK,YAAc,EAEnB,OAGF,GAAM,GAAc,AADF,AADA,MAAK,MAAQ,KAAK,OACN,KAAK,UACH,KAAK,UACrC,YAAK,KAAK,KAAK,GACR,KAAK,KAAK,WAGL,OAAO,CACnB,YAAK,UAAY,KAAM,IAAU,IAAI,YAAoB,GACvD,GAAoB,EAAE,cAAc,kBAEtC,KAAK,UAAY,EACV,GAAU,IAAI,QAIlB,CACD,UAAW,KAAM,IAAO,CACtB,OAAW,KAAW,IAAQ,EAAK,GAAM,EAAG,SAAS,SAAU,CAC7D,GAAI,IAAU,OACd,KAAM,IACJ,EAAQ,GAAG,QACX,EAAQ,IAAI,GAAM,EAAG,MAEvB,KAAK,WAAc,EAAQ,OAC3B,KAAK,WAAc,EAAQ,OAE7B,KAAM,IAAM,IAEd,GAAI,CAAC,EAAI,IACP,GAAK,GACH,EAAG,OAAO,CACR,QAAS,oBACT,YAAa,eACb,IAAK,mBAGL,EAAW,IACb,GAAK,EAAG,SACN,eACA,IACA,GAAI,EAAO,IAAI,GAAM,EAAG,gBAGrB,OAMf,YAA6B,EAAuB,CAClD,MAAO,GACJ,KAAK,aACL,KAAK,QAAS,WAAY,qBAC1B,MAAM,cAAe,GACrB,SAAS,iBAAkB,GAC3B,SAAS,eAAgB,GCzJ9B,OAA6B,qBCItB,oBAAyB,GAAiB,GAC/B,AADX,GACW,OAAiB,QACjB,AAFX,GAEW,GAAK,GCHhB,oBAAwB,GAAW,GACjC,AADF,GACE,UAAuB,YACd,AAFX,GAEW,iBAAmB,mBCO9B,YAAuC,EAAa,CACzD,MAAO,oBAAoB,MAAoB,IAG1C,YAAuC,EAAmB,CAC/D,MAAO,IAAY,EAAW,GAA8B,KAEvD,YAAmC,EAAa,CACrD,MAAO,gBAAgB,MAAgB,IAMlC,oBAAoB,GAAW,OAM7B,oBAAmB,EAAsB,CAC9C,MAAO,IACL,GAAU,IAAI,YAAY,GACxB,EACG,cAAc,gBACd,KAAK,QAAS,WAAY,qBAC1B,QAAQ,aAAc,IAE3B,IAAM,GAIV,WAAY,CACV,MAAO,IAAU,IAAI,YAAY,GAC/B,EAAE,MAAM,CAAE,QAAS,KAAK,KAAO,cAI7B,wBAAuB,EAAsC,CACjE,KAAM,IAAU,MAAM,OACpB,EAAU,IAAI,GAAO,GAAE,QAAS,KAAK,IAAQ,IAC7C,IAIJ,gBAAgB,EAA6C,CAC3D,GAAM,GAAM,EAAU,IAAI,GAAO,GAAE,QAAS,KAAK,IAAQ,IACzD,YAAK,SAAS,KAAK,wBAA0B,KAAK,KAAM,GACjD,GAAU,MAAM,OAAO,KAjCzB,AADF,GACE,UAAuB,QACd,AAFX,GAEW,iBAAmB,OHM9B,oBAAwB,GAAgD,CAiB7E,YACW,EACQ,EACA,EACA,EAAkB,GAClB,EACjB,CACA,MACE,aAAa,EAAW,OAAO,KAAK,QACpC,IAAM,GAAmB,KAAK,MAC9B,EAAa,OATN,kBACQ,oBACA,oBACA,uBACA,+BArBV,iBAAc,GAAI,IAAK,EAAI,GAC3B,QAAK,GAAI,iBAEV,mBAAgB,GACP,eAAY,GAAI,IAGhB,eAAY,GAAI,IAExB,uBAAoB,GAAI,IAAiB,GAAK,GAsC9C,YAAS,EAAK,IACrB,GAAM,MAAM,OAAO,KAAK,WAAW,IAAI,GAAS,EAAE,YAG3C,cAAW,EAAK,IACvB,KAAK,SAAS,KAAK,GAAO,EAAI,IAAI,GAAM,EAAG,MA8EpC,sBAAmB,EAAK,SAAY,CAC3C,GAAM,GAAW,KAAM,MAAK,WACtB,EAAU,KAAM,IAAU,IAAI,YAAY,GAC9C,EAAG,QAAQ,UAAW,GAAU,SAElC,YAAK,cAAgB,IAAW,EACzB,GACN,GA7GD,KAAK,cAAgB,KAAK,gBAAkB,EAAI,KAEhD,KAAK,SAGP,GAAG,EAAoB,EAAmC,CACxD,KAAK,GAAG,YAAY,EAAO,GAG7B,QAAS,CACP,UAAgB,MACT,KAGT,OAAQ,CACN,UAAmB,KAAK,MACjB,UAWH,cAAc,CAClB,KAAM,IACJ,SACE,MAAM,MAAK,iBAAiB,UACrB,KAAK,QAEd,CAAE,UAAW,OAAW,cAAe,EAAI,IAI/C,MAAO,CACL,MACE,MAAK,OACJ,KAAK,eAAiB,KAAK,UAAU,SAAW,KAAK,UAAU,WAIhE,WAAW,CACb,MACE,CAAC,MACD,CAAC,KACD,CAAC,KAAK,QACN,CAAC,KAAK,OACN,CAAC,KAAK,eACN,KAAK,mBAAqB,KAAK,mBAI7B,aAAY,EAAmB,EAAoB,CACvD,GAAI,EAAW,GAAQ,CACrB,GAAM,GAAM,KAAM,MAAK,SAKvB,KAAM,AAJI,GACR,EAAI,EAAW,GAAQ,EAAI,KAAK,GAAM,EAAG,OAAS,IAClD,EAAI,IAEE,uBAAuB,GAC/B,KAAK,OAAO,MAAM,gBAAiB,CAAE,UAEvC,KAAK,cAAgB,GACrB,KAAK,iBAAiB,QACtB,EAAM,IAAM,WAGR,SAAQ,EAAiB,CAC7B,KAAM,GAAK,SAEX,KAAK,iBAAiB,QACtB,KAAK,cAAgB,MAGnB,qBAAoC,CACtC,MAAO,GAAI,KAAK,kBAAkB,eAAgB,GAAM,aAAe,GAGzE,mBAAoB,CAClB,MAAO,MAAK,UAAU,eAGxB,WAAY,CACV,MAAO,MAAK,YAAY,gBAGpB,YAAY,CAChB,MAAO,MAAK,UAAU,aAAgB,KAAM,MAAK,mBAGnD,kBAAmB,CAGjB,MAAO,MAAK,gBACR,KAAK,UAAU,aAEf,KAAK,IAAI,KAAK,UAAU,aAAc,KAAK,gCAY3C,WAAW,CACf,GAAM,GAAO,KAAK,YACZ,EAAO,KAAM,MAAK,YAElB,EAAc,GAAQ,IAAO,GAAQ,GAAO,IAAQ,GAC1D,MAAO,CAAE,OAAM,OAAM,cAAa,cAAe,IAAM,GAGjD,qBAAsB,CAC5B,MAAO,MAAK,oBAAoB,IAAI,GAAM,EAAG,SAGzC,SAAS,CACb,MAAO,MAAK,YAGR,MAAK,EAAQ,KAAK,cAAgB,EAAG,EAAiB,CAC1D,GAAM,GAAW,KAAM,MAAK,WACxB,EAAI,GAAU,QACf,QAAQ,UAAW,GACnB,WAAW,KAAM,KAAK,uBACtB,MAAM,GACT,MAAI,IACF,GAAI,EAAE,WAAW,GAAkB,KAAY,KAAM,OAEhD,GAAU,MAAM,IAAI,QAGf,OAAO,CACnB,MAAO,AAAC,MAAK,SAET,KAAK,UAAU,SAAS,KAAK,KAAO,UAAW,IAAM,KAAK,SAD1D,YAKQ,OAAM,EAAS,GAAO,CAClC,GAAI,CAAC,KAAK,SAAU,OACpB,GAAM,GAAQ,KAAM,MAAK,KAAK,KAAK,cAAgB,EAAG,GAEtD,GAAI,EAAM,SAAW,EAAG,CACtB,KAAK,OAAO,KAAK,qCACjB,KAAK,cAAgB,GACrB,OAGF,GAAI,GAAqB,KAAK,cAAgB,KAAK,mBAOnD,IANA,KAAK,OAAO,MAAM,UAAW,CAC3B,SACA,qBACA,kBAAmB,EAAM,SAIzB,CAAC,MACD,CAAC,KACD,CAAC,KAAK,OACN,EAAqB,GACrB,EAAW,IACX,CACA,GAAM,GAAO,EAAM,QACnB,GAAI,KAAM,MAAK,aAAa,GAAO,CACjC,KAAK,cAAgB,GACrB,IACA,GAAM,GAAO,EAAQ,CACnB,KAAO,KAAK,YAAY,KAAO,WAC/B,EAAK,OACJ,KAAK,KACR,KAAK,OAAO,KAAK,YAAc,EAAK,SAAU,CAAE,uBAC3C,KAAK,UAAU,KAAK,EAAM,SAAY,CACzC,GAAI,CACF,KAAK,YAAY,UACjB,KAAM,IACJ,EACA,IAAM,KAAK,aAAa,GACxB,CAAC,EAAS,IACR,KAAK,OAAO,KAAK,sBAAuB,GAAE,WAAY,KAE1D,KAAK,GAAG,KAAK,YAAa,SACnB,EAAP,CACA,KAAK,OAAO,KAAK,oBAAqB,UACtC,CACA,KAAM,MAAK,QAAQ,GACnB,EAAM,GAAU,OAKxB,AAAI,CAAC,GAAU,EAAqB,GAElC,KAAM,MAAK,MAAM,MIhPvB,YAAuB,EAAU,EAAe,CAC9C,MAAO,GAAE,uBAAuB,EAAI,IAAI,GAAO,EAAE,SAAU,EAAI,OAGjE,mBAA2D,CAIzD,MAAO,CAAC,GAHK,KAAM,IAAY,KAAW,KAAM,IAC9C,GAAe,EAAI,WAAY,IAEhB,IAAgB,IAAI,GAGvC,mBAAmE,CACjE,MAAO,IAAY,KAAmB,IAGxC,kBAA6C,EAAa,CACxD,GAAM,GAAM,EAAS,iCAAmC,EAAM,KAExD,EAAQ,KAAM,IAAM,MAAM,UAAU,CACxC,KAAM,GAA8B,KAGtC,KAAM,IAAU,UACd,CACE,KAAM,GAAe,wBACrB,QAAS,GACT,MAAO,GAET,IACE,GAAI,KAAK,WAAY,CAAE,MAAO,EAAM,OAC7B,GAAU,IAAI,aAAa,CAChC,UAAW,KAAO,IAAkB,GAAc,EAAO,GACzD,GAAI,CAAC,EAAuB,IAC1B,GAAK,EACF,OAAO,MACP,QAAQ,KAAM,OACd,MAAM,UAAW,IAAK,IACtB,SAAS,MAAO,OAAQ,EAAM,KAC7B,EAAW,IACb,GAAK,EAAG,SAAS,KAAM,IAAK,GAAI,KAE3B,OAMf,GAAM,GAAiB,KAAM,GAAM,YACnC,SAAI,KAAK,6BAA8B,CACrC,MAAO,EAAM,KACb,mBAGK,EAAiB,EAAI,EAAM,KAAO,OAG3C,mBAA2C,CACzC,GAAM,GAAO,KAAM,MACnB,MAAO,IAAM,IAAI,YAAoB,GACnC,EACG,MAAM,YACN,WACA,SAAS,YAAa,oBAAqB,YAC3C,MAAM,gBAAiB,IAAK,IAC5B,SAAS,GACR,EAAK,QAAQ,GAAO,EAAG,MAAM,gBAAiB,OAAQ,EAAM,QAKpE,mBAA4C,CAC1C,MAAO,IAAY,KAAmB,IAGxC,kBAAgD,EAAa,CAC3D,GAAM,GAAM,EAAS,6BAA+B,EAAM,KACpD,EAAQ,KAAM,IAAM,MAAM,UAAU,CACxC,KAAM,GAA0B,KAGlC,KAAM,IAAU,UACd,CACE,KAAM,GAAe,oBACrB,QAAS,GACT,MAAO,GAET,IACE,GAAI,KAAK,WAAY,CAAE,UAChB,GAAM,IAAI,aAAa,CAC5B,UAAW,GAAO,GAAc,EAAO,GACvC,GAAI,CAAC,EAAuB,IAC1B,GAAK,EACF,OAAO,YACP,WACA,SAAS,YAAa,oBAAqB,YAC3C,QAAQ,WAAY,OACpB,MAAM,gBAAiB,IAAK,IAC5B,SAAS,gBAAiB,OAAQ,EAAM,KACvC,EAAW,IACb,GAAK,EAAG,SAAS,WAAY,IAAK,GAAI,KAEjC,OAKf,GAAM,GAAa,KAAM,GAAM,YAC/B,SAAI,KAAK,yBAA0B,CACjC,MAAO,EAAM,KACb,eAGK,EAAa,EAAI,EAAM,KAAO,OC7HhC,oBAAmC,GAAU,CAoBlD,YACE,EACS,EACT,EACA,CACA,MACE,EACA,IAAM,GACN,GAAM,KAAK,YAAY,GACvB,GACA,GARO,wBAUT,AAAK,KAAK,cAAc,KAAK,IAAM,KAAK,mBA/B7B,KACX,EACA,EACoC,CAEpC,YAAM,MACC,EAAS,qBAAqB,eACjC,OACA,EACE,KACA,GACE,GAAI,IACF,EACA,EACA,SAoBE,aAAY,EAAe,CACvC,GAAM,GAAS,KAAM,MAAK,iBAAiB,EAAM,EAAG,WACpD,EAAI,GAAQ,WAAY,GAAM,KAAK,kBAAkB,KAAK,MC1CvD,GAAM,IAAwB,eAE9B,gBAAgC,GAAU,CAC/C,YACW,EAIT,EACA,CACA,MACE,CAAC,IACD,IAAM,GACN,GAAM,KAAK,YAAY,GACvB,GACA,GAXO,gCAeG,aAAY,EAAe,CACvC,GAAM,GAAU,EAAM,EAAG,UACzB,KAAK,OAAO,KAAK,cAAe,CAAE,UAAS,OAC3C,GAAM,GAAS,KAAM,MAAK,oBAAoB,EAAU,IACxD,EAAI,GAAQ,KAAM,GAAM,KAAK,kBAAkB,KAAK,MClBjD,oBAA+B,GAAU,CAkBtC,YACN,EACS,EACT,EACA,CACA,MACE,EACA,IAAM,GACN,GAAM,KAAK,YAAY,GACvB,GACA,GARO,oBAeT,AAAK,KAAK,cAAc,KAAK,IAAM,KAAK,mBAlC7B,KACX,EACA,EACgC,CAChC,MAAO,GAAS,iBAAiB,eAC7B,OACA,EACE,KACA,GACE,GAAI,IACF,EACA,EACA,SAyBE,aAAY,EAAe,CACvC,GAAM,GAAS,KAAM,MAAK,aAAa,EAAM,EAAG,WAChD,EAAI,GAAQ,WAAY,GAAM,KAAK,kBAAkB,KAAK,MCdvD,oBAA6B,GAA+B,CAUjE,YACW,EAMT,CACA,MAAM,iBAAkB,IAAM,KAAK,QAAS,EAAa,OAPhD,YAVF,UAAO,iBACP,WAAQ,GAAI,IACZ,SAAM,GAAI,IACV,qBAAkB,GAAI,KAkBtB,eAAY,EACnB,IAAM,GAAS,UAAU,GAAe,cAIjC,sBAAmB,EAC1B,IAAM,GAAS,cAAc,MAE7B,GAkFe,yBAAsB,EAAK,IAAM,MAUjC,kBAAe,KAAO,IAAoB,CACzD,GAAM,GAAS,KAAM,MAAK,KAAK,aAAa,GAC5C,YAAK,gBAAgB,IAAI,GACzB,KAAK,OAAO,KAAK,+BAAiC,EAAU,IAAK,CAAE,WAE/D,GAAsB,IACnB,GAAO,EAAO,UACjB,KAAM,MAAK,GAAI,YAAY,CAAC,CAAE,SAAU,EAAI,MAG9C,KAAM,IAAY,GAAQ,iBAAkB,KAAM,IAAO,CAEvD,GAAM,GAAS,EAAI,OAAO,GAAM,CAAC,KAAK,gBAAgB,IAAI,IAC1D,KAAM,IAAM,IAAI,KAAK,GACnB,EAAE,QAAQ,KAAM,GAAQ,OAAO,CAAE,QAAS,KAE5C,AAAI,KAAK,IAAM,MAAQ,KAAK,GAAG,MAC7B,KAAK,OAAO,KACV,4DAGF,KAAM,MAAK,GAAG,YAAY,EAAO,IAAI,GAAO,EAAE,SAAU,EAAI,UAK3D,GAjIP,AAAK,KAAK,WAcE,MAAM,CAClB,GAAI,CAiCF,GAhCI,KAAK,OAAS,KAIlB,MAAM,IAAQ,mBAAmB,MAEjC,KAAK,IAAM,KAAM,IAAqB,IACpC,KAAK,KAAK,iBACV,KAAK,KAAK,wBAGZ,KAAK,OAAO,KAAK,8BAA+B,CAC9C,QAAS,KAAK,KAAK,KACnB,SAAU,KAAK,KAAK,MACpB,YAAa,KAAK,KAAK,SACvB,UAAW,KAAM,QAGnB,KAAM,MAAK,KAAK,cAEhB,KAAK,OAAO,KAAK,+BAAgC,CAC/C,QAAS,KAAK,KAAK,KACnB,SAAU,KAAK,KAAK,MACpB,YAAa,KAAK,KAAK,SACvB,UAAW,KAAM,QAGnB,KAAM,MAAK,KAAK,MAEhB,KAAK,IAAI,QACT,KAAM,MAAK,mBAEP,KAAK,OAAS,KAAU,OAG5B,KAAK,GAAK,GAAI,IACZ,KAAK,KAAK,oBACV,KAAK,KAAK,wBAGZ,KAAK,GAAK,KAAM,IAAiB,IAC/B,KAAK,aACL,KAAK,KAAK,wBAGZ,KAAK,OAAO,KAAK,yBAA0B,CACzC,OAAQ,KAAK,IAAI,KACjB,QAAS,KAAK,IAAI,MAClB,WAAY,KAAK,IAAI,SACrB,UAAW,KAAM,QAGnB,KAAM,MAAK,IAAI,cACf,KAAM,MAAK,mBAEX,KAAM,MAAK,IAAI,MAGf,KAAM,MAAK,IAAI,cACf,KAAM,MAAK,IAAI,MAGf,KAAM,MAAK,iBAAiB,UAE5B,KAAK,OAAO,KAAK,mBAEZ,KAAK,OAEH,MAAK,MAAM,UAChB,KAAM,IAAS,cAAc,aAExB,EAAP,CACA,EAAQ,8BAA+B,GAClC,KAAK,MAAM,OAAO,IAM3B,oBAAqB,CACnB,MAAO,GACL,KAAK,GACL,GAAM,EAAG,mBACT,IAAM,KAAK,4BAiCD,QAAQ,CAEpB,KAAM,IAAO,KAAK,IAAK,KAAK,GAAI,KAAK,IACrC,KAAK,IAAM,KAAK,GAAK,KAAK,GAAK,OAGjC,QAAS,CACP,MACE,CAAC,EAAI,KAAK,KAAK,cACf,CAAC,EAAI,KAAK,IAAI,cACd,CAAC,EAAI,KAAK,IAAI,aAIlB,MAAO,CACL,MAAO,CAAC,KAAK,MAAM,QAGrB,aAAc,CACZ,MAAO,MAAK,MAAM,aAGd,WAAW,CAGf,GAAI,KAAK,OAAS,KAAK,SAAU,OACjC,GAAM,GAAI,KAAM,MAAK,YAErB,GAAI,KAAK,OACP,MAAO,CACL,EAAE,eAAe,CACf,MAAO,OACP,IAAK,6CACL,IAAK,GACL,YAAa,IACb,cAAe,EACf,YAAa,KAInB,GAAM,GAAc,EAEd,EAAM,KAAK,IACjB,GAAI,GAAO,MAAQ,CAAC,EAAI,OAAQ,CAC9B,GAAM,GAAiB,KAAM,GAAI,YACjC,KAAM,IAAO,EAAI,YAAY,WAAY,KAAM,IAAc,CAC3D,KAAK,IAAI,KACL,MAAM,MAAK,qBAAwB,GAAkB,KAG3D,GAAM,CAAE,eAAgB,KAAM,GAAI,WAC5B,EAAM,KAAK,IAAI,cACf,EACJ,0BAA4B,GAAc,EAAK,GAAM,KAAO,EAAI,UAElE,MAAO,CACL,EAAE,eAAe,CACf,MAAO,aACP,MACA,IAAK,EAAc,CACjB,EAAI,mBACJ,2BAA2B,GAAI,eAEjC,YAAa,EACb,cAAe,EACf,yBAGK,KAAK,IAAM,MAAQ,KAAK,IAAM,KAAM,CAC7C,GAAM,GAAS,KAAM,MAAK,GAAG,YAE7B,KAAK,IAAI,KAAK,EAAS,EAAO,KAAK,GAAG,YAAY,WAAY,IAE9D,GAAM,GAAO,EACP,EAAO,KAAK,GAAG,YACf,EAAW,EAAQ,GAAO,GAC1B,EAAc,GAAQ,IAAM,EAAU,GACtC,EAAM,KAAK,IAAI,cACf,EACJ,0BAA4B,GAAc,EAAK,GAAM,KAAO,EAAI,UAClE,MAAO,GAAE,eAAe,CACtB,MAAO,aACP,MACA,IAAK,EAAK,CACR,KAAK,GAAG,mBACR,KAAK,GAAG,mBACR,mCAAmC,GAAI,eAEzC,cACA,cAAe,IAAM,EACrB,mBC5QD,oBAA8B,GAAgB,CACnD,YAAqB,EAAoC,CACvD,MAAM,CACJ,KAAM,kBACN,SAAU,IACR,KAAY,KACR,OACA,EAAQ,KAAK,OAAQ,KAAM,IAAM,CAC/B,KAAM,IAAS,cAAc,GAC7B,KAAM,QAEd,WAAY,OAVK,cCDhB,oBAA0B,GAAe,CAAzC,aATP,CASO,oBACI,eAAY,GAAI,IAEzB,MAAO,CACL,MAAO,CAAC,KAAK,UAAU,QAGzB,aAAc,CACZ,MAAO,MAAK,UAAU,UCN1B,YAAa,EAAoB,CAC/B,GAAI,EAAG,cAAe,MAAO,GAC7B,GAAM,GAAQ,EAAI,GAAS,EAAG,MAC9B,MAAI,GAAM,SAAS,GAAS,OAAe,EACvC,EAAM,SAAS,GAAS,UAAkB,EAC1C,EAAM,SAAS,GAAS,OAAe,EACpC,EAGF,YAAyB,EAAgC,CAC9D,MAAO,CAAC,GAAI,GAAI,EAAE,MAMb,YAAmB,EAA2C,CAEnE,MAAO,IAAO,EAAO,GAAM,GAAgB,ICDtC,GAAM,IAAa,CAAE,KAAM,IACrB,GAAe,CAAE,KAAM,IAO7B,QAAwB,CAQ7B,YACW,EACA,EACA,EACT,CAHS,WACA,WACA,cAPM,sBAAqC,GAE9C,WAAQ,GA4DC,mBAAgB,EAAK,SAAY,CAChD,GAAI,AAAU,KAAM,IAAW,KAAK,OAAhC,GACF,KAAK,OAAO,KAAK,0BAA4B,KAAK,SAC7C,CACL,GAAM,GAAW,KAAM,MAAK,IAAI,WAC1B,EAAY,GAAU,EAAI,IAAW,OAAO,GAO5C,KAAK,IAAI,mBAAqB,MAE9B,EAAG,eACH,EAAG,WAAa,KAAK,IAAI,mBACzB,CAAC,GAAsB,KAAK,IAAI,kBAAmB,EAAG,YAEtD,MAAK,OAAO,KACV,iCAAmC,KAAK,IAAI,kBAC5C,EAAG,YAEE,IAGJ,CAAC,GAAc,IAElB,CAAC,EAAM,GAAS,GAAU,EAAW,GAAM,EAAG,eACpD,KAAK,iBAAiB,KAAK,GAAG,GAE9B,KAAM,MAAK,IAAI,YAAa,KAAM,IAAiB,OAAO,OA+D7C,eAAY,CAC3B,KAAK,aACL,KAAK,cACL,KAAK,aACL,KAAK,qBACL,KAAK,aACL,KAAK,qBACL,IAAI,GAAK,KAAO,IAED,KAAM,GAAE,KAAK,MAAM,IA3JlC,KAAK,KAAO,2BAA6B,EAAM,IAC/C,KAAK,OAAS,EAAS,KAAK,SAG1B,SAAkB,CACpB,MAAO,MAAK,QAAU,KAGxB,MAA0B,CACxB,MAAO,MAAK,QAAU,KAAO,KAAO,KAAK,OAAO,OAGlD,MAAgB,CACd,MAAO,MAAK,WASR,MAAK,EAAgC,CACzC,GAAI,KAAK,IAAI,MAAO,MAAO,IAC3B,GAAM,GAAQ,KAAK,MACb,EAAsB,KAAM,IAChC,IACE,GAAW,KAAK,UAAW,GAAM,KAAK,IAAI,MAAQ,GAAS,EAAE,IAC/D,CACE,WAAY,KAAK,IAAI,WAErB,iBAAkB,IAChB,GAAW,GAAU,IAAK,GAAmB,KAAK,IAAI,eAG5D,MAAI,IAAU,KAAa,GAC3B,MAAK,MAAQ,EAAO,OAAS,GAC7B,KAAK,OAAO,MAAM,SAAU,CAC1B,SACA,IAAK,EAAU,EACf,QAAS,KAAK,MAAQ,IAEjB,GAGD,YAAY,EAAe,CACjC,MAAO,CAAC,KAAK,OAAS,CAAC,MAAc,KAAK,MAAQ,EAG5C,aAAa,EAAe,CAClC,MAAO,MAAK,MAAQ,GAAO,KAAK,YAAY,GAAS,OAAY,QAqCrD,sBAAqB,EAAe,CAChD,KACE,KAAK,YAAY,IAChB,MAAK,eAAiB,MAAQ,EAAW,KAAK,oBAC/C,CACA,GAAI,KAAK,IAAI,MAAO,MAAO,IAC3B,GAAI,KAAK,eAAiB,KAAM,CAC9B,GAAM,GAAQ,KAAK,iBAAiB,QACpC,AAAM,KAAM,IAAmB,IAC7B,MAAK,cAAgB,GAAI,IAAkB,EAAO,KAAK,IAAK,OAIhE,GAAM,GAAW,KAAK,cACtB,GAAI,GAAY,KAAM,CAEpB,GAAM,GACJ,EAAS,mBAAmB,eAAiB,EAC7C,KAAK,IAAI,UAAU,OAAS,IACxB,EAAI,KAAM,IAAc,EAAS,KAAK,GAAQ,EAAW,IAC7D,MAAK,OAAO,KACV,0BACE,EAAS,IACT,mBACA,GAEG,KAET,AAAI,IAAK,MAAQ,EAAE,OAAS,KAC1B,MAAK,cAAgB,eAWf,sBAAqC,CACjD,MAAI,MAAK,eAAiB,MAAQ,EAAW,KAAK,kBAChD,MAAK,OAAO,KACV,qCACA,GACE,KACA,SACA,kBACA,gBACA,qBAGG,IAEP,MAAM,MAAK,IAAI,kBAAkB,KAAK,KAC/B,MCrLN,GAAM,IAAU,EAAK,IAAO,GAAU,EAAQ,IAAM,GAAM,KAM1D,gBAA8B,GAAoC,CAKvE,YACW,EACA,EACA,EACT,EACS,EAAa,EACtB,CACA,MACE,mBAAqB,EAAK,WAAa,IACvC,IAAM,CACJ,GAAmB,KAAK,OAE1B,EAAa,OAXN,YACA,mBACA,yBAEA,kBATH,WAAQ,GAAI,IAkBlB,AAAI,GAAqB,MACvB,CAAI,KAAK,KAAK,WAAW,WAAW,GAClC,KAAK,kBAAoB,EAEzB,KAAK,OAAO,MAAM,qCAItB,KAAK,SAAW,GAAI,IAAkB,EAAM,MAC5C,GAAgB,SAGd,WAAW,CACb,MAAO,CAAC,KAAK,OAAS,KAAK,UAAU,QAGvC,QAAS,CACP,MAAO,MAAK,MAGd,KAAM,CACJ,MAAO,MAAK,MAAM,cAAc,KAAK,KAAO,SAAU,IAAM,KAAK,aAGrD,OAAO,CACnB,GAAI,KAAK,OAAS,KAAK,UAAU,SAAU,OAE3C,AAAI,AADW,MAAM,MAAK,SAAS,KAAK,KAAK,MAAQ,OAC1C,MACT,MAAK,OAAO,KAAK,8BACjB,GAAmB,KAAK,MACnB,KAAK,UAAU,aCjE1B,OAAwB,mBCWxB,kBACE,EACA,EAAmB,GACnB,CACA,GAAM,GAAkE,GAExE,OAAW,KAAa,IAAQ,EAAO,KAAM,CAC3C,GAAM,GAAqD,GAC3D,OAAW,KAAQ,GACjB,EAAa,KAAK,CAAE,OAAM,IAAK,KAAM,IAAe,EAAK,cAG3D,GAAM,GAAS,KAAM,IAAU,MAAM,KAAK,GACxC,EAAE,QACA,MACA,EAAa,IAAI,GAAM,EAAG,IAAI,cAI5B,EAA2B,GAEjC,KAAM,IAAuB,CAC3B,KAAM,gBACN,OAAQ,EAAO,IAAI,GAAM,SAAY,CACnC,GAAM,GAAM,EAAa,KAAK,GAAM,EAAG,IAAI,aAAe,EAAG,KACvD,EAAK,EAAU,IAAI,EAAI,KAAK,WAAY,EAAI,MAClD,AAAI,KAAM,GAAG,YAAY,IACvB,EAAW,KAAK,CACd,KAAM,EAAI,KAAK,WACf,QAAS,EAAG,QACZ,YAAa,EAAG,SAMpB,GACF,KAAM,IAAU,MAAM,EAAW,IAAI,GAAM,EAAG,cAEhD,EAAM,KAAK,GAAG,GAGhB,GAAM,GAAa,EAAM,IAAI,GAAM,EAAG,MAEtC,MAAO,CACL,QACA,MAAO,EAAM,OAAO,GAAM,CAAC,EAAW,SAAS,EAAG,cDvBtD,YAAmB,EAAwC,CACzD,GAAM,GAAK,EAAQ,GAAS,IAC5B,MAAO,GAAG,SAAS,GAAS,OACxB,QACA,EAAG,SAAS,GAAS,UACrB,MACA,QASC,oBAA6B,GAAU,CAqCpC,YACG,EACA,EACA,EACA,EACT,EACA,CACA,MACE,CAAC,GAAe,gBAAgB,IAChC,GAAM,KAAK,YAAY,GACvB,GAAM,KAAK,YAAY,GACvB,GACA,GAXO,YACA,WACA,gBACA,2BApCH,sBAAmB,EACnB,qBAAkB,EAET,yBAAsB,GAAI,IAAQ,IAClC,yBAAsB,GAAI,IAAQ,IAClC,oBAAiB,GAAI,IAAiB,GAAK,GAC3C,qBAAkB,GAAI,IAAe,GAAK,GAKlD,eAAY,GAAI,IAChB,sBAAmB,GAAI,IAAK,EAAI,GAEjC,qBAA0B,EAoLzB,kBAAe,KAAO,IAAqC,CAClE,KAAK,OAAO,MAAM,iBAAkB,CAClC,mBAAoB,GAAQ,EAAgB,GAAM,EAAG,cAEvD,GAAM,GAAmB,GACnB,CAAE,QAAO,SAAU,KAAM,IAAK,gBAAiB,IACnD,GAAc,EAAgB,IAGhC,AADA,KAAK,OAAO,MAAM,iBAAkB,CAAE,QAAO,UACzC,GAAQ,IAKZ,KAAM,MAAK,YACT,EAAM,IAAI,GAAO,EACf,SAAU,EAAG,WACb,KAAM,GAAU,EAAG,UArKvB,KAAK,iBAAmB,AAAC,GAAmB,CAC1C,KAAK,OAAO,MAAM,qBAAsB,GACpC,KAAK,QAAQ,EAAE,OACjB,MAAK,eAAe,KAAK,GAAG,EAAE,MAAM,EAAE,SAAS,EAAE,IAAI,QAAQ,OAC7D,KAAK,gBAAkB,KAAK,QAKhC,GAAc,KAAK,kBACnB,KAAK,OAAO,KAAK,IAAM,GAA0B,KAAK,yBA5DjD,iBAAgB,EAAa,CAClC,MAAO,OAAS,cAqBL,KACX,EACA,EACA,EACA,CACA,MAAO,IAAI,IACT,EACC,KAAM,GAAK,MACZ,EACA,KAAM,MACN,MA+BA,iBAAiB,CACnB,MAAO,MAAK,mBAGV,eAAe,CACjB,MAAO,MAAK,oBAAoB,IAAI,GAAM,EAAG,aAG3C,mBAAmB,CACrB,MAAO,MAAK,aAAa,IAAI,GAAM,GAAS,IAAI,IAGlD,QAAQ,EAAoB,CAC1B,OAAW,KAAQ,MAAK,aACtB,GAAI,IAAe,EAAM,MAAO,GAElC,MAAO,MAGL,uBAA+B,CACjC,MAAO,IAAM,KAAK,aAAc,GAAQ,GAAW,eAAQ,QAGzD,0BAAkC,CACpC,MAAO,IACL,EACA,KAAK,oBACL,KAAK,oBAAsB,KAAK,yBAIhC,6BAAsC,CACxC,MAAO,MAAK,sBAAwB,KAAK,uBAGvC,iBAAyB,CAC3B,MAAO,MAAK,iBAAmB,KAAK,mBAGlC,sBAA8B,CAChC,MAAO,MAAK,oBAGV,sBAA8B,CAChC,MAAO,MAAK,mBAGV,yBAAyB,CAC3B,MAAO,MAAK,oBAAoB,OAG9B,yBAAyB,CAC3B,MAAO,MAAK,oBAAoB,SAG5B,QAAQ,CACZ,MAAO,CACL,aAAc,KAAM,MAAK,eACzB,oBAAqB,KAAK,oBAC1B,oBAAqB,KAAK,oBAC1B,uBAAwB,KAAK,uBAC7B,uBAAwB,KAAK,wBAIjC,qBAAsB,CACpB,MAAO,CACL,oBAAqB,KAAK,oBAC1B,oBAAqB,KAAK,qBAItB,UAAU,EAAoB,CAEpC,MAAO,IAAU,QAAQ,QAAQ,UAAW,QAMxC,eAAe,CACnB,MAAO,IAAU,IAAI,WACnB,KAAK,UAAU,KAAM,MAAK,YAAY,MAAM,YAI1C,qBAAqB,CACzB,MAAO,IAAU,IAAI,WACnB,KAAK,UAAU,KAAM,MAAK,YACvB,SAAS,OAAQ,KAAM,SACvB,MAAM,YAIP,oBAAoB,CACxB,MAAO,IAAU,IAAI,WACnB,KAAK,UAAU,KAAM,MAAK,YACvB,SAAS,OAAQ,IAAK,SACtB,MAAM,UAIT,qBAAoC,CACtC,MAAO,GAAO,KAAK,eAAe,QAAS,IACzC,EAAI,KAAK,kBAAkB,eAAgB,GAAM,aAAe,SAI9D,0BAAyB,EAAyB,CACtD,GAAM,GAA8B,GAC9B,EAAoE,GAC1E,KAAM,IAAuB,CAC3B,KAAM,2BACN,OAAQ,EAAW,IAAI,GAAM,SAAY,CACvC,GAAM,GAAK,KAAM,GAAG,YACpB,AAAI,GAAM,MACR,CAAI,AAAU,KAAM,GAAG,gBAAnB,GACF,EAAkB,KAAK,EAAG,IAE1B,EAAM,KAAK,CAAE,SAAU,EAAG,WAAY,KAAM,GAAU,EAAG,YAKjE,KAAM,IAAU,MAAM,GACtB,KAAM,MAAK,YAAY,GACvB,KAAK,OAAO,KAAK,6BAA8B,CAC7C,oBACA,eA6BU,aAAY,EAAe,EAAY,CACnD,KAAK,OAAO,KAAK,gBAAiB,CAAE,KAAI,QACpC,GAAiB,IAAQ,CAAC,KAAK,gBAAgB,IAAI,EAAG,WACxD,KAAM,GAAQ,GAAe,IAAI,EAAG,UAAW,GAC7C,MAAK,gBAAgB,IAAI,EAAG,UAC5B,KAAK,OAAO,KAAK,gBAAkB,GAC5B,KAAK,aAAa,CAAC,MAKxB,WAAW,EAAe,EAAmB,CACnD,KAAK,OAAO,MAAM,cAAgB,EAAG,SAAW,KAAO,EAAY,QACnE,GAAM,GAAI,GAAY,GACtB,AAAI,GAAW,EAAE,KACf,KAAK,kBAEL,KAAK,mBAGH,EAAY,GACd,CAAI,GAAW,EAAE,KACf,KAAK,oBAAoB,KAAK,GAG9B,KAAK,oBAAoB,KAAK,SAKtB,aAAY,EAAiC,CAEzD,GAAI,AADY,EAAG,OAAS,SACb,KAAK,yBAA2B,EAAG,MAAO,GAEzD,GAAM,GAAI,GAAS,IAAI,EAAG,UAC1B,MAAO,CAAC,EAAK,KAAK,iBAAiB,IAAI,KAAQ,SAAS,GAAM,SAGlD,aAAY,EAAe,CACvC,GAAM,GAAQ,KAAK,MACnB,GAAI,CACF,GAAM,GAAS,KAAM,MAAK,SAAS,EAAG,UACtC,AAAI,GAAgB,GAClB,KAAM,MAAK,WAAW,EAAI,KAAK,MAAQ,GAC9B,GAAc,IACvB,KAAM,MAAK,YAAY,EAAI,GAAQ,EAAO,cAErC,EAAP,CACA,MAAO,MAAK,YAAY,EAAI,UAC5B,CACA,KAAK,iBAAiB,UACtB,KAAK,UAAU,KAAK,KAAK,MAAQ,GACjC,KAAK,kBAAkB,KAAK,EAAG,aAjR9B,MAIW,AAJX,GAIW,UAAY,EAkR9B,YAAqB,EAA0B,CAC7C,MAAO,GAAU,IAAI,EAAG,UEvRnB,oBAA4B,GAA4B,CAqDnD,YACC,EACA,EACA,EACA,EACA,EACA,EACT,CACA,MAAM,iBAAmB,EAAO,IAAK,IAAM,KAAK,QAAS,EAAa,OAP7D,YACA,eACA,mBACA,sBACA,wBACA,8BAhBF,WAAQ,KAAK,MACd,iBAAc,GACd,oBAAiB,GACR,SAAM,GAAI,IAClB,yBAAsB,GAAI,IAAoB,IACvD,sBAAmB,EACnB,yBAAsB,EACtB,yBAAsB,EAsBL,iBAAc,AAAC,GAAkB,CAChD,AAAI,GAAW,EAAG,UAAW,KAAK,sBAC7B,KAAK,uBAIH,eAAY,EAAK,IACxB,GAAS,UAAU,KAAK,QAAS,KAAK,KAAK,aAGpC,eAAY,EAAK,SACvB,MAAM,MAAK,aAAa,mBAIlB,sBAAmB,EAC1B,IAAM,GAAS,cAAc,MAC7B,GAAS,IAAM,GAGR,8BAA2B,EAClC,SAAY,CACV,GAAM,GAAI,KAAM,MAAK,YACrB,KAAM,GAAE,QACN,GAAkB,sBAClB,KAAK,iBAAiB,YAExB,GAAM,GAAuB,KAAK,oBAAoB,KAAK,IAC3D,AAAI,GAAwB,MAC1B,KAAM,GAAE,QACN,GAAkB,qBAClB,IAIN,GAAS,GAAK,KAGP,uBAAoB,AAAC,GACrB,EAAY,GAAK,WAAY,GAClC,MAAK,mBACL,KAAK,oBAAoB,KAAK,GAC9B,KAAK,OAAO,MAAM,sBAAuB,CACvC,iBAAkB,KAAK,iBACvB,IAAK,EAAI,aAEJ,KAAK,6BAIP,uBAAoB,EAAK,SAAY,CAE5C,GAAM,GAAa,AADL,MAAM,IAAS,SACJ,KAAK,GAAM,EAAG,MAAQ,KAAK,SACpD,MAAO,GAAO,GAAY,cAAe,KAAK,SAGvC,yBAAsB,EAAK,SAAY,CAC9C,GAAI,KAAK,eAAgB,MAAO,GAChC,GAAM,GAAe,KAAM,MAAK,oBAChC,MAAO,IAAU,IAAI,YAAoB,GACvC,EACG,MAAM,MAAO,OAAQ,KAAK,QAAU,KACpC,SAAS,YAAa,IAAK,KAE/B,GAAK,GA8DS,WAAQ,EAAK,SAAY,CACxC,GAAM,GAAY,KAAM,MAAK,YACvB,EAAoB,KAAM,MAAK,oBAiCrC,GA/BA,KAAK,OAAO,KAAK,UAAW,CAC1B,YACA,sBAGF,EAAI,EAAU,qBAAsB,GAAM,KAAK,oBAAoB,KAAK,IACxE,GACE,EAAU,oBACV,GAAO,KAAK,qBAAuB,GAErC,GACE,EAAU,oBACV,GAAO,KAAK,qBAAuB,GAGrC,KAAM,MAAK,wBAEX,KAAK,OAAO,KAAK,wCACjB,KAAK,YAAc,GAEnB,KAAM,MAAK,8BAKX,KAAM,MAAK,eAAe,cAAc,MAAM,GAAO,CACnD,EAAQ,oCAAqC,KAK3C,CAAC,KAAK,MAAO,CACf,KAAM,MAAK,UAAU,UACrB,GAAM,GAAI,KAAM,MAAK,WACrB,KAAK,OAAO,KAAK,uCACjB,KAAM,GAAE,OAAO,CAAE,YAAa,KAAK,WA/KrC,KAAK,eAAe,GAAG,YAAa,KAAK,aACpC,KAAK,UAAU,QAAQ,KAAK,qBA9DtB,KAAI,CACf,OACA,MACA,cACA,mBACA,0BAO8B,CAC9B,GAAM,GAAU,KAAM,IAAW,EAAK,IAAM,EAAK,OAC3C,EAAS,KAAM,GAAK,iBAC1B,GAAI,GAAW,MAAQ,GAAU,KAAM,CACrC,EAAS,iBAAiB,KAAK,iCAAmC,EAAM,CACtE,UACA,WAEF,OAMF,GAAM,GAAiB,KAAM,IAAe,IAC1C,EACA,EACA,GAGF,MAAO,IAAI,IACT,EACA,EACA,EACA,EACA,EACA,QA2BU,QAAQ,CACpB,KAAM,IAAI,KAAK,iBACf,KAAM,IAAI,KAAK,gBACf,KAAM,MAAK,iBAAiB,eAqEhB,wBAAwB,CACpC,GAAM,GAAY,KAAM,MAAK,YAI7B,GAAI,AAAQ,EAAU,wBAAlB,KAA0C,CAC5C,KAAK,OAAO,KAAK,+CACjB,OAEF,GAAM,GAAW,KAAM,MAAK,YAC5B,KAAK,iBAAmB,EAAO,EAAM,EAAU,uBAAwB,GACvE,KAAK,gBAAkB,GAAI,IACxB,KAAM,MAAK,KAAK,iBACjB,KAAK,eAAe,aACpB,KAAK,kBACL,EAAU,sBAEZ,KAAK,OAAO,KAAK,kDAAmD,CAClE,qBAAsB,EAAU,uBAElC,KAAM,MAAK,gBAAgB,cAAc,MAAM,GAAO,CACpD,EAAQ,sCAAuC,KAEjD,KAAK,OAAO,KAAK,oDAAqD,CACpE,iBAAkB,KAAK,mBAEzB,KAAM,GAAS,QAAQ,GAAkB,uBAAwB,aAGrD,8BAA8B,CAC1C,GACE,CAAC,EAAS,UAAU,gBACpB,AAAS,MAAM,MAAK,cAAc,oBAAlC,KAEA,KAAK,OAAO,KAAK,mDACZ,CACL,GAAM,GAAW,KAAM,MAAK,YACtB,EAAoB,KAAM,MAAK,oBAErC,KAAK,OAAO,KAAK,iDAAkD,CACjE,2BAA4B,KAAM,MAAK,eAAe,iBAExD,KAAM,IAAU,MAAM,QAAQ,CAC5B,UAAW,KAAO,IAChB,KAAK,eAAe,yBAAyB,GAC/C,GAAI,AAAC,GACH,EACG,MAAM,MAAO,OAAQ,KAAK,QAAU,KACpC,SAAS,YAAa,IAAK,KAElC,KAAK,OAAO,KAAK,iDAAkD,CACjE,2BAA4B,KAAM,MAAK,eAAe,iBAExD,KAAM,GAAS,QAAQ,GAAkB,mBAAoB,QAE/D,KAAK,oBAAoB,QACzB,KAAK,eAAiB,GA+CxB,gBAAiB,CACf,MAAO,MAAK,oBAAsB,KAAK,oBAGzC,cAAe,CACb,MAAO,MAAK,eAAe,kBAGzB,aAAa,CACf,MAAO,MAAK,iBASR,sBAAuC,CAC3C,GAAI,CAAC,KAAK,WAAY,MAAO,KAQ7B,GAAM,GAAW,IAAM,CAAE,MAAK,iBAAmB,IAAM,GAAK,IAE5D,MAAO,IAAQ,EAAU,QAGrB,WAA8B,CAClC,GAAM,GAAO,KAAK,OACZ,EAAS,MAAc,IACvB,EAAQ,KAAK,OAAS,OAAS,EAAS,SAAW,aAEnD,EAAgB,GACtB,AAAI,CAAC,GAAQ,CAAC,GACZ,GAAY,KAAK,eAAe,mBAAoB,GAAM,EAAI,KAAK,IAC/D,KAAK,YACP,EAAI,KACF,YACE,GACE,KAAK,oBAAoB,eACzB,KAAK,KAAK,cAMpB,GAAM,GAAgB,GAEtB,AAAI,KAAK,oBAAsB,KAAK,oBAAsB,GACxD,EAAI,KACF,YACA,GAAK,KAAK,oBAAqB,SAC/B,MACA,GAAK,KAAK,oBAAqB,SAAW,KAI9C,GAAM,GAAe,KAAM,MAAK,eAChC,AAAI,CAAC,GAAQ,EAAe,GAC1B,EAAI,KACF,KAAK,WAAa,WAAa,GAC/B,GAAI,GACJ,0BAGJ,EAAI,KAAK,EAAc,GAAK,KAAK,MAEjC,GAAM,GAAgB,GACtB,EAAI,KAAK,GAAW,IACf,GAAM,EAAI,KAAK,IAAI,cAAe,GAAM,EAAI,KAAK,IAEtD,GAAM,GAAI,KAAM,MAAK,YAErB,MAAI,MAAK,oBAAsB,GAC7B,KAAM,GAAE,QACN,GAAkB,oBAClB,OAAO,KAAK,sBAGZ,KAAK,oBAAsB,GAC7B,KAAM,GAAE,QACN,GAAkB,oBAClB,OAAO,KAAK,sBAIT,KAAK,OAAO,IAAI,CACrB,IAAK,cACL,OAAQ,EAAE,eAAe,GACvB,QACA,IAAK,EAAI,KAAK,MACd,OACI,KAAM,MAAK,oBAKf,WAA8B,CAClC,GAAI,KAAK,OACP,MAAO,CACL,YAAa,IACb,cAAe,EACf,YAAa,GAKjB,GAAM,GAAa,KAAM,MAAK,sBAGxB,EAAc,IAAM,EAEpB,EAAY,KAAM,MAAK,iBACvB,EAAU,KAAM,MAAK,eACrB,EACJ,IAAY,GAAK,IAAc,EAC3B,EACA,GAAQ,EAAc,GAAa,GAAU,IAAa,GAC1D,EAAgB,IAAO,GAAc,GACrC,EAAI,CAAE,cAAa,gBAAe,eAcxC,GAbA,KAAK,OAAO,MAAM,eAAgB,CAAE,aAAY,YAAW,UAAS,MAEhE,GAAI,CAAC,EAAE,YAAa,EAAE,cAAe,EAAE,gBAAkB,KAC3D,KAAK,OAAO,KAAK,qBAAsB,CACrC,IACA,YACA,UACA,aACA,cACA,gBACA,gBAGA,IAAe,KAAO,EAAY,EAAG,CACvC,GAAM,GAAM,KAAK,eACb,EAAc,EACZ,EAAW,KAAM,GAAI,qBACrB,EAAW,KAAM,GAAI,oBAC3B,CACE,GAAM,GAAK,EAAI,uBACf,AAAI,EAAW,GAAK,GAAM,MACxB,IAAe,EAAW,GAG9B,CACE,GAAM,GAAK,EAAI,uBACf,AAAI,EAAW,GAAK,GAAM,MACxB,IAAe,EAAW,GAG9B,CACE,GAAM,GACJ,EAAc,EAAI,EAAc,KAAoB,OAChD,EACJ,EAAI,iBAAiB,WAAa,EAC9B,EACE,EAAI,iBAAiB,WACrB,GAAO,GAAW,GAAY,GAEhC,OACN,KAAK,OAAO,KAAK,OAAQ,GACvB,OACA,OACA,oBAAqB,EAAI,iBAAiB,YACvC,EAAI,UAET,EAAI,GAAI,EAAQ,CAAC,EAAM,KAAS,GAAO,KAAK,IAAI,KAAK,GAAM,MAG/D,MAAO,KC7bX,GAAM,IAAS,EAAK,IAAM,EAAS,cAEtB,GAAsB,GAAI,IAAO,GAAK,GAOnD,mBAAgC,CAC9B,MAAO,IAAY,KAAW,GAC5B,EAAI,YAAc,IAAS,EAAI,EAAI,MAC/B,EAAQ,GAAe,EAAI,WAAY,GAAM,GAAQ,EACnD,WAAY,EAAI,WAChB,IAAK,EAAI,cAEX,QAIR,YAA4B,EAAc,CACxC,MAAO,GAAQ,EAAE,MAAO,GAAQ,EAAE,WAAY,EAAE,WAAY,SAG9D,YAA6B,EAAoB,CAC/C,MAAO,GAAQ,GAAe,GAAa,GAAQ,EACjD,aACA,IAAK,EAAI,cAIb,mBAA2B,CACzB,MAAO,IAAY,EAAS,UAAU,OAAQ,IAGhD,mBAAoC,CAClC,GAAM,GAAiB,GACvB,EAAI,KAAK,GAAI,KAAM,OACf,EAAS,cAAc,gBACzB,EAAI,KAAK,GAAI,KAAM,OAGrB,GAAM,GAAK,KAAM,IAAU,KAAuB,GAAoB,IACpE,KAAS,MAAM,+BAAgC,EAAS,YAAY,QAGtE,AAAI,EAAS,iBAAiB,gBAC5B,EAAI,QAAQ,GAGV,EAAS,gBAAgB,gBAC3B,EAAI,KAAK,GAGX,GAAY,EAAK,GAAM,EAAG,YAE1B,GAAM,GAAS,KAAM,IACnB,EACA,GACE,CAAC,GAAoB,IAAI,EAAG,aAC5B,GAA8B,EAAG,aAGrC,YAAS,KAAK,cAAe,GACtB,EAKT,mBAA4C,CAC1C,GAAM,GAAO,KAAM,MACb,EAAQ,KAAM,IAAS,QAC7B,MAAO,GAAK,IAAI,GAAS,OACpB,EAAM,KAAK,GAAM,EAAG,MAAQ,EAAK,MACjC,IAIP,mBAAmE,CACjE,GAAM,GAAM,KAAM,MAClB,MAAO,IAAW,GAMpB,kBAAiC,EAAqB,CACpD,GAAM,GAAK,KAAM,IAAU,kBAAkB,CAC3C,KAAM,GAAe,mBAGjB,EAAmB,EACvB,GAAI,UACJ,KAAK,MAAQ,EAAS,kBAAkB,eAAiB,IAMrD,EACJ,GAAM,MAAQ,EAAS,kBAAkB,gBAAkB,EACvD,GACA,EAAI,OAAO,GAAM,CAAC,GAAG,EAAG,gBAAiB,IAE/C,KAAS,KAAK,eAAgB,CAC5B,MACA,mBACA,qBAAsB,EAAqB,IAAI,GAAM,EAAG,cAG1D,CAEE,GAAM,GAAU,KAAK,MAAQ,GAAK,GAC5B,EAAe,EAAqB,OACxC,GAAM,CAAC,GAAG,EAAG,gBAAiB,IAC9B,GACF,GAAI,GAAgB,KAClB,YAAS,KAAK,eAAgB,CAAE,iBACzB,EAIX,KAAS,KACP,qFAGF,CACE,GAAM,GAAsB,GAAW,EAAsB,GAC3D,EAAO,EAAG,cAAe,KAAK,QAGhC,GAAI,GAAuB,KACzB,YAAS,KAAK,eAAgB,CAAE,wBACzB,EAIX,KAAS,KACP,6FAGF,KAAM,IAAU,gBAAgB,CAAE,KAAM,GAAe,mBCjJlD,oBAAyB,GAA+B,CAM7D,YACW,EACA,EACA,EACT,CACA,MAAM,aAAc,IAAM,KAAK,iBAAkB,EAAa,OAJrD,mBACA,wBACA,8BARM,gBAAa,GAAI,IAWhC,AAAK,KAAK,0BAGN,WAAW,CACf,MAAO,GAAQ,KAAK,YAAa,GAAM,EAAG,YAG5C,MAAgB,CACd,MAAO,MAAK,WAAW,QAGzB,aAAc,CACZ,MAAO,MAAK,WAAW,QAGjB,gBAAgC,CACtC,GAAM,GAAI,KAAK,YACf,YAAK,YAAc,OACnB,KAAK,eAAiB,OACf,GAAI,QAGC,aAAY,EAAmB,CAC3C,GAAI,KAAK,MAAO,OAUhB,AAAK,AARK,GAAc,IAAI,CAC1B,KAAM,EAAU,IAAI,EAAI,YACxB,IAAK,EAAI,IAAI,WACb,YAAa,KAAK,YAClB,iBAAkB,KAAK,iBACvB,uBAAwB,KAAK,yBAI5B,KAAK,KAAM,IAAQ,CAClB,KAAK,YAAc,EACnB,KAAK,eAAiB,GAAQ,KAAO,OAAY,EACjD,AAAI,GAAQ,KACV,MAAK,OAAO,KAAK,2CAA4C,GAC7D,KAAM,GAAK,cACX,KAAK,OAAO,KAAK,sBAAuB,IAExC,IAAoB,IAAI,EAAI,YAC5B,KAAK,OAAO,KAAK,mCAAoC,MAGxD,MAAM,GAAO,CACZ,KAAK,OAAO,KAAK,wBAAyB,KAE3C,KAAK,IAAM,KAAK,2BAMf,qBAAqB,CACzB,GAAI,KAAK,OAAS,KAAK,WAAW,SAAU,OAE5C,GAAM,GAAU,KAAM,MACtB,GAAI,GAAW,KACb,MAAK,MAAK,WAAW,UACd,KAAK,iBAId,GAAI,KAAK,gBAAgB,aAAe,EAAQ,WAC9C,MAAO,MAAK,YAAY,KCnFvB,YAA+B,CAKpC,YAAqB,EAAiB,EAAoB,CAArC,YAJb,YAAS,GAyBR,SAAM,EAAK,IAClB,GAAW,KAAK,KAAK,MAAO,IAAM,WAAa,KAAK,KAAK,YAOlD,eAAY,EAAK,SACxB,GAAS,UAAU,KAAM,MAAK,MAAO,KAAK,SA7B1C,KAAK,KAAO,YAAc,EAAO,IACjC,KAAK,KAAO,GAAI,IAAS,KAAK,MAAM,QAAQ,MAG1C,QAAQ,CACV,MAAO,MAAK,OAGd,KAAM,CACJ,KAAK,OAAS,GAGhB,MAAO,CACL,MAAO,MAAK,KAAK,QAGnB,aAAc,CACZ,MAAO,MAAK,KAAK,WAOf,SAAS,CACX,MAAO,MAAK,KAAK,gBAOb,WAAW,CAEf,MAAO,AADG,MAAM,MAAK,aACZ,eAAe,CACtB,MAAO,KAAK,KAAK,QAAU,aAAe,WCjChD,GAAM,IAAS,EAAK,IAAM,EAAS,UAEnC,kBACE,EACA,EACA,EACA,EACA,CACA,GAAI,EAAM,GAAa,OAEvB,GAAM,GAAO,EAAU,IAAI,GAE3B,GAAI,KAAM,GAAK,iBACb,MAAO,IAAI,IAAS,EAAM,EAAS,IAC9B,GAAI,KAAM,GAAK,cAEpB,MAAO,IAAc,IAAI,CACvB,OACA,YAAa,EACb,mBACA,2BAGF,KAAS,KAAK,uDAAyD,GAQpE,oBAAoB,GAA+B,CAiBxD,YAAY,EAA+B,EAAiC,CAC1E,MAAM,SAAS,KAAS,IAAM,GAAI,KAAK,aAAc,EAAa,OADzB,cAD1B,WAAQ,GAAI,IAOrB,SAAM,EAAK,SAAY,CAC7B,GAAI,CACF,OAAW,KAAS,MAAK,OAAQ,CAC/B,GAAM,GAAO,KAAM,KACnB,AAAI,GAAQ,MACZ,MAAK,YAAc,EACnB,KAAM,GAAK,eAEb,AAAK,KAAK,MAAM,gBACT,EAAP,CACA,EAAQ,qBAAsB,GACzB,KAAK,MAAM,OAAO,MAfzB,AAAK,KAAK,YAlBL,UACL,EACA,EACA,EACA,EACO,CACP,MAAO,IAAI,IACT,uBACA,EAAI,GAAO,IAAI,GAAQ,IACrB,GAAY,EAAM,EAAa,EAAkB,KA4BvD,MAAgB,CACd,MAAO,CAAC,KAAK,MAAM,QAGrB,aAA6B,CAC3B,MAAO,MAAK,MAAM,aAGd,WAAW,CACf,MAAO,GAAI,KAAK,YAAa,GAAM,EAAG,crMpB1C,GAAM,IAAS,EAAS,eAiBjB,QAAkB,CAiBvB,YACmB,EAAwB,WAAE,KAAK,MAAM,GAC7C,EAAyB,GAClC,CAFiB,mBACR,UAlBM,YAAS,EAAS,eAGlB,qBAAkB,EACjC,IAAM,GAAI,IAAgB,IAAM,KAAK,SAE/B,kBAAe,EA0Fd,iBAA6B,KACpC,IAC+B,CAC/B,GAAI,CACF,MAAO,MAAM,MAAK,YAAY,GAAI,IAAqB,UAChD,EAAP,CACA,UAAO,KAAK,qBAAuB,EAAY,GACxC,CAAE,KAAM,EAAY,WAId,WAAQ,EAAK,SAAY,CACxC,GAAI,KAAM,IAAS,KAAK,QAAQ,OAAQ,CACtC,KAAK,OAAO,KAAK,kDACjB,OAGF,GAAY,GAAG,EAAI,KAAK,cAEpB,EAAS,UAAU,gBACrB,MAAK,OAAO,KAAK,iDACjB,KAAM,OAGR,GAAM,GAAU,GAAQ,mBACxB,KAAK,OAAO,KAAK,0BAA4B,EAAQ,SAErD,KAAM,GAAQ,MAEV,EAAS,QAAQ,gBACnB,MAAK,OAAO,KACV,gEAEF,KAAM,OAGR,KAAK,gBAAkB,KAAM,MAAK,oBAElC,KAAM,MAAK,OAGX,KAAM,MAAK,kBAIX,KAAK,QAAQ,gBAAgB,WAAY,IAAM,KAAK,UACpD,KAAK,QAAQ,gBAAgB,gBAAiB,IAAM,KAAK,cACzD,WAAE,GAAG,UAAW,IAAM,KAAK,cAEvB,IAAU,EAAW,KAAK,cAC5B,GAAc,GAAM,QAAQ,IAAI,EAAU,KAG5C,GAAM,GAAe,GACrB,GAAa,GAAG,cAAe,GAC7B,KAAK,YAAY,GAAI,QAAS,EAAO,GAAI,MAAO,IAAO,IAGzD,GAAa,GAAG,kBAAmB,GACjC,KAAK,gBAAgB,GAAI,YAAa,EAAO,GAAI,MAAO,MAG1D,GAAiB,IAAM,KAAK,oCAeb,sBAAmB,GAAI,KA8DvB,uBAAoB,EAAK,SAAY,CACpD,KAAK,iBAAiB,QACtB,GAAM,GAAW,KAAM,IAAc,aACrC,GAAI,GAAY,KACd,MAAO,MAAK,OAAO,MAAM,4BAE3B,KAAK,OAAO,KAAK,yCAA2C,GAE5D,GAAM,GAAmB,GAAuB,EAE1C,EAAK,GAAI,iBAAa,CAC1B,eAAgB,IACd,MAAK,OAAO,KAAK,yBAA0B,CACzC,SAAU,QAAQ,SAClB,SAAU,EAAS,WACnB,SAAU,OAEL,GACL,QAAQ,SACR,CAAC,GAAG,GAAS,aAAc,EAAS,YACpC,IAIJ,SAAU,KAAoB,EAE9B,oBAAqB,EAAI,EACzB,mBAAoB,EAAS,mBAAmB,eAGhD,mBAAoB,EACpB,kBAAmB,OACnB,0BAA2B,EAC3B,mBACA,eAAgB,YAChB,KAAM,GACN,KAAM,GACN,YAAa,SACb,kBAAmB,KAGrB,SAAG,GAAG,WAAY,CAAC,EAAuB,IAAS,CACjD,AAAI,GAAQ,MAAQ,GAAQ,MAC1B,KAAK,iBAAiB,IAAI,EAAI,KAAQ,QAAQ,KAI3C,GAAI,IAAqB,YAAa,EAAI,EAAa,SAc/C,4BAAyB,IACxC,EACE,KAAK,gBACL,GAAM,EAAG,EAAE,UAAY,EAAG,EAAE,aAC5B,IAAM,GAGO,kBAAe,EAAK,IAC5B,GAAQ,mBAAmB,WAGnB,sBAAmB,AAAC,GACnC,KAAK,gBAAgB,EAAa,IAEnB,oBAAiB,EAAK,SAAY,CACjD,GAAI,EAAS,iBAAiB,eAAgB,CAC5C,KAAK,OAAO,KAAK,uCACjB,OAEF,GAAM,GAAM,GAAI,IAAe,CAC7B,iBAAkB,KAAK,iBACvB,aAAc,AAAC,GACN,KAAK,YAAY,EAAS,GAAO,IAE1C,oBAAqB,AAAC,GACb,KAAK,oBAAoB,EAAS,IAE3C,uBAAwB,KAAK,yBAK/B,MAAK,GAAI,cAAc,KAAK,SAAY,CAEtC,KAAK,OAAO,KAAK,6BACZ,KAAK,KAAK,YAEjB,EAAI,cAAc,MAAM,GAAO,CAC7B,EAAQ,wBAAyB,GAC5B,KAAK,KAAK,YAGV,IAGQ,uBAAoB,EAAK,IAAM,CAC9C,GAAM,GAAM,GAAI,IAChB,MAAK,GAAI,cAAc,KAAK,SAAY,CAEtC,KAAK,OAAO,KAAK,sDACZ,KAAK,KAAK,YAEV,IAQA,oCAAiC,GAAS,SAAY,CAC7D,GAAM,GAAI,KAAM,MAAK,KAAK,QAC1B,AAAI,YAAa,KACV,EAAE,sBAER,IAEM,UAAO,EAAK,SAAY,CAC/B,KAAM,MAAK,eAEX,CACE,GAAM,GAAM,KAAM,MAAK,iBACvB,GAAI,GAAO,MAAQ,CAAC,EAAI,OACtB,MAAO,GAIX,CACE,GAAM,GAAM,KAAK,oBACjB,GAAI,CAAC,EAAI,OACP,MAAO,GAIX,GAAM,GAAS,EAAW,KAAK,aAC3B,GAAM,SACJ,KAAK,YACL,KAAK,YACL,KAAK,iBACL,KAAK,wBAEP,GAAI,IACF,KAAK,YACL,KAAK,iBACL,KAAK,wBAGX,MAAI,MAAK,cACF,GAAM,GACR,KAAK,IAAM,EAAI,EAAQ,GAAM,EAAG,gBAChC,KAAK,IAAM,GAAM,IACjB,MAAM,GACL,KAAK,QAAQ,KAAK,CAChB,OAAQ,UAAY,EACpB,OAAQ,GACR,YAAa,MAGhB,KAAK,IACJ,KAAK,QAAQ,KAAK,CAChB,OAAQ,WACR,OAAQ,EACR,YAAa,MAKd,IAzYP,GAAc,EAAa,GAC3B,GAAY,GAAG,GACf,KAAK,aACH,EAAS,aAAa,gBAAkB,EAAW,GACrD,KAAK,QAAU,GAAI,IAAQ,CACzB,KAAM,SAGR,GAAkB,IAIhB,KAAK,QAAQ,KAAK,CAChB,OAAQ,kBACR,OAAQ,EACR,YAAa,MAIjB,KAAK,QAAQ,MAAM,GACjB,EAAQ,iBAAkB,GAAI,IAAa,CAAE,MAAO,EAAK,MAAO,OAIlE,KAAK,eAAiB,GAAI,IAAe,GAAa,EAAI,EAAU,GAClE,EAAE,UAAU,SAAS,KAIvB,GAAI,IACF,SAAY,EAAU,IAAI,KAAM,OAChC,EAAS,oBAAoB,eAAiB,EAC9C,GAAK,EAAE,UAAU,SAAS,UAIxB,OAAyB,CAC7B,GAAM,GAAI,KAAM,MAAK,OACrB,MAAO,IAAK,MAAQ,EAAE,OAGhB,aAAc,CACpB,KAAK,eACD,KAAK,aAAe,IAAO,GACxB,KAAK,eAAe,eAIvB,SAAS,CACb,GAAI,CACF,GAAM,GAAI,KAAM,MAAK,KAAK,QACpB,EAAK,KAAM,MACjB,AAAI,IAAQ,IAAO,GAAO,IAAO,GAAQ,KACvC,MAAK,OAAO,KACV,wDACA,GAEG,KAAK,eAAe,QAAQ,KAAK,eAAe,SAAW,IAGlE,GAAM,GAAyB,CAC7B,YAAa,EAAS,YAAY,MAClC,QAAS,EAAS,QAAQ,MAC1B,OAAQ,IACR,KAAM,KAAM,MAAK,OACjB,KAAM,EAAI,EAAG,GAAM,EAAG,MACtB,aAAc,EACd,SAAU,KAAM,IAAG,YAErB,GAAY,SACL,EAAP,CACA,GAAY,CAAE,gBAsEZ,mBAAkB,EAAoB,CAC1C,GAAM,GAAQ,KAAK,MACb,EAAS,KAAM,MAAK,YAAY,GAAI,IAAW,IACrD,MAAI,KACF,GAAY,SACP,GADO,CAEV,UAAW,KAAK,MAAQ,IACrB,IAEA,OAKK,aAAe,EAAgC,CAC3D,GAAI,IAAU,OACd,KAAM,MAAK,QACX,GAAM,GAAK,KAAM,MAAK,iBAAiB,EACvC,MAAI,IAAM,KACD,KAAK,OAAO,MAAM,gCAEpB,GACL,SAAY,CACV,GAAI,IAAU,OACd,GAAM,GAAM,EAAI,GAChB,GAAI,CACF,YAAK,iBAAiB,IACpB,EACA,GAAI,IAAQ;AAAA,EAAM,GAAM,KAAK,WAAW,GAAK,KAExC,KAAM,GAAG,YAAY,UAC5B,CACA,KAAK,cACL,KAAK,iBAAiB,OAAO,KAGjC,CACE,WAAY,EACZ,iBAAkB,UAKlB,aAAY,EAAiB,EAAgB,EAAuB,CACxE,YAAK,OAAO,KAAK,yBAA0B,CAAE,UAAS,QAAO,iBACtD,GAAO,EAAS,GACrB,KAAK,kBAAkB,CAAE,cAAe,EAAI,QAAO,uBAIjD,iBAAgB,EAAqB,EAAgB,CACzD,YAAK,OAAO,KAAK,4BAA6B,CAAE,gBACzC,GAAO,EAAa,GACzB,KAAK,kBAAkB,CAAE,kBAAmB,EAAI,gBAI9C,qBAAoB,EAAiB,EAAgB,CACzD,YAAK,OAAO,KAAK,gCAAiC,CAAE,YAC7C,GAAO,EAAS,GACrB,KAAK,kBAAkB,CAAE,qBAAsB,EAAI,gBAIjD,aAAa,CACjB,GAAM,GAAI,KAAM,MAAK,OACrB,AAAK,EAAE,OAIL,KAAK,OAAO,KAAK,iCAHjB,MAAK,OAAO,KAAK,wCACjB,KAAM,GAAE,OAwDJ,WAAW,EAAW,CAC5B,GAAM,GAAO,EACX,GAAI,IAAM,KAAK,MAAM,IACrB,IAEF,AAAI,GAAc,IACZ,KAAQ,GAAY,GACxB,GAAgB,SA2Dd,cAAc,CAClB,YAAM,IAAI,KAAK,KAAK,QAAS,GACtB,KAAK,SsM/bhB,GAAI,CACF,AAAQ,KAAsB,eAC9B,EAYF,mBAAqB,CACnB,GAAM,GAAM,KAAM,IAAI,IACpB,OACA,4BACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qJAEC,IACC,GACA,GACA,GACA,GACA,GACA,IAED,QACH,GAAI,IAAY,EAAI,MAGtB,AAAK",
  "names": []
}
